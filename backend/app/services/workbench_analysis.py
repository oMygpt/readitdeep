"""
Read it DEEP - å·¥ä½œå°åˆ†ææœåŠ¡

åŠŸèƒ½:
- æ–¹æ³•ç‚¼é‡‘å°: æç‚¼ç ”ç©¶æ–¹æ³• + å®¡ç¨¿è§†è§’åˆ†æ
- èµ„äº§ä»“åº“: è¯†åˆ« GitHub/Huggingface/æ•°æ®é›†ç­‰èµ„æº
- æ™ºèƒ½ç¬”è®°: ä¿å­˜åŸæ–‡ + å¿ƒå¾— + ä½ç½®ä¿¡æ¯
"""

import json
import logging
import re
from typing import Optional
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from app.config import get_settings
from app.agents.prompt_loader import get_prompt_loader
from app.core.workbench_store import workbench_store
from app.core.token_tracker import get_tracking_callback

logger = logging.getLogger(__name__)
settings = get_settings()


# ç§»é™¤å…¨å±€ LLM åˆå§‹åŒ–
# llm = ChatOpenAI(...) 

from app.core.store import store
from app.core.config_manager import ConfigManager
from app.core.database import async_session_maker, get_db

async def get_llm_for_paper(paper_id: str):
    """æ ¹æ®è®ºæ–‡å½’å±è·å–é…ç½®å¥½çš„ LLM å®ä¾‹"""
    paper = store.get(paper_id)
    user_id = paper.get("user_id") if paper else None
    
    async with async_session_maker() as db:
        config = await ConfigManager.get_effective_config(db, user_id)
        
    return ChatOpenAI(
        base_url=config.get("llm_base_url") or settings.llm_base_url,
        api_key=config.get("llm_api_key") or settings.llm_api_key or "dummy",
        model=config.get("llm_model") or settings.llm_model,
        temperature=0.3,
        request_timeout=90,  # 90 seconds timeout for LLM calls
    )

async def analyze_method(
    text: str,
    paper_id: str,
    paper_title: str,
    location: str = "",
) -> dict:
    """
    æ–¹æ³•ç‚¼é‡‘å°åˆ†æ
    
    æç‚¼ç ”ç©¶æ–¹æ³•ï¼Œç”Ÿæˆä¼ªä»£ç ï¼Œä»¥å®¡ç¨¿è§†è§’åˆ†æ
    """
    llm = await get_llm_for_paper(paper_id)
    
    loader = get_prompt_loader()
    prompt_file = loader.get_prompt("workbench_method")
    
    if not prompt_file:
        # Fallback prompt
        system_prompt = "ä½ æ˜¯ä¸€ä½èµ„æ·±å­¦æœ¯å®¡ç¨¿äººå’Œç ”ç©¶æ–¹æ³•ä¸“å®¶ã€‚"
        user_prompt = f"åˆ†æä»¥ä¸‹è®ºæ–‡ç‰‡æ®µï¼Œæç‚¼ç ”ç©¶æ–¹æ³•:\n\n{text}"
    else:
        system_prompt = prompt_file.system_prompt
        user_prompt = prompt_file.user_prompt_template.format(
            text=text,
            paper_title=paper_title,
            location=location,
        )
    
    try:
        callback = get_tracking_callback("workbench_method")
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ], config={"callbacks": [callback]})
        
        content = response.content
        
        # å¥å£®çš„ JSON æå–é€»è¾‘
        analysis = None
        
        # æ–¹æ³• 1: å°è¯•ä» ```json ... ``` ä»£ç å—æå–
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            try:
                analysis = json.loads(json_match.group(1).strip())
            except json.JSONDecodeError as e:
                logger.warning(f"JSON code block parse failed: {e}")
        
        # æ–¹æ³• 2: å°è¯•ä» ``` ... ``` ä»£ç å—æå–ï¼ˆæ—  json æ ‡è®°ï¼‰
        if analysis is None:
            json_match = re.search(r'```\s*(.*?)\s*```', content, re.DOTALL)
            if json_match:
                try:
                    analysis = json.loads(json_match.group(1).strip())
                except json.JSONDecodeError:
                    pass
        
        # æ–¹æ³• 3: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹ï¼ˆå»é™¤å‰åç©ºç™½ï¼‰
        if analysis is None:
            try:
                analysis = json.loads(content.strip())
            except json.JSONDecodeError:
                pass
        
        # æ–¹æ³• 4: å°è¯•æå–ä» { å¼€å§‹åˆ°æœ€åä¸€ä¸ª } çš„å†…å®¹
        if analysis is None:
            brace_match = re.search(r'\{.*\}', content, re.DOTALL)
            if brace_match:
                try:
                    analysis = json.loads(brace_match.group(0))
                except json.JSONDecodeError as e:
                    logger.error(f"JSON brace extraction failed: {e}, extracted: {brace_match.group(0)[:200]}")
        
        # æœ€ç»ˆå›é€€: å°è£…ä¸ºç®€å•å¯¹è±¡
        if analysis is None:
            logger.warning(f"All JSON parsing methods failed for workbench_method, raw content: {content[:300]}")
            analysis = {"method_name": "Analysis Result", "core_idea": content[:200], "full_text": content}
        
        # ä»æ–°æ¨¡æ¿æ ¼å¼ä¸­æå–ä¿¡æ¯
        # æ–°æ¨¡æ¿è¿”å›: paper_type, methods[], hypotheses_or_goals[]
        # å…¼å®¹æ—§æ ¼å¼: method_name, core_idea
        if "methods" in analysis and isinstance(analysis["methods"], list) and len(analysis["methods"]) > 0:
            # æ–°æ ¼å¼: ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–¹æ³•ä½œä¸ºä¸»æ–¹æ³•å
            first_method = analysis["methods"][0]
            method_name = first_method.get("name", "æœªå‘½åæ–¹æ³•")
            core_idea = first_method.get("description", "")
            # å¦‚æœæœ‰ paper_typeï¼Œæ·»åŠ åˆ°æè¿°ä¸­
            if analysis.get("paper_type"):
                core_idea = f"[{analysis['paper_type']}] {core_idea}"
        else:
            # å…¼å®¹æ—§æ ¼å¼æˆ–æ— æ–¹æ³•æƒ…å†µ
            method_name = analysis.get("method_name", analysis.get("paper_type", "æœªå‘½åæ–¹æ³•"))
            core_idea = analysis.get("core_idea", analysis.get("description", text[:100]))
        
        # ä¿å­˜åˆ°å·¥ä½œå°
        item = workbench_store.add_item(
            type="method",
            title=method_name,
            description=core_idea,
            source_paper_id=paper_id,
            zone="methods",
            data={
                "analysis": analysis,
                "original_text": text,
                "location": location,
                "analyzed_at": datetime.utcnow().isoformat(),
            },
        )
        
        return {
            "success": True,
            "item_id": item.id,
            "analysis": analysis,
        }
        
    except Exception as e:
        logger.error(f"Method analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
        }


async def analyze_asset(
    text: str,
    paper_id: str,
    paper_title: str,
    location: str = "",
) -> dict:
    """
    èµ„äº§ä»“åº“åˆ†æ
    
    è¯†åˆ« GitHub/Huggingface/æ•°æ®é›†ç­‰å¯å¤ç”¨èµ„æº
    """
    llm = await get_llm_for_paper(paper_id)
    
    loader = get_prompt_loader()
    prompt_file = loader.get_prompt("workbench_asset")
    
    if not prompt_file:
        system_prompt = "ä½ æ˜¯ä¸€ä½å­¦æœ¯èµ„æºæ•´ç†ä¸“å®¶ã€‚"
        user_prompt = f"è¯†åˆ«ä»¥ä¸‹è®ºæ–‡ç‰‡æ®µä¸­çš„å¯å¤ç”¨èµ„æº:\n\n{text}"
    else:
        system_prompt = prompt_file.system_prompt
        user_prompt = prompt_file.user_prompt_template.format(
            text=text,
            paper_title=paper_title,
            location=location,
        )
    
    try:
        callback = get_tracking_callback("workbench_asset")
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ], config={"callbacks": [callback]})
        
        content = response.content
        
        # å¥å£®çš„ JSON æå–é€»è¾‘
        analysis = None
        
        # æ–¹æ³• 1: å°è¯•ä» ```json ... ``` ä»£ç å—æå–
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            try:
                analysis = json.loads(json_match.group(1).strip())
            except json.JSONDecodeError as e:
                logger.warning(f"JSON code block parse failed in asset: {e}")
        
        # æ–¹æ³• 2: å°è¯•ä» ``` ... ``` ä»£ç å—æå–ï¼ˆæ—  json æ ‡è®°ï¼‰
        if analysis is None:
            json_match = re.search(r'```\s*(.*?)\s*```', content, re.DOTALL)
            if json_match:
                try:
                    analysis = json.loads(json_match.group(1).strip())
                except json.JSONDecodeError:
                    pass
        
        # æ–¹æ³• 3: å°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹ï¼ˆå»é™¤å‰åç©ºç™½ï¼‰
        if analysis is None:
            try:
                analysis = json.loads(content.strip())
            except json.JSONDecodeError:
                pass
        
        # æ–¹æ³• 4: å°è¯•æå–ä» { å¼€å§‹åˆ°æœ€åä¸€ä¸ª } çš„å†…å®¹
        if analysis is None:
            brace_match = re.search(r'\{.*\}', content, re.DOTALL)
            if brace_match:
                try:
                    analysis = json.loads(brace_match.group(0))
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON brace extraction failed in asset: {e}")
        
        # æœ€ç»ˆå›é€€: ç©ºèµ„äº§åˆ—è¡¨
        if analysis is None:
            logger.warning(f"All JSON parsing methods failed for workbench_asset, raw content: {content[:300]}")
            analysis = {"assets": []}
        
        # ä¸ºæ¯ä¸ªè¯†åˆ«åˆ°çš„èµ„äº§åˆ›å»ºæ¡ç›®
        created_items = []
        assets = analysis.get("assets", [])
        
        for asset in assets:
            item = workbench_store.add_item(
                type="dataset" if asset.get("type") == "dataset" else "code",
                title=asset.get("name", "æœªå‘½åèµ„æº"),
                description=asset.get("description", ""),
                source_paper_id=paper_id,
                zone="datasets",
                data={
                    "asset": asset,
                    "original_text": text,
                    "location": location,
                    "analyzed_at": datetime.utcnow().isoformat(),
                },
            )
            created_items.append(item.id)
        
        return {
            "success": True,
            "item_ids": created_items,
            "analysis": analysis,
            "assets_count": len(assets),
        }
        
    except Exception as e:
        logger.error(f"Asset analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
        }


def create_smart_note(
    text: str,
    paper_id: str,
    paper_title: str,
    location: str = "",
    is_title_note: bool = False,
    reflection: str = "",
) -> dict:
    """
    åˆ›å»ºæ™ºèƒ½ç¬”è®°
    
    ä¿ç•™åŸæ–‡ï¼Œè®°å½•ä½ç½®ï¼Œæ”¯æŒç”¨æˆ·å¿ƒå¾—
    """
    item = workbench_store.add_item(
        type="note",
        title=f"ğŸ“ {paper_title[:30]}..." if is_title_note else f"ğŸ“Œ {text[:30]}...",
        description=reflection if reflection else "ç‚¹å‡»æ·»åŠ å¿ƒå¾—...",
        source_paper_id=paper_id,
        zone="notes",
        data={
            "original_text": text,
            "location": location,
            "is_title_note": is_title_note,
            "reflection": reflection,
            "reflection_updated_at": None,
            "created_at": datetime.utcnow().isoformat(),
        },
    )
    
    return {
        "success": True,
        "item_id": item.id,
        "item": {
            "id": item.id,
            "title": item.title,
            "description": item.description,
            "data": item.data,
        },
    }





def update_note_reflection(item_id: str, reflection: str) -> dict:
    """
    æ›´æ–°ç¬”è®°å¿ƒå¾—
    """
    success = workbench_store.update_item(item_id, {
        "description": reflection[:100] + "..." if len(reflection) > 100 else reflection,
        "data": {
            **workbench_store.get_item(item_id).get("data", {}),
            "reflection": reflection,
            "reflection_updated_at": datetime.utcnow().isoformat(),
        },
    })
    
    if success:
        return {
            "success": True,
            "item_id": item_id,
        }
    else:
        return {
            "success": False,
            "error": "Item not found",
        }


async def analyze_summary(
    text: str,
    paper_id: str,
    paper_title: str,
) -> dict:
    """
    ç”Ÿæˆè®ºæ–‡æ‘˜è¦ (Smart Summary)
    """
    llm = await get_llm_for_paper(paper_id)
    
    loader = get_prompt_loader()
    prompt_file = loader.get_prompt("summary")
    
    if not prompt_file:
        system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†æå¸ˆã€‚"
        user_prompt = f"è¯·ä¸ºä»¥ä¸‹è®ºæ–‡ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ·±åº¦æ‘˜è¦:\n\n{text}"
    else:
        system_prompt = prompt_file.system_prompt
        user_prompt = prompt_file.user_prompt_template.format(
            content=text,  # Summary prompt uses {content}
            text=text,     # Fallback if uses {text}
            paper_title=paper_title,
        )
    
    try:
        callback = get_tracking_callback("agent_summary")
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ], config={"callbacks": [callback]})
        
        summary = response.content.strip()
        
        return {
            "success": True,
            "summary": summary,
        }
        
    except Exception as e:
        logger.error(f"Summary analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
        }
