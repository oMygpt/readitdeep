"""
Read it DEEP - å·¥ä½œå°åˆ†æžæœåŠ¡

åŠŸèƒ½:
- æ–¹æ³•ç‚¼é‡‘å°: æç‚¼ç ”ç©¶æ–¹æ³• + å®¡ç¨¿è§†è§’åˆ†æž
- èµ„äº§ä»“åº“: è¯†åˆ« GitHub/Huggingface/æ•°æ®é›†ç­‰èµ„æº
- æ™ºèƒ½ç¬”è®°: ä¿å­˜åŽŸæ–‡ + å¿ƒå¾— + ä½ç½®ä¿¡æ¯
"""

import json
import logging
import re
from typing import Optional
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

from app.config import get_settings
from app.agents.prompt_loader import get_prompt_loader
from app.core.workbench_store import workbench_store

logger = logging.getLogger(__name__)
settings = get_settings()


# ç§»é™¤å…¨å±€ LLM åˆå§‹åŒ–
# llm = ChatOpenAI(...) 

from app.core.store import store
from app.core.config_manager import ConfigManager
from app.core.database import async_session_maker, get_db

async def get_llm_for_paper(paper_id: str):
    """æ ¹æ®è®ºæ–‡å½’å±žèŽ·å–é…ç½®å¥½çš„ LLM å®žä¾‹"""
    paper = store.get(paper_id)
    user_id = paper.get("user_id") if paper else None
    
    async with async_session_maker() as db:
        config = await ConfigManager.get_effective_config(db, user_id)
        
    return ChatOpenAI(
        base_url=config.get("llm_base_url") or settings.llm_base_url,
        api_key=config.get("llm_api_key") or settings.llm_api_key or "dummy",
        model=config.get("llm_model") or settings.llm_model,
        temperature=0.3,
        request_timeout=90,  # 90 seconds timeout for LLM calls
    )

async def analyze_method(
    text: str,
    paper_id: str,
    paper_title: str,
    location: str = "",
) -> dict:
    """
    æ–¹æ³•ç‚¼é‡‘å°åˆ†æž
    
    æç‚¼ç ”ç©¶æ–¹æ³•ï¼Œç”Ÿæˆä¼ªä»£ç ï¼Œä»¥å®¡ç¨¿è§†è§’åˆ†æž
    """
    llm = await get_llm_for_paper(paper_id)
    
    loader = get_prompt_loader()
    prompt_file = loader.get_prompt("workbench_method")
    
    if not prompt_file:
        # Fallback prompt
        system_prompt = "ä½ æ˜¯ä¸€ä½èµ„æ·±å­¦æœ¯å®¡ç¨¿äººå’Œç ”ç©¶æ–¹æ³•ä¸“å®¶ã€‚"
        user_prompt = f"åˆ†æžä»¥ä¸‹è®ºæ–‡ç‰‡æ®µï¼Œæç‚¼ç ”ç©¶æ–¹æ³•:\n\n{text}"
    else:
        system_prompt = prompt_file.system_prompt
        user_prompt = prompt_file.user_prompt_template.format(
            text=text,
            paper_title=paper_title,
            location=location,
        )
    
    try:
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ])
        
        content = response.content
        
        # å°è¯•è§£æž JSON
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            try:
                analysis = json.loads(json_match.group(1))
            except json.JSONDecodeError:
                analysis = {"error": "JSON parse failed", "raw": content} 
        else:
            # å°è¯•ç›´æŽ¥è§£æž
            try:
                analysis = json.loads(content)
            except json.JSONDecodeError:
                # å‡å¦‚è¿”å›žçš„ä¸æ˜¯JSONï¼Œå°è¯•å°è£…
                analysis = {"method_name": "Analysis Result", "core_idea": content[:200], "full_text": content}
        
        # ä¿å­˜åˆ°å·¥ä½œå°
        item = workbench_store.add_item(
            type="method",
            title=analysis.get("method_name", "æœªå‘½åæ–¹æ³•"),
            description=analysis.get("core_idea", text[:100]),
            source_paper_id=paper_id,
            zone="methods",
            data={
                "analysis": analysis,
                "original_text": text,
                "location": location,
                "analyzed_at": datetime.utcnow().isoformat(),
            },
        )
        
        return {
            "success": True,
            "item_id": item.id,
            "analysis": analysis,
        }
        
    except Exception as e:
        logger.error(f"Method analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
        }


async def analyze_asset(
    text: str,
    paper_id: str,
    paper_title: str,
    location: str = "",
) -> dict:
    """
    èµ„äº§ä»“åº“åˆ†æž
    
    è¯†åˆ« GitHub/Huggingface/æ•°æ®é›†ç­‰å¯å¤ç”¨èµ„æº
    """
    llm = await get_llm_for_paper(paper_id)
    
    loader = get_prompt_loader()
    prompt_file = loader.get_prompt("workbench_asset")
    
    if not prompt_file:
        system_prompt = "ä½ æ˜¯ä¸€ä½å­¦æœ¯èµ„æºæ•´ç†ä¸“å®¶ã€‚"
        user_prompt = f"è¯†åˆ«ä»¥ä¸‹è®ºæ–‡ç‰‡æ®µä¸­çš„å¯å¤ç”¨èµ„æº:\n\n{text}"
    else:
        system_prompt = prompt_file.system_prompt
        user_prompt = prompt_file.user_prompt_template.format(
            text=text,
            paper_title=paper_title,
            location=location,
        )
    
    try:
        response = await llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ])
        
        content = response.content
        
        # è§£æž JSON
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            try:
                analysis = json.loads(json_match.group(1))
            except json.JSONDecodeError:
                analysis = {"assets": []}
        else:
            try:
                analysis = json.loads(content)
            except json.JSONDecodeError:
                analysis = {"assets": []}
        
        # ä¸ºæ¯ä¸ªè¯†åˆ«åˆ°çš„èµ„äº§åˆ›å»ºæ¡ç›®
        created_items = []
        assets = analysis.get("assets", [])
        
        for asset in assets:
            item = workbench_store.add_item(
                type="dataset" if asset.get("type") == "dataset" else "code",
                title=asset.get("name", "æœªå‘½åèµ„æº"),
                description=asset.get("description", ""),
                source_paper_id=paper_id,
                zone="datasets",
                data={
                    "asset": asset,
                    "original_text": text,
                    "location": location,
                    "analyzed_at": datetime.utcnow().isoformat(),
                },
            )
            created_items.append(item.id)
        
        return {
            "success": True,
            "item_ids": created_items,
            "analysis": analysis,
            "assets_count": len(assets),
        }
        
    except Exception as e:
        logger.error(f"Asset analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
        }


def create_smart_note(
    text: str,
    paper_id: str,
    paper_title: str,
    location: str = "",
    is_title_note: bool = False,
    reflection: str = "",
) -> dict:
    """
    åˆ›å»ºæ™ºèƒ½ç¬”è®°
    
    ä¿ç•™åŽŸæ–‡ï¼Œè®°å½•ä½ç½®ï¼Œæ”¯æŒç”¨æˆ·å¿ƒå¾—
    """
    item = workbench_store.add_item(
        type="note",
        title=f"ðŸ“ {paper_title[:30]}..." if is_title_note else f"ðŸ“Œ {text[:30]}...",
        description=reflection if reflection else "ç‚¹å‡»æ·»åŠ å¿ƒå¾—...",
        source_paper_id=paper_id,
        zone="notes",
        data={
            "original_text": text,
            "location": location,
            "is_title_note": is_title_note,
            "reflection": reflection,
            "reflection_updated_at": None,
            "created_at": datetime.utcnow().isoformat(),
        },
    )
    
    return {
        "success": True,
        "item_id": item.id,
        "item": {
            "id": item.id,
            "title": item.title,
            "description": item.description,
            "data": item.data,
        },
    }


def update_note_reflection(item_id: str, reflection: str) -> dict:
    """
    æ›´æ–°ç¬”è®°å¿ƒå¾—
    """
    success = workbench_store.update_item(item_id, {
        "description": reflection[:100] + "..." if len(reflection) > 100 else reflection,
        "data": {
            **workbench_store.get_item(item_id).get("data", {}),
            "reflection": reflection,
            "reflection_updated_at": datetime.utcnow().isoformat(),
        },
    })
    
    if success:
        return {
            "success": True,
            "item_id": item_id,
        }
    else:
        return {
            "success": False,
            "error": "Item not found",
        }
