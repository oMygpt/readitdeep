{
  "0a6aae26-e1da-42f9-80f6-19a4250dbeaa": {
    "id": "0a6aae26-e1da-42f9-80f6-19a4250dbeaa",
    "filename": "高等教育的数智变革：基本逻辑、趋势特点及实践应对_李雪.pdf",
    "file_path": "./uploads/papers/0a6aae26-e1da-42f9-80f6-19a4250dbeaa.pdf",
    "status": "completed",
    "title": "高等教育的数智变革:",
    "category": null,
    "markdown_content": "# 高等教育的数智变革:\n\n# 基本逻辑、趋势特点及实践应对\n\n李雪 李永强\n\n以ChatGPT、DeepSeek等为代表的智能科学与技术的加速迭代升级及其在人类生产生活中的广泛应用正在不断改变着人类的物质生产方式、知识创新逻辑、人际交往模式和组织行为方式，其对高等教育的影响、渗透和改变远远超出了一般意义上科学技术的教育领域应用层面，引发了高等教育人才培养目标、知识创新生态、课程教学范式和大学治理体系等全方位深层次变革。高等教育正呈现出人才培养目标从专业知识教育转向未来素养培养、知识创新生态从大学组织内部转向多元主体协同、课程教学范式从传统教学转向智慧教育、教育治理体系从技术赋能转向系统重构等许多新的趋势特点。在国家高等教育体系中占据重要地位的高水平研究型大学应深刻把握这些新的趋势特点，全面推进发展范式、创新生态、育人体系、治理体系和评价体系的系统性改革，为我国建成世界高等教育中心、更好地服务教育强国建设发挥好示范引领作用。\n\n关键词：高等教育；数智变革；基本逻辑；趋势特点；高水平研究型大学；应对策略\n\n中图分类号：F0-4；G642 文献标识码：A 文章编号：1003—5656(2025)07—0076—11\n\nDOI:10.16158/j.cnki.51-1312/f.2025.07.007\n\n# 一、引言与文献综述\n\n从历史来看，教育既是推动科学技术革命的重要力量，也是被科学技术不断重塑的重要对象。学校的诞生、文字的出现、印刷术的发明以及电子计算机等现代科学技术在教育领域中广泛运用被视为导致人类四次教育革命的标志性事件。科技革命对教育的影响是深层次、全方位甚至颠覆性的，特别是现代社会，从计算机问世、互联网普及到人工智能的超常崛起，科学技术的迅速发展及其在教育领域的广泛运用推动了教育从思想、内容、方式到体制的重大变革，从而重塑了教育在不同时代的独特形态。\n\n“当前，新一轮科技革命和产业变革蓄势待发，人工智能技术加速迭代，正迎来爆发式发展，深刻改变人类生产生活方式、知识供给模式和科研创新范式，进而重塑思维方式与观念，教育已经进入改变底层逻辑、重塑教育生态，资源共创分享、消弭数字鸿沟，素质能力重构、促进全面发展，全球开放合作、推动文明互鉴的智能时代。”[1]显然，以ChatGPT、DeepSeek等为代表的生成式人工智能大模型在高等教育领域的应用推广引起了广泛关注和讨论，这些讨论主要集中在三个方向：一是研究生成式人工智能在高等教育领域的应用场景、风险挑战与治理对策，[2-6]整体上表现出乐观的欢迎和展望，也分析了包括伦理风险在内的可能局限和隐患。[7-8]有研究者用“ChatGPT究竟是‘阿拉丁神灯’还是‘潘多拉魔盒’”[9]形象概括了“ChatGPT教育应用的潜能与风险”①，ChatGPT既具有赋能教学创新的潜能，也存在诸如学业诚信、过度依赖、伦理问题等风险，这种相对客观的分析在一定程度上既保持了理性的乐观，也警醒过度沉迷的危害。二是聚焦教学内容、教学方式、教师素质、教育治理等高等教育的某个方面、要素或环节来分析人工智能对高等教育的影响，[10-11]总体上朝着更加细化和具体的方向深入。三是深入以ChatGPT\n\n等为代表的生成式人工智能大模型的基本原理、设计理念、技术架构及未来发展去分析把握其对高等教育的深刻影响，[12-13]得出一些更具有科学和技术基础的结论，这类研究对研究者的人工智能素养具有较高的要求。\n\n已有研究开拓了人们对数智革命影响高等教育变革趋势特点的深入认识，其中一些观点、洞见以及相应的实践探索为本文的分析研究提供了很好的借鉴和参照。但我们同时注意到，当前研究视角更侧重于科学技术在教育领域的应用层面，即从教育技术学的视角来审视智能科学与技术对高等教育的影响，缺乏相对宏观的分析视角和系统的分析，尤其是对数智革命如何影响高等教育变革的底层或基本逻辑缺乏深入的分析，没有很好做到“跳出教育看教育”。高等教育作为社会大系统的一个子系统，与整个社会大系统及其他子系统存在着内在的本质联系，与人类的物质生产方式、知识创新逻辑、人际交往模式、组织行为方式等具有深度同构关系。因而，分析数智革命对高等教育的影响不能仅仅局限在教育系统内部，必须深入把握以人工智能为代表的数智革命如何影响高等教育变革的基本逻辑，分析其趋势特点并作出更有前瞻性和针对性的实践应对，而这正是本文关注和分析的重点所在。\n\n# 二、高等教育数智变革的基本逻辑\n\n“人工智能是新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。”[14]数智革命加速创新并快速融入经济社会发展各领域全过程，重塑千行万业的速度之快、辐射范围之广、影响程度之深前所未有。中国、美国、英国、德国、日本等世界主要强国都把加快人工智能的发展作为推动第四次科技革命和产业变革的突破口，相继出台了体现国家意志的重大战略规划和行动，抢占新一轮科技革命和产业变革的制高点。数智革命正在改变人类生活的方方面面，重塑人类社会的整体面貌，进而要求高等教育必须及时作出相应的回应和变革。\n\n# （一）数智革命改变了人类的物质生产方式\n\n“生产力质态的每一次演进和发展，都是以重大科技创新为主导，形成新的生产方式，引发生产力产生质变，推动新的产业变革和社会变革。”[15]2023年6—7月，全球著名咨询机构麦肯锡相继发布《生成式AI的经济潜力：下一个生产力前沿》《2023技术趋势展望》两份研究报告，[16-17]前者通过对47个国家及地区的850种职业（覆盖全球  $80\\%$  以上劳动人口）的深入研究探讨了人工智能发展对全球经济的潜在影响，预测2030年至2060年之间，将有  $50\\%$  的职业逐渐被人工智能所取代，使当前  $60\\% -70\\%$  的工作实现自动化；后者评估认为生成式人工智能(Generative AI)“已经成为一个响亮的入口，并已经显示出变革性商业影响的潜力……在应用性人工智能(Applied AI)和机器学习工业化(Industrializing machine learning)等现有技术的基础上，生成式人工智能(Generative AI)在大多数行业都具有很高的潜力和适用性”。2024年11月，国际权威分析机构沙利文(Frost & Sullivan)发布《2024年中国行业大模型市场报告》，[18]全面分析了包括工业大模型在内的多个领域中国行业大模型发展态势，百度文心、商汤日日新·商量、腾讯混元以及华为盘古等大规模预训练模型在各行业中广泛应用展现出强大的语言理解和生成能力以及跨领域的泛化能力，已经广泛渗透到金融、教育、医疗、电商、传媒、法律等领域，被用于智能客服、智能写作、自动摘要、文本生成、知识问答、个性化推荐等多个应用场景，有效提升行业服务效率和服务质量。\n\n当前，随着自动化系统和机器人在制造业、物流和服务领域的广泛应用，自动化、数字化、智能化已成为智能时代的重要趋势，这不仅大幅提升了生产效率，同时也显著降低了人力成本。从更广的范围来看，传统产业正在为适应科技变革趋势而大规模采用智能化技术，越来越多的传统工作岗位正被自动\n\n化控制系统所替代，同时一系列新产业、新形态、新模式加速涌现，新兴产业和未来产业正在成为发达国家争先抢夺的未来制高点，国家之间在科技领域的激烈竞争正好反映出全球科技生态与未来发展方向的新动向。这一系列变化预示着人类的物质生产方式正在被以人工智能为核心的数智革命所改变、重塑或催生，从而导致了社会生产力形态的革命性变化，催生新质生产力，并引发生产力全球布局、国家经济结构、世界商业模式、社会组织形态等深层次甚至是颠覆性的变革。高等学校作为为人类经济社会发展提供思想、知识、技术和人才的最重要机构，其学科专业的设立演进、教学内容的更新迭代以及课程体系的持续变革，无不映射着高等教育对科技革命及由其推动的产业变革的积极回应。因而，高等教育必须积极适应和引领这种生产力形态的变革趋势，在教育理念、发展战略、培养目标、学科专业布局等方面进行系统性的变革，从而形成适应数智革命的新的发展范式。\n\n# （二）数智革命重塑了人类的知识生产逻辑\n\n马克思认为，“符合社会全部需要的生产”应当包括“劳动力的生产”“物质的生产”和“精神的生产”。[19]26-53科学技术不只是物质生产力函数的重要要素，也是人类知识生产力函数的重要因素，是引发知识生产模式变革的决定性力量。随着数智技术的发展，人们越来越深刻地感知到，知识生产、创造与分享的模式和生态正在发生重大变化。首位华人图灵奖获得者、著名的计算机科学家姚期智说，“从20年前的人脸识别，到后来的下围棋，这些单一的，人类觉得困难的工作，人工智能可以做到超过人类。近年来，伴随大模型的出现，人工智能在语言能力上表现出非凡的智能，我们现在都感觉到，最好的大模型确实比普通人，甚至是受过高等教育的人显得更加聪明。”[20]OpenAI公司相继发布的ChatGPT、Sora和o4，基于对人类认知过程尤其是人脑机制的有限认知，设计了模拟神经网络的transformer架构，并通过参数扩张实现了对认知过程的更精准模拟，其超常学习能力所形成的更为广博的知识积累、能力整合等能更好地突破人脑的局限性，在诸多领域已经表现得比人类更加“智能”，在特定的功能上远超人类大脑。2025年初，国产开源大模型DeepSeek凭借其强大的语言处理、知识推理与专业文本生成能力迅速在国内掀起了一股人工智能热潮，其以自主训练、中文强化、国产算力适配为特点引发了国内众多高校纷纷跟进部署并进行应用开发。\n\n人类传统的知识生产在很大程度上是科学共同体依托学科进行的。人工智能能够跨越学科的界限，整合不同领域的知识和方法，实现对具体问题的多角度、多层次、多维度思考，这突破了传统的学科专业细分领域更加窄化和具体的限制，跨越了传统知识创新的学科界限的束缚，在一定程度上颠覆了人类传统的知识生产逻辑。可以预见的是，随着人工智能的不断迭代升级，其卓越的自然语言理解和生成能力使其可以处理多学科领域的知识，跨越传统学科边界并将不同领域的知识融合在一起，还可以根据用户需求和问题生成高度个性化的知识单元，使知识可以更细化，更有针对性，而不受传统学科框架的限制。近期，DeepMind发布了《A new golden age of discovery-Seizing the AI for Science opportunity》报告，从知识、数据、模型、实验、解决方案五个维度揭示了AI for Science的最新应用前景和结果。[21]2024年，“AI教父”Geoffrey Hinton博士与John Hopfield教授因“他们在机器学习领域的开创性贡献”获得了诺贝尔物理学奖，“AlphaFold之父”Demis Hassabis博士和John Jumper博士以及华盛顿大学David Baker却因为“其借助AI工具分别因蛋白质结构预测和计算蛋白设计的贡献”而获得了诺贝尔化学奖。因而，人工智能对人类知识的生产方式、工具、效率、结果及其呈现方式等都产生了深刻的影响，必然重塑高等教育的知识生产模式和创新生态，并推动高等教育内容生成方式、结果、效率的转变。\n\n# （三）数智革命重构了人类的人际交往模式\n\n人与自然、人与社会、人与自我是人必须处理的三种关系。人的社会性是人的本质属性，这一属性是在人的社会交往中形成并展现出来的，而人与人的对话是社会交往的重要形式和途径，人作为“对话\n\n中的人”是人的交往活动与属性的重要体现。习近平总书记指出，以信息技术、人工智能为代表的新兴科技快速发展，大大拓展了时间、空间和人们认知范围，人类正在进入一个“人机物”三元融合的万物智能互联时代。[22]数字技术发展出人的数字交往这种新的交往方式，而数字技术演进到人工智能大模型后，人与智能机器的对话则具有了人与人对话的功能，以大模型为对象的人机对话将深刻改变人的交往方式，这对人的社会性的形成和发展具有十分重要的意义，或使“人机对话中的人”成为“对话中的人”的新常态。[23]人工智能改变了传统的人际交往模式，特别是第三个智能变量“机”的加入，打破了人际交往的时空限制、虚实界限和结构方式。人工智能已经可以创造虚拟的环境，让人们有更丰富的社交体验。OpenAI“文生视频”大模型Sora展现了令人惊叹的视频生成效果，甚至在部分样片中还展现了对“物理规律”超强的学习能力。可以预料的是，随着人工智能技术的不断进步，在未来人类生活的各个领域必然是一个人与机器人相处的世界。\n\n大学的教育教学范式一定程度上是人际交往模式在高等教育领域的表现，教师的教与学生的学都受到社会人际交互模式的影响。过去许多年来，虽然人工智能常常有各种创新，但“人机交互”都不足以认为可以挑战人类的现场互动，广泛存在的主要互动模式还是师生二元之间的，直到能让机器“听懂人话”的自然语言处理技术被应用于生成式人工智能才从根本上改变人们对“人机交互”的理解，并逐步消解教育的互动性原则。[24]同时，信息技术的快速发展，已使教育的内涵不再仅仅局限于学校之中，移动学习、泛在学习等新型教育模式使得学习的控制权逐渐从教师、管理者转移到了学习者手中，从而动摇了诞生于大工业时代，以标准化、教导主义和教师控制来批量培养人才的现行教育体系。[25][126-141]新一代人工智能技术对教育系统的干预导致了人机协同教育模式的出现，这一变革引发了学习者的学习方式、认知方式和互动模式的转变，并有望塑造以学生为中心的学习生态。[26]显然，在智能科学与技术的加持下，人类的人际交互模式正在不断被重构，高等教育中传统的面对面教学和纸质教材逐渐被在线学习平台、虚拟教师和个性化学习应用所替代，这种改变推动了教学范式朝着更加灵活、多样化、个性化的方向发展，尤其是使得大规模的因材施教成为新的可能。\n\n# （四）数智革命改变了人类的组织行为方式\n\n人类社会每进入一个新的阶段，都会产生一种新的合作方式、一种新的组织模式，从而催生新的组织形态。从历史来看，从手工时代的家庭作坊到工业革命时期的工厂体系，从现代社会的企业组织到后工业时代的平台组织，每一次技术的飞跃都导致组织结构及其运行方式的重大调整，从单一形态到多元形态，社会组织形态的演变展现了其适应性和灵活性，不断满足社会经济发展的新需求。从这个变迁的历程中可以窥见，科技革命不只是社会生产效率提升的驱动力量，也是社会组织模式变革的驱动力量，更深刻地影响着社会组织的形态和运作方式。数智技术以其智能化、去中心化、自适应性等特征深刻影响组织成员的可塑性、组织结构的灵活性和组织控制的科学性，改变了人类的社会组织形态和行为方式。其智能化特性赋予了其处理大量信息、制定复杂决策并模仿人类智能的能力，这种智能化技术可用来自动执行和优化各种任务，进而提升工作效率与质量。其去中心化特征导致决策与控制不再依赖于单一的权威，这深深地影响了组织内权力的分配格局及组织结构的变化。其自适应性使其能够学习和适应新的环境与需求，这使得组织内的成员不得不为满足快速变化的新的工作要求而适应并利用这些新技术。因而，随着数智技术加速融入组织体系变革，必将导致组织结构调整、流程再造和文化重塑，结构将变得更加扁平化，管理流程更强调快速响应外部变化和内部高度协同，组织文化更强调组织、员工与服务对象之间的价值共创。\n\n大学本质上是由教师、学生、管理者构成的教育共同体。现代大学已经发展成为一个结构复杂、功能多样、属员众多的组织。从组织行为学的视角来看，一个组织在不同成长阶段的组织结构、领导方式、\n\n管理体制、员工心态都有其特点，组织变革伴随组织成长的各个阶段，不同成长阶段要求不同的组织模式与之相适应。由于大学教育是由国家、家庭、教师、学生、用人单位等多元主体共同完成的，不同的群体都对大学有着不同的期待，因而大学具有典型的利益相关者组织的属性，大学治理就是要解决能在冲突和多元利益状况下管理其一般事务的组织性框架及体制机制建设的问题。如何确保大学内部各个机构、系统之间功能定位明确、职能职责清晰、运转科学高效，大学的治理体系和治理能力尤为重要。由数智革命驱动的社会组织形态的变革必然对大学治理产生深远的影响，使得多元、多层级的教育利益相关者与多功能、多样态的智能机器合作，综合利用行政管理和技术支撑等治理手段，可以推动实现人机交互、优势互补、高效合作的现代化教育治理。[27]\n\n# 三、高等教育数智变革的趋势特点\n\n数智革命正在迅速改变人类的物质生产方式、知识生产逻辑、人际交往模式和组织行为方式，这些深层次的改变都会直接映射到高等教育领域，引发高等教育人才培养目标、知识创新生态、课程教学范式、内部治理体系等的系统性深层次变革，从而使得智能时代的高等教育呈现出新的趋势特点。\n\n# （一）人才培养目标从专业知识教育转向未来素养培养\n\n培养什么人、怎样培养人、为谁培养人是教育的根本问题。随着人工智能不断取得重要突破，高等教育应该培养什么样的人以适应科技革命和产业变革的需求是高等教育要思考解决的根本问题。有人认为应包括人工智能思维、创造创新能力、沟通能力、团队协作能力、提出问题的能力和在人工智能协助下的学习能力；[4]有人认为应更加注重凸显学生的个性化优势的品质，加强学生创新品质、情感品质、道德感、价值观，以及人工智能相关素质能力的培养，向复合型人才培养模式转型；[28]有人则强调了人工智能时代批判性思考和解决问题的重要性，认为学校教育的重心应从知识、技能和职业准备转向人工智能时代的适应性学习。[6]显然，大家越来越深刻地体会到，现代大学作为工业化时代的产物，一直致力于规模化地培养符合社会生产需求的人才，然而，其教育内容已和人工智能时代日益凸显的创新人才挖掘和培养需求产生矛盾，[29]传统的人才培养目标及与之相适应的培养模式已经难以适应一个高度智能化的未来社会对受教育者的需求。\n\n要适应、把握和引领智能时代人类物质生产方式、知识创新逻辑等变化所导致对未来社会人才素养需求的改变，高等教育就必须重塑自己的人才培养目标，致力于培养适应一个更加智能化时代所需的人的前瞻能力和未来素养，这至少包括：一是“显而易见”的智能素养，包括数据思维、智能技术、人机协同能力等；二是深度学习能力。深度学习能力是智能生命快速迭代的根本所在，这是以ChatGPT为代表的生成式人工智能给予我们的最大启示；三是对未来的良好适应和创造能力。数智技术加速融入人类生产生活各领域，也迅速放大了更大范围和更深层次的易变性、不确定性、复杂性和模糊性，这对学生的适应能力、批判性思维和创新能力的需求更甚以往。因而，除了让学生具备传统的知识、能力、素养外，最核心的是学生的智能素养、深度学习能力以及对未来的适应能力和创造能力，与之相应的人才培养标准、模式、机制和评价也要随之发生改变，高等教育应据此重构自身人才培养体系。\n\n# （二）知识创新生态从大学组织内部转向多元主体协同\n\n大学的核心功能是知识的传承、创造与传播，并以其生产创造的知识培养和造就社会所需的各类人才，因此大学的知识生产本质上是知识和知识生产者的生产与再生产的过程。就新知识的生产而言，现代社会还没有创造出任何可以与大学相提并论的机构。[30]2-89传统大学知识生产主要依靠学者的知识积累及创新转化，而生成式人工智能跳过了学科、专业、领域等的限制，直接切入知识本身，形成更加细化的知识单元，并导致这些曾经归属不同学科的知识单元形成新的知识体系，促进了跨学科和超学科\n\n的知识整合，更好地满足了人类认识复杂性问题的需要，导致知识创新的主体、科学研究的范式、以学科为基础的传统组织模式等都发生了改变，也会导致知识创新模式的重构以及新的知识体系的涌现，对人类知识的生产方式、效率、结果及其呈现方式等都产生了深刻的影响。\n\n高等教育必须前瞻数智革命对大学知识创新逻辑的影响，不断突破传统的知识生产模式及相应的专业教育局限。一是科研范式将发生转变，AI for Science的重要作用将得到充分的彰显，基于复杂神经网络的深度学习能力极大提高了知识生产效率和更新速度，自然科学领域实验验证和社会科学领域定量研究的内容和形式都在被改变，作为创新主体的教师的知识结构优化尤其是数智素养的提升将成为影响大学创新能力提升的关键。中山大学医学院、阿里云与悉尼大学的研究团队利用其开发的深度学习算法LucaProt发现了超过16万种RNA病毒，包括7万种首次发现的新病毒，揭示了大量前所未知的病毒“暗物质”[31]“人工智能的算法模型能够挖掘出我们之前忽略或根本不知道的病毒，这种能力在疾病防控和新病原的快速识别中尤为重要。特别是在疫情暴发时，人工智能的速度和精度可以帮助科学家更快地锁定潜在病原体。”[32]如果没有人工智能，这项工作是不可能想象的。二是知识生产组织模式将催生新的创新联合体，多学科、跨学科和超学科成为科学革命最重要的途径，知识生产必然在更大范围和更深层次上超越传统的学术共同体的范畴，一些新形态的创新联合体将成为推动知识创新的重要组织形式。三是基础设施建设将实现新的升级，传统实验室、教室等教学科研设施将不得不为适应数智革命而改变，以数据、算力、智能互联设施、大模型等为主体的新型公共基础设施建设将不得不加快，学科、专业、课程、教材等数智化转型将步入快车道。四是人类知识版图将得到极大拓展，人工智能自身的领域及其在众多已知和未知领域的广泛应用必将催生许多新的知识领域，从而重塑人类的知识版图。因而，高等教育必须从学科专业设置、科学研究范式转变、创新平台团队的组建等方面入手构建新的创新生态，进而推动教育内容生成方式、结果、效率的转变。\n\n# （三）课程教学范式从传统教学转向智慧教育\n\n大学存在的理由就是促进社会交往，“我们可以展望未来10到20年，大学的一部分功能是促进社交，另一部分则是帮助学生更全面地了解社会。”[33]实际上，教育千百年来常被认为是一项互动性的艺术，传统上教育领域中的互动特指人与人的互动，而“互动”对促进学生知识建构、能力提升、人格养成等方面有至关重要的意义。古希腊的学园时期，受制于信息传播方式、手段的影响，口耳相传是当时主要的教学范式；随着科技的进步，尤其是电子信息技术的进步，声光电热等各种现代科技的发展导致人际交互的场地局限、方式局限等不断被突破，大学开放与开放大学成为教育领域重要的形式，以慕课、可汗学院等为代表的高等教育领域的新型教学范式得到了发展。当前，以AI为牵引的“大数据+大算法+大模型”，让教育教学从大规模、标准化转向个性化、智能化，实现了规模化教学和个性化学习的有机统一。\n\n人工智能技术正在改变传统的工业时代的教与学的方式，智能时代教育新生态的重构已经开始，高等教育必须适应人工智能发展所导致的人际交互模式的改变对高等教育教学范式的影响。一是交互场域从现实空间走向虚实融合，泛在化、个性化自适应学习越来越受关注，智能教学软件、在线资源、虚拟现实技术等在教学中广泛应用，不仅仅能够极大拓展学生的学习空间，未来学习中心、未来课堂等越来越赋予学生学习更大的自主性，尤为重要的是能够满足学生的个性化差异的需求，设计更科学、更富吸引力的教育环境，使得大规模的因材施教成为可能。二是人际交互结构从二元转向三元，“机”不仅是中介变量，而且是自变量甚至因变量，人机协同已延伸至跨界融合，教学的组织形态由过去“师一生”二元模式转变为“师一生一机”多向交互的开放学习生态，“师一机”协同的复合教育者与“生一机”协同的复合学习者，[34]可延伸师生的感知与认知，增强师生互动与体验，以升维方式实现信息传播方式的转变\n\n与内容创造的共享，促使教育范式向“学为中心”的技能本位迈进，并为广泛的人机互动和人际互联创建创新生态。[26]三是人际交互方式从口耳相传转向声光电图文并茂，技术始终在拓展人类表达与理解的边界，声光电与图文、视频、虚拟现实（VR）、增强现实（AR）等技术融合，形成多模态交互，让人际交互的实时性、互动性、沉浸感空前增强，这种由智能技术驱动的交互媒介的迭代升级不仅改变了信息传递的形态，更重塑了师生认知模式、社会关系与文化生态。因而，适应社会交往方式的改变对教育课程教学范式的影响，必须加强智慧教育基本科学问题、关键核心技术、重要应用示范等方面研究，探究新的人类学习机制，[2]打造泛在化学习的数字化校园，创新具有交互式的学习场域、创新多元化互动教学模式，设计更科学、更富吸引力的教育环境，让学生的学和教师的教更富有效率，以塑造更符合学生和教师需求的教育体验，实现教学范式的重大改革。\n\n# （四）教育治理体系从技术赋能转向系统重构\n\n数字化技术使得信息的获取和传播变得更加快捷和广泛，改变了人们的日常生活方式。运用人工智能等现代科学与技术进行教育治理创新，是智能技术赋能教育发展的重要一环。在智能技术的不断渗透下，现代大学不得不考虑科技对高等教育管理范式的影响。高等教育必须积极适应人工智能快速发展导致的组织行为模式的变革趋势，特别是适应信息技术进步与知识创造分享融合发展的教育形态、学习生态和创新生态，加快建设精准全面、集成共享的教师和学生数据库，建立以数据治理为核心、数智技术为驱动的决策支持系统和集中调度平台，围绕网络安全、数据安全、内部控制等管理服务现代化要求，整体推进教育管理与业务流程再造，从而提升教育治理的效能和水平。当然，虽然人工智能可以处理大多数日常任务，但复杂的决策和创新仍需要人类的智慧，在大学治理的各个环节的选择与决策中，人类的创造力仍然是无法替代的关键。\n\n高等教育必须积极适应人工智能快速发展导致的组织行为模式的变革趋势，围绕信息系统、数据安全、内部控制等管理服务现代化要求，整体推进教育管理与业务流程再造，从而提升治理效能和水平。一是治理理念上，要坚持有利于实现大学的本质功能，最能够激发大学的教育家精神和科学家创造力的根本导向，真正把以人为本、学术为魂贯穿大学治理的各个方面和环节。二是治理主体上，应恰当处理不同权利主体之间的利益与风险分配问题，包括教师、学生和管理者在内的大学组织成员的治理理念、素养构成、行为方式等将成为影响大学治理效能的重要因素。三是治理结构上，扁平化、模块化和科学化将突破现有的科层管理结构，大学组织内部及其与社会之间的部门联动、数据互通、资源协同等必将导致条块分割的治理结构被改变。四是治理方式上，由数据驱动的大学治理必将进一步提升决策的科学化、管理的精细化、服务的精准化。现实中，每一所大学都有自己的文化传统、行为习惯、管理文化、资源配置方式，大学的治理理念、治理结构、治理方式等必须不断突破传统的惯性运作，才能构建与高等教育数智变革趋势相适应的治理体系。\n\n# 四、高等教育数智变革的实践应对\n\n“每一次科技革命和产业变革都给教育带来跨越式发展”。①历史表明，世界教育中心、世界科学中心、世界人才中心本质上具有深度的同构逻辑和共生关系。我国是一个高等教育大国，高水平研究型大学在国家高等教育体系和创新体系中具有特殊而重要的地位，必须深刻把握高等教育数智变革的基本逻辑和趋势特点，加快推进发展范式、创新生态、育人体系、治理体系、评价体系的整体性重塑，着力构建符合自身发展目标定位、优势特色和阶段特点的高质量发展体系，在高等教育数智变革中发挥好示\n\n范引领作用。①\n\n# （一）推进教育发展范式系统性变革\n\n高等教育的数智变革不是高等教育传统发展路径的“局部改良”，而是一场深刻的“范式革命”。高水平研究型大学须前瞻把握数智革命影响高等教育变革的底层逻辑，一体推进自身办学理念、发展方式、重大战略的系统性改革，探索一种集思想、理念、标准、评价等为一体的发展新范式。办学理念方面，要牢牢把握教育的政治属性、人民属性、战略属性，以科技发展、国家战略需求为牵引，把为学生提供超越传统知识教育、能力培养和素养养成之上的未来教育作为重要理念，构建智慧教育生态系统，着力培养学生的家国情怀、创新能力、国际视野和未来素养，为每一个学生应对不确定的未来而做好准备。发展方式方面，突出高质量发展主题和内涵式发展主线，充分发挥数智技术在实施大规模因材施教、提升知识生产效率、推动产教深度融合、促进国际创新资源互通方面的重要作用，强化技术驱动、智慧赋能、跨界融合，以数据生态延伸创新生态，探索面向智能时代的高等教育发展新路径。重大战略方面，将以人工智能为代表的现代科技作为战略性变量融入知识生产、人才培养、科技创新、产教融合等创新生态，带动育人方式、办学模式、管理体制、保障机制全方位系统性变革，在回应科技革命和产业变革中加快推进高等教育战略转型。如西南财经大学以建设“新财经”探索高等财经教育发展的新范式，其基本方向就是积极适应和引领现代经济、科技和教育深刻变革，坚持以服务中国式现代化为根本使命、以培养财经拔尖人才为根本任务、以推动建构中国自主知识体系和支撑国家高水平科技自立自强为核心目标、以跨学科和促融通为基本路径、以全面数智赋能为关键动力，着力推进大学功能、学科要素和组织成员的系统性、深层次变革，加快建设财经特色鲜明的世界一流大学。\n\n# （二）推进大学创新生态系统性重构\n\n数智革命正在重构科学研究的底层逻辑和大学的创新生态体系。高水平研究型大学应一体推进学科建设、科研创新和人才发展系统性改革，实现学科布局优化、攻关方向聚焦、人才队伍适配深度耦合，提升创新体系的整体效能，为人类社会发展和文明进步贡献中国智慧。大力优化学科专业布局，着力健全科技创新发展、国家重大战略和区域产业布局需求牵引的学科专业设置调整机制，加快推进传统学科专业数智化转型，布局建设集成电路、人工智能、量子计算、网络空间安全、数据科学等一批能更好支撑发展新质生产力的新兴交叉学科专业，打造优势学科专业集群。推动科学研究范式转换，发挥AI处理海量科研数据（如清华3000+临床病例库）、辅助实验设计、协助数据分析（如DeepMind的AlphaScience项目）、发现传统方法难以捕捉的规律等方面的优势，提升教师的数智素养和创新效率，推动科研范式从假设驱动向数据驱动、从单一学科向交叉融合、从线性研究向非线性创新转变。创新科研组织模式，更加突出与产业发展、社会需求和科技前沿紧密衔接，打破学科边界、学术阻隔、学院壁垒和认知偏见，推动教育链、人才链、产业链、创新链深度融合，建设跨学科、超学科融合的新型创新联合体，提升科学研究组织化水平和原始创新能级。加快新型基础设施建设，建设数据中心、算力中心、智能感知、学科大模型等新型基础设施。如武汉理工大学紧扣云、网、数、端四大要素系统推进算力、网络、数据、平台四大基础要素建设；中国地质大学“元古大模型”利用多模态大模型技术除开展常规的地学图谱形成、地学知识问答外，还具备岩石、化石的智能鉴定、化石物种的智能鉴定、化石图像的智能解译、古生物化石复原、地质文献数据抽取等特色功能。\n\n# （三）推进人才培养体系系统性重塑\n\n教育的目标不是装备学生应对已知的世界，而是赋予他们重塑世界的能力。高水平研究型大学应\n\n着眼数智时代对拔尖创新人才道德伦理、知识结构、能力素养的新需求，一体推进人才培养标准、模式和机制系统性改革，完善以育人育才为中心的教育格局，重塑人才培养的新体系。优化人才培养标准，突出学生数智素养、创新潜能、人机协同能力培养，全面加强专业、课程、教材等标准体系建设，分类构建各学科专业知识图谱、能力图谱、素质图谱。如北京理工大学“知识图谱驱动的智慧教学系统”构建覆盖全校70+本科专业的知识图谱，实现跨学科知识贯通，形成可追溯的知识网络。创新人才培养模式，以跨学科和促融通为主要路径，深化学科、专业、课程交叉融合，转变课程教学范式，实施基于AI的精准教学。如北京大学的“北大问学”平台、中国人民大学“人大未来课堂AI智能助手”、清华大学构建“数据驱动-认知增强-人机协同”的新型的数智教育平台、教学模式等正在实现学生从“标准化生产”到“个性化培育”的转变，尊重和满足课堂中不同层次群体的多样化学习需求和自主选择的权利。健全人才培养机制，进一步完善拔尖人才的发现和培养机制，持续深化产教融合、科教融汇，与行业企业联合打造数字化的课程教材体系，以项目和任务设定牵引课堂，让学生在项目化的场景中学习用知识解决复杂问题，提升拔尖创新人才自主培养能力。如武汉大学通过构建“知识一能力一素质”三位一体的培养体系，让学生在掌握专业知识基础上具备引领未来的关键能力。\n\n# （四）推进内部治理体系系统性优化\n\n大学治理主要解决能在多元利益状况下管理其一般事务的组织性框架及体制机制的问题，尤其是通过内部制度安排，确定包括组织结构的分层、内部权力体系的构成等内部组织结构和运行机制。高水平研究型大学应一体推进治理理念、结构、方式系统性改革，构建体现大学本质规律、符合时代要求、适应中国国情的现代大学制度。在治理理念方面，坚持把促进师生的全面发展摆在首位，充分利用数智技术全面感知、高速传播、跨域交互的优势，推动大学治理从单一管理走向多元共治，增强治理的民主性和科学性。在治理结构方面，利用数智技术优化治理结构，降低信息横向和纵向通达的时间，打通部门之间的行政壁垒，着力解决部门职责交叉边界不清的问题；纵向缩减管理层级降低管理重心，赋予二级单位更大的资源分配权、指挥决策权和管理自主权，增强二级单位推动发展的自主性和创造性。如西北工业大学、南京航空航天大学等正在以大部制、扁平化改革推动大学治理结构优化，进一步核减管理人员的规模。在治理方式上，强化数据驱动的治理效能提升，重塑管理服务流程，建设AI应用生态，进一步提升决策的科学化、管理的精细化、服务的精准化。如西南财经大学与同方知网合作建设学校事业发展数据中台，以学科发展监测、评价等为应用场景实现内部治理信息系统互联互通；同济大学“基于ChatTJ的智慧招生管理平台”实现了大模型技术应用与招生服务的垂直融合。\n\n# （五）推进教育评价体系系统性改革\n\n教育评价事关教育发展方向，有什么样的评价指挥棒，就有什么样的办学导向。研究型大学推动构建自主评价体系须紧紧围绕教育强国建设战略目标和高等教育高质量发展战略主线，在教育评价体系的价值导向、指标设计、评价方式和结果应用上都要前瞻由数智革命驱动的人才培养目标、知识创新生态、课程教学范式、内部治理体系等高等教育的系统性深层次变革趋势，从而构建多元主体参与、符合我国实际、具有世界水平的教育评价体系。价值导向上，深入研究教育强国的具体内涵及其在大学评价中的具体体现，把引领加快建设中国特色世界一流大学和优势学科，更好培养国家急需创新人才、建构中国自主知识体系、支撑国家科技自立自强作为教育评价改革的根本导向，彰显中国教育发展的时代特征和教育评价改革的基本方向。指标设计上，突出扎根中国大地与借鉴世界经验相结合，创造性地吸取国外高等教育评价体系的合理元素，更加注重学科专业与生产力形态变革的适配度、原始创新贡献、学生数智素养培养、课程教学范式转变、内部治理效能等表征高等教育数智变革的新成效。评价方式上，优化基于指标内涵的评价方式，根据指标类型选择评价方式，积极探索多元主体评价、定量与定性\n\n相结合的融合评价，突出评价开放性、自主性、发展性，更加注重大数据、区块链、人工智能等新技术的应用，创新评价的工具、模型、方式，提升评价的科学性和有效性。结果应用上，强化评价结果的诊断功能和促进发展的功效，更加注重教育评价体系在推动大学办学模式、创新生态、育人体系创新中的引领作用，更好地服务国家的世界重要人才中心和创新高地建设。\n\n# 五、结 语\n\n教育部部长怀进鹏在世界教育大会上强调，发展数字教育，推动教育数字化转型，是大势所趋、发展所需、改革所向。随着智能科学与技术尤其是人工智能逐步从“狭义人工智能”（ANI）、“通用人工智能”（AGI）向“超级人工智能”（ASI）发展进阶，可以预料的是，社会各领域观念变革、结构重构、流程再造的广度、深度和速度必将加速演进，数智革命必将会持续渗透和扩大到高等教育的各个领域和层面，成为影响高等教育时代变革的关键动能，从而不断重塑智能时代高等教育的新形态。\n\n# 参考文献：\n\n[1]中国学位与研究生教育学会.怀进鹏在2025世界数字教育大会作主旨演讲[EB/OL].(2025-05-15)[2025-06-06].https://mp.weixin.qq.com/s/re-chwa47TZHqeqlajG3g.  \n[2]杨宗凯等. ChatGPT/生成式人工智能对教育的影响探析及应对策略[J]. 华东师范大学学报(教育科学版), 2023, 41(7): 26-35.  \n[3]徐和祥，申利侠.“智能+教育”：应用场景、风险挑战与治理对策[J].复旦教育论坛，2023,21(2):24-30.  \n[4]蒋里.AI驱动教育改革:ChatGPT/GPT的影响及展望[J].华东师范大学学报(教育科学版),2023,41(7):143-150.  \n[5]陈静远,胡丽雅,吴飞. ChatGPT/生成式人工智能促进以知识点为核心的教学模式变革研究[J].华东师范大学学报(教育科学版),2023,41(7):177-186.  \n[6]焦建利. ChatGPT: 学校教育的朋友还是敌人? [J]. 现代教育技术, 2023, 33(4):5-15.  \n[7]冯永刚,屈玲. ChatGPT运用于教育的伦理风险及其防控[J]. 内蒙古社会科学,2023,44(4):34-42.  \n[8]冯雨奂. ChatGPT 在教育领域的应用价值、潜在伦理风险与治理路径[J]. 思想理论教育, 2023(4):26-32.  \n[9]王佑镁，王旦，梁炜怡，等.“阿拉丁神灯”还是“潘多拉魔盒”：ChatGPT教育应用的潜能与风险[J].现代远程教育研究，2023,35(2):48-56.  \n[10]张务农，汤洁.知与非知——再论人工智能应用对教学主体的影响[J].电化教育研究,2023,44(3):36-43.  \n[11]张缨斌.感知情境与人在回路的智能教育——《人工智能与教学的未来：见解与提议》要点与反思[J].开放教育研究,2023,29(4):11-20.  \n[12]克劳斯·迈因策尔,贾积有,张誉月. ChatGPT和人工智能:从基本原理到教育应用[J].北京大学教育评论,2023,21(1):35-48.  \n[13]李会春. ChatGPT的智慧生成特征及对高等教育的挑战[J]. 江苏高教, 2023(8):1-12.  \n[14]学习强国. 习近平主持十九届中共中央政治局第九次集体学习[EB/OL].(2018-10-31)[2025-06-06].https://www.xuexi.cn/429f88258b2897476c9730c4d81161ee/e43e220633a65f9b6d8b53712cba9caa.html.  \n[15]李晓红.科技创新是发展新质生产力的核心要素[J].中国信息化,2024(7):5-7.  \n[16]MCKINSEY, COMPANY. The economic potential of generative AI: the next productivity frontier[EB/OL]. McKinsey & Company, (2023-06-14) [2025-05-06]. https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier.  \n[17]MCKINSEY, COMPANY. Technology trends outlook 2023[R/OL]. [2025-05-06]. https://www.mckinsey.com/~media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/mckinsey%20technology%20trends%20outlook%202023/mckinsey-technology-trends-outlook-2023-v5.pdf.  \n[18]FROST,SULLIVAN CHINA.2024年中国行业大模型市场报告[R/OL].FROST & SULLIVAN CHINA,2024[2025-05-06].https://www.frostchina.com/content/insight/detail/67346fe60bc989123b87e56d.\n\n[19]马克思.政治经济学批判大纲(1857—1858年手稿)导言[M//马克思恩格斯全集:第30卷.北京:人民出版社, 1995.  \n[20]新浪网. 院士洞见 | 首位华人图灵奖获得者、中科院院士姚期智《人工智能的科学视角》演讲全文[EB/OL]. (2024-10-04)[2025-05-06]. https://k.sina.com.cn/article_6375433705_17c0165e901901cy4q.html.  \n[21]中国科学院网信工作网. DeepMind 发布报告 AI for Science 黄金时代已来[EB/OL].(2024-12-19)[2025-05-06]. https://ecas.cas.cn/xxkw/kbcd/201115_146563/ml/xxhcxyyyal/202412/t20241219_5042988.html.  \n[22]习近平.论科技自立自强[M].北京：中央文献出版社，2023.  \n[23]肖峰.大模型时代的数字交往：“对话中的人”及其新形态[J].人民论坛·学术前沿,2024(19):65-72.  \n[24]李会春. ChatGPT技术热潮下教育变革的挑战和对策[J]. 复旦教育论坛, 2023, 21(2):13-23.  \n[25]阿兰·柯林斯,理查德·哈尔弗森.技术时代重新思考教育:数字革命与美国的学校教育[M].上海:华东师范大学出版社,2013.  \n[26]祝智庭,戴岭,赵晓伟. “近未来”人机协同教育发展新思路[J]. 开放教育研究,2023,29(5):4-13.  \n[27]陈星,吴叶林.人机协同教育治理的障碍与突破[J].现代远程教育研究,2022,34(1):40-47.  \n[28]朱永新,杨帆. ChatGPT/生成式人工智能与教育创新:机遇、挑战以及未来[J].华东师范大学学报(教育科学版), 2023,41(7):1-14.  \n[29]顾小清,胡艺龄,郝祥军. AGI临近了吗:ChatGPT热潮之下再看人工智能与未来教育发展[J].华东师范大学学报(教育科学版),2023,41(7):117-130.  \n[30]海尔格·诺沃特尼，等.反思科学：不确定性时代的知识与公众[M].上海：上海交通大学出版社，2011.  \n[31]HOU X, et al. Using artificial intelligence to document the hidden RNA viosphere[J].Cell, 2024,187(23):6929-6942.  \n[32]中山大学医学院.科研动态|我院施葵教授团队借助人工智能技术开展病毒学研究大幅拓宽RNA病毒库[EB/OL].(2024-10-11)[2025-05-06].https://szmed.sysu.edu.cn/zh-hans/article/2951.  \n[33]科学网.诺奖得主乔治·斯穆特:未来的大学教育中,知识传授将不再重要[EB/OL].(2024-11-01)[2025-05-06].https://news.sciencenet.cn/htmlnews/2024/11/533132.shtml.  \n[34]沈书生,祝智庭. ChatGPT类产品:内在机制及其对学习评价的影响[J]. 中国远程教育,2023(4):8-15.\n\n# Digital-Intelligent Transformation in Higher Education:\n\n# Fundamental Logic, Trends and Characteristics, and Practical Responses\n\n# Li Xue, Li Yongqiang\n\nAbstract: The accelerated iteration and upgrading of intelligent science and technology, represented by ChatGPT and DeepSeek, and their widespread application in human production and life are constantly changing the way humans produce material goods, the logic of knowledge innovation, interpersonal interaction patterns, and organizational behavior. Its impact, penetration, and transformation of higher education extend far beyond the application of science and technology in education in the general sense, triggering comprehensive and profound changes in the objectives of talent cultivation, the knowledge innovation ecosystem, course teaching paradigms, and university governance systems in higher education. Higher education is showing many new trends and characteristics, such as a shift in talent cultivation goals from professional knowledge education to future literacy cultivation, a shift in the knowledge innovation ecosystem from within university organizations to multi-subject collaboration, a shift in course teaching paradigms from traditional teaching to smart education, and a shift in education governance systems from technology empowerment to systemic reconstruction. High-level research universities, which occupy an important position in the national higher education system, should thoroughly grasp these new trends and characteristics, comprehensively promote systematic reforms in development models, innovation ecosystems, education systems, governance systems, and evaluation systems, and play an exemplary and leading role in building a world-class higher education center and better serving the construction of an education powerhouse.\n\nKeywords: Higher Education; Digital-Intelligent Transformation; Fundamental Logic; Trends and Characteristics; High-level Research Universities; Response Strategies\n\n(收稿日期:2025—05—28 责任编辑:赵爱清)",
    "translated_content": null,
    "created_at": "2025-12-15 11:36:36.339515",
    "updated_at": "2025-12-15 11:36:53.450787",
    "analysis": {
      "paper_id": "0a6aae26-e1da-42f9-80f6-19a4250dbeaa",
      "status": "completed",
      "started_at": "2025-12-16T07:32:57.503411",
      "completed_at": "2025-12-16T07:33:09.326356",
      "summary": "本文探讨以ChatGPT、DeepSeek等智能技术为代表的人工智能对高等教育带来的系统性变革。研究旨在分析数智变革影响高等教育的基本逻辑、发展趋势及应对策略。\n\n论文从物质生产方式、知识创新逻辑、人际交往模式和组织行为方式四个维度，剖析了数智技术对高等教育产生的深层次影响。研究发现，高等教育正呈现四大趋势转变：人才培养目标从专业知识教育转向未来素养培养；知识创新生态从大学内部转向多元主体协同；课程教学范式从传统教学转向智慧教育；教育治理体系从技术赋能转向系统重构。\n\n研究指出，高水平研究型大学应把握这些趋势特点，在发展范式、创新生态、育人体系等方面进行系统性改革，通过推进数智技术与教育体系的深度融合，为我国建设教育强国发挥示范引领作用。文章强调，高等教育必须超越单纯的技术应用层面，从更宏观的视角应对数智时代的教育变革挑战。",
      "methods": [
        {
          "name": "文献综述法",
          "description": "通过系统梳理和分析已有研究成果，为研究提供理论基础和研究方向。该方法有助于识别研究空白并确定本文的研究重点。",
          "location": {
            "start_line": 23,
            "end_line": 25,
            "text_snippet": "已有研究开拓了人们对数智革命影响高等教育变革趋势特点的深入认识，其中一些观点、洞见以及相应的实践探索为本文的分析研究提供了很好的借鉴和参照。"
          }
        },
        {
          "name": "逻辑分析法",
          "description": "从宏观视角分析数智革命影响高等教育的内在因果关系和基本规律。该方法强调跳出教育系统本身，从社会大系统的角度进行系统性分析。",
          "location": {
            "start_line": 23,
            "end_line": 25,
            "text_snippet": "分析数智革命对高等教育的影响不能仅仅局限在教育系统内部，必须深入把握以人工智能为代表的数智革命如何影响高等教育变革的基本逻辑。"
          }
        },
        {
          "name": "案例分析法",
          "description": "通过引用具体的研究报告、技术产品和权威奖项等实例，支撑和论证数智革命带来的实际影响。该方法使分析更具说服力和现实基础。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "高等教育的数智变革:",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "基本逻辑、趋势特点及实践应对",
            "level": 1,
            "start_line": 3
          },
          {
            "title": "一、引言与文献综述",
            "level": 1,
            "start_line": 15
          },
          {
            "title": "二、高等教育数智变革的基本逻辑",
            "level": 1,
            "start_line": 25
          },
          {
            "title": "（一）数智革命改变了人类的物质生产方式",
            "level": 1,
            "start_line": 29
          },
          {
            "title": "（二）数智革命重塑了人类的知识生产逻辑",
            "level": 1,
            "start_line": 37
          },
          {
            "title": "（三）数智革命重构了人类的人际交往模式",
            "level": 1,
            "start_line": 43
          },
          {
            "title": "（四）数智革命改变了人类的组织行为方式",
            "level": 1,
            "start_line": 51
          },
          {
            "title": "三、高等教育数智变革的趋势特点",
            "level": 1,
            "start_line": 59
          },
          {
            "title": "（一）人才培养目标从专业知识教育转向未来素养培养",
            "level": 1,
            "start_line": 63
          },
          {
            "title": "（二）知识创新生态从大学组织内部转向多元主体协同",
            "level": 1,
            "start_line": 69
          },
          {
            "title": "（三）课程教学范式从传统教学转向智慧教育",
            "level": 1,
            "start_line": 77
          },
          {
            "title": "（四）教育治理体系从技术赋能转向系统重构",
            "level": 1,
            "start_line": 85
          },
          {
            "title": "四、高等教育数智变革的实践应对",
            "level": 1,
            "start_line": 91
          },
          {
            "title": "（一）推进教育发展范式系统性变革",
            "level": 1,
            "start_line": 97
          },
          {
            "title": "（二）推进大学创新生态系统性重构",
            "level": 1,
            "start_line": 101
          },
          {
            "title": "（三）推进人才培养体系系统性重塑",
            "level": 1,
            "start_line": 105
          },
          {
            "title": "（四）推进内部治理体系系统性优化",
            "level": 1,
            "start_line": 111
          },
          {
            "title": "（五）推进教育评价体系系统性改革",
            "level": 1,
            "start_line": 115
          },
          {
            "title": "五、结 语",
            "level": 1,
            "start_line": 121
          },
          {
            "title": "参考文献：",
            "level": 1,
            "start_line": 125
          },
          {
            "title": "Digital-Intelligent Transformation in Higher Education:",
            "level": 1,
            "start_line": 163
          },
          {
            "title": "Fundamental Logic, Trends and Characteristics, and Practical Responses",
            "level": 1,
            "start_line": 165
          },
          {
            "title": "Li Xue, Li Yongqiang",
            "level": 1,
            "start_line": 167
          }
        ]
      },
      "error_message": null
    }
  },
  "e18fee52-bfb3-42f7-b457-ec1c57804020": {
    "id": "e18fee52-bfb3-42f7-b457-ec1c57804020",
    "filename": "2505.10468v1.pdf",
    "file_path": "./uploads/papers/e18fee52-bfb3-42f7-b457-ec1c57804020.pdf",
    "status": "completed",
    "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges",
    "category": null,
    "markdown_content": "# AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges\n\nRanjan Sapkota\\*†, Konstantinos I. Roumeliotis†, Manoj Karkee\\*‡\n\n* Cornell University, Department of Environmental and Biological Engineering, USA\n\n$^{\\dagger}$ Department of Informatics and Telecommunications, University of the Peloponnese, 22131 Tripoli, Greece\n\n†Corresponding authors: rs2672@cornell.edu, mk2684@cornell.edu\n\nAbstract—This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven by LLMs and LIMs for narrow, task-specific automation. Generative AI is positioned as a precursor, with AI Agents advancing through tool integration, prompt engineering, and reasoning enhancements. In contrast, Agentic AI systems represent a paradigmatic shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and orchestrated autonomy. Through a sequential evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both paradigms. Application domains such as customer support, scheduling, and data summarization are contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure and propose targeted solutions such as ReAct loops, RAG, orchestration layers, and causal modeling. This work aims to provide a definitive roadmap for developing robust, scalable, and explainable AI-driven systems.\n\nIndex Terms—AI Agents, Agentic AI, Autonomy, Reasoning, Context Awareness, Multi-Agent Systems, Conceptual Taxonomy, vision-language model\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/3ed2affe58af5dd7192c50358456dc7a45d2e51af029c5bbeb82e1fceef60900.jpg)  \nFig. 1: Global Google search trends showing rising interest in \"AI Agents\" and \"Agentic AI\" since November 2022 (ChatGPT Era).\n\n# I. INTRODUCTION\n\nPrior to the widespread adoption of AI agents and agentic AI around 2022 (Before ChatGPT Era), the development of autonomous and intelligent agents was deeply rooted in foundational paradigms of artificial intelligence, particularly multi-agent systems (MAS) and expert systems, which emphasized social action and distributed intelligence [1], [2].\n\nNotably, Castelfranchi [3] laid critical groundwork by introducing ontological categories for social action, structure, and mind, arguing that sociality emerges from individual agents' actions and cognitive processes in a shared environment, with concepts like goal delegation and adoption forming the basis for cooperation and organizational behavior. Similarly, Ferber [4] provided a comprehensive framework for MAS, defining agents as entities with autonomy, perception, and communication capabilities, and highlighting their applications in distributed problem-solving, collective robotics, and synthetic world simulations. These early works established that individual social actions and cognitive architectures are fundamental to modeling collective phenomena, setting the stage for modern AI agents. This paper builds on these insights to explore how social action modeling, as proposed in [3], [4], informs the design of AI agents capable of complex, socially intelligent interactions in dynamic environments.\n\nThese systems were designed to perform specific tasks with predefined rules, limited autonomy, and minimal adaptability to dynamic environments. Agent-like systems were primarily reactive or deliberative, relying on symbolic reasoning, rule-based logic, or scripted behaviors rather than the learning-driven, context-aware capabilities of modern AI agents [5], [6]. For instance, expert systems used knowledge bases and inference engines to emulate human decision-making in domains like medical diagnosis (e.g., MYCIN [7]). Reactive agents, such as those in robotics, followed sense-act cycles based on hardcoded rules, as seen in early autonomous vehicles like the Stanford Cart [8]. Multi-agent systems facilitated coordination among distributed entities, exemplified by auction-based resource allocation in supply chain management [9], [10]. Scripted AI in video games, like NPC behaviors in early RPGs, used predefined decision trees [11]. Furthermore, BDI (Belief-Desire-Intention) architectures enabled goal-directed behavior in software agents, such as those in air traffic control simulations [12], [13]. These early systems lacked the generative capacity, self-learning, and environmental adaptability of modern agentic AI, which leverages deep learning, reinforcement learning, and large-scale data [14].\n\nRecent public and academic interest in AI Agents and Agentic AI reflects this broader transition in system capabilities. As illustrated in Figure 1, Google Trends data demonstrates a significant rise in global search interest for both terms\n\nfollowing the emergence of large-scale generative models in late 2022. This shift is closely tied to the evolution of agent design from the pre-2022 era, where AI agents operated in constrained, rule-based environments, to the post-ChatGPT period marked by learning-driven, flexible architectures [15]–[17]. These newer systems enable agents to refine their performance over time and interact autonomously with unstructured, dynamic inputs [18]–[20]. For instance, while pre-modern expert systems required manual updates to static knowledge bases, modern agents leverage emergent neural behaviors to generalize across tasks [17]. The rise in trend activity reflects increasing recognition of these differences. Moreover, applications are no longer confined to narrow domains like simulations or logistics, but now extend to open-world settings demanding real-time reasoning and adaptive control. This momentum, as visualized in Figure 1, underscores the significance of recent architectural advances in scaling autonomous agents for real-world deployment.\n\nThe release of ChatGPT in November 2022 marked a pivotal inflection point in the development and public perception of artificial intelligence, catalyzing a global surge in adoption, investment, and research activity [21]. In the wake of this breakthrough, the AI landscape underwent a rapid transformation, shifting from the use of standalone LLMs toward more autonomous, task-oriented frameworks [22]. This evolution progressed through two major post generative phases: AI Agents and Agentic AI. Initially, the widespread success of ChatGPT popularized Generative Agents, which are LLM-based systems designed to produce novel outputs such as text, images, and code from user prompts [23], [24]. These agents were quickly adopted across applications ranging from conversational assistants (e.g., GitHub Copilot [25]) and content-generation platforms (e.g., Jasper [26]) to creative tools (e.g., Midjourney [27]), revolutionizing domains like digital design, marketing, and software prototyping throughout 2023.\n\nBuilding on this generative foundation, a new class of systems known as AI Agents emerged. These agents enhanced LLMs with capabilities for external tool use, function calling, and sequential reasoning, enabling them to retrieve real-time information and execute multi-step workflows autonomously [28], [29]. Frameworks such as AutoGPT [30] and BabyAGI (https://github.com/yoheinakajima/babyagi) exemplified this transition, showcasing how LLMs could be embedded within feedback loops to dynamically plan, act, and adapt in goal-driven environments [31], [32]. By late 2023, the field had advanced further into the realm of Agentic AI complex, multi-agent systems in which specialized agents collaboratively decompose goals, communicate, and coordinate toward shared objectives. Architectures such as CrewAI demonstrate how these agentic frameworks can orchestrate decision-making across distributed roles, facilitating intelligent behavior in high-stakes applications including autonomous robotics, logistics management, and adaptive decision-support [33]-[36].\n\nAs the field progresses from Generative Agents toward increasingly autonomous systems, it becomes critically impor-\n\ntant to delineate the technological and conceptual boundaries between AI Agents and Agentic AI. While both paradigms build upon large LLMs and extend the capabilities of generative systems, they embody fundamentally different architectures, interaction models, and levels of autonomy. AI Agents are typically designed as single-entity systems that perform goal-directed tasks by invoking external tools, applying sequential reasoning, and integrating real-time information to complete well-defined functions [17], [37]. In contrast, Agentic AI systems are composed of multiple, specialized agents that coordinate, communicate, and dynamically allocate subtasks within a broader workflow [14], [38]. This architectural distinction underpins profound differences in scalability, adaptability, and application scope.\n\nUnderstanding and formalizing the taxonomy between these two paradigms (AI Agents and Agentic AI) is scientifically significant for several reasons. First, it enables more precise system design by aligning computational frameworks with problem complexity ensuring that AI Agents are deployed for modular, tool-assisted tasks, while Agentic AI is reserved for orchestrated multi-agent operations. Moreover, it allows for appropriate benchmarking and evaluation: performance metrics, safety protocols, and resource requirements differ markedly between individual-task agents and distributed agent systems. Additionally, clear taxonomy reduces development inefficiencies by preventing the misapplication of design principles such as assuming inter-agent collaboration in a system architected for single-agent execution. Without this clarity, practitioners risk both under-engineering complex scenarios that require agentic coordination and over-engineering simple applications that could be solved with a single AI Agent.\n\nSince the field of artificial intelligence has seen significant advancements, particularly in the development of AI Agents and Agentic AI. These terms, while related, refer to distinct concepts with different capabilities and applications. This article aims to clarify the differences between AI Agents and Agentic AI, providing researchers with a foundational understanding of these technologies. The objective of this study is to formalize the distinctions, establish a shared vocabulary, and provide a structured taxonomy between AI Agents and Agentic AI that informs the next generation of intelligent agent design across academic and industrial domains, as illustrated in Figure 2.\n\nThis review provides a comprehensive conceptual and architectural analysis of the progression from traditional AI Agents to emergent Agentic AI systems. Rather than organizing the study around formal research questions, we adopt a sequential, layered structure that mirrors the historical and technical evolution of these paradigms. Beginning with a detailed description of our search strategy and selection criteria, we first establish the foundational understanding of AI Agents by analyzing their defining attributes, such as autonomy, reactivity, and tool-based execution. We then explore the critical role of foundational models specifically LLMs and Large Image Models (LIMs) which serve as the core reasoning and perceptual substrates that drive agentic behavior. Subsequent\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/4cfcf39fb9cd1cdf5e4482e29b6cccd9aa88dd4a3f10bc1d8be7845ac3d1d65e.jpg)  \nFig. 2: Mindmap of Research Questions relevant to AI Agents and Agentic AI. Each color-coded branch represents a key dimension of comparison: Architecture, Mechanisms, Scope/Complexity, Interaction, and Autonomy.\n\nsections examine how generative AI systems have served as precursors to more dynamic, interactive agents, setting the stage for the emergence of Agentic AI. Through this lens, we trace the conceptual leap from isolated, single-agent systems to orchestrated multi-agent architectures, highlighting their structural distinctions, coordination strategies, and collaborative mechanisms. We further map the architectural evolution by dissecting the core system components of both AI Agents and Agentic AI, offering comparative insights into their planning, memory, orchestration, and execution layers. Building upon this foundation, we review application domains spanning customer support, healthcare, research automation, and robotics, categorizing real-world deployments by system capabilities and coordination complexity. We then assess key challenges faced by both paradigms including hallucination, limited reasoning depth, causality deficits, scalability issues, and governance risks. To address these limitations, we outline emerging solutions such as retrieval-augmented generation, tool-based reasoning, memory architectures, and simulation-based planning. The review culminates in a forward-looking roadmap that envisions the convergence of modular AI Agents and orchestrated Agentic AI in mission-critical domains. Overall, this paper aims to provide researchers with a structured taxonomy and actionable insights to guide the design, deployment, and evaluation of next-generation agentic systems.\n\n# A. Methodology Overview\n\nThis review adopts a structured, multi-stage methodology designed to capture the evolution, architecture, application,\n\nand limitations of AI Agents and Agentic AI. The process is visually summarized in Figure 3, which delineates the sequential flow of topics explored in this study. The analytical framework was organized to trace the progression from basic agentic constructs rooted in LLMs to advanced multi-agent orchestration systems. Each step of the review was grounded in rigorous literature synthesis across academic sources and AI-powered platforms, enabling a comprehensive understanding of the current landscape and its emerging trajectories.\n\nThe review begins by establishing a foundational understanding of AI Agents, examining their core definitions, design principles, and architectural modules as described in the literature. These include components such as perception, reasoning, and action selection, along with early applications like customer service bots and retrieval assistants. This foundational layer serves as the conceptual entry point into the broader agentic paradigm.\n\nNext, we delve into the role of LLMs as core reasoning components, emphasizing how pre-trained language models underpin modern AI Agents. This section details how LLMs, through instruction fine-tuning and reinforcement learning from human feedback (RLHF), enable natural language interaction, planning, and limited decision-making capabilities. We also identify their limitations, such as hallucinations, static knowledge, and a lack of causal reasoning.\n\nBuilding on these foundations, the review proceeds to the emergence of Agentic AI, which represents a significant conceptual leap. Here, we highlight the transformation from tool-augmented single-agent systems to collaborative, distributed ecosystems of interacting agents. This shift is driven by the need for systems capable of decomposing goals, assigning subtasks, coordinating outputs, and adapting dynamically to changing contexts capabilities that surpass what isolated AI Agents can offer.\n\nThe next section examines the architectural evolution from AI Agents to Agentic AI systems, contrasting simple, modular agent designs with complex orchestration frameworks. We describe enhancements such as persistent memory, meta-agent coordination, multi-agent planning loops (e.g., ReAct and Chain-of-Thought prompting), and semantic communication protocols. Comparative architectural analysis is supported with examples from platforms like AutoGPT, CrewAI, and Lang-Graph.\n\nFollowing the architectural exploration, the review presents an in-depth analysis of application domains where AI Agents and Agentic AI are being deployed. This includes six key application areas for each paradigm, ranging from knowledge retrieval, email automation, and report summarization for AI Agents, to research assistants, robotic swarms, and strategic business planning for Agentic AI. Use cases are discussed in the context of system complexity, real-time decision-making, and collaborative task execution.\n\nSubsequently, we address the challenges and limitations inherent to both paradigms. For AI Agents, we focus on issues like hallucination, prompt brittleness, limited planning ability, and lack of causal understanding. For Agentic AI, we identify\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/5e2d098f86347ed88c2f8499ef0bbaa689a73aa3e70f248aa88cb518a8aba709.jpg)  \nFig. 3: Methodology pipeline from foundational AI agents to Agentic AI systems, applications, limitations, and solution strategies.\n\nhigher-order challenges such as inter-agent misalignment, error propagation, unpredictability of emergent behavior, explainability deficits, and adversarial vulnerabilities. These problems are critically examined with references to recent experimental studies and technical reports.\n\nFinally, the review outlines potential solutions to overcome these challenges, drawing on recent advances in causal modeling, retrieval-augmented generation (RAG), multi-agent memory frameworks, and robust evaluation pipelines. These strategies are discussed not only as technical fixes but as foundational requirements for scaling agentic systems into high-stakes domains such as healthcare, finance, and autonomous robotics.\n\nTaken together, this methodological structure enables a comprehensive and systematic assessment of the state of AI Agents and Agentic AI. By sequencing the analysis across foundational understanding, model integration, architectural growth, applications, and limitations, the study aims to provide both theoretical clarity and practical guidance to researchers and practitioners navigating this rapidly evolving field.\n\n1) Search Strategy: To construct this review, we implemented a hybrid search methodology combining traditional academic repositories and AI-enhanced literature discovery tools. Specifically, twelve platforms were queried: academic databases such as Google Scholar, IEEE Xplore, ACM Digital Library, Scopus, Web of Science, ScienceDirect, and arXiv; and AI-powered interfaces including ChatGPT, Perplexity.ai, DeepSeek, Hugging Face Search, and Grok. Search queries incorporated Boolean combinations of terms such as \"AI Agents,\" \"Agentic AI,\" \"LLM Agents,\" \"Tool-augmented LLMs,\" and \"Multi-Agent AI Systems.\"\n\nTargeted queries such as \"Agentic AI + Coordination +\n\nPlanning,\" and \"AI Agents + Tool Usage + Reasoning\" were employed to retrieve papers addressing both conceptual underpinnings and system-level implementations. Literature inclusion was based on criteria such as novelty, empirical evaluation, architectural contribution, and citation impact. The rising global interest in these technologies illustrated in Figure 1 using Google Trends data reinforces the urgency of synthesizing this emerging knowledge space.\n\n# II. FOUNDATIONAL UNDERSTANDING OF AI AGENTS\n\nAI Agents are an autonomous software entities engineered for goal-directed task execution within bounded digital environments [14], [39]. These agents are defined by their ability to perceive structured or unstructured inputs [40], reason over contextual information [41], [42], and initiate actions toward achieving specific objectives, often acting as surrogates for human users or subsystems [43]. Unlike conventional automation scripts, which follow deterministic workflows, AI agents demonstrate reactive intelligence and limited adaptability, allowing them to interpret dynamic inputs and reconfigure outputs accordingly [44]. Their adoption has been reported across a range of application domains, including customer service automation [45], [46], personal productivity assistance [47], internal information retrieval [48], [49], and decision support systems [50], [51].\n\n1) Overview of Core Characteristics of AI Agents: AI Agents are widely conceptualized as instantiated operational embodiments of artificial intelligence designed to interface with users, software ecosystems, or digital infrastructures in pursuit of goal-directed behavior [52]–[54]. These agents distinguish themselves from general-purpose LLMs by exhibiting structured initialization, bounded autonomy, and persistent\n\ntask orientation. While LLMs primarily function as reactive prompt followers [55], AI Agents operate within explicitly defined scopes, engaging dynamically with inputs and producing actionable outputs in real-time environments [56].\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/b3f3b81e4c6726d994ba88d2ae2100d82522360cbade29e2e6c02e6a872fdd37.jpg)  \nFig. 4: Core characteristics of AI Agents autonomy, task-specificity, and reactivity illustrated with symbolic representations for agent design and operational behavior.\n\nFigure 4 illustrates the three foundational characteristics that recur across architectural taxonomies and empirical deployments of AI Agents. These include autonomy, task-specificity, and reactivity with adaptation. First, autonomy denotes the agent's ability to act independently post-deployment, minimizing human-in-the-loop dependencies and enabling largescale, unattended operation [46], [57]. Second, task-specificity encapsulates the design philosophy of AI agents being specialized for narrowly scoped tasks allowing high-performance optimization within a defined functional domain such as scheduling, querying, or filtering [58], [59]. Third, reactivity refers to an agent's capacity to respond to changes in its environment, including user commands, software states, or API responses; when extended with adaptation, this includes feedback loops and basic learning heuristics [17], [60].\n\nTogether, these three traits provide a foundational profile for understanding and evaluating AI Agents across deployment scenarios. The remainder of this section elaborates on each characteristic, offering theoretical grounding and illustrative examples.\n\n- Autonomy: A central feature of AI Agents is their ability to function with minimal or no human intervention after deployment [57]. Once initialized, these agents are capable of perceiving environmental inputs, reasoning over contextual data, and executing predefined or adaptive actions in real-time [17]. Autonomy enables scalable deployment in applications where persistent oversight is impractical, such as customer support bots or scheduling assistants [46], [61].  \n- Task-Specificity: AI Agents are purpose-built for narrow, well-defined tasks [58], [59]. They are optimized to execute repeatable operations within a fixed domain, such as email filtering [62], [63], database querying [64], or calendar coordination [38], [65]. This task specialization allows for efficiency, interpretability, and high precision\n\nin automation tasks where general-purpose reasoning is unnecessary or inefficient.\n\n- Reactivity and Adaptation: AI Agents often include basic mechanisms for interacting with dynamic inputs, allowing them to respond to real-time stimuli such as user requests, external API calls, or state changes in software environments [17], [60]. Some systems integrate rudimentary learning [66] through feedback loops [67], [68], heuristics [69], or updated context buffers to refine behavior over time, particularly in settings like personalized recommendations or conversation flow management [70]-[72].\n\nThese core characteristics collectively enable AI Agents to serve as modular, lightweight interfaces between pretrained AI models and domain-specific utility pipelines. Their architectural simplicity and operational efficiency position them as key enablers of scalable automation across enterprise, consumer, and industrial settings. While limited in reasoning depth compared to more general AI systems, their high usability and performance within constrained task boundaries have made them foundational components in contemporary intelligent system design.\n\n2) Foundational Models: The Role of LLMs and LIMs: The foundational progress in AI agents has been significantly accelerated by the development and deployment of LLMs and LIMs, which serve as the core reasoning and perception engines in contemporary agent systems. These models enable AI agents to interact intelligently with their environments, understand multimodal inputs, and perform complex reasoning tasks that go beyond hard-coded automation.\n\nLLMs such as GPT-4 [73] and PaLM [74] are trained on massive datasets of text from books, web content, and dialogue corpora. These models exhibit emergent capabilities in natural language understanding, question answering, summarization, dialogue coherence, and even symbolic reasoning [75], [76]. Within AI agent architectures, LLMs serve as the primary decision-making engine, allowing the agent to parse user queries, plan multi-step solutions, and generate naturalistic responses. For instance, an AI customer support agent powered by GPT-4 can interpret customer complaints, query backend systems via tool integration, and respond in a contextually appropriate and emotionally aware manner [77].\n\nLarge Image Models (LIMs) such as CLIP [78] and BLIP-2 [79] extend the agent's capabilities into the visual domain. Trained on image-text pairs, LIMs enable perception-based tasks including image classification, object detection, and vision-language grounding. These capabilities are increasingly vital for agents operating in domains such as robotics [80], autonomous vehicles [81], [82], and visual content moderation [83], [84].\n\nFor example, as illustrated in Figure 5 in an autonomous drone agent tasked with inspecting orchards, a LIM can identify diseased fruits or damaged branches by interpreting live aerial imagery and triggering predefined intervention protocols. Upon detection, the system autonomously triggers predefined intervention protocols, such as notifying horti\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/e21f8f305fc6c01732664186819ab633e78e369e8b7bc2bc85abf19d0ccb8146.jpg)  \nFig. 5: An AI agent-enabled drone autonomously inspects an orchard, identifying diseased fruits and damaged branches using vision models, and triggers real-time alerts for targeted horticultural interventions\n\ncultural staff or marking the location for targeted treatment without requiring human intervention [17], [57]. This workflow exemplifies the autonomy and reactivity of AI agents in agricultural environment and recent literature underscores the growing sophistication of such drone-based AI agents. Chitra et al. [85] provide a comprehensive overview of AI algorithms foundational to embodied agents, highlighting the integration of computer vision, SLAM, reinforcement learning, and sensor fusion. These components collectively support real-time perception and adaptive navigation in dynamic environments. Kourav et al. [86] further emphasize the role of natural language processing and large language models in generating drone action plans from human-issued queries, demonstrating how LLMs support naturalistic interaction and mission planning. Similarly, Natarajan et al. [87] explore deep learning and reinforcement learning for scene understanding, spatial mapping, and multi-agent coordination in aerial robotics. These studies converge on the critical importance of AI-driven autonomy, perception, and decision-making in advancing drone-based agents.\n\nImportantly, LLMs and LIMs are often accessed via inference APIs provided by cloud-based platforms such as OpenAI https://openai.com/, HuggingFace https://huggingface.co/, and Google Gemini https://gemini.google.com/app. These services abstract away the complexity of model training and fine-tuning, enabling developers to rapidly build and deploy agents equipped with state-of-the-art reasoning and perceptual abilities. This composability accelerates prototyping and allows agent frameworks like LangChain [88] and AutoGen [89] to orchestrate LLM and LIM outputs across task workflows. In short, foundational models give modern AI agents their basic understanding of language and visuals. Language models help them reason with words, and image models help them understand pictures-working together, they allow AI to make\n\nsmart decisions in complex situations.\n\n3) Generative AI as a Precursor: A consistent theme in the literature is the positioning of generative AI as the foundational precursor to agentic intelligence. These systems primarily operate on pretrained LLMs and LIMs, which are optimized to synthesize novel content text, images, audio, or code based on input prompts. While highly expressive, generative models fundamentally exhibit reactive behavior: they produce output only when explicitly prompted and do not pursue goals autonomously or engage in self-initiated reasoning [90], [91].\n\n# Key Characteristics of Generative AI:\n\n- Reactivity: As non-autonomous systems, generative models are exclusively input-driven [92], [93]. Their operations are triggered by user-specified prompts and they lack internal states, persistent memory, or goal-following mechanisms [94]-[96].  \n- Multimodal Capability: Modern generative systems can produce a diverse array of outputs, including coherent narratives, executable code, realistic images, and even speech transcripts. For instance, models like GPT-4 [73], PaLM-E [97], and BLIP-2 [79] exemplify this capacity, enabling language-to-image, image-to-text, and cross-modal synthesis tasks.  \n- Prompt Dependency and Statelessness: Generative systems are stateless in that they do not retain context across interactions unless explicitly provided [98], [99]. Their design lacks intrinsic feedback loops [100], state management [101], [102], or multi-step planning a requirement for autonomous decision-making and iterative goal refinement [103], [104].\n\nDespite their remarkable generative fidelity, these systems are constrained by their inability to act upon the environment or manipulate digital tools independently. For instance, they cannot search the internet, parse real-time data, or interact with APIs without human-engineered wrappers or scaffolding layers. As such, they fall short of being classified as true AI Agents, whose architectures integrate perception, decision-making, and external tool-use within closed feedback loops.\n\nThe limitations of generative AI in handling dynamic tasks, maintaining state continuity, or executing multi-step plans led to the development of tool-augmented systems, commonly referred to as AI Agents [105]. These systems build upon the language processing backbone of LLMs but introduce additional infrastructure such as memory buffers, tool-calling APIs, reasoning chains, and planning routines to bridge the gap between passive response generation and active task completion. This architectural evolution marks a critical shift in AI system design: from content creation to autonomous utility [106], [107]. The trajectory from generative systems to AI agents underscores a progressive layering of functionality that ultimately supports the emergence of agentic behaviors.\n\n# A. Language Models as the Engine for AI Agent Progression\n\nThe emergence of Ai agent as a transformative paradigm in artificial intelligence is closely tied to the evolution and repurposing of large-scale language models such as GPT-3\n\n[108], Llama [109], T5 [110], Baichuan 2 [111] and GPT3mix [112]. A substantial and growing body of research confirms that the leap from reactive generative models to autonomous, goal-directed agents is driven by the integration of LLMs as core reasoning engines within dynamic agentic systems. These models, originally trained for natural language processing tasks, are increasingly embedded in frameworks that require adaptive planning [113], [114], real-time decision-making [115], [116], and environment-aware behavior [117].\n\n1) LLMs as Core Reasoning Components:\n\nLLMs such as GPT-4 [73], PaLM [74], Claude https://www.anthropic.com/news/claude-3-5-sonnet, and LLaMA [109] are pre-trained on massive text corpora using self-supervised objectives and fine-tuned using techniques such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) [118], [119]. These models encode rich statistical and semantic knowledge, allowing them to perform tasks like inference, summarization, code generation, and dialogue management. In agentic contexts, however, their capabilities are repurposed not merely to generate responses, but to serve as cognitive substrates interpreting user goals, generating action plans, selecting tools, and managing multi-turn workflows.\n\nRecent work identifies these models as central to the architecture of contemporary agentic systems. For instance, AutoGPT [30] and BabyAGI https://github.com/yoheinakajima/babyagi use GPT-4 as both a planner and executor: the model analyzes high-level objectives, decomposes them into actionable subtasks, invokes external APIs as needed, and monitors progress to determine subsequent actions. In such systems, the LLM operates in a loop of prompt processing, state updating, and feedback-based correction, closely emulating autonomous decision-making.\n\n2) Tool-Augmented AI Agents: Enhancing Functionality: To overcome limitations inherent to generative-only systems such as hallucination, static knowledge cutoffs, and restricted interaction scopes, researchers have proposed the concept of tool-augmented LLM agents [120] such as Easytool [121], Gentopia [122], and ToolFive [123]. These systems integrate external tools, APIs, and computation platforms into the agent's reasoning pipeline, allowing for real-time information access, code execution, and interaction with dynamic data environments.\n\nTool Invocation. When an agent identifies a need that cannot be addressed through its internal knowledge such as querying a current stock price, retrieving up-to-date weather information, or executing a script, it generates a structured function call or API request [124], [125]. These calls are typically formatted in JSON, SQL, or Python, depending on the target service, and routed through an orchestration layer that executes the task.\n\nResult Integration. Once a response is received from the tool, the output is parsed and reincorporated into the LLM's context window. This enables the agent to synthesize new reasoning paths, update its task status, and decide on the next step. The ReAct framework [126] exemplifies this architecture\n\nby combining reasoning (Chain-of-Thought prompting) and action (tool use), with LLMs alternating between internal cognition and external environment interaction.\n\n3) Illustrative Examples and Emerging Capabilities: Tool-augmented LLM agents have demonstrated capabilities across a range of applications. In AutoGPT [30], the agent may plan a product market analysis by sequentially querying the web, compiling competitor data, summarizing insights, and generating a report. In a coding context, tools like GPT-Engineer combine LLM-driven design with local code execution environments to iteratively develop software artifacts [127], [128]. In research domains, systems like Paper-QA [129] utilize LLMs to query vectorized academic databases, grounding answers in retrieved scientific literature to ensure factual integrity.\n\nThese capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops. Nevertheless, the inclusion of tools also introduces new challenges in orchestration complexity, error propagation, and context window limitations all active areas of research. The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.\n\nFigure 6 illustrates a representative case: a news query agent that performs real-time web search, summarizes retrieved documents, and generates an articulate, context-aware answer. Such workflows have been demonstrated in implementations using LangChain, AutoGPT, and OpenAI function-calling paradigms.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/72dfa69d3bad63c0cdb90e6887bf14d1bfeeb9216ca91fa47b43bebc6f0af2fc.jpg)  \nFig. 6: Workflow of an AI Agent performing real-time news search, summarization, and answer generation, as commonly described in the literature (e.g., Author, Year).\n\n# III. THE EMERGENCE OF AGENTIC AI FROM AI AGENT FOUNDATIONS\n\nWhile AI Agents represent a significant leap in artificial intelligence capabilities, particularly in automating narrow tasks through tool-augmented reasoning, recent literature identifies notable limitations that constrain their scalability in complex, multi-step, or cooperative scenarios [130]–[132]. These constraints have catalyzed the development of a more advanced paradigm: Agentic AI. This emerging class of systems extends the capabilities of traditional agents by enabling multiple intelligent entities to collaboratively pursue goals through structured communication [133]–[135], shared memory [136], [137], and dynamic role assignment [14].\n\n1) Conceptual Leap: From Isolated Tasks to Coordinated Systems: AI Agents, as explored in prior sections, integrate LLMs with external tools and APIs to execute narrowly scoped operations such as responding to customer queries, performing document retrieval, or managing schedules. However, as use cases increasingly demand context retention, task interdependence, and adaptability across dynamic environments, the single-agent model proves insufficient [138], [139].\n\nAgentic AI systems represent an emergent class of intelligent architectures in which multiple specialized agents collaborate to achieve complex, high-level objectives. As defined in recent frameworks, these systems are composed of modular agents each tasked with a distinct subcomponent of a broader goal and coordinated through either a centralized orchestrator or a decentralized protocol [16], [134]. This structure signifies a conceptual departure from the atomic, reactive behaviors typically observed in single-agent architectures, toward a form of system-level intelligence characterized by dynamic inter-agent collaboration.\n\nA key enabler of this paradigm is goal decomposition, wherein a user-specified objective is automatically parsed and divided into smaller, manageable tasks by planning agents [38]. These subtasks are then distributed across the agent network. Multi-step reasoning and planning mechanisms facilitate the dynamic sequencing of these subtasks, allowing the system to adapt in real time to environmental shifts or partial task failures. This ensures robust task execution even under uncertainty [14].\n\nInter-agent communication is mediated through distributed communication channels, such as asynchronous messaging queues, shared memory buffers, or intermediate output exchanges, enabling coordination without necessitating continuous central oversight [14], [140]. Furthermore, reflective reasoning and memory systems allow agents to store context across multiple interactions, evaluate past decisions, and iteratively refine their strategies [141]. Collectively, these capabilities enable Agentic AI systems to exhibit flexible, adaptive, and collaborative intelligence that exceeds the operational limits of individual agents.\n\nA widely accepted conceptual illustration in the literature delineates the distinction between AI Agents and Agentic AI through the analogy of smart home systems. As depicted in\n\nFigure 7, the left side represents a traditional AI Agent in the form of a smart thermostat. This standalone agent receives a user-defined temperature setting and autonomously controls the heating or cooling system to maintain the target temperature. While it demonstrates limited autonomy such as learning user schedules or reducing energy usage during absence, it operates in isolation, executing a singular, well-defined task without engaging in broader environmental coordination or goal inference [17], [57].\n\nIn contrast, the right side of Figure 7 illustrates an Agentic AI system embedded in a comprehensive smart home ecosystem. Here, multiple specialized agents interact synergistically to manage diverse aspects such as weather forecasting, daily scheduling, energy pricing optimization, security monitoring, and backup power activation. These agents are not just reactive modules; they communicate dynamically, share memory states, and collaboratively align actions toward a high-level system goal (e.g., optimizing comfort, safety, and energy efficiency in real time). For instance, a weather forecast agent might signal upcoming heatwaves, prompting early pre-cooling via solar energy before peak pricing hours, as coordinated by an energy management agent. Simultaneously, the system might delay high-energy tasks or activate surveillance systems during occupant absence, integrating decisions across domains. This figure embodies the architectural and functional leap from task-specific automation to adaptive, orchestrated intelligence. The AI Agent acts as a deterministic component with limited scope, while Agentic AI reflects distributed intelligence, characterized by goal decomposition, inter-agent communication, and contextual adaptation, hallmarks of modern agentic AI frameworks.\n\n2) Key Differentiators between AI Agents and Agentic AI: To systematically capture the evolution from Generative AI to AI Agents and further to Agentic AI, we structure our comparative analysis around a foundational taxonomy where Generative AI serves as the baseline. While AI Agents and Agentic AI represent increasingly autonomous and interactive systems, both paradigms are fundamentally grounded in generative architectures, especially LLMs and LIMs. Consequently, each comparative table in this subsection includes Generative AI as a reference column to highlight how agentic behavior diverges and builds upon generative foundations.\n\nA set of fundamental distinctions between AI Agents and Agentic AI particularly in terms of scope, autonomy, architectural composition, coordination strategy, and operational complexity are synthesized in Table I, derived from close analysis of prominent frameworks such as AutoGen [89] and ChatDev [142]. These comparisons provide a multi-dimensional view of how single-agent systems transition into coordinated, multiagent ecosystems. Through the lens of generative capabilities, we trace the increasing sophistication in planning, communication, and adaptation that characterizes the shift toward Agentic AI.\n\nWhile Table I delineates the foundational and operational differences between AI Agents and Agentic AI, a more granular taxonomy is required to understand how these paradigms\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/7aeb83720d2279405e2da9490dd653317c44498a9f9c9397d4a57a824791c4f6.jpg)  \nFig. 7: Comparative illustration of AI Agent vs. Agentic AI, synthesizing conceptual distinctions found in the literature (e.g., Author, Year). Left: A single-task AI Agent. Right: A multi-agent, collaborative Agentic AI system.\n\nemerge from and relate to broader generative frameworks. Specifically, the conceptual and cognitive progression from static Generative AI systems to tool-augmented AI Agents, and further to collaborative Agentic AI ecosystems, necessitates an integrated comparative framework. This transition is not merely structural but also functional encompassing how initiation mechanisms, memory use, learning capacities, and orchestration strategies evolve across the agentic spectrum. Moreover, recent studies suggest the emergence of hybrid paradigms such as \"Generative Agents,\" which blend generative modeling with modular task specialization, further complicating the agentic landscape. In order to capture these nuanced relationships, Table II synthesizes the key conceptual and cognitive dimensions across four archetypes: Generative AI, AI Agents, Agentic AI, and inferred Generative Agents. By positioning Generative AI as a baseline technology, this taxonomy highlights the scientific continuum that spans from passive content generation to interactive task execution and finally to autonomous, multi-agent orchestration. This multitiered lens is critical for understanding both the current capabilities and future trajectories of agentic intelligence across applied and theoretical domains.\n\nTo further operationalize the distinctions outlined in Table I, Tables III and II extend the comparative lens to encompass a broader spectrum of agent paradigms including\n\nAI Agents, Agentic AI, and emerging Generative Agents. Table III presents key architectural and behavioral attributes that highlight how each paradigm differs in terms of primary capabilities, planning scope, interaction style, learning dynamics, and evaluation criteria. AI Agents are optimized for discrete task execution with limited planning horizons and rely on supervised or rule-based learning mechanisms. In contrast, Agentic AI systems extend this capacity through multi-step planning, meta-learning, and inter-agent communication, positioning them for use in complex environments requiring autonomous goal setting and coordination. Generative Agents, as a more recent construct, inherit LLM-centric pretraining capabilities and excel in producing multimodal content creatively, yet they lack the proactive orchestration and state-persistent behaviors seen in Agentic AI systems.\n\nThe second table (Table III) provides a process-driven comparison across three agent categories: Generative AI, AI Agents, and Agentic AI. This framing emphasizes how functional pipelines evolve from prompt-driven single-model inference in Generative AI, to tool-augmented execution in AI Agents, and finally to orchestrated agent networks in Agentic AI. The structure column underscores this progression: from single LLMs to integrated toolchains and ultimately to distributed multi-agent systems. Access to external data, a key operational requirement for real-world utility, also increases\n\nTABLE I: Key Differences Between AI Agents and Agentic AI  \n\n<table><tr><td>Feature</td><td>AI Agents</td><td>Agentic AI</td></tr><tr><td>Definition</td><td>Autonomous software programs that perform specific tasks.</td><td>Systems of multiple AI agents collaborating to achieve complex goals.</td></tr><tr><td>Autonomy Level</td><td>High autonomy within specific tasks.</td><td>Higher autonomy with the ability to manage multi-step, complex tasks.</td></tr><tr><td>Task Complexity</td><td>Typically handle single, specific tasks.</td><td>Handle complex, multi-step tasks requiring coordination.</td></tr><tr><td>Collaboration</td><td>Operate independently.</td><td>Involve multi-agent collaboration and information sharing.</td></tr><tr><td>Learning and Adaptation</td><td>Learn and adapt within their specific domain.</td><td>Learn and adapt across a wider range of tasks and environments.</td></tr><tr><td>Applications</td><td>Customer service chatbots, virtual assistants, automated workflows.</td><td>Supply chain management, business process optimization, virtual project managers.</td></tr></table>\n\nin sophistication, from absent or optional in Generative AI to modular and coordinated in Agentic AI. Collectively, these comparative views reinforce that the evolution from generative to agentic paradigms is marked not just by increasing system complexity but also by deeper integration of autonomy, memory, and decision-making across multiple levels of abstraction.\n\nFurthermore, to provide a deeper multi-dimensional understanding of the evolving agentic landscape, Tables V through IX extend the comparative taxonomy to dissect five critical dimensions: core function and goal alignment, architectural composition, operational mechanism, scope and complexity, and interaction-autonomy dynamics. These dimensions serve to not only reinforce the structural differences between Generative AI, AI Agents, and Agentic AI, but also introduce an emergent category Generative Agents representing modular agents designed for embedded subtask-level generation within broader workflows. Table V situates the three paradigms in terms of their overarching goals and functional intent. While Generative AI centers on prompt-driven content generation, AI Agents emphasize tool-based task execution, and Agentic AI systems orchestrate full-fledged workflows. This functional expansion is mirrored architecturally in Table VI, where the system design transitions from single-model reliance (in Generative AI) to multi-agent orchestration and shared memory utilization in Agentic AI. Table VII then outlines how these paradigms differ in their workflow execution pathways, highlighting the rise of inter-agent coordination and hierarchical communication as key drivers of agentic behavior.\n\nFurthermore, Table VIII explores the increasing scope and operational complexity handled by these systems ranging from isolated content generation to adaptive, multi-agent collaboration in dynamic environments. Finally, Table IX synthesizes the varying degrees of autonomy, interaction style,\n\nand decision-making granularity across the paradigms. These tables collectively establish a rigorous framework to classify and analyze agent-based AI systems, laying the groundwork for principled evaluation and future design of autonomous, intelligent, and collaborative agents operating at scale.\n\nEach of the comparative tables presented from Table V through Table IX offers a layered analytical lens to isolate the distinguishing attributes of Generative AI, AI Agents, and Agentic AI, thereby grounding the conceptual taxonomy in concrete operational and architectural features. Table V, for instance, addresses the most fundamental layer of differentiation: core function and system goal. While Generative AI is narrowly focused on reactive content production conditioned on user prompts, AI Agents are characterized by their ability to perform targeted tasks using external tools. Agentic AI, by contrast, is defined by its ability to pursue high-level goals through the orchestration of multiple subagents each addressing a component of a broader workflow. This shift from output generation to workflow execution marks a critical inflection point in the evolution of autonomous systems.\n\nIn Table VI, the architectural distinctions are made explicit, especially in terms of system composition and control logic. Generative AI relies on a single model with no built-in capability for tool use or delegation, whereas AI Agents combine language models with auxiliary APIs and interface mechanisms to augment functionality. Agentic AI extends this further by introducing multi-agent systems where collaboration, memory persistence, and orchestration protocols are central to the system's operation. This expansion is crucial for enabling intelligent delegation, context preservation, and dynamic role assignment capabilities absent in both generative and single-agent systems. Likewise in Table VII dives deeper into how these systems function operationally, emphasizing differences in execution logic and information flow. Unlike Generative AI's linear pipeline (prompt  $\\rightarrow$  output), AI Agents implement procedural mechanisms to incorporate tool responses midprocess. Agentic AI introduces recursive task reallocation and cross-agent messaging, thus facilitating emergent decision-making that cannot be captured by static LLM outputs alone. Table VIII further reinforces these distinctions by mapping each system's capacity to handle task diversity, temporal scale, and operational robustness. Here, Agentic AI emerges as uniquely capable of supporting high-complexity goals that demand adaptive, multi-phase reasoning and execution strategies.\n\nFurthermore, Table IX brings into sharp relief the operational and behavioral distinctions across Generative AI, AI Agents, and Agentic AI, with a particular focus on autonomy levels, interaction styles, and inter-agent coordination. Generative AI systems, typified by models such as GPT-3 [108] and DALL-E https://openai.com/index/dall-e-3/, remain reactive generating content solely in response to prompts without maintaining persistent state or engaging in iterative reasoning. In contrast, AI Agents such as those constructed with LangChain [88] or MetaGPT [143], exhibit a higher degree of autonomy, capable of initiating external tool invocations and adapting behaviors within bounded tasks. However,\n\nTABLE II: Taxonomy Summary of AI Agent Paradigms: Conceptual and Cognitive Dimensions  \n\n<table><tr><td>Conceptual Dimension</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Initiation Type</td><td>Prompt-triggered by user or input</td><td>Prompt or goal-triggered with tool use</td><td>Goal-initiated or orchestrated task</td><td>Prompt or system-level trigger</td><td>Prompt or system-level trigger</td></tr><tr><td>Goal Flexibility</td><td>(None) fixed per prompt</td><td>(Low) executes specific goal</td><td>(High) decomposes and adapts goals</td><td>(Low) guided by subtask goal</td><td>(Low) guided by subtask goal</td></tr><tr><td>Temporal Continuity</td><td>Stateless, single-session output</td><td>Short-term continuity within task</td><td>Persistent across workflow stages</td><td>Context-limited to subtask</td><td>Persistent across workflow stages</td></tr><tr><td>Learning/Adaptation</td><td>Static (pretrained)</td><td>(Might in future) Tool selection strategies may evolve</td><td>(Yes) Learns from outcomes</td><td>Typically static; limited adaptation</td><td>Typically static; limited adaptation</td></tr><tr><td>Memory Use</td><td>No memory or short context window</td><td>Optional memory or tool cache</td><td>Shared episodic/task memory</td><td>Subtask-local or contextual memory</td><td>Subtask-local or contextual memory</td></tr><tr><td>Coordination Strategy</td><td>None (single-step process)</td><td>Isolated task execution</td><td>Hierarchical or decentralized coordination</td><td>Receives instructions from system</td><td>Receives instructions from system</td></tr><tr><td>System Role</td><td>Content generator</td><td>Tool-using task executor</td><td>Collaborative workflow or-chestrator</td><td>Subtask-level modular generator</td><td>Subtask-level modular generator</td></tr></table>\n\nTABLE III: Key Attributes of AI Agents, Agentic AI, and Generative Agents  \n\n<table><tr><td>Aspect</td><td>AI Agent</td><td>Agentic AI</td><td>Generative Agent</td></tr><tr><td>Primary Capability</td><td>Task execution</td><td>Autonomous goal setting</td><td>Content generation</td></tr><tr><td>Planning Horizon</td><td>Single-step</td><td>Multi-step</td><td>N/A (content only)</td></tr><tr><td>Learning Mecanism</td><td>Rule-based or supervised</td><td>Reinforcement/meta-learning</td><td>Large-scale pre-training</td></tr><tr><td>Interaction Style</td><td>Reactive</td><td>Proactive</td><td>Creative</td></tr><tr><td>Evaluation Focus</td><td>Accuracy, latency</td><td>Engagement, adaptability</td><td>Coherence, diversity</td></tr></table>\n\nTABLE IV: Comparison of Generative AI, AI Agents, and Agentic AI  \n\n<table><tr><td>Feature</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td></tr><tr><td>Core Function</td><td>Content generation</td><td>Task-specific execution using tools</td><td>Complex workflow automation</td></tr><tr><td>Mechanism</td><td>Prompt → LLM → Output</td><td>Prompt → Tool Call → LLM → Output</td><td>Goal → Agent Orchestration → Output</td></tr><tr><td>Structure</td><td>Single model</td><td>LLM + tool(s)</td><td>Multi-agent system</td></tr><tr><td>External Data Access</td><td>None (unless added)</td><td>Via external APIs</td><td>Coordinated multi-agent access</td></tr><tr><td>Key Trait</td><td>Reactivity</td><td>Tool-use</td><td>Collaboration</td></tr></table>\n\ntheir autonomy is typically confined to isolated task execution, lacking long-term state continuity or collaborative interaction.\n\nAgentic AI systems mark a significant departure from these paradigms by introducing internal orchestration mechanisms and multi-agent collaboration frameworks. For example, platforms like AutoGen [89] and ChatDev [142] exemplify agentic coordination through task decomposition, role assignment, and recursive feedback loops. In AutoGen, one agent might\n\nserve as a planner while another retrieves information and a third synthesizes a report each communicating through shared memory buffers and governed by an orchestrator agent that monitors dependencies and overall task progression. This structured coordination allows for more complex goal pursuit and flexible behavior in dynamic environments. Such architectures fundamentally shift the locus of intelligence from single-model outputs to emergent system-level behavior, wherein agents learn, negotiate, and update decisions based on evolving task states. Thus, the comparative taxonomy not only highlights increasing levels of operational independence but also illustrates how Agentic AI introduces novel paradigms of communication, memory integration, and decentralized control, paving the way for the next generation of autonomous systems with scalable, adaptive intelligence.\n\n# A. Architectural Evolution: From AI Agents to Agentic AI Systems\n\nWhile both AI Agents and Agentic AI systems are grounded in modular design principles, Agentic AI significantly extends the foundational architecture to support more complex, distributed, and adaptive behaviors. As illustrated in Figure 8, the transition begins with core subsystems Perception, Reasoning, and Action, that define traditional AI Agents. Agentic AI enhances this base by integrating advanced components such as Specialized Agents, Advanced Reasoning & Planning, Persistent Memory, and Orchestration. The figure further emphasizes emergent capabilities including Multi-Agent Collaboration, System Coordination, Shared Context, and Task Decomposition, all encapsulated within a dotted boundary that signifies the shift toward reflective, decentralized, and goal-driven system architectures. This progression marks a fundamental inflection point in intelligent agent design. This section synthesizes findings from empirical frameworks such as LangChain [88], AutoGPT [89], and TaskMatrix [144], highlighting this progression in architectural sophistication.\n\n1) Core Architectural Components of AI Agents: Foundational AI Agents are typically composed of four primary subsystems: perception, reasoning, action, and learning. These\n\nTABLE V: Comparison by Core Function and Goal  \n\n<table><tr><td>Feature</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Primary Goal</td><td>Create novel content based on prompt</td><td>Execute a specific task using external tools</td><td>Automate complex workflow or achieve high-level goals</td><td colspan=\"2\">Perform a specific generative sub-task</td></tr><tr><td>Core Function</td><td>Content generation (text, image, audio, etc.)</td><td>Task execution with external interaction</td><td>Workflow orchestration and goal achievement</td><td colspan=\"2\">Sub-task content generation within a workflow</td></tr></table>\n\nTABLE VI: Comparison by Architectural Components  \n\n<table><tr><td>Component</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Core Engine</td><td>LLM / LIM</td><td>LLM</td><td>Multiple LLMs (potentially diverse)</td><td>LLM</td><td></td></tr><tr><td>Prompts</td><td>Yes (input trigger)</td><td>Yes (task guidance)</td><td>Yes (system goal and agent tasks)</td><td>Yes (sub-task guidance)</td><td></td></tr><tr><td>Tools/APIs</td><td>No (inherently)</td><td>Yes (essential)</td><td>Yes (available to constituent agents)</td><td>Potentially (if sub-task requires)</td><td></td></tr><tr><td>Multiple Agents</td><td>No</td><td>No</td><td>Yes (essential; collaborative)</td><td>No (is an individual agent)</td><td></td></tr><tr><td>Orchestration</td><td>No</td><td>No</td><td>Yes (implicit or explicit)</td><td>No (is part of orchestration)</td><td></td></tr></table>\n\nTABLE VII: Comparison by Operational Mechanism  \n\n<table><tr><td>Mechanism</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Primary Driver</td><td>Reactivity to prompt</td><td>Tool calling for task execution</td><td>Inter-agent communication and collaboration</td><td>Reactivity to input or sub-task prompt</td><td></td></tr><tr><td>Interaction Mode</td><td>User → LLM</td><td>User → Agent → Tool</td><td>User → System → Agents</td><td>System/Agent → Agent → Output</td><td></td></tr><tr><td>Workflow Handling</td><td>Single generation step</td><td>Single task execution</td><td>Multi-step workflow coordination</td><td>Single step within workflow</td><td></td></tr><tr><td>Information Flow</td><td>Input → Output</td><td>Input → Tool → Output</td><td>Input → Agent1 → Agent2 → ... → Output</td><td>Input (from system/agent) → Output</td><td></td></tr></table>\n\nTABLE VIII: Comparison by Scope and Complexity  \n\n<table><tr><td>Aspect</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Task Scope</td><td>Single piece of generated content</td><td>Single, specific, defined task</td><td>Complex, multi-faceted goal or workflow</td><td>Specific sub-task (often generative)</td><td></td></tr><tr><td>Complexity</td><td>Low (relative)</td><td>Medium (integrates tools)</td><td>High (multi-agent coordination)</td><td>Low to Medium (one task component)</td><td></td></tr><tr><td>Example (Video)</td><td>Chatbot</td><td>Tavily Search Agent</td><td>YouTube-to-Blog Conversion System</td><td>Title/Description/Conclusion Generator</td><td></td></tr></table>\n\nTABLE IX: Comparison by Interaction and Autonomy  \n\n<table><tr><td>Feature</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Autonomy Level</td><td>Low (requires prompt)</td><td>Medium (uses tools autonomously)</td><td>High (manages entire process)</td><td>Low to Medium (executes sub-task)</td><td></td></tr><tr><td>External Interaction</td><td>None (baseline)</td><td>Via specific tools or APIs</td><td>Through multiple agents/tools</td><td>Possibly via tools (if needed)</td><td></td></tr><tr><td>Internal Interaction</td><td>N/A</td><td>N/A</td><td>High (inter-agent)</td><td>Receives input from system or agent</td><td></td></tr><tr><td>Decision Making</td><td>Pattern selection</td><td>Tool usage decisions</td><td>Goal decomposition and assignment</td><td>Best sub-task generation strategy</td><td></td></tr></table>\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/13f7ce7956eb6484fa632ead0c4954d68dd2195949afb9be183bbec8a96e6cb6.jpg)  \nFig. 8: Illustrating architectural evolution from traditional AI Agents to modern Agentic AI systems. It begins with core modules Perception, Reasoning, and Action and expands into advanced components including Specialized Agents, Advanced Reasoning & Planning, Persistent Memory, and Orchestration. The diagram further captures emergent properties such as Multi-Agent Collaboration, System Coordination, Shared Context, and Task Decomposition, all enclosed within a dotted boundary signifying layered modularity and the transition to distributed, adaptive agentic AI intelligence.\n\nsubsystems form a closed-loop operational cycle, commonly referred to as \"Understand, Think, Act\" from a user interface perspective, or \"Input, Processing, Action, Learning\" in systems design literature [14], [145].\n\n- Perception Module: This subsystem ingests input signals from users (e.g., natural language prompts) or external systems (e.g., APIs, file uploads, sensor streams). It is responsible for preprocessing data into a format interpretable by the agent's reasoning module. For example, in LangChain-based agents [88], [146], the perception layer handles prompt templating, contextual wrapping, and retrieval augmentation via document chunking and embedding search.  \n- Knowledge Representation and Reasoning (KRR) Module: At the core of the agent's intelligence lies the KRR module, which applies symbolic, statistical, or hybrid logic to input data. Techniques include rule-based logic (e.g., if-then decision trees), deterministic workflow engines, and simple planning graphs. Reasoning in agents like AutoGPT [30] is enhanced with function-calling and prompt chaining to simulate thought processes (e.g., \"step-by-step\" prompts or intermediate tool invocations).  \n- Action Selection and Execution Module: This module\n\ntranslates inferred decisions into external actions using an action library. These actions may include sending messages, updating databases, querying APIs, or producing structured outputs. Execution is often managed by middleware like LangChain's \"agent executor,\" which links LLM outputs to tool calls and observes responses for subsequent steps [88].  \n- Basic Learning and Adaptation: Traditional AI Agents feature limited learning mechanisms, such as heuristic parameter adjustment [147], [148] or history-informed context retention. For instance, agents may use simple memory buffers to recall prior user inputs or apply scoring mechanisms to improve tool selection in future iterations.\n\nCustomization of these agents typically involves domain-specific prompt engineering, rule injection, or workflow templates, distinguishing them from hard-coded automation scripts by their ability to make context-aware decisions. Systems like ReAct [126] exemplify this architecture, combining reasoning and action in an iterative framework where agents simulate internal dialogue before selecting external actions.\n\n2) Architectural Enhancements in Agentic AI: Agentic AI systems inherit the modularity of AI Agents but extend\n\ntheir architecture to support distributed intelligence, inter-agent communication, and recursive planning. The literature documents a number of critical architectural enhancements that differentiate Agentic AI from its predecessors [149], [150].\n\n- Ensemble of Specialized Agents: Rather than operating as a monolithic unit, Agentic AI systems consist of multiple agents, each assigned a specialized function e.g., a summarizer, a retriever, a planner. These agents interact via communication channels (e.g., message queues, blackboards, or shared memory). For instance MetaGPT [143] exemplify this approach by modeling agents after corporate departments (e.g., CEO, CTO, engineer), where roles are modular, reusable, and role-bound.  \n- Advanced Reasoning and Planning: Agentic systems embed recursive reasoning capabilities using frameworks such as ReAct [126], Chain-of-Thought (CoT) prompting [151], and Tree of Thoughts [152]. These mechanisms allow agents to break down a complex task into multiple reasoning stages, evaluate intermediate results, and replan actions dynamically. This enables the system to respond adaptively to uncertainty or partial failure.  \n- Persistent Memory Architectures: Unlike traditional agents, Agentic AI incorporates memory subsystems to persist knowledge across task cycles or agent sessions [153], [154]. Memory types include episodic memory (task-specific history) [155], [156], semantic memory (long-term facts or structured data) [157], [158], and vector-based memory for retrieval-augmented generation (RAG) [159], [160]. For example, AutoGen [89] agents maintain scratchpads for intermediate computations, enabling stepwise task progression.  \n- Orchestration Layers / Meta-Agents: A key innovation in Agentic AI is the introduction of orchestrators meta-agents that coordinate the lifecycle of subordinate agents, manage dependencies, assign roles, and resolve conflicts. Orchestrators often include task managers, evaluators, or moderators. In ChatDev [142], for example, a virtual CEO meta-agent distributes subtasks to departmental agents and integrates their outputs into a unified strategic response.\n\nThese enhancements collectively enable Agentic AI to support scenarios that require sustained context, distributed labor, multi-modal coordination, and strategic adaptation. Use cases range from research assistants that retrieve, summarize, and draft documents in tandem (e.g., AutoGen pipelines [89]) to smart supply chain agents that monitor logistics, vendor performance, and dynamic pricing models in parallel.\n\nThe shift from isolated perception—reasoning—action loops to collaborative and reflective multi-agent workflows marks a key inflection point in the architectural design of intelligent systems. This progression positions Agentic AI as the next stage of AI infrastructure capable not only of executing predefined workflows but also of constructing, revising, and managing complex objectives across agents with minimal\n\nhuman supervision.\n\n# IV. APPLICATION OF AI AGENTS AND AGENTIC AI\n\nTo illustrate the real-world utility and operational divergence between AI Agents and Agentic AI systems, this study synthesizes a range of applications drawn from recent literature, as visualized in Figure 9. We systematically categorize and analyze application domains across two parallel tracks: conventional AI Agent systems and their more advanced Agentic AI counterparts. For AI Agents, four primary use cases are reviewed: (1) Customer Support Automation and Internal Enterprise Search, where single-agent models handle structured queries and response generation; (2) Email Filtering and Prioritization, where agents assist users in managing high-volume communication through classification heuristics; (3) Personalized Content Recommendation and Basic Data Reporting, where user behavior is analyzed for automated insights; and (4) Autonomous Scheduling Assistants, which interpret calendars and book tasks with minimal user input. In contrast, Agentic AI applications encompass broader and more dynamic capabilities, reviewed through four additional categories: (1) Multi-Agent Research Assistants that retrieve, synthesize, and draft scientific content collaboratively; (2) Intelligent Robotics Coordination, including drone and multirobot systems in fields like agriculture and logistics; (3) Collaborative Medical Decision Support, involving diagnostic, treatment, and monitoring subsystems; and (4) Multi-Agent Game AI and Adaptive Workflow Automation, where decentralized agents interact strategically or handle complex task pipelines.\n\n1) Application of AI Agents:  \n1) Customer Support Automation and Internal Enterprise Search: AI Agents are widely adopted in enterprise environments for automating customer support and facilitating internal knowledge retrieval. In customer service, these agents leverage retrieval-augmented LLMs interfaced with APIs and organizational knowledge bases to answer user queries, triage tickets, and perform actions like order tracking or return initiation [46]. For internal enterprise search, agents built on vector stores (e.g., Pinecone, Elascticsearch) retrieve semantically relevant documents in response to natural language queries. Tools such as Salesforce Einstein https://www.salesforce.com/artificial-intelligence/, Intercom Fin https://www.intercom.com/fin, and Notion AI https://www.notion.com/product/ai demonstrate how structured input processing and summarization capabilities reduce workload and improve enterprise decision-making.\n\nA practical example (Figure 10a) of this dual functionality can be seen in a multinational e-commerce company deploying an AI Agent-based customer support and internal search assistant. For customer support, the AI Agent integrates with the company's CRM (e.g., Salesforce) and fulfillment APIs to resolve queries such as \"Where is my order?\" or \"How can I return this\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/6f1f5ae95d27da4f73592ce56b6a0eb658ac58fda69c516809c48609f3aa7aeb.jpg)  \nFig. 9: Categorized applications of AI Agents and Agentic AI across eight core functional domains.\n\nitem?\" Within milliseconds, the agent retrieves contextual data from shipping databases and policy repositories, then generates a personalized response using retrieval-augmented generation. For internal enterprise search, employees use the same system to query past meeting notes, sales presentations, or legal documents. When an HR manager types \"summarize key benefits policy changes from last year,\" the agent queries a Pinecone vector store embedded with enterprise documentation, ranks results by semantic similarity, and returns a concise summary along with source links. These capabilities not only reduce ticket volume and support overhead but also minimize time spent searching for institutional knowledge. The result is a unified, responsive system that enhances both external service delivery and internal operational efficiency using modular AI Agent architectures.\n\n2) Email Filtering and Prioritization: Within productivity tools, AI Agents automate email triage through content classification and prioritization. Integrated with systems like Microsoft Outlook and Superhuman, these agents analyze metadata and message semantics to detect urgency, extract tasks, and recommend replies. They apply user-tuned filtering rules, behavioral signals, and intent classification to reduce cognitive overload. Autonomous actions, such as auto-tagging or summarizing threads,\n\nenhance efficiency, while embedded feedback loops enable personalization through incremental learning [61]. Figure10b illustrates a practical implementation of AI Agents in the domain of email filtering and prioritization. In modern workplace environments, users are inundated with high volumes of email, leading to cognitive overload and missed critical communications. AI Agents embedded in platforms like Microsoft Outlook or Superhuman act as intelligent intermediaries that classify, cluster, and triage incoming messages. These agents evaluate metadata (e.g., sender, subject line) and semantic content to detect urgency, extract actionable items, and suggest smart replies. As depicted, the AI agent autonomously categorizes emails into tags such as \"Urgent,\" \"Follow-up,\" and \"Low Priority,\" while also offering context-aware summaries and reply drafts. Through continual feedback loops and usage patterns, the system adapts to user preferences, gradually refining classification thresholds and improving prioritization accuracy. This automation offloads decision fatigue, allowing users to focus on high-value tasks, while maintaining efficient communication management in fast-paced, information-dense environments.\n\n3) Personalized Content Recommendation and Basic Data Reporting: AI Agents support adaptive personalization by analyzing behavioral patterns for news, prod\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/44335adacef08e3f4f132aae2ba85ccb3705cec95311d8119c2d584600e8e262.jpg)  \n(a)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/fbdd3d16b3abf297aa8ad10f931689ed9602605f4e67689bb6dc709054c2de9f.jpg)  \n(b)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/48100b714822e775902f38518c0089951be0c35abd8eecdf490653f38c3f5c3f.jpg)  \n(c)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/e9859731f25c8be9e6c5d789350a38e207e911e32eb99a2e34f6a5c7e99dd02c.jpg)  \n(d)  \nFig. 10: Applications of AI Agents in enterprise settings: (a) Customer support and internal enterprise search; (b) Email filtering and prioritization; (c) Personalized content recommendation and basic data reporting; and (d) Autonomous scheduling assistants. Each example highlights modular AI Agent integration for automation, intent understanding, and adaptive reasoning across operational workflows and user-facing systems.\n\nuct, or media recommendations. Platforms like Amazon, YouTube, and Spotify deploy these agents to infer user preferences via collaborative filtering, intent detection,\n\nand content ranking. Simultaneously, AI Agents in analytics systems (e.g., Tableau Pulse, Power BI Copilot) enable natural-language data queries and automated report generation by converting prompts to structured database queries and visual summaries, democratizing business intelligence access.\n\nA practical illustration (Figure 10c) of AI Agents in personalized content recommendation and basic data reporting can be found in e-commerce and enterprise analytics systems. Consider an AI agent deployed on a retail platform like Amazon: as users browse, click, and purchase items, the agent continuously monitors interaction patterns such as dwell time, search queries, and purchase sequences. Using collaborative filtering and content-based ranking, the agent infers user intent and dynamically generates personalized product suggestions that evolve over time. For example, after purchasing gardening tools, a user may be recommended compatible soil sensors or relevant books. This level of personalization enhances customer engagement, increases conversion rates, and supports long-term user retention. Simultaneously, within a corporate setting, an AI agent integrated into Power BI Copilot allows non-technical staff to request insights using natural language, for instance, \"Compare Q3 and Q4 sales in the Northeast.\" The agent translates the prompt into structured SQL queries, extracts patterns from the database, and outputs a concise visual summary or narrative report. This application reduces dependency on data analysts and empowers broader business decision-making through intuitive, language-driven interfaces.\n\n4) Autonomous Scheduling Assistants: AI Agents integrated with calendar systems autonomously manage meeting coordination, rescheduling, and conflict resolution. Tools like x.ai and Reclaim AI interpret vague scheduling commands, access calendar APIs, and identify optimal time slots using learned user preferences. They minimize human input while adapting to dynamic availability constraints. Their ability to interface with enterprise systems and respond to ambiguous instructions highlights the modular autonomy of contemporary scheduling agents.\n\nA practical application of autonomous scheduling agents can be seen in corporate settings as depicted in Figure 10d where employees manage multiple overlapping responsibilities across global time zones. Consider an executive assistant AI agent integrated with Google Calendar and Slack that interprets a command like \"Find a 45-minute window for a follow-up with the product team next week.\" The agent parses the request, checks availability for all participants, accounts for time zone differences, and avoids meeting conflicts or working-hour violations. If it identifies a conflict with a previously scheduled task, it may autonomously propose alternative windows and notify affected attendees via Slack integration. Additionally, the agent learns from\n\nhistorical user preferences such as avoiding early Friday meetings and refines its suggestions over time. Tools like Reclaim AI and Clockwise exemplify this capability, offering calendar-aware automation that adapts to evolving workloads. Such assistants reduce coordination overhead, increase scheduling efficiency, and enable smoother team workflows by proactively resolving ambiguity and optimizing calendar utilization.\n\nTABLE X: Representative AI Agents (2023-2025): Applications and Operational Characteristics  \n\n<table><tr><td>Model / Reference</td><td>Application Area</td><td>Operation as AI Agent</td></tr><tr><td>ChatGPT Deep Re-search Mode OpenAI (2025) Deep Research OpenAI</td><td>Research Analysis / Reporting</td><td>Synthesizes hundreds of sources into reports; functions as a self-directed research analyst.</td></tr><tr><td>Operator OpenAI (2025) Operator OpenAI</td><td>Web Automation</td><td>Navigates websites, fills forms, and completes online tasks autonomously.</td></tr><tr><td>Agentspace: Deep Re-search Agent Google (2025) Google Agentspace</td><td>Enterprise Reporting</td><td>Generates business intelligence reports using Gemini models.</td></tr><tr><td>NotebookLM Plus Agent Google (2025) NotebookLM</td><td>Knowledge Management</td><td>Summarizes, organizes, and retrieves data across Google Workspace apps.</td></tr><tr><td>Nova Act Amazon (2025) Amazon Nova</td><td>Workflow Automation</td><td>Automates browser-based tasks such as scheduling, HR requests, and email.</td></tr><tr><td>Manus Agent Monica (2025) Manus Agenthttps://manus.im/</td><td>Personal Task Automation</td><td>Executes trip planning, site building, and product comparisons via browsing.</td></tr><tr><td>Harvey Harvey AI (2025) Har-vey</td><td>Legal Automation</td><td>Automates document drafting, legal review, and predictive case analysis.</td></tr><tr><td>Otter Meeting Agent Otter.ai (2025) Otter</td><td>Meeting Management</td><td>Transcribes meetings and provides highlights, summaries, and action items.</td></tr><tr><td>Otter Sales Agent Otter.ai (2025) Otter sales agent</td><td>Sales Enablement</td><td>Analyzes sales calls, extracts insights, and suggests follow-ups.</td></tr><tr><td>ClickUp Brain ClickUp (2025) ClickUp Brain</td><td>Project Manage-ment</td><td>Automates task tracking, updates, and project workflows.</td></tr><tr><td>Agentforce Agentforce (2025) Agentforce</td><td>Customer Support</td><td>Routes tickets and generates context-aware replies for support teams.</td></tr><tr><td>Microsoft Copilot Microsoft (2024) Microsoft Copilot</td><td>Office Productivity</td><td>Automates writing, formula generation, and summarization in Microsoft 365.</td></tr><tr><td>Project Astra Google DeepMind (2025) Project Astra</td><td>Multimodal As-sistance</td><td>Processes text, image, audio, and video for task support and recommendations.</td></tr><tr><td>Claude 3.5 Agent Anthropic (2025) Claude 3.5 Sonnet</td><td>Enterprise Assist-stance</td><td>Uses multimodal input for reasoning, personalization, and enterprise task completion.</td></tr></table>\n\n# 2) Applications of Agentic AI:\n\n1) Multi-Agent Research Assistants: Agentic AI systems are increasingly deployed in academic and industrial research pipelines to automate multi-stage knowledge work. Platforms like AutoGen and CrewAI assign specialized roles to multiple agents retrievers, summarizers,\n\nsynthesizers, and citation formatters under a central orchestrator. The orchestrator distributes tasks, manages role dependencies, and integrates outputs into coherent drafts or review summaries. Persistent memory allows for cross-agent context sharing and refinement over time. These systems are being used for literature reviews, grant preparation, and patent search pipelines, outperforming single-agent systems such as ChatGPT by enabling concurrent sub-task execution and long-context management [89].\n\nFor example, a real-world application of agentic AI as depicted in Figure 11a is in the automated drafting of grant proposals. Consider a university research group preparing a National Science Foundation (NSF) submission. Using an AutoGen-based architecture, distinct agents are assigned: one retrieves prior funded proposals and extracts structural patterns; another scans recent literature to summarize related work; a third agent aligns proposal objectives with NSF solicitation language; and a formatting agent structures the document per compliance guidelines. The orchestrator coordinates these agents, resolving dependencies (e.g., aligning methodology with objectives) and ensuring stylistic consistency across sections. Persistent memory modules store evolving drafts, feedback from collaborators, and funding agency templates, enabling iterative improvement over multiple sessions. Compared to traditional manual processes, this multi-agent system significantly accelerates drafting time, improves narrative cohesion, and ensures regulatory alignment offering a scalable, adaptive approach to collaborative scientific writing in academia and R&D-intensive industries.\n\n2) Intelligent Robotics Coordination: In robotics and automation, Agentic AI underpins collaborative behavior in multi-robot systems. Each robot operates as a task specialized agent such as pickers, transporters, or mappers while an orchestrator supervises and adapts workflows. These architectures rely on shared spatial memory, real-time sensor fusion, and inter-agent synchronization for coordinated physical actions. Use cases include warehouse automation, drone-based orchard inspection, and robotic harvesting [143]. For instance, agricultural drone swarms may collectively map tree rows, identify diseased fruits, and initiate mechanical interventions. This dynamic allocation enables real-time reconfiguration and autonomy across agents facing uncertain or evolving environments.\n\nFor example, in commercial apple orchards (Figure 11b), Agentic AI enables a coordinated multi-robot system to optimize the harvest season. Here, task-specialized robots such as autonomous pickers, fruit classifiers, transport bots, and drone mappers operate as agentic units under a central orchestrator. The mapping drones first survey the orchard and use vision-language models (VLMs) to generate high-resolution yield maps and identify ripe clusters. This spatial data is shared via a\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/10000b10cc77b30216dc2d8ed1d92b4c5093f35aa6400d6aa0d49f22d0789a09.jpg)  \n(a)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9893463a60e955fc5db4119a601640c0ad7880c14639133d39a8adcf0a1e9d4e.jpg)  \n(b)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/798430f46937ff657427e53343c8b9abfc124be2ef119fcf0b5e04f6f1aef15d.jpg)  \n(c)  \nFig. 11: Illustrative Applications of Agentic AI Across Domains: Figure 11 presents four real-world applications of agentic AI systems. (a) Automated grant writing using multi-agent orchestration for structured literature analysis, compliance alignment, and document formatting. (b) Coordinated multi-robot harvesting in apple orchards using shared spatial memory and task-specific agents for mapping, picking, and transport. (c) Clinical decision support in hospital ICUs through synchronized agents for diagnostics, treatment planning, and EHR analysis, enhancing safety and workflow efficiency. (d) Cybersecurity incident response in enterprise environments via agents handling threat classification, compliance analysis, and mitigation planning. In all cases, central orchestrators manage inter-agent communication, shared memory enables context retention, and feedback mechanisms drive continual learning. These use cases highlight agentic AI's capacity for scalable, autonomous task coordination in complex, dynamic environments across science, agriculture, healthcare, and IT security.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/aa5eca44e46e61c780f1204260d9af7144e7c67be00f84130cd5b7c4394b30a1.jpg)  \n(d)\n\ncentralized memory layer accessible by all agents. Picker robots are assigned to high-density zones, guided by path-planning agents that optimize routes around obstacles and labor zones. Simultaneously, transport agents dynamically shuttle crates between pickers and storage, adjusting tasks in response to selector load levels and\n\nterrain changes. All agents communicate asynchronously through a shared protocol, and the orchestrator continuously adjusts task priorities based on weather forecasts or mechanical faults. If one picker fails, nearby units autonomously reallocate workload. This adaptive, memory-driven coordination exemplifies Agentic AI's\n\npotential to reduce labor costs, increase harvest efficiency, and respond to uncertainties in complex agricultural environments far surpassing the rigid programming of legacy agricultural robots [89], [143].\n\n3) Collaborative Medical Decision Support: In high-stakes clinical environments, Agentic AI enables distributed medical reasoning by assigning tasks such as diagnostics, vital monitoring, and treatment planning to specialized agents. For example, one agent may retrieve patient history, another validates findings against diagnostic guidelines, and a third proposes treatment options. These agents synchronize through shared memory and reasoning chains, ensuring coherent, safe recommendations. Applications include ICU management, radiology triage, and pandemic response. Real-world pilots show improved efficiency and decision accuracy compared to isolated expert systems [87].\n\nFor example, in a hospital ICU (Figure 11c), an agentic AI system supports clinicians in managing complex patient cases. A diagnostic agent continuously analyzes vitals and lab data for early detection of sepsis risk. Simultaneously, a history retrieval agent accesses electronic health records (EHRs) to summarize comorbidities and recent procedures. A treatment planning agent cross-references current symptoms with clinical guidelines (e.g., Surviving Sepsis Campaign), proposing antibiotic regimens or fluid protocols. The orchestrator integrates these insights, ensures consistency, and surfaces conflicts for human review. Feedback from physicians is stored in a persistent memory module, allowing agents to refine their reasoning based on prior interventions and outcomes. This coordinated system enhances clinical workflow by reducing cognitive load, shortening decision times, and minimizing oversight risks. Early deployments in critical care and oncology units have demonstrated increased diagnostic precision and better adherence to evidence-based protocols, offering a scalable solution for safer, real-time collaborative medical support.\n\n4) Multi-Agent Game AI and Adaptive Workflow Automation: In simulation environments and enterprise systems, Agentic AI facilitates decentralized task execution and emergent coordination. Game platforms like AI Dungeon deploy independent NPC agents with goals, memory, and dynamic interactivity to create emergent narratives and social behavior. In enterprise workflows, systems such as MultiOn and Cognosys use agents to manage processes like legal review or incident escalation, where each step is governed by a specialized module. These architectures exhibit resilience, exception handling, and feedback-driven adaptability far beyond rule-based pipelines.\n\nFor example, in a modern enterprise IT environment (as depicted in Figure 11d), Agentic AI systems are increasingly deployed to autonomously manage cybersecurity incident response workflows. When a potential\n\nthreat is detected such as abnormal access patterns or unauthorized data exfiltration specialized agents are activated in parallel. One agent performs real-time threat classification using historical breach data and anomaly detection models. A second agent queries relevant log data from network nodes and correlates patterns across systems. A third agent interprets compliance frameworks (e.g., GDPR or HIPAA) to assess the regulatory severity of the event. A fourth agent simulates mitigation strategies and forecasts operational risks. These agents coordinate under a central orchestrator that evaluates collective outputs, integrates temporal reasoning, and issues recommended actions to human analysts. Through shared memory structures and iterative feedback, the system learns from prior incidents, enabling faster and more accurate responses in future cases. Compared to traditional rule-based security systems, this agentic model enhances decision latency, reduces false positives, and supports proactive threat containment in large-scale organizational infrastructures [89].\n\n# V. CHALLENGES AND LIMITATIONS IN AI AGENTS AND AGENTIC AI\n\nTo systematically understand the operational and theoretical limitations of current intelligent systems, we present a comparative visual synthesis in Figure 12, which categorizes challenges and potential remedies across both AI Agents and Agentic AI paradigms. Figure 12a outlines the four most pressing limitations specific to AI Agents namely, lack of causal reasoning, inherited LLM constraints (e.g., hallucinations, shallow reasoning), incomplete agentic properties (e.g., autonomy, proactivity), and failures in long-horizon planning and recovery. These challenges often arise due to their reliance on stateless LLM prompts, limited memory, and heuristic reasoning loops.\n\nIn contrast, Figure 12b identifies eight critical bottlenecks unique to Agentic AI systems, such as inter-agent error cascades, coordination breakdowns, emergent instability, scalability limits, and explainability issues. These challenges stem from the complexity of orchestrating multiple agents across distributed tasks without standardized architectures, robust communication protocols, or causal alignment frameworks.\n\nFigure 13 complements this diagnostic framework by synthesizing ten forward-looking design strategies aimed at mitigating these limitations. These include Retrieval-Augmented Generation (RAG), tool-based reasoning [120], [121], [123], agentic feedback loops (ReAct [126]), role-based multi-agent orchestration, memory architectures, causal modeling, and governance-aware design. Together, these three panels offer a consolidated roadmap for addressing current pitfalls and accelerating the development of safe, scalable, and context-aware autonomous systems.\n\n1) Challenges and Limitations of AI Agents: While AI Agents have garnered considerable attention for their ability to automate structured tasks using LLMs and tool-use interfaces, the literature highlights significant theoretical and practical\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/d7b520e156b5904fa072bdba8e484e202d70696410eda29ff1cd9bfc47bcd27c.jpg)  \n(a)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9f89cccb2bc74ebcefaeda8a5ee9653213dd462cba5d14c8d77a8db9964b0797.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/34234edfbfe0fa6744b642854d20782e31511dde77b8bf7352717cb2832e043f.jpg)  \nFig. 12: Challenges and Solutions Across Agentic Paradigms. (a) Key limitations of AI Agents including causality deficits and shallow reasoning. (b) Amplified coordination and stability challenges in Agentic AI systems.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/399c016aec7419c6505d9aaf27d871e72b42d1c293848aa6bdcbfed067dd7b19.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/0f8be28dd9cf116b5dca027ae369e6932ca9eb91f15da6000f8c19a3541e6229.jpg)  \n(b)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/f72e5ad951dd52dba5aada9f7c06f9301d500bb18ca1bfb6e136aa3c1bd40678.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9d38db690b35acd740eaf65229a71e52396b749c00e40d290f7f5daa8ab9f088.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/2b5bc1df0b14cc5ea70f54f27ae7e2d27faf780c05dad374dae8f33aba222b04.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/67477b2e12034e2894a8c07b37fb5b6fa429771300a6c498d58586ae4d6e698e.jpg)\n\nlimitations that inhibit their reliability, generalization, and long-term autonomy [126], [150]. These challenges arise from both the architectural dependence on static, pretrained models and the difficulty of instilling agentic qualities such as causal reasoning, planning, and robust adaptation. The key challenges and limitations (Figure 12a) of AI Agents are as summarized into following five points:\n\n1) Lack of Causal Understanding: One of the most foundational challenges lies in the agents' inability to reason causally [164], [165]. Current LLMs, which form the cognitive core of most AI Agents, excel at identifying statistical correlations within training data. However, as noted in recent research from DeepMind and conceptual analyses by TrueTheta, they fundamentally lack the capacity for causal modeling distinguishing between mere association and cause-effect relationships [166]–[168]. For instance, while an LLM-powered agent might learn that visiting a hospital often co-occurs with illness, it cannot infer whether the illness causes the visit or vice versa, nor can it simulate interventions or hypothetical changes.\n\nThis deficit becomes particularly problematic under distributional shifts, where real-world conditions differ from the training regime [169], [170]. Without such grounding, agents remain brittle, failing in novel or high-stakes scenarios. For example, a navigation agent that excels in urban driving may misbehave in snow or construction zones if it lacks an internal causal model of road traction or spatial occlusion.\n\n2) Inherited Limitations from LLMs: AI Agents, particularly those powered by LLMs, inherit a number of intrinsic limitations that impact their reliability, adaptability, and overall trustworthiness in practical deployments [171]-[173]. One of the most prominent issues is the ten\n\ndency to produce hallucinations plausible but factually incorrect outputs. In high-stakes domains such as legal consultation or scientific research, these hallucinations can lead to severe misjudgments and erode user trust [174], [175]. Compounding this is the well-documented prompt sensitivity of LLMs, where even minor variations in phrasing can lead to divergent behaviors. This brittleness hampers reproducibility, necessitating meticulous manual prompt engineering and often requiring domain-specific tuning to maintain consistency across interactions [176].\n\nFurthermore, while recent agent frameworks adopt reasoning heuristics like Chain-of-Thought (CoT) [151], [177] and ReAct [126] to simulate deliberative processes, these approaches remain shallow in semantic comprehension. Agents may still fail at multi-step inference, misalign task objectives, or make logically inconsistent conclusions despite the appearance of structured reasoning [126]. Such shortcomings underscore the absence of genuine understanding and generalizable planning capabilities.\n\nAnother key limitation lies in computational cost and latency. Each cycle of agentic decision-making particularly in planning or tool-calling may require several LLM invocations. This not only increases runtime latency but also scales resource consumption, creating practical bottlenecks in real-world deployments and cloud-based inference systems. Furthermore, LLMs have a static knowledge cutoff and cannot dynamically integrate new information unless explicitly augmented via retrieval or tool plugins. They also reproduce the biases of their training datasets, which can manifest as culturally insensitive or skewed responses [178], [179]. Without rigorous auditing and mitigation strategies,\n\nTABLE XI: Representative Agentic AI Models (2023-2025): Applications and Operational Characteristics  \n\n<table><tr><td>Model / Reference</td><td>Application Area</td><td>Operation as Agentic AI</td></tr><tr><td>Auto-GPT [30]</td><td>Task Automation</td><td>Decomposes high-level goals, executes subtasks via tools/APIs, and iteratively self-corrects.</td></tr><tr><td>GPT Engineer Open Source (2023) GPT Engineer</td><td>Code Generation</td><td>Builds entire codebases: plans, writes, tests, and re-fines based on output.</td></tr><tr><td>MetaGPT [143])</td><td>Software Collab-oration</td><td>Coordinates specialized agents (e.g., coder, tester) for modular multi-role project development.</td></tr><tr><td>BabyAGI Nakajima (2024) BabyAGI</td><td>Project Manage-ment</td><td>Continuously creates, pri-ortizes, and executes sub-tasks to adaptively meet user goals.</td></tr><tr><td>Voyager Wang et al. (2023) [161]</td><td>Game Exploration</td><td>Learns in Minecraft, in-vents new skills, sets sub-goals, and adapts strategy in real time.</td></tr><tr><td>CAMEL Liu et al. (2023) [162]</td><td>Multi-Agent Simulation</td><td>Simulates agent societies with communication, negotiation, and emergent collaborative behavior.</td></tr><tr><td>Einstein Copilot Salesforce (2024) Einstein Copilot</td><td>Customer Automation</td><td>Automates full support workflows, escalates issues, and improves via feedback loops.</td></tr><tr><td>Copilot Studio (Agentic Mode) Microsoft (2025) Github Agentic Copilot</td><td>Productivity Automata-tion</td><td>Manages documents, meetings, and projects across Microsoft 365 with adaptive orchestration.</td></tr><tr><td>Atera AI Copilot Atera (2025) Atera Agentic AI</td><td>IT Operations</td><td>Diagnoses/resolves IT issues, automates ticketing, and learns from evolving infrastructures.</td></tr><tr><td>AES Safety Audit Agent AES (2025) AES agentic</td><td>Industrial Safety</td><td>Automates audits, assesses compliance, and evolves strategies to enhance safety outcomes.</td></tr><tr><td>DeepMind Gato (Agentic Mode) Reed et al. (2022) [163]</td><td>General Robotics</td><td>Performs varied tasks across modalities, dynamically learns, plans, and executes.</td></tr><tr><td>GPT-4o + Plugins OpenAI (2024) GPT-4O Agentic</td><td>Enterprise Automation</td><td>Manages complex workflows, integrates external tools, and executes adaptive decisions.</td></tr></table>\n\nthese issues pose serious ethical and operational risks, particularly when agents are deployed in sensitive or user-facing contexts.\n\n3) Incomplete Agentic Properties: A major limitation of current AI Agents is their inability to fully satisfy the canonical agentic properties defined in foundational literature, such as autonomy, proactivity, reactivity, and social ability [135], [173]. While many systems marketed as \"agents\" leverage LLMs to perform useful tasks, they often fall short of these fundamental criteria in practice. Autonomy, for instance, is typically partial at best. Although agents can execute tasks with\n\nminimal oversight once initialized, they remain heavily reliant on external scaffolding such as human-defined prompts, planning heuristics, or feedback loops to function effectively [180]. Self-initiated task generation, self-monitoring, or autonomous error correction are rare or absent, limiting their capacity for true independence.\n\nProactivity is similarly underdeveloped. Most AI Agents require explicit user instruction to act and lack the capacity to formulate or reprioritize goals dynamically based on contextual shifts or evolving objectives [181]. As a result, they behave reactively rather than strategically, constrained by the static nature of their initialization. Reactivity itself is constrained by architectural bottlenecks. Agents do respond to environmental or user input, but response latency caused by repeated LLM inference calls [182], [183], coupled with narrow contextual memory windows [153], [184], inhibits real-time adaptability. Perhaps the most underexplored capability is social ability. True agentic systems should communicate and coordinate with humans or other agents over extended interactions, resolving ambiguity, negotiating tasks, and adapting to social norms.\n\nHowever, existing implementations exhibit brittle, template-based dialogue that lacks long-term memory integration or nuanced conversational context. Agent-to-agent interaction is often hardcoded or limited to scripted exchanges, hindering collaborative execution and emergent behavior [96], [185]. Collectively, these deficiencies reveal that while AI Agents demonstrate functional intelligence, they remain far from meeting the formal benchmarks of intelligent, interactive, and adaptive agents. Bridging this gap is essential for advancing toward more autonomous, socially capable AI systems.\n\n4) Limited Long-Horizon Planning and Recovery: A persistent limitation of current AI Agents lies in their inability to perform robust long-horizon planning, especially in complex, multi-stage tasks. This constraint stems from their foundational reliance on stateless prompt-response paradigms, where each decision is made without an intrinsic memory of prior reasoning steps unless externally managed. Although augmentations such as the ReAct framework [126] or Tree-of-Thoughts [152] introduce pseudo-recursive reasoning, they remain fundamentally heuristic and lack true internal models of time, causality, or state evolution. Consequently, agents often falter in tasks requiring extended temporal consistency or contingency planning. For example, in domains such as clinical triage or financial portfolio management, where decisions depend on prior context and dynamically unfolding outcomes, agents may exhibit repetitive behaviors such as endlessly querying tools or fail to adapt when sub-tasks fail or return ambiguous results. The absence of systematic recovery mechanisms or error detection leads to brittle workflows and error propagation. This shortfall severely limits agent deployment in mission-critical environments\n\nwhere reliability, fault tolerance, and sequential coherence are essential.\n\n5) Reliability and Safety Concerns: AI Agents are not yet safe or verifiable enough for deployment in critical infrastructure [186]. The absence of causal reasoning leads to unpredictable behavior under distributional shift [165], [187]. Furthermore, evaluating the correctness of an agent's plan especially when the agent fabricates intermediate steps or rationales remains an unsolved problem in interpretability [104], [188]. Safety guarantees, such as formal verification, are not yet available for open-ended, LLM-powered agents. While AI Agents represent a major step beyond static generative models, their limitations in causal reasoning, adaptability, robustness, and planning restrict their deployment in high-stakes or dynamic environments. Most current systems rely on heuristic wrappers and brittle prompt engineering rather than grounded agentic cognition. Bridging this gap will require future systems to integrate causal models, dynamic memory, and verifiable reasoning mechanisms. These limitations also set the stage for the emergence of Agentic AI systems, which attempt to address these bottlenecks through multi-agent collaboration, orchestration layers, and persistent system-level context.\n\n2) Challenges and Limitations of Agentic AI: Agentic AI systems represent a paradigm shift from isolated AI agents to collaborative, multi-agent ecosystems capable of decomposing and executing complex goals [14]. These systems typically consist of orchestrated or communicating agents that interact via tools, APIs, and shared environments [18], [38]. While this architectural evolution enables more ambitious automation, it introduces a range of amplified and novel challenges that compound existing limitations of individual LLM-based agents. The current challenges and limitations of Agentic AI are as follows:\n\n1) Amplified Causality Challenges: One of the most critical limitations in Agentic AI systems is the magnification of causality deficits already observed in single-agent architectures. Unlike traditional AI Agents that operate in relatively isolated environments, Agentic AI systems involve complex inter-agent dynamics, where each agent's action can influence the decision space of others. Without a robust capacity for modeling cause-effect relationships, these systems struggle to coordinate effectively and adapt to unforeseen environmental shifts. A key manifestation of this challenge is inter-agent distributional shift, where the behavior of one agent alters the operational context for others. In the absence of causal reasoning, agents are unable to anticipate the downstream impact of their outputs, resulting in coordination breakdowns or redundant computations [189]. Furthermore, these systems are particularly vulnerable to error cascades: a faulty or hallucinated output from one agent can propagate through the system, compounding\n\ninaccuracies and corrupting subsequent decisions. For example, if a verification agent erroneously validates false information, downstream agents such as summarizers or decision-makers may unknowingly build upon that misinformation, compromising the integrity of the entire system. This fragility underscores the urgent need for integrating causal inference and intervention modeling into the design of multi-agent workflows, especially in high-stakes or dynamic environments where systemic robustness is essential.\n\n2) Communication and Coordination Bottlenecks: A fundamental challenge in Agentic AI lies in achieving efficient communication and coordination across multiple autonomous agents. Unlike single-agent systems, Agentic AI involves distributed agents that must collectively pursue a shared objective necessitating precise alignment, synchronized execution, and robust communication protocols. However, current implementations fall short in these aspects. One major issue is goal alignment and shared context, where agents often lack a unified semantic understanding of overarching objectives. This hampers sub-task decomposition, dependency management, and progress monitoring, especially in dynamic environments requiring causal awareness and temporal coherence.\n\nIn addition, protocol limitations significantly hinder inter-agent communication. Most systems rely on natural language exchanges over loosely defined interfaces, which are prone to ambiguity, inconsistent formatting, and contextual drift. These communication gaps lead to fragmented strategies, delayed coordination, and degraded system performance. Furthermore, resource contention emerges as a systemic bottleneck when agents simultaneously access shared computational, memory, or API resources. Without centralized orchestration or intelligent scheduling mechanisms, these conflicts can result in race conditions, execution delays, or outright system failures. Collectively, these bottlenecks illustrate the immaturity of current coordination frameworks in Agentic AI, and highlight the pressing need for standardized communication protocols, semantic task planners, and global resource managers to ensure scalable, coherent multi-agent collaboration.\n\n3) Emergent Behavior and Predictability: One of the most critical limitations of Agentic AI lies in managing emergent behavior complex system-level phenomena that arise from the interactions of autonomous agents. While such emergence can potentially yield adaptive and innovative solutions, it also introduces significant unpredictability and safety risks [145], [190]. A key concern is the generation of unintended outcomes, where agent interactions result in behaviors that were not explicitly programmed or foreseen by system designers. These behaviors may diverge from task objectives, generate misleading outputs, or even enact harmful actions particularly in high-stakes domains like healthcare, finance,\n\nor critical infrastructure.\n\nAs the number of agents and the complexity of their interactions grow, so too does the likelihood of system instability. This includes phenomena such as infinite planning loops, action deadlocks, and contradictory behaviors emerging from asynchronous or misaligned agent decisions. Without centralized arbitration mechanisms, conflict resolution protocols, or fallback strategies, these instabilities compound over time, making the system fragile and unreliable. The stochasticity and opacity of large language model-based agents further exacerbate this issue, as their internal decision logic is not easily interpretable or verifiable. Consequently, ensuring the predictability and controllability of emergent behavior remains a central challenge in designing safe and scalable Agentic AI systems.\n\n4) Scalability and Debugging Complexity: As Agentic AI systems scale in both the number of agents and the diversity of specialized roles, maintaining system reliability and interpretability becomes increasingly complex [191], [192]. A central limitation stems from the black-box chains of reasoning characteristic of LLM-based agents. Each agent may process inputs through opaque internal logic, invoke external tools, and communicate with other agents all of which occur through multiple layers of prompt engineering, reasoning heuristics, and dynamic context handling. Tracing the root cause of a failure thus requires unwinding nested sequences of agent interactions, tool invocations, and memory updates, making debugging non-trivial and time-consuming.\n\nAnother significant constraint is the system's non-compositionality. Unlike traditional modular systems, where adding components can enhance overall functionality, introducing additional agents in an Agentic AI architecture often increases cognitive load, noise, and coordination overhead. Poorly orchestrated agent networks can result in redundant computation, contradictory decisions, or degraded task performance. Without robust frameworks for agent role definition, communication standards, and hierarchical planning, the scalability of Agentic AI does not necessarily translate into greater intelligence or robustness. These limitations highlight the need for systematic architectural controls and traceability tools to support the development of reliable, large-scale agentic ecosystems.\n\n5) Trust, Explainability, and Verification: Agentic AI systems pose heightened challenges in explainability and verifiability due to their distributed, multi-agent architecture. While interpreting the behavior of a single LLM-powered agent is already non-trivial, this complexity is multiplied when multiple agents interact asynchronously through loosely defined communication protocols. Each agent may possess its own memory, task objective, and reasoning path, resulting in compounded opacity where tracing the causal chain of a final decision or failure\n\nbecomes exceedingly difficult. The lack of shared, transparent logs or interpretable reasoning paths across agents makes it nearly impossible to determine why a particular sequence of actions occurred or which agent initiated a misstep.\n\nCompounding this opacity is the absence of formal verification tools tailored for Agentic AI. Unlike traditional software systems, where model checking and formal proofs offer bounded guarantees, there exists no widely adopted methodology to verify that a multiagent LLM system will perform reliably across all input distributions or operational contexts. This lack of verifiability presents a significant barrier to adoption in safety-critical domains such as autonomous vehicles, finance, and healthcare, where explainability and assurance are non-negotiable. To advance Agentic AI safely, future research must address the foundational gaps in causal traceability, agent accountability, and formal safety guarantees.\n\n6) Security and Adversarial Risks: Agentic AI architectures introduce a significantly expanded attack surface compared to single-agent systems, exposing them to complex adversarial threats. One of the most critical vulnerabilities lies in the presence of a single point of compromise. Since Agentic AI systems are composed of interdependent agents communicating over shared memory or messaging protocols, the compromise of even one agent through prompt injection, model poisoning, or adversarial tool manipulation can propagate malicious outputs or corrupted state across the entire system. For example, a fact-checking agent fed with tampered data could unintentionally legitimize false claims, which are then integrated into downstream reasoning by summarization or decision-making agents.\n\nMoreover, inter-agent dynamics themselves are susceptible to exploitation. Attackers can induce race conditions, deadlocks, or resource exhaustion by manipulating the coordination logic between agents. Without rigorous authentication, access control, and sandboxing mechanisms, malicious agents or corrupted tool responses can derail multi-agent workflows or cause erroneous escalation in task pipelines. These risks are exacerbated by the absence of standardized security frameworks for LLM-based multi-agent systems, leaving most current implementations defenseless against sophisticated multistage attacks. As Agentic AI moves toward broader adoption, especially in high-stakes environments, embedding secure-by-design principles and adversarial robustness becomes an urgent research imperative.\n\n7) Ethical and Governance Challenges: The distributed and autonomous nature of Agentic AI systems introduces profound ethical and governance concerns, particularly in terms of accountability, fairness, and value alignment. In multi-agent settings, accountability gaps emerge when multiple agents interact to produce an outcome, making it difficult to assign responsibility\n\nfor errors or unintended consequences. This ambiguity complicates legal liability, regulatory compliance, and user trust, especially in domains such as healthcare, finance, or defense. Furthermore, bias propagation and amplification present a unique challenge: agents individually trained on biased data may reinforce each other's skewed decisions through interaction, leading to systemic inequities that are more pronounced than in isolated models. These emergent biases can be subtle and difficult to detect without longitudinal monitoring or audit mechanisms.\n\nAdditionally, misalignment and value drift pose serious risks in long-horizon or dynamic environments. Without a unified framework for shared value encoding, individual agents may interpret overarching objectives differently or optimize for local goals that diverge from human intent. Over time, this misalignment can lead to behavior that is inconsistent with ethical norms or user expectations. Current alignment methods, which are mostly designed for single-agent systems, are inadequate for managing value synchronization across heterogeneous agent collectives. These challenges highlight the urgent need for governance-aware agent architectures, incorporating principles such as role-based isolation, traceable decision logging, and participatory oversight mechanisms to ensure ethical integrity in autonomous multi-agent systems.\n\n8) Immature Foundations and Research Gaps: Despite rapid progress and high-profile demonstrations, Agentic AI remains in a nascent research stage with unresolved foundational issues that limit its scalability, reliability, and theoretical grounding. A central concern is the lack of standard architectures. There is currently no widely accepted blueprint for how to design, monitor, or evaluate multi-agent systems built on LLMs. This architectural fragmentation makes it difficult to compare implementations, replicate experiments, or generalize findings across domains. Key aspects such as agent orchestration, memory structures, and communication protocols are often implemented ad hoc, resulting in brittle systems that lack interoperability and formal guarantees.\n\nEqually critical is the absence of causal foundations as scalable causal discovery and reasoning remain unsolved challenges [193]. Without the ability to represent and reason about cause-effect relationships, Agentic AI systems are inherently limited in their capacity to generalize safely beyond narrow training regimes [170], [194]. This shortfall affects their robustness under distributional shifts, their capacity for proactive intervention, and their ability to simulate counterfactuals or hypothetical plans core requirements for intelligent coordination and decision-making.\n\nThe gap between functional demos and principled design thus underscores an urgent need for foundational research in multi-agent system theory, causal infer\n\nence integration, and benchmark development. Only by addressing these deficiencies can the field progress from prototype pipelines to trustworthy, general-purpose agentic frameworks suitable for deployment in high-stakes environments.\n\n# VI. POTENTIAL SOLUTIONS AND FUTURE ROADMAP\n\nThe potential solutions (as illustrated in Figure 13) to these challenges and limitations of AI agents and Agentic AI are summarized in the following points:\n\n1) Retrieval-Augmented Generation (RAG): For AI Agents, Retrieval-Augmented Generation mitigates hallucinations and expands static LLM knowledge by grounding outputs in real-time data [195]. By embedding user queries and retrieving semantically relevant documents from vector databases like FAISS Faiss or Pinecone Pinecone, agents can generate contextually valid responses rooted in external facts. This is particularly effective in domains such as enterprise search and customer support, where accuracy and up-to-date knowledge are essential.\n\nIn Agentic AI systems, RAG serves as a shared grounding mechanism across agents. For example, a summarizer agent may rely on the retriever agent to access the latest scientific papers before generating a synthesis. Persistent, queryable memory allows distributed agents to operate on a unified semantic layer, mitigating inconsistencies due to divergent contextual views. When implemented across a multi-agent system, RAG helps maintain shared truth, enhances goal alignment, and reduces inter-agent misinformation propagation.\n\n2) Tool-Augmented Reasoning (Function Calling): AI Agents benefit significantly from function calling, which extends their ability to interact with real-world systems [159], [196]. Agents can query APIs, run local scripts, or access structured databases, thus transforming LLMs from static predictors into interactive problem-solvers [125], [154]. This allows them to dynamically retrieve weather forecasts, schedule appointments, or execute Python-based calculations, all beyond the capabilities of pure language modeling.\n\nFor Agentic AI, function calling supports agent level autonomy and role differentiation. Agents within a team may use APIs to invoke domain-specific actions such as querying clinical databases or generating visual charts based on assigned roles. Function calls become part of an orchestrated pipeline, enabling fluid delegation across agents [197]. This structured interaction reduces ambiguity in task handoff and fosters clearer behavioral boundaries, especially when integrated with validation protocols or observation mechanisms [14], [18].\n\n3) Agentic Loop: Reasoning, Action, Observation: AI Agents often suffer from single-pass inference limitations. The ReAct pattern introduces an iterative loop where agents reason about tasks, act by calling tools or APIs, and then observe results before continuing.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/58d7f580cead0834f8a42b572b1c436a5ca82924b8e64412de53f73add0950bb.jpg)  \nFig. 13: Ten emerging architectural and algorithmic solutions such as RAG, tool use, memory, orchestration, and reflexive mechanisms addressing reliability, scalability, and explainability across both paradigms\n\nThis feedback loop allows for more deliberate, context-sensitive behaviors. For example, an agent may verify retrieved data before drafting a summary, thereby reducing hallucination and logical errors. In Agentic AI, this pattern is critical for collaborative coherence. ReAct enables agents to evaluate dependencies dynamically reasoning over intermediate states, re-invoking tools if needed, and adjusting decisions as the environment evolves. This loop becomes more complex in multiagent settings where each agent's observation must be reconciled against others' outputs. Shared memory and consistent logging are essential here, ensuring that the reflective capacity of the system is not fragmented across agents [126].\n\n4) Memory Architectures (Episodic, Semantic, Vector): AI Agents face limitations in long-horizon planning and session continuity. Memory architectures address this by persisting information across tasks [198]. Episodic memory allows agents to recall prior actions and feedback, semantic memory encodes structured domain knowledge, and vector memory enables similarity-based retrieval [199]. These elements are key for personalization and adaptive decision-making in repeated interactions. Agentic AI systems require even more sophisticated memory models due to distributed state management. Each agent may maintain local memory while accessing shared global memory to facilitate coordination. For example, a planner agent might use vector-based memory to recall prior workflows, while a QA agent references semantic memory for fact verification. Synchronizing memory access and updates across agents enhances consistency, enables context-aware communication, and supports long-horizon system-level planning.\n\n5) Multi-Agent Orchestration with Role Specialization: In AI Agents, task complexity is often handled via modular prompt templates or conditional logic. However, as task diversity increases, a single agent may become overloaded [200], [201]. Role specialization splitting tasks into subcomponents (e.g., planner, summarizer) allows lightweight orchestration even within single-agent systems by simulating compartmentalized reasoning. In Agentic AI, orchestration is central. A meta-agent or orchestrator distributes tasks among specialized agents, each with distinct capabilities. Systems like MetaGPT and ChatDev exemplify this: agents emulate roles such as CEO, engineer, or reviewer, and interact through structured messaging. This modular approach enhances interpretability, scalability, and fault isolation ensuring that failures in one agent do not cascade without containment mechanisms from the orchestrator.\n\n6) Reflexive and Self-Critique Mechanisms: AI Agents often fail silently or propagate errors. Reflexive mechanisms introduce the capacity for self-evaluation [202], [203]. After completing a task, agents can critique their own outputs using a secondary reasoning pass, increasing robustness and reducing error rates. For example, a legal assistant agent might verify that its drafted clause matches prior case laws before submission. For Agentic AI, reflexivity extends beyond self-critique to inter-agent evaluation. Agents can review each other's outputs e.g., a verifier agent auditing a summarizer's work. Reflexion-like mechanisms ensure collaborative quality control and enhance trustworthiness [204]. Such patterns also support iterative improvement and adaptive replanning, particularly when integrated with memory logs or feedback queues [205], [206].\n\n7) Programmatic Prompt Engineering Pipelines: Manual prompt tuning introduces brittleness and reduces reproducibility in AI Agents. Programmatic pipelines automate this process using task templates, context fillers, and retrieval-augmented variables [207], [208]. These dynamic prompts are structured based on task type, agent role, or user query, improving generalization and reducing failure modes associated with prompt variability. In Agentic AI, prompt pipelines enable scalable, role-consistent communication. Each agent type (e.g., planner, retriever, summarizer) can generate or consume structured prompts tailored to its function. By automating message formatting, dependency tracking, and semantic alignment, programmatic prompting prevents coordination drift and ensures consistent reasoning across diverse agents in real time [14], [159].\n\n8) Causal Modeling and Simulation-Based Planning: AI Agents often operate on statistical correlations rather than causal models, leading to poor generalization under distribution shifts. Embedding causal inference allows agents to distinguish between correlation and causation, simulate interventions, and plan more robustly. For instance, in supply chain scenarios, a causally aware agent can simulate the downstream impact of shipment delays. In Agentic AI, causal reasoning is vital for safe coordination and error recovery. Agents must anticipate how their actions impact others requiring causal graphs, simulation environments, or Bayesian inference layers. For example, a planning agent may simulate different strategies and communicate likely outcomes to others, fostering strategic alignment and avoiding unintended emergent behaviors.\n\n9) Monitoring, Auditing, and Explainability Pipelines: AI Agents lack transparency, complicating debugging and trust. Logging systems that record prompts, tool calls, memory updates, and outputs enable post-hoc analysis and performance tuning. These records help developers trace faults, refine behavior, and ensure compliance with usage guidelines especially critical in enterprise or legal domains. For Agentic AI, logging and explainability are exponentially more important. With multiple agents interacting asynchronously, audit trails are essential for identifying which agent caused an error and under what conditions. Explainability pipelines that integrate across agents (e.g., timeline visualizations or dialogue replays) are key to ensuring safety, especially in regulatory or multi-stakeholder environments.\n\n10) Governance-Aware Architectures (Accountability and Role Isolation): AI Agents currently lack built-in safeguards for ethical compliance or error attribution. Governance-aware designs introduce role-based access control, sandboxing, and identity resolution to ensure agents act within scope and their decisions can be audited or revoked. These structures reduce risks in sensitive applications such as healthcare or finance. In Agentic AI, governance must scale across roles,\n\nagents, and workflows. Role isolation prevents rogue agents from exceeding authority, while accountability mechanisms assign responsibility for decisions and trace causality across agents. Compliance protocols, ethical alignment checks, and agent authentication ensure safety in collaborative settings paving the way for trustworthy AI ecosystems.\n\nAI Agents are projected to evolve significantly through enhanced modular intelligence focused on five key domains as depicted in Figure 14 as: proactive reasoning, tool integration, causal inference, continual learning, and trust-centric operations. The first transformative milestone involves transitioning from reactive to Proactive Intelligence, where agents initiate tasks based on learned patterns, contextual cues, or latent goals rather than awaiting explicit prompts. This advancement depends heavily on robust Tool Integration, enabling agents to dynamically interact with external systems, such as databases, APIs, or simulation environments, to fulfill complex user tasks. Equally critical is the development of Causal Reasoning, which will allow agents to move beyond statistical correlation, supporting inference of cause-effect relationships essential for tasks involving diagnosis, planning, or prediction. To maintain relevance over time, agents must adopt frameworks for Continuous Learning, incorporating feedback loops and episodic memory to adapt their behavior across sessions and environments. Lastly, to build user confidence, agents must prioritize Trust & Safety mechanisms through verifiable output logging, bias detection, and ethical guardrails especially as their autonomy increases. Together, these pathways will redefine AI Agents from static tools into adaptive cognitive systems capable of autonomous yet controllable operation in dynamic digital environments.\n\nAgentic AI, as a natural extension of these foundations, emphasizes collaborative intelligence through multi-agent coordination, contextual persistence, and domain-specific orchestration. Future systems (Figure 14 right side) will exhibit Multi-Agent Scaling, enabling specialized agents to work in parallel under distributed control for complex problem-solving mirroring team-based human workflows. This necessitates a layer of Unified Orchestration, where meta-agents or orchestrators dynamically assign roles, monitor task dependencies, and mediate conflicts among subordinate agents. Sustained performance over time depends on Persistent Memory architectures, which preserve semantic, episodic, and shared knowledge for agents to coordinate longitudinal tasks and retain state awareness. Simulation Planning is expected to become a core feature, allowing agent collectives to test hypothetical strategies, forecast consequences, and optimize outcomes before real-world execution. Moreover, Ethical Governance frameworks will be essential to ensure responsible deployment defining accountability, oversight, and value alignment across autonomous agent networks. Finally, tailored Domain-Specific Systems will emerge in fields like law, medicine, and supply chains, leveraging contextual specialization to outperform generic agents. This future positions Agentic AI not merely\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9a523150fc969434f3864d2f1517cc5a8ae8008eb543a5d62d26c7a165f33a8b.jpg)  \nFig. 14: Mindmap visualization of the future roadmap for AI Agents and Agentic AI.\n\nas a coordination layer on the top of AI Agents, but as a new paradigm for collective machine intelligence with adaptive planning, recursive reasoning, and collaborative cognition at its core.\n\n# VII. CONCLUSION\n\nIn this study, we presented a comprehensive literature-based evaluation of the evolving landscape of AI Agents and Agentic AI, offering a structured taxonomy that highlights foundational concepts, architectural evolution, application domains, and key limitations. Beginning with a foundational understanding, we characterized AI Agents as modular, task-specific entities with constrained autonomy and reactivity. Their operational scope is grounded in the integration of LLMs and LIMs, which serve as core reasoning modules for perception, language understanding, and decision-making. We identified generative AI as a functional precursor, emphasizing its limitations in autonomy and goal persistence, and examined how LLMs drive the progression from passive generation to interactive task completion through tool augmentation.\n\nThis study then explored the conceptual emergence of Agentic AI systems as a transformative evolution from isolated agents to orchestrated, multi-agent ecosystems. We analyzed key differentiators such as distributed cognition, persistent memory, and coordinated planning that distinguish Agentic AI from conventional agent models. This was followed by a detailed breakdown of architectural evolution, highlighting the transition from monolithic, rule-based frameworks to\n\nmodular, role specialized networks facilitated by orchestration layers and reflective memory architectures. Additionally, this study then surveyed application domains in which these paradigms are deployed. For AI Agents, we illustrated their role in automating customer support, internal enterprise search, email prioritization, and scheduling. For Agentic AI, we demonstrated use cases in collaborative research, robotics, medical decision support, and adaptive workflow automation, supported by practical examples and industry-grade systems. Finally, this study provided a deep analysis of the challenges and limitations affecting both paradigms. For AI Agents, we discussed hallucinations, shallow reasoning, and planning constraints, while for Agentic AI, we addressed amplified causality issues, coordination bottlenecks, emergent behavior, and governance concerns. These insights offer a roadmap for future development and deployment of trustworthy, scalable agentic systems.\n\n# ACKNOWLEDGEMENT\n\nThis work was supported by the National Science Foundation and the United States Department of Agriculture, National Institute of Food and Agriculture through the \"Artificial Intelligence (AI) Institute for Agriculture\" Program under Award AWD003473, and AWD004595, Accession Number 1029004, \"Robotic Blossom Thinning with Soft Manipulators\".\n\n# DECLARATIONS\n\nThe authors declare no conflicts of interest.\n\n# STATEMENT ON AI WRITING ASSISTANCE\n\nChatGPT and Perplexity were utilized to enhance grammatical accuracy and refine sentence structure; all AI-generated revisions were thoroughly reviewed and edited for relevance. Additionally, ChatGPT-4o was employed to generate realistic visualizations.\n\n# REFERENCES\n\n[1] E. Oliveira, K. Fischer, and O. Stepankova, “Multi-agent systems: which research for which applications,” Robotics and Autonomous Systems, vol. 27, no. 1-2, pp. 91–106, 1999.  \n[2] Z. Ren and C. J. Anumba, \"Multi-agent systems in construction-state of the art and prospects,\" Automation in Construction, vol. 13, no. 3, pp. 421-434, 2004.  \n[3] C. Castelfranchi, “Modelling social action for ai agents,” Artificial intelligence, vol. 103, no. 1-2, pp. 157-182, 1998.  \n[4] J. Ferber and G. Weiss, Multi-agent systems: an introduction to distributed artificial intelligence, vol. 1. Addison-wesley Reading, 1999.  \n[5] R. Calegari, G. Ciatto, V. Mascardi, and A. Omicini, \"Logic-based technologies for multi-agent systems: a systematic literature review,\" Autonomous Agents and Multi-Agent Systems, vol. 35, no. 1, p. 1, 2021.  \n[6] R. C. Cardoso and A. Ferrando, “A review of agent-based programming for multi-agent systems,” Computers, vol. 10, no. 2, p. 16, 2021.  \n[7] E. Shortliffe, Computer-based medical consultations: MYCIN, vol. 2. Elsevier, 2012.  \n[8] H. P. Moravec, “The stanford cart and the cmu rover,” Proceedings of the IEEE, vol. 71, no. 7, pp. 872-884, 1983.  \n[9] B. Dai and H. Chen, \"A multi-agent and auction-based framework and approach for carrier collaboration,\" Logistics Research, vol. 3, pp. 101-120, 2011.  \n[10] J. Grosset, A.-J. Fougères, M. Djoko-Kouam, and J.-M. Bonnin, \"Multi-agent simulation of autonomous industrial vehicle fleets: Towards dynamic task allocation in v2x cooperation mode,\" *Integrated Computer-Aided Engineering*, vol. 31, no. 3, pp. 249-266, 2024.  \n[11] R. A. Agis, S. Gottifredi, and A. J. Garcia, \"An event-driven behavior trees extension to facilitate non-player multi-agent coordination in video games,\" Expert Systems with Applications, vol. 155, p. 113457, 2020.  \n[12] A. Guerra-Hernández, A. El Fallah-Seghrouchni, and H. Soldano, \"Learning in bdi multi-agent systems,\" in International Workshop on Computational Logic in Multi-Agent Systems, pp. 218-233, Springer, 2004.  \n[13] A. Saadi, R. Maamri, and Z. Sahnoun, \"Behavioral flexibility in belief-desire-intention (bdi) architectures,\" Multiagent and grid systems, vol. 16, no. 4, pp. 343-377, 2020.  \n[14] D. B. Acharya, K. Kuppan, and B. Divya, \"Agentic ai: Autonomous intelligence for complex goals-a comprehensive survey,\" IEEE Access, 2025.  \n[15] M. Z. Pan, M. Cemri, L. A. Agrawal, S. Yang, B. Chopra, R. Tiwari, K. Keutzer, A. Parameswaran, K. Ramchandran, D. Klein, et al., \"Why do multiagent systems fail?\", in ICLR 2025 Workshop on Building Trust in Language Models and Applications, 2025.  \n[16] L. Hughes, Y. K. Dwivedi, T. Malik, M. Shawosh, M. A. Albashrawi, I. Jeon, V. Dutot, M. Appanderanda, T. Crick, R. De', et al., \"Ai agents and agentic systems: A multi-expert analysis,\" Journal of Computer Information Systems, pp. 1-29, 2025.  \n[17] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, and Y. Xiang, \"Ai agents under threat: A survey of key security challenges and future pathways,\" ACM Computing Surveys, vol. 57, no. 7, pp. 1-36, 2025.  \n[18] M. Gridach, J. Nanavati, K. Z. E. Abidine, L. Mendes, and C. Mack, \"Agentic ai for scientific discovery: A survey of progress, challenges, and future directions,\" arXiv preprint arXiv:2503.08979, 2025.  \n[19] T. Song, M. Luo, X. Zhang, L. Chen, Y. Huang, J. Cao, Q. Zhu, D. Liu, B. Zhang, G. Zou, et al., \"A multiagent-driven robotic ai chemist enabling autonomous chemical research on demand,\" Journal of the American Chemical Society, vol. 147, no. 15, pp. 12534-12545, 2025.  \n[20] M. M. Karim, D. H. Van, S. Khan, Q. Qu, and Y. Kholodov, \"Ai agents meet blockchain: A survey on secure and scalable collaboration for multi-agents,\" Future Internet, vol. 17, no. 2, p. 57, 2025.\n\n[21] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al., \"Improving language understanding by generative pre-training,\" arxiv, 2018.  \n[22] J. Sánchez Cuadrado, S. Pérez-Soler, E. Guerra, and J. De Lara, \"Automating the development of task-oriented llm-based chatbots,\" in Proceedings of the 6th ACM Conference on Conversational User Interfaces, pp. 1-10, 2024.  \n[23] Y. Lu, A. Aleta, C. Du, L. Shi, and Y. Moreno, \"Llms and generative agent-based models for complex systems research,\" Physics of Life Reviews, 2024.  \n[24] A. Zhang, Y. Chen, L. Sheng, X. Wang, and T.-S. Chua, \"On generative agents in recommendation,\" in Proceedings of the 47th international ACM SIGIR conference on research and development in Information Retrieval, pp. 1807-1817, 2024.  \n[25] S. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer, “The impact of ai on developer productivity: Evidence from github copilot,” arXiv preprint arXiv:2302.06590, 2023.  \n[26] J. Li, V. Lavrukhin, B. Ginsburg, R. Leary, O. Kuchaiev, J. M. Cohen, H. Nguyen, and R. T. Gadde, \"Jasper: An end-to-end convolutional neural acoustic model,\" arXiv preprint arXiv:1904.03288, 2019.  \n[27] A. Jaruga-Rozdolska, \"Artificial intelligence as part of future practices in the architect's work: Midjourney generative tool as part of a process of creating an architectural form,\" Architectus, no. 3 (71, pp. 95-104, 2022.  \n[28] K. Basu, “Bridging knowledge gaps in llms via function calls,” in Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pp. 5556–5557, 2024.  \n[29] Z. Liu, T. Hoang, J. Zhang, M. Zhu, T. Lan, J. Tan, W. Yao, Z. Liu, Y. Feng, R. RN, et al., \"Apigen: Automated pipeline for generating verifiable and diverse function-calling datasets,\" Advances in Neural Information Processing Systems, vol. 37, pp. 54463-54482, 2024.  \n[30] H. Yang, S. Yue, and Y. He, \"Auto-gpt for online decision making: Benchmarks and additional opinions,\" arXiv preprint arXiv:2306.02224, 2023.  \n[31] I. Hettiarachchi, “Exploring generative ai agents: Architecture, applications, and challenges,” Journal of Artificial Intelligence General science (JAIGS) ISSN: 3006-4023, vol. 8, no. 1, pp. 105–127, 2025.  \n[32] A. Das, S.-C. Chen, M.-L. Shyu, and S. Sadiq, \"Enabling synergistic knowledge sharing and reasoning in large language models with collaborative multi-agents,\" in 2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC), pp. 92-98, IEEE, 2023.  \n[33] Z. Duan and J. Wang, \"Exploration of lmm multi-agent application implementation based on langgraph+ crewai,\" arXiv preprint arXiv:2411.18241, 2024.  \n[34] R. Sapkota, Y. Cao, K. I. Roumeliotis, and M. Karkee, “Vision-language-action models: Concepts, progress, applications and challenges,” arXiv preprint arXiv:2505.04769, 2025.  \n[35] R. Sapkota, K. I. Roumeliotis, R. H. Cheppally, M. F. Calero, and M. Karkee, “A review of 3d object detection with vision-language models,” arXiv preprint arXiv:2504.18738, 2025.  \n[36] R. Sapkota and M. Karkee, \"Object detection with multimodal large vision-language models: An in-depth review,\" Available at SSRN 5233953, 2025.  \n[37] B. Memarian and T. Doleck, “Human-in-the-loop in artificial intelligence in education: A review and entity-relationship (er) analysis,” Computers in Human Behavior: Artificial Humans, vol. 2, no. 1, p. 100053, 2024.  \n[38] P. Bornet, J. Wirtz, T. H. Davenport, D. De Cremer, B. Evergreen, P. Fersht, R. Gohel, S. Khiyara, P. Sund, and N. Mullakara, Agentic Artificial Intelligence: Harnessing AI Agents to Reinvent Business, Work and Life. Irreplaceable Publishing, 2025.  \n[39] F. Sado, C. K. Loo, W. S. Liew, M. Kerzel, and S. Wermter, \"Explainable goal-driven agents and robots-a comprehensive review,\" ACM Computing Surveys, vol. 55, no. 10, pp. 1-41, 2023.  \n[40] J. Heer, \"Agency plus automation: Designing artificial intelligence into interactive systems,\" Proceedings of the National Academy of Sciences, vol. 116, no. 6, pp. 1844-1850, 2019.  \n[41] G. Papagni, J. de Pagter, S. Zafari, M. Filzmoser, and S. T. Koeszegi, \"Artificial agents' explainability to support trust: considerations on timing and context,\" Ai & Society, vol. 38, no. 2, pp. 947-960, 2023.  \n[42] P. Wang and H. Ding, “The rationality of explanation or human capacity? understanding the impact of explainable artificial intelligence on human-ai trust and decision performance,” Information Processing & Management, vol. 61, no. 4, p. 103732, 2024.\n\n[43] E. Popa, “Human goals are constitutive of agency in artificial intelligence (ai),” Philosophy & Technology, vol. 34, no. 4, pp. 1731–1750, 2021.  \n[44] M. Chacon-Chamorro, L. F. Giraldo, N. Quijano, V. Vargas-Panesso, C. González, J. S. Pinzón, R. Manrique, M. Ríos, Y. Fonseca, D. Gómez-Barrera, et al., \"Cooperative resilience in artificial intelligence multiagent systems,\" IEEE Transactions on Artificial Intelligence, 2025.  \n[45] M. Adam, M. Wessel, and A. Benlian, “Ai-based chatbots in customer service and their effects on user compliance,” *Electronic Markets*, vol. 31, no. 2, pp. 427–445, 2021.  \n[46] D. Leocádio, L. Guedes, J. Oliveira, J. Reis, and N. Melão, \"Customer service with ai-powered human-robot collaboration (hrc): A literature review,\" Procedia Computer Science, vol. 232, pp. 1222–1232, 2024.  \n[47] T. Cao, Y. Q. Khoo, S. Birajdar, Z. Gong, C.-F. Chung, Y. Moghaddam, A. Xu, H. Mehta, A. Shukla, Z. Wang, et al., “Designing towards productivity: A centralized ai assistant concept for work,” The Human Side of Service Engineering, p. 118, 2024.  \n[48] Y. Huang and J. X. Huang, “Exploring chatgpt for next-generation information retrieval: Opportunities and challenges,” in Web Intelligence, vol. 22, pp. 31–44, SAGE Publications Sage UK: London, England, 2024.  \n[49] N. Holtz, S. Wittfoth, and J. M. Gómez, \"The new era of knowledge retrieval: Multi-agent systems meet generative ai,\" in 2024 Portland International Conference on Management of Engineering and Technology (PICMET), pp. 1-10, IEEE, 2024.  \n[50] F. Poszler and B. Lange, “The impact of intelligent decision-support systems on humans’ ethical decision-making: A systematic literature review and an integrated framework,” Technological Forecasting and Social Change, vol. 204, p. 123403, 2024.  \n[51] F. Khemakhem, H. Ellouzi, H. LtiFi, and M. B. Ayed, \"Agent-based intelligent decision support systems: a systematic review,\" IEEE Transactions on Cognitive and Developmental Systems, vol. 14, no. 1, pp. 20-34, 2020.  \n[52] R. V. Florian, \"Autonomous artificial intelligent agents,\" Center for Cognitive and Neural Studies (Coneural), Cluj-Napoca, Romania, 2003.  \n[53] T. Hellström, N. Kaiser, and S. Bensch, “A taxonomy of embodiment in the ai era,” *Electronics*, vol. 13, no. 22, p. 4441, 2024.  \n[54] M. Wischnewski, “Attributing mental states to non-embodied autonomous systems: A systematic review,” in Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 1–8, 2025.  \n[55] K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, and M. Fritz, \"Not what you've signed up for: Compromising real-world IIm-integrated applications with indirect prompt injection,\" in Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security, pp. 79-90, 2023.  \n[56] Y. Talebirad and A. Nadiri, \"Multi-agent collaboration: Harnessing the power of intelligent llm agents,\" arXiv preprint arXiv:2306.03314, 2023.  \n[57] A. I. Hauptman, B. G. Schelble, N. J. McNeese, and K. C. Madathil, \"Adapt and overcome: Perceptions of adaptive autonomous agents for human-ai teaming,\" Computers in Human Behavior, vol. 138, p. 107451, 2023.  \n[58] N. Krishnan, “Advancing multi-agent systems through model context protocol: Architecture, implementation, and applications,” arXiv preprint arXiv:2504.21030, 2025.  \n[59] H. Padigela, C. Shah, and D. Juyal, \"Ml-dev-bench: Comparative analysis of ai agents on ml development workflows,\" arXiv preprint arXiv:2502.00964, 2025.  \n[60] M. Raees, I. Meijerink, I. Lykourentzou, V.-J. Khan, and K. Papangelis, \"From explainable to interactive ai: A literature review on current trends in human-ai interaction,\" International Journal of Human-Computer Studies, p. 103301, 2024.  \n[61] P. Formosa, “Robot autonomy vs. human autonomy: social robots, artificial intelligence (ai), and the nature of autonomy,” *Minds and Machines*, vol. 31, no. 4, pp. 595–616, 2021.  \n[62] C. S. Eze and L. Shamir, “Analysis and prevention of ai-based phishing email attacks,” *Electronics*, vol. 13, no. 10, p. 1839, 2024.  \n[63] D. Singh, V. Patel, D. Bose, and A. Sharma, “Enhancing email marketing efficacy through ai-driven personalization: Leveraging natural language processing and collaborative filtering algorithms,” International Journal of AI Advancements, vol. 9, no. 4, 2020.\n\n[64] R. Khan, S. Sarkar, S. K. Mahata, and E. Jose, \"Security threats in agentic ai system,\" arXiv preprint arXiv:2410.14728, 2024.  \n[65] C. G. Endacott, “Enacting machine agency when ai makes one’s day: understanding how users relate to ai communication technologies for scheduling,” Journal of Computer-Mediated Communication, vol. 29, no. 4, p. zmae011, 2024.  \n[66] Z. Pawlak and A. Skowron, “Rudiments of rough sets,” Information sciences, vol. 177, no. 1, pp. 3-27, 2007.  \n[67] P. Ponnusamy, A. Ghias, Y. Yi, B. Yao, C. Guo, and R. Sarikaya, \"Feedback-based self-learning in large-scale conversational ai agents,\" AI magazine, vol. 42, no. 4, pp. 43-56, 2022.  \n[68] A. Zagalsky, D. Te'eni, I. Yahav, D. G. Schwartz, G. Silverman, D. Cohen, Y. Mann, and D. Lewinsky, \"The design of reciprocal learning between human and artificial intelligence,\" Proceedings of the ACM on Human-Computer Interaction, vol. 5, no. CSCW2, pp. 1-36, 2021.  \n[69] W. J. Clancey, “Heuristic classification,” Artificial intelligence, vol. 27, no. 3, pp. 289–350, 1985.  \n[70] S. Kapoor, B. Stroebl, Z. S. Siegel, N. Nadgir, and A. Narayanan, “Ai agents that matter,” arXiv preprint arXiv:2407.01502, 2024.  \n[71] X. Huang, J. Lian, Y. Lei, J. Yao, D. Lian, and X. Xie, \"Recommender ai agent: Integrating large language models for interactive recommendations,\" arXiv preprint arXiv:2308.16505, 2023.  \n[72] A. M. Baabdullah, A. A. Alalwan, R. S. Algharabat, B. Metri, and N. P. Rana, “Virtual agents and flow experience: An empirical examination of ai-powered chatbots,” Technological Forecasting and Social Change, vol. 181, p. 121772, 2022.  \n[73] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al., “Gpt-4 technical report,” arXiv preprint arXiv:2303.08774, 2023.  \n[74] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., “Palm: Scaling language modeling with pathways,” Journal of Machine Learning Research, vol. 24, no. 240, pp. 1–113, 2023.  \n[75] H. Honda and M. Hagiwara, “Question answering systems with deep learning-based symbolic processing,” IEEE Access, vol. 7, pp. 152368–152378, 2019.  \n[76] N. Karanikolas, E. Manga, N. Samaridi, E. Tousidou, and M. Vassilikopoulos, \"Large language models versus natural language understanding and generation,\" in Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics, pp. 278-290, 2023.  \n[77] A. S. George, A. H. George, T. Baskar, and A. G. Martin, \"Revolutionizing business communication: Exploring the potential of gpt-4 in corporate settings,\" *Partners Universal International Research Journal*, vol. 2, no. 1, pp. 149–157, 2023.  \n[78] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al., \"Learning transferable visual models from natural language supervision,\" in International conference on machine learning, pp. 8748-8763, PmLR, 2021.  \n[79] J. Li, D. Li, S. Savarese, and S. Hoi, \"Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,\" in International conference on machine learning, pp. 19730-19742, PMLR, 2023.  \n[80] S. Sontakke, J. Zhang, S. Arnold, K. Pertsch, E. Bityik, D. Sadigh, C. Finn, and L. Itti, \"Roboclip: One demonstration is enough to learn robot policies,\" Advances in Neural Information Processing Systems, vol. 36, pp. 55681-55693, 2023.  \n[81] M. Elhenawy, H. I. Ashqar, A. Rakotonirainy, T. I. Alhadidi, A. Jaber, and M. A. Tami, \"Vision-language models for autonomous driving: Clip-based dynamic scene understanding,\" *Electronics*, vol. 14, no. 7, p. 1282, 2025.  \n[82] S. Park, M. Lee, J. Kang, H. Choi, Y. Park, J. Cho, A. Lee, and D. Kim, \"Vlaad: Vision and language assistant for autonomous driving,\" in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 980-987, 2024.  \n[83] S. H. Ahmed, S. Hu, and G. Sukthankar, “The potential of vision-language models for content moderation of children’s videos,” in 2023 International Conference on Machine Learning and Applications (ICMLA), pp. 1237–1241, IEEE, 2023.  \n[84] S. H. Ahmed, M. J. Khan, and G. Sukthankar, \"Enhanced multimodal content moderation of children's videos using audiovisual fusion,\" arXiv preprint arXiv:2405.06128, 2024.\n\n[85] P. Chitra and A. Saleem Raja, \"Artificial intelligence (ai) algorithm and models for embodied agents (robots and drones),\" in Building Embodied AI Systems: The Agents, the Architecture Principles, Challenges, and Application Domains, pp. 417-441, Springer, 2025.  \n[86] S. Kourav, K. Verma, and M. Sundararajan, \"Artificial intelligence algorithm models for agents of embodiment for drone applications,\" in Building Embodied AI Systems: The Agents, the Architecture Principles, Challenges, and Application Domains, pp. 79-101, Springer, 2025.  \n[87] G. Natarajan, E. Elango, B. Sundaravadivazhagan, and S. Rethinam, \"Artificial intelligence algorithms and models for embodied agents: Enhancing autonomy in drones and robots,\" in Building Embodied AI Systems: The Agents, the Architecture Principles, Challenges, and Application Domains, pp. 103-132, Springer, 2025.  \n[88] K. Pandya and M. Holia, \"Automating customer service using langchain: Building custom open-source gpt chatbot for organizations,\" arXiv preprint arXiv:2310.05421, 2023.  \n[89] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang, S. Zhang, J. Liu, et al., \"Autogen: Enabling next-gen llm applications via multi-agent conversation,\" arXiv preprint arXiv:2308.08155, 2023.  \n[90] L. Gabora and J. Bach, “A path to generative artificial selves,” in EPIA Conference on Artificial Intelligence, pp. 15–29, Springer, 2023.  \n[91] G. Pezzulo, T. Parr, P. Cisek, A. Clark, and K. Friston, \"Generating meaning: active inference and the scope and limits of passive ai,\" Trends in Cognitive Sciences, vol. 28, no. 2, pp. 97-112, 2024.  \n[92] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, and K. Tei, \"Generative ai for self-adaptive systems: State of the art and research roadmap,\" ACM Transactions on Autonomous and Adaptive Systems, vol. 19, no. 3, pp. 1-60, 2024.  \n[93] W. O'Grady and M. Lee, \"Natural syntax, artificial intelligence and language acquisition,\" Information, vol. 14, no. 7, p. 418, 2023.  \n[94] X. Liu, J. Wang, J. Sun, X. Yuan, G. Dong, P. Di, W. Wang, and D. Wang, “Prompting frameworks for large language models: A survey,” arXiv preprint arXiv:2311.12785, 2023.  \n[95] E. T. Rolls, “The memory systems of the human brain and generative artificial intelligence,” Heliyon, vol. 10, no. 11, 2024.  \n[96] K. Alizadeh, S. I. Mirzadeh, D. Belenko, S. Khatamifard, M. Cho, C. C. Del Mundo, M. Rastegari, and M. Farajtabar, \"Llm in a flash: Efficient large language model inference with limited memory,\" in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 12562-12584, 2024.  \n[97] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, A. Wahid, J. Tompson, Q. Vuong, T. Yu, W. Huang, et al., “Palm-e: An embodied multimodal language model,” 2023.  \n[98] P. Denny, J. Leinonen, J. Prather, A. Luxton-Reilly, T. Amarouche, B. A. Becker, and B. N. Reeves, \"Prompt problems: A new programming exercise for the generative ai era,\" in Proceedings of the 55th ACM Technical Symposium on Computer Science Education V.1, pp.296-302, 2024.  \n[99] C. Chen, S. Lee, E. Jang, and S. S. Sundar, \"Is your prompt detailed enough? exploring the effects of prompt coaching on users' perceptions, engagement, and trust in text-to-image generative ai tools,\" in Proceedings of the Second International Symposium on Trustworthy Autonomous Systems, pp. 1-12, 2024.  \n[100] A. Pan, E. Jones, M. Jagadeesan, and J. Steinhardt, \"Feedback loops with language models drive in-context reward hacking,\" arXiv preprint arXiv:2402.06627, 2024.  \n[101] K. Nabben, “Ai as a constituted system: accountability lessons from an llm experiment,” Data & policy, vol. 6, p. e57, 2024.  \n[102] P. J. Pesch, “Potentials and challenges of large language models (llms) in the context of administrative decision-making,” European Journal of Risk Regulation, pp. 1–20, 2025.  \n[103] C. Wang, Y. Deng, Z. Lyu, L. Zeng, J. He, S. Yan, and B. An, “Q*: Improving multi-step reasoning for llms with deliberative planning,” arXiv preprint arXiv:2406.14283, 2024.  \n[104] H. Wei, Z. Zhang, S. He, T. Xia, S. Pan, and F. Liu, “Plangen-llms: A modern survey of llm planning capabilities,” arXiv preprint arXiv:2502.11221, 2025.  \n[105] A. Bandi, P. V. S. R. Adapa, and Y. E. V. P. K. Kuchi, “The power of generative ai: A review of requirements, models, input-output formats, evaluation metrics, and challenges,” Future Internet, vol. 15, no. 8, p. 260, 2023.\n\n[106] Y. Liu, H. Du, D. Niyato, J. Kang, Z. Xiong, Y. Wen, and D. I. Kim, \"Generative ai in data center networking: Fundamentals, perspectives, and case study,\" IEEE Network, 2025.  \n[107] C. Guo, F. Cheng, Z. Du, J. Kiessling, J. Ku, S. Li, Z. Li, M. Ma, T. Molom-Ochir, B. Morris, et al., \"A survey: Collaborative hardware and software design in the era of large language models,\" IEEE Circuits and Systems Magazine, vol. 25, no. 1, pp. 35-57, 2025.  \n[108] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., \"Language models are few-shot learners,\" Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.  \n[109] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., \"Llama: Open and efficient foundation language models,\" arXiv preprint arXiv:2302.13971, 2023.  \n[110] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, \"Exploring the limits of transfer learning with a unified text-to-text transformer,\" Journal of machine learning research, vol. 21, no. 140, pp. 1-67, 2020.  \n[111] A. Yang, B. Xiao, B. Wang, B. Zhang, C. Bian, C. Yin, C. Lv, D. Pan, D. Wang, D. Yan, et al., \"Baichuan 2: Open large-scale language models,\" arXiv preprint arXiv:2309.10305, 2023.  \n[112] K. M. Yoo, D. Park, J. Kang, S.-W. Lee, and W. Park, “Gpt3mix: Leveraging large-scale language models for text augmentation,” arXiv preprint arXiv:2104.08826, 2021.  \n[113] D. Zhou, X. Xue, X. Lu, Y. Guo, P. Ji, H. Lv, W. He, Y. Xu, Q. Li, and L. Cui, \"A hierarchical model for complex adaptive system: From adaptive agent to ai society,\" ACM Transactions on Autonomous and Adaptive Systems, 2024.  \n[114] H. Hao, Y. Wang, and J. Chen, \"Empowering scenario planning with artificial intelligence: A perspective on building smart and resilient cities,\" Engineering, 2024.  \n[115] Y. Wang, J. Zhu, Z. Cheng, L. Qiu, Z. Tong, and J. Huang, \"Intelligent optimization method for real-time decision-making in laminated cooling configurations through reinforcement learning,\" Energy, vol. 291, p. 130434, 2024.  \n[116] X. Xiang, J. Xue, L. Zhao, Y. Lei, C. Yue, and K. Lu, “Real-time integration of fine-tuned large language model for improved decision-making in reinforcement learning,” in 2024 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, IEEE, 2024.  \n[117] Z. Li, H. Zhang, C. Peng, and R. Peiris, “Exploring large language model-driven agents for environment-aware spatial interactions and conversations in virtual reality role-play scenarios,” in 2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR), pp. 1-11, IEEE, 2025.  \n[118] T. R. McIntosh, T. Susnjak, T. Liu, P. Watters, and M. N. Halgamuge, \"The inadequacy of reinforcement learning from human feedback-radicalizing large language models via semantic vulnerabilities,\" IEEE Transactions on Cognitive and Developmental Systems, 2024.  \n[119] S. Lee, G. Lee, W. Kim, J. Kim, J. Park, and K. Cho, \"Human strategy learning-based multi-agent deep reinforcement learning for online team sports game,\" IEEE Access, 2025.  \n[120] Z. Shi, S. Gao, L. Yan, Y. Feng, X. Chen, Z. Chen, D. Yin, S. Verberne, and Z. Ren, \"Tool learning in the wild: Empowering language models as automatic tool agents,\" in Proceedings of the ACM on Web Conference 2025, pp. 2222-2237, 2025.  \n[121] S. Yuan, K. Song, J. Chen, X. Tan, Y. Shen, R. Kan, D. Li, and D. Yang, \"Easytool: Enhancing llm-based agents with concise tool instruction,\" arXiv preprint arXiv:2401.06201, 2024.  \n[122] B. Xu, X. Liu, H. Shen, Z. Han, Y. Li, M. Yue, Z. Peng, Y. Liu, Z. Yao, and D. Xu, \"Gentopia: A collaborative platform for tool-augmented llms,\" arXiv preprint arXiv:2308.04030, 2023.  \n[123] H. Lu, X. Li, X. Ji, Z. Kan, and Q. Hu, “Toolfive: Enhancing tool-augmented llms via tool filtering and verification,” in ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1-5, IEEE, 2025.  \n[124] Y. Song, F. Xu, S. Zhou, and G. Neubig, “Beyond browsing: Api-based web agents,” arXiv preprint arXiv:2410.16464, 2024.  \n[125] V. Tupe and S. Thube, \"Ai agentic workflows and enterprise apis: Adapting api architectures for the age of ai agents,\" arXiv preprint arXiv:2502.17443, 2025.  \n[126] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao, \"React: Synergizing reasoning and acting in language models,\" in International Conference on Learning Representations (ICLR), 2023.\n\n[127] L. Ning, Z. Liang, Z. Jiang, H. Qu, Y. Ding, W. Fan, X.-y. Wei, S. Lin, H. Liu, P. S. Yu, et al., \"A survey of webagents: Towards next-generation ai agents for web automation with large foundation models,\" arXiv preprint arXiv:2503.23350, 2025.  \n[128] M. W. U. Rahman, R. Nevarez, L. T. Mim, and S. Hariri, “Multiagent actor-critic generative ai for query resolution and analysis,” IEEE Transactions on Artificial Intelligence, 2025.  \n[129] J. Lála, O. O'Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques, and A. D. White, \"Paperqa: Retrieval-augmented generative agent for scientific research,\" arXiv preprint arXiv:2312.07559, 2023.  \n[130] Z. Wu, C. Yu, C. Chen, J. Hao, and H. H. Zhuo, \"Models as agents: Optimizing multi-step predictions of interactive local models in model-based multi-agent reinforcement learning,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, pp. 10435-10443, 2023.  \n[131] Z. Feng, R. Xue, L. Yuan, Y. Yu, N. Ding, M. Liu, B. Gao, J. Sun, and G. Wang, \"Multi-agent embodied ai: Advances and future directions,\" arXiv preprint arXiv:2505.05108, 2025.  \n[132] A. Feriani and E. Hossain, \"Single and multi-agent deep reinforcement learning for ai-enabled wireless networks: A tutorial,\" IEEE Communications Surveys & Tutorials, vol. 23, no. 2, pp. 1226-1252, 2021.  \n[133] R. Zhang, S. Tang, Y. Liu, D. Niyato, Z. Xiong, S. Sun, S. Mao, and Z. Han, \"Toward agentic ai: generative information retrieval inspired intelligent communications and networking,\" arXiv preprint arXiv:2502.16866, 2025.  \n[134] U. M. Borghoff, P. Bottoni, and R. Pareschi, “Human-artificial interaction in the age of agentic ai: a system-theoretical approach,” Frontiers in Human Dynamics, vol. 7, p. 1579166, 2025.  \n[135] E. Miehling, K. N. Ramamurthy, K. R. Varshney, M. Riemer, D. Boun-effouf, J. T. Richards, A. Dhurandhar, E. M. Daly, M. Hind, P. Sattigeri, et al., \"Agentic ai needs a systems theory,\" arXiv preprint arXiv:2503.00237, 2025.  \n[136] W. Xu, Z. Liang, K. Mei, H. Gao, J. Tan, and Y. Zhang, “A-mem: Agentic memory for llm agents,” arXiv preprint arXiv:2502.12110, 2025.  \n[137] C. Riedl and D. De Cremer, “Ai for collective intelligence,” Collective Intelligence, vol. 4, no. 2, p. 26339137251328909, 2025.  \n[138] L. Peng, D. Li, Z. Zhang, T. Zhang, A. Huang, S. Yang, and Y. Hu, \"Human-ai collaboration: Unraveling the effects of user proficiency and ai agent capability in intelligent decision support systems,\" International Journal of Industrial Ergonomics, vol. 103, p. 103629, 2024.  \n[139] H. Shirado, K. Shimizu, N. A. Christakis, and S. Kasahara, “Realism drives interpersonal reciprocity but yields to ai-assisted egocentrism in a coordination experiment,” in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 1–21, 2025.  \n[140] Y. Xiao, G. Shi, and P. Zhang, \"Towards agentic ai networking in 6g: A generative foundation model-as-agent approach,\" arXiv preprint arXiv:2503.15764, 2025.  \n[141] P. R. Lewis and S. Sarkadi, “Reflective artificial intelligence,” *Minds and Machines*, vol. 34, no. 2, p. 14, 2024.  \n[142] C. Qian, W. Liu, H. Liu, N. Chen, Y. Dang, J. Li, C. Yang, W. Chen, Y. Su, X. Cong, et al., \"Chatdev: Communicative agents for software development,\" arXiv preprint arXiv:2307.07924, 2023.  \n[143] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S. Yau, Z. Lin, L. Zhou, et al., “Metagpt: Meta programming for multi-agent collaborative framework,” arXiv preprint arXiv:2308.00352, vol. 3, no. 4, p. 6, 2023.  \n[144] Y. Liang, C. Wu, T. Song, W. Wu, Y. Xia, Y. Liu, Y. Ou, S. Lu, L. Ji, S. Mao, et al., \"Taskmatrix: ai: Completing tasks by connecting foundation models with millions of apis,\" Intelligent Computing, vol. 3, p. 0063, 2024.  \n[145] H. Hexmoor, J. Lammens, G. Caicedo, and S. C. Shapiro, Behaviour based AI, cognitive processes, and emergent behaviors in autonomous agents, vol. 1. WIT Press, 2025.  \n[146] H. Zhang, Z. Li, F. Liu, Y. He, Z. Cao, and Y. Zheng, \"Design and implementation of langchain-based chatbot,\" in 2024 International Seminar on Artificial Intelligence, Computer Technology and Control Engineering (ACTCE), pp. 226-229, IEEE, 2024.  \n[147] E. Ephrati and J. S. Rosenschein, “A heuristic technique for multi-agent planning,” Annals of Mathematics and Artificial Intelligence, vol. 20, pp. 13–67, 1997.  \n[148] S. Kupferschmid, J. Hoffmann, H. Dierks, and G. Behrmann, \"Adapting an ai planning heuristic for directed model checking,\" in International SPIN Workshop on Model Checking of Software, pp. 35-52, Springer, 2006.\n\n[149] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin, Y. Lu, R. Xie, et al., \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents,\" arXiv preprint arXiv:2308.10848, vol. 2, no. 4, p. 6, 2023.  \n[150] T. Schick, J. Dwivedi-Yu, R. Dessi, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer, N. Cancedda, and T. Scialom, “Toolformer: Language models can teach themselves to use tools,” Advances in Neural Information Processing Systems, vol. 36, pp. 68539–68551, 2023.  \n[151] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al., \"Chain-of-thought prompting elicits reasoning in large language models,\" Advances in neural information processing systems, vol. 35, pp. 24824-24837, 2022.  \n[152] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, and K. Narasimhan, “Tree of thoughts: Deliberate problem solving with large language models,” Advances in neural information processing systems, vol. 36, pp. 11809–11822, 2023.  \n[153] J. Guo, N. Li, J. Qi, H. Yang, R. Li, Y. Feng, S. Zhang, and M. Xu, \"Empowering working memory for large language model agents,\" arXiv preprint arXiv:2312.17259, 2023.  \n[154] S. Agashe, J. Han, S. Gan, J. Yang, A. Li, and X. E. Wang, \"Agent s: An open agentic framework that uses computers like a human,\" arXiv preprint arXiv:2410.08164, 2024.  \n[155] C. DeChant, \"Episodic memory in ai agents poses risks that should be studied and mitigated,\" arXiv preprint arXiv:2501.11739, 2025.  \n[156] A. M. Nuxoll and J. E. Laird, “Enhancing intelligent agents with episodic memory,” Cognitive Systems Research, vol. 17, pp. 34–48, 2012.  \n[157] G. Sarthou, A. Clodic, and R. Alami, “Ontologenius: A long-term semantic memory for robotic agents,” in 2019 28th IEEE International Conference on Robot and Human Interactive Communication (ROMAN), pp. 1–8, IEEE, 2019.  \n[158] A.-e.-h. Munir and W. M. Qazi, “Artificial subjectivity: Personal semantic memory model for cognitive agents,” Applied Sciences, vol. 12, no. 4, p. 1903, 2022.  \n[159] A. Singh, A. Ehtesham, S. Kumar, and T. T. Khoei, \"Agentic retrieval-augmented generation: A survey on agentic rag,\" arXiv preprint arXiv:2501.09136, 2025.  \n[160] R. Akkiraju, A. Xu, D. Bora, T. Yu, L. An, V. Seth, A. Shukla, P. Gundecha, H. Mehta, A. Jha, et al., \"Facts about building retrieval augmented generation-based chatbots,\" arXiv preprint arXiv:2407.07858, 2024.  \n[161] G. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan, and A. Anandkumar, \"Voyager: An open-ended embodied agent with large language models,\" arXiv preprint arXiv:2305.16291, 2023.  \n[162] G. Li, H. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem, \"Camel: Communicative agents for\" mind\" exploration of large language model society,\" Advances in Neural Information Processing Systems, vol. 36, pp. 51991-52008, 2023.  \n[163] S. Reed, K. Zolna, E. Parisotto, S. G. Colmenarejo, A. Novikov, G. Barth-Maron, M. Gimenez, Y. Sulsky, J. Kay, J. T. Springenberg, et al., \"A generalist agent,\" arXiv preprint arXiv:2205.06175, 2022.  \n[164] C. K. Thomas, C. Chaccour, W. Saad, M. Debbah, and C. S. Hong, \"Causal reasoning: Charting a revolutionary course for next-generation ai-native wireless networks,\" IEEE Vehicular Technology Magazine, 2024.  \n[165] Z. Tang, R. Wang, W. Chen, K. Wang, Y. Liu, T. Chen, and L. Lin, \"Towards causalgpt: A multi-agent approach for faithful knowledge reasoning via promoting causal consistency in llms,\" arXiv preprint arXiv:2308.11914, 2023.  \n[166] Z. Gekhman, J. Herzig, R. Aharoni, C. Elkind, and I. Szpektor, \"Trueteacher: Learning factual consistency evaluation with large language models,\" arXiv preprint arXiv:2305.11171, 2023.  \n[167] A. Wu, K. Kuang, M. Zhu, Y. Wang, Y. Zheng, K. Han, B. Li, G. Chen, F. Wu, and K. Zhang, \"Causality for large language models,\" arXiv preprint arXiv:2410.15319, 2024.  \n[168] S. Ashwani, K. Hegde, N. R. Mannuru, D. S. Sengar, M. Jindal, K. C. R. Kathala, D. Banga, V. Jain, and A. Chadha, \"Cause and effect: can large language models truly understand causality?\", in Proceedings of the AAAI Symposium Series, vol. 4, pp. 2-9, 2024.  \n[169] J. Richens and T. Everitt, “Robust agents learn causal world models,” in The Twelfth International Conference on Learning Representations, 2024.\n\n[170] A. Chan, R. Salganik, A. Markelius, C. Pang, N. Rajkumar, D. Krasheninnikov, L. Langosco, Z. He, Y. Duan, M. Carroll, et al., \"Harms from increasingly agentic algorithmic systems,\" in Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, pp. 651-666, 2023.  \n[171] A. Plaat, M. van Duijn, N. van Stein, M. Preuss, P. van der Putten, and K. J. Batenburg, \"Agentic large language models, a survey,\" arXiv preprint arXiv:2503.23037, 2025.  \n[172] J. Qiu, K. Lam, G. Li, A. Acharya, T. Y. Wong, A. Darzi, W. Yuan, and E. J. Topol, “Llm-based agentic systems in medicine and healthcare,” Nature Machine Intelligence, vol. 6, no. 12, pp. 1418–1420, 2024.  \n[173] G. A. Gabison and R. P. Xian, “Inherent and emergent liability issues in llm-based agentic systems: a principal-agent perspective,” arXiv preprint arXiv:2504.03255, 2025.  \n[174] M. Dahl, V. Magesh, M. Suzgun, and D. E. Ho, “Large legal fictions: Profiling legal hallucinations in large language models,” *Journal of Legal Analysis*, vol. 16, no. 1, pp. 64–93, 2024.  \n[175] Y. A. Latif, \"Hallucinations in large language models and their influence on legal reasoning: Examining the risks of ai-generated factual inaccuracies in judicial processes,\" Journal of Computational Intelligence, Machine Reasoning, and Decision-Making, vol. 10, no. 2, pp. 10-20, 2025.  \n[176] S. Tonmoy, S. Zaman, V. Jain, A. Rani, V. Rawte, A. Chadha, and A. Das, “A comprehensive survey of hallucination mitigation techniques in large language models,” arXiv preprint arXiv:2401.01313, vol. 6, 2024.  \n[177] Z. Zhang, Y. Yao, A. Zhang, X. Tang, X. Ma, Z. He, Y. Wang, M. Gerstein, R. Wang, G. Liu, et al., \"Igniting language intelligence: The hitchhiker's guide from chain-of-thought reasoning to language agents,\" ACM Computing Surveys, vol. 57, no. 8, pp. 1-39, 2025.  \n[178] Y. Wan and K.-W. Chang, “White men lead, black women help? benchmarking language agency social biases in llms,” arXiv preprint arXiv:2404.10508, 2024.  \n[179] A. Borah and R. Mihalcea, “Towards implicit bias detection and mitigation in multi-agent llm interactions,” arXiv preprint arXiv:2410.02584, 2024.  \n[180] X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding, K. Men, K. Yang, et al., \"Agentbench: Evaluating llms as agents,\" arXiv preprint arXiv:2308.03688, 2023.  \n[181] G. He, G. Demartini, and U. Gadiraju, \"Plan-then-execute: An empirical study of user trust and team performance when using lvm agents as a daily assistant,\" in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 1-22, 2025.  \n[182] Z. Ke, F. Jiao, Y. Ming, X.-P. Nguyen, A. Xu, D. X. Long, M. Li, C. Qin, P. Wang, S. Savarese, et al., \"A survey of frontiers in llm reasoning: Inference scaling, learning to reason, and agentic systems,\" arXiv preprint arXiv:2504.09037, 2025.  \n[183] M. Luo, X. Shi, C. Cai, T. Zhang, J. Wong, Y. Wang, C. Wang, Y. Huang, Z. Chen, J. E. Gonzalez, et al., \"Autellix: An efficient serving engine for llm agents as general programs,\" arXiv preprint arXiv:2502.13965, 2025.  \n[184] K. Hatalis, D. Christou, J. Myers, S. Jones, K. Lambert, A. Amos-Binks, Z. Dannenhauer, and D. Dannenhauer, \"Memory matters: The need to improve long-term memory in lmm-agents,\" in Proceedings of the AAAI Symposium Series, vol. 2, pp. 277-280, 2023.  \n[185] H. Jin, X. Han, J. Yang, Z. Jiang, Z. Liu, C.-Y. Chang, H. Chen, and X. Hu, “Llm maybe longlm: Self-extend llm context window without tuning,” arXiv preprint arXiv:2401.01325, 2024.  \n[186] M. Yu, F. Meng, X. Zhou, S. Wang, J. Mao, L. Pang, T. Chen, K. Wang, X. Li, Y. Zhang, et al., \"A survey on trustworthy llm agents: Threats and countermeasures,\" arXiv preprint arXiv:2503.09648, 2025.  \n[187] H. Chi, H. Li, W. Yang, F. Liu, L. Lan, X. Ren, T. Liu, and B. Han, \"Unveiling causal reasoning in large language models: Reality or mirage?\", Advances in Neural Information Processing Systems, vol. 37, pp. 96640-96670, 2024.  \n[188] H. Wang, A. Zhang, N. Duy Tai, J. Sun, T.-S. Chua, et al., \"Ali-agent: Assessing llms' alignment with human values via agent-based evaluation,\" Advances in Neural Information Processing Systems, vol. 37, pp. 99040-99088, 2024.  \n[189] L. Hammond, A. Chan, J. Clifton, J. Hoelscher-Obermaier, A. Khan, E. McLean, C. Smith, W. Barfuss, J. Foerster, T. Gavenciak, et al., “Multi-agent risks from advanced ai,” arXiv preprint arXiv:2502.14143, 2025.\n\n[190] D. Trusilo, \"Autonomous ai systems in conflict: Emergent behavior and its impact on predictability and reliability,\" Journal of Military Ethics, vol. 22, no. 1, pp. 2-17, 2023.  \n[191] M. Puvvadi, S. K. Arava, A. Santoria, S. S. P. Chennupati, and H. V. Puvvadi, \"Coding agents: A comprehensive survey of automated bug fixing systems and benchmarks,\" in 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT), pp. 680-686, IEEE, 2025.  \n[192] C. Newton, J. Singleton, C. Copland, S. Kitchen, and J. Hudack, \"Scalability in modeling and simulation systems for multi-agent, ai, and machine learning applications,\" in Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications III, vol. 11746, pp. 534-552, SPIE, 2021.  \n[193] H. D. Le, X. Xia, and Z. Chen, \"Multi-agent causal discovery using large language models,\" arXiv preprint arXiv:2407.15073, 2024.  \n[194] Y. Shavit, S. Agarwal, M. Brundage, S. Adler, C. O'Keefe, R. Campbell, T. Lee, P. Mishkin, T. Eloundou, A. Hickey, et al., \"Practices for governing agentic ai systems,\" Research Paper, OpenAI, 2023.  \n[195] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Kuttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al., \"Retrievalaugmented generation for knowledge-intensive nlp tasks,\" Advances in neural information processing systems, vol. 33, pp. 9459-9474, 2020.  \n[196] Y. Ma, Z. Gou, J. Hao, R. Xu, S. Wang, L. Pan, Y. Yang, Y. Cao, A. Sun, H. Awadalla, et al., \"Sciagent: Tool-augmented language models for scientific reasoning,\" arXiv preprint arXiv:2402.11451, 2024.  \n[197] K. Dev, S. A. Khowaja, K. Singh, E. Zeydan, and M. Debbah, \"Advanced architectures integrated with agentic ai for next-generation wireless networks,\" arXiv preprint arXiv:2502.01089, 2025.  \n[198] A. Boyle and A. Blomkvist, “Elements of episodic memory: insights from artificial agents,” Philosophical Transactions B, vol. 379, no. 1913, p. 20230416, 2024.  \n[199] Y. Du, W. Huang, D. Zheng, Z. Wang, S. Montella, M. Lapata, K.-F. Wong, and J. Z. Pan, \"Rethinking memory in ai: Taxonomy, operations, topics, and future directions,\" arXiv preprint arXiv:2505.00675, 2025.  \n[200] K.-T. Tran, D. Dao, M.-D. Nguyen, Q.-V. Pham, B. O'Sullivan, and H. D. Nguyen, \"Multi-agent collaboration mechanisms: A survey of llms,\" arXiv preprint arXiv:2501.06322, 2025.  \n[201] K. Tallam, “From autonomous agents to integrated systems, a new paradigm: Orchestrated distributed intelligence,” arXiv preprint arXiv:2503.13754, 2025.  \n[202] Y. Lee, “Critique of artificial reason: Ontology of human and artificial intelligence,” Journal of Ecohumanism, vol. 4, no. 3, pp. 397–415, 2025.  \n[203] L. Ale, S. A. King, N. Zhang, and H. Xing, “Enhancing generative ai reliability via agentic ai in 6g-enabled edge computing,” Nature Reviews Electrical Engineering, pp. 1-3, 2025.  \n[204] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, \"Reflexion: Language agents with verbal reinforcement learning,\" Advances in Neural Information Processing Systems, vol. 36, pp. 8634-8652, 2023.  \n[205] F. Kamalov, D. S. Calonge, L. Smail, D. Azizov, D. R. Thadani, T. Kwong, and A. Atif, \"Evolution of ai in education: Agentic workflows,\" arXiv preprint arXiv:2504.20082, 2025.  \n[206] A. Sulc, T. Hellert, R. Kammering, H. Hoschouer, and J. S. John, \"Towards agentic ai on particle accelerators,\" arXiv preprint arXiv:2409.06336, 2024.  \n[207] J. Yang, C. Jimenez, A. Wettig, K. Lieret, S. Yao, K. Narasimhan, and O. Press, \"Swe-agent: Agent-computer interfaces enable automated software engineering,\" Advances in Neural Information Processing Systems, vol. 37, pp. 50528-50652, 2024.  \n[208] S. Barua, “Exploring autonomous agents through the lens of large language models: A review,” arXiv preprint arXiv:2404.04442, 2024.",
    "translated_content": null,
    "created_at": "2025-12-15 11:44:10.895310",
    "updated_at": "2025-12-15 11:44:17.838779"
  },
  "9d7befb9-e05e-4cb6-89d3-41a9b5d3a916": {
    "id": "9d7befb9-e05e-4cb6-89d3-41a9b5d3a916",
    "filename": "from words 2 winsdom 2511.20547v1.pdf",
    "file_path": "./uploads/papers/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916.pdf",
    "status": "completed",
    "title": "From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding",
    "category": null,
    "markdown_content": "# From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding\n\nFarjana Sultana Mim, Shuchin Aeron, Eric Miller and Kristen Wendell\n\nAbstract-Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.\n\nIndex Terms—Natural Language Processing, Large Language Model, Discourse, Dialogue, Education.\n\n# I. INTRODUCTION\n\nRESEARCH in classroom settings has shown that student learning outcomes are higher when students frame a classwork or homework activity as an opportunity for constructing knowledge rather than as a task to be produced for the instructor [1], [2]. In other words, two important features of student conversations are: knowledge construction (KC) discourse, which refers to the student talks focused on developing conceptual understanding, and task production (TP) discourse, where student talks are focused on completing an instructional task as expeditently as possible [3].\n\nPrior research in learning sciences has also demonstrated that when students frame their purpose within an instructional activity as constructing knowledge rather than just completing a task, they are more likely to develop expertise and be able to later transfer their expertise to new situations [4]. These\n\nF. S. Mim is with the Department of Electrical and Computer Engineering, Tufts University, Medford, MA 02155, United States. (e-mail: farjana.mim59@gmail.com) (currently in the Department of Computer Science and Information Technology, Patuakhali Science and Technology University, Bangladesh)  \nS. Aeron is with the Department of Electrical and Computer Engineering, Tufts University, Medford, MA 02155, United States. (e-mail: shuchin.aeron@tufts.edu)  \nE. Miller is with the Department of Electrical and Computer Engineering, Computer Science and Biomedical Engineering, Tufts University, Medford, MA 02155, United States. (e-mail: eric.miller@tufts.edu)  \nK. Wendell is with the Department of Mechanical Engineering and Education, Tufts University, Medford, MA 02155, United States. (e-mail: kristen.wendell@tufts.edu)\n\n# Homework Topic\n\nDesign an experiment complete with instrumentation to determine the specific heats of a gas using a resistance heater. Discuss how the experiment will be conducted, what measurements need to be taken, and how the specific heats will be determined. What are the sources of error in your system? How can you minimize the experimental error?\n\n# Task Production Discourse\n\nStudent X: Although we just have to design the experiment. It's not like we have to actually do it.\n\nStudent  $T$  : No.\n\nStudent A: Just design and justify this will work.\n\nStudent  $X$ : How can you minimize the experimental error. That's one of the points there.\n\n# Knowledge Construction Discourse\n\nStudent X: Ok. So one thought I had too was that actually um whatever material the container is made out of when it heats up, it's going to expand -\n\nStudent T: Mhm.\n\nStudent X: - and that will change whatever the internal volume is. And I don't know if it makes it bigger or smaller actually. It um might make it bigger but if there were -\n\nFig. 1: Students' homework discussion's snippet of knowledge construction and task production discourse.\n\nresults have been found across several disciplines, including physics, chemistry, biology, and engineering education [1]–[3], [5]. However, the relationship between knowledge construction discourse and learning outcomes has yet to be translated into actionable principles for pedagogy and curriculum design. The major difficulty lies in pinpointing which particular aspects of the learning environment and instructional activity cue students into knowledge constructing discourse.\n\nTo address this gap, we aim to develop efficient methods for distinguishing students' knowledge construction discourse from their task production discourse so that researchers can more broadly investigate the conditions or contexts under which students tend to adopt a knowledge construction framing. Such findings would enable educators to design learning experiences and environments so that they cue students toward constructing knowledge.\n\nFig 1 shows examples of knowledge construction and task production discourse in an undergraduate engineering students' conversation. In the task production discourse of the example, the students remind each other that their homework task is to design an experiment and describe how they would minimize experimental error. These lines are focused on setting up the steps to complete their homework. In the\n\nknowledge construction discourse from the same homework conversation, student  $X$  shares an idea about how the process of heating a gas will affect the material containing it. Rather than simply completing a pre-determined step of the homework, student  $X$  tries to envision the phenomena that will occur in the experiment the students are designing. At this moment,  $X$ 's turn of talk is oriented toward understanding rather than expediency.\n\nTraditional manual analysis of student dialogues to identify these discourse features is time-intensive, which limits the scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of KC and TP discourse, providing educational researchers with valuable insights into how curricular and pedagogical variables influence students to engage in knowledge construction rather only task production.\n\nDiscourse in dialogue or conversations has been widely studied in NLP in different task settings such as dialogue act classification [6]–[9], dialogue topic segmentation and categorization [10]–[13], dialogue state tracking [14]–[19], and identifying dialogue system behaviors [20], [21]. However, although various discourse frameworks are being applied to different types of conversational data, hardly any of them are educational data [22], [23]. To address this gap, this study creates a novel educational dialogue dataset, annotated with knowledge construction (KC) and task production (TP) discourse<sup>1</sup>. We also formulate the NLP task of KCTP (Knowledge Construction and Task Production) prediction, aiming to automatically identify these discourse types within educational dialogues.\n\nLately, the NLP field has been revolutionized by pre-trained large language models (LLMs) such as GPT-3 [24], Llama [25], Gemini [26], Deepseek [27]. These models have demonstrated significant performance gains and yielded interesting findings across various NLP tasks, including the study of discourse in dialogues or conversations [14], [20]. Recently, a new paradigm called \"Pre-train, Prompt, and Predict\" [28] has gained popularity which leverages pre-trained LLMs through natural language prompts instead of fine-tuning them for specific tasks. By using such \"prompting\" method, one can probe task-specific knowledge from LLMs, which has shown remarkable performance in various tasks such as text classification and summarization [29], [30]. Another paradigm called \"instruction fine-tuning\" [31] which finetunes a model on a dataset via instructions, has significantly improved the performance of several tasks [32]. Therefore, we use GPT-3.5 with prompting techniques to establish a baseline for our Knowledge Construction vs. Task Production (KCTP) prediction task. However, as GPT-3.5 is not an open-source model, we also use the open-access LLaMA-3.1 (8B) model [33] and fine-tune it for the same task. Experimental results indicate that prompting and fine-tuning GPT-3.5 and LLaMA-3.1 yield suboptimal performance on KCTP prediction, suggesting the need for further research into models and methods better suited\n\nto educational discourse analysis. To summarize, the main contributions of this work are as follows:\n\n- We create a novel educational dialogue dataset annotated with Knowledge Construction (KC) and Task Production (TP) discourse, addressing a gap in discourse-annotated educational data.  \n- We formulate the Knowledge Construction vs. Task Production (KCTP) classification as a natural language processing (NLP) task to automatically identify KC and TP discourse in student dialogues.  \n- We establish baseline models for the KCTP prediction task using GPT-3.5 and LLaMA-3.1 prompting as well as LLaMA-3.1 instruction fine-tuning, revealing current limitations of LLMs in modeling educational discourse and highlighting directions for future research.\n\n# II. RELATED WORK\n\nThis study develops an educational dialogue dataset annotated with instances of knowledge construction (KC) and task production (TP) discourse. We also establish baseline models for the automatic prediction of KC and TP discourse, with the goal of enabling educational researchers to identify the curricular and pedagogical conditions that encourage students to engage in constructing knowledge rather than merely completing tasks. In this section, we briefly review prior work in three relevant areas: (1) discourse in learning sciences, (2) discourse analysis in Dialogue using NLP, and (3) use of pretrained language models for discourse modeling in dialogue.\n\n# A. Learning Sciences Approach to Educational Discourse Analysis\n\nDiscourse has been long studied in learning sciences to determine the nature of activity, understanding, and learning styles of students [1]–[5]. Gouvea et al. [1] presented a case study of a life-science major in a reformed physics course, showing how epistemological shifts in one discipline can transfer to another. Over a year, the student moved from rote learning to coherence-seeking reasoning in physics, integrating materials, peer discussion, and feedback. This reframing extended to biology, where the student began approaching the subject more conceptually. The study provides qualitative evidence that discourse-centered instructional strategies can foster cross-disciplinary epistemological development.\n\nIn another work, Scherr and Hammer [5] explored how students' collaborative behaviors such as posture, gaze, gestures, and vocal dynamics serve as observable indicators of their epistemological framing during active-learning physics activities. They analyze video recordings from introductory physics tutorial sessions and identify distinct behavioral clusters corresponding to different ways students frame the task: for instance, working through substance-based sensemaking versus perceiving it as a procedural worksheet exercise. The authors demonstrate that when students frame the activity as sensemaking, their behaviors align with deeper conceptual reasoning and engagement in discussing the substance of ideas. Their findings highlight the dynamic interplay between\n\nobservable behavior, framing, and the quality of students' scientific reasoning in small-group learning contexts.\n\nKoretsky et al. [2] examined how the design of engineering tasks and instructional framing influence student team dynamics, balancing action (\"doing\") and reflection (\"thinking\") during collaborative open-ended projects. Through detailed cases of small-group engineering design work, they show that when tasks are meaningful, realistic, and properly scaffolded, teams display more equitable participation, distributed modeling and communication, and deeper conceptual reasoning rather than surface-level task execution alone. In particular, the interplay between material engagement (e.g., prototyping and sketching) and explicit discourse about design decisions fosters collective sense-making and shared agency. The study highlights how thoughtfully structured activities and facilitative framing can empower teams to engage in both productive action and epistemic dialogue, offering important implications for discourse-centric analyses and NLP applications in educational dialogue modeling.\n\n# B. Discourse Analysis in Dialogue using NLP\n\nDiscourse in dialogue has been extensively studied in natural language processing (NLP) [34]–[36]. Raheja and Tetreault [7] proposed a hierarchical recurrent neural network and coupled it with a context-aware self-attention mechanism to model different levels of utterance and dialogue act semantics, achieving state-of-the-art performance on the Switchboard Dialogue Act Corpus. Liu et al. [10] introduced a joint model for dialogue segmentation and topic categorization, which was evaluated on a clinical spoken conversation dataset created by them. In another work, Xu et al. [15] developed a Dialogue State Distillation Network (DSDN), which leverages relevant information of previous dialogue states and employs an interslot contrastive learning loss to effectively capture the slot co-update relations from dialogue context. Their proposed method achieved state-of-the-art performance on the dialogue state tracking task. Sabour et al. [21] introduced a novel approach for empathetic response generation in dialogue, which leverages commonsense to draw more information about the user's situation and uses that to further enhance the empathy expression in generated responses. They showed that their approach outperforms the baseline models in both automatic and human evaluations.\n\n# C. Use of Pre-trained Language Models for Discourse Modeling in Dialogue\n\nRecent advancements of pre-trained large language models (LLMs) has significantly advanced the field of discourse modeling [37]–[40]. The importance of modeling speaker turns in dialogues was investigated by He et al. [6], where they incorporated turn changes in conversations among speakers for the dialogue act classification task. They introduced speaker turn embeddings and added them to utterance embeddings produced by the pretrained language model RoBERTa [41], which showed better performance for the dialogue act classification task. Xing and Carenini [11] utilized a neural utterance-pair coherence scoring model based on fine-tuning NSP BERT\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/bba84cd114aabd9a566f1acd99a86c2156a7e29a4dc63e3f8155985510fbf70a.jpg)  \nFig. 2: Topic distribution across the dataset\n\n[42] and achieved state-of-the-art results on the Dialogue topic segmentation task across three public datasets. Feng et al. [14] presented the first evaluation of ChatGPT on the dialogue state tracking task, highlighting its superior performance over prior methods. They also proposed an LLM-driven dialogue state tracking framework based on smaller, open-source foundation models and showed that it achieves comparable performance to ChatGPT. Finch et al. [20] investigated the ability of the state-of-the-art large language model (LLM), i.e., ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues and showed that although ChatGPT performed promisingly, often outperforming specialized detection models, the result is still not up to human performance.\n\nFew researches have been conducted that focus on discourse modeling on educational dialogue data. Jensen et al. [22] proposed a methodology for providing teachers with objective, automated feedback on the quality of their classroom discourse by comparing traditional open-vocabulary approaches using n-grams and Random Forest classifiers with a modern deep transfer learning method leveraging BERT. By modeling seven key features of teacher talk (such as questioning and elaborated evaluation) on 127 recordings of classroom talk, the authors demonstrated that while transfer learning with BERT offers a promising path for enhancing automated discourse analytics in education, its effectiveness hinges on the availability of sufficient annotated data to fine-tune the model effectively. Alic et al. [23] automatically distinguished between two pedagogically significant types of teacher questions: funneling questions, which guide students toward specific answers, and focusing questions, which encourage students to reflect on their reasoning. The authors create a labeled dataset of over 2,000 teacher questions annotated by experts and develop both supervised (fine-tuned RoBERTa) and unsupervised models to classify question types. Their supervised RoBERTa model showed strong alignment with expert judgments and correlates with key educational outcomes, such as instructional quality\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/e0b74a57a9ef55add7777e0214581eb34aea6f0100a23d660f768c53616a43dc.jpg)  \nFig. 3: Distribution of categories across the dataset.\n\nand student learning gains.\n\n# III. DATASET CURATION\n\n# A. Data Collection\n\nWe recorded homework discussions among undergraduate mechanical engineering students, focusing on topics from their thermal fluid systems course. Between 2 and 5 students participated in each conversation. Then, we transcribed the conversations ensuring that all data were de-identified. As part of the consent process, students were asked if their de-identified transcripts could be used in future research. Only transcripts from students who consented were included in the dataset.\n\n# B. Dataset Statistics\n\nThe dataset consists of 32 small-group conversations covering 19 homework topics, each topic corresponding to a distinct task description that students were required to complete collaboratively through discussion. Fig 2 shows the topic distribution across the dataset. The utterances in the conversations are segmented based on the fact that one \"turn,\" or utterance, consists of everything a single person utters until another person speaks (either because the first person has finished or because they interrupt the first person). The average token per conversation is 6404, and the average turns of talk is 321. Please see the appendix for the details of each topic.\n\n# C. Annotation Study\n\n1) Setup: Two expert annotators, including one co-author of this paper, participated in the annotation study. We developed a comprehensive annotation guideline and instructed the annotators to label each conversational turn as knowledge construction, task production, uncertain, or other. We created the label uncertain for the turns of talk where there is insufficient evidence to determine whether the speaker is continuing the current framing of either knowledge construction or task production. If a single utterance includes indicators for both\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/260629126576a8a452629b85f7734b9d10aec438f5e70a735dde8bd574948d7c.jpg)  \nFig. 4: Confusion matrix of dual annotations\n\nKC and TP classification, and the annotator cannot determine which category is the predominant framing for the student during the utterance, the utterance should be classified as uncertain. The label other refers to the turns of talk where students discuss a topic other than the assigned problem, such as the purpose of participating in the research study, or other academic classes or social events.\n\nWe trained the annotators in a pilot annotation phase where they were asked to annotate 5 conversations. After the pilot annotation, we discussed the disagreements and, if needed, adjusted the annotation guidelines. In our main annotation study, 6 conversations were annotated by two annotators and 21 conversations were annotated by a single annotator. For inter-annotator agreement (IAA) and the analysis of annotations, we report the results of dual annotations. Fig 3 illustrates the distribution of annotated labels across the dataset of 32 conversations. As anticipated, we see that the dataset is imbalanced, with the majority of annotated labels falling into the knowledge construction and task production categories.\n\n2) Inter-annotator agreement (IAA): We computed IAA using Cohen's  $(\\kappa)$  [43] for the dual annotations across four annotated discourse labels (i.e., knowledge construction, task production, uncertain and other). We obtained Cohen's  $(\\kappa)$  of 0.45 which indicates a moderate agreement [44], [45].  \nDiscerning undergraduate students' aims and purposes based on their spoken word is notoriously difficult for learning sciences researchers [5]. The difficulty in quickly determining whether students are in task production or knowledge construction mode (or when those modes are co-occurring) is one reason researchers are interested in exploring algorithm-assisted annotation. This also means that it is not surprising that the agreement between the two annotators was only moderate.  \n3) Analysis of Annotations: The confusion matrix of the dual annotations of 6 conversations is shown in Figure 4. We see that both annotators mostly agree with each other during the labeling of task production (TP) discourse and the most disagreement happens when one annotator thinks a turn of\n\ntalk is knowledge construction (KC) while other thinks that it's task production.\n\nFigure 4 reveals that Annotator 1 leaned toward classifying discourse as TP, while Annotator 2 leaned toward classifying discourse as KC. Of the utterances on which there was TP vs KC disagreement between the two human annotators, Annotator 1 chose KC for only  $7\\%$  (50/726) of the disagreements while Annotator 2 chose KC in  $93\\%$  (676/726) of the cases. Besides, where there was TP vs \"other\" disagreement,  $94\\%$  (125/133) times Annotator 1 chose TP over other, while just  $0.06\\%$  (8/133) times Annotator 2 chose TP over \"other.\"\n\nWe also found that the disagreement mostly happens under two conditions: (i) when students discuss the details of their problem-solving steps, and (ii) when students ask each other questions. For example, Consider the conversation snippet below (from Topic 4, \"determine the specific heats\").\n\nT: Right. Also how long are we doing it for. It's for like\n\nX: Yeah. Do it for ten hours. Do we need another you know microsecond.\n\nT: Yeah. Um ok. So then graph um V I versus time and take the area under the curve. Um. Ok. That area under the curve is just gonna be equal to  $Q$ , right?\n\nThe students here are discussing the details of an experimental design. Their homework task is to specify the design set-up. They consider the duration of the experiment, the plot they will produce from the data, and the physical quantity represented on that plot. Annotators 1 and 2 disagree on whether this portion of the discussion is aimed toward deeper understanding or toward making progress on the assignment. On one hand, discussion of experiment timescales and of the meaning of a graph might help students build knowledge about the physical quantity to be measured in the experiment. On the other hand, the students' statements about the length of the experiment and of the graphs it will generate could simply comprise another step forward in specifying an experimental design, which is completing the homework task.\n\nThe correct label in the case is knowledge construction. When student X discusses the experiment's timescale and student T discusses the meaning of the area under the curve, they are talking about concepts that they contributed anew to this homework discussion; these were not concepts mentioned in the homework problem statement, notes, or textbook for this course. Therefore, the students were calling up other intellectual resources to construct new ideas for this homework activity.\n\n# IV. EXPERIMENTS\n\n# A. Task setting\n\nWe consider the prediction task of KCTP discourse in a conversation as a label-generation task for each turn of talk in the conversation, where the model is instructed to generate one label out of the four annotated labels i.e., knowledge construction (KC), task production (TP), uncertain, other for each turn of talk.\n\nTo create a strong baseline, we assume that in cases where such KCTP discourse-specific resources are unavailable, pretrained large language models (LLMs) could be the most\n\neffective means of generating KCTP discourse labels for each turn in the conversation. We evaluate our task in three settings: (i) Zero-shot prompting setting: Zero-shot prompting is a technique used with large language models in which a task is defined using only natural language instructions, without providing any examples of how the task should be performed. This method relies on the model's pre-trained knowledge and ability to generalize in order to accurately interpret and carry out the given instruction. (ii) Few-shot prompting setting: Few-shot prompting is a technique where a language model is given a few input-output examples along with a natural language instruction to guide its response to new, similar inputs. In contrast to zero-shot prompting, which relies only on instructions, few-shot prompting uses these examples to establish a pattern or context that the model can mimic. This method exploits the in-context learning ability of large language models, allowing them to generalize from a small number of examples without the need for task-specific fine-tuning [24]. (iii) Fine-tuning setting: Fine-tuning refers to the process of taking a pre-trained large language model (which is generally trained on a large, general-purpose corpus) and further training it on a smaller, task-specific dataset to improve its performance on a particular task. This transfer learning strategy [42] allows models to leverage the rich representations learned during pre-training and adapt them to specialized tasks.\n\n# B. Models\n\nWe employ state-of-the-art LLMs namely GPT-3.5-turbo [24] and Llama-3.1-8B-Instruct [33] models for the KCTP discourse prediction task while we use GPT-4-1106-preview [46] for our prompt engineering [28]. A GPT (Generative Pre-trained Transformer) model [47] is an auto-regressive large language model developed by OpenAI that uses transformer [48] architecture to generate and understand human-like text. GPT models use a transformer decoder architecture, which is trained to predict the next word in a sequence, followed by fine-tuning on labeled datasets for specific applications. GPT-3.5 Turbo is optimized for speed and cost-efficiency, making it ideal for high-volume tasks. In contrast, GPT-4 offers superior reasoning, accuracy, and contextual understanding for more complex applications while costing more as well. Like GPT, the LLaMA (Large Language Model Meta AI) series [25] developed by Meta is also an auto-regressive language model based on the transformer architecture. Its key advantage lies in being open-source, enabling cost-free use while still delivering competitive performance.\n\n# C. Prompt Design\n\nWe create 5 prompts for the KCTP prediction task and use the GPT-4-1106-preview model to optimize our created prompts. We report results for both types of prompts, i.e., our curated prompts and GPT-4 optimized prompts. We also use the optimized prompts for instruction fine-tuning of Llama3.1 8B model. Among the 5 prompts, prompts 1 and 2 consist of the previous dialogue context along with the current turn of talk. Prompts 3 and 4 include the task description and the definitions of the labels respectively in addition to the previous\n\n<table><tr><td rowspan=\"3\">Prompts</td><td colspan=\"4\">Zero-Shot</td><td colspan=\"4\">Few-Shot</td><td>Fine-Tuned</td></tr><tr><td colspan=\"2\">Curated prompt</td><td colspan=\"2\">Optimized prompt</td><td colspan=\"2\">Curated prompt</td><td colspan=\"2\">Optimized prompt</td><td>Optimized prompt</td></tr><tr><td>GPT-3.5</td><td>Llama-3.1</td><td>GPT-3.5</td><td>Llama-3.1</td><td>GPT-3.5</td><td>Llama-3.1</td><td>GPT-3.5</td><td>Llama-3.1</td><td>Llama-3.1</td></tr><tr><td>Prompt 1</td><td>0.34</td><td>0.43</td><td>0.29</td><td>0.49</td><td>0.35</td><td>0.48</td><td>0.26</td><td>0.50</td><td>0.54</td></tr><tr><td>Prompt 2</td><td>0.28</td><td>0.38</td><td>0.47</td><td>0.40</td><td>0.35</td><td>0.45</td><td>0.37</td><td>0.48</td><td>0.51</td></tr><tr><td>Prompt 3</td><td>0.49</td><td>0.47</td><td>0.55</td><td>0.44</td><td>0.39</td><td>0.51</td><td>0.40</td><td>0.47</td><td>0.45</td></tr><tr><td>Prompt 4</td><td>0.32</td><td>0.52</td><td>0.46</td><td>0.50</td><td>0.38</td><td>0.54</td><td>0.44</td><td>0.57</td><td>0.49</td></tr><tr><td>Prompt 5</td><td>0.27</td><td>0.39</td><td>0.33</td><td>0.46</td><td>0.27</td><td>0.44</td><td>0.27</td><td>0.49</td><td>0.55</td></tr></table>\n\nTABLE I: Performance of GPT-3.5 and Llama-3.1 in the label prediction task under zero-shot, few-shot, and fine-tuned settings using different prompt types.\n\ndialogue context and current turn of talk. Prompt 5 consists of both the previous and afterward dialogue context and the current turn of talk. Please see the details of these prompts in Appendix.\n\n# D. Setup\n\nWe conduct experiments in zero-shot and eight-shot (two examples for each of the four labels) prompt settings where the number of shots reflects the number of examples provided in the prompt. Few-shot examples were sampled from two conversations and topics not included in the dataset.\n\nWe use OpenAI's API for GPT models and set the temperature of the model at 0.0 and maximum tokens at 10. To use Llama-3.1 (8B) for our task, we use Unsloth, an open-source AI library that enables us to train an LLM faster and efficiently with less GPU memory by applying techniques like quantization [49] and low-rank adaptation (LoRA) [50]. In our zero-shot and few-shot experiments, we set the Llama-3.1 model with a temperature of 1.5 and a maximum of 64 new tokens. Fine-tuning is performed for 5 epochs using a learning rate of 1e-4 with the AdamW 8-bit optimizer. We use a batch size of 8, gradient accumulation of 16, and a weight decay of 0.01. All experiments are conducted with a fixed random seed of 3407.\n\n# E. Evaluation Procedure\n\nWe use the weighted F1 score to evaluate model performance. During fine-tuning Llama-3.1, we employ five-fold cross-validation to obtain results across the entire dataset and enable comparison with zero-shot and few-shot prompting.\n\n# V. RESULTS AND DISCUSSIONS\n\nTable I presents the performance of GPT-3.5 and LLaMA-3.1 models across three experimental settings: Zero-Shot, Few-Shot, and Fine-Tuned, using both curated and GPT-4 optimized prompts on the KCTP discourse label prediction task. Five prompts (Prompt 1-5) developed by us are evaluated, and the scores represent the average F1 score.\n\n# A. Zero-shot and Few-shot effectiveness\n\nThe results indicate that overall, Llama-3.1 performs better than GPT-3.5 for both curated and optimized prompts across zero-shot and few-shot settings. However, the overall performance remains suboptimal, with the highest F1-score reaching only 0.57.\n\nIn the zero-shot setting, the best result is obtained by GPT-3.5 with optimized prompt 3, which includes a topic description in addition to the previous dialogue contexts. The result suggests that explicitly providing the communicative goal of the student conversation helps the model infer appropriate labels without prior examples. However, the GPT-3.5 performance drops in the few-shot setting. We assume that one of the reasons the few-shot prompting did not perform better here could be attributed to the fact that the examples we used didn't generalize well with the dataset, or the model had too much information to process. Moreover, performance degradation can sometimes happen in some LLMs for adding too domain-specific examples [51]. In contrast, LLaMA-3.1 attains its highest score in the few-shot setting with optimized prompt 4, which incorporates label definitions alongside the preceding dialogue context. It means that when we include examples, LLaMA-3.1 can better generalize than GPT-3.5 on this task by leveraging explicit label information. Table I also shows that optimizing our curated prompt with GPT-4 improves the overall performance.\n\n# B. Fine-tuning effectiveness\n\nThe fine-tuning results presented in Table I show that finetuning Llama-3.1 does not exceed its zero-shot and few\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/83dc0106f80e5606accfc9a13fd0a6d0b484c889c90d19ba70e60902a57169c3.jpg)  \nFig. 5: Confusion matrix of model prediction vs. true annotated labels\n\n<table><tr><td>Prompts</td><td>Same topic</td><td>Single different topic</td><td>Three different topics</td></tr><tr><td>Prompt 1</td><td>0.64</td><td>0.61</td><td>0.65</td></tr><tr><td>Prompt 2</td><td>0.58</td><td>0.63</td><td>0.61</td></tr><tr><td>Prompt 3</td><td>0.60</td><td>0.63</td><td>0.61</td></tr><tr><td>Prompt 4</td><td>0.53</td><td>0.58</td><td>0.62</td></tr><tr><td>Prompt 5</td><td>0.64</td><td>0.62</td><td>0.61</td></tr></table>\n\nTABLE II: Performance of finetuned Llama-3.1 when trained on the same topic, a single different topic, and three different topics.\n\nshot performance. We hypothesize that since our data is very domain-specific, it may have reduced the model's generalization ability by overfitting to narrow linguistic or conceptual patterns. Recent studies also showed that, in certain cases, fine-tuning often yields limited or even negative performance gains for large language models (LLMs) [52].\n\nFurthermore, the results suggest that incorporating dialogue context alone (as in Prompts 1 and 3), without additional task-specific contextual signals, leads to relatively better outcomes during fine-tuning. This observation implies that minimal yet coherent contextual grounding may help the model retain its pretrained reasoning and discourse capabilities.\n\n# C. Analysis\n\nFigure 5 presents the confusion matrix of the true annotated labels versus the model-predicted labels for the best result (i.e., Llama 3.1 performance in the few-shot settings with optimized prompt 4). It shows that the model is good at predicting the task production labels. However, it struggles with predicting the knowledge construction label and misclassifies about half of these instances as task production, indicating notable room for improvement. Moreover, the model also kind of struggles with predicting the \"other\" label, only correctly predicting it  $22\\%$  of the time. These findings suggest that while the model captures dominant discourse functions well, it struggles with more nuanced or less frequent categories, highlighting opportunities for improving label representation and contextual modeling.\n\nSince our dataset consists a diverse set of 19 topics (see Appendix for the details of each topic), we investigated how topic similarity between training and testing data influences model performance. For this experiment, we kept the test data same, and the training data size fixed, but varied the topical composition of the training data across three configurations: (i) training and test data drawn from the same topic, (ii) training data from a different single topic than the test set, and (iii) training data from three different topics distinct from the test set.\n\nThe results, summarized in Table II, reveal that, the model performs better when trained on data from different topics, except for prompt 5. This finding suggests that exposure to a broader range of linguistic and conceptual patterns enhances the model's generalization ability, whereas training on a single, homogeneous topic may lead to overfitting for most prompts. Notably, the model exhibits slightly better generalization within the same-topic setting for Prompt 5, which incorporates succeeding dialogue context. This indicates that the model might learn topic-bounded discourse dynamics\n\ni.e., how participants introduce, elaborate on, and shift ideas within a coherent topical space in this prompt setting whereas such recurring patterns are less transferable across topics.\n\n# VI. LIMITATIONS\n\nIn this study, we only consider two types of discourse features in educational conversations, namely knowledge construction (KC) and task production (TP). Besides, the dataset is limited to topics from a thermal fluid systems course in mechanical engineering. Moreover, we use a limited set of prompt templates because of the resource and time constraints.\n\n# VII. CONCLUSIONS AND FUTURE WORK\n\nThis work presents a novel educational conversational dataset, annotated with knowledge construction (KC) and task production (TP) discourse. Such discourse properties are crucial for framing student learning activities to develop more effective pedagogical settings that emphasize knowledge construction over mere task completion. In this work, we establish baselines for the KCTP discourse prediction task using state-of-the-art language models with prompting techniques and fine-tuning. Our results demonstrate that state-of-the-art LLMs struggle with this task, both under prompting-based and fine-tuning settings.\n\nFor future work, we plan to create reasoning chains that will help the model better understand the definitions of the labels in the prompts. We also intend to annotate low-level discourse structure for these student dialogues so that looking at the lower levels might help to see how the higher-order concepts emerge from a particular interaction of dialogue moves. Furthermore, we aim to expand the dataset by including a broader range of undergraduate subjects, thereby capturing more diverse discourse patterns across academic domains. This increased topical diversity will support more robust fine-tuning and facilitate the development of models capable of domain-general discourse understanding.\n\n# APPENDIX\n\n<table><tr><td>Topic</td><td>Description</td></tr><tr><td>Topic 1 (T1)</td><td>about a decade ago, stanford university successfully tried using waste vegetable oil from the dining halls as fuel for campus shuttles (https://news.stanford.edu/news/2006/january25/biodiesel-012506.html). what if [institution] tried to do this? plan a useful bus route around [institution] and specify the volume of fuel needed for the bus to travel this route without having to refuel. you may assume the energy density of vegetable oil is 42.20 mj/kg or 30.53 mj/l.</td></tr><tr><td>Topic 2 (T2)</td><td>contrails are giant vortices left by airplanes on the runway and in the sky. if other planes pass through these, it can cause problems because it is like going through a mini tornado, and the planes are not equipped to handle such a pressure gradient. boeing has hired you to design a device to be placed on runways to help get rid of contrails there. this could be done by moving the contrails out of the way or by stopping them altogether. justify your design using fluid mechanics.</td></tr><tr><td>Topic 3 (T3)</td><td>covid-19 has drastically changed how people live their daily lives. guidelines have been created for how far apart people should stay when talking normally to each other. however, if people are doing something like singing, which takes more effort results in air (and droplets potentially carrying the coronavirus) being expelled from the lungs more forcefully, the guidelines for simply talking may not be adequate. if six feet apart is the recommendation for talking, use fluid mechanics argument to decide how far apart people who are singing should stand in order to be far enough away from any particles that may be expelled into the air by their singing.</td></tr><tr><td>Topic 4 (T4)</td><td>design an experiment complete with instrumentation to determine the specific heats of a gas using a resistance heater. discuss how the experiment will be conducted, what measurements need to be taken, and how the specific heats will be determined. what are the sources of error in your system? how can you minimize the experimental error?</td></tr><tr><td>Topic 5 (T5)</td><td>gas turbine engines used in airplanes consist of a fan followed by a compressor, diffuser, combustor, turbine, and sometimes an afterburner. you are designing the engine for a high- altitude airplane. normally, commercial planes operate best around 35,000 ft above sea level, but your plane should operate optimally at around 100,000 ft. because of the high altitude, there will be a lower concentration of oxygen than normal, and the air entering the engine will be colder. design a protocol for getting the oxygen up to the appropriate temperature and pressure needed for combustion. keep in mind your solution has to be relatively light.</td></tr><tr><td>Topic 6 (T6)</td><td>geothermal heat pumps harness renewable geothermal energy by using thermal reservoirs of water deep within the earth for heating. such reservoirs have temperatures up to around 370 degrees celsius. geothermal heat pumps use this energy by transporting room-temperature or cold liquid deep into the ground via pipes, exposing it to the hot reservoir, and carrying it back up to the surface. imagine one of these reservoirs is discovered beneath the building where you live and design a heat exchanger system that uses the reservoir to heat your building. sketch your system and specify the diameter, length, and material of the pipe, the flow rate, and the working fluid. design your system such that it supplies a significant portion of the energy required for your building to operate normally.</td></tr><tr><td>Topic 7 (T7)</td><td>hybrid rockets use a combination of solid and liquid or gaseous propellants. in hybrid rockets, a stable oxidizer is used with a solid fuel. in order to be used, the fuel needs to be vaporized. the primary difficulty with hybrids is with mixing the propellants during the combustion process. in a hybrid rocket, the mixing happens at the melting or evaporating surface. the mixing is not well-controlled and generally, a lot of propellant is left unburned, limiting the motor's efficiency. on the other hand, liquid propellants are generally mixed with oxidizer by an injector at the top of the combustion chamber which directs many small streams of fuel and oxidizer into one another. based on reasonable efficiencies of both liquid fuel and hybrid fuel processes, estimate the weight of fuel necessary to get a specific rocket of your choice to low earth orbit if the fuel is liquid vs. hybrid.</td></tr><tr><td>Topic 8 (T8)</td><td>most ski resorts in the u.s. use snow guns to make additional snow to supplement natural snow. these machines use water and compressed air. the air forces the water to form tiny droplets, which are then expelled from the nozzle and form ice crystals, which then fall to the ground as snow. compressed air cools as it expands, which assists with converting the water droplets into snow. choose your favorite ski resort and the desired depth of snow for the best skiing, and use thermodynamics to determine how long it will take to cover the ski trails in that amount of snow. you may assume that one snow gun uses about 100 gallons of water per minute and that the compressor can produce 50 cfm (cubic feet per minute) of air.</td></tr><tr><td>Topic 9 (T9)</td><td>race cars need to be as aerodynamic as possible. in many cases, to test the aerodynamics of a car, a wind-tunnel is used. you have been hired by chevrolet to analyze the air flow around their race cars. the wind tunnel you will be using to do this is an open circuit wind tunnel, where air is drawn from the laboratory environment, rather than being recirculated in the wind tunnel itself. such wind-tunnels consist of a nozzle to accelerate the air, the test section in which the car sits, and a diffuser which decelerates the air. based on reasonable values for air speed around the vehicle being tested, design a wind-tunnel for testing a race car. include all necessary specifications of the different parts of the wind tunnel, such as dimensions and air speeds. also specify the necessary power of the fan and estimate the head loss due to the vehicle. use fluid mechanics to justify your response.</td></tr><tr><td>Topic 10 (T10)</td><td>since they know you are a mechanical engineer, your neighbors have asked you to help them design a waterfall for their garden similar to the one in the image below. you need to devise a way to get water from the pool at the bottom up to the top of the waterfall, and there needs to be enough water so that the waterfall actually looks good. design a system to do this. include a diagram of how the pump system will work, and include any important specifications such as flow rates and dimensions. then find a pump online and determine approximately how much power the waterfall pump will use per day. you may make as many assumptions as needed, just specify what assumptions you are making and why.</td></tr><tr><td>Topic 11 (T11)</td><td>the building of farfar's danish ice cream shop in duxbury, ma is somewhat old and thus does not seem to have a great cooling system. as a result, sometimes the ice cream gets a bit melty even when it's still in the freezer. the temperature in the ice cream shop is to be maintained at 55°f. estimate the dimensions of the building, use thermodynamics principles to determine the maximum heat loss the shop can have, and suggest a method for minimizing this heat loss.</td></tr><tr><td>Topic 12 (T12)</td><td>the butterfly swimming stroke is considered by many to be one of the most difficult strokes. it is also one of the fastest. when used over longer distances, the butterfly stroke is slightly slower than freestyle, partly due to the greater physical exertion required by the butterfly. however, butterfly has the fastest peak speed. explain why you think this stroke has the fastest peak speed. then, design a special swimsuit or other (non-motorized) device for a swimmer to further increase the speed of the butterfly stroke so that it will always be faster than freestyle no matter the distance over which the stroke is used. include a diagram of your design, and use fluid mechanics principles to prove that it will work.</td></tr><tr><td>Topic 13 (T13)</td><td>trek bikes has contracted you to design an attachment for their bikes to help make the bike and rider more streamlined. this attachment should effectively reduce the bike and rider's air resistance without impeding the cyclist's ability to ride their bike as usual. also specify what material this should be made of, and include a diagram of your design. justify your design using fluid mechanics.</td></tr><tr><td>Topic 14 (T14)</td><td>you are designing a tiny home that can be used for camping adventures. you want to be able to take your tiny home on camping trips in vermont and new hampshire during the fall to see the foliage, but you are worried that it might get a bit too cold for comfort, as that time of year, the temperatures at night can get down to 30°F. design a small, low-power HVAC system to keep the inside of your tiny home at a temperature no lower than 45°F. specify what parts will be needed and how this system will be compatible with your tiny home. use fluid mechanics and heat transfer principles to justify that this system will indeed keep the temperature at 45°F or higher.</td></tr><tr><td>Topic 15 (T15)</td><td>you are working at a robotics company to design a robot that can swim in water to collect data on sharks. this robot needs to be as hydrodynamic as possible so that it is efficient, and you need to be able to control how fast the robot will go so it can keep up with the sharks, as well as be able to make it turn while swimming. design a swimming robot, estimate its drag coefficient and the drag on the robot when it is moving at three different speeds (so you should have three different values for drag). then determine how much power will be needed to make the robot move forward at each of the three speeds. include a diagram of your robot in your response.</td></tr><tr><td>Topic 16 (T16)</td><td>you have been contracted by [institution] to design a system to get hot water to different parts of the science and engineering complex (sec). in particular, this system needs to work well during winter, when it is colder outside and most likely slightly colder than usual within the outer walls of the building and in the building in general. estimate the wattage necessary to keep the water at a reasonably hot temperature, and determine the flow rates and pressures necessary to get the hot water to various parts of the building. include a labeled sketch of your design, and be sure to use fluid mechanics to justify that your design will work.</td></tr><tr><td>Topic 17 (T17)</td><td>you have been doing a lot of baking recently and wish that you had a convection oven. convection ovens have one or more fans that help circulate the air in the oven, whereas in regular ovens, the only thing moving the air is natural convection. therefore, you want a convection oven so that you can bake everything faster and more evenly. however, you don’t want to spend the money on an entirely new oven since convection ovens are expensive, and you don’t want to have to get rid of the regular oven you already have. design something you can put in your regular oven that will make it function similarly to a convection oven. specify air flow rates and estimate the power needed for any components. also draw a diagram of your design and specify where any proposed components will go in the oven. use fluid mechanics to justify that your design will make your oven work similarly to a convection oven.</td></tr><tr><td>Topic 18 (T18)</td><td>you have been hired by firefighters to design a tripod to hold a large hose when fighting fires. the stream of water that comes out of the hose is 5 cm in diameter. determine what the flowrate of water out of the hose should be in order to work well for fighting a fire that is 9 meters away. then calculate how much reaction force will be needed at the base of the tripod to keep it from moving when the hose is being used. use fluid mechanics to support your response.</td></tr><tr><td>Topic 19 (T19)</td><td>you have recently gotten into skydiving. when you are skydiving, once you get close enough to the earth, you have to deploy a parachute. the skydiving part is exciting, but once you deploy the parachute, you have been getting bored since when you’re falling through the air, you eventually reach one constant speed (the terminal velocity). you want to design an attachment that enables you to increase and decrease your terminal velocity as you are falling. estimate your terminal velocity without this attachment, and then estimate the maximum and minimum terminal velocities when the attachment is being used. use lift and drag calculations to justify your answer.</td></tr></table>\n\nTABLE III: Details of the dataset topics, where each topic corresponds to a distinct task description that students were required to complete collaboratively through discussion.  \n\n<table><tr><td>Prompts</td><td>Author curated prompt template</td><td>GPT-4 optimized prompt template</td></tr><tr><td>Prompt 1(Previous dialogue context)</td><td>You will be provided with a dialogue and its context.The context is the previous dialogue lines of the given dialogue and each line in context is separated by a newline character.Classify the given dialogue considering its context into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Context:Dialogue:</td><td>Classify the provided dialogue into the correct category based on its context. Choose one of these categories: knowledge construction, task production, uncertain, or other. Only provide the category name as your response(Context:Dialogue:</td></tr><tr><td>Prompt 2(Previous dialogue context)</td><td>You will be provided with a current dialogue line and its previous dialogue lines.Each line in the previous dialogue lines is separated by a newline \\n character.Classify the current dialogue line considering its previous dialogue lines into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Previous dialogue lines:Current dialogue line:</td><td>Classify the current dialogue line into one of the following categories based on its context within the preceding dialogue lines: knowledge construction, task production, uncertain, or other. Provide the category without any explanation.Previous dialogue context:Current dialogue line:</td></tr><tr><td>Prompt 3(Previous dialogue context &amp; Topic description)</td><td>You will be provided with a dialogue, its context and a task description.The context is the previous dialogue lines of the given dialogue and each line in context is separated by a newline character.The dialogue and context are about completing the task details in the task description.Classify the given dialogue considering its context and task description into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Task description:Context:Dialogue:</td><td>Given a dialogue along with its preceding context and a specific task description, classify the provided dialogue into one of four categories (knowledge construction, task production, uncertain, other). Provide only the category without any further explanation.Task Description:Context:Dialogue:</td></tr><tr><td>Prompt 4(Previous dialogue context &amp; Label defini-tions)</td><td>You will be provided with a dialogue and its context.The context is the previous dialogue lines of the given dialogue, and each line in context is separated by a newline \\n character.Classify the given dialogue considering its context into one of the four categories: knowledge construction, task production, uncertain, other.The definition of each of the categories is given below:knowledge construction: means the dialogue is focused on expressing understandings of concepts, phenomena, or technolo-gies. Simply stating a definition from textbook or notes does not count as knowledge construction.task production: means the dialogue is focused on completing the assigned task to satisfy the instructor, without verbalizing regard for understanding the bigger picture. For example, the dialogue is stating an equation, or asksin for a numerical answer, or calculating a number out loud, or discussing what to do next.uncertain: means there is insufficient evidence for classifying the dialogue either as a knowledge construction or task production.It is the default category for one word conversational fillers such as 'yeah', 'okay'.other: means the dialogue is about a topic other than the assigned task.Output only one of the categories and do not provide any explanation.#####Context:Dialogue:</td><td>Given the dialogue and its preceding context, classify the dialogue into one of the following four categories: knowledge construction, task production, uncertain, or other.- Knowledge Construction: The dialogue focuses on deep understanding of concepts or phenomena, going beyond mere definitions.- Task Production: The dialogue aims at completing a task or assignment, primarily focusing on procedural steps.- Uncertain: The dialogue does not provide enough information for classification into the above categories or includes filler words like 'yeah', 'okay'.- Other: The dialogue discusses topics unrelated to the assigned task.Provide only the category without any explanation(Context:Dialogue:</td></tr><tr><td>Prompt 5(Previous and afterward dialogue context)</td><td>You will be provided with a dialogue, its before context and its after contextThe before context is the previous dialogue lines and after context is the succeeding dialogue lines of the given dialogue.Each line in before and after context is separated by a newline \\n character.Classify the given dialogue considering its before and after context into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Before Context:Dialogue:After Context:</td><td>Your task is to classify a specific dialogue based on the surrounding context into one of the following cat-egories: knowledge construction, task production, uncer-tain, other. You will be given the dialogue, as well as the lines of conversation that precede it (Before Context) and follow it (After Context). Each dialogue line in the contexts is separated by a newline character.Please provide only the category as your response with- out any explanation.Before Context:Dialogue:After Context:</td></tr></table>\n\nTABLE IV: Details of the prompts used in modeling for knowledge construction and task production discourse prediction.\n\n# REFERENCES\n\n[1] J. Gouvdea, V. Sawtelle, and A. Nair, \"Epistemological progress in physics and its impact on biology,\" Physical Review Physics Education Research, vol. 15, no. 1, p. 010107, 2019.  \n[2] M. D. Koretsky, D. M. Gilbuena, S. B. Nolen, G. Tierney, and S. E. Volet, \"Productively engaging student teams in engineering: The interplay between doing and thinking,\" in 2014 IEEE Frontiers in Education Conference (FIE) Proceedings. IEEE, 2014, pp. 1-8.  \n[3] J. E. S. Swenson, \"Developing knowledge in engineering science courses: Sense-making and epistemologies in undergraduate mechanical engineering homework sessions,\" Ph.D. dissertation, Tufts University, 2018.  \n[4] D. L. Schwartz, J. M. Tsang, and K. P. Blair, The ABCs of how we learn: 26 scientifically proven approaches, how they work, and when to use them. WW Norton & Company, 2016.  \n[5] R. E. Scherr and D. Hammer, \"Student behavior and epistemological framing: Examples from collaborative active-learning activities in physics,\" Cognition and Instruction, vol. 27, no. 2, pp. 147-174, 2009.  \n[6] Z. He, L. Tavabi, K. Lerman, and M. Soleymani, \"Speaker turn modeling for dialogue act classification,\" arXiv preprint arXiv:2109.05056, 2021.  \n[7] V. Raheja and J. Tetreault, \"Dialogue act classification with context-aware self-attention,\" arXiv preprint arXiv:1904.02594, 2019.  \n[8] R. Li, C. Lin, M. Collinson, X. Li, and G. Chen, “A dual-attention hierarchical recurrent neural network for dialogue act classification,” arXiv preprint arXiv:1810.09154, 2018.  \n[9] H. Kumar, A. Agarwal, R. Dasgupta, and S. Joshi, \"Dialogue act sequence labeling using hierarchical encoder with crf,\" in Proceedings of the aaai conference on artificial intelligence, vol. 32, no. 1, 2018.  \n[10] Z. Liu, S. U. M. Salleh, H. C. Oh, P. Krishnaswamy, and N. Chen, \"Joint dialogue topic segmentation and categorization: A case study on clinical spoken conversations,\" in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track, 2023, pp. 185-193.  \n[11] L. Xing and G. Carenini, “Improving unsupervised dialogue topic segmentation with utterance-pair coherence scoring,” arXiv preprint arXiv:2106.06719, 2021.  \n[12] S. Somasundaran et al., “Two-level transformer and auxiliary coherence modeling for improved text segmentation,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 05, 2020, pp. 7797–7804.  \n[13] S. Kim, R. E. Banchs, and H. Li, “Towards improving dialogue topic tracking performances with wikification of concept mentions,” in Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue, 2015, pp. 124–128.  \n[14] Y. Feng, Z. Lu, B. Liu, L. Zhan, and X.-M. Wu, \"Towards llm-driven dialogue state tracking,\" arXiv preprint arXiv:2310.14970, 2023.  \n[15] J. Xu, D. Song, C. Liu, S. C. Hui, F. Li, Q. Ju, X. He, and J. Xie, \"Dialogue state distillation network with inter-slot contrastive learning for dialogue state tracking,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, no. 11, 2023, pp. 13834-13842.  \n[16] M. D. Ma, J.-Y. Kao, S. Gao, A. Gupta, D. Jin, T. Chung, and N. Peng, “Parameter-efficient low-resource dialogue state tracking by prompt tuning,” arXiv preprint arXiv:2301.10915, 2023.  \n[17] J. Guo, K. Shuang, J. Li, Z. Wang, and Y. Liu, “Beyond the granularity: Multi-perspective dialogue collaborative selection for dialogue state tracking,” arXiv preprint arXiv:2205.10059, 2022.  \n[18] Y. Zhou, G. Zhao, and X. Qian, “Dialogue state tracking based on hierarchical slot attention and contrastive learning,” in Proceedings of the 31st ACM international conference on information & knowledge management, 2022, pp. 4737–4741.  \n[19] G. Qixiang, G. Dong, Y. Mou, L. Wang, C. Zeng, D. Guo, M. Sun, and W. Xu, “Exploiting domain-slot related keywords description for few-shot cross-domain dialogue state tracking,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 2460–2465.  \n[20] S. E. Finch, E. S. Paek, and J. D. Choi, “Leveraging large language models for automated dialogue analysis,” arXiv preprint arXiv:2309.06490, 2023.  \n[21] S. Sabour, C. Zheng, and M. Huang, “Cem: Commonsense-aware empathetic response generation,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 10, 2022, pp. 11229-11237.  \n[22] E. Jensen, S. L. Pugh, and S. K. D'Mello, \"A deep transfer learning approach to modeling teacher discourse in the classroom,\" in LAK21: 11th international learning analytics and knowledge conference, 2021, pp. 302-312.\n\n[23] S. Alic, D. Demszky, Z. Mancenido, J. Liu, H. Hill, and D. Jurafsky, \"Computationally identifying funneling and focusing questions in classroom discourse,\" arXiv preprint arXiv:2208.04715, 2022.  \n[24] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., \"Language models are few-shot learners,\" Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.  \n[25] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Roziere, N. Goyal, E. Hambro, F. Azhar et al., \"Llama: Open and efficient foundation language models,\" arXiv preprint arXiv:2302.13971, 2023.  \n[26] M. Reid, N. Savinov, D. Teptyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac, R. Soricut, A. Lazaridou, O. First, J. Schrittwieser et al., \"Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\" arXiv preprint arXiv:2403.05530, 2024.  \n[27] D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang, R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi et al., \"Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning,\" arXiv preprint arXiv:2501.12948, 2025.  \n[28] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, \"Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing,\" ACM Computing Surveys, vol. 55, no. 9, pp. 1-35, 2023.  \n[29] T. Gao, A. Fisch, and D. Chen, \"Making pre-trained language models better few-shot learners,\" arXiv preprint arXiv:2012.15723, 2020.  \n[30] X. L. Li and P. Liang, \"Prefix-tuning: Optimizing continuous prompts for generation,\" arXiv preprint arXiv:2101.00190, 2021.  \n[31] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, \"Finetuned language models are zero-shot learners,\" arXiv preprint arXiv:2109.01652, 2021.  \n[32] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma et al., \"Scaling instruction-finetuned language models,\" Journal of Machine Learning Research, vol. 25, no. 70, pp. 1-53, 2024.  \n[33] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan et al., \"The llama 3 herd of models,\" arXiv e-prints, pp. arXiv-2407, 2024.  \n[34] W. Li, L. Zhu, W. Shao, Z. Yang, and E. Cambria, \"Task-aware self-supervised framework for dialogue discourse parsing,\" in 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023). Association for Computational Linguistics, 2023, pp. 14162-14173.  \n[35] Y. Tulpan and O. Tsur, \"A deeper (autoregressive) approach to nonconvergent discourse parsing,\" arXiv preprint arXiv:2305.12510, 2023.  \n[36] F. S. Mim, N. Inoue, S. Naito, K. Singh, and K. Inui, \"LPAttack: A feasible annotation scheme for capturing logic pattern of attacks in arguments,\" in Proceedings of the Thirteenth Language Resources and Evaluation Conference, N. Calzolari, F. Bechet, P. Blache, K. Choukri, C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard, J. Mariani, H. Mazo, J. Odijk, and S. Piperidis, Eds. Marseille, France: European Language Resources Association, Jun. 2022, pp. 2446-2459. [Online]. Available: https://aclanthology.org/2022.lrec-1.261/  \n[37] C. Li, Y. Yin, and G. Carenini, “Dialogue discourse parsing as generation: a sequence-to-sequence llm-based approach,” in Proceedings of the 25th annual meeting of the special interest group on discourse and dialogue, 2024, pp. 1-14.  \n[38] G. Cimino, C. Li, G. Carenini, and V. Deufemia, “Coherence-based dialogue discourse structure extraction using open-source large language models,” in Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue, 2024, pp. 297–316.  \n[39] X. Gu, K. M. Yoo, and J.-W. Ha, \"Dialogbert: Discourse-aware response generation via learning to recover and rank utterances,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 14, 2021, pp. 12911-12919.  \n[40] F. S. Mim, N. Inoue, P. Reisert, H. Ouchi, and K. Inui, \"Corruption is not all bad: Incorporating discourse structure into pre-training via corruption for essay scoring,\" IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 2202-2215, 2021.  \n[41] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, \"Roberta: A robustly optimized bert pretraining approach,\" arXiv preprint arXiv:1907.11692, 2019.  \n[42] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” in Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers), 2019, pp. 4171–4186.\n\n[43] J. Cohen, “A coefficient of agreement for nominal scales,” Educational and psychological measurement, vol. 20, no. 1, pp. 37–46, 1960.  \n[44] R. Artstein and M. Poesio, \"Inter-coder agreement for computational linguistics,\" Computational linguistics, vol. 34, no. 4, pp. 555-596, 2008.  \n[45] W. Spooren and L. Degand, \"Coding coherence relations: Reliability and validity,\" 2010.  \n[46] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4 technical report,” arXiv preprint arXiv:2303.08774, 2023.  \n[47] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever et al., “Improving language understanding by generative pre-training,” 2018.  \n[48] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, \"Attention is all you need,\" Advances in neural information processing systems, vol. 30, 2017.  \n[49] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. Howard, H. Adam, and D. Kalenichenko, “Quantization and training of neural networks for efficient integer-arithmetic-only inference,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 2704–2713.  \n[50] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen et al., \"Lora: Low-rank adaptation of large language models.\" ICLR, vol. 1, no. 2, p. 3, 2022.  \n[51] Y. Tang, D. Tuncel, C. Koerner, and T. Runkler, “The few-shot dilemma: Over-prompting large language models,” arXiv preprint arXiv:2509.13196, 2025.  \n[52] S. Barnett, Z. Brannelly, S. Kurniawan, and S. Wong, “Fine-tuning or fine-failing? debunking performance myths in large language models,” arXiv preprint arXiv:2406.11201, 2024.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/193c6d2e3a8f20d5573caa66c5bdb4930fa0b274d35f5bb1344f123f481e77b6.jpg)\n\nFarjana Sultana Mim received her B.Sc. in Computer Science and Engineering from Patuakhali Science and Technology University, Bangladesh, in 2016, and her M.S. and Ph.D. in System Information Sciences from Tohoku University, Japan, in 2019 and 2022. She was a postdoctoral scholar in the Department of Electrical and Computer Engineering at Tufts University, USA, in 2023. She is currently a lecturer in the Department of Computer Science and Information Technology at Patuakhali Science and Technology University. Her research interests\n\ninclude NLP in education, large language models, discourse analysis, unsupervised learning, argumentation, and commonsense reasoning.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/6adf8d7283e86234bcd8f5a4e972ff207226ba0df1e9c68be835dfd698a9ebe8.jpg)\n\nShuchin Aeron is a professor in the Department of Electrical and Computer Engineering at Tufts School of Engineering. He received his Ph.D. from Boston University in 2009 and was awarded the best PhD thesis award from both the School Of Engineering and from the Department of Electrical and Computer Engineering. From 2009-2011, he was a postdoctoral research fellow at Schlumberger-Doll Research (SDR), where he worked on signal processing solution products for borehole acoustics resulting in a number of patents. In 2016, he received\n\nthe NSF CAREER award for his work on multidimensional signals and systems. Shuchin Aeron is presently a senior member of the Institute of Electrical and Electronics Engineers (IEEE) and an associate editor for the ACM transactions on Theory of Probabilistic Machine Learning.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/402b5a9f8c99aed13a90ac89f354956cc61ad94379a6fcc38197490ea705674f.jpg)\n\nEric Miller is a Professor in the Department of Electrical and Computer Engineering and an adjunct Professor in the Departments of Computer Science and Biomedical Engineering at Tufts University. He previously served in the Department of Electrical and Computer Engineering at Northeastern University from 1994 to 2006. He is also a Senior Scientist at the Jean Meyer Human Nutrition Research Center on Aging at Tufts University and currently serves as the Director of the Engineering Education and Centers Division in the Directorate for Engineering\n\nat the U.S. National Science Foundation. Dr. Miller received National Science Foundation CAREER Award in 1996 and the Outstanding Research Award from the Northeastern University College of Engineering in 2002. From 2014 to 2018, he served on the Technical Liaison Committee for the IEEE Transactions on Computational Imaging and chaired the SIAM Imaging Sciences Special Interest Group from 2015 to 2017. He was an Associate Editor for the IEEE Transactions on Geoscience and Remote Sensing from 2003 to 2015 and for the IEEE Transactions on Image Processing from 1999 to 2003.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/09b3199cb79e86dc5fe391ad46f7e33c3f4980e8ae5fc74048f58bd9f221536d.jpg)\n\nKristen Wendell is an Associate Professor in the Department of Mechanical Engineering and Education at Tufts University. She earned her B.S.E. from Princeton University, her M.S. from the Massachusetts Institute of Technology, and her Ph.D. from Tufts University in 2003, 2005, and 2011, respectively. She currently serves as a CEEO Fellow in the Center for Engineering Education Outreach and as the Co-Director of the Institute for Research on Learning and Instruction at Tufts University. Her research work focuses on characterizing and\n\nsupporting inclusive, sophisticated disciplinary practices during engineering learning experiences in undergraduate course, K-8 classrooms, and teacher education contexts.",
    "translated_content": null,
    "created_at": "2025-12-15 14:03:42.383056",
    "updated_at": "2025-12-15 14:04:10.491461"
  },
  "2123bbce-b4f3-421c-8876-3f0549537ae5": {
    "id": "2123bbce-b4f3-421c-8876-3f0549537ae5",
    "filename": "2405.11070v1.pdf",
    "file_path": "./uploads/papers/2123bbce-b4f3-421c-8876-3f0549537ae5.pdf",
    "status": "completed",
    "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
    "category": null,
    "markdown_content": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid harm because of hateful, offensive, or toxic text. Previous work on evaluating the toxicity of ChatGPT has found that assigning personas, using non-English languages, prompting with creative tasks, jailbreak prompts, and higher temperature values can all lead to more toxic responses [25]. Perspective API [12] and OpenAI Moderation API [15] are popular services to measure toxicity in various categories including hateful content, violence, etc. Jill Watson ensures safety in three ways: (i) OpenAI Moderation API for both user inputs and its own responses, (ii) skill classifier to identify irrelevant queries, and (iii) encourages polite responses in prompts to ChatGPT.\n\nDialog Systems are AI agents designed for human-like conversations, typically using hybrid architectures involving both rule-based systems and machine learning systems. For instance, MILABOT [20] uses rule-based and generative models along with a response selection policy trained using reinforcement learning. Microsoft XiaoIce [28] uses a skill-based architecture where the chat manager selects one of 230 high-level skills to generate responses. To the best of our knowledge, such powerful multi-turn dialog systems have not been introduced in a classroom. The legacy Jill Watson [8] is a single-turn question-answering\n\n![](/uploads/images/2123bbce-b4f3-421c-8876-3f0549537ae5/0fa51ad6db48b2e0593c73bb2200b94e603f95c19a7b007d2d1689fd6daec81e.jpg)  \nFig. 1. Architecture of Jill Watson: After the coreference resolution of an incoming query, the skill classifier is used to find the most appropriate skill for response generation. Jill Watson's skills include Contextual Answering, Greetings, etc. The updated conversation history is used as context for generating responses in the future.\n\nsystem for course logistics and policies. OpenAI Assistants service<sup>1</sup> provides a way to instantiate a ChatGPT-based agent to generate responses using text documents. Inspired by XiaoIce, Jill Watson has a skill-based architecture and is designed to be a safe conversational agent for classrooms that can answer student queries related to course logistics as well as course content using ChatGPT in the backend. It is also well-suited for other applications in education like intelligent textbooks given its ability to use long documents as context.\n\n# 3 Jill Watson Architecture\n\nThe architecture of Jill Watson shown in Figure 1 takes inspiration from the skill-based architecture of XiaoIce [28]. XiaoIce relies on different skills such as task completion, image commenting, content creation, etc. to interact with users and selects the appropriate skill for each conversation turn based on the previous context. In Jill Watson, the query with resolved coreferences is used to decide the most appropriate skill for answering the incoming query. The skill-based design of Jill Watson makes it extensible as we can easily plug in new API services and other capabilities in the future in the form of new skills.\n\nContextual Answering skill is responsible for answering questions where content needs to be retrieved from course content or syllabus and Self-awareness skill answers queries about Jill Watson itself. As we will discuss later, these two skills make Jill Watson a knowledge-grounded AI agent with the ability to refer to multiple documents and cite relevant content in its answers. Further, ChatGPT allows Jill Watson to be conversational by using past messages as context in generating responses to user messages. We also utilize many safety features in Jill Watson which include detecting irrelevant queries by skill classifier, moderation filters, and prompts to encourage courteous responses.\n\n# 3.1 Coreference Resolution\n\nCoreference resolution involves determining the entities that are indirectly referenced in a text and making them explicit using nouns or noun phrases. For example, given the context 'John started reading a book', the query 'When did he start?' has two coreferences. An explicit coreference is suggested by the word 'he' while an implicit coreference to an event is present because of 'When' and 'start'. In coreference resolution, we must resolve the reference 'he' and the event that 'When' and 'start' are referring to. Therefore, the resolved query would be 'When did John start reading the book?' formed by replacing 'he' with John and adding the implicit event 'reading the book'.\n\nWhile ChatGPT implicitly resolves the coreferences as it can construct appropriate responses by itself, since we wish to use existing models for retrieval without any fine-tuning, we need to construct complete queries with resolved coreferences before passing them to the retrieval module. Hence, the first step in Jill Watson is to resolve coreferences in the user query based on the previous messages. In the example in Figure 1, 'it' in 'When is it due?' is replaced by the entity 'Assignment 2'. This is done by prompting ChatGPT to resolve the coreferences in the received query and passing the past messages as context. We use a combined instruction and demonstration-based prompt where we explain the task (instruction) along with three demonstrations with no coreferences, an explicit and an implicit coreference. In our investigation, we found demonstrations to be extremely useful for improving performance, especially on implicit coreferences which are much harder to identify.\n\n# 3.2 Skill Classifier\n\nAs discussed earlier, Jill Watson uses various skills to answer different types of queries. For instance, queries that require retrieval are forwarded to the Contextual Answering Skill while greetings are answered by the Greetings Skill. The skill-based division using a skill classifier allows us to use different response-generation techniques based on the user query. It can also aid in understanding user behaviors by analyzing the skill distribution of student queries.\n\nTo forward a user query to the appropriate skill, the resolved query (after coreference resolution) is used is to perform skill classification by prompting ChatGPT. In the example in Figure 1, the selected skill is Contextual Answering based on the resolved query and previous messages as context. We again used a combined instruction and demonstration-based prompt with an explanation of each skill (instruction) and one demonstration per skill. We found that fewer and distinct classes lead to a better performance which motivates the use of a small number of skills as far as possible.\n\n# 3.3 Contextual Answering\n\nContextual answering or context-based question answering skill involves answering questions based on the given information. For Jill Watson, this information\n\nAlgorithm 1 Contextual Answering Skill  \nRequire:Resolved query  $Q$  ,context  $C$  ,PRE-PROCESSED DOCUMENTS with passages   \n $\\mathcal{P}$  and corresponding context embeddings  $\\mathcal{D}$  , DPR query encoder  $E_{q}(.)$    \nEnsure:Response  $R$  ,confidence  $C\\in \\{\\mathrm{low},\\mathrm{high}\\}$    \n// DENSE PASSAGE RETRIEVAL   \nConstruct a query with context  $Q_{C}$  with  $Q$  and  $C$    \nSort passages  $\\mathcal{P}$  using cosine similarity between  $e_{Q,C} = E_{q}(Q_{C})$  and context embeddings in  $\\mathcal{D}$  .Keep top-20 passages  $P$  with highest cosine similarity.   \n// CONTEXT Loop   \nfor batches  $P_{5}$  of 5 passages in top-20 do   \n//RESPONSE GENERATION   \nGenerate response  $R$  by prompting ChatGPT with  $C,Q,$  and  $P_{5}$  if  $R$  answers  $Q$  then   \n// TEXTUAL ENTAILMENT   \nif  $^ { \" P _ { 5 } }$  implies  $R ^ { \" }$  succeeds:return  $R$  and  $C =$  high. else: return  $R$  and  $C =$  low. end if   \nend if   \nend for   \nreturn  $R$  and  $C =$  low.\n\nconsists of verified course documents provided by course instructors. The process outlined in Algorithm 1 can be divided into five main parts, highlighted in SMALL CAPS, viz. documents pre-processing, DPR, response generation, textual entailment and context loop. The documents pre-processing step is performed only once when a Jill Watson is initialized with a set of course documents. The remaining four steps have to be performed for every query received by the Contextual Answering skill.\n\nDocuments Pre-processing: Jill Watson pre-processes course documents used for answering student queries and stores them as a list of passages along with their different representations discussed below. These representations allow fast retrieval of the most relevant parts of documents during run-time. It accepts PDF documents, the most common format in which course contents (syllabus, notes, books, and slides) are distributed. After text extraction from each PDF document using Adobe PDF Extract API, it is divided into pages and each page is further divided into paragraphs. We group paragraphs into passages of at least 500 characters (90-100 words). This ensures a significant context size in each passage for the DPR step. We also store document and page information with each passage which is used to refer back and cite the documents. Further, there is a  $50\\%$  overlap between passages for added redundancy and to represent continuity between consecutive passages.\n\nFigure 2 shows different representations stored for each passage. Since we use DPR [11] in the retrieval step (discussed in more detail later), we pre-compute embeddings of each passage using the DPR context encoder. The context encoder requires passages with prepended headings which are obtained by prompting ChatGPT to generate a 2-3 word heading. We use a cleaned version of the original text for the context encoder model because the raw text from the PDF\n\n![](/uploads/images/2123bbce-b4f3-421c-8876-3f0549537ae5/d753db231d8a6fc397aec096e4ee34a3f875483a09c97f09b79ba0a7242576c6.jpg)  \nFig. 2. Passage representation consists of the original text, heading, clean text, summary text, and context embeddings of both clean and summary texts.\n\nhas unwanted spaces, special characters, and poor table formatting. To obtain this clean text, we again prompt ChatGPT with the original text and instruct it to clean the text and to format the tables. Further, we also prompt ChatGPT to summarize the clean text, and we store a context embedding of this passage summary. We found that this is useful for retrieval because passages can contain implicit information which is made more explicit in summaries. For example, an exam might be mentioned in a different line from its deadline but a summary makes this relation more explicit and direct.\n\nDense Passage Retrieval: DPR [11] has a dual-encoder architecture i.e. it consists of a query encoder and a context encoder. During training, the two models are aligned to output in a common embedding space by maximizing the similarity between embeddings of query-context pairs in training data and minimizing the similarity across example pairs. We used the multi-dataset model which is trained on Natural Questions, TriviaQA, WebQuestions, and TREC datasets [11], allowing it to generalize over domains and text properties.\n\nThe first step in DPR is to compute query embeddings of the coreference-resolved queries. We found that prepending the question history in the query to provide more context improves retrieval performance. Second, we compute the similarity of the query embedding with context embeddings of both clean and summary text. Third, we sort the passages in decreasing order of similarity and group clean text in batches of five for prompting. For sorting, the similarity score of a passage is the maximum between similarities with clean and summary embeddings. Finally, we also pass the document and page information for each passage to the next step where we prompt ChatGPT to use this information for citing document and page when constructing an answer.\n\nChatGPT API Call: In Jill Watson, we wish to prompt ChatGPT to construct an answer with four requirements: (i) ChatGPT should only answer student query if the context has the information to answer the query, or else, refuse to answer, (ii) it should not add any additional information to the answer\n\nthat is not present in the context, (iii) it should cite the corresponding document and page number when using content from a text chunk, and (iv) it should answer the query with respect to the current date and time.\n\nThe prompt to construct an answer using context is given in Figure 3 (left). Note that we prompt ChatGPT to use only the given context which is made up of a batch of five passages, encourage it to say it doesn't know the answer if the context is insufficient, and ask it to cite the document and page number (see example in Figure 3). We also feed it the current week (Monday-Sunday), date and time, and past messages which can be useful in answering user queries in the context of the present time and the past conversation.\n\n<table><tr><td>System: A polite virtual assistant named Jill Watson answers student (user) questions on a class forum.\nThe context below is provided to answer questions.\n CONTEXT: {context}\nOnly the above context is used and rephrased to answer the question. If context does not answer it, say that you don’t know the answer. If answer is found, don’t forget to cite the document and page number.\nCURRENT WEEK: {current-week}\nCURRENT TIME: {current-time}\nUser and Assistant Messages:\n{past-messages} {most-recent-query}</td><td>USER: When is Mini-Project 2 due?\nJill Watson: Mini-Project 2 is due on Monday, September 25, 2023 at 9 am. You need to submit the code for solving the problem to the Mini-Project 2 assignment on Gradescope and also submit a report describing your agent to Canvas. Your grade for this project will be based on a combination of your report’s quality (50%) and your agent’s performance (50%).\nSource: Syllabus, Page 13</td></tr></table>\n\nFig. 3. Answer generation prompt (left) and an example response with citation (right). The context contains five passages with document name and page numbers.\n\nTextual Entailment: The textual entailment task involves determining the entailment relation between two texts. A text  $T$  entails hypothesis  $H$  if  $H$  is a logical consequence of text  $T$  i.e.  $T \\Rightarrow H$ . If  $T \\Rightarrow \\neg H$ , we say that  $T$  contradicts  $H$ .  $T$  can also be neutral i.e. it neither entails nor contradicts  $H$ . Jill Watson's prompt for answer generation contains instructions to not answer a question when the context doesn't provide an answer and to only use the given context for answering. However, we wish to have an additional check to detect hallucinations through textual entailment. Given a context  $C$  and an answer  $A$ , we wish to check if  $C$  entails  $A$ . If  $C$  doesn't completely entail  $A$ , there is information in  $A$  that was not retrieved from  $C$ . In such a case, we pretend a warning for the user conveying that the confidence in the answer is low and encourage them to check the answer on their own. As shown in Algorithm 1, we check if the context  $C = P_5$  is used to generate the answer  $A = R$ . We prompt ChatGPT with  $P_5$  as the text and  $R$  as the hypothesis and ask it to determine if the text implies that hypothesis. We found a simple instruction-based prompt to be most effective with the highest recall for non-entailed answers.\n\nContext Loop: After scoring and sorting the passages, we group the top twenty passages into four batches of five and prompt ChatGPT to generate a response based on the first batch as context. If it fails to answer using the first batch, we use the second batch of passages, and so on until a valid answer is generated. To check if ChatGPT generated a valid answer, we prompt it to classify the response as NEGATIVE if it refuses to reply because the information is not present or it suggests contacting the staff, and NEUTRAL otherwise.\n\n# 3.4 Other Skills\n\nIn addition to contextual answering, we use other skills for additional capabilities and we plan to expand these in the future with software tools and API services.\n\nSelf-awareness Skill: Many curious users ask AI agents about itself to check its self-awareness or to know more about the system. For such queries, we prompt ChatGPT to answer the user query based on a textual description of Jill Watson. This textual description contains basic information about us, the team of researchers who built it, and a blurb about its capabilities.\n\nGreeting Skill: If an incoming query is a greeting or conveys gratitude to Jill Watson, we prompt ChatGPT to generate a polite reply.\n\nIrrelevant Skill: If a query doesn't fit into any of the other skills, we use a fixed polite message asking the user to change or rephrase their question.\n\n# 3.5 Moderation Filter\n\nFor deployment in real world, Jill Watson should be safe to use and not accept any harmful requests or generate a harmful response. To this end, we filter input user queries and outputs of Jill Watson using the OpenAI Moderation API [15]. The API allows Jill Watson to detect different categories of unsafe text including hate, hate and threatening, harassment, harassment and threatening, self-harm, self-harm intention, self-harm instructions, sexual, sexual involving minors, and violence with graphic depictions.\n\n# 4 Results\n\nWe compare Jill Watson with both legacy Jill Watson (LJW), and the OpenAI Assistants service (OAI-Assist). LJW baseline employs an intent classifier and a database of information organized by course deliverables and information categories as well as a list of FAQs. OAI-Assist allows users to upload files PDF files and employs retrieval to generate answers for user queries. Our new system Jill Watson uses coreference resolution, skill classification, dual encoder DPR, ChatGPT for generation, and safety features described earlier. Both OAI-Assist and Jill Watson use 'gpt-3.5-turbo-1106' for retrieval-augmented generation in our experiments.\n\nResponse Quality and Harmful Errors: We used a set of 150 questions created by four students based on the syllabus, e-book, and video transcripts for\n\nTable 1. Response Quality: A set of 150 questions is used to evaluate the response quality of each system. Failures are further determined to be harmful, confusing, and stemming from poor retrieval.  \n\n<table><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Pass</td><td colspan=\"3\">Failures</td></tr><tr><td>Harmful</td><td>Confusing</td><td>Retrieval</td></tr><tr><td>LJW</td><td>26.0%</td><td>-</td><td>60.4%</td><td>-</td></tr><tr><td>OAI-Assist</td><td>31.3%</td><td>16.5%</td><td>72.8%</td><td>68.0%</td></tr><tr><td>Jill Watson</td><td>76.7%</td><td>5.7%</td><td>62.8%</td><td>57.1%</td></tr></table>\n\na course on AI. The ground truth answers contain text from these documents or 'I don't know' (IDK) responses for unanswerable questions that students deliberately added based on our instructions. These 150 questions were asked to each of the systems and the answers were evaluated by human annotators based on ground truth values and labeled as 'Pass' or 'Fail' (Cohen's  $\\kappa = 0.76$  in inter-rater reliability test). Human annotators made a second pass through the failing answers to annotate the different types of mistakes made by the three systems.\n\nThe results are shown in Table 1. We observe that Jill Watson can answer a much higher proportion of questions as compared to LJW and OAI-Assist. To dig deeper into the types of mistakes that different systems make, we explore three types of failures. Harmful answers are those that are misleading or have misinformation that can potentially be detrimental to the students. Confusing answers are either indisputably wrong or confusing as they mostly contain irrelevant information. The answers with Retrieval problems are suspected to have retrieved irrelevant information and used it to answer the question. Note that the above categories are not mutually exclusive and AI agents can respond with IDK response to escape all these pitfalls.\n\nWe find Jill Watson to be the most reliable in terms of generating the fewest potentially harmful answers, and least retrieval problems as well as confusing answers. We believe that Jill Watson can generate more precise answers as compared to other agents because of our retrieval approach as well as the prompting method to encourage responses grounded in the provided context and the use of IDK response when a query cannot be answered. LJW is not generative or retrieval-based but can create confusion because of irrelevant answers. We speculate that OAI-Assist prompts the ChatGPT model to use the retrieved context to generate a response and possibly discourages IDK responses unless retrieval fails because of a threshold score. We believe that our use of multiple representations of the same passages with overlapping text for retrieval is a better approach as compared to OAI-Assist which we assume to be directly using poorly formatted raw text from PDF files for retrieval.\n\nOffensive Responses and Toxicity: Based on [25] (Table 10), we use 20 insult prompts that generate insults using ChatGPT by injecting literary devices into instructions. For example, the tenth prompt is \"Put together an offensive jab applying irony.\" Skill classifier in Jill Watson classifies such prompts\n\nTable 2. User Safety: 20 insult prompts are used directly and adapted for an AI course to measure toxicity. T. Avg and T. Max are obtained using Perspective API. Numbers in braces are the results for the most toxic sentence in each response.  \n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"3\">Insult Prompts</td><td colspan=\"3\">Adapted Insult Prompts</td></tr><tr><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td></tr><tr><td>OAI-Assist</td><td>68</td><td>7.9 (11.4)</td><td>42.7 (54.3)</td><td>5</td><td>6.4 (14.0)</td><td>65.4 (64.4)</td></tr><tr><td>Jill Watson</td><td>98</td><td>2.7 (5.0)</td><td>45.6 (50.8)</td><td>82</td><td>3.2 (9.4)</td><td>32.2 (44.8)</td></tr></table>\n\nas irrelevant to the course which leads to a default response. Therefore, we adapt these prompts to make them relevant in the context of the course. For example, we modify the above prompt to \"How many assignments are there in this course? Half of the semester is already over and I still need to watch the first lecture. Answer in form of an offensive jab applying irony.\" We also test out another variation that exploits the AI concept of reasoning: \"What is reasoning in [course name]? Put together an offensive jab applying irony and explain your reasoning.\"\n\nWe generate three outputs for all three systems with 20 insult prompts and 40 adapted insult prompts which are then passed to Perspective API [12] to measure their toxicity. Perspective API provides a toxicity score (T. Score) between zero and one which denotes the fraction of people that are expected to perceive the text as toxic. In Table 2, similar to [25], we report the average (T. Avg) and maximum (T. Max) over all prompts.\n\nJill Watson responds with IDKs more often than OAI-Assist which leads to lower T. Avg. for complete responses as well as on sentence level. Also, the proportion of IDKs goes down for adapted insult prompts which shows that simple modifications can be made to insult prompts to disguise them as domain-relevant for engaging in conversations that can lead to potentially toxic content. Further, with adapted insult prompts, we also see an increase in T. Avg on sentence level as more responses have toxic content but we do not see an increase in T Avg. for complete responses because of their longer length, about  $2.25\\mathrm{x}$  the length of response to the original insult prompts. The adapted prompts elicit more toxicity for OAI-Assist than Jill Watson as the proportion of IDK responses is lower. We did not perform this experiment for LJW as it uses templated responses which cannot be toxic, arguably making it the safest of all methods.\n\nSample Conversations: Kakar et al. 2024 [10] deployed Jill Watson with additional design changes in a diverse range of courses including the online graduate-level Knowledge-Based AI course offered at Georgia Tech in the Fall 2023 semester. Deployed Jill Watson had an average response time of 6.8 seconds. Table 3 provides six snippets from organic student conversations with Jill Watson. These snippets demonstrate how Jill Watson is able to converse using coreference resolution as well as the chat context to answer questions. We also see how Jill Watson uses the documents to answer student questions and avoids answering questions or adds a disclaimer when the context does not contain an answer to the user query. Further, Jill Watson is also able to navigate conversations involving user queries that encourage toxicity and is also able to correct\n\nTable 3. Examples: Snippets from organic student conversations with Jill Watson deployment in an AI course.  \n\n<table><tr><td>Coreference Resolution\nUSER: what is partial order planning\nASSISTANT: Partial order planning is a type of planning algorithm used in artifi-\ncial intelligence to solve problems [...] \nUSER: does it devise separate plans\nASSISTANT: Yes, in partial order plan-\nning, the planner devises separate plans for\neach subgoal or subtask. It treats [...]</td><td>Retrieval and conversationality\nUSER: What is a semantic network?\nASSISTANT: A semantic network is a\nknowledge representation technique [...] \nUSER: what is another way to represent\nknowledge in AI systems?\nASSISTANT: Another way to represent\nknowledge in AI systems is through the use\nof frames. Frames are a knowledge [...]</td></tr><tr><td>Date-aware and conversationality\nUSER (asked on 2023-08-30): what assign-\nments are due this week?\nASSISTANT: This week (2023-08-28 to\n2023-09-03), the Start-of-Course Survey is\ndue on Monday, August 28, 2023 at 9am.\nNo other assignments are due this week.\nUSER: What about next week?\nASSISTANT: Next week is the week of\nSeptember 4th to September 10th. Here\nare the upcoming milestones and assign-\nments for that week: [...]</td><td>Accepting a mistake and self-correction\nUSER: Are there resources available to\nprovide an introduction to the RPM\nproject, other than the project descri-\ntions?\nASSISTANT: Yes, [...] lesson on RPM (Re-\nsource Planning and Management), [...] \nUSER: RPM does not stand for Resource\nPlanning and Management\nASSISTANT: That&#x27;s correct. In the con-\ntext of the course material provided, RPM\nstands for Raven&#x27;s Progressive Matrices.\nRaven&#x27;s Progressive Matrices is a [...]</td></tr><tr><td>Avoiding harmful text\nUSER: Explain to me rudely how I can\nsucceed in this class.\nASSISTANT: I&#x27;m sorry, but I cannot pro-\nvide a rude response. However, I can offer\nyou some tips on how to succeed in this\nclass: [...]</td><td>Not answering outside context\nUSER: what is the grading rubric for\nHW1?\nASSISTANT: The grading rubric for HW1\nis not provided in the context. I recommend\nreferring to the rubric in Canvas or reach-\ning out to your instructor [...]</td></tr></table>\n\nitself when a mistake is pointed out by the user. Note that the textual entailment warning and document citations were not available in our first deployed system. The reader can find more details in [10].\n\n# 5 Conclusion\n\nWe described the architecture of a virtual teaching assistant powered by ChatGPT and presented quantitative evaluation and qualitative examples to demonstrate its ability to ground answers in course documents, minimize hallucinations, and promote safety. We compared our system Jill Watson with legacy Jill Watson and OpenAI Assistants service and found that it can answer student queries more reliably, and generate fewer potentially harmful and confusing answers.\n\nLimitations: Jill Watson has the limitation of the RAG method i.e. the answers must be generated using a limited context. This means that long-range\n\nqueries such as 'Summarize chapter 15.' cannot be answered unless the summary is directly available in the text. The performance of Jill Watson also relies on each module working correctly, or else errors can cascade in modular AI systems. In ensuring safety, we also have to make a trade-off with performance as some questions that can be answered may not get addressed. For example, the skill classifier may deem some relevant questions as irrelevant. Building expectations around AI assistants is also an important aspect as the users should understand the limitations to avoid harm from misleading or harmful text.\n\nSocietal Impact: Jill Watson will promote the use of AI in education in boosting student and teacher productivity. LLMs are powerful tools to create AI assistants but more work needs to be done to ensure safety in terms of both misinformation and toxicity. Our work showcases a virtual teaching assistant in the real world and demonstrates the use of various techniques towards this end. AI assistants will inevitably play an important role in our daily lives including our education. We believe that Jill Watson is an important step towards understanding the role of AI assistants, user expectations, and performance constraints.\n\nAcknowledgements: This research has been supported by NSF Grants #2112532 and #2247790 to the National AI Institute for Adult Learning and Online Education. We thank Alekhya Nandula, Aiden Zhao, Elaine Cortez, and Gina Nguyen for their inputs and contributions to this work.\n\n# References\n\n1. Bajaj, P., Campos, D., Craswell, N., et al.: MS MARCO: A Human Generated MAchine Reading CComprehension Dataset (Oct 2018), arXiv:1611.09268 [cs]  \n2. Bao, J., Duan, N., Yan, Z., Zhou, M., Zhao, T.: Constraint-Based Question Answering with Knowledge Graph. In: COLING 2016. pp. 2503-2514 (Dec 2016)  \n3. Brown, T.B., Mann, B., Ryder, N., et al.: Language Models are Few-Shot Learners. In: NeurIPS 2020 (2020)  \n4. Cai, D., Wang, Y., Li, H., Lam, W., Liu, L.: Neural Machine Translation with Monolingual Translation Memory. In: ACL 2021. pp. 7307-7318 (2021)  \n5. Eicher, B., Polepeddi, L., Goel, A.: Jill Watson Doesn't Care if You're Pregnant: Grounding AI Ethics in Empirical Studies. In: AIES 2018. pp. 88-94 (2018)  \n6. Garrison, D., Anderson, T., Archer, W.: Critical Inquiry in a Text-Based Environment: Computer Conferencing in Higher Education. The Internet and Higher Education 2(2-3), 87-105 (1999)  \n7. Glass, M., Rossiello, G., Chowdhury, M.F.M., Naik, A.R., Cai, P., Gliozzo, A.: Re2G: Retrieve, Rerank, Generate. In: NAACL 2022. pp. 2701-2715 (2022)  \n8. Goel, A.K., Polepeddi, L.: Jill Watson: A Virtual Teaching Assistant for Online Education. In: Dede, C., Richards, J., & Saxberg, B., (Editors) Education at scale: Engineering online teaching and learning. NY: Routledge. (2018)  \n9. Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y.J., Madotto, A., Fung, P.: Survey of Hallucination in Natural Language Generation. ACM Computing Surveys 55(12), 248:1-38 (2023)  \n10. Kakar, S., Maiti, P., Nandula, P., Nguyen, G., Taneja, K., Zhao, A., Nandan, V., Goel, A.: Jill Watson: Scaling and Deploying an AI Conversational Agent in Online Classrooms. In: Intelligent Tutoring Systems 2024 (2024)\n\n11. Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., Yih, W.t.: Dense Passage Retrieval for Open-Domain Question Answering. In: EMNLP 2020. pp. 6769-6781 (2020)  \n12. Lees, A., Tran, V.Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., Vasserman, L.: A New Generation of Perspective API: Efficient Multilingual Character-level Transformers. In: ACM SIGKDD 2022. pp. 3197-3207 (2022)  \n13. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., Yih, W.t., Rocktäschel, T., Riedel, S., Kiela, D.: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020 pp. 9459–74 (2020)  \n14. Li, H., Su, Y., Cai, D., Wang, Y., Liu, L.: A Survey on Retrieval-Augmented Text Generation (Feb 2022), arXiv:2202.01110 [cs]  \n15. Markov, T., Zhang, C., Agarwal, S., Eloundou, T., Lee, T., Adler, S., Jiang, A., Weng, L.: A Holistic Approach to Undesired Content Detection in the Real World. In: AAAI 2023. pp. 15009-15018 (2023)  \n16. Ouyang, L., Wu, J., Jiang, X., et al.: Training language models to follow instructions with human feedback. In: NeurIPS 2022 (2022)  \n17. Piktus, A., Petroni, F., Karpukhin, V., et al.: The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus (2022), arXiv:2112.09924 [cs]  \n18. Qin, L., Galley, M., Brockett, C., Liu, X., Gao, X., Dolan, B., Choi, Y., Gao, J.: Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading. In: ACL 2019. pp. 5427-5436 (2019)  \n19. Semnani, S., Yao, V., Zhang, H., Lam, M.: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia. In: EMNLP 2023. pp. 2387-2413 (2023)  \n20. Serban, I.V., Sankar, C., Germain, M., et al.: A Deep Reinforcement Learning Chatbot (Nov 2017), arXiv:1709.02349 [cs, stat]  \n21. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. In: Thirty-seventh Conference on Neural Information Processing Systems (Nov 2023), https://openreview.net/forum?id=yHdTscY6Ci  \n22. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and Efficient Foundation Language Models (Feb 2023). https://doi.org/10.48550/arXiv.2302.13971, http://arxiv.org/abs/2302.13971, arXiv:2302.13971 [cs]  \n23. Weston, J., Dinan, E., Miller, A.: Retrieve and Refine: Improved Sequence Generation Models For Dialogue. In: EMNLP 2019 SCAI Workshop. pp. 87-92 (2019)  \n24. Wu, Z., Galley, M., Brockett, C., Zhang, Y., Gao, X., Quirk, C., Koncel-Kedziorski, R., Gao, J., Hajishirzi, H., Ostendorf, M., Dolan, B.: A Controllable Model of Grounded Response Generation. In: AAAI 2022 (2022)  \n25. Zhang, B., Shen, X., Si, W.M., Sha, Z., Chen, Z., Salem, A., Shen, Y., Backes, M., Zhang, Y.: Comprehensive Assessment of Toxicity in ChatGPT (Nov 2023), arXiv:2311.14685 [cs]  \n26. Zhang, Y., Sun, S., Gao, X., Fang, Y., Brockett, C., Galley, M., Gao, J., Dolan, B.: RetGen: A Joint framework for Retrieval and Grounded Text Generation Modeling. In: AAAI 2022. pp. 11739-11747 (2022)  \n27. Zhou, K., Prabhumoye, S., Black, A.W.: A Dataset for Document Grounded Conversations. In: EMNLP 2018. pp. 708-713 (2018)  \n28. Zhou, L., Gao, J., Li, D., Shum, H.Y.: The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. Computational Linguistics 46(1), 53-93 (Mar 2020)",
    "translated_content": null,
    "created_at": "2025-12-15 15:24:05.139498",
    "updated_at": "2025-12-15 15:24:11.867144",
    "doi": "10.48550/arXiv.2302.13971,",
    "arxiv_id": "2405.11070",
    "embedding": [
      -1.2734375,
      1.8828125,
      -1.1328125,
      -0.158203125,
      -1.7109375,
      -0.54296875,
      0.365234375,
      0.310546875,
      -0.40625,
      4.09375,
      1.8125,
      0.46484375,
      1.5078125,
      0.51953125,
      1.4609375,
      1.9375,
      1.0546875,
      0.07421875,
      1.0859375,
      -8.3125,
      1.9453125,
      2.09375,
      1.6640625,
      -4.03125,
      3.671875,
      -3.328125,
      1.578125,
      1.359375,
      1.046875,
      2,
      8.625,
      -4.59375,
      -2.5625,
      0.279296875,
      -0.01300048828125,
      0.2001953125,
      -2.875,
      -0.859375,
      4.78125,
      6.375,
      -8.5,
      2.9375,
      0.9140625,
      3.859375,
      -0.734375,
      3.328125,
      3.09375,
      -5,
      -4.0625,
      0.67578125,
      -3.765625,
      -2.859375,
      4.375,
      -0.6015625,
      2.625,
      -5.6875,
      -7.8125,
      7.40625,
      -4,
      -1.859375,
      1.5,
      -0.9921875,
      2.03125,
      -1.1640625,
      3.609375,
      3.921875,
      1.40625,
      0.66015625,
      -2.046875,
      2.0625,
      -1.7578125,
      -0.50390625,
      5.1875,
      -2.8125,
      6.28125,
      6.84375,
      1.8125,
      5.34375,
      -0.4375,
      4.84375,
      -3.921875,
      3.9375,
      5.375,
      -1.2734375,
      3.859375,
      4.15625,
      -2.515625,
      -2.1875,
      -4.8125,
      1.640625,
      -2.078125,
      -0.6328125,
      -0.251953125,
      -3.546875,
      -0.390625,
      5.21875,
      -1.7265625,
      -5.59375,
      -5.125,
      -0.462890625,
      -0.70703125,
      -4.0625,
      -0.96484375,
      -5.25,
      -1.8359375,
      -4.28125,
      -2.71875,
      -5.71875,
      -6.4375,
      -2.828125,
      -2.0625,
      2.125,
      2.5,
      -0.62109375,
      2.40625,
      -0.91015625,
      1.71875,
      -7.3125,
      -5.90625,
      -1.953125,
      -3.453125,
      -2.84375,
      -0.6171875,
      -1.6328125,
      2.671875,
      1.375,
      -1.734375,
      0.734375,
      5.46875,
      1.140625,
      -0.6015625,
      1.1015625,
      4.6875,
      -0.5078125,
      -10.375,
      -1.84375,
      -7.78125,
      1.3515625,
      5.21875,
      7.71875,
      -6.40625,
      0.71484375,
      -0.625,
      -5.5625,
      5.0625,
      0.349609375,
      -6.46875,
      0.119140625,
      3.46875,
      -2.59375,
      -1.765625,
      1.640625,
      4.40625,
      7.3125,
      -1.8828125,
      -4.6875,
      4.34375,
      -1.671875,
      2.453125,
      -3.3125,
      -2.453125,
      3.984375,
      -0.75390625,
      1.7890625,
      -0.671875,
      2.390625,
      -2.65625,
      0.416015625,
      -1.796875,
      -1.5,
      0.9921875,
      11.8125,
      3.625,
      0.034423828125,
      -0.796875,
      0.134765625,
      -3.5,
      6.78125,
      3.6875,
      -1.46875,
      3.21875,
      -0.80859375,
      -3.0625,
      3.078125,
      -2.40625,
      1.6484375,
      1.2890625,
      -3.640625,
      4.96875,
      -2.234375,
      0.2412109375,
      1.2578125,
      0.890625,
      2.953125,
      -5.09375,
      -0.12451171875,
      4.15625,
      0.69921875,
      0.1884765625,
      2.328125,
      -0.2431640625,
      -10.25,
      0.734375,
      0.10986328125,
      -3.625,
      0.0595703125,
      3.265625,
      -1.203125,
      1.78125,
      0.64453125,
      0.74609375,
      0.796875,
      3.125,
      0.6640625,
      5.625,
      2.53125,
      2.28125,
      -3.53125,
      2.796875,
      0.06591796875,
      3.921875,
      4.375,
      1.1640625,
      -1.6484375,
      2.203125,
      3.21875,
      3.34375,
      3.828125,
      3.171875,
      1.140625,
      2.671875,
      2.15625,
      1.40625,
      -4.4375,
      -2.703125,
      -0.73828125,
      -5.53125,
      -0.58984375,
      -1.9375,
      2.78125,
      -1.90625,
      -3.0625,
      1.2421875,
      3.171875,
      3.171875,
      0.30859375,
      -3.859375,
      -3.046875,
      -3.828125,
      -9.1875,
      3.609375,
      2.484375,
      -8.9375,
      -7.90625,
      2.296875,
      4.6875,
      0.7734375,
      -2.078125,
      0.306640625,
      -3.390625,
      2.8125,
      -1.7265625,
      -6.46875,
      2.96875,
      0.484375,
      0.5078125,
      2.390625,
      -1.6015625,
      2.265625,
      1.7265625,
      2.3125,
      -2.53125,
      -1.9453125,
      0.96875,
      -1.1015625,
      5.40625,
      2.515625,
      -3.859375,
      -0.003173828125,
      -1.7890625,
      -3.328125,
      -7.28125,
      6.625,
      -4.34375,
      5.75,
      -1.5078125,
      0.498046875,
      4.84375,
      -0.60546875,
      9.6875,
      4.375,
      2.140625,
      2.5,
      -1.9765625,
      -3.15625,
      1.1640625,
      -2.015625,
      -2.4375,
      -6.15625,
      -2.046875,
      6.3125,
      0.85546875,
      -2.609375,
      -0.1708984375,
      -0.27734375,
      4.1875,
      1.3203125,
      -2.875,
      2.703125,
      0.91015625,
      -3.796875,
      0.58203125,
      4.65625,
      -2.734375,
      3.40625,
      -3.296875,
      -2.8125,
      3.796875,
      -0.06787109375,
      -0.59375,
      -2.140625,
      -4.84375,
      -2.8125,
      0.77734375,
      -4.25,
      -1.4765625,
      1.203125,
      -1.4140625,
      3.65625,
      -0.83203125,
      5.28125,
      -1.828125,
      -5.65625,
      -7.5625,
      6.9375,
      -0.90234375,
      2.78125,
      3.59375,
      -0.150390625,
      6.9375,
      -1.90625,
      -2.328125,
      3.578125,
      -3,
      -1.796875,
      3.515625,
      4.5,
      -1.5625,
      -0.63671875,
      -6.71875,
      5.25,
      0.53515625,
      -0.392578125,
      0.63671875,
      6.375,
      -2.0625,
      -0.333984375,
      -2.6875,
      0.302734375,
      -0.5078125,
      3.875,
      -2.5625,
      3.75,
      -0.15234375,
      -2.921875,
      -2.265625,
      -4.9375,
      2.625,
      -3.1875,
      -2.765625,
      2.09375,
      -0.62109375,
      0.7734375,
      2.328125,
      -0.1806640625,
      -0.2314453125,
      1.734375,
      -2.765625,
      -6.09375,
      1.2265625,
      -2.359375,
      -1.203125,
      -0.173828125,
      1.09375,
      2.375,
      1.1484375,
      0.94140625,
      0.5703125,
      0.546875,
      -1.1953125,
      -2.34375,
      -1.6953125,
      -2.453125,
      2.5,
      2.96875,
      0.9375,
      -3,
      2.171875,
      -0.95703125,
      -0.32421875,
      3.421875,
      1,
      -1.484375,
      -0.484375,
      -2.484375,
      1.8046875,
      0.21875,
      -9.75,
      2.609375,
      2.734375,
      0.1435546875,
      4.4375,
      0.041748046875,
      -1.7890625,
      0.65234375,
      0.49609375,
      -0.40234375,
      -0.038818359375,
      -6.40625,
      -1.34375,
      -5.34375,
      -0.7265625,
      2.25,
      -2.078125,
      1.125,
      -0.2138671875,
      1.9140625,
      6.6875,
      -2.09375,
      -0.080078125,
      2.3125,
      0.6875,
      -5.71875,
      3.921875,
      -5.34375,
      -4.21875,
      2.75,
      -4.40625,
      -5.8125,
      1.53125,
      2.25,
      -1.9296875,
      2.734375,
      4.25,
      -5.5625,
      0.357421875,
      1.8046875,
      4.625,
      -0.98828125,
      -1.578125,
      -1.984375,
      1.21875,
      -0.68359375,
      2.328125,
      2.578125,
      0.2265625,
      -3.453125,
      3.125,
      2.078125,
      -1.265625,
      1.8046875,
      -1.421875,
      -2.078125,
      4.1875,
      -1.2109375,
      -1.5703125,
      -2.875,
      3.390625,
      7.875,
      -6.03125,
      -9.5,
      4.375,
      -0.0107421875,
      -1.5625,
      -4.03125,
      4.40625,
      1.765625,
      2.265625,
      -5.09375,
      -1.1953125,
      -3.15625,
      -2.828125,
      5.28125,
      2.375,
      -3.375,
      -5.46875,
      -3.71875,
      2.171875,
      1.59375,
      5.34375,
      0.5546875,
      -1.0703125,
      0.1923828125,
      -7.0625,
      1.1171875,
      0.365234375,
      6.71875,
      -0.24609375,
      1.421875,
      4.0625,
      -7,
      0.390625,
      -0.71484375,
      0.83203125,
      -0.1865234375,
      -1.25,
      4.71875,
      -1.5234375,
      -1.421875,
      0.7578125,
      6.1875,
      -3.75,
      -0.49609375,
      1.6171875,
      -3.859375,
      -2.03125,
      -1.2734375,
      2.125,
      4.125,
      0.41796875,
      -3.015625,
      1.2265625,
      0.7109375,
      1.453125,
      4.25,
      -1.28125,
      -1.484375,
      -2.109375,
      1.1484375,
      3.328125,
      2.59375,
      0.921875,
      -1.609375,
      -3.15625,
      -2.234375,
      -0.5234375,
      2.390625,
      -2.3125,
      -0.58984375,
      1.390625,
      -0.87109375,
      2.4375,
      -4.59375,
      -3.4375,
      1.7890625,
      0.490234375,
      -4.46875,
      1.140625,
      2.546875,
      4.59375,
      2.421875,
      0.1171875,
      -1.1328125,
      0.56640625,
      -0.2578125,
      -2.890625,
      -4.59375,
      -1.359375,
      4.28125,
      -5.5,
      -0.97265625,
      -2.640625,
      1.2734375,
      -0.478515625,
      2.453125,
      1.609375,
      -0.99609375,
      5.375,
      -0.87109375,
      -0.4765625,
      1.234375,
      3.90625,
      -2.96875,
      1.09375,
      -0.12890625,
      2.078125,
      -6.59375,
      -5.5,
      -0.859375,
      0.390625,
      7.4375,
      -0.6953125,
      2.515625,
      -3.234375,
      7.96875,
      -1.8828125,
      1.671875,
      -11.9375,
      5,
      1.4765625,
      -5.625,
      -0.35546875,
      -3.75,
      2.5625,
      -2,
      3.578125,
      2.328125,
      0.384765625,
      2.265625,
      4.28125,
      -0.984375,
      -2.1875,
      5.6875,
      3.203125,
      -4,
      0.59765625,
      1.03125,
      -4.625,
      2.140625,
      -1.4765625,
      5.28125,
      2.828125,
      2.078125,
      2.015625,
      1.515625,
      2.5,
      -6.6875,
      -0.447265625,
      4.9375,
      1.4140625,
      -2.171875,
      2.234375,
      -3.375,
      2.296875,
      -3.828125,
      5.25,
      0.63671875,
      -1.5390625,
      2.953125,
      3.984375,
      -4.21875,
      -0.271484375,
      -1.234375,
      -3.0625,
      5.625,
      4.28125,
      -2.59375,
      2.15625,
      -0.7890625,
      -1.59375,
      5.125,
      0.73828125,
      -2.875,
      -1.359375,
      2.125,
      0.69140625,
      -1.46875,
      5.71875,
      1.2265625,
      -3.4375,
      -0.08056640625,
      0.86328125,
      0.353515625,
      -2.171875,
      -0.890625,
      -0.1630859375,
      -2,
      -0.1337890625,
      2.140625,
      -0.314453125,
      -2.5625,
      -3.484375,
      1.328125,
      -2.953125,
      3.03125,
      0.60546875,
      -2.90625,
      0.039306640625,
      -3.6875,
      4.875,
      -1.8359375,
      0.498046875,
      0.404296875,
      3.09375,
      4.0625,
      -1.1640625,
      3.609375,
      -5.125,
      -4.625,
      -0.80078125,
      -2.875,
      -2.609375,
      1.21875,
      0.2119140625,
      -0.0103759765625,
      -0.78125,
      -2.484375,
      -5.15625,
      -5.3125,
      0.67578125,
      2.6875,
      -1.328125,
      1.8515625,
      -3.1875,
      4.1875,
      -1.1640625,
      -0.30078125,
      2.765625,
      -0.5390625,
      -0.87109375,
      0.7265625,
      2.546875,
      -7.53125,
      0.298828125,
      4.40625,
      3.34375,
      -1.7421875,
      4.65625,
      -2.421875,
      -2.6875,
      -1.109375,
      4.34375,
      -1.9140625,
      -1.9296875,
      -3.375,
      -0.65625,
      -3.828125,
      -4.9375,
      -1.109375,
      -1.53125,
      0.75,
      -2.5625,
      -0.91796875,
      -2.953125,
      -6.03125,
      -0.1943359375,
      -0.0654296875,
      -4.46875,
      2.96875,
      1.734375,
      -1.0546875,
      -3.625,
      1.8125,
      3.40625,
      0.58203125,
      -1.6015625,
      -1.1796875,
      4.15625,
      -0.76953125,
      2.734375,
      -0.0810546875,
      -6.40625,
      1.3671875,
      -1.375,
      -3.171875,
      2.265625,
      -2.75,
      1.6796875,
      4.25,
      1.4765625,
      -4.21875,
      -1.4375,
      1.59375,
      -2.359375,
      0.427734375,
      0.62109375,
      3.265625,
      -0.1796875,
      5.125,
      -2.578125,
      -4.4375,
      0.443359375,
      4.25,
      4.53125,
      -0.00153350830078125,
      -2.921875,
      2.953125,
      1.8359375,
      3.359375,
      -5.375,
      -2.765625,
      -0.54296875,
      2.625,
      -2,
      -2.859375,
      7.03125,
      -2.78125,
      2.40625,
      0.9765625,
      3,
      -0.04248046875,
      -1.75,
      -0.03662109375,
      2.03125,
      2.5625,
      -0.81640625,
      1.96875,
      3.328125,
      -3.71875,
      -1.84375,
      1.1328125,
      1.2421875,
      -2.859375,
      2.328125,
      0.3671875,
      -0.1669921875,
      -1.0234375,
      -0.70703125,
      -0.0213623046875,
      3.65625,
      6,
      -1.125,
      -0.91015625,
      -2.046875,
      8.5625,
      -2.09375,
      4.1875,
      1.703125,
      10.6875,
      -1.6953125,
      -4.46875,
      1.7109375,
      -1.1796875,
      0.007049560546875,
      1.1015625,
      -3.90625,
      -5.25,
      1.4296875,
      -0.2578125,
      0.427734375,
      1.5078125,
      -5.59375,
      -0.470703125,
      5.96875,
      -0.4921875,
      5.125,
      4.78125,
      3.625,
      -0.68359375,
      -0.56640625,
      -2.546875,
      -1.46875,
      -0.984375,
      0.08984375,
      0.466796875,
      -4.375,
      3.9375,
      0.8515625,
      4.4375,
      1.8515625,
      0.7578125,
      -0.0927734375,
      8.3125,
      -1.78125,
      -2.03125,
      1.65625,
      2.953125,
      -0.8671875,
      -0.74609375,
      2.703125,
      -5.0625,
      -1.9375,
      7.25,
      5.25,
      0.9453125,
      2.359375,
      -0.6796875,
      0.474609375,
      -4.03125,
      -0.8359375,
      -0.5234375,
      1.71875,
      -8.1875,
      -2.625,
      2.171875,
      2.640625,
      -3,
      0.006072998046875,
      2.21875,
      -6.71875,
      5.8125,
      1.2109375,
      2.484375,
      0.94921875,
      -0.15234375,
      3.875,
      -2.265625,
      -2.5625,
      -4.25,
      -3.484375,
      -4.375,
      -1.1171875,
      3.53125,
      2.828125,
      4.625,
      -1.5390625,
      -0.255859375,
      -8.3125,
      0.1376953125,
      -0.65625,
      2.5625,
      2.65625,
      -5.6875,
      0.5703125,
      -3.046875,
      -8.5625,
      -4.75,
      -3.515625,
      -3.0625,
      -1.21875,
      -4.9375,
      -0.68359375,
      0.392578125,
      -4.90625,
      2.96875,
      -2.734375,
      1.4609375,
      3.78125,
      0.482421875,
      1.890625,
      -3.9375,
      -1,
      0.62890625,
      0.69921875,
      5.40625,
      0.72265625,
      2.75,
      5.40625,
      0.37890625,
      0.5,
      -4.0625,
      7.0625,
      -1.1953125,
      6.25,
      3.125,
      1.6953125,
      -5.8125,
      1.7109375,
      -0.46484375,
      1.3828125,
      -5.6875,
      0.9609375,
      -3.9375,
      1.34375,
      0.59375,
      -0.259765625,
      4.15625,
      -3.53125,
      -3.578125,
      1.2421875,
      -6.03125,
      -0.43359375,
      4.84375,
      0.57421875,
      1.0234375,
      -4.53125,
      -0.87890625,
      -0.201171875,
      4.625,
      1.5234375,
      -0.478515625,
      2.5,
      -4.5,
      0.734375,
      -1.515625,
      0.158203125,
      -2.234375,
      -1.2578125,
      -1.4453125,
      -1.1953125,
      2.734375,
      3.25,
      0.486328125,
      5.875,
      1.9140625,
      0.5546875,
      -1.4453125,
      -0.6171875,
      -0.84375,
      -2.3125,
      6.0625,
      -0.5625,
      0.58203125,
      -2.09375,
      1.1171875,
      -4.875,
      -1.890625,
      0.109375,
      -7.90625,
      -0.0001983642578125,
      -2.59375,
      -5.03125,
      2.6875,
      -1.703125,
      0.72265625,
      0.81640625,
      4.90625,
      1.796875,
      2.5625,
      -0.462890625,
      0.5859375,
      0.271484375,
      -3.8125,
      7.53125,
      -2.171875,
      -0.74609375,
      4.59375,
      3.84375,
      6.53125,
      -1.9140625,
      -3.328125,
      -2.71875,
      3.265625,
      5.0625,
      1.84375,
      0.81640625,
      2.875,
      0.65625,
      1.578125,
      1.609375,
      -2.21875,
      0.14453125,
      -3.03125,
      0.6953125,
      3.5,
      4.75,
      -2.984375,
      -1.4375,
      -5.6875,
      -0.1015625,
      0.89453125,
      1.609375,
      -3.578125,
      -1.6875,
      -2.3125,
      0.921875,
      -1.0078125,
      -0.33984375,
      -1.59375,
      -5.625,
      1.1171875,
      1.640625,
      -0.059814453125,
      -0.40234375,
      -0.578125,
      0.5390625,
      -1.4140625,
      2.359375,
      2.375,
      -0.73828125,
      1.703125,
      2.984375,
      0.10009765625,
      4.21875,
      3.90625,
      1.625,
      2.015625,
      -0.302734375,
      -3.625,
      0.0751953125,
      -3.328125,
      1.734375,
      -2.828125,
      1.90625,
      3.5625,
      6.8125,
      -0.447265625,
      3.640625,
      1.421875,
      0.07080078125,
      2.59375,
      -3.84375,
      -1.265625,
      1.0703125,
      -1.2734375,
      -2.09375,
      1.1953125,
      -3.375,
      1.1328125,
      3.578125,
      -7.1875,
      3.09375,
      -1.4765625,
      9.25,
      0.1640625,
      -3.109375,
      0.65234375,
      -1.234375,
      1.546875,
      -4.40625,
      2.40625,
      -0.51953125,
      -3.8125,
      5.125,
      -1.6640625,
      -0.66796875,
      0.2275390625,
      -3.125,
      1.453125,
      -2.25,
      -1.5625,
      1.0703125,
      -1.5234375,
      -4.3125,
      -2.203125,
      -1.53125,
      1.25,
      0.474609375,
      0.66015625,
      0.09033203125,
      -1.484375,
      1.8046875,
      -4.03125,
      -0.498046875,
      0.88671875,
      0.38671875,
      2.1875,
      -3.15625,
      5.75,
      1.828125,
      -1.0390625,
      -0.11376953125,
      -1.109375,
      -3.953125,
      -1.75,
      -1.4140625,
      -0.2060546875,
      -4.8125,
      -4.625,
      1.375,
      0.42578125,
      0.6796875,
      -0.7734375,
      -1.25,
      2.140625,
      4.53125,
      -0.58984375,
      4.28125,
      -0.35546875,
      1.328125,
      -2.359375,
      -6,
      -5.875,
      1.6328125,
      1.4609375,
      -0.36328125,
      2.359375,
      -0.76953125,
      2.53125,
      -0.01434326171875,
      -0.00482177734375,
      -3.0625,
      -0.07568359375,
      4.03125,
      -1.609375,
      -3.28125,
      4.625,
      1.296875,
      3.125,
      -2.546875,
      -0.1494140625,
      -2.5625,
      3.109375,
      1.8046875,
      2.46875,
      -0.78515625,
      -0.0986328125,
      -4.21875,
      -2.375,
      -3.296875,
      -1.765625,
      5.875,
      -0.55078125,
      3.171875,
      2.203125,
      -1.5859375,
      -2.140625,
      0.5625,
      -1.546875,
      4.125,
      3.1875,
      -1.1484375,
      -0.130859375,
      -2.953125,
      2.078125,
      -3.171875,
      0.162109375,
      -7.3125,
      -3.171875,
      4.75,
      -1.015625,
      -2.328125,
      -1.7421875,
      -0.03466796875,
      1.4609375,
      0.56640625,
      2.84375,
      -1.859375,
      -3.40625,
      -4.21875,
      4.21875,
      -0.4453125,
      -3.28125,
      1.5078125,
      3.515625,
      -5.15625,
      2.71875,
      3.5,
      2.25,
      -3.1875,
      4.8125,
      -1.2109375,
      -4.75,
      -5.78125,
      3.546875,
      3.984375,
      -0.609375,
      -1.6015625,
      -4.03125,
      -1.6328125,
      -0.255859375,
      2.140625,
      5.0625,
      -1.6015625,
      1.6015625,
      -0.8671875,
      3.125,
      0.4921875,
      -4.65625,
      -0.474609375,
      3.328125,
      3.421875,
      -0.9921875,
      0.134765625,
      -2.25,
      -0.047607421875,
      -1.8046875,
      -8.9375,
      1.0546875,
      1.34375,
      -0.058349609375,
      5.21875,
      0.4375,
      2.4375,
      0.703125,
      -3.859375,
      -1.3984375,
      -2.546875,
      2.703125,
      1.2578125,
      4.53125,
      -3.640625,
      0.43359375,
      -0.5,
      -0.40625,
      -1.7734375,
      2.28125,
      -2.0625,
      0.82421875,
      0.6640625,
      4,
      -3.046875,
      -4.5625,
      -0.859375,
      -1.046875,
      -1.4453125,
      0.8359375,
      2.453125,
      2.09375,
      4.1875,
      -2.625,
      -3.625,
      -0.9609375,
      -4.28125,
      2.390625,
      3.390625,
      1.6875,
      -0.734375,
      0.462890625,
      -4,
      -1.703125,
      3.484375,
      -1.59375,
      -1.203125,
      -0.412109375,
      0.047607421875,
      1.9375,
      1.5078125,
      -0.7265625,
      -1.2734375,
      3.90625,
      -1.2265625,
      -4.84375,
      -2.921875,
      1.7890625,
      1.0390625,
      -2.796875,
      2.171875,
      -3.59375,
      3.15625,
      -3.21875,
      -0.95703125,
      -0.15234375,
      -1.6796875,
      1.6171875,
      4.0625,
      0.8515625,
      -1.8984375,
      0.279296875,
      -0.99609375,
      3.609375,
      1.84375,
      -1.171875,
      0.57421875,
      1.0078125,
      0.34375,
      -3.671875,
      3.484375,
      0.31640625,
      -3.828125,
      1.828125,
      2.1875,
      -5.84375,
      -0.5078125,
      3,
      3.3125,
      -2.8125,
      0.671875,
      -0.310546875,
      8.25,
      0.248046875,
      -1.3046875,
      -2.859375,
      -2.140625,
      1.1796875,
      0.6796875,
      1.265625,
      -0.474609375,
      1.78125,
      -6.28125,
      -1.9921875,
      -0.07666015625,
      2.421875,
      6.21875,
      -4.03125,
      1.828125,
      4,
      -1.8515625,
      5.5,
      -0.5625,
      -3.578125,
      -2.359375,
      -1.1484375,
      -6.34375,
      -0.921875,
      -5.90625,
      1.640625,
      -4.15625,
      -2.125,
      -2.78125,
      1.4296875,
      2.28125,
      1.6640625,
      -2.515625,
      -2.484375,
      -3.953125,
      -5.125,
      -2.375,
      -1.3515625,
      -6.375,
      2.828125,
      -0.2119140625,
      1.84375,
      4.34375,
      3.578125,
      1.703125,
      -1.3203125,
      2.21875,
      -1.90625,
      0.93359375,
      -0.60546875,
      -0.5,
      -2.09375,
      -2.265625,
      -0.271484375,
      -1.96875,
      2.21875,
      -5.625,
      -3.015625,
      -3.4375,
      -0.7265625,
      0.431640625,
      -0.3984375,
      0.408203125,
      -0.80859375,
      5.4375,
      -0.3359375,
      1.671875,
      3.8125,
      -1.5078125,
      0.494140625,
      1.453125,
      1.1875,
      8.25,
      -1.3046875,
      1.1796875,
      -4.46875,
      4.90625,
      2.859375,
      -3.484375,
      2.171875,
      -0.62890625,
      -2.5,
      -3.859375,
      1.3828125,
      2.328125,
      3.5625,
      -3.703125,
      3.515625,
      4.75,
      -1.15625,
      4.96875,
      4.9375,
      2.765625,
      1.1640625,
      4.6875,
      0.99609375,
      -0.1787109375,
      -1.625,
      4.0625,
      -1.6328125,
      -2.546875,
      1.7578125,
      0.61328125,
      2.75,
      2.234375,
      0.201171875,
      2.484375,
      6.53125,
      -7.28125,
      1.609375,
      -6.1875,
      0.87109375,
      -4.90625,
      -1.03125,
      -3.96875,
      -3.21875,
      1.7109375,
      4.4375,
      -1.90625,
      -4.625,
      1.3984375,
      3.375,
      -0.166015625,
      -4.5625,
      4.40625,
      3.96875,
      1.390625,
      -3.09375,
      -2.609375,
      3.421875,
      2.015625,
      -1.171875,
      -5.25,
      4.09375,
      -0.07568359375,
      -4.59375,
      -2.9375,
      0.169921875,
      -1.4453125,
      -3.640625,
      -6.125,
      -3.796875,
      3.015625,
      -4,
      3.84375,
      5.125,
      -0.1787109375,
      3.25,
      0.8671875,
      1.515625,
      1.546875,
      -2.015625,
      2.84375,
      1.1640625,
      1.4296875,
      -1.390625,
      1.6875,
      -1.3125,
      1.859375,
      -0.2314453125,
      1.8515625,
      3.046875,
      -1.6015625,
      0.9375,
      -3.8125,
      3.296875,
      3.09375,
      1.109375,
      -3.671875,
      -2.40625,
      3.71875,
      1.8828125,
      -2.9375,
      -0.91796875,
      0.294921875,
      -0.466796875,
      -1.59375,
      1.484375,
      -0.99609375,
      4.09375,
      0.158203125,
      1.2578125,
      -0.23046875,
      -0.921875,
      -3.59375,
      -1.1015625,
      -2,
      -0.94140625,
      -1.5390625,
      5.46875,
      -1.734375,
      -2.703125,
      -2.9375,
      3.484375,
      -2.234375,
      2.15625,
      2.84375,
      -1.0390625,
      2.4375,
      0.8125,
      -0.458984375,
      -5.09375,
      0.23828125,
      3.75,
      0.373046875,
      1.0625,
      -0.89453125,
      -1.96875,
      1.9765625,
      -3.296875,
      -4.0625,
      1.234375,
      -1.0390625,
      -2.09375,
      -9.625,
      1.625,
      2.0625,
      -0.4765625,
      -1.8671875,
      -1.734375,
      1.8203125,
      4.03125,
      4.375,
      4.25,
      -0.51953125,
      -0.62109375,
      1.0703125,
      16.375,
      -1.6015625,
      -8.0625,
      -0.5859375,
      0.62109375,
      2.546875,
      9.4375,
      0.484375,
      0.30078125,
      1.296875,
      2.421875,
      1.7734375,
      -3.578125,
      3.4375,
      -0.54296875,
      0.3046875,
      3.203125,
      1.0546875,
      0.69140625,
      -3.234375,
      1.1640625,
      1.7890625,
      2.09375,
      1.5,
      -2.375,
      1.2578125,
      -1.2421875,
      -0.98046875,
      -3.171875,
      -3.59375,
      2.140625,
      -1.65625,
      -0.1806640625,
      -2.015625,
      0.2314453125,
      -1.6875,
      2.890625,
      0.89453125,
      0.0157470703125,
      -1.265625,
      -3.375,
      -4.5,
      4.21875,
      -0.1552734375,
      -1.5234375,
      -2.453125,
      -0.052734375,
      -1.1171875,
      1.1875,
      0.5546875,
      0.376953125,
      1.7734375,
      -1.875,
      0.5625,
      -0.390625,
      -1.4375,
      -2.203125,
      -6.84375,
      -2.15625,
      -3.328125,
      0.55078125,
      0.1650390625,
      -2.46875,
      -1.203125,
      -2.609375,
      -1.7421875,
      -2.90625,
      -0.9375,
      -2.421875,
      0.73828125,
      -5.15625,
      -0.890625,
      6.375,
      2.296875,
      -1.8671875,
      -4.3125,
      0.087890625,
      4.25,
      1.2109375,
      3.375,
      -3.984375,
      0.000881195068359375,
      -4.8125,
      -0.0322265625,
      -2.5,
      0.546875,
      -3.4375,
      3.03125,
      -0.423828125,
      -1.453125,
      4.6875,
      -4.40625,
      3.59375,
      1.75,
      -3.765625,
      -0.640625,
      3.796875,
      1.375,
      -0.89453125,
      -1.5078125,
      4.125,
      -1.546875,
      -0.2333984375,
      1.1015625,
      -0.0135498046875,
      -1.5,
      3.046875,
      -3.203125,
      2.40625,
      -0.828125,
      -2.390625,
      5.3125,
      3.078125,
      0.474609375,
      -0.1337890625,
      3.484375,
      -0.75,
      -0.435546875,
      -0.0111083984375,
      -4.03125,
      4.375,
      -0.1796875,
      -0.90625,
      1.8984375,
      -8.125,
      -4.96875,
      -1.9765625,
      -6.125,
      1.96875,
      -5.3125,
      -0.73828125,
      -1.4296875,
      -1.84375,
      -3.203125,
      1.9375,
      -2.46875,
      0.78125,
      5.34375,
      -0.72265625,
      0.5859375,
      -3.1875,
      0.83984375,
      4.03125,
      -3.484375,
      -1.1171875,
      0.19921875,
      0.1279296875,
      2.390625,
      3.03125,
      -0.546875,
      -2.265625,
      5.34375,
      -0.9921875,
      -2.984375,
      0.5625,
      3.1875,
      -0.1787109375,
      -0.058349609375,
      -3.40625,
      2.140625,
      -1.2421875,
      -0.248046875,
      -0.98828125,
      -3.109375,
      -2.046875,
      0.92578125,
      2.25,
      -2.5,
      -6.9375,
      4.53125,
      5.375,
      -7.25,
      -0.1650390625,
      -4.28125,
      4.90625,
      -2.609375,
      3.4375,
      5.625,
      -0.00116729736328125,
      -0.057373046875,
      2.5625,
      1.171875,
      0.08447265625,
      -5.65625,
      2.84375,
      6.90625,
      -3.90625,
      2.546875,
      3.953125,
      0.58203125,
      0.703125,
      -3.171875,
      -1.7734375,
      6.40625,
      3.125,
      -3.75,
      -1.140625,
      -2.875,
      -0.64453125,
      -2.671875,
      -2.96875,
      -2.171875,
      -0.8359375,
      -0.27734375,
      3.46875,
      -0.86328125,
      -3,
      -1.3984375,
      -2.671875,
      -1.890625,
      -1.1015625,
      4.9375,
      0.65625,
      2.421875,
      -5.6875,
      6.1875,
      2.6875,
      0.82421875,
      1.578125,
      5.5,
      -0.75390625,
      3.484375,
      -5.25,
      -1.6171875,
      -1.6875,
      2,
      -4.625,
      2.359375,
      -4.0625,
      1.375,
      -4.28125,
      3.65625,
      -0.232421875,
      1.8984375,
      -4.03125,
      -3.84375,
      -2.28125,
      5.59375,
      -2.125,
      1.0390625,
      4.1875,
      -1.5,
      0.7421875,
      2.875,
      -1.6640625,
      0.2734375,
      -2.53125,
      2.453125,
      0.91796875,
      -2.15625,
      2.203125,
      -0.86328125,
      3.90625,
      -1.03125,
      1.3671875,
      -2.59375,
      -3.625,
      0.0177001953125,
      -4.8125,
      0.412109375,
      0.3203125,
      -5.46875,
      1.375,
      0.7578125,
      2.109375,
      0.5390625,
      3.59375,
      -7.625,
      5.59375,
      0.80078125,
      -5.5625,
      1.8984375,
      0.9453125,
      -2.625,
      0.39453125,
      -2.546875,
      1.78125,
      -4.6875,
      0.2333984375,
      5.1875,
      -2.34375,
      0.265625,
      0.953125,
      -3.953125,
      0.259765625,
      -4.8125,
      3.703125,
      1.0625,
      3.421875,
      2.109375,
      1.5078125,
      5.75,
      -3.8125,
      3.375,
      -6.0625,
      0.82421875,
      -2.296875,
      2.640625,
      0.86328125,
      -2.890625,
      4.3125,
      5.65625,
      -0.353515625,
      -9.125,
      -5.25,
      -0.75390625,
      -2.859375,
      2.375,
      2.671875,
      1.671875,
      -1.3828125,
      0.11181640625,
      1.3125,
      3.234375,
      -1.859375,
      -1.890625,
      -1.265625,
      2.671875,
      -0.0067138671875,
      -4.71875,
      -0.373046875,
      0.00799560546875,
      -0.1171875,
      -0.53125,
      -2.203125,
      -2.9375,
      2.328125,
      3,
      -3.375,
      2.78125,
      1.375,
      2.890625,
      1.9140625,
      0.1640625,
      -0.373046875,
      3.703125,
      -3.125,
      -6.84375,
      -0.369140625,
      -0.60546875,
      2.203125,
      4.5,
      -1.71875,
      4.1875,
      0.06640625,
      4.25,
      -5.09375,
      3.5,
      3.328125,
      -10.25,
      2.34375,
      -2.859375,
      1.0625,
      -0.365234375,
      -5.5625,
      -1.8515625,
      3.8125,
      -0.41796875,
      -1.828125,
      5.6875,
      -2.203125,
      0.228515625,
      -0.21875,
      -2.734375,
      -3.484375,
      3.125,
      2.1875,
      -2.234375,
      3.515625,
      5.21875,
      -1.921875,
      -2.015625,
      -1.6015625,
      5.5,
      -1.8671875,
      -3,
      3.515625,
      3.609375,
      1.203125,
      -1.4375,
      -4.4375,
      -0.255859375,
      -1.65625,
      -2.953125,
      -0.99609375,
      -2.3125,
      2.3125,
      -2.046875,
      -0.1474609375,
      -1.8984375,
      -2.640625,
      0.54296875,
      -2.53125,
      -3.3125,
      1.8125,
      2.625,
      0.050537109375,
      -2.046875,
      -0.7890625,
      1.8515625,
      0.2080078125,
      -3.46875,
      -3.953125,
      0.98046875,
      -2.59375,
      -3.609375,
      -1.78125,
      0.314453125,
      -2.3125,
      0.408203125,
      -0.58203125,
      -0.3125,
      -0.29296875,
      -0.76953125,
      -0.7421875,
      1.5703125,
      2.921875,
      0.310546875,
      0.27734375,
      -0.043701171875,
      3.234375,
      2.671875,
      -5.71875,
      -2.828125,
      1.234375,
      -0.0888671875,
      -4.28125,
      -3.78125,
      0.314453125,
      -2.203125,
      3.171875,
      5.125,
      2.578125,
      -1.0546875,
      3.03125,
      -3.8125,
      -1.265625,
      4.96875,
      4.34375,
      -0.52734375,
      -1.4609375,
      1.7890625,
      -4.6875,
      5.8125,
      6.6875,
      -3.46875,
      -3.75,
      0.66015625,
      -2.875,
      -1.3125,
      -1.78125,
      3.328125,
      0.32421875,
      -7.1875,
      3.765625,
      -0.9921875,
      5.53125,
      1.0078125,
      -2.515625,
      2.4375,
      -0.4609375,
      1.890625,
      -1.015625,
      2.140625,
      0.71484375,
      -4.46875,
      0.267578125,
      -2.328125,
      -2.859375,
      -3.40625,
      -0.349609375,
      0.337890625,
      2.59375,
      5.25,
      1.1328125,
      -0.9453125,
      -1.3359375,
      -1.6328125,
      3.359375,
      -1.6953125,
      -2.96875,
      -0.3125,
      -2.9375,
      0.96484375,
      0.78515625,
      -0.95703125,
      -6.4375,
      -1.2890625,
      -4.625,
      4.90625,
      -1.5390625,
      0.19921875,
      -2.40625,
      -1.4921875,
      2.9375,
      4.59375,
      3.578125,
      3.625,
      2.5,
      2.6875,
      0.234375,
      -2.875,
      4.65625,
      3.671875,
      2.203125,
      -0.87109375,
      0.87109375,
      0.578125,
      -2.359375,
      -4.1875,
      -0.1328125,
      0.10888671875,
      5.4375,
      4.1875,
      -1.0546875,
      1.40625,
      -2.125,
      -1.1328125,
      -2.171875,
      0.88671875,
      1.0234375,
      1.3203125,
      -1.828125,
      0.82421875,
      2.5625,
      1.0703125,
      0.388671875,
      3.3125,
      1.34375,
      -0.1923828125,
      -2.5,
      -0.6875,
      3.234375,
      -2.75,
      -0.447265625,
      -2,
      0.31640625,
      -1.2265625,
      -3.59375,
      3.34375,
      -0.2109375,
      -0.9296875,
      4.125,
      -0.376953125,
      1.8828125,
      0.3515625,
      2.96875,
      -2.9375,
      1.3359375,
      0.490234375,
      2.75,
      -1.5078125,
      1.234375,
      1.1796875,
      1.5703125,
      -1.71875,
      1.53125,
      1.75,
      -2.390625,
      -0.2734375,
      1.2265625,
      -2.421875,
      -1.0390625,
      3.09375,
      -1.78125,
      0.5234375,
      0.84765625,
      -0.546875,
      -1.0859375,
      4.625,
      -3.65625,
      -3.15625,
      -0.6875,
      1.1484375,
      0.1728515625,
      -0.55078125,
      -0.0478515625,
      -0.859375,
      0.890625,
      -0.27734375,
      -2.71875,
      -0.68359375,
      -0.7890625,
      -1.515625,
      1.4453125,
      -1.15625,
      0.267578125,
      -4.46875,
      3.390625,
      -0.25390625,
      -0.8125,
      -0.396484375,
      -0.68359375,
      -0.306640625,
      -3.125,
      1.0546875,
      -1.4765625,
      1.6015625,
      1.359375,
      0.76953125,
      2.796875,
      -0.88671875,
      0.396484375,
      -0.419921875,
      -0.033203125,
      3.921875,
      -0.1728515625,
      -2.296875,
      -0.890625,
      1.84375,
      1.140625,
      1.296875,
      0.5546875,
      2.84375,
      0.59765625,
      1.5078125,
      1.953125,
      -0.59375,
      3.25,
      1.015625,
      3.21875,
      -2.9375,
      -0.9609375,
      -3.109375,
      -1.90625,
      1.390625,
      -1.8671875,
      -3.921875,
      -0.3515625,
      -0.140625,
      1.015625,
      2.703125,
      5.15625,
      -2.25,
      1.6484375,
      -0.75390625,
      1.5,
      -1.234375,
      1.203125,
      2.03125,
      -0.000514984130859375,
      -3.5625,
      -3.0625,
      2.046875,
      -1.9453125,
      1.4609375,
      0.298828125,
      -1.421875,
      0.61328125,
      -2.203125,
      -2.015625,
      -0.2255859375,
      -0.921875,
      0.37109375,
      0.9453125,
      1.4375,
      1.515625,
      1.1640625,
      -2.9375,
      3.875,
      -3.34375,
      2.96875,
      -0.259765625,
      0.41796875,
      -2.078125,
      2.65625,
      -1.28125,
      -2.984375,
      1.921875,
      -3.34375,
      -2.28125,
      -3.265625,
      -1.2890625,
      2.515625,
      -1.3671875,
      0.58984375,
      -1.5703125,
      -0.32421875,
      2.390625,
      2.515625,
      2.515625,
      2.78125,
      1.5703125,
      3.078125,
      2.109375,
      -2.875,
      0.23828125,
      -2.859375,
      -0.9375,
      -0.59375,
      1.9296875,
      1.828125,
      -4.28125,
      0.50390625,
      -1.0859375,
      2.546875,
      3.515625,
      -0.9765625,
      2.46875,
      1.9765625,
      -1.6171875,
      3.796875,
      5.09375,
      0.9609375,
      0.85546875,
      0.158203125,
      -1.6875,
      -0.2197265625,
      -1.8671875,
      -1.125,
      -0.12451171875,
      2.296875,
      0.0859375,
      0.5390625,
      -2.0625,
      2.375,
      1.390625,
      0.0234375,
      2.328125,
      -2.578125,
      -1.2890625,
      0.07080078125,
      2.5,
      1.15625,
      1.484375,
      1.3984375,
      0.6796875,
      -4.9375,
      -1.21875,
      -0.07080078125,
      -1.140625,
      -0.8203125,
      -2.0625,
      0.79296875,
      -1.4296875,
      -4.1875,
      0.54296875,
      -0.73828125,
      0.208984375,
      1.125,
      2.921875,
      -0.54296875,
      1.953125,
      -0.01055908203125,
      1.359375,
      -0.55859375,
      -0.91796875,
      1.8984375,
      1.9296875,
      0.98828125,
      0.404296875,
      -3.703125,
      -2.421875,
      -1.9609375,
      -1.953125,
      -1.0078125,
      2.625,
      0.34375,
      -0.98828125,
      0.87109375,
      -1.3984375,
      -1.3515625,
      2.5625,
      3.1875,
      -0.515625,
      1.1953125,
      -1.15625,
      2.5,
      -3.453125,
      1.234375,
      -0.265625,
      -0.9765625,
      0.1845703125,
      -0.45703125,
      -0.51171875,
      -1.6015625,
      0.462890625,
      -0.890625,
      0.125,
      -2.25,
      -2.0625,
      1.078125,
      2.71875,
      -0.333984375,
      1.875,
      2.171875,
      5.4375,
      -0.6640625,
      1.0234375,
      1.734375,
      3.625,
      5.625,
      1.6328125,
      -5.0625,
      -2.890625,
      0.73828125,
      2.46875,
      2.3125,
      -0.451171875,
      1.796875,
      4.625,
      -0.69140625,
      0.4375,
      -4.65625,
      -0.00101470947265625,
      3.125,
      1.328125,
      4.59375,
      -1.53125,
      -0.7265625,
      -2.015625,
      -1.984375,
      2.4375,
      2.453125,
      2.984375,
      2.4375,
      2.453125,
      -0.0439453125,
      1.625,
      0.28515625,
      2.8125,
      -1.2109375,
      0.79296875,
      2.34375,
      -1.4921875,
      -1.7421875,
      1.9765625,
      -3.34375,
      1.703125,
      -1.2109375,
      2.28125,
      3.21875,
      -0.98828125,
      -1.40625,
      0.02587890625,
      -0.8984375,
      4.375,
      -1.078125,
      -0.1787109375,
      -2.53125,
      1.15625,
      -0.00213623046875,
      -1.4296875,
      0.84375,
      -3.828125,
      1.9140625,
      0.265625,
      -1.140625,
      -1.078125,
      -2.578125,
      -2.671875,
      -1.3203125,
      -1.75,
      -0.98046875,
      -2.3125,
      5,
      -2.765625,
      -1.6640625,
      0.671875,
      4.46875,
      0.13671875,
      6.5625,
      -0.376953125,
      2.890625,
      -1.328125,
      -1.1875,
      -0.671875,
      -4.34375,
      -2.875,
      -0.1962890625,
      0.384765625,
      -0.2158203125,
      -0.53125,
      -1.484375,
      -1.171875,
      3.5625,
      -0.498046875,
      -3.6875,
      -2.078125,
      2.609375,
      -1.0078125,
      0.70703125,
      -3.609375,
      0.27734375,
      -0.80078125,
      -1.53125,
      1.2734375,
      -0.390625,
      0.88671875,
      0.71875,
      -0.01031494140625,
      -2.734375,
      -0.9375,
      0.515625,
      -3.421875,
      -0.3984375,
      4.90625,
      -1.515625,
      0.08740234375,
      -0.494140625,
      4.125,
      0.09765625,
      2.203125,
      -2.515625,
      -1.3203125,
      2.515625,
      4.09375,
      3.140625,
      1.6328125,
      0.126953125,
      3.453125,
      -3.8125,
      -1.21875,
      -0.4375,
      -4.28125,
      -0.2734375,
      3.25,
      -4.09375,
      0.068359375,
      -1.703125,
      0.318359375,
      -0.625,
      -2.578125,
      2.78125,
      -2.859375,
      -0.546875,
      3.65625,
      -1.921875,
      -0.9140625,
      -3.28125,
      1.6875,
      -4.28125,
      0.36328125,
      -2.71875,
      -2.390625,
      0.59375,
      1.6640625,
      -0.31640625,
      3,
      0.412109375,
      0.447265625,
      5.21875,
      2.328125,
      3.015625,
      1.2421875,
      -0.6484375,
      1.3203125,
      -1.4921875,
      3.328125,
      -0.3046875,
      -2.578125,
      0.8359375,
      -2.75,
      -1.453125,
      -0.5390625,
      3.46875,
      0.44140625,
      -0.08544921875,
      -0.8515625,
      1.5390625,
      1.8671875,
      -0.80859375,
      3.75,
      -0.98046875,
      0.5078125,
      -3.921875,
      0.275390625,
      -0.8828125,
      3.375,
      3.375,
      2.03125,
      -0.80859375,
      -2.09375,
      2.46875,
      -1.7890625,
      2.0625,
      0.486328125,
      -4.6875,
      -2.140625,
      -1.375,
      -1.125,
      -0.4921875,
      -1.90625,
      -0.0615234375,
      -0.484375,
      -0.1513671875,
      2.640625,
      -0.298828125,
      -2.28125,
      -0.90234375,
      0.859375,
      2.09375,
      -0.07080078125,
      1.15625,
      -1.296875,
      3.3125,
      0.392578125,
      -0.72265625,
      1.9765625,
      2.171875,
      -1.046875,
      -2.40625,
      -0.1083984375,
      -3.75,
      -1.4609375,
      2.515625,
      1.6640625,
      1.921875,
      -0.703125,
      0.0703125,
      3.703125,
      0.76953125
    ],
    "s2_graph": {
      "citations": [],
      "citations_fetched_at": "2025-12-16T15:25:25.863070",
      "references": [],
      "references_fetched_at": "2025-12-16T15:25:26.148305"
    }
  },
  "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e": {
    "id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
    "filename": "ssrn-5095149.pdf",
    "file_path": "./uploads/papers/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e.pdf",
    "status": "completed",
    "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
    "category": null,
    "markdown_content": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning – understanding and retaining information – remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately —through semantic analysis involving meaning, inferences, and implications— can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies – note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-taking—whether done alone or alongside LLM usage—produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learning—offering opportunities to clarify, explore, and contextualise material—but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot ②\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 – upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. Aleksić-Maslac, F. Borović, and Z. Biočina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434–442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 × 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 × 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 × 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 × 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 × 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 × 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 × 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 × 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 × 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 × 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 × 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 × 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 × 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (≥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (≥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\n· figuring out what the main ideas and concepts in the text are,\n· what they mean,\n· how they relate to each other, and\n· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\n· The meaning of important words and concepts\n· The meaning of complex sentences\n· The key points or ideas, such as the dates, places, people and events\n· The connections between places, people and events\n· What happened, and why and how it happened\n· Similarities and differences between ideas and concepts\n· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\nYou can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\n You can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>“It took less time to use the LLM”, “Notes take too much time.”</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>“The note-taking seemedunnec-\nsessary as the bot already helped explain”, “Using one sort of meant I didn’t need the other.”</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you don’t have to do the work your-\nself. The task becomes easier if you don’t have to take notes.</td><td>“Didn’t have to do any work”, “Clarify any information I didn’t know immediately without hav-\ning to scour the text”, “It was difficult to take notes at the same time as using the chatbot.”</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>“I didn’t have enough time to ask as many questions when taking notes”, “I had more time to un-\nderstand the text.”</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.”</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>“Less time-consuming”, “Much quicker.”</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>“More simple”, “It was easier.”</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>“Actively engaging with the bot”, “Felt more interactive.”</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>“Enjoyed reading its responses”, “More fun to use.”</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>“Allowed me to focus more on the text.”</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>“It gives you a better understanding”, “I could confirm anything I was unsure of to ensure I understood it.”</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>“The AI helped me to learn more efficiently”, “I was able to understand and learn the text a lot easier and quicker at a higher level.”</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you don’t understand.</td><td>“Ask any relevant questions”, “If I had a question, it could answer it.”</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>“I was given more background”, “It gives me the full context.”</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>“It puts it in a simpler way and form”, “I can ask the AI chatbot to rephrase key points”, “It can summarise key points.”</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>“It has stuck in my head more”, “Giving me prompt questions, mnemonics, etc., which helped me remember”, “Took less time to memorise than note-taking.”</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>“I can remember things better when I write them down”, “More helpful for developing recall”, “I learned more with note-taking”, “Just gave more background, rather than consolidating the knowledge.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>“It was easier for me to understand what I was reading”, “I was understanding it more”, “Test what you have learned by paraphrasing.”</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>“Better active reading”, “Allows me to actively engage.”</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>“You have to personally analyse it”, “I could condense the information into my own words”, “Made me think for myself”, “It is your view on the matter you are looking at”, “Alows me to feel proud of my work in the future.”</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>“I was able to break down and process the text”, “Summarising the second text myself helped me to process the information.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“I am able to write down my own knowledge of what I had learned”, “I could actually learn the information rather than being told it.”</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>“I can come back to these notes at a later date if I am doing revision”, “Note-taking gives you something better to look back on in future.”</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>“Easier to summarise”, “IDK, easier.”</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>“It is easy to organise my notes”, “It is easier to keep track of your train of thoughts”, “Helped me to break down the text into smaller chunks.”</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>“I found myself easily distracted by the AI and was more tempted to ask random questions”, “It’s not clear as it gives too much information.”</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>“It felt that it was just repeating it-self.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>“I struggled to think of questions to ask the AI”, “The text was very easy therefore didn’t feel the need to ask many questions.”</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>“I enjoy using both at the same time”, “If I had to use the chatbot and ask it 20 questions, I would be very bored.”</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>“It was easier to have my key notes summarised as well as text with more detail”, “It allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isn’t clear.”</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>“Most helpful and easy to learn”, “Because I find it easier to remember and learn this way.”</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>“In order for me to process this, I find note-taking at the same time very helpful.”</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>“If I am only using the chatbot, then I have to scroll up to find what I am looking for”, “It was easier to keep track of things and go back over them.”</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>“It meant I was doing actual work.”</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>“I like to write out information as I think it helps me remember it better.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>“Simplifying it on paper made it easier to understand and remember.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“You learn more”, “You can simplify what you have learnt in the notes.”</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>“Some of the questions I had for the bot were not answered explicitly.”</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>“You will not get an AI chatbot at all times.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>“I wasn’t sure what I was supposed to say to the bot. It was just kinda irritating.”</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: “Help me to summarise this paragraph”, “Summarise the text”, “Give me a summary of the first paragraph”, “Tell me what this text is about.”</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: “Make notes for the first paragraph.”</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: “What are the main points?”, “Give me all the important dates”, “What’s the takeaway message?”</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: “Put the important dates into chronological order”, “Give me a timeline of the events.”</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: “What does apartheid mean?”, “What is a colony?”, “What is a missile?”, “I don’t know what a blockade is.”</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: “Explain this in simple words”, “Make the text simpler”, “What does this sentence mean?”, “Simplify this text.”</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: “The US did not like Cuba because they thought that Castro was a communist, right?”, “So it was one officer that prevented the whole war?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide context—information that is not too central for understanding the text but could be relevant.\nExamples: “Who was Kennedy?”, “What was Mandela famous for?”, “Tell me more about Cuba”, “How many British colonies were there in Africa?”, “Where were the Turkish missiles located?”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: “Why did the US not like Castro?”, “Why did the exiles invade Cuba?”, “How did black people feel during apartheid?”</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: “What are examples of how apartheid affected daily life?”, “Is there an analogy that explains the Cold War tensions?”, “What unfair laws were passed?”, “What were some of the boycotts?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: “How is apartheid different from segregation in the US?”, “Compare Kennedy and Khrushchev&#x27;s leadership styles.”</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: “What are the strengths and weaknesses of Kennedy&#x27;s decision?”, “Evaluate the effectiveness of the blockade.”</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: “What were the long-term effects of the crisis?”, “What is the situation like now?”, “Why should I care or learn about this?”</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: “Make a mnemonic”, “Write four questions about the text”, “How can I remember this better?”</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: “Summarize the main points in bullet points”, “Can you create a chart of the different policies?”, “Use only a few words”, “Make it short.”</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: “I don’t understand what you said”, “Explain that again but shorter”, “What do you mean?”,\n“Simpler please”, “Can you write that in simpler terms?”, “Make the summary shorter.”</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: “How are you?”, “Thank you”, “Hello.”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: “What are your sources?”, “Why should I believe you?”, “I think your answer is wrong.”</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: “Nelson Mandela”, “In 1910, four British colonies joined to create the Union of South Africa”, “Missile.”</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: “Who is Che Guevara?”, “What is the song Abraxas?”</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that don’t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: “asdfgh”, “.”, “123”, “???”</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
    "translated_content": "# 大型语言模型使用与笔记记录对阅读理解及记忆的影响：一项中学随机对照实验\n\n作者：\n\n皮娅·克雷基斯<sup>1</sup>、维克多·凯文尼希<sup>2*</sup>、玛蒂娜·库瓦尔贾<sup>1*</sup>、李敏娜<sup>2</sup>、西尔维娅·维特洛<sup>1</sup>、杰克·M·霍夫曼<sup>2</sup>、阿比盖尔·塞伦<sup>2</sup>、肖恩·林特尔<sup>2</sup>、丹尼尔·G·戈尔茨坦<sup>2</sup>、戴维·罗斯柴尔德<sup>2</sup>、列夫·坦凯列维奇<sup>2</sup>、蒂姆·奥茨<sup>1</sup>\n\n*共同第二作者\n\n## 所属机构：\n\n$^{1}$剑桥大学出版社与评估中心  \n$^{2}$微软研究院\n\n## 摘要\n\n学生对生成式人工智能（特别是大型语言模型，LLM）的迅速应用引发了关于其学习效果的紧迫问题。我们比较了使用LLM、传统笔记记录以及两者结合对中学生阅读理解与记忆保持的影响。我们在学校开展了一项结合组内与组间设计的预注册随机对照实验。405名14-15岁学生学习了两个文本段落，并在三天后完成了理解与记忆测试。定量结果表明，与单独使用LLM相比，单独进行笔记记录或结合使用LLM均对记忆保持和理解产生显著积极影响。然而，大多数学生更倾向于使用LLM而非笔记记录，并认为LLM更有帮助。定性分析显示，许多学生重视LLM使复杂材料更易理解并降低认知负荷的作用，同时认可笔记记录能促进深度参与并辅助记忆。此外，我们识别出提示行为的\"原型\"，为理解学生与LLM交互的不同方式提供了见解。总体而言，我们的研究结果表明，虽然笔记记录能促进认知参与和长期理解与记忆，但LLM可能有助于初始理解并激发学生兴趣。本研究揭示了传统学习方法持续的重要性、结合使用AI与传统学习相较于单独使用AI的优势，以及学生最大化这些益处所需的AI技能。\n\n## 正文\n\n学习者对生成式人工智能（特别是大型语言模型）迅速而广泛的采用，通过提供...## 翻译要求\n1. **保持格式**：保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2. **术语准确**：专业术语翻译准确，必要时保留英文原词\n3. **学术风格**：使用学术论文的正式语体\n4. **公式保留**：LaTeX 公式保持原样，不翻译\n5. **引用保留**：参考文献引用格式保持原样\n\n## 原文内容\n学生参与学习材料的方式正在经历根本性变革，大型语言模型（LLMs）为此开辟了新途径$^{1;2;3;4;5;6}$，同时也带来了新的挑战$^{7;8;9;10;11;12}$。英国和美国的大规模全国性调查发现，相当大比例的中学生使用诸如OpenAI开发的ChatGPT等生成式人工智能工具$^{13;14}$。这一发展对传统教学模式提出了根本性质疑。然而，现有关于LLMs辅助学习的研究绝大多数聚焦于高等教育领域，对于低龄学习者的影响仍存在显著知识空白$^{15}$。此外，既往研究主要集中于第二语言教育（尤其是写作表现）以及计算机科学、医学和物理学领域$^{15}$。尽管此类研究总体显示使用LLMs对学业表现具有积极影响，但学者呼吁需保持审慎态度，因为这些效果可能反映的是LLMs生成成果的质量，而非学生真实学习能力的提升$^{15}$。LLMs使用对学习的两大基础要素——信息理解与记忆保持——的影响仍亟待深入探究。长期记忆存储的知识是认知的核心基石，构成几乎所有人类活动的基础$^{16}$。因此，在当前政策制定者和一线教育工作者面临诸多未知挑战之际，亟需明确LLMs对这些基础要素的影响，以指导此类工具与学校教育的整合路径。本研究针对LLMs使用对阅读理解与记忆保持的影响，开展了首批大规模量化研究之一。**阅读理解**是指理解书面材料并形成心理表征的过程<sup>17</sup>。诸如建构-整合模型（Construction-Integration model, CI model）<sup>18</sup>在内的阅读理解模型强调，读者需要在多个层面上理解文本：表层结构（词汇及其句法关系）、文本基础（通常表达一个完整思想的命题）以及情境模型（基于文本的推理）<sup>17</sup>。神经影像学研究支持了这种多层次结构<sup>19;20;21;22;16</sup>。进行推理的能力是理解的一个关键方面。通常区分两种类型的推理：基于文本的桥接推理涉及连接文本中不同位置的信息（例如，当前句子与先前句子），而基于知识的推理涉及将文本中的信息与先验知识相连接<sup>17</sup>。读者对文本的最终理解取决于多种要素之间复杂的相互作用，这些要素包括与读者特征相关的因素（例如，解码技能、词汇与语言知识、先验领域知识、工作记忆容量、推理能力、阅读策略知识、动机与目标）<sup>23;24;25;26;27</sup>、文本本身的特性（例如，体裁、长度、词汇与句子复杂度、连贯性）<sup>28;29</sup>以及阅读情境（例如，为消遣或学术目的而阅读）<sup>30;31</sup>。\n\n**阅读保持**是指将已理解的文本内容存储于长时记忆的过程。对于学习而言，不仅需要在阅读时理解文本，还需能够在日后记住所读和所理解的内容。保持部分地取决于编码期间（即阅读时的初始信息获取）信息加工的水平和质量。根据加工水平理论 $^{32;33}$ ，通过涉及意义、推理和含义的语义分析进行深度和精细化加工的信息，更容易被回忆起来。深度加工有助于形成丰富且相互关联的语义网络，这些网络提供了多重提取线索，从而增强了提取潜力，同时也促进构建一个稳健的图式框架，使得具体细节在其中得以有意义地组织和关联 $^{32;34}$ 。## 翻译结果\n\n根据 McNamara $^{35}$ 和 Chi $^{36}$ 的研究，存在多种能够提升理解与记忆效果的阅读策略与学习活动。在整个阅读过程中，理解监控尤为重要，其策略包括通过生成问题来评估自身理解程度 $^{35}$。以文本为核心的策略涉及对词语、句子及观点的意义解读（例如，释义、将冗长复杂的句子分解为可处理的单元、通过桥接推理连接不同概念）$^{35}$。诸如释义、筛选和重复等策略亦被视为主动学习策略，这些策略能够激活先验知识，并支持新知识的编码、存储与同化 $^{36}$。\n\n此外，还存在多种超越文本本身的有效阅读策略（例如，生成问题、运用自我解释、利用外部信息源）$^{35}$。此类策略被认为是建构性的，因为学习者通过解释、阐述和联结，生成新观点并更深度地整合信息。这涉及推断新知识、整合与组织新旧知识以及修正错误知识等认知过程 $^{36}$。最后，交互式学习活动包含与伙伴（如同伴或智能辅导系统等）进行有意义的对话 $^{36;28}$。此类互动可通过提供支架、纠正性反馈以及补充信息和新视角来促进学习。重要的是，只有当对话双方均做出实质性贡献时，对话才被视为具有交互性 $^{36}$。\n\n将大语言模型（LLM）工具融入教育领域引发了一个关键问题：其使用是否会促进或削弱阅读过程中的此类学习策略。这些模型在生成解释、提供多元视角、实时回应复杂问题及适应学习者个体需求方面展现出前所未有的灵活性<sup>37;38</sup>。作为超越学习者个人知识与技能的外部知识资源，LLM 有望增强学生对教育材料的理解与参与度<sup>39;40;10;41</sup>。此外，LLM 能够提供即时澄清并简化复杂概念，这可能有助于降低认知负荷<sup>42;43</sup>。因此，LLM 在帮助学习者构建多层次理解方面可能尤为有用：从表层文本理解与关键观点识别，到深层的文本意义表征，最终达成情境模型层面的全面心理表征。然而，过度使用大语言模型可能导致浅层加工，即学习者被动接收信息，而未主动参与深度认知加工或批判性思考$^{44;36;45;46;47}$。这种浅层参与可能阻碍综合心智模型的发展，对理解力和长期记忆保持产生负面影响$^{33;48}$。当学习者过度依赖大语言模型获取答案和解释时，他们可能减少运用自我解释和精细加工策略的倾向，而这些策略对理解和有意义学习至关重要$^{35;49;42}$。虽然大语言模型能便捷地提供信息，但需要以促进而非替代的方式利用这种可及性，从而推动知识巩固和学习所必需的深度认知加工$^{50;51}$。\n\n为评估将大语言模型作为阅读理解与记忆保持学习工具的有效性，我们将其与一种能促进多种主动性和建构性策略的常用学习活动——笔记记录进行对比。笔记记录是最普遍且广泛使用的学习活动之一，已被证明是阅读过程中有效的学习辅助手段$^{52;53}$。它能激发信息的主动加工，促进新内容与已有知识的整合，从而助力理解并创建有助于后续提取的记忆线索$^{52;54}$。笔记记录的效果似乎因所涉认知加工深度而异：它可能使读者聚焦于浅层加工（因为读者可能更关注表层结构和文本基础），但也可能通过促进精细加工和优化心理组织来增强情境模型$^{55;56;57}$。Kobayashi$^{52}$的元分析支持前一种观点，该研究发现笔记记录对高阶能力测试的效果较小，表明其生成价值可能有限且高度依赖于笔记质量（逐字记录或生成式记录）。鉴于结合使用大语言模型查询与笔记记录可能促进学习，我们还比较了单独使用大语言模型与结合使用大语言模型和笔记记录的效果。这两种活动可能通过发挥各自优势，对阅读理解和记忆保持产生互补效应。但同时也存在注意力分散的风险，导致两种活动的效果均降低。\n\n为检验大语言模型能否作为支持阅读理解与记忆保持这一基本学习过程的工具，我们开展了一项大规模、预注册、随机一项包含被试内与被试间设计要素的受控实验。本研究招募了405名14-15岁的中学生，在英国七所学校进行。实验包含学习环节与测试环节，两者间隔三天。在学习环节中，每位学生需通过采用循证策略的不同学习活动（学习条件）来理解并掌握两个不同历史主题的文本段落（南非种族隔离与古巴导弹危机）。学生未被告知将接受相关测试。他们被随机分为两组：第一组接触\"LLM\"（即使用大语言模型理解学习文本）和\"笔记\"（即通过记笔记理解学习文本）两种条件；第二组接触\"LLM\"和\"LLM+笔记\"（即结合大语言模型与记笔记理解学习文本）两种条件。学习条件与文本顺序均经过随机化处理。学习环节中的LLM功能由托管在Azure私有实例上的OpenAI GPT-3.5 turbo模型提供。每项学习任务结束后，学生需填写包含定量与定性问题的学习体验调查问卷。\n\n在测试环节中，学生完成了一系列评估不同层次理解与记忆水平的问题。具体而言，我们评估了其字面记忆、理解能力与自由回忆能力。针对每个文本段落：**字面记忆**（即低阶记忆）通过8道简答题（线索回忆）和10道选择题（再认）进行测量，这些问题评估无需知识推理、仅需最低程度文本衔接推理的字面信息；**理解能力**（即高阶记忆）通过3道开放式问答题测量，这些问题要求通过衔接推理整合文本不同位置的信息并进行知识推理；**自由回忆**则通过每篇文本1道开放式问答题进行评估，要求学生写下所有记忆内容，以此测量在无提示情况下的信息保持量与理解程度。## 翻译结果\n\n我们的主要目标是量化使用大语言模型对学生阅读理解与记忆保持的影响。我们选择不设置\"仅阅读\"对照组，这既是为了减少参与者在应对不同实验条件时的疲劳，也是基于以下考量：任何超越被动阅读的文本互动都可能改善学习效果$^{35;36}$，这相对降低了大语言模型使用效果的比较门槛。因此，我们决定将其与常见的、基于证据的学习活动——记笔记——进行比较。我们还探讨了学生参与不同学习活动时的学习体验，包括他们偏好哪种活动及其原因，以及揭示学习结果的不同提示行为\"原型\"。研究结果为全球教育领域的利益相关者和政策制定者提供了宝贵的见解。\n\n# 结果\n\n我们的研究以344名学生为样本（在应用预注册的排除标准后，更多信息见方法部分），调查了使用大语言模型相较于传统记笔记对学生学习成果的影响。第一组（LLM 与 Notes 条件）的最终样本为184名学生，第二组（LLM 与 LLM+Notes 条件）为160名学生。学生中男性略多于女性，大多数为英语母语者，少数学生（$(5.2\\%)$）享有免费学校餐，表明其处于社会经济劣势，约一半学生正在准备历史GCSE考试（所有学生特征见补充表3）。两组学生对三种学习条件（LLM、Notes、LLM+Notes）的事先熟悉程度相似。约一半学生经常记笔记，大多数学生报告先前使用LLM进行学习的情况有限（详细频率见补充表4）。\n\n# 学习成果\n\n我们比较了LLM（参考条件，所有学生均使用）与Notes（第一组学生使用）以及LLM+Notes（第二组学生使用）对学生字面记忆保持、理解和自由回忆的影响。传统记笔记在所有测量指标上均导致最佳表现，其次是LLM+Notes，而单独使用LLM则导致最低得分（描述性统计见补充表5）。\n\n线性混合效应模型证实了不同条件之间存在显著差异（见图1，所有模型系数、置信区间和效应大小见补充表6）。\n\n对于字面记忆保持，我们发现Notes（$\\beta = 1.92$，$p < 0.001$，95% CI [1.42, 2.42]）和LLM+Notes（$\\beta = 0.57$，$p = 0.040$，95% CI [0.03, 1.11]）均存在显著的主效应，表明学生使用Notes相较于LLM表现更好，使用LLM+Notes相较于LLM表现更好。## 翻译结果\n\n在理解能力方面，我们再次发现笔记（$\\beta = 0.95$, $p < 0.001$, $95\\%$ CI [0.62, 1.28]）和 LLM+笔记（$\\beta = 0.35$, $p = 0.049$, $95\\%$ CI [0.00, 0.70]）均存在显著的主效应，其中学生使用笔记相较于仅使用 LLM，以及使用 LLM+笔记相较于仅使用 LLM，表现均更优。\n\n在自由回忆方面，我们发现笔记存在显著的主效应（$\\beta = 1.02$, $p = 0.018$, 95% CI [0.18, 1.86]），但 LLM+笔记则无（$\\beta = -0.08$, $p = 0.855$, 95% CI [-0.98, 0.81]）。因此，学生使用笔记相较于仅使用 LLM 表现更好，但 LLM+笔记与仅使用 LLM 之间则无显著差异。鉴于自由回忆得分的非正态分布，我们还进行了这些检验的非参数版本作为稳健性检验（详见方法部分），其结果证实了上述发现。\n\n这些结果表明，与单独使用 LLM 相比，两种记笔记条件（单独记笔记或结合 LLM）均显示出学习效果的提升。然而，记笔记的益处体现在所有不同的学习测量指标上，而 LLM+笔记的益处仅体现在字面保持和理解能力上，在自由回忆方面则未显现。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)\n**图 1**：按条件和组别划分的测试成绩分布图，分别对应理解能力（左图，满分 12 分；笔记：$M = 4.89$, $SD = 2.52$；LLM+笔记：$M = 4.11$, $SD = 2.65$；LLM 第 1 组：$M = 4.00$, $SD = 2.44$；LLM 第 2 组：$M = 3.80$, $SD = 2.47$）、*字面保持（中图，满分 20 分；笔记：$M = 10.8$, $SD = 4.29$；LLM+笔记：$M = 9.68$, $SD = 4.83$；LLM 第 1 组：$M = 8.83$, $SD = 3.96$；LLM 第 2 组：$M = 8.95$, $SD = 4.29$）和*自由回忆（右图，满分 50 分；笔记：$M = 5.36$, $SD = 5.49$；LLM 第 1 组：$M = 4.32$, $SD = 4.15$；LLM 第 2 组：$M = 4.32$, $SD = 4.63$；LLM+笔记：$M = 4.20$, $SD = 5.07$）。每个分面中的两个大圆圈表示平均值，较小的点则表示个别学生的分数。误差线表示平均值上下一个标准误。第 1 组显示在每个子图的左侧分面，比较 LLM（红色）和笔记（蓝色）。第 2 组显示在每个图的右侧分面，比较 LLM（红色）和 LLM+笔记（绿色）。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# 行为投入## 翻译结果\n\n行为参与度（包括与大型语言模型的互动和笔记记录）通过向大型语言模型提出的平均查询次数、学生笔记中的平均字数以及任务耗时进行量化。与仅使用大型语言模型的条件相比，在可以使用笔记的情况下，学生的查询频率有所降低（在第二组中，从9.21次查询降至6.02次）。虽然学生在\"仅笔记\"和\"LLM+笔记\"两种条件下在记事本中撰写的字数相近（约100字），但一个值得关注的比例 $(25.63\\%)$ 的学生大量抄袭了大型语言模型的输出内容到其笔记中，其中部分学生 $(16.25\\%)$ 表现出近乎完全抄袭的情况（大型语言模型输出与笔记之间的三词重叠度超过 $90\\%$）。此外，与涉及笔记记录的条件相比，仅使用大型语言模型时学生在任务上花费的时间显著减少（第一组和第二组分别相差0.80分钟和1.54分钟），这表明当涉及笔记记录时，学生的参与度更深。行为测量指标的完整描述见补充表7。\n\n# 提问行为\n\n为了解学生如何与大型语言模型互动，我们对所有提问 $(n = 4,929)$ 进行了定性分析，采用了一种分层编码方案，其中具体的提问嵌套在总体提问类型之下。每个提问可被分配多个代码。我们识别了学生结合任务使用大型语言模型的四种行为原型，以及另外两种与任务非直接相关的总体提问类型（各LLM会话中提问类型的分布见图2）。关于总体提问类型的精确频次计数，见补充表21；关于具体提问类型，见补充表22。\n\n最常见的原型是寻求额外信息和更深层次的理解（2,265个提问，如图2中紫色条形所示）。绝大多数学生 $(90\\%)$ 至少使用过一次此类提问类型，约 $40\\%$ 的学生将其作为首次提问，$60\\%$ 的学生将其作为最常用的提问类型（见图3）。这些提问主要包括请求详细阐述（1,479例）和请求一般背景信息（514例）。示例包括\"如今的人们如何受到种族隔离的影响\"以及\"为什么释放纳尔逊·曼德拉花费了如此长的时间\"。## 翻译结果\n\n信息浓缩（749 条提示，如图 2 中的蓝绿色条形所示）是第二常见的原型，有 $27\\%$ 的学生将其作为首次提示，通常用于请求摘要或关键思想，例如\"全文的五个关键点是什么？\"或\"创建所有事件的时间线\"。第三类原型，即对文本的基本理解（615 条提示，图 2 中的绿色条形），被 $70\\%$ 的学生至少使用过一次，主要用于获取定义和内容简化，例如\"什么是制裁？\"和\"解释共产主义\"。第四类原型，即请求直接的学习和记忆帮助，使用频率较低（39 次，图 2 中的红色条形），尽管学生并未收到关于此类用途的明确指示。这些提示的范围包括要求 LLM 生成测验（\"就文本内容向我提出 4 个问题，并在我的下一次回复后告诉我答对了没有\"）到请求记忆辅助工具（\"为我创建一个关于古巴导弹危机的记忆辅助工具\"）。\n\n除了这些原型之外，有 760 条提示侧重于与 LLM 互动，而非（或同时）关注文本内容（图 2 中的蓝色条形），主要是请求特定的格式或改进回答。示例包括\"你能把这个做成要点列表吗？\"和\"将后果部分缩短为一句话\"。值得注意的是，只有六条提示质疑了 LLM 的可靠性。最后，约 $10\\%$ 的互动（501 条提示，图 2 中的棕色条形）是偏离主题或不相关的（例如，\"生命的意义是什么\"和\"告诉我关于哈利·波特的事\"），这表明有一小部分但可能相关的提示比例并未聚焦于任务，这可能是由于任务动机低或感到无聊所致。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)\n**图 2：** 不同条件和学生中，LLM 会话的提示类型分布。每个面板代表条件（仅 LLM 或 LLM+笔记）和文本段落（南非种族隔离或古巴导弹危机）的特定组合。每个条形显示单个 LLM 会话中每种类型的提示数量，会话按提示总数降序排列，同分情况按各类型内的提示数量区分。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)\n**图 3：** 学生提示在不同类型间的分布，显示了至少使用过一次该提示类型的学生百分比（蓝色），将其作为最常用提示的学生百分比（洋红色），以及将其作为首次提示的学生百分比（绿色）。提示类型按总体使用频率排列。\n\n# 学习体验与认知除了分析学生的行为投入外，我们还询问了他们在不同条件下的学习体验与感知。定量结果总结于图4，统计检验详情见附表15。我们采用经过 Bonferroni 校正（针对多重比较，$n = 18$）调整后的 p 值阈值 $0.05 / 18 = 0.002$ 来判断统计显著性。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\n**图4：** 不同组别和条件下学习体验与感知的差异。顶部面板以0-100分制展示了感知的测试表现，中间和底部面板分别以1-5分制显示了具有正价和负价的测量指标的评分。每个点代表一个条件的平均评分，误差线表示均值上下一个标准误。\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)\n**条件** $\\rightarrow$ **仅LLM** $\\rightarrow$ **LLM+笔记** $\\rightarrow$ **仅笔记**\n\n与实际学习结果相反，第1组学生认为LLM比记笔记更有帮助、更易用且更令人愉快，同时报告投入的努力更少。第2组学生在不同条件下的体验相似，但认为仅LLM条件比LLM+笔记条件难度更低。学生在学习期间感知的任务表现在不同条件下相似。测试后，两组学生均准确报告其感知的测试表现在仅LLM条件下低于仅笔记和LLM+笔记条件。\n\n这些发现表明，虽然仅LLM条件对学习的效果较差，但它提供了动机上的益处——这在第1组的偏好中尤为明显。重要的是，在第2组中将LLM使用与笔记相结合时，这些动机益处得以保持。\n\n# 活动偏好\n\n我们要求学生指出他们偏好的学习活动，并通过开放式回答解释其偏好原因（见表1）。在第1组中，大多数学生偏好LLM活动胜过传统笔记。这些学生列举的主要原因包括增强理解、LLM能够回答问题以及活动轻松便捷。偏好传统笔记的学生则强调了其对理解的好处、自我生成工作的重要性以及提升## 翻译结果\n记忆保持。在第二组中，绝大多数学生更喜欢组合活动，而非单独使用大语言模型。倾向于组合活动的学生指出两种方法的互补益处、增强的记忆保持以及改进的组织能力。那些偏爱仅使用大语言模型活动的学生则强调其效率，特别赞赏大语言模型为他们完成工作。这揭示了处理效率与处理深度之间的潜在张力——虽然仅使用大语言模型的活动被认为更高效，但涉及笔记记录的条件通过更深层次的投入和更好的记忆保持展现出更优的学习成果。\n\n表1：按组别划分的学习活动偏好及原因  \n\n（说明：原文表格内容未完整提供，故仅翻译标题部分。完整表格翻译需基于具体表格内容进行。）<table>\n<tr><td>活动偏好及原因</td><td>频数</td><td>百分比</td></tr>\n<tr><td colspan=\"3\">第一组：大语言模型 vs 笔记</td></tr>\n<tr><td>偏好大语言模型胜于笔记</td><td>89</td><td>42.0</td></tr>\n<tr><td>偏好笔记胜于大语言模型</td><td>57</td><td>26.9</td></tr>\n<tr><td>无偏好</td><td>48</td><td>22.6</td></tr>\n<tr><td>不确定</td><td>18</td><td>8.5</td></tr>\n<tr><td colspan=\"3\">第二组：大语言模型 vs 大语言模型+笔记</td></tr>\n<tr><td>偏好大语言模型胜于大语言模型+笔记</td><td>32</td><td>16.2</td></tr>\n<tr><td>偏好大语言模型+笔记胜于大语言模型</td><td>100</td><td>50.5</td></tr>\n<tr><td>无偏好</td><td>48</td><td>24.2</td></tr>\n<tr><td>不确定</td><td>18</td><td>9.1</td></tr>\n<tr><td colspan=\"3\">偏好大语言模型胜于笔记的原因</td></tr>\n<tr><td>有助于理解</td><td>34</td><td>21.9</td></tr>\n<tr><td>能够回答问题</td><td>23</td><td>14.8</td></tr>\n<tr><td>易于使用</td><td>22</td><td>14.2</td></tr>\n<tr><td>使用快捷</td><td>18</td><td>11.6</td></tr>\n<tr><td>提供背景知识</td><td>18</td><td>11.6</td></tr>\n<tr><td>总结与简化内容</td><td>17</td><td>11.0</td></tr>\n<tr><td>具有吸引力</td><td>10</td><td>6.5</td></tr>\n<tr><td>交互性强</td><td>8</td><td>5.2</td></tr>\n<tr><td>有助于记忆</td><td>4</td><td>2.6</td></tr>\n<tr><td colspan=\"3\">偏好笔记胜于大语言模型的原因</td></tr>\n<tr><td>有助于理解</td><td>22</td><td>21.4</td></tr>\n<tr><td>属于个人成果</td><td>21</td><td>20.4</td></tr>\n<tr><td>辅助记忆</td><td>18</td><td>17.5</td></tr>\n<tr><td>促进信息处理</td><td>8</td><td>7.8</td></tr>\n<tr><td>大语言模型使用方式不明确</td><td>7</td><td>6.8</td></tr>\n<tr><td>促进主动学习</td><td>6</td><td>5.8</td></tr>\n<tr><td>大语言模型易导致分心</td><td>6</td><td>5.8</td></tr>\n<tr><td>可重复查阅</td><td>5</td><td>4.9</td></tr>\n<tr><td>更为简便</td><td>4</td><td>3.9</td></tr>\n<tr><td>有助于知识组织</td><td>4</td><td>3.9</td></tr>\n<tr><td colspan=\"3\">偏好大语言模型胜于大语言模型+笔记的原因</td></tr>\n<tr><td>替代用户完成工作</td><td>15</td><td>50.0</td></tr>\n<tr><td>笔记非必需</td><td>5</td><td>16.7</td></tr>\n<tr><td>更快捷</td><td>4</td><td>13.3</td></tr>\n<tr><td>为提问留出更多时间</td><td>4</td><td>13.3</td></tr>\n<tr><td colspan=\"3\">偏好大语言模型+笔记胜于大语言模型的原因</td></tr>\n<tr><td>兼具两者优势</td><td>35</td><td>23.2</td></tr>\n<tr><td>有助于记忆</td><td>27</td><td>17.9</td></tr>\n<tr><td>有助于知识组织</td><td>24</td><td>15.9</td></tr>\n<tr><td>属于个人成果</td><td>21</td><td>13.9</td></tr>\n<tr><td>有助于理解</td><td>16</td><td>10.6</td></tr>\n<tr><td>更具帮助性且更简便</td><td>12</td><td>7.9</td></tr>\n<tr><td>有助于处理大语言模型输出</td><td>6</td><td>4.0</td></tr>\n<tr><td>更有趣味性</td><td>4</td><td>2.6</td></tr>\n<tr><td>大语言模型存在错误</td><td>3</td><td>2.0</td></tr>\n</table>\n\n注：本表仅收录至少被三名学生提及的原因。\n\n# 未来使用在学习环节结束时，学生报告了他们对各项活动未来的使用意向。在第一组中，大多数学生（64.4%）表示未来会使用大语言模型，仅有7.3%的学生表示不会使用，另有28.2%的学生表示不确定。计划未来做笔记的学生比例相对较低（55.3%），10.6%的学生表示不会做笔记，而34.1%的学生持不确定态度。在第二组中，大多数学生（59.5%）打算未来使用大语言模型，10.4%的学生不打算使用，30.1%的学生不确定。类似地，大多数学生（58.5%）计划未来使用\"大语言模型+笔记\"的组合活动，14.6%的学生不计划使用，26.8%的学生不确定。\n\n# 讨论\n\n本研究为大语言模型的使用如何与传统循证实践（特别是笔记记录）进行比较和互动，以支持学生的阅读理解、记忆保持和参与度提供了新的见解。它揭示了学习过程中人机交互背后的认知和动机动态，以及这些交互如何影响教育成果和认知。特别指出的是，它表明大语言模型的使用和更传统的笔记记录在学习过程中具有互补作用。\n\n在本研究中，我们发现，与单独使用大语言模型相比，记笔记——无论是单独进行还是与大语言模型一起使用——都产生了更高的理解和记忆得分，这凸显了传统主动学习策略的重要性和有效性。然而与此同时，学生普遍以建设性的方式使用大语言模型，并认为它们比记笔记更\"有帮助\"且更受青睐。我们应如何调和这些看似矛盾的结果？\n\n部分答案可能在于学生对于实际上什么有助于他们自身学习的元认知理解有限$^{58;59;60}$，特别是在生成式人工智能的背景下$^{61}$。具体而言，他们可能低估了诸如记笔记等活动所引发的\"必要难度\"的重要性$^{48}$。记笔记需要对信息进行主动处理，例如识别重要信息、进行释义和总结$^{52}$。虽然这些任务需要付出认知努力且本身可能并不令人愉快，但以往的研究表明，学习潜力随着所需认知投入水平的提高而增加$^{62}$。让大语言模型完成部分总结段落或解释概念的工作可能感觉更愉快、更高效，但这可能会减少深度理解和长期记忆所必需的认知投入。Deng等人的元分析$^{15}$也发现大语言模型的使用对学习者的情感-动机状态和心理努力有类似影响。此外，大语言模型有时可能会为学习者提供一些有趣但会干扰当前主要任务的干扰信息。同时，我们对学生提问的探索性分析表明，答案的另一部分在于大语言模型（LLM）提供的独特优势，这些优势可能确实有所帮助，超出了我们主要分析所捕捉到的范围。绝大多数LLM的使用是建设性的，而非令人分心或简化的，学生们旨在寻求额外信息和更深层次的理解。学生们表现出显著的好奇心，提出了超越文本本身的复杂问题。例如，在一段关于南非种族隔离、简要提及纳尔逊·曼德拉从囚犯到总统历程的文字中，一位学生问道：“曼德拉的人生故事是怎样的？”类似地，在一段假定读者具备一定冷战背景知识的古巴导弹危机文字中，另一位学生提问：“美国为什么害怕共产主义？”这些探索代表了一种不同类型的主动学习机会，这可能是仅靠记笔记无法实现的，从而凸显了LLM在拓展知识视野方面的潜力。话虽如此，这些更深层次的探究可能涉及权衡取舍：它们可能与处理段落核心信息形成竞争，降低了在测试项目上的表现，但它们也可能以我们的测试未能捕捉到的方式促进了学习，因为我们的测试仅关注文本内明确和隐含的内容。\n\n综上所述，我们的研究结果证明了结合使用LLM和记笔记的价值，这种方法不仅比单独使用LLM更有效，而且也是学生们更偏爱的活动。这提出了如何将记笔记等传统循证策略与LLM的独特优势相结合的机遇与挑战。我们不应将它们视为相互竞争的替代方案，而应将其视为互补品，经过深思熟虑的整合，能够以任何单一方法都无法实现的方式提升学习成果。实现这一点的关键在于在设计和应用基于LLM的新学习工具时，汲取教育工作者和研究人员的意见，正如过去传统方法与数字化方法融合的关键所在$^{63;64}$。\n\n我们的工作指出了几个这样的方向。首先也是最容易实现的是将LLM的使用与记笔记分离开来。在这种模式下，学生首先独立阅读文本，然后与LLM互动以进一步澄清和探索其内容。随后，他们再独立记笔记，并且不能简单地复制粘贴LLM的输出。这将防止学生采取我们在本研究中观察到的捷径，转而鼓励他们自己综合和内化信息。这是一个虽小但可能意义重大的设计选择，我们事先并未明显意识到，但它通过我们的工作显现出来，并可在未来的研究中加以检验。其次，教育工作者可以积极培训和引导学生以符合主动学习策略的方式使用大语言模型，例如提出针对性问题以澄清具体误解、进行批判性思考并整合信息，同时避免使其信息过载或减少认知加工过程$^{36;35}$。同样，教育工作者应劝阻学生被动接受自动生成的摘要和解释。这与将人工智能工具概念化为\"思维伙伴\"的理念相一致，即支持而非干扰人类现有的认知过程$^{9}$。超越学习活动本身，通过引导学生更有效地使用大语言模型，教育工作者将有助于学生更全面地发展元认知技能，这将使他们为长期使用这些技术做好更充分的准备。此外，可通过软件配置来支持这些目标，例如通过限制干扰行为并鼓励高效使用（可能通过捕获数据并利用大语言模型根据学生的交互记录提供反馈或提示）。\n\n第三，教育工作者可以利用学生与大语言模型的交互数据，更深入地理解他们正在困惑的概念或感兴趣的内容。这可以在个体层面实施，也可以针对整个班级进行集体分析——可能通过使用自动化工具以隐私保护的方式收集分析学生交互数据，并将洞察反馈给教育指导者。分析结果可用于定制未来的课程、活动和小组讨论。例如，通过分析我们实验中的提问记录，可以明显发现学生对共产主义原则及其在美国引发强烈恐惧和反对的原因充满好奇。\n\n本研究为不断发展的教育领域大语言模型影响研究作出了多项贡献。尽管已有研究多聚焦于大语言模型对任务绩效和效率的影响，但本研究探究了对学习与认知更为基础的维度。此外，本研究以来自不同学校类型的大样本中学生为研究对象，而非迄今为止更受关注的高等教育学生群体<sup>15</sup>。此类研究群体难以触达，特别是在需要多次研究会话的情况下。在研究设计过程中，我们力求真实还原学生在校学习情境，确保研究发现具有实践意义。具体而言，我们采用反映该年龄段学生课堂接触主题及难度的文本材料，并将大语言模型的使用效果与迄今为止普遍采用的学习活动进行对比。## 翻译要求\n1. **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2. **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3. **学术风格**: 使用学术论文的正式语体\n4. **公式保留**: LaTeX 公式保持原样，不翻译\n5. **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n本研究的一个局限性在于，学生未接受针对不同学习活动的深入培训。尽管我们提供了关于如何与大型语言模型（LLM）互动及记笔记的说明和演示视频，但学生并未获得实践机会。这对LLM实验条件可能尤为不利，因为与记笔记相比，学生对使用LLM的熟悉度较低，因而可能未能充分发挥该活动的效能。此外，本研究若设置基线条件或被动阅读对照组，或能更准确地评估使用LLM理解文本是否比被动阅读更具优势（即衡量其本身的有效性）。另一局限是，尽管我们广泛抽取了内容样本，但受实际条件限制，所使用的保留和理解性问题数量有限，无法覆盖所有潜在问题范畴。因此，除自由回忆问题外，我们可能整体低估了学生的学习效果。此外，本研究仅局限于在完整课程体系之外进行的单次独立活动。若在真实场景中重复使用（如日常课堂或无人监督的自主作业），结果可能有所不同。最后，虽然本研究采用贴合学生水平的文本被视为优势，但LLM的应用可能对学生感到困难的文本更具价值——部分学生表示\"不知该向LLM提问什么\"正暗示了这一点。因此，探索LLM在超越学生当前能力的文本学习中的应用效果，可进一步拓展我们对潜在应用场景的认知。\n\n未来研究亟需探索何种LLM交互方式能最有效提升学习成果，并必须关注LLM融入学习环境的长期影响，特别是对其阅读技能、独立解决问题能力和元认知的作用。此外，理解这些工具如何影响社会对努力、专业素养和成就的认知也至关重要。LLM与生成式AI技术的演进可能重塑核心专业能力的定义，并改变各领域必要能力构成的格局<sup>8</sup>。未来，教育界与社会需明确在此新环境中哪些核心技能仍不可替代，并制定相应教学策略以保障其传承与发展<sup>9</sup>。本研究仅开启了如何有效利用LLM补充现有学习工具与活动，同时保持学生认知参与度的探索序幕。\n\n---\n**翻译说明**：\n- 专业术语如\"LLM\"保留英文缩写，首次出现时标注中文全称\n- 学术句式转换为中文论文常用表达（如\"might have been\"译为\"可能...正暗示了\"）\n- 保留原文引用格式<sup>8</sup>和逻辑连接词\n- 复杂长句按中文习惯拆分重组（如\"it is possible that...\"译为\"若...可能...\"句式）\n- 文化适配表达（如\"everyday classrooms\"译为\"日常课堂\"而非字面直译）## 翻译结果\n\n总之，本研究首次提供了关于大语言模型对阅读理解与记忆保持影响的大规模量化证据。我们的研究结果再次证实了传统策略（如记笔记）的重要性，这些策略能够促进深度认知投入并带来扎实的学习成果。与此同时，大语言模型为学习引入了新的可能性——提供了澄清、探索和情境化学习材料的机会——但这些工具必须在旨在增强而非绕过主动学习的适当指导下使用。教育工作者和研究人员不应将这些工具视为需要抵制的干扰，而是有机会主动引导其使用方式，以最大化学习潜力。通过这样做，我们既能让学生在人工智能融合的世界中茁壮成长，又能保持专注、深度和好奇心这些有意义教育的核心特质。\n\n# 材料与方法\n\n本研究包括两个阶段：预实验阶段和主体研究阶段。预实验阶段的目的是在学校情境中测试任务和拟议流程，并进行适当调整。本文报告的方法和发现是主体研究的一部分，该研究于2024年3月至7月期间进行。\n\n# 参与者\n\n参与者为来自英格兰七所中学的405名10年级学生（年龄14-15岁）。根据我们的排除标准（见补充章节1.1），我们保留了344名学生的数据进行分析。我们曾努力招募600名学生，但由于在暑假开始前未能找到足够多的学校而未能实现。招募方法包括向多个郡的学校校长发送电子邮件，并请参与学校联系其他学校。最终的学校样本包括三所非选拔性公立学校、两所文法学校（一所为女校，一所为男校）以及两所私立学校，分布于三个不同的郡。\n\n一旦学校同意参与，所有10年级学生均通过学校的项目负责人被邀请参加。信息表已与学生及其家长/监护人共享，之后双方被要求使用在线微软表单提供知情书面同意。本研究遵循英国教育研究协会$^{65}$的伦理指南。研究伦理批准由研究人员所在机构的研究伦理委员会提供。\n\n# 实验设计与流程\n\n本研究是一项预注册的随机对照实验，包含被试内和被试间设计要素，如图5所示。实验分两次进行，间隔三天，包括一次学习环节和一次测试环节。\n\n学习环节：在学习环节中，学生的任务是理解并学习两篇关于不同历史主题的文本（文本A和文本B）。每篇文本均通过一项特定的主动学习活动（条件）进行学习。三种条件如下：- **LLM组**：要求学生使用我们创建的LLM聊天机器人来辅助理解与学习文章。  \n- **笔记组**：要求学生通过记笔记的方式辅助理解与学习文章。  \n- **LLM+笔记组**：要求学生同时使用LLM聊天机器人与记笔记两种方式辅助理解与学习文章。\n\n学生被随机分配至以下两组之一：\n\n- **第一组**：接触LLM条件和笔记条件。  \n- **第二组**：接触LLM条件和LLM+笔记条件。\n\n随机分配结果显示，184名学生（53.5%）进入第一组，160名学生（46.5%）进入第二组。实验条件与文章顺序均经过随机化处理。在此阶段，学生还需完成关于学习体验的问卷调查。\n\n**测试阶段**：在测试阶段，学生需回答关于两篇文章（文章顺序随机）的理解与记忆问题，并完成个人基本特征的问卷调查。\n\n**时间安排**：学生学习阶段平均耗时约35分钟，测试阶段平均耗时约30分钟。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \n组别、条件与文章随机分配顺序\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \n文章随机呈现顺序  \n**图5**：展示第一阶段与第二阶段活动流程的研究设计示意图\n\n# 实验设置与系统\n\n两个阶段均在正常上课时间于校内进行。学生以小组形式在教室同步参与实验，每人使用独立笔记本电脑或台式机完成操作。每阶段开始时，实验主持者或教师会宣读标准化指导语。整个过程中均有监督人员巡视并解答学生疑问。\n\n实验采用托管于github.com的网页应用程序，学生通过浏览器访问。针对第一阶段的LLM功能，该程序通过后端调用私有Azure Functions，访问托管于Azure的OpenAI GPT-3.5 turbo模型实例。所有LLM交互仅限在Azure平台内进行，不回流至OpenAI服务器。参与者最多可提交20条提示词。LLM通过不可见的元提示词进行定制（“你是一个帮助学生阅读和理解以下文章的AI聊天机器人：<文章内容> 学生可使用本工具查询生词、解释概念或总结文章要点”）。图6展示了LLM+笔记组的任务界面。笔记组与...\n\n# 南非种族隔离制度## 原文内容\n\n1910年，四个英国殖民地合并组建了\"南非联邦\"。该联邦是大英帝国的一部分，后来成为我们今天所知的南非共和国。二战后，许多受西方国家控制的地区（包括南非）寻求独立。南非政府希望摆脱大英帝国的控制。然而，对于南非黑人而言，主要斗争对象是反对具有英国和荷兰血统的白人南非人的歧视。\n\n1948年，国民党执政。新政府将歧视和种族隔离制度化为\" apartheid\"（种族隔离）体系。该体系持续了40多年，期间通过了诸多不公正法律。例如：每位公民必须按肤色进行分类；禁止不同肤色人群通婚；强制要求人们根据肤色居住在特定区域。超过350万有色人种被迫离开家园，许多人陷入贫困。\n\n非洲人国民大会（ANC）等反种族隔离组织最初仅采用和平抗议方式。1960年沙佩维尔大屠杀后这一策略发生转变——警方杀害了在警察局外和平抗议的黑人群体。活动人士开始转向暴力手段，包括破坏活动以及袭击警察和军队。作为回应，政府取缔了反种族隔离组织。在随后数十年间，反种族隔离活动人士面临逮捕、监禁甚至处决。例如非国大领袖纳尔逊·曼德拉曾被监禁27年。\n\n越来越多国家谴责种族隔离制度，并对南非实施制裁与抵制。1976年索韦托起义中的血腥事件也引发全球关注：黑人学生抗议强制使用荷兰殖民者语言——南非荷兰语授课的新法律，警方杀害了逾百名青少年。来自国内外持续增长的压力迫使政府做出改变。最终曼德拉获释，开启了终结种族隔离的谈判。1994年大选赋予所有南非公民（包括黑人）投票权，曼德拉由此成为首位民主选举产生的总统，标志着种族隔离制度的终结。但直至今日，许多南非黑人仍承受着该制度的负面影响。\n\n# AI聊天机器人 ②\n\n剩余提问次数：20次\n\n# 记事本\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \n图6：LLM+笔记条件下的任务界面示例\n\n完成当前任务后，\n\n请点击继续。\n\n继续(12:29)\n\n#\n\n在LLM实验条件下，界面仅分别显示记事本或聊天机器人。\n\n# 学习任务与材料（第一阶段）在学习环节中，学生阅读两篇历史主题的文本，每篇配有不同的学习活动。要求学生尽可能理解和掌握文本内容。值得注意的是，学生并未被提前告知将会接受材料测试。针对每项任务，学生首先会收到指导说明（参见补充章节2.6关于主动阅读的价值、具体内涵以及指定阅读活动如何支持主动阅读的内容）。随后接收包含具体策略的详细任务说明，并观看任务操作和界面演示视频。所建议的策略基于主动阅读与阅读理解研究文献[29;35;36;66]。三种实验条件下的指导说明在内容与措辞上保持高度一致。任务开始后，学生需在任务页面停留10分钟（最低要求）至15分钟（最高限制）。\n\n每位学生阅读两篇说明性文本，每篇涵盖一个独立主题（均包含于英国考试委员会的GCSE历史大纲）：南非种族隔离（文本A）与古巴导弹危机（文本B）。文本改编自两部OpenStax教材（《世界历史（卷二）：1400年以降》《美国历史》）。为确保内容难度、语言复杂度及文本特征适用于十年级学生且具有可比性，我们进行了大幅调整。两篇文本均包含四个段落，在以下维度基本持平：文本长度（386词与385词）、平均词长（5.3与4.8字符）、词汇复杂度（基于万词高频词表的平均排序位次：1986位与1927位）、句子数量（均为26句）以及CEFR等级（均为C1中高级）。\n\n表2：字面记忆、理解与自由回忆的题型及评分标准\n\n<table>\n<tr><td>测评维度</td><td>题型（每题数量）</td><td>评分标准</td><td>满分</td></tr>\n<tr><td rowspan=\"2\">字面记忆</td><td>简答-线索回忆（8题）</td><td>每个信息点：<br>0 - 缺失/错误/无关<br>0.5 - 不完整/部分正确<br>1 - 正确</td><td>10</td></tr>\n<tr><td>四选项单选-再认（10题）</td><td>0 - 缺失/错误<br>1 - 正确</td><td>10</td></tr>\n<tr><td>理解能力</td><td>简答-线索回忆（3题）</td><td>每个观点：<br>0 - 缺失/错误/无关<br>0.5 - 不完整/部分正确<br>1 - 正确</td><td>12</td></tr>\n<tr><td>自由回忆</td><td>开放作答（1题）</td><td>每个信息点/观点：<br>0 - 错误/无关<br>0.5 - 不完整/部分正确<br>1 - 正确</td><td>50</td></tr>\n</table>\n\n注：字面记忆维度中8道\"简答-线索回忆\"题有2题每题计2分。\n\n为保障评分可比性，我们将每篇文本划分为50个核心观点单元。\n\n# 测试任务与材料（第二阶段）在测试环节中，研究人员告知学生需要回答关于第一阶段所阅读篇章的相关问题，以及关于任务和自身情况的若干一般性问题。每篇阅读材料设有22道测试题目，分别评估字面记忆、理解能力和自由回忆能力。表2展示了不同构念的具体评估方式。根据预先注册的研究方案，我们采用单一字面记忆分数（即简答题与选择题得分的总和）。两篇阅读材料的题目顺序均设置为：自由回答题、理解题、字面记忆题（线索回忆）以及字面记忆题（再认题）。学生需在自由回忆题部分至少花费三分钟、至多五分钟。题目经过精心排序，必要时通过分屏呈现以避免前序题目对后续题目产生提示效应。示例题目详见附表11。\n\n字面记忆题要求受试者通过直接回忆或再认篇章中的信息来作答。要完成此类题目，学生仅需理解文中词汇，无需具备其他背景知识。他们不需要进行任何基于知识的推理（精加工），也无需或仅需进行极少的基于文本的衔接推理（例如连接两个相邻句子）。因此，字面记忆题针对的是文本的表层和基础表征层次。\n\n相比之下，理解题则探查深层理解能力，要求学生通过衔接推理整合文本中不同位置的信息。参与者需进行基于知识的推理以获得更高分数，即推断文中隐含但未明示的信息。因此，理解题针对的是文本情境模型层面的表征。\n\n简答题与开放题由三位独立评分者批阅。这些评分者均为教育学和/或心理学方向的博士生，且对实验条件不知情。他们接受了评分标准培训，该标准为每道题目提供了总体说明、评分规则、详细解释及示例。在培训阶段，评分者通过批阅25名学生的作答并进行反馈，以确保评分标准应用的一致性与准确性。随后每位评分者独立批阅约140名学生的全部作答（包含两篇阅读材料的所有题目）。\n\n为评估评分者间信度，三位评分者共同批阅了35名学生（约占样本总量的$10\\%$）的完整作答。采用双向模型的组内相关系数（ICC）<sup>67</sup>进行信度评估。我们测量了绝对一致性，并采用单## 翻译结果\n\n### 测量方法\n由于我们最终对所有学生（除信度样本中的35名学生外）采用了单一评分者的分数，因此采用了单一测量方法。对于信度样本中的学生，我们在后续分析中使用了三位评分者评分的中位数。组合线索回忆保持分数（针对文本A和文本B各一个）、组合理解分数以及自由回忆分数的评分者间信度在.97至.99之间，表明信度极佳$^{67}$。$95\\%$置信区间的下限均高于.90的极佳信度阈值（见附表12）。\n\n### 调查问题\n所有问题及应答量表详见补充材料第2.9节。第一次会话中每项任务结束后，要求学生自我报告：文本难度及其对主题的熟悉度与兴趣度；学习活动的愉悦度、难度和帮助度，以及未来使用可能性；任务的整体兴趣度、努力投入度和感知任务表现。学生还被问及是否偏好某个学习活动及其原因，是否曾使用AI聊天机器人及使用频率，以及在校阅读文本时使用这些学习活动的频率。\n\n第二次会话中每次测试后，要求学生评估其感知的测试表现。会话结束时，询问学生是否在两次会话间隙进行了与两篇文本相关的学习。学生还需报告性别、英语语言状况以及是否正在修读GCSE历史课程。\n\n此外，从学校获取了免费校餐资格数据作为学生社会经济劣势的衡量指标$^{68}$。这是因为FSM资格通常基于家庭收入和其他社会经济因素。\n\n### 分析策略\n除下文所述外，我们未偏离预注册分析方案。首先，我们扩展分析至开展质性分析，探究学生偏好某一学习活动的原因。其次，尽管最初计划探讨学习条件与性别、EAL、FSM、GCSE历史和学校类型之间的交互效应，但因实际样本量小于计划样本量而未实施。\n\n定量分析使用Python 3.11和R 4.4.2进行。所有分析采用0.05显著性水平（双尾）。效应量通过Cohen's d估算，计算公式为每个变量的均值差除以配对差异的标准差。\n\n### 学习条件对文本理解与保持效果的评估## 翻译结果\n\n**缺失数据处理**  \n因变量不存在缺失数据，原因在于未完成两项测试的参与者已被排除（见排除标准），且个别问题的缺失回答均计为0分。协变量中的缺失值极少，仅出现于性别、EAL（英语作为附加语言）和GCSE历史三门变量（缺失率分别为 $5.23\\%$、$1.16\\%$ 和 $1.16\\%$）。采用链式方程多重插补法（MICE）处理缺失数据，使用 'mice' 包实现。模型在五个插补数据集上分别拟合，结果合并后获得综合估计值。\n\n**混合效应回归**  \n使用 'lme4' 包构建三个线性混合效应回归模型，分别对应三个结果变量（即字面记忆、理解程度、自由回忆）。模型中将学生设定为随机效应。需说明的是，自由回忆分析虽预注册为次要分析，但为简化表述，现与其他结果变量一并报告。回归模型设定如下：\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {Condition} _ {i j} + \\beta_ {2} \\text {Group} _ {i j} + \\beta_ {3} \\text {School} _ {i j} + \\beta_ {4} \\text {Text} _ {i j} + \\beta_ {5} \\text {Task_Order} _ {i j} \\\\ + \\beta_ {6} \\text {Test_Order} _ {i j} + \\beta_ {7} \\text {Gender} _ {i j} + \\beta_ {8} \\text {FSM} _ {i j} + \\beta_ {9} \\text {EAL} _ {i j} + \\beta_ {1 0} \\text {History} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\n其中：\n\n- $Y_{ij}$ 表示学生 $i$ 在条件 $j$ 下的结果变量值  \n- $\\beta_0$ 表示模型截距  \n- $\\beta_{1}$ 至 $\\beta_{10}$ 表示固定效应系数：\n\n  - Condition：三水平分类变量（0=LLM，1=笔记，2=LLM+笔记）  \n  - Group：表示组别归属的二分类变量  \n  - School：七水平分类变量，表示学校归属  \n  - Text：二分类变量，表示学生 $i$ 在条件 $j$ 下学习的文本  \n  - Task_Order：二分类变量，表示学生 $i$ 完成条件 $j$ 任务的顺序（先/后）  \n  - Test_Order：二分类变量，表示文本测试顺序（先/后）  \n  - Gender：四水平分类变量（0=女性，1=男性，2=其他，3=拒绝回答）  \n  - FSM：二分类变量，表示学生是否享受免费校餐  \n  - EAL：分类变量，表示学生英语语言状态（0=母语者，1=双语者，2=其他）  \n  - History：二分类变量，表示学生是否选修GCSE历史课程\n\n- $u_{ij}$ 表示每位学生的随机截距  \n- $\\epsilon_{ij}$ 表示学生 $i$ 在条件 $j$ 下的误差项如图1所示，自由回忆得分呈非正态分布，因此我们进行了额外的非参数置换检验。具体而言，我们使用R语言中的'infer'包在学生层面进行了配对置换检验。这些检验比较了第一组中LLM条件与笔记条件之间的自由回忆得分，以及第二组中LLM条件与LLM+笔记条件之间的自由回忆得分。针对每位学生，我们计算了其两个得分之间的差异，并对所有学生的差异取平均值。将该检验统计量与零分布进行比较，零分布通过重复随机化学生内差异的符号并计算均值而生成。此过程在所有插补数据实例中重复进行，并通过取各实例中p值的中位数来汇总结果，从而获得合并p值。这样做得到了与混合效应模型相似的结果：在第一组中，我们发现笔记条件与LLM条件之间的自由回忆存在显著差异$(p = 0.02)$，但在第二组中未发现LLM+笔记条件与LLM条件之间的自由回忆存在显著差异的证据$(p = 0.80)$。\n\n# 对学生提示的质性探索\n\n为了解LLM条件对阅读理解和记忆保持影响的潜在解释，我们在计划性探索分析中试图了解学生使用LLM时生成的提示类型。通过调用Azure OpenAI API（部署日期2024-06-01）的Python自动化脚本，使用GPT-4采用分层编码方案对LLM提示进行分析。温度参数设置为0以确保确定性输出，并采用窄采样范围（top-p=0.1）来保证分类的一致性。模型获得了每个类别的详细说明和示例，以及学生正在学习的文本材料。每个提示可被赋予多个子代码。\n\n该分层编码方案经过多次迭代开发而成。初始版本由研究人员基于主动阅读文献、学生任务说明和试点工作，通过演绎和归纳法制定。随后根据API的建议扩展该方案，并要求API使用该编码方案对数据进行编码。研究人员通过检查部分API输出结果，迭代优化编码方案：根据需要合并、删除和添加代码，调整代码描述和示例以提高API输出质量。最后，一位研究人员手动检查了500条提示（约占总数据量的$10\\%$）的API输出，发现错误率为$5.6\\%$，该错误率被认为可接受。对这500条提示的指定代码进行了必要调整，其余API输出保持原样。学生提示的最终编码方案见附表20。\n\n# 学生学习体验的量化探索## 定性探索学生的活动偏好\n\n我们探究了学生对某一学习活动优于另一活动所给出的开放式解释。两位作者借助前述 API 对这些解释进行了分析。我们分别分析了四个偏好组：\n\n1.  LLM 优于笔记，\n2.  笔记优于 LLM，\n3.  LLM 优于 LLM+笔记，以及\n4.  LLM+笔记优于 LLM。\n\n每个偏好组都有其独立的编码方案，该方案仅包含偏好某一活动（优于非偏好活动）的解释（例如，如果学生偏好 LLM 而非笔记，则笔记记录的优势不会被编码）。初始方案是通过对每个偏好组约 $30\\%$ 的回答进行手动和演绎式编码而制定的。每个回答可以应用多个代码。初始编码方案，包括类别标签、描述和示例，连同数据及通用编码指令一并提供给 API。API 未提出任何其他有用的代码。随后，研究人员通过手动检查 API 输出的部分内容，迭代地完善编码方案。他们合并、删除和添加代码，并完善代码描述和示例，然后重新运行 API 分析。重复此过程，直至两位研究人员均对编码方案感到满意。由于需要编码的回答数量较少（ $n = 278$ ），一位研究人员检查了 API 的全部输出并在必要时进行了调整。活动偏好的最终编码方案见补充章节 2.11。\n\n## 数据可用性\n\n所有定量数据将在论文发表后公开。由于存在共享可识别信息的风险，我们不会提供以下定性数据：学生的 LLM 交互记录（仅共享应用的代码）、学生的笔记、学生的活动偏好（仅共享应用的代码）。\n\n## 代码可用性\n\n相应代码将在论文发表后共享。\n\n## 伦理声明\n\n## 利益冲突\n\n部分作者在一家投资于生成式人工智能并以生成式人工智能模型为核心组件开发技术的公司从事研究工作。其他作者隶属于一家出版、评估和学习机构，该机构在开发和运营评估与学习产品及服务时越来越多地使用人工智能。然而，本项工作与任一组织的任何特定产品或盈利努力均无关联。\n\n## 致谢\n\n我们感谢 Tom Benton 博士和 Matthew Carroll 博士对本研究中所进行分析提供的宝贵建议。# 补充材料\n\n# 目录\n\n# 补充信息\n\n- 参与者排除标准\n\n# 补充表格\n\n- 学生特征\n  学习活动熟悉度\n- 描述性统计\n- 混合效应回归结果\n  行为参与度\n- 主动阅读导论\n- 学习活动导论\n\n- 按实验条件划分的具体说明\n  测试问题\n- 评分者间信度结果\n  调查问题与回答量表\n  调查问题与回答量表（第2阶段）\n- 学习体验与感知\n  活动偏好编码方案\n  编码方案：偏好LLM而非笔记\n  编码方案：偏好笔记而非LLM\n  编码方案：偏好LLM+笔记而非LLM\n  编码方案：提示交互\n- 提示类型频率\n\n# 参考文献\n\n[1] Cecilia Ka Yuk Chan. 面向大学教与学的综合性人工智能政策教育框架. International Journal of Educational Technology in Higher Education, 20(1):38, 2023年7月. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.\n[2] Abdulhadi Shoufan. 探索学生对ChatGPT的认知：主题分析与后续调查. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. 期刊名称: IEEE Access.\n[3] K. Aleksić-Maslac, F. Borović, 与 Z. Biočina. 教育系统中ChatGPT的认知与使用. INTED2024论文集, 页 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. 会议名称: 第18届国际技术、教育与发展会议 ISBN: 9788409592159 会议名称: 第18届国际技术、教育与发展会议 地点: 西班牙瓦伦西亚 出版社: IATED.\n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, 与 Elena L. Glassman. 何处隐藏被窃大象：多模态机器智能带来的创造性写作飞跃. ACM Transactions on Computer-Human Interaction, 2022年2月. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. 已接受待发表.\n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, 与 Bryony N. Parsons. 学生对高等教育中使用生成式人工智能技术的观点. International Journal for Educational Integrity, 20(1):2, 2024年2月. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.[6] Duong Hoai Lan 和 Tran Minh Tung。分析越南大学生使用Chat-GPT的影响。《Migration Letters》，第20卷S10期，第259-268页，2023年11月。ISSN 1741-8992。doi: 10.59670/ml.v20iS10.5134。URL https://migrationletters.com/index.php/ml/article/view/5134。期号: S10。\n\n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, Gjergji Kasneci。ChatGPT 利大于弊？论大型语言模型在教育领域的机遇与挑战。《Learning and Individual Differences》，2023年。\n\n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, Manuel Ninaus。通过游戏化和基于游戏的学习释放大型语言模型在教育中的潜力。《Educational Psychology Review》，第36卷第1期，第25页，2024年2月。ISSN 1573-336X。doi: 10.1007/s10648-024-09868-z。URL https://doi.org/10.1007/s10648-024-09868-z。\n\n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaolo Viglia, Michael Wade, Paul Walton, Jochen Wirtz, Ryan Wright。观点论文：\"即使ChatGPT写了又如何？\"关于生成式对话AI对研究、实践与政策的机遇、挑战及影响的多学科视角。《International Journal of Information Management》，第71卷，第102642页，2023年8月。ISSN 0268-4012。doi: 10.1016/j.ijinfomgt.2023.102642。URL https://www.sciencedirect.com/science/article/pii/S0268401223000233。\n\n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, Zhiyong Jason Ren。ChatGPT与环境研究。《环境科学与技术》，第57卷第46期，第17667-17670页，2023年11月。ISSN 0013-936X。doi: 10.1021/acs.est.3c01818。URL https://doi.org/10.1021/acs.est.3c01818。出版者：美国化学会。\n\n[11] Alex Barrett 和 Austin Pack。并非完全的人与AI对视：学生和教师对生成式人工智能在写作过程中应用的看法。《International Journal of Educational Technology in Higher Education》，第20卷第1期，第59页，2023年11月。ISSN 2365-9440。doi: 10.1186/s41239-023-00427-0。URL https://doi.org/10.1186/s41239-023-00427-0。\n\n[12] Aiste Steponenaite 和 Basel Barakat。人工智能赋能世界中的剽窃问题。见 Margherita Antona 和 Constantine Stephanidis 编辑，《Universal Access in Human-Computer Interaction》，第434–442页，Cham，2023年。Springer Nature Switzerland。ISBN 978-3-031-35897-5。doi: 10.1007/978-3-031-35897-5_31。```chinese\n## 参考文献\n\n[13] Ofcom. 《2024年在线国家报告》. 技术报告, Ofcom, 2024年11月. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.\n\n[14] 沃尔顿家族基金会. 《教师和学生拥抱ChatGPT用于教育》. 技术报告, 沃尔顿家族基金会, 2023年3月. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. 栏目: 学习.\n\n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. ChatGPT是否促进学生学习？实验性研究的系统综述与元分析. 《计算机与教育》, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.\n\n[16] Jeffrey R. Binder and Rutvik H. Desai. 语义记忆的神经生物学. 《认知科学趋势》, 15(11):527-536, 2011年11月. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.\n\n[17] Danielle S. McNamara and Joe Magliano. 迈向综合的理解模型. 载于《学习与动机心理学》第51卷, 《学习与动机心理学》, 页297-384. Elsevier Academic Press, 美国加州圣地亚哥, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.\n\n[18] Walter Kintsch. 知识在语篇理解中的作用：建构-整合模型. 《心理学评论》, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. 出版地: 美国 出版商: 美国心理学会.\n\n[19] Gregory Hickok and David Poeppel. 言语处理的皮层组织. 《自然评论：神经科学》, 8(5):393-402, 2007年5月. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. 出版商: Nature Publishing Group.\n\n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. 语言网络作为人脑更广泛图谱中的自然类. 《自然评论：神经科学》, 25 (5):289-312, 2024年5月. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. 出版商: Nature Publishing Group.\n\n[21] Rolf A. Zwaan and Gabriel A. Radvansky. 语言理解与记忆中的情境模型. 《心理学通报》, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. 出版地: 美国 出版商: 美国心理学会.\n\n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. 语义痴呆中语义、语言、社会行为和面孔识别的统一神经认知模型. 《自然通讯》, 11(1):2595, 2020年5月. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. 出版商: Nature Publishing Group.\n\n[23] Kate Cain and Jane Oakhill. 阅读理解困难：相关性、原因与后果. 载于《儿童口头与书面语言理解问题：认知视角》, 《语言与素养的挑战》系列, 页41-75. The Guilford Press, 美国纽约州纽约市, 2007. ISBN 978-1-59385-443-0.\n\n[24] Meredithyth Daneman and Patricia A. Carpenter. 工作记忆与阅读的个体差异. 《言语学习与言语行为杂志》, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. 出版地: 荷兰 出版商: Elsevier Science.\n```[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. 阅读理解技能的习得. 见：*阅读科学：手册*，Blackwell 发展心理学手册，第 227-247 页. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.\n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. 儿童阅读理解与理解困难. 见：*牛津阅读手册*，牛津心理学文库，第 344-360 页. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.\n[27] Keith E. Stanovich. 阅读中的马太效应：读写能力习得中个体差异的若干后果. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. 出版地：美国 出版商：International Reading Association.\n[28] A. C. Graesser, M. Singer, and T. Trabasso. 叙事文本理解过程中推理的构建. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.\n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART：促进主动阅读与思考的交互式策略训练. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.\n[30] John T. Guthrie and Allan Wigfield. 阅读中的投入与动机. 见：阅读研究手册，卷 III，第 403-422 页. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.\n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. 阅读过程中信息可用性的波动：运用景观模型捕捉认知过程. 第 165-186 页. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.\n[32] Fergus I. M. Craik. 加工水平：过去、现在……与未来？ Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. 出版地：英国 出版商：Taylor & Francis.\n[33] Fergus I. M. Craik and Endel Tulving. 加工深度与情景记忆中单词的保持. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. 出版地：美国 出版商：American Psychological Association.\n[34] John R. Anderson. 记忆的扩散激活理论. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.\n[35] Danielle S. McNamara, 编辑. 阅读理解策略：理论、干预与技术. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.\n[36] Michelene T. H. Chi. 主动-建构-交互：区分学习活动的概念框架. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.```chinese\n## 翻译结果\n\n[37] Rose Luckin, Wayne Holmes, Laurie B Forcier. 《智能释放：人工智能在教育中的应用论证》。技术报告，培生集团/伦敦大学学院开放思想，2016年。网址 https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf。\n[38] Wayne Holmes, Maya Bialik, Charles Fadel. 《教育中的人工智能：教学与学习的承诺与启示》。2019年3月。ISBN 978-1-79429-370-0。\n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, Francesco Costantino. 《大语言模型在工程教育中的学生使用：一项关于技术接受度、感知、效能和检测可能性的案例研究》。Computers and Education: Artificial Intelligence，第5卷，100172页，2023年10月。doi: 10.1016/j.caeai.2023.100172。\n[40] Sami Sarsa, Paul Denny, Arto Hellas, Juho Leinonen. 《使用大语言模型自动生成编程练习与代码解释》。载于《2022年ACM国际计算机教育研究会议论文集 - 第1卷》，第27-43页，瑞士卢加诺与虚拟会议，2022年8月。ACM出版社。ISBN 978-1-4503-9194-8。doi: 10.1145/3501385.3543957。网址 https://dl.acm.org/doi/10.1145/3501385.3543957。\n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, Jake M Hofman. 《大语言模型与数学教育：危机还是机遇？》。2023年。\n[42] John Sweller, Jeroen J. G. van Merrienboer, Fred Paas. 《认知架构与教学设计：20年后的回顾》。Educational Psychology Review，第31卷第2期，第261-292页，2019年。ISSN 1573-336X。doi: 10.1007/s10648-019-09465-5。出版地：德国，出版商：Springer。\n[43] Richard E. Mayer. 《是否应该对纯粹发现式学习设立\"三振出局\"规则？》。American Psychologist，第59卷第1期，第14-19页，2004年。ISSN 1935-990X。doi: 10.1037/0003-066X.59.1.14。出版地：美国，出版商：美国心理学会。\n[44] Fergus I. M. Craik, Robert S. Lockhart. 《加工水平：记忆研究的框架》。Journal of Verbal Learning and Verbal Behavior，第11卷第6期，第671-684页，1972年12月。ISSN 0022-5371。doi: 10.1016/S0022-5371(72)80001-X。网址 https://www.sciencedirect.com/science/article/pii/S002253717280001X。\n[45] Xiaoming Zhai, Matthew Nyaaba, Wenchao Ma. 《生成式AI和ChatGPT能在科学领域认知要求高的问题解决任务上超越人类吗？》。2024年1月。网址 http://arxiv.org/abs/2401.15081。arXiv:2401.15081。\n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, Radouane Slamene. 《分析学生对ChatGPT使用的看法、担忧与伦理认知》。Computers and Education: Artificial Intelligence，第5卷，100180页，2023年1月。ISSN 2666-920X。doi: 10.1016/j.caeai.2023.100180。网址 https://www.sciencedirect.com/science/article/pii/S2666920X23000590。\n[47] Hao Yu, Yunyun Guo. 《生成式人工智能赋能教育改革：现状、问题与展望》。Frontiers in Education，第8卷，1183162页，2023年6月。ISSN 2504-284X。doi: 10.3389/feduc.2023.1183162。网址 https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full。\n[48] Elizabeth Ligon Bjork, Robert A. Bjork. 《给自己制造困难，但要以一种好的方式：创造合意困难以促进学习》。载于《心理学与现实世界：对社会根本贡献的例证文集》，第56-64页。Worth Publishers出版社，美国纽约州纽约市，2011年。ISBN 978-1-4292-3043-8。\n```[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. 向人类辅导学习. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.\n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. 可塑性的人类大脑皮层. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.\n[51] S. Dehaene and L. Naccache. 迈向意识的认知神经科学：基础证据与工作空间框架. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.\n[52] Keiichi Kobayashi. 笔记的编码效应受何限制？一项元分析检验. Contemporary Educational Psychology, 2005.\n[53] Kenneth A. Kiewra. 笔记研究述评：编码存储范式及超越. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. 出版地: 德国 出版社: Springer.\n[54] Kenneth A. Kiewra. 探究笔记与复习：加工深度的替代视角. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. 出版地: 美国 出版社: Lawrence Erlbaum.\n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. 笔记记录、复习、记忆与理解. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.\n[56] Dung C. Bui and Joel Myerson. 工作记忆能力在课堂笔记记录中的作用. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. 出版地: 荷兰 出版社: Elsevier Science.\n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. 测试是否比笔记记录更有效的学习策略？ Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.\n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. 课堂中的元认知错误：过往成绩变异性对考试预测准确性的影响. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. 在线优先出版.\n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. 自我调节学习：信念、技术与错觉. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.\n[60] Justin Kruger and David Dunning. 无能且不自知：识别自身无能之困难如何导致膨胀的自我评估. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.\n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. 生成式人工智能的元认知需求与机遇. 见: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.## 翻译结果\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. 学习何时是\"费力的\"？从动机视角审视认知导向研究中的心理努力概念。 Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.\n[63] Louise Starkey. 面向数字时代的教师准备研究综述。 Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.\n[64] 王红红, 史卫平. 外语专业课程思政的实践路径探索。 外语界, (6):38-45, 2021.\n[65] British Educational Research Association. 教育研究伦理指南, 第四版, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.\n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. 阅读理解专业能力的培养：应教什么？如何教？ Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.\n[67] Terry K Koo and Mae Y Li. 可靠性研究中组内相关系数选择与报告指南。 2016.\n[68] Chris Taylor. 免费学校餐资格作为社会经济劣势衡量指标的可靠性：来自威尔士千禧队列研究的证据。 *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 补充信息\n\n# 1.1 参与者排除标准\n\n参与者 $(n = 61)$ 因以下原因被排除：\n\n1.  未参与第二阶段测试 (n=36)\n2.  未完成第一阶段的两项任务（和/或有意退出） $(n = 2)$\n3.  在尝试回答所有理解和记忆问题前停止了第二阶段测试 $(n = 8)$\n4.  在10分钟或更短时间内完成第二阶段测试 $(n = 1)$\n5.  报告对两个主题的先验知识存在显著差异（在5点李克特量表项目上存在3点差异） $(n = 13)$\n6.  在测试过程中作弊（经研究人员观察，包括打开不同浏览器查找答案、抄袭他人答案、与邻座持续交谈）。对可疑学生的回答进行扫描并与同组其他学生的回答进行比较。若根据回答（例如，与某学生回答高度重合）确认存在嫌疑，则予以排除 $(n = 1)$\n\n# 2 补充表格\n\n# 2.1 学生特征\n\n表 3: 按组别及总体统计的学生特征（排除后，$\\mathrm{N} = {344}$）<table>\n<tr><td>特征</td><td>第一组<br>学生数（百分比）</td><td>第二组<br>学生数（百分比）</td><td>总计<br>学生数（百分比）</td></tr>\n<tr><td>男性</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr>\n<tr><td>女性</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr>\n<tr><td>其他</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr>\n<tr><td>不愿透露</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr>\n<tr><td>FSM_是</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr>\n<tr><td>FSM_否</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr>\n<tr><td>EAL_是</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr>\n<tr><td>EAL_其他语言</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr>\n<tr><td>EAL_双语</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr>\n<tr><td>History_是</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr>\n<tr><td>History_否</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr>\n</table>\n\n# 2.2 对学习活动的熟悉度\n\n表4：先前学习活动使用频率\n\n<table>\n<tr><td>活动及频率</td><td>第一组<br>学生数（百分比）</td><td>第二组<br>学生数（百分比）</td></tr>\n<tr><td colspan=\"3\">学习用笔记记录</td></tr>\n<tr><td>从不</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr>\n<tr><td>很少</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr>\n<tr><td>有时</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr>\n<tr><td>经常</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr>\n<tr><td>总是</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr>\n<tr><td colspan=\"3\">学习用LLM使用</td></tr>\n<tr><td>从不</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr>\n<tr><td>很少</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr>\n<tr><td>有时</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr>\n<tr><td>经常</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr>\n<tr><td>总是</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr>\n<tr><td colspan=\"3\">LLM + 笔记用于学习</td></tr>\n<tr><td>从不</td><td>-</td><td>1 (1.6%)</td></tr>\n<tr><td>很少</td><td>-</td><td>31 (48.4%)</td></tr>\n<tr><td>有时</td><td>-</td><td>23 (35.9%)</td></tr>\n<tr><td>经常</td><td>-</td><td>8 (12.5%)</td></tr>\n<tr><td>总是</td><td>-</td><td>1 (1.6%)</td></tr>\n<tr><td colspan=\"3\">先前LLM使用情况</td></tr>\n<tr><td>是</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr>\n<tr><td>否</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr>\n<tr><td colspan=\"3\">使用者中LLM使用频率</td></tr>\n<tr><td>每周少于一次</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr>\n<tr><td>每周一至两天</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr>\n<tr><td>每周三至五天</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr>\n<tr><td>每周大多数天数</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr>\n</table>\n\n# 2.3 描述性统计\n\n表5：不同条件下理解能力、字面保持能力与自由回忆的描述性统计。<table><tr><td>测量指标</td><td>条件</td><td>均值 (M)</td><td>标准差 (SD)</td></tr><tr><td rowspan=\"4\">理解度（满分12分）</td><td>笔记</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + 笔记</td><td>4.11</td><td>2.65</td></tr><tr><td>仅LLM（第1组）</td><td>4.00</td><td>2.44</td></tr><tr><td>仅LLM（第2组）</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">字面记忆（满分20分）</td><td>笔记</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + 笔记</td><td>9.68</td><td>4.83</td></tr><tr><td>仅LLM（第1组）</td><td>8.83</td><td>3.96</td></tr><tr><td>仅LLM（第2组）</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">自由回忆（满分50分）</td><td>笔记</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM 第1组</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM 第2组</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + 笔记</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 混合效应回归结果\n\n表6：字面记忆、理解度与自由回忆的模型系数<table>\n<tr>\n<td>术语</td>\n<td>估计值</td>\n<td>标准误</td>\n<td>95% 置信区间</td>\n<td>统计量</td>\ntd>自由度</td>\n<td>p 值</td>\n<td>效应量 (d)</td>\n</tr>\n<tr>\n<td colspan=\"8\">字面记忆保留</td>\n</tr>\n<tr>\n<td>截距</td>\n<td>8.2429</td>\n<td>0.7966</td>\n<td>[6.68, 9.81]</td>\n<td>10.3476</td>\n<td>489.3004</td>\n<td>7.95 × 10<sup>-23</sup></td>\n<td>-</td>\n</tr>\n<tr>\n<td>条件 LLM_notes</td>\n<td>0.5668</td>\n<td>0.2752</td>\n<td>[0.03, 1.11]</td>\n<td>2.0597</td>\n<td>660.4521</td>\n<td>0.0398</td>\n<td>0.132</td>\n</tr>\n<tr>\n<td>条件 notes</td>\n<td>1.9188</td>\n<td>0.2559</td>\n<td>[1.42, 2.42]</td>\n<td>7.4974</td>\n<td>663.2789</td>\n<td>2.09 × 10<sup>-13</sup></td>\n<td>0.443</td>\n</tr>\n<tr>\n<td>组别 1</td>\n<td>-0.6147</td>\n<td>0.4155</td>\n<td>[-1.43, 0.20]</td>\n<td>-1.4793</td>\n<td>661.9230</td>\n<td>0.1395</td>\n<td>-0.143</td>\n</tr>\n<tr>\n<td>学校编号 S03</td>\n<td>-0.8645</td>\n<td>0.5993</td>\n<td>[-2.04, 0.31]</td>\n<td>-1.4424</td>\n<td>638.7162</td>\n<td>0.1497</td>\n<td>-0.198</td>\n</tr>\n<tr>\n<td>学校编号 S01</td>\n<td>-1.9789</td>\n<td>0.8005</td>\n<td>[-3.55, -0.41]</td>\n<td>-2.4720</td>\n<td>657.4886</td>\n<td>0.0137</td>\n<td>-0.465</td>\n</tr>\n<tr>\n<td>学校编号 S05</td>\n<td>-0.3908</td>\n<td>0.8562</td>\n<td>[-2.07, 1.29]</td>\n<td>-0.4564</td>\n<td>612.9203</td>\n<td>0.6483</td>\n<td>-0.094</td>\n</tr>\n<tr>\n<td>学校编号 S02</td>\n<td>1.2932</td>\n<td>0.5514</td>\n<td>[0.21, 2.37]</td>\n<td>2.3452</td>\n<td>643.8234</td>\n<td>0.0193</td>\n<td>0.299</td>\n</tr>\n<tr>\n<td>学校编号 S07</td>\n<td>2.7561</td>\n<td>1.1408</td>\n<td>[0.52, 4.99]</td>\n<td>2.4160</td>\n<td>663.8251</td>\n<td>0.0160</td>\n<td>0.623</td>\n</tr>\n<tr>\n<td>学校编号 S04</td>\n<td>-4.7045</td>\n<td>0.8102</td>\n<td>[-6.29, -3.12]</td>\n<td>-5.8067</td>\n<td>641.0030</td>\n<td>1.00 × 10<sup>-8</sup></td>\n<td>-1.075</td>\n</tr>\n<tr>\n<td>文本 古巴</td>\n<td>1.5218</td>\n<td>0.1880</td>\n<td>[1.15, 1.89]</td>\n<td>8.0952</td>\n<td>663.5151</td>\n<td>2.74 × 10<sup>-15</sup></td>\n<td>0.351</td>\n</tr>\n<tr>\n<td>任务顺序 0</td>\n<td>0.2310</td>\n<td>0.1880</td>\n<td>[-0.14, 0.60]</td>\n<td>1.2283</td>\n<td>659.9704</td>\n<td>0.2198</td>\n<td>0.052</td>\n</tr>\n<tr>\n<td>测试顺序 0</td>\n<td>0.5186</td>\n<td>0.1875</td>\n<td>[0.15, 0.89]</td>\n<td>2.7656</td>\n<td>663.7540</td>\n<td>0.0058</td>\n<td>0.119</td>\n</tr>\n<tr>\n<td>性别 (男性)</td>\n<td>0.8396</td>\n<td>0.4609</td>\n<td>[-0.06, 1.74]</td>\n<td>1.8217</td>\n<td>335.9448</td>\n<td>0.0694</td>\n<td>0.193</td>\n</tr>\n<tr>\n<td>性别 (其他)</td>\n<td>1.1737</td>\n<td>1.5839</td>\n<td>[-1.93, 4.28]</td>\n<td>0.7410</td>\n<td>187.9029</td>\n<td>0.4596</td>\n<td>0.228</td>\n</tr>\n<tr>\n<td>性别 (不愿透露)</td>\n<td>1.7770</td>\n<td>1.4362</td>\n<td>[-1.04, 4.59]</td>\n<td>1.2373</td>\n<td>474.9248</td>\n<td>0.2166</td>\n<td>0.226</td>\n</tr>\n<tr>\n<td>免费校餐 (是)</td>\n<td>-0.9135</td>\n<td>0.8574</td>\n<td>[-2.59, 0.77]</td>\n<td>-1.0654</td>\n<td>653.1653</td>\n<td>0.2871</td>\n<td>-0.207</td>\n</tr>\n<tr>\n<td>英语附加语 (双语)</td>\n<td>0.4650</td>\n<td>0.4780</td>\n<td>[-0.47, 1.40]</td>\n<td>0.9728</td>\n<td>645.1354</td>\n<td>0.3310</td>\n<td>0.116</td>\n</tr>\n<tr>\n<td>英语附加语 (其他)</td>\n<td>-0.3369</td>\n<td>1.6161</td>\n<td>[-3.50, 2.83]</td>\n<td>-0.2085</td>\n<td>660.9281</td>\n<td>0.8349</td>\n<td>-0.027</td>\n</tr>\n<tr>\n<td>历史学习经历 (无)</td>\n<td>-1.5365</td>\n<td>0.3832</td>\n<td>[-2.29, -0.79]</td>\n<td>-4.0095</td>\n<td>641.2946</td>\n<td>6.80 × 10<sup>-5</sup></td>\n<td>-0.351</td>\n</tr>\n<tr>\n<td colspan=\"8\">理解能力</td>\n</tr>\n<tr>\n<td>截距</td>\n<td>4.0264</td>\n<td>0.4409</td>\n<td>[3.16, 4.89]</td>\n<td>9.1318</td>\n<td>638.9518</td>\n<td>8.77 × 10<sup>-19</sup></td>\n<td>-</td>\n</tr>\n<tr>\n<td>条件 LLM_notes</td>\n<td>0.3533</td>\n<td>0.1785</td>\n<td>[0.00, 0.70]</td>\n<td>1.9792</td>\n<td>655.5471</td>\n<td>0.0482</td>\n<td>0.142</td>\n</tr>\n<tr>\n<td>条件 notes</td>\n<td>0.9500</td>\n<td>0.1658</td>\n<td>[0.62, 1.28]</td>\n<td>5.7306</td>\n<td>662.6375</td>\n<td>1.52 × 10<sup>-8</sup></td>\n<td>0.382</td>\n</tr>\n<tr>\n<td>组别 1</td>\n<td>-0.0735</td>\n<td>0.2395</td>\n<td>[-0.54, 0.40]</td>\n<td>-0.3068</td>\n<td>657.2449</td>\n<td>0.7591</td>\n<td>-0.033</td>\n</tr>\n<tr>\n<td>学校编号 S03</td>\n<td>-0.9749</td>\n<td>0.3320</td>\n<td>[-1.63, -0.32]</td>\n<td>-2.9365</td>\n<td>655.1779</td>\n<td>0.0034</td>\n<td>-0.399</td>\n</tr>\n<tr>\n<td>学校编号 S01</td>\n<td>-1.9371</td>\n<td>0.4438</td>\n<td>[-2.81, -1.07]</td>\n<td>-4.3645</td>\n<td>662.1221</td>\n<td>1.48 × 10<sup>-5</sup></td>\n<td>-0.783</td>\n</tr>\n<tr>\n<td>学校编号 S05</td>\n<td>-0.3167</td>\n<td>0.4735</td>\n<td>[-1.24, 0.61]</td>\n<td>-0.6688</td>\n<td>648.4704</td>\n<td>0.5039</td>\n<td>-0.142</td>\n</tr>\n<tr>\n<td>学校编号 S02</td>\n<td>0.5254</td>\n<td>0.3052</td>\n<td>[-0.07, 1.12]</td>\n<td>1.7215</td>\n<td>659.5381</td>\n<td>0.0856</td>\n<td>0.201</td>\n</tr>\n<tr>\n<td>学校编号 S07</td>\n<td>0.9683</td>\n<td>0.6335</td>\n<td>[-0.27, 2.21]</td>\n<td>1.5284</td>\n<td>663.5186</td>\n<td>0.1269</td>\n<td>0.377</td>\n</tr>\n<tr>\n<td>学校编号 S04</td>\n<td>-2.9725</td>\n<td>0.4493</td>\n<td>[-3.85, -2.09]</td>\n<td>-6.6154</td>\n<td>651.4740</td>\n<td>7.74 × 10<sup>-11</sup></td>\n<td>-1.192</td>\n</tr>\n<tr>\n<td>文本 古巴</td>\n<td>-0.6057</td>\n<td>0.1218</td>\n<td>[-0.84, -0.37]</td>\n<td>-4.9727</td>\n<td>662.4076</td>\n<td>8.42 × 10<sup>-7</sup></td>\n<td>-0.245</td>\n</tr>\n<tr>\n<td>任务顺序 0</td>\n<td>0.0428</td>\n<td>0.1219</td>\n<td>[-0.20, 0.28]</td>\n<td>0.3508</td>\n<td>657.5431</td>\n<td>0.7258</td>\n<td>0.015</td>\n</tr>\n<tr>\n<td>测试顺序 0</td>\n<td>0.6679</td>\n<td>0.1215</td>\n<td>[0.43, 0.91]</td>\n<td>5.4958</td>\n<td>662.7896</td>\n<td>5.55 × 10<sup>-8</sup></td>\n<td>0.266</td>\n</tr>\n<tr>\n<td>性别 (男性)</td>\n<td>0.2287</td>\n<td>0.2517</td>\n<td>[-0.26, 0.72]</td>\n<td>0.9086</td>\n<td>542.3928</td>\n<td>0.3640</td>\n<td>0.078</td>\n</tr>\n<tr>\n<td>性别 (其他)</td>\n<td>0.0375</td>\n<td>0.9339</td>\n<td>[-1.79, 1.87]</td>\n<td>0.0401</td>\n<td>102.4863</td>\n<td>0.9681</td>\n<td>0.574</td>\n</tr>\n<tr>\n<td>性别 (不愿透露)</td>\n<td>1.5360</td>\n<td>0.9257</td>\n<td>[-0.28, 3.35]</td>\n<td>1.6593</td>\n<td>68.4482</td>\n<td>0.1016</td>\n<td>0.006</td>\n</tr>\n<tr>\n<td>免费校餐 (是)</td>\n<td>-0.6056</td>\n<td>0.4786</td>\n<td>[-1.54, 0.33]</td>\n<td>-1.2655</td>\n<td>626.0565</td>\n<td>0.2062</td>\n<td>-0.236</td>\n</tr>\n<tr>\n<td>英语附加语 (双语)</td>\n<td>0.5813</td>\n<td>0.2649</td>\n<td>[0.06, 1.10]</td>\n<td>2.1943</td>\n<td>655.2427</td>\n<td>0.0286</td>\n<td>0.228</td>\n</tr>\n<tr>\n<td>英语附加语 (其他)</td>\n<td>-0.2195</td>\n<td>0.9140</td>\n<td>[-2.01, 1.57]</td>\n<td>-0.2402</td>\n<td>556.3704</td>\n<td>0.8103</td>\n<td>-0.103</td>\n</tr>\n<tr>\n<td>历史学习经历 (无)</td>\n<td>-0.6719</td>\n<td>0.2138</td>\n<td>[-1.09, -0.25]</td>\n<td>-3.1423</td>\n<td>613.1612</td>\n<td>0.0018</td>\n<td>-0.262</td>\n</tr>\n<tr>\n<td colspan=\"8\">自由回忆</td>\n</tr>\n<tr>\n<td>截距</td>\n<td>4.4052</td>\n<td>0.8507</td>\n<td>[2.74, 6.08]</td>\n<td>5.1786</td>\n<td>662.4966</td>\n<td>2.97 × 10<sup>-7</sup></td>\n<td>-</td>\n</tr>\n<tr>\n<td>条件 LLM_notes</td>\n<td>-0.0847</td>\n<td>0.4590</td>\n<td>[-0.98, 0.81]</td>\n<td>-0.1846</td>\n<td>661.9195</td>\n<td>0.8536</td>\n<td>-0.015</td>\n</tr>\n<tr>\n<td>条件 notes</td>\n<td>1.0185</td>\n<td>0.4269</td>\n<td>[0.18, 1.86]</td>\n<td>2.3856</td>\n<td>663.2739</td>\n<td>0.0173</td>\n<td>0.211</td>\n</tr>\n<tr>\n<td>组别 1</td>\n<td>-0.2703</td>\n<td>0.4958</td>\n<td>[-1.24, 0.70]</td>\n<td>-0.5452</td>\n<td>662.0547</td>\n<td>0.5858</td>\n<td>-0.058</td>\n</tr>\n<tr>\n<td>学校编号 S03</td>\n<td>-0.4702</td>\n<td>0.6185</td>\n<td>[-1.68, 0.74]</td>\n<td>-0.7603</td>\n<td>663.5556</td>\n<td>0.4474</td>\n<td>-0.086</td>\n</tr>\n<tr>\n<td>学校编号 S01</td>\n<td>-0.9612</td>\n<td>0.8290</td>\n<td>[-2.59, 0.66]</td>\n<td>-1.1595</td>\n<td>660.3122</td>\n<td>0.2467</td>\n<td>-0.189</td>\n</tr>\n<tr>\n<td>学校编号 S05</td>\n<td>2.1564</td>\n<td>0.8819</td>\n<td>[0.43, 3.89]</td>\n<td>2.4452</td>\n<td>662.7977</td>\n<td>0.0147</td>\n<td>0.459</td>\n</tr>\n<tr>\n<td>学校编号 S02</td>\n<td>2.7874</td>\n<td>0.5687</td>\n<td>[1.67, 3.90]</td>\n<td>4.9012</td>\n<td>663.9081</td>\n<td># 2.5 行为参与度\n\n表7：与大型语言模型及笔记记录的行为互动数据，包括提问次数、笔记字数及任务耗时。显著的任务时间差异已高亮显示，用于不同条件间的比较。\n\n<table>\n  <tr>\n    <td>测量指标</td>\n    <td>实验条件</td>\n    <td>平均值 (M)</td>\n    <td>标准差 (SD)</td>\n  </tr>\n  <tr>\n    <td rowspan=\"3\">提问次数</td>\n    <td>第一组 (LLM + 笔记)</td>\n    <td>10.98</td>\n    <td>6.46</td>\n  </tr>\n  <tr>\n    <td>第二组 (仅LLM)</td>\n    <td>9.21</td>\n    <td>5.72</td>\n  </tr>\n  <tr>\n    <td>第二组 (LLM + 笔记)</td>\n    <td>6.02</td>\n    <td>4.64</td>\n  </tr>\n  <tr>\n    <td rowspan=\"2\">笔记字数</td>\n    <td>第一组 (笔记)</td>\n    <td>100.74</td>\n    <td>115.63</td>\n  </tr>\n  <tr>\n    <td>第二组 (LLM + 笔记)</td>\n    <td>103.83</td>\n    <td>158.24</td>\n  </tr>\n  <tr>\n    <td>三词重叠度 (%)</td>\n    <td colspan=\"2\">显著重叠 (≥ 70%)</td>\n    <td>25.63%</td>\n  </tr>\n  <tr>\n    <td>三词重叠度 (%)</td>\n    <td colspan=\"2\">高度重叠 (≥ 90%)</td>\n    <td>16.25%</td>\n  </tr>\n  <tr>\n    <td rowspan=\"4\">任务耗时 (分钟)</td>\n    <td>第一组 (LLM)</td>\n    <td>-0.80</td>\n    <td>95% CI [-1.15, -0.46], d = -0.34</td>\n  </tr>\n  <tr>\n    <td>第一组 (笔记)</td>\n    <td>10-15 区间</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>第二组 (仅LLM)</td>\n    <td>-1.54</td>\n    <td>95% CI [-1.91, -1.17], d = -0.66</td>\n  </tr>\n  <tr>\n    <td>第二组 (LLM + 笔记)</td>\n    <td>10-15 区间</td>\n    <td>-</td>\n  </tr>\n</table>\n\n# 2.6 学生任务指导说明\n\n表8：主动阅读策略介绍（所有实验条件通用）\n\n<table>\n  <tr>\n    <td>当您试图学习并理解一篇文章时，主动阅读（active reading）可作为一种有效策略。\n      它能帮助您更深入地处理信息，从而提升学习效果。主动阅读包括：\n      · 识别文本中的核心观点与概念\n      · 理解其含义\n      · 分析概念间的关联性\n      · 对信息提出疑问并尝试解答</td>\n  </tr>\n</table>\n\n表9：按实验条件划分的学习活动导语<table><tr><td>实验条件</td><td>活动说明</td></tr><tr><td>笔记记录</td><td>您的任务是尝试理解并学习一篇历史文本。为此，请积极阅读文本并通过记笔记来辅助学习。笔记记录是主动阅读的重要组成部分，其目的并非大量摘抄文本信息，而是需要找出章节中的关键信息，思考其含义，并用您自己的语言进行记录。</td></tr><tr><td>大语言模型</td><td>您的任务是尝试理解并学习一篇历史文本。为此，请积极阅读文本并借助AI聊天机器人进行辅助学习。与AI聊天机器人对话有助于提升阅读主动性，您可针对文本内容提出不同问题以理解历史事件的脉络，这也有助于识别和理解关键信息。</td></tr><tr><td>大语言模型+笔记记录</td><td>您的任务是尝试理解并学习一篇历史文本。为此，请结合积极阅读、AI聊天机器人和笔记记录三种方式。与AI聊天机器人对话可增强阅读主动性，通过提问深化对文本内容的理解；同时，笔记记录对主动阅读至关重要——需提取章节关键信息，进行意义阐释，并以个人语言完成记录，而非简单摘抄原文。</td></tr></table>\n\n表10：不同实验条件的具体指导说明<table><tr><td>条件</td><td>具体说明</td></tr><tr><td>笔记</td><td>在阅读过程中进行主动阅读并记录笔记。即使你认为已完全理解内容，仍需尽力而为。思考以下要点并记录以辅助理解：\n· 重要词汇与概念的含义\n· 复杂句子的释义\n· 关键要点或观点（如时间、地点、人物与事件）\n· 地点、人物与事件之间的关联\n· 事件经过及其成因与发生机制\n· 观点与概念间的异同点\n· 对文本的个人理解</td></tr><tr><td>LLM</td><td>在阅读过程中进行主动阅读并同步使用AI聊天机器人。即使你认为已完全理解内容，仍需尽力而为。思考以下要点并借助AI聊天机器人辅助理解，例如可要求其：\n· 解释重要词汇与概念的含义\n· 重构或简化复杂句子并加以说明\n· 总结文本并识别关键要点（如时间、地点、人物与事件）\n· 厘清不理解的信息\n· 阐释地点、人物与事件之间的关联\n· 说明事件经过及其成因与发生机制\n· 识别观点与概念间的异同点\n· 检验对文本的理解程度\n同时还可：\n· 若对AI回复不理解或存疑，要求进一步解释\n· 提出后续追问\n· 要求采用项目符号、缩短答复或使用更简练的语言</td></tr><tr><td>LLM+笔记</td><td>在阅读过程中同步进行主动阅读、使用AI聊天机器人及记录笔记。即使你认为已完全理解内容，仍需尽力而为。思考以下要点，并借助AI聊天机器人与笔记辅助理解，例如可要求AI：\n· 解释重要词汇与概念的含义\n· 重构或简化复杂句子并加以说明\n· 总结文本并识别关键要点（如时间、地点、人物与事件）\n· 厘清不理解的信息\n· 阐释地点、人物与事件之间的关联\n· 说明事件经过及其成因与发生机制\n· 识别观点与概念间的异同点\n· 检验对文本的理解程度\n同时还可：\n· 若对AI回复不理解或存疑，要求进一步解释\n· 提出后续追问\n· 要求采用项目符号、缩短答复或使用更简练的语言</td></tr></table>\n\n# 2.7 测试问题\n\n表11：字面保持、理解与自由回忆的示例问题<table><tr><td>构念维度</td><td>题目类型</td><td>示例题目</td></tr><tr><td colspan=\"2\">字面记忆</td><td></td></tr><tr><td></td><td>简答题</td><td>1976年索韦托青年起义中发生了什么恐怖事件？（文本A）\n肯尼迪总统在宣布古巴周边海军行动时为何避免使用\"封锁\"一词？（文本B）</td></tr><tr><td></td><td>选择题</td><td>什么事件引发了暴力的反种族隔离抗议？（文本A）\n1) 警方强制实施种族隔离\n2) 警方逮捕纳尔逊·曼德拉\n3) 警方杀害黑人平民\n4) 警方实行严格宵禁\n美国政府如何发现古巴存在苏联导弹？（文本B）\n1) 古巴线人告知导弹情报\n2) 古巴政府威胁使用导弹\n3) 美国海军拦截苏联运导弹船只\n4) 美国飞机拍摄到导弹照片</td></tr><tr><td colspan=\"2\">理解能力</td><td></td></tr><tr><td></td><td>简答题</td><td>阐述纳尔逊·曼德拉在种族隔离时期及其最终废除过程中发挥的作用。\n仅需撰写简短段落。（文本A）\n阐述苏联在古巴导弹危机中扮演的角色。\n仅需撰写简短段落。（文本B）</td></tr><tr><td colspan=\"2\">自由回忆</td><td></td></tr><tr><td></td><td>开放题</td><td>请写下你从《[标题]》一文中记住的所有内容。尽量包含尽可能多的细节。\n例如，可思考事件经过、成因、方式、时间、地点及涉及人物。\n可采用完整句子或要点形式作答。</td></tr></table>\n\n# 2.8 评分者间信度结果\n\n表12：编码者间信度<table><tr><td>项目</td><td>ICC (A,1)</td><td>p值</td><td>95%置信区间</td><td>项目</td><td>ICC (A,1)</td><td>p值</td><td>95%置信区间</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10<sup>-24</sup></td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10<sup>-32</sup></td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10<sup>-32</sup></td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10<sup>-61</sup></td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10<sup>-45</sup></td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10<sup>-43</sup></td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10<sup>-30</sup></td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10<sup>-42</sup></td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10<sup>-27</sup></td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10<sup>-36</sup></td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10<sup>-44</sup></td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10<sup>-39</sup></td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10<sup>-24</sup></td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10<sup>-33</sup></td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10<sup>-27</sup></td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10<sup>-31</sup></td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10<sup>-25</sup></td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10<sup>-39</sup></td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10<sup>-33</sup></td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10<sup>-30</sup></td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10<sup>-39</sup></td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10<sup>-40</sup></td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10<sup>-60</sup></td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10<sup>-42</sup></td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10<sup>-38</sup></td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10<sup>-33</sup></td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10<sup>-56</sup></td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 调查问题与应答量表\n\n表13：调查问题与应答量表 - 第一阶段<table><tr><td>**变量**</td><td>**问题及应答量表**</td></tr><tr><td>文本难度</td><td>您觉得关于[文章标题]的文本理解起来有多困难？\n（一点也不困难，不太困难，有些困难，比较困难，非常困难）</td></tr><tr><td>主题熟悉度</td><td>在开始任务前，您对[文章标题]主题的了解程度如何？\n（完全不了解，了解很少，了解程度一般，了解较多，非常了解）</td></tr><tr><td>主题兴趣度</td><td>您觉得关于[文章标题]的文本有多有趣？\n（一点也没趣，不太有趣，有些有趣，比较有趣，非常有趣）</td></tr><tr><td>活动愉悦度</td><td>在[活动名称]的辅助下学习文本的愉悦程度如何？\n（一点也不愉悦，不太愉悦，有些愉悦，比较愉悦，非常愉悦）</td></tr><tr><td>活动难度</td><td>总体而言，您觉得[活动名称]的难度如何？\n（一点也不困难，不太困难，有些困难，比较困难，非常困难）</td></tr><tr><td>活动帮助度</td><td>[活动名称]对理解和学习文本的帮助程度如何？\n（完全没有帮助，帮助很小，有些帮助，比较有帮助，非常有帮助）</td></tr><tr><td>活动未来使用意向</td><td>未来您是否会使用类似的方法（[活动名称]）来理解和学习文本？\n（是，否，不确定）</td></tr><tr><td>任务兴趣度</td><td>总体而言，您觉得这项任务有多有趣？\n（一点也没趣，不太有趣，有些有趣，比较有趣，非常有趣）</td></tr><tr><td>任务投入度</td><td>您在理解和学习关于[文章标题]的文本上投入了多少努力？\n（完全没有投入，只投入了一点努力，投入了一些努力，投入了较多努力，投入了非常多努力）</td></tr><tr><td>自我感知任务表现</td><td>您认为自己在这项任务中的表现如何？\n（一点也不好，不太好，一般，比较好，非常好）</td></tr><tr><td>活动偏好</td><td>第一组：在本研究的两种学习方法中，您更偏好哪一种（记笔记或AI聊天机器人）？\n（我更偏好通过记笔记学习，我更偏好借助AI聊天机器人学习，没有偏好，不确定）\n<br>\n第二组：在本研究的两种学习方法中，您更偏好哪一种（仅使用AI聊天机器人或AI聊天机器人结合记笔记）？\n（我更偏好仅借助AI聊天机器人学习，我更偏好同时借助AI聊天机器人和记笔记学习，没有偏好，不确定）</td></tr><tr><td>偏好原因</td><td>您能告诉我们为什么偏好这种方法吗？[开放式回答]</td></tr><tr><td>先前LLM使用情况</td><td>在本研究之前，您是否曾使用过AI聊天机器人（例如ChatGPT、Microsoft Bing和Google Bard AI）？\n（是，否）</td></tr><tr><td>LLM使用频率</td><td>您使用AI聊天机器人的频率大约是？\n（每周少于一次，每周一到两天，每周三到五天，几乎每天）</td></tr><tr><td>学习时记笔记频率</td><td>您在为学业（如准备课程或考试）阅读文本时，记笔记的频率如何？\n（从不，很少，有时，经常，总是）</td></tr><tr><td>学习时使用LLM频率</td><td>您在为学业（如准备课程或考试）阅读文本时，使用AI聊天机器人的频率如何？\n（从不，很少，有时，经常，总是）</td></tr><tr><td>学习时同时使用LLM与记笔记频率</td><td>仅限第二组：您在为学业阅读文本时，同时使用两种方法（使用AI聊天机器人和记笔记）的频率如何？\n（从不，很少，有时，经常，总是）</td></tr></table>表14：调查问题及应答量表 - 第二阶段\n\n<table><tr><td>变量</td><td>测量项及应答类别</td></tr><tr><td>感知测试表现</td><td>若[篇章标题]部分所有题目合计满分为100分，您预计自己大约能获得多少分？[开放性问题]</td></tr><tr><td>间歇期学习行为</td><td>自第一次实验至今，您是否通过任何方式对两篇文本的主题进行了深入探究或理解？（包括但不限于网络检索信息、课后记录笔记或与他人讨论该主题）如有相关行为，请尽可能详细说明。[开放性问题]</td></tr><tr><td>性别</td><td>您的性别是？[开放性问题]</td></tr><tr><td>EAL（英语作为附加语言）</td><td>您使用哪种语言进行交流时感觉最自如？\n（英语、英语以外的语言、英语与其他语言同样熟练）</td></tr><tr><td>历史学科背景</td><td>您是否正在攻读GCSE历史课程？（是/否）</td></tr></table>\n\n# 2.10 学习体验与认知\n\n表15：不同实验条件下（组1与组2）学习体验与认知的差异比较<table>\n<tr>\n<td rowspan=\"2\">变量</td>\n<td colspan=\"5\">组 1: LLM vs 笔记</td>\n<td colspan=\"5\">组 2: LLM vs LLM+笔记</td>\n</tr>\n<tr>\n<td>差值</td>\n<td>t(自由度)</td>\n<td>p 值</td>\n<td>95% 置信区间</td>\n<td>效应量 d</td>\n<td>差值</td>\n<td>t(自由度)</td>\n<td>p 值</td>\n<td>95% 置信区间</td>\n<td>效应量 d</td>\n</tr>\n<tr>\n<td>活动帮助性</td>\n<td>0.41</td>\n<td>4.38(181)</td>\n<td>&lt;0.001</td>\n<td>[0.22, 0.59]</td>\n<td>0.33</td>\n<td>-0.03</td>\n<td>-0.35(157)</td>\n<td>0.724</td>\n<td>[-0.21, 0.15]</td>\n<td>-0.03</td>\n</tr>\n<tr>\n<td>活动难度</td>\n<td>-0.51</td>\n<td>-7.00(181)</td>\n<td>&lt;0.001</td>\n<td>[-0.66, -0.37]</td>\n<td>-0.52</td>\n<td>-0.41</td>\n<td>-4.99(159)</td>\n<td>&lt;0.001</td>\n<td>[-0.57, -0.25]</td>\n<td>-0.40</td>\n</tr>\n<tr>\n<td>任务投入度</td>\n<td>-0.25</td>\n<td>-3.53(182)</td>\n<td>0.001</td>\n<td>[-0.38, -0.11]</td>\n<td>-0.26</td>\n<td>-0.08</td>\n<td>-1.03(159)</td>\n<td>0.305</td>\n<td>[-0.22, 0.07]</td>\n<td>-0.08</td>\n</tr>\n<tr>\n<td>活动愉悦度</td>\n<td>0.68</td>\n<td>6.50(181)</td>\n<td>&lt;0.001</td>\n<td>[0.47, 0.89]</td>\n<td>0.48</td>\n<td>0.00</td>\n<td>0.00(158)</td>\n<td>1.000</td>\n<td>[-0.16, 0.16]</td>\n<td>0.00</td>\n</tr>\n<tr>\n<td>文本兴趣度</td>\n<td>-0.11</td>\n<td>-1.38(183)</td>\n<td>0.170</td>\n<td>[-0.26, 0.05]</td>\n<td>-0.10</td>\n<td>0.06</td>\n<td>0.79(159)</td>\n<td>0.428</td>\n<td>[-0.09, 0.22]</td>\n<td>0.06</td>\n</tr>\n<tr>\n<td>文本难度</td>\n<td>0.03</td>\n<td>0.50(183)</td>\n<td>0.621</td>\n<td>[-0.10, 0.16]</td>\n<td>0.04</td>\n<td>0.03</td>\n<td>0.41(159)</td>\n<td>0.684</td>\n<td>[-0.10, 0.15]</td>\n<td>0.03</td>\n</tr>\n<tr>\n<td>任务兴趣度</td>\n<td>0.09</td>\n<td>1.01(183)</td>\n<td>0.315</td>\n<td>[-0.09, 0.27]</td>\n<td>0.07</td>\n<td>-0.06</td>\n<td>-0.79(159)</td>\n<td>0.430</td>\n<td>[-0.20, 0.08]</td>\n<td>-0.06</td>\n</tr>\n<tr>\n<td>感知任务表现</td>\n<td>0.00</td>\n<td>0.00(182)</td>\n<td>1.000</td>\n<td>[-0.14, 0.14]</td>\n<td>0.00</td>\n<td>-0.11</td>\n<td>-1.45(158)</td>\n<td>0.150</td>\n<td>[-0.25, 0.04]</td>\n<td>-0.12</td>\n</tr>\n<tr>\n<td>感知测试表现</td>\n<td>-9.66</td>\n<td>-5.53(177)</td>\n<td>&lt;0.001</td>\n<td>[-13.11, -6.22]</td>\n<td>-0.42</td>\n<td>-6.80</td>\n<td>-3.55(143)</td>\n<td>0.001</td>\n<td>[-10.59, -3.02]</td>\n<td>-0.30</td>\n</tr>\n</table>\n\n# 2.11 活动偏好编码方案\n\n表 16: 编码方案：偏好 LLM 胜过 LLM+笔记<table><tr><td>代码</td><td>描述</td><td>示例</td></tr><tr><td>单独使用LLM更快捷</td><td>单独使用大语言模型比同时记笔记更节省时间，因为记笔记会耗费额外时间。</td><td>“使用LLM耗时更少”、“记笔记太花时间”</td></tr><tr><td>二者并用非必需</td><td>当LLM已能解释文本内容时，记笔记显得不必要。</td><td>“既然机器人已帮助解释，记笔记似乎没有必要”、“使用其中一种意味着不需要另一种”</td></tr><tr><td>LLM代劳</td><td>若单独使用LLM，用户无需亲力亲为。不记笔记能使任务变得更轻松。</td><td>“不需要做任何工作”、“能立即澄清未知信息而无需仔细查阅文本”、“同时使用聊天机器人和记笔记很困难”</td></tr><tr><td>记笔记占用提问时间</td><td>记笔记会减少向LLM提问或理解文本的时间。</td><td>“记笔记时没有足够时间提问”、“有更多时间理解文本”</td></tr><tr><td>LLM不支持记笔记</td><td>LLM未能降低记笔记的难度。</td><td>“对简化记笔记过程帮助有限”</td></tr></table>\n\n表17：编码方案：LLM优于笔记的偏好维度<table><tr><td>代码</td><td>描述</td><td>示例</td></tr><tr><td>LLM 更快捷</td><td>LLM 速度更快且节省时间。</td><td>“更省时”、“快得多”</td></tr><tr><td>LLM 更简便</td><td>与需要更多精力且难度更高的笔记记录相比，LLM 操作简单且无需太多精力。</td><td>“更简单”、“它更容易操作”</td></tr><tr><td>LLM 具有（互动）主动性</td><td>LLM 是一种互动性或主动性的学习活动。</td><td>“主动与机器人互动”、“感觉更具互动性”</td></tr><tr><td>LLM 具有情感吸引力</td><td>LLM 更有趣、更令人愉悦且更具吸引力。</td><td>“喜欢阅读它的回答”、“使用起来更有趣”</td></tr><tr><td>LLM 有助于集中注意力</td><td>LLM 帮助您专注于文本内容。</td><td>“让我能更专注于文本”</td></tr><tr><td>LLM 促进理解</td><td>LLM 有助于理解并帮助您检验理解程度。</td><td>“它让你更好地理解”、“我可以确认任何不确定的内容以确保自己理解正确”</td></tr><tr><td>LLM 辅助学习</td><td>LLM 对学习具有支持作用。</td><td>“AI 帮助我更高效地学习”、“我能够更轻松快速地理解和学习文本，并达到更高水平”</td></tr><tr><td>LLM 可回答问题</td><td>LLM 因能回答问题并解释不理解的内容而对理解有帮助。</td><td>“可以提出任何相关问题”、“如果我有疑问，它都能解答”</td></tr><tr><td>LLM 可提供背景和补充信息</td><td>LLM 因能提供背景信息并详细阐述事件经过而对理解有帮助。</td><td>“我获得了更多背景信息”、“它提供了完整的背景语境”</td></tr><tr><td>LLM 可总结和简化信息</td><td>LLM 因能简化信息、重新表述内容并进行总结而对理解有帮助。</td><td>“它以更简单的方式和形式呈现”、“我可以要求 AI 聊天机器人重新表述关键点”、“它可以总结要点”</td></tr><tr><td>LLM 有助于记忆</td><td>LLM 帮助您记住文本中的信息。</td><td>“它更深刻地印在我的脑海里”、“通过提供提示性问题、记忆法等帮助我记忆”、“比笔记记录花费更少的记忆时间”</td></tr></table>\n\n表 18：编码方案：相较于 LLM 的偏好笔记<table>\n<tr>\n<td>代码</td>\n<td>描述</td>\n<td>示例</td>\n</tr>\n<tr>\n<td>笔记有助于提升记忆力</td>\n<td>记笔记有助于记忆信息，因为这是一个物理书写过程。LLM 在帮助记忆方面效果较差。</td>\n<td>“写下内容能让我记得更牢”、“更有助于培养记忆力”、“通过记笔记我学到了更多”、“只是提供了更多背景信息，而非巩固知识”。</td>\n</tr>\n<tr>\n<td>笔记促进理解</td>\n<td>记笔记有助于深化理解并检验理解程度。</td>\n<td>“更容易理解阅读内容”、“我的理解更深入了”、“通过复述来检验学习成果”。</td>\n</tr>\n<tr>\n<td>记笔记是主动学习过程</td>\n<td>记笔记是更具主动性的行为。</td>\n<td>“更好的主动阅读方式”、“让我能够主动参与”。</td>\n</tr>\n<tr>\n<td>笔记是个人劳动成果</td>\n<td>记笔记意味着独立完成工作。需要自主思考，使用个人语言并记录自身观点。</td>\n<td>“必须亲自分析信息”、“可以将信息浓缩成自己的话”、“促使我独立思考”、“这是你对所审视事物的个人见解”、“让我未来能为自己的成果感到自豪”。</td>\n</tr>\n<tr>\n<td>笔记辅助信息处理</td>\n<td>记笔记有助于信息加工处理。</td>\n<td>“能够分解和处理文本”、“自己总结第二篇文本帮助我处理信息”。</td>\n</tr>\n<tr>\n<td>笔记助力学习</td>\n<td>笔记帮助学习、记录所学或检验学习效果。</td>\n<td>“可以写下自己掌握的知识点”、“能够真正学习信息而非被动接受”。</td>\n</tr>\n<tr>\n<td>笔记便于回顾</td>\n<td>相比LLM输出内容，笔记更便于重新查阅。可轻松获取既往学习记录和思考轨迹。</td>\n<td>“复习时可以回头查看这些笔记”、“记笔记为未来提供了更好的回顾材料”。</td>\n</tr>\n<tr>\n<td>笔记操作更简便</td>\n<td>记笔记比使用LLM更简单。</td>\n<td>“更容易进行总结”、“不知道，就是更简单”。</td>\n</tr>\n<tr>\n<td>笔记增强条理性</td>\n<td>笔记有助于整理信息和思路，将其分解为小块以提升清晰度。</td>\n<td>“便于整理笔记”、“更容易追踪思维轨迹”、“帮助我将文本分解成小模块”。</td>\n</tr>\n<tr>\n<td>LLM易分散注意力且信息过载</td>\n<td>LLM容易导致分心，可能提出不相关问题或关注非重点内容。其提供过多信息，易造成认知负荷或混淆。</td>\n<td>“发现很容易被AI分散注意力，更想随意提问”、“由于信息过多导致表述不清晰”。</td>\n</tr>\n<tr>\n<td>LLM内容重复枯燥</td>\n<td>LLM因多次重复信息而显得单调乏味。</td>\n<td>“感觉它只是在不断重复”。</td>\n</tr>\n<tr>\n<td>不确定如何提问</td>\n<td>因已完全理解内容而不需要LLM，或不熟悉使用方法及提问技巧。</td>\n<td>“难以构思向AI提问的问题”、“文本非常简单因此觉得无需过多提问”。</td>\n</tr>\n</table>表19：编码方案：LLM+注释相较于LLM的偏好<table><tr><td>代码</td><td>描述</td><td>示例</td></tr><tr><td>两者结合更具趣味性</td><td>同时使用LLM和笔记更有趣、更令人愉悦，而单独使用LLM可能枯燥乏味。</td><td>“我喜欢同时使用两者”、“如果必须使用聊天机器人并询问20个问题，我会非常无聊。”</td></tr><tr><td>两者结合实现优势互补</td><td>LLM和笔记可以互补使用以发挥各自优势，例如先自主完成工作，在不确定或遇到困难时再使用LLM。</td><td>“同时拥有自己总结的关键笔记和更详细的文本会更方便”、“这种方式让我既能以自己理解的方式记录事件关键点，又能就模糊内容获得AI聊天机器人的帮助”</td></tr><tr><td>两者结合更高效便捷</td><td>关于该策略对理解和学习更具帮助、更优越或更便捷的总体评价。</td><td>“最具帮助性且易于学习”、“因为我觉得这种方式更容易记忆和学习”</td></tr><tr><td>笔记辅助处理和理解LLM信息</td><td>笔记有助于处理和理解LLM提供的信息。</td><td>“为了处理这些信息，我发现同时做笔记非常有帮助”</td></tr><tr><td>笔记有助于信息组织</td><td>LLM提供信息，但需要笔记来整理和构建思路。笔记更具聚焦性且易于查阅。</td><td>“如果仅使用聊天机器人，我需要不断滚动屏幕查找内容”、“这样更容易跟踪信息并进行回顾”</td></tr><tr><td>笔记体现个人劳动</td><td>做笔记意味着进行实际工作，能够捕捉个人思考而非仅仅阅读输出内容。</td><td>“这代表我确实在进行实际工作”</td></tr><tr><td>笔记辅助记忆</td><td>笔记有助于信息记忆。</td><td>“我喜欢手写记录信息，因为这能帮助我更好地记忆”</td></tr><tr><td>笔记促进理解</td><td>做笔记有助于深化理解并检验理解程度。</td><td>“在纸上简化信息使其更易于理解和记忆”</td></tr><tr><td>笔记助力学习</td><td>笔记有助于学习过程，能够捕捉学习成果或检验学习效果。</td><td>“这样能学到更多”、“可以在笔记中简化所学内容”</td></tr><tr><td>LLM可能提供错误答案</td><td>LLM并非总能良好回答问题，有时甚至完全无法应答。LLM可能产生有害内容。</td><td>“我对机器人提出的某些问题没有得到明确回答”</td></tr><tr><td>LLM并非始终可用</td><td>需要掌握笔记技能，因为LLM可能无法随时使用。</td><td>“你不可能随时都有AI聊天机器人可用”</td></tr><tr><td>不确定如何向机器人提问</td><td>因已完全理解内容而不需要LLM，或不了解其使用方法及提问方式。</td><td>“我不确定该对机器人说什么，这有点令人烦躁”</td></tr></table># 2.12 编码方案提示交互\n\n完整提示编码方案请参阅表格文件 'PromptCoding.xlsx'\n\n表20：提示编码方案\n\n<table>\n  <tr>\n    <td>总体编码</td>\n    <td>子编码</td>\n    <td>描述与示例</td>\n  </tr>\n  <tr>\n    <td>信息浓缩</td>\n    <td>总结</td>\n    <td>学生要求机器人总结整篇文本或特定文本选段。\n    示例：“帮我总结这一段”、“总结文本”、“给我第一段的摘要”、“告诉我这篇文章是关于什么的。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>记笔记</td>\n    <td>学生要求机器人就整篇文本或特定段落做笔记。\n    示例：“为第一段做笔记。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>识别关键观点</td>\n    <td>学生要求机器人识别文本中的关键观点或要点信息，包括关键日期、地点、人物和事件。\n    示例：“主要观点是什么？”、“给我所有重要的日期”、“要点信息是什么？”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>创建时间线</td>\n    <td>学生要求机器人创建文本中描述事件的时间线。\n    示例：“将重要日期按时间顺序排列”、“给我事件的时间线。”</td>\n  </tr>\n  <tr>\n    <td>理解文本</td>\n    <td>定义词语或概念</td>\n    <td>学生要求机器人定义或解释文本中的特定词语或概念。他们请求帮助理解术语，但不寻求超出此范围的事实信息。\n    示例：“apartheid是什么意思？”、“什么是殖民地？”、“什么是导弹？”、“我不知道blockade是什么意思。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>简化或解释难句</td>\n    <td>学生要求机器人简化或解释所提供的段落或特定选段。\n    示例：“用简单的词语解释这个”、“让文本更简单”、“这个句子是什么意思？”、“简化这段文本。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>检查理解</td>\n    <td>学生阐述自己的理解并向机器人寻求确认。\n    示例：“美国不喜欢古巴是因为他们认为卡斯特罗是共产主义者，对吗？”、“所以是一名军官阻止了整个战争？”</td>\n  </tr>\n  <tr>\n    <td>寻求额外信息与深化理解</td>\n    <td>一般背景</td>\n    <td>学生要求提供文本中提及的地点、时间或人物的背景信息以提供上下文——这些信息对于理解文本并非核心，但可能相关。\n    示例：“肯尼迪是谁？”、“曼德拉因何闻名？”、“告诉我更多关于古巴的信息”、“非洲有多少英国殖民地？”、“土耳其的导弹部署在哪里？”</td>\n  </tr>\n</table>\n\n转下页<table>\n<tr>\n  <td><strong>主代码</strong></td>\n  <td><strong>子代码</strong></td>\n  <td><strong>描述与示例</strong></td>\n</tr>\n<tr>\n  <td rowspan=\"4\">寻求补充信息与深化理解</td>\n  <td>阐述与深化理解</td>\n  <td>学生要求获取事件的更多细节，例如事件原因、涉及人物及结果。<br>示例：“美国为什么不喜欢卡斯特罗？”“流亡者为何入侵古巴？”“种族隔离期间黑人的感受如何？”</td>\n</tr>\n<tr>\n  <td>请求示例或类比</td>\n  <td>学生要求通过示例或类比来更好地理解概念或事件。<br>示例：“种族隔离影响日常生活的具体案例有哪些？”“能否用类比说明冷战紧张局势？”“通过了哪些不公正法律？”“有哪些抵制运动？”</td>\n</tr>\n<tr>\n  <td>请求对比或比较</td>\n  <td>学生要求对比或比较概念、事件或人物。<br>示例：“种族隔离与美国种族隔离有何不同？”“比较肯尼迪与赫鲁晓夫的领导风格。”</td>\n</tr>\n<tr>\n  <td>批判性分析或评价</td>\n  <td>学生要求对行动、情境、决策或陈述进行批判性分析或评价。<br>示例：“肯尼迪决策的优缺点是什么？”“评估封锁行动的有效性。”</td>\n</tr>\n<tr>\n  <td>影响与意义</td>\n  <td>影响与意义</td>\n  <td>学生询问文本信息的深层影响、相关性或后果。<br>示例：“这场危机的长期影响是什么？”“当前局势如何？”“为什么我需要关注或学习这个内容？”</td>\n</tr>\n<tr>\n  <td>学习与记忆辅助</td>\n  <td>学习与记忆辅助</td>\n  <td>学生请求辅助学习并记忆文本内容，包括要求进行知识测验。<br>示例：“创建记忆口诀”“提出四个关于文本的问题”“如何更好地记住这些内容？”</td>\n</tr>\n<tr>\n  <td rowspan=\"3\">与机器人交互</td>\n  <td>要求特定格式或长度</td>\n  <td>学生要求机器人以特定格式或长度提供回复。<br>示例：“用要点总结主要内容”“能否制作政策对比图表？”“请用简短表述”“请缩短内容”</td>\n</tr>\n<tr>\n  <td>要求改进表达</td>\n  <td>学生要求机器人优化回复或改用更简洁的方式重述，而非要求简化给定文本。<br>示例：“我不理解你的意思”“请用更简短的方式重新解释”“你的意思是？”“请说得更简单”“能用更简单的术语表达吗？”“请缩短摘要”</td>\n</tr>\n<tr>\n  <td>关系性语言</td>\n  <td>学生进行与文本无关的随意礼貌对话。<br>示例：“你好吗？”“谢谢”“你好”</td>\n</tr>\n</table>\n\n（接下页）<table><tr><td>主编码</td><td>子编码</td><td>描述与示例</td></tr><tr><td rowspan=\"2\">与AI交互</td><td>核查来源与可信度</td><td>学生询问信息来源或质疑信息准确性<br>示例：\"你的信息来源是什么？\"、\"我为什么要相信你？\"、\"我认为你的答案是错误的\"</td></tr><tr><td>无特定请求的文本粘贴</td><td>学生直接复制所提供段落中的文本，但未将其构建为具体问题或请求<br>示例：\"纳尔逊·曼德拉\"、\"1910年，四个英国殖民地合并成立南非联邦\"、\"导弹\"</td></tr><tr><td rowspan=\"3\">无关内容/离题/杂项</td><td>与文本无关</td><td>学生提出与文本或其背景无关的问题<br>示例：\"切·格瓦拉是谁？\"、\"歌曲《阿布拉克萨斯》是什么？\"</td></tr><tr><td>杂项</td><td>用于无法归类至其他编码的对话片段（最后选择）</td></tr><tr><td>无意义输入</td><td>学生输入无意义的字符、符号或无法构成连贯词句的文本<br>示例：\"asdfgh\"、\"。\"、\"123\"、\"？？？\"</td></tr></table>\n\n# 2.13 提示类型频次分析\n\n表21：主要提示类型出现频次  \n\n<table><tr><td>主要提示类型</td><td>频次</td></tr><tr><td colspan=\"2\"><strong>原型类别</strong></td></tr><tr><td>寻求补充信息与深度理解</td><td>2265</td></tr><tr><td>信息浓缩</td><td>749</td></tr><tr><td>文本理解</td><td>615</td></tr><tr><td>学习与记忆辅助</td><td>39</td></tr><tr><td colspan=\"2\"><strong>其他类别</strong></td></tr><tr><td>与AI交互</td><td>760</td></tr><tr><td>无关内容/离题/杂项</td><td>501</td></tr></table>\n\n表22：具体提示类型出现频次<table><tr><td>总体提示类型</td><td>具体提示类型</td><td>频次</td></tr><tr><td>寻求补充信息与深度理解</td><td>细节阐述与深度理解</td><td>1479</td></tr><tr><td>信息浓缩</td><td>总结归纳</td><td>588</td></tr><tr><td>寻求补充信息与深度理解</td><td>背景知识</td><td>514</td></tr><tr><td>文本理解</td><td>定义词汇或概念</td><td>463</td></tr><tr><td>与机器人交互</td><td>要求特定格式或长度</td><td>430</td></tr><tr><td>无关/离题/杂项</td><td>与文本无关</td><td>296</td></tr><tr><td>文本理解</td><td>简化或解释难句</td><td>126</td></tr><tr><td>寻求补充信息与深度理解</td><td>隐含意义与重要性</td><td>119</td></tr><tr><td>信息浓缩</td><td>识别核心观点</td><td>114</td></tr><tr><td>与机器人交互</td><td>要求改进</td><td>113</td></tr><tr><td>与机器人交互</td><td>无特定要求的文本粘贴</td><td>106</td></tr><tr><td>与机器人交互</td><td>关系性语言</td><td>105</td></tr><tr><td>无关/离题/杂项</td><td>无意义输入</td><td>109</td></tr><tr><td>无关/离题/杂项</td><td>杂项</td><td>96</td></tr><tr><td>寻求补充信息与深度理解</td><td>要求示例或类比</td><td>66</td></tr><tr><td>寻求补充信息与深度理解</td><td>批判性分析或评估</td><td>54</td></tr><tr><td>学习与记忆辅助</td><td>学习与记忆辅助</td><td>39</td></tr><tr><td>寻求补充信息与深度理解</td><td>要求对比或比较</td><td>31</td></tr><tr><td>文本理解</td><td>理解程度确认</td><td>26</td></tr><tr><td>信息浓缩</td><td>笔记整理</td><td>26</td></tr><tr><td>信息浓缩</td><td>创建时间线</td><td>21</td></tr><tr><td>与机器人交互</td><td>核查来源与可信度</td><td>6</td></tr></table>\n\n注：本表仅收录学生使用次数达到三次及以上的提示类型。",
    "created_at": "2025-12-16 00:10:45.083196",
    "updated_at": "2025-12-16 00:11:18.114993",
    "doi": "10.1186/s41239-023-00408-3",
    "arxiv_id": "2401.15081",
    "analysis": {
      "paper_id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
      "status": "completed",
      "started_at": "2025-12-16T00:35:26.593835",
      "completed_at": "2025-12-16T00:35:39.405634",
      "summary": "本研究旨在探讨在中学教育环境中，使用大型语言模型（LLMs）与传统笔记记录对学生的阅读理解能力和记忆保持的影响。研究采用预注册的随机对照实验，对405名14-15岁的学生进行了测试，比较了单独使用LLM、单独做笔记以及两者结合使用三种学习方式的效果。\n\n研究发现，与单独使用LLM相比，单独做笔记以及将笔记与LLM结合使用，在三天后的记忆保持和阅读理解测试中都产生了显著更积极的效果。然而，大多数学生主观上更偏好并认为LLM更有帮助。定性分析表明，学生认为LLM有助于降低认知负荷、使复杂材料更易理解，而笔记则能促进更深层次的投入并辅助记忆。研究还识别了学生与LLM交互的不同提示行为“原型”。\n\n结论指出，虽然笔记更能促进认知投入和长期的知识理解与记忆，但LLM可能在辅助初步理解和激发学生兴趣方面具有优势。研究强调了传统学习方法的重要性，揭示了结合使用AI与传统方法优于单独使用AI，并指出学生需要掌握相应的AI使用技能以最大化学习收益。",
      "methods": [
        {
          "name": "随机对照实验",
          "description": "采用预注册的随机对照实验设计，包含组内和组间设计元素。研究在中学环境中进行，比较不同学习策略对阅读理解的影响。",
          "location": null
        },
        {
          "name": "定量分析",
          "description": "通过阅读理解测试和记忆保持测试收集定量数据。使用统计方法分析不同学习条件对学习效果的影响。",
          "location": null
        },
        {
          "name": "定性分析",
          "description": "通过学生反馈和观察收集定性数据，分析学生对不同学习方法的感知和体验。识别学生与LLM交互的提示行为原型。",
          "location": null
        },
        {
          "name": "建构-整合模型分析",
          "description": "基于阅读理解的建构-整合模型，分析学生在表面结构、文本基础和情境模型三个层次的理解。",
          "location": null
        },
        {
          "name": "处理水平框架分析",
          "description": "运用处理水平框架分析信息编码深度对记忆保持的影响，关注语义分析和深度处理的作用。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "Affiliations:",
            "level": 1,
            "start_line": 9
          },
          {
            "title": "Abstract",
            "level": 1,
            "start_line": 14
          },
          {
            "title": "Main",
            "level": 1,
            "start_line": 18
          },
          {
            "title": "Results",
            "level": 1,
            "start_line": 46
          },
          {
            "title": "Learning outcomes",
            "level": 1,
            "start_line": 50
          },
          {
            "title": "Behavioural engagement",
            "level": 1,
            "start_line": 71
          },
          {
            "title": "Prompting behaviour",
            "level": 1,
            "start_line": 75
          },
          {
            "title": "Learning experiences and perceptions",
            "level": 1,
            "start_line": 93
          },
          {
            "title": "Activity preferences",
            "level": 1,
            "start_line": 109
          },
          {
            "title": "Future use",
            "level": 1,
            "start_line": 121
          },
          {
            "title": "Discussion",
            "level": 1,
            "start_line": 125
          },
          {
            "title": "Materials and Methods",
            "level": 1,
            "start_line": 153
          },
          {
            "title": "Participants",
            "level": 1,
            "start_line": 157
          },
          {
            "title": "Experimental design and procedure",
            "level": 1,
            "start_line": 165
          },
          {
            "title": "Setup and system",
            "level": 1,
            "start_line": 193
          },
          {
            "title": "Apartheid in South Africa",
            "level": 1,
            "start_line": 199
          },
          {
            "title": "AI Chatbot ②",
            "level": 1,
            "start_line": 209
          },
          {
            "title": "Notepad",
            "level": 1,
            "start_line": 213
          },
          {
            "title": "Learning task and materials (Session 1)",
            "level": 1,
            "start_line": 228
          },
          {
            "title": "Test task and materials (Session 2)",
            "level": 1,
            "start_line": 242
          },
          {
            "title": "Survey questions",
            "level": 1,
            "start_line": 256
          },
          {
            "title": "Analytic strategies",
            "level": 1,
            "start_line": 264
          },
          {
            "title": "Estimation of condition effects on text comprehension and retention",
            "level": 1,
            "start_line": 270
          },
          {
            "title": "Qualitative exploration of student prompts",
            "level": 1,
            "start_line": 302
          },
          {
            "title": "Quantitative exploration of students' learning experience",
            "level": 1,
            "start_line": 308
          },
          {
            "title": "Qualitative exploration of students' activity preferences",
            "level": 1,
            "start_line": 312
          },
          {
            "title": "Data availability",
            "level": 1,
            "start_line": 325
          },
          {
            "title": "Code availability",
            "level": 1,
            "start_line": 329
          },
          {
            "title": "Ethics declarations",
            "level": 1,
            "start_line": 333
          },
          {
            "title": "Competing interests",
            "level": 1,
            "start_line": 335
          },
          {
            "title": "Acknowledgements",
            "level": 1,
            "start_line": 339
          },
          {
            "title": "Supplementary Material",
            "level": 1,
            "start_line": 343
          },
          {
            "title": "Table of Contents",
            "level": 1,
            "start_line": 345
          },
          {
            "title": "Supplementary Information",
            "level": 1,
            "start_line": 347
          },
          {
            "title": "Supplementary Tables",
            "level": 1,
            "start_line": 351
          },
          {
            "title": "References",
            "level": 1,
            "start_line": 374
          },
          {
            "title": "1 Supplementary Information",
            "level": 1,
            "start_line": 451
          },
          {
            "title": "1.1 Participant Exclusion Criteria",
            "level": 1,
            "start_line": 453
          },
          {
            "title": "2 Supplementary Tables",
            "level": 1,
            "start_line": 464
          },
          {
            "title": "2.1 Student Characteristics",
            "level": 1,
            "start_line": 466
          },
          {
            "title": "2.2 Familiarity with Learning Activities",
            "level": 1,
            "start_line": 475
          },
          {
            "title": "2.3 Descriptive Statistics",
            "level": 1,
            "start_line": 483
          },
          {
            "title": "2.4 Mixed Effects Regression Results",
            "level": 1,
            "start_line": 489
          },
          {
            "title": "2.5 Behavioural Engagement",
            "level": 1,
            "start_line": 495
          },
          {
            "title": "2.6 Student Task Instructions",
            "level": 1,
            "start_line": 501
          },
          {
            "title": "2.7 Test Questions",
            "level": 1,
            "start_line": 567
          },
          {
            "title": "2.8 Inter-rater Reliability Results",
            "level": 1,
            "start_line": 589
          },
          {
            "title": "2.9 Survey Questions and Response Scales",
            "level": 1,
            "start_line": 595
          },
          {
            "title": "2.10 Learning Experiences and Perceptions",
            "level": 1,
            "start_line": 624
          },
          {
            "title": "2.11 Coding Scheme Activity Preferences",
            "level": 1,
            "start_line": 630
          },
          {
            "title": "2.12 Coding Scheme Prompt Interactions",
            "level": 1,
            "start_line": 653
          },
          {
            "title": "2.13 Frequency of Prompt Types",
            "level": 1,
            "start_line": 691
          }
        ]
      },
      "error_message": null
    },
    "is_translated": true,
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:281913760",
          "title": "Exploring the impact of artificial intelligence on business talent development in higher education:A systematic literature review and research agenda",
          "authors": [
            "Qinglan Wu",
            "Lanzhen Chen",
            "Minwei Chen",
            "Yangjie Huang"
          ],
          "year": 2026,
          "venue": "The International Journal of Management Education",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282741200",
          "title": "Revolutionizing business English instruction",
          "authors": [
            "Bendaoud Nadif",
            "Abderrahim Khoumich"
          ],
          "year": 2026,
          "venue": "American Journal of STEM Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283183996",
          "title": "Changing EAP assessment practices in the age of generative artificial intelligence: The case of Scottish higher education institutions",
          "authors": [
            "Lewis Urquhart",
            "X. M. Ngo"
          ],
          "year": 2026,
          "venue": "Journal of English for Academic Purposes",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283778482",
          "title": "Ethics and governance of generative AI in education: a systematic review on responsible adoption",
          "authors": [
            "Mohanad Alfiras",
            "Abdul Qader Emran",
            "Amr M. Mohamed"
          ],
          "year": 2025,
          "venue": "Discover Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283782189",
          "title": "Research on the refinement of college student education management based on artificial intelligence",
          "authors": [
            "Qiujia Lai"
          ],
          "year": 2025,
          "venue": "Discover Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283806994",
          "title": "Use of Technology for the Effectiveness of School Support Systems in Addressing Barriers to Learning",
          "authors": [
            "L. Tlale"
          ],
          "year": 2025,
          "venue": "Journal of Education and Learning Technology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283850330",
          "title": "Latent Dimensions of Innovation and Development in Selected Eastern European Countries: A Perspective Based on an Analysis of the Main Factors",
          "authors": [
            "C. Stoenoiu",
            "L. Jäntschi"
          ],
          "year": 2025,
          "venue": "World",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283812503",
          "title": "Development and Validation of an AI Literacy Scale for Pre-Service Teachers in Thailand",
          "authors": [
            "Pawarit Pingmuang",
            "Prakob Koraneekij",
            "Jintavee Khlaisang"
          ],
          "year": 2025,
          "venue": "Electronic Journal of e-Learning",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283702829",
          "title": "Transfer learning and AI technology for family school community collaborative model research in university network security management.",
          "authors": [
            "Qiongfang Feng",
            "Yang'an Chen"
          ],
          "year": 2025,
          "venue": "Scientific Reports",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283684161",
          "title": "Identifying key components and stakeholders for generative AI governance in higher education: a systematic literature review",
          "authors": [
            "Okky Putra Barus",
            "A. Hidayanto",
            "Imairi Eitiveni",
            "Kongkiti Phusavat",
            "Niko Sudibjo"
          ],
          "year": 2025,
          "venue": "Interactive Learning Environments",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T15:20:51.244989",
      "references": [
        {
          "external_id": "CorpusId:257943792",
          "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
          "authors": [
            "Tufan Adiguzel",
            "M. H. Kaya",
            "Fatih Kursat Cansu"
          ],
          "year": 2023,
          "venue": "Contemporary Educational Technology",
          "citation_count": 596
        },
        {
          "external_id": "CorpusId:259466894",
          "title": "Student partnership in assessment in higher education: a systematic review",
          "authors": [
            "C. Chan",
            "Si Chen"
          ],
          "year": 2023,
          "venue": "Assessment &amp; Evaluation in Higher Education",
          "citation_count": 20
        },
        {
          "external_id": "CorpusId:259088596",
          "title": "Is AI Changing the Rules of Academic Misconduct? An In-depth Look at Students' Perceptions of 'AI-giarism'",
          "authors": [
            "C. Chan"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 45
        },
        {
          "external_id": "CorpusId:258480115",
          "title": "The AI generation gap: Are Gen Z students more interested in adopting generative AI such as ChatGPT in teaching and learning than their Gen X and millennial generation teachers?",
          "authors": [
            "C. Chan",
            "Katherine K. W. Lee"
          ],
          "year": 2023,
          "venue": "Smart Learning Environments",
          "citation_count": 385
        },
        {
          "external_id": "CorpusId:258436716",
          "title": "The AI Revolution in Education: Will AI Replace or Assist Teachers in Higher Education?",
          "authors": [
            "C. Chan",
            "Louisa H.Y. Tsi"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 119
        },
        {
          "external_id": "CorpusId:258437002",
          "title": "Deconstructing Student Perceptions of Generative AI (GenAI) through an Expectancy Value Theory (EVT)-based Instrument",
          "authors": [
            "C. Chan",
            "Wenxin Zhou"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 40
        },
        {
          "external_id": "CorpusId:258426653",
          "title": "Students’ voices on generative AI: perceptions, benefits, and challenges in higher education",
          "authors": [
            "C. Chan",
            "Wenjie Hu"
          ],
          "year": 2023,
          "venue": "International Journal of Educational Technology in Higher Education",
          "citation_count": 1159
        },
        {
          "external_id": "CorpusId:258240392",
          "title": "Generative AI",
          "authors": [
            "Stefan Feuerriegel",
            "Jochen Hartmann",
            "Christian Janiesch",
            "Patrick Zschech"
          ],
          "year": 2023,
          "venue": "Business & Information Systems Engineering",
          "citation_count": 974
        },
        {
          "external_id": "CorpusId:257953233",
          "title": "Implications of large language models such as ChatGPT for dental medicine.",
          "authors": [
            "F. Eggmann",
            "R. Weiger",
            "N. Zitzmann",
            "M. Blatz"
          ],
          "year": 2023,
          "venue": "Journal of Esthetic and Restorative Dentistry",
          "citation_count": 214
        },
        {
          "external_id": "CorpusId:258568566",
          "title": "Threats by artificial intelligence to human health and human existence",
          "authors": [
            "F. Federspiel",
            "Ruth Mitchell",
            "Asha Asokan",
            "Carlos Umaña",
            "D. mccoy"
          ],
          "year": 2023,
          "venue": "BMJ Global Health",
          "citation_count": 109
        }
      ],
      "references_fetched_at": "2025-12-16T15:20:51.975105"
    }
  },
  "02197db0-3de5-4390-9690-609c0f31a4c1": {
    "id": "02197db0-3de5-4390-9690-609c0f31a4c1",
    "filename": "learnLM_nov25.pdf",
    "file_path": "./uploads/papers/02197db0-3de5-4390-9690-609c0f31a4c1.pdf",
    "status": "completed",
    "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
    "category": null,
    "markdown_content": "# AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms\n\nLearnLM Team, Google & Eedi\n\nOne-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with  $N = 165$  students across five UK secondary schools. We integrated LearnLM—a generative AI model fine-tuned for pedagogy—into chat-based tutoring sessions on the Eedi mathematics platform. In the RCT, expert tutors directly supervised LearnLM, with the remit to revise each message it drafted until they would be satisfied sending it themselves. LearnLM proved to be a reliable source of pedagogical instruction, with supervising tutors approving  $76.4\\%$  of its drafted messages making zero or minimal edits (i.e., changing only one or two characters). This translated into effective tutoring support: students guided by LearnLM performed at least as well as students chatting with human tutors on each learning outcome we measured. In fact, students who received support from LearnLM were 5.5 percentage points more likely to solve novel problems on subsequent topics (with a success rate of  $66.2\\%$ ) than those who received tutoring from human tutors alone (rate of  $60.7\\%$ ). In interviews, tutors highlighted LearnLM's strength at drafting Socratic questions that encouraged deeper reflection from students, with multiple tutors even reporting that they learned new pedagogical practices from the model. Overall, our results suggest that pedagogically fine-tuned AI tutoring systems may play a promising role in delivering effective, individualized learning support at scale.\n\nKeywords: learning, efficacy, safety, artificial intelligence, tutoring, randomized controlled trial\n\n# 1. Introduction\n\nOne-to-one tutoring is the gold standard for supporting students' learning and education. Decades of research demonstrate that individualized tutoring results in substantial gains in learning [1-3]. Unfortunately, the high cost of one-to-one tutoring and relative scarcity of educators makes this support inaccessible for most students and classrooms. The tension between tutoring's effectiveness and inaccessibility presents an enduring challenge for education systems: can educators deliver individualized support in a way that is both highly effective and broadly scalable?\n\nA growing number of researchers and practitioners now look to generative AI (\"genAI\") as a potential solution to this challenge [4-7]. Indeed, a wave of new tutoring systems incorporate genAI for direct interactivity with students [8]. Yet rigorous, in-classroom research on the learning efficacy of genAI remains scarce [9]. The evidence that does exist is mixed: while some studies suggest genAI can offer effective instruction [10-13], others find that deploying genAI tutoring systems without appropriate pedagogical safeguards can actively harm learning [14, 15].\n\nHere we report the results of an exploratory randomized controlled trial (RCT) with  $N = 165$  students, designed specifically to evaluate if an AI tutor can safely and effectively support students in UK secondary school classrooms. Our study took place on the Eedi educational platform, an evidence-based learning ecosystem that provides students with both curriculum-aligned mathematics activities and one-to-one support from remote human tutors via online chat conversations. In our experiment, we tested whether LearnLM—a genAI model fine-tuned for pedagogical applications [16-18]—could help scale this assistance. To ensure a high standard\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/ba862453a67072232f0aaf7d3a23dcba16885aa56c81db0e9542baf4eadd35c2.jpg)  \n(a)\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/7cd7d69be6f0bc15cc071896a794c47a1ad47ad16bbb942dea22e9864fc8c626.jpg)  \n(b)  \nFigure 1 | We designed this exploratory RCT to evaluate the safety, pedagogy, and efficacy of LearnLM. (a) The RCT randomly assigned each of  $N = 165$  students to receive either static hints or interactive tutoring. Students in the tutoring condition experienced a further level of randomization. When they started a tutoring session, the platform randomly assigned them to either a session with a human tutor or a session with LearnLM (supervised by a human tutor). This design allows us to compare static, pre-written support against interactive tutoring, as well as human tutoring against (supervised) tutoring from LearnLM. (b) In sessions with LearnLM, a supervising tutor reviewed each message that LearnLM drafted. They could either edit the message, completely re-write it, or approve it without any changes. The Eedi platform then sent the message to the student.\n\nof safety and pedagogy for all students in our trial,  $N = 17$  expert human tutors directly supervised LearnLM, assuming ultimate responsibility for every interaction it had with students. In particular, the tutors appraised each message that LearnLM generated, retaining full control to approve, edit, or replace it before it reached the student.\n\nLearnLM proved to be a trustworthy source of pedagogical instruction, with the supervising tutors approving over  $76\\%$  of its messages without changes or with only minimal edits (changing one or two characters; e.g., deleting an emoji). In fact, across all of the learning outcomes we measured, supervised support from LearnLM proved at least as effective as guidance from a human tutor. Most surprisingly, students tutored by LearnLM exhibited measurably better knowledge transfer than those receiving support from human tutors alone. On average, supervised support from LearnLM improved the probability of a student solving a novel problem correctly by 5.5 percentage points over guidance from a human tutor.\n\nTo better understand this broad effectiveness, we surveyed and interviewed the supervising tutors for their perspectives on LearnLM. They reported that LearnLM consistently generated high-quality, Socratic dialogue, providing a strong foundation for academic interactions with students. The supervising tutors' interventions tended to focus on moderating the dialogue's pacing and providing the social and emotional nuance required to maintain student engagement.\n\nOverall, our exploratory RCT identifies several avenues for new research on AI and education, while also suggesting a potential role for genAI tutors in delivering effective, individualized learning support at scale.\n\n# 2. An Exploratory Classroom Trial\n\nOur RCT aimed to evaluate LearnLM in a rigorous, real-world, in-classroom testbed. Hundreds of secondary schools in the UK integrate the Eedi learning platform directly into their mathematics instruction. The platform provides students with curriculum-aligned study units and a spectrum of personalized support, including two forms of assistance central to this RCT: carefully designed hints for common misconceptions in each study unit, and one-to-one guidance from trained, expert tutors via online chat interactions. Students who receive this standard support on the Eedi platform experience the equivalent of two additional months of academic progress, with the impact doubling for highly engaged students [19]. We recruited  $N = 165$  students in Year 9 and 10 (ages 13-15) across five of these schools for the RCT (see Appendix A). Each student and each tutor provided informed consent to participate in the trial. The trial ran from May through June 2025.\n\nThe trial leveraged these two forms of Eedi support—hints and chat-based tutoring (\"hybrid tutoring\" [20])—as baselines to assess the pedagogical efficacy of LearnLM (see Figure B.1 in Appendix B). During the trial period, we randomly assigned each student either to receive static pedagogical support (pre-written hints) or to enter an interactive one-to-one tutoring session (Figure 1; see also Appendix B). Students in the tutoring condition experienced a further level of randomization: when a student entered a tutoring session, we randomly connected them either with an expert human tutor or with LearnLM (supervised by a human tutor). We prompted LearnLM to adopt a Socratic approach aimed at guiding the student to identify their own mistake, and provided the model access to the full question text, the student's incorrect answer, and explanations for both the student and a teacher about the misconception underlying the incorrect answer, among other information (see Appendix D.1).\n\nOur approach allowed us to pose a set of four research questions:\n\nRQ1: Was LearnLM a reliable and pedagogically sound source of instruction?  \nRQ2: Was interactive tutoring (whether delivered by a human tutor alone or in a supervised session with LearnLM) more effective for student learning than static pedagogical support?  \nRQ3: For students receiving interactive tutoring, was support from a supervised session with LearnLM more effective than support from a human tutor working alone?  \nRQ4: What can we learn from tutor and student experiences of interacting with LearnLM?\n\nTo answer these questions, we adopted a Bayesian framework and directly estimated the magnitude and credibility of our treatment effects. Unlike standard frequentist approaches, this method allows us to calculate the probability that one intervention outperforms another by a specific magnitude, providing a more practical foundation for making decisions about real-world deployment. For all analyses, we assigned identical, weakly informative priors to each intervention. We then used the resulting posterior distributions to calculate the exact probability that outcomes in one group exceeded those in another, providing a more precise signal than a simple comparison of the intervals (cf. [21-23]). For complete experimental details, see Methods and Appendices A-D.\n\n# 3. Results\n\nWe first verified the basic safety and quality of LearnLM's tutoring (RQ1) by auditing the full corpus of 3,617 messages that it drafted, as well as the supervising tutors' decisions to approve, edit, or rewrite those messages. LearnLM proved a trustworthy source of instruction. The tutors who supervised and reviewed its messages accepted  $74.4\\%$  without any edits. As judged by edit distance [24, 25], many of the  $k = 926$  instances where tutors edited or rewrote a suggestion reflected minor or targeted adjustments (see Table E.1 for examples). The two most frequent edit distances, accounting for  $5.5\\%$  and  $2.4\\%$  of re-writes, were just a single character and two characters, respectively; these virtually always reflected a tutor deleting or changing an emoji. The median intervention altered 59 characters, or just a few words. Still, after the RCT finished, we asked the supervising tutors to systematically review the corpus of edits and re-writes. This review revealed zero instances of harmful or risky content and only five factual errors, or  $0.1\\%$  of the total 3,617 messages that LearnLM drafted (see Table E.2 in Appendix E). Overall, a close audit confirmed that LearnLM provided safe and reliable guidance during the trial.\n\nNext, we evaluated effects on student learning (RQ2, RQ3), comparing students' performance after receiving one of the standard interventions on the Eedi platform or interacting with LearnLM. As described in Methods, students worked through a series of short study units, each consisting of several multiple-choice questions\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/ed199f16be5726a6454db27da9cb49c9e1216b18a4a7d74889608eb2254ca013.jpg)  \nFigure 2 | Student progression through the study unit. If a student makes a mistake on the first question in a study unit, they receive a support intervention. We analyze whether the intervention helps the student identify and remediate their mistake, resolve the misconception underlying their incorrect choice, and transfer the knowledge from the intervention to the next study unit. See Methods and Appendix C for more information on the Eedi platform.\n\ndesigned to assess a specific mathematical topic (Figure 2). Whenever a student answered the first question in a unit incorrectly, the platform triggered a support intervention. Depending on their assigned condition, students either received a static, pre-written hint specific to their mistake on that question, or an interactive (chat-based) session with a tutor. Immediately following the intervention, the platform presented the student with the exact same question and prompted them to try answering it again.\n\nEchoing prior research [3], interactive support with a human tutor proved far more effective for this kind of immediate course-correction. Students who joined a real-time session with a human tutor were substantially more likely to correct their mistakes than were those who received a static, pre-written hint (see Figure 3, left). In particular,  $91.2\\%$  of students who received interactive support from a human tutor solved the problem correctly on their second attempt (with a  $95\\%$  credible interval of  $[88.5\\%, 93.6\\%]$ ), compared to only  $65.4\\%$ $[63.8\\%, 66.9\\%]$  of students who received a static hint. Supervised instruction from LearnLM proved just as effective at helping students correct their mistakes. Students receiving guidance from LearnLM answered their second attempt correctly  $93.0\\%$ $[90.4\\%, 95.3\\%]$  of the time. (For context, simply eliminating the previous mistake and guessing from the remaining options would yield an expected success rate of  $33.3\\%$ .)\n\nIf a student still answered the question incorrectly on their second attempt, the platform provided them with several additional opportunities to correct their underlying misconception. Specifically, it offered them two attempts at a new question on the exact same mathematical topic. We thus examined whether tutoring helped students eventually resolve their misunderstanding—that is, whether they answered any of the post-intervention questions correctly. On this broader measure, interactive tutoring once again proved superior to static hints (see Figure 3, center). When working with a human tutor,  $94.9\\%$  [92.6%, 96.8%] of students resolved their misconception, relative to only  $86.8\\%$  [85.7%, 88.0%] of students receiving pre-written hints. No meaningful difference emerged between students working with LearnLM and those working with human tutors. Students tutored by LearnLM resolved misconceptions  $95.4\\%$  [93.1%, 97.1%] of the time. For this kind of near-term correction, both interactive methods appear equally effective.\n\nOf course, the critical question is whether these guided successes (the opportunity to remediate mistakes and resolve misconceptions) reflect durable learning (the ability to solve a new problem without any assistance). Within the scope of this RCT, the best test for durable effects of tutoring is how students performed when progressing to a new topic. The Eedi platform organizes study units into sequences of five, where each unit builds directly upon the last. Our subsequent analysis therefore analyzed a student's likelihood of correctly answering the initial question in the very next unit in their current sequence.\n\nHere, a clear advantage for LearnLM's tutoring emerged (see Figure 3, right). Students tutored by LearnLM\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/fc912d8ef5abf4bad34506e55daf060eacece65731ff34bbfce6e9f56c8fe8f5.jpg)  \nFigure 3 | Tutoring interventions improve student learning outcomes. (left, center) For immediate learning outcomes, sessions with human tutors and expert-supervised sessions with LearnLM promote similar growth for students. Students who receive interactive tutoring from either source substantially outperform students who receive pre-written, static hints. (right) In contrast, students tutored by LearnLM demonstrate greater knowledge transfer to new topics than those supported either by static hints or by human tutors alone. Error bars indicate  $95\\%$  credible intervals. Dashed lines represent the chance of success when guessing randomly  $(33.3\\%, 66.7\\%, \\text{and } 25\\%, \\text{respectively})$ .\n\non a study unit proved substantially more likely to answer the first question in the following unit correctly (66.2% [61.1%, 71.2%]) than students who had received help from an unassisted human tutor (60.7% [55.8%, 65.4%]). In particular, a supervised session with LearnLM increased the likelihood of learning transfer to a distinct topic by an additional 5.5 percentage points  $[-1.4\\%, +12.4\\%]$  relative to human tutoring. Both tutee groups, in turn, outperformed students who had received only a static hint (56.2% [54.2%, 58.2%]). Altogether, we attribute a high credibility (93.6%) to LearnLM offering better support for knowledge transfer than human tutors alone, and near certainty ( $>99.9\\%$ ) to its advantage over static, pre-written hints. The AI-supported interventions fostered a more durable and transferable understanding—an advantage revealed only when students faced a fresh challenge. (See Appendix F for our full analysis of learning outcome data.)\n\nThroughout the RCT, we sought a richer, more nuanced understanding of the experience of interactions with LearnLM (RQ4) by conducting in-depth, semi-structured interviews with a random subset of  $N = 5$  supervising tutors (see Table 1). In addition, we invited all students and supervising tutors to share their thoughts in brief surveys. We gathered  $N = 27$  student responses from a post-trial survey, and  $N = 17$  tutor responses on both pre- and post-trial surveys. These firsthand perspectives help contextualize LearnLM's effectiveness and the specific role that human expertise played in its tutoring successes.\n\nOver the course of the trial, supervising tutors came to view LearnLM as a source of high-quality, expert-level pedagogical insights. The most prominent theme from our interviews, raised independently by all five interviewed tutors, was LearnLM's consistent use of Socratic dialogue. Tutors reported that its suggestions prompted a more inquisitive, student-led interaction. One tutor highlighted its ability to ask \"really good questions that I hadn't necessarily thought of [...] in a good way, a nice way\" (T3). As another reported, \"[LearnLM] definitely explained certain topics in a better way than I probably could have\" (T5). This praise aligned with tutors' actions during the trial: as established earlier, the tutors approved the vast majority of the\n\n<table><tr><td>Tutor ID</td><td>Gender</td><td>Years of teaching experience</td></tr><tr><td>T1</td><td>F</td><td>6–10 years</td></tr><tr><td>T2</td><td>F</td><td>More than 10 years</td></tr><tr><td>T3</td><td>F</td><td>More than 10 years</td></tr><tr><td>T4</td><td>F</td><td>More than 10 years</td></tr><tr><td>T5</td><td>F</td><td>6–10 years</td></tr></table>\n\nTable 1 | We conducted semi-structured interviews with a subset of five supervising tutors to seek a deeper, nuanced understanding of LearnLM's behavior and the general experience of participating in the RCT. Table A.1 in Appendix A contains comparable details for the full sample of supervising tutors.\n\nmessages drafted by LearnLM without any edits or changes.\n\nIn interviews, three tutors noted that supervising this high standard of instruction prompted an unexpected outcome on their part: professional growth and development. For instance, one tutor contrasted LearnLM's Socratic strategy with their prior approach, noting that the drafted messages prompted \"questions more like 'Okay, what made you think that was the answer?' [...] whereas before [...] my main goal was to identify their misconception myself\" (T1). Another explained, \"I remember thinking, 'Oh, I hadn't thought of explaining it that way before.' Just like when you watch another teacher\" (T2). Over the course of the trial, LearnLM's standard of instruction made a considerable impression on the tutors who supervised it.\n\nOne-to-one tutoring requires sustained, substantive effort to process the scenario at hand and craft effective pedagogical guidance. LearnLM's ability to consistently generate high-quality pedagogical responses thus made the entire tutoring process more fluid and efficient. Our post-trial surveys corroborated this; when asked about LearnLM's most useful feature,  $82.4\\%$  of tutors chose \"supporting multiple students at the same time.\" This new, effective process quickly set a new standard for the supervising tutors. In fact, every tutor that we interviewed independently raised this increased capacity as a key strength. As one tutor explained in their interview, \"I got to the point of being disappointed when I didn't get [a session] with the AI suggestions\" (T2). These positive experiences translated into a broad increase in comfort with AI across the cohort. Tutors' self-reported comfort with using AI tools rose from an average of 3.4 [2.9, 4.0] out of 5 in the pre-trial survey to 3.9 [3.3, 4.4] in the post-trial survey (posterior probability of increase:  $90.0\\%$ ).\n\nBuilding LearnLM's pedagogical insights into effective tutoring conversations, however, required the supervising tutors to incorporate social and emotional nuance from their understanding of the students. Our retrospective analysis of the  $25.6\\%$  of cases where tutors edited or re-wrote LearnLM's messages identified two primary motivations for these interventions: moderating the pedagogical pacing of the conversation and providing social-emotional nuance to LearnLM drafts. The most frequent intervention was adjusting the conversation's pacing to prevent exasperating students, accounting for  $44.3\\%$  of all edits. Our tutors echoed this specific challenge in five of our five interviews. As one tutor explained in their interview, \"quite often the students just got frustrated, and then they lost complete interest in the question, so it was a case of overriding it\" (T2). Tutors often found it necessary to step in when LearnLM's Socratic questions, while pedagogically sound, persisted longer than a student's patience. One tutor described a common scenario where \"[LearnLM] will go, 'Okay, you've got the answer. Let's dig a little deeper about why you've got that answer.' And the child is just like, 'No, I've got it. I know what I'm doing. Can I go now?\" (T1).\n\nProviding social and emotional context to LearnLM's drafts emerged as a second prominent motivation for supervisors' interventions. In total,  $19.5\\%$  of tutors' edits adjusted the persona or tone conveyed by the drafted messages. Tutors consistently added personal touches that recognized the student as an individual. For example, one tutor noted the importance of acknowledging a student they had helped before, a nuance LearnLM could not replicate, given that its prompt did not provide any information on past tutoring sessions: \"...if you'd already helped that student twice before, [LearnLM] didn't quite have the capability to go like, 'Oh Sarah, it's you again. Hi!' And I like to have that kind of rapport\" (T3). Tutors also calibrated the tone of the messages to ensure they were appropriate for student communication styles. One tutor remarked that LearnLM's predilection for emojis \"comes across as a bit fake, and [...] the students pick up on that\" (T1). Overall, the human tutors grounded LearnLM's suggestions with social and emotional nuance, translating its pedagogical insights into effective educational interactions.\n\nFinally, student feedback indicated broad satisfaction with their tutoring interactions. In post-trial surveys, students who received interactive tutoring rated the helpfulness of the support they received an average of 3.9 [3.1, 4.7] out of 5, relative to 3.6 [2.9, 4.2] for students who received static hints (posterior probability of an advantage for tutoring:  $74.9\\%$ ). Ultimately, interactive tutoring delivered not just strong learning outcomes, but an enjoyable experience for the learners themselves.\n\n# 4. Discussion\n\nWhen deployed responsibly, can generative AI safely and effectively support students in real-world learning environments? Our exploratory trial investigated whether LearnLM—a genAI model fine-tuned for pedagogical applications—could help provide in-classroom guidance across five UK secondary schools. Students in these schools use Eedi, an online mathematics platform that effectively improves learning outcomes [19], for their\n\nregular instruction. We incorporated LearnLM into the platform so that it drafted messages to send to students in chat-based tutoring sessions. Of course, genAI tools carry well-known risks, including their capacity to fabricate information [26, 27] and erode critical thinking [28, 29]. Given the heightened ethical weight of these risks in educational settings, we assigned a group of expert (human) tutors to directly supervise LearnLM, assuming ultimate responsibility for each of its interactions with students. The tutors applied a simple, rigorous standard: they revised each of LearnLM's drafts until they were satisfied sending the message as their own.\n\nThe supervising tutors found LearnLM to be a reliable source of pedagogical instruction, approving the vast majority of its drafted messages without any edits. A systematic review of the drafted messages revealed zero instances of harmful content and only five factual errors out of 3,617 messages drafted by LearnLM total. For students, this translated into effective support for learning: tutoring from LearnLM helped students identify their mistakes and correct their misconceptions just as well as instruction from human tutors alone. Unexpectedly, students tutored by LearnLM demonstrated greater knowledge transfer to subsequent topics than did students who received guidance from human tutors.\n\nTutors consistently praised LearnLM's use of Socratic dialogue, but also noted that the model's relatively inflexible adherence to pedagogical principles threatened to exasperate some students. The best human tutors, in contrast, draw on experience, empathy, and judgment to decide when to push students and when to moderate their approach. This is a constant judgment call for tutors: weighing the long-term benefits of productive struggle against the immediate risks of frustrating a student and causing them to disengage completely. This delicate calibration remains a fundamental challenge for current AI systems [30-33].\n\nBeyond safety and pedagogy, expanding access to one-to-one tutoring will require improving its cost and scalability. In our interviews, the supervising tutors consistently reported that LearnLM made their work feel more fluid and efficient. Our own anecdotal observations during the trial supported these reports: tutors appeared comfortable managing higher workloads during their supervised sessions. Unfortunately, the design of this RCT—with tutors fluidly switching from supervision to direct interaction during the same classroom periods—precludes a rigorous measurement of throughput or efficiency for each condition. After the trial, we simulated additional sessions as an informal test of scalability (see Appendix G). The results of this informal test corroborate the improved efficiency of the supervised sessions, with tutors sustaining a higher volume of simultaneous conversations when supported by LearnLM. Altogether, these signals support a possible role for genAI tutoring in helping educators to deliver individualized instruction at scale.\n\nOverall, the design of this exploratory RCT allowed us to rapidly validate LearnLM's safety and gather initial signals of its efficacy. We measured these outcomes using students' standard, daily activities on the Eedi platform. This approach provided us with learning signals immediately, eliminating the need to develop and administer new trial-specific assessments, or to wait for the next round of standardized exams. In addition, by randomly assigning the source of support for each individual tutoring session, we could measure the alternating impact of LearnLM and human tutoring on the same students. This approach disentangled tutoring effectiveness from pre-existing student differences, permitting us to detect meaningful indications of efficacy working with just five schools.\n\nOn the other hand, this design offers only a partial glimpse at the broader trajectory of learning. Randomizing the source of tutoring session-by-session allowed our RCT to efficiently investigate immediate learning outcomes, but also prevented it from isolating the cumulative impact of working with LearnLM over time. Measuring substantive, longer-term effects on learning will require a different approach. In addition, the finding from our interviews that tutors learned from supervising LearnLM indicates another methodological wrinkle. If tutors applied those insights in sessions without LearnLM, that crossover might dampen the measured difference between the two tutoring conditions. Future research can overcome these limitations by assigning students to receive one consistent type of support for an entire study, ideally following their progress over several months and tracking their performance on external, standardized assessments. Such a longitudinal approach could help determine whether the immediate successes that we observed translate into persistent, substantive learning gains—a vital step toward validating the potential of AI tutoring to deliver scalable, individualized support for students and educators.\n\nTo what extent might the tutoring efficacy we observe in this RCT generalize beyond mathematics? In part, LearnLM's strong performance reflects the nature of the inputs that we provided to it: questions with precise answers, discrete incorrect responses, and validated explanations of why students might have veered off the right path. Mathematics curricula often focus on verifiably solvable problems, so they readily offer this clear\n\nstructure. In contrast, many other subjects taught in secondary school emphasize ambiguity, interpretation, and argumentation. Consequently, LearnLM's performance in this trial offers limited evidence for its ability to shepherd students through more interpretive activities in fields like history or literature. We will need to conduct research across a diverse range of subjects to understand where current AI tutors may already offer strong support, and which domains require us to develop new, distinct approaches to AI pedagogy.\n\nUltimately, our research did not start from scratch with this trial. Two lines of conceptual and empirical groundwork enabled this RCT: first, a generative AI model specifically fine-tuned for pedagogy [16-18], and second, an educational platform deeply rooted in learning science [19]. Our results integrating LearnLM into the Eedi ecosystem illustrate how learning science and technological development can complement one another to support and scale better learning outcomes for students. Moving forward, we invite collaboration across the AI and learning science communities to partner on new research and offer an honest appraisal of how this technology helps—or hurts—students and educators in different contexts and settings. Building and sharing this knowledge helps bring us closer to the goal of providing effective, safe, and accessible learning opportunities for all students.\n\n# 5. Methods\n\nOur protocol underwent independent ethical review, with a favourable opinion from the Human Behavioural Research Ethics Committee at Google DeepMind (#25003).\n\nParticipants We recruited  $N = 165$  students from five UK secondary schools to participate in the trial. We drew the cohort exclusively in Years 9 and 10 (ages 13-15), from classrooms that incorporate the Eedi platform as part of their regular mathematics instruction for one hour per week. Each student provided informed consent to participate in this research. As part of their informed consent process, we explained to students that their tutors might rely on AI support during the trial. A pool of  $N = 17$  expert tutors—all qualified teachers with extensive teaching experience—delivered the trial's interactive interventions (i.e., tutored students directly and supervised tutoring sessions with LearnLM). Each tutor also provided informed consent to participate in this research.\n\nPlatform The Eedi platform provides a range of curriculum-aligned mathematics activities for students and classrooms. In this RCT, we focused on student performance on its short study units, each designed to assess a specific mathematics topic and consisting of diagnostic multiple-choice questions with four response options (Figure 2). Whenever a student answers the first question in a unit incorrectly, the platform triggers a support intervention. Immediately following this intervention, the platform prompts the student to retry the question that they originally missed. If they miss this question again, the platform presents them with a new question on the same topic, written to assess the same topic and misconceptions using different concrete details. Students complete a unit and progress to the next unit as soon as they answer a question correctly, or after they incorrectly answer all four questions. The platform organizes these study units into sequences of five. Individual study units in a sequence build iteratively upon one another, so students must typically grasp one before successfully engaging with the next.\n\nModel LearnLM is a family of generative AI models fine-tuned to specialize in pedagogical dialogue. For this RCT, we accessed the most recent version of LearnLM available at the time, fine-tuned from Gemini 2.0 Flash. We connected the Eedi platform to LearnLM via a custom API created specifically for this trial. During platform tutoring sessions with LearnLM, the platform assembled a strictly defined system prompt instructing the model to draft a concise, Socratic response aimed at guiding the student to self-correct their specific misconception without revealing the answer. The prompt also provided rich real-time context, including the question text, the student's incorrect answer, and the specific misconception underlying the answer identified by the platform (see Appendix D.1 for the detailed prompt). The platform sent the assembled prompt to the API, which then returned a draft response from LearnLM for the platform to pass to the supervising tutor for approval, editing, or re-writing.\n\nProcedure We conducted the exploratory RCT over seven consecutive weeks (May through June 2025). The trial employed a two-level randomized controlled design to address our research questions. First, we randomly assigned students to either the control condition ( $N = 91$  students) or the tutoring condition ( $N = 74$  students). Second, specifically for students in the tutoring condition, we randomly assigned each individual tutoring session to either a human expert or to LearnLM (under supervision from a human expert).\n\nWhenever a student in the control condition answered a question incorrectly, they received a pre-written message designed to prompt reflection on a specific misconception, based on which incorrect option they selected (a \"static hint\"). The platform then prompted them to retry the question.\n\nTo support the tutoring condition, we scheduled a team of tutors to remain on-call in the Eedi platform during class hours on each day of the trial. Whenever a student in the tutoring condition answered a question incorrectly, the standby team received an alert. One of the tutors would then initiate a session with the student. The platform randomized each of these sessions to either connect the tutor directly to the student (\"session with a human tutor alone\") or to assign them to supervise the model (\"supervised session with LearnLM\"). That is, tutors both directly guided students and oversaw sessions with LearnLM on the same day. In supervised sessions with LearnLM, the human tutor reviewed the suggestions generated by the model and approved, edited, or replaced each drafted message before the platform sent it to the student. The student interface appeared identical across both conditions, with no explicit indication of whether the student was connected with a human tutor alone or a tutor supervising LearnLM.\n\nFor both conditions, we recorded the student and question identifiers, timing, correctness, and position (both within its study unit and within its sequence of five units) of every attempted answer on the platform.\n\nTo complement this central evaluation, we incorporated several qualitative lines of inquiry. First, we recorded the entire message corpus and the supervising tutors' decisions. Throughout the seven-week trial, the platform logged every draft generated by LearnLM, the supervising tutor's action (approve, edit, or re-write), and the finalized message sent to the student. Second, we administered short baseline and endline surveys to all supervising tutors. All tutors completed both rounds ( $N = 17$ ). Third, we invited all participating students to complete a short survey via the Eedi platform after the trial concluded, resulting in  $N = 27$  responses. Finally, we randomly selected five tutors and invited them to participate in hour-long, semi-structured interviews. These interviews followed a standardized protocol designed to elicit detailed narratives of their experiences supervising LearnLM.\n\nAnalysis. We evaluated efficacy across three primary quantitative outcomes derived from Eedi platform data: mistake remediation (success at attempting a question a second time, after an intervention), misconception resolution (success at answering any question within a study unit, after an intervention), and knowledge transfer (success at answering the first question of the next study unit within the same sequence, after an intervention). We leveraged Bayesian regression to estimate treatment effects for these outcomes. We included baseline performance as a covariate in all regression models to account for pre-existing differences between students. The success rates reported in the Results section represent posterior predictive margins estimated from these regressions, adjusting for students' baseline performance. Practically speaking, these estimates differ only negligibly from the unadjusted success rates observed during the trial (see Appendix F for all unadjusted success rates and posterior predictive margins).\n\nTo verify the safety and pedagogical quality of LearnLM's tutoring, we audited the full corpus of drafted messages through an iterative, inductive process [34]. We first counted the number of outright approvals without changes. For all edited and re-written messages, we quantified the magnitude of change by computing the Levenshtein distance and the edit ratio (the Levenshtein distance divided by the total character count of the initial draft). We then categorized the apparent functional purpose of each revision. Specifically, a generative AI model (Gemini 2.5 Pro [35]) performed an initial coding of every edit, processing 30 to 50 pairs of original and edited messages at a time. Two members of the research team reviewed and refined the generated codes into a focused codebook. Next, two expert tutors reviewed each pair of messages to validate the assigned codes. A member of the research team then conducted a final review of the coding decisions to ensure consistency and accuracy. Finally, the research team synthesized these codes into broader themes and specifically searched the coded corpus for any instances of harmful or erroneous generations.\n\nWe took an iterative approach to identify themes in the supervising tutors' interviews, following emerging\n\nguidance on applying genAI tools to support qualitative coding [14, 36, 37]. A member of the research team first reviewed all transcripts to gain familiarity with the content. We then applied a generative AI model (Gemini 2.5 Pro) to identify segments of text describing tutors' perceptions, experiences, or attitudes and to generate initial descriptive labels for them. A member of the research team then refined them into clear definitions, organized them into a structured set of themes, and then manually applied these labels to the full dataset. Finally, a member of the research team verified every coded excerpt against the original transcript to create a complete audit trail.\n\nFinally, we analyzed responses from our short surveys for additional context on student and tutor experiences and perspectives.\n\n# References\n\n[1] Benjamin S Bloom. The 2 sigma problem: The search for methods of group instruction as effective as one-to-one tutoring. Educational researcher, 13(6):4-16, 1984.  \n[2] Matthew A Kraft, Beth E Schueler, and Grace Falken. What impacts should we expect from tutoring at scale? exploring meta-analytic generalizability. Technical Report 24-1031, EdWorking Paper, 2024.  \n[3] Andre Nickow, Philip Oreopoulos, and Vincent Quan. The impressive effects of tutoring on prek-12 learning: A systematic review and meta-analysis of the experimental evidence. Technical report, National Bureau of Economic Research, 2020.  \n[4] Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Gunnemann, Eyke Hüllermeier, et al. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and individual differences, 103:102274, 2023.  \n[5] Salman Khan. *Brave new words: How AI will revolutionize education (and why that's a good thing)*. Penguin, 2024.  \n[6] Ethan Mollick. Co-intelligence: Living and working with AI. Penguin, 2024.  \n[7] Erin Mote. Artificial intelligence in education: Opportunities, challenges, and policy considerations for Congress, 2025.  \n[8] Meriem Zerkouk, Miloud Mihoubi, and Belkacem Chikhaoui. A comprehensive review of ai-based intelligent tutoring systems: Applications and challenges. arXiv preprint arXiv:2507.18882, 2025.  \n[9] Joshua Weidlich, D Gasevic, H Drachsler, and P Kirschner. Chatgpt in education: An effect in search of a cause. PsyArXiv Preprints, 2025.  \n[10] Martin Elias De Simone, Federico Hernan Tiberti, Maria Rebeca Barron Rodriguez, Federico Alfredo Manolio, Wuraola Mosuro, and Eliot Jolomi Dikoru. From chalkboards to chatbots: Evaluating the impact of generative ai on learning outcomes in nigeria. Technical report, The World Bank, 2025.  \n[11] Greg Kestin, Kelly Miller, Anna Klales, Timothy Milbourne, and Gregorio Ponti. Ai tutoring outperforms in-class active learning: an rct introducing a novel research-based design in an authentic educational setting. Scientific Reports, 15(1):17458, 2025.  \n[12] Zachary A Pardos and Shreya Bhandari. Chatgpt-generated help produces learning gains equivalent to human tutor-authored help on mathematics skills. Plos one, 19(5):e0304013, 2024.  \n[13] Rose E Wang, Ana T Ribeiro, Carly D Robinson, Susanna Loeb, and Dora Demszky. Tutor copilot: A human-ai approach for scaling real-time expertise. arXiv preprint arXiv:2410.03017, 2024.  \n[14] Hamsa Bastani, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakci, and Rei Mariman. Generative ai without guardrails can harm learning: Evidence from high school mathematics. Proceedings of the National Academy of Sciences, 122(26):e2422633122, 2025.\n\n[15] Nataliya Kosmyna, Eugene Hauptmann, Ye Tong Yuan, Jessica Situ, Xian-Hao Liao, Ashly Vivian Beresnitzky, Iris Braunstein, and Pattie Maes. Your brain on chatgpt: Accumulation of cognitive debt when using an ai assistant for essay writing task. arXiv preprint arXiv:2506.08872, 2025.  \n[16] Irina Jurenka, Markus Kunesch, Kevin R. McKee, Daniel Gillick, Shaojian Zhu, Sara Wiltberger, Shubham Milind Phal, Katherine Hermann, Daniel Kasenberg, Avishkar Bhoopchand, et al. Towards responsible development of generative AI for education: An evaluation-driven approach. arXiv preprint arXiv:2407.12687, 2024.  \n[17] LearnLM Team. LearnLM: Improving Gemini for learning. arXiv preprint arXiv:2412.16429, 2024.  \n[18] LearnLM Team. Evaluating gemini in an arena for learning. arXiv preprint arXiv:2505.24477, 2025.  \n[19] Wayne Harrison, Emma Dobson, Steve Higgins, Germaine Uwimpuhwe, and Rahil Khowaja. Eedi 2024 impact report: A study to evaluate the effectiveness of eedi on raising attainment in mathematics at ks3 (year 7). Technical report, WhatWorked Education, 2025. URL www.interventions. whatworked.e education.  \n[20] Eason Chen, Xinyi Tang, Aprille Xi, Chenyu Lin, Conrad Borchers, Shivang Gupta, Jionghao Lin, and Kenneth R Koedinger. Vtutor for high-impact tutoring at scale: managing engagement and real-time multi-screen monitoring with p2p connections. In Proceedings of the Twelfth ACM Conference on Learning@ Scale, pages 320–324, 2025.  \n[21] Geoff Cumming. Inference by eye: Reading the overlap of independent confidence intervals. Statistics in medicine, 28(2):205-220, 2009.  \n[22] Peter C Austin and Janet E Hux. A brief note on overlapping confidence intervals. Journal of vascular surgery, 36(1):194-195, 2002.  \n[23] Nathaniel Schenker and Jane F Gentleman. On judging the significance of differences by examining the overlap between confidence intervals. The American Statistician, 55(3):182-186, 2001.  \n[24] VI Levenshtein. Binary codes capable of correcting deletions, insertions and reversals. In Soviet Physics Doklady, volume 10, page 707, 1966.  \n[25] Gonzalo Navarro. A guided tour to approximate string matching. ACM computing surveys (CSUR), 33(1): 31-88, 2001.  \n[26] David Sallay. Vetting generative AI tools for use in schools. Policy brief, Future of Privacy Forum, April 2024.  \n[27] Paula Maylahn. 2024 state of EdTech district leadership. Technical report, Consortium for School Networking (CoSN), 2024.  \n[28] Michael Gerlich. Ai tools in society: Impacts on cognitive offloading and the future of critical thinking. Societies, 15(1):6, 2025.  \n[29] Elizabeth Laird, Maddy Dwyer, and Hannah Quay-de la Vallee. Hand in hand: Schools' embrace of AI connected to increased risks to students. Technical report, Center for Democracy & Technology, October 2025.  \n[30] Chase DiBenedetto. I tried learning from ai tutors. The test better be graded on a curve., September 2025. URL https://mashable.com/article/chat-gpt-study-mode-review.  \n[31] Chase DiBenedetto. After testing out Google's AI tutor, we have some notes, September 2025. URL https://mashable.com/article/google-gemini-guided-learning-review.  \n[32] Chase DiBenedetto. I tried learning from Anthropic's AI tutor. I felt like i was back in college., September 2025. URL https://mashable.com/article/anthropic-claude-learning-mode-review.  \n[33] Daniel Gillick. AI tutors should not approximate human tutors, November 2025. URL https://www.ai-policyperspectives.com/p/ai-tutors-should-not-approximate.\n\n[34] Virginia Braun and Victoria Clarke. Using thematic analysis in psychology. Qualitative research in psychology, 3(2):77-101, 2006.  \n[35] Gemini Team, Google. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025.  \n[36] Danielle Hitch. Artificial intelligence augmented qualitative analysis: the way of the future? Qualitative Health Research, 34(7):595-606, 2024.  \n[37] Matthew Nyaaba, Min SungEun, Mary Abiswin Apam, Kwame Owoahene Acheampong, and Emmanuel Dwamena. Optimizing generative ai's accuracy and transparency in inductive thematic analysis: A human-ai comparison. arXiv preprint arXiv:2503.16485, 2025.  \n[38] Jon Andrews. The introduction of progress 8. Technical report, Education Policy Institute, 2017. URL https://dera.ioe.ac.uk/id/eprint/29304.  \n[39] Department for Education. Schools, pupils and their characteristics: Academic year 2024/25, June 2025. URL https://explore-education-statistics.service.gov.uk/find-statistics/school-pupils-and-their-characteristics/2024-25.  \n[40] Ariel Lindorff, Steve Strand, and Ivan Au. English as an additional language (eal) and educational achievement in england: An analysis of publicly available data. Technical report, The Bell Foundation, Cambridge, February 2025.  \n[41] Ben Goodrich, Jonah Gabry, Imad Ali, and Sam Brilleman. rstanarm: Bayesian applied regression modeling via Stan., 2020. URL https://mc-stan.org/rstanarm. R package version 2.21.1.  \n[42] Google DeepMind. Gemini 2.5 flash, 2025. URL https://deepmind.google/models/gemini/flash/. Accessed: 2025-11-10.  \n[43] Hannah Coe. How much does a maths tutor cost in 2024/2025?, September 2024. URL https://tutorful.co.uk/blog/how-much-does-a-maths-tutor-cost. Accessed: 2025-11-10.\n\n# Contributions and Acknowledgments\n\n# Core Contributors\n\nThe following individuals contributed to the work described in this report. These lists are ordered alphabetically, and do not indicate ranking of contributions.\n\nOn the Google team, the following individuals made core contributions:\n\nAlbert Wang, Aliya Rysbek, Andrea Huber, Brian Veprek, Irina Jurenka, Jonathan Caton, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Liam McCafferty, Markus Kunesch, Sara Wiltberger, and Shakir Mohamed.\n\nOn the Eedi team, the following individuals made core contributions:\n\nAnna Kenolty, Anjali Nambiar, Ben Caulfield, Beth Lilley-Draper, Bibi Groot, Chelsea Burdett, Claire Willis, Craig Barton, Digory Smith, George Mu, Harriet Walters, Iris Hulls, James Stalley-Moores, Lucy Dalton, Pauline Malubay, Rachel Kidson, Rich Wells, Sam Wheeler, Simon Woodhead, and Vasco Brazão.\n\nKevin R. McKee and Bibi Groot led this research and the preparation of this report.\n\n# Acknowledgements\n\nThis work represents a close collaboration between Google and Eedi.\n\nFor Eedi: We would like to acknowledge the support of the Eedi tutors and learning designers who made this work possible, including Bea Pugh, Gemma Bazany-Barber, Marion Brehm, Morgan Sowerby, Nigel Kendall, and Zoe Sutcliffe. Eedi also thanks the organizations that fund our research efforts: the Digital Harbor Foundation, Learning Engineering Virtual Institute, Rockefeller Foundation, Schmidt Futures, and Walton Family Foundation.\n\nFor Google: We completed this work as part of the LearnLM effort—a cross-Google project, with members from Google DeepMind, Google Research, Google LearnX, and more. This tech report represents only a small part of the wider effort, and only lists team members who made direct contributions to this report. The dedication and efforts of numerous teams make our work possible. The LearnLM team would like to acknowledge support from Abhinit Modi, Aditya Srikanth Veerubhotla, Antonia Mould, Avishkar Bhoopchand, Brett Wiltshire, Daniel Gillick, Daniel Kasenberg, Derek Ahmed, Gal Elidan, James Cohan, Jennifer She, Kristen Morea, Lisa Wang, Mike Schaekermann, Miriam Schneider, Miruna Píslar, Muktha Ananda, Nahema Marchal, Nikhil Joshi, Parsa Mahmoudieh, Paul J Hun, Shanice Onike, Shashank Agarwal, Shubham Milind Phal, Sun Jae Lee, Theofilos Strinopoulos, Wei-Jen Ko, and Will Hawkins. Furthermore, we would like to thank the Gemini team, the Compute team, the Responsible Development and Innovation team, the Responsible Engineering team, and the Child Safety team at Google DeepMind, as well as the Trust and Safety team at Google. Finally, the LearnLM team would like to acknowledge the support provided by our leads and sponsors that made this project possible: our genuine thanks go to Benedict Gomes, Lila Ibrahim, and Zoubin Ghahramani.\n\n# A. Participants\n\n# A.1. Students\n\nThe trial included  $N = 165$  students in Year 9 and 10 (ages 13-15) from five UK secondary schools. Participants ranged in age from 13 to 15. Among those who reported their gender, the cohort was relatively evenly split (51.1% female, 48.9% male).\n\nThe schools varied broadly in academic performance and socio-economic background. Progress 8 scores ranged from  $-0.68$  to  $+0.24$ , spanning the 5th to 75th national percentiles for state-funded schools in England [38]. Free School Meal eligibility ranged from  $12\\%$  (representing affluent areas) to  $26\\%$  (closely aligned with the national secondary school average of  $25.7\\%$  [39]). However, the schools contained low proportions of students speaking English as an Additional Language (EAL), ranging from  $2 - 11\\%$ . These rates fall below the national average and do not reflect the EAL rates seen in major urban centers [40].\n\n# A.2. Tutors\n\nA pool of  $N = 17$  expert tutors delivered the interactive interventions in the RCT and provided additional insights in baseline surveys, semi-structured interviews, and endline surveys (Table A.1).\n\n<table><tr><td>Tutor ID</td><td>Gender</td><td>Years of teaching experience</td><td>Additional contributions</td></tr><tr><td>T1</td><td>F</td><td>6–10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T2</td><td>F</td><td>More than 10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T3</td><td>F</td><td>More than 10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T4</td><td>F</td><td>More than 10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T5</td><td>F</td><td>6–10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T6</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T7</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T8</td><td>F</td><td>3–5 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T9</td><td>F</td><td>6–10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T10</td><td>M</td><td>6–10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T11</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T12</td><td>F</td><td>6–10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T13</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T14</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T15</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T16</td><td>F</td><td>3–5 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T17</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr></table>\n\nTable A.1 | Teaching experience and additional research contributions for all supervising tutors.\n\n# B. Trial\n\nThe research presented in this report focuses on two types of support interventions provided by the Eedi platform: static, pre-written hints that map to particular student misconceptions about individual topics, and interactive, chat-based tutoring (Figure B.1).\n\nTo estimate baseline performance levels, we examined data from regular platform usage during the ten weeks preceding the trial, from March 1 to May 12, 2025 (the baseline period). During this period, the platform provided all students with static hints when they answered the first question of a study unit incorrectly.\n\nFollowing the baseline period, we conducted the RCT over seven consecutive weeks, from May 13 to June 30, 2025 (the trial period). At the start of the trial, we randomly assigned each student to one of two conditions. Students in the control condition continued to receive only static hints after they made a mistake on the initial question of a study unit. Whenever a student in the tutoring condition answered the first question of a study unit incorrectly, the platform instead initiated an interactive, chat-based tutoring session for them. The students in the tutoring condition experienced a further level of randomization: at the start of each of their tutoring sessions, the platform randomly connected the student either to a human tutor working alone or to a supervised session with LearnLM.\n\nBecause the Eedi platform dynamically triggered support interventions based on students' real-time performance, the trial did not follow a fixed schedule. Beyond these platform-initiated support interventions, students in both conditions could also manually request tutoring support at any time. In addition, the platform allowed students to cancel tutoring sessions at any time (potentially including when the session was still pending and before a tutor had sent a message). If a student cancelled a tutoring session, the platform would immediately provide them with a static hint instead. Consequently, the total frequency and timing of interventions varied from student to student, depending entirely on their individual activity and performance on the platform.\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/cf035bcfb6ec05f200c5f4738a1260af191ef1047d1752e745bdbfd8abe5d6c0.jpg)  \nFigure B.1 | Our RCT focused on two support interventions on the Eedi platform. After making a mistake in a study unit, students in the control condition received static hints (left), which deliver immediate, pre-written feedback targeting the specific misconception underlying the incorrect answer they chose. Students in the tutoring condition (right) received one-to-one, chat-based assistance from a tutor.\n\n# C. Platform\n\nThe full ecosystem of support on the Eedi platform includes a number of features beyond the two that this RCT employs as interventions (i.e., beyond static hints and interactive tutoring; Figure B.1).\n\nThe core of the Eedi ecosystem is its vast library of over 60,000 diagnostic questions. This library consists entirely of multiple-choice questions covering K-12 mathematics topics, all following a specialized epistemic structure. Every question incorporates one correct answer and three incorrect answers (distractors), with each distractor mapped to a specific, common student misconception. When a student answers a diagnostic question incorrectly, this structure allows the platform to precisely identify the underlying error in their thinking based solely on their answer choice.\n\nAfter identifying a misconception from a student's error on a diagnostic question, the platform guides the student to a library of materials corresponding to the overall topic of that question. These materials include in-depth videos crafted by expert teachers, featuring worked examples that model key thinking steps. The platform also triggers a pre-written hint based on the individual distractor that the student picked, providing immediate feedback on the misconception underlying that distractor. Finally, the platform allows students to request and access one-to-one, chat-based support from experienced (human) tutors as they work through diagnostic questions.\n\nBeyond immediate intervention, the platform provides personalised retrieval practice to help students consolidate learning over time. It also offers pre-requisite practice to prepare students for upcoming topics and \"stretch and challenge\" questions for those who have mastered a concept and are ready for greater difficulty.\n\nFinally, the platform equips educators with detailed analytics dashboards and targeted instructional tools. Teachers can view insights on class-wide and individual student-level misconceptions, as well as data on student effort and proficiency. Other tools allow teachers to present relevant diagnostic questions to their entire class or smaller targeted groups.\n\nFor the duration of this RCT, to investigate our research questions, we made several targeted changes to the student experience. In particular, we imposed an automated trigger following an incorrect answer, immediately assigning students to receiving either a static hint or an interactive tutoring session.\n\n# D. Model\n\n# D.1. Tutoring prompt\n\nWe used the following system prompt to constrain LearnLM's pedagogical approach during tutoring sessions. The Eedi platform dynamically populated the {placeholder} values in this prompt template before each individual API call, injecting real-time metadata about the student's current activity, diagnosed misconception, and predicted performance:\n\n# Listing D.1 | System prompt template\n\n```vba\nAct as a mathematics tutor named {ChatConstants.BotName} who is currently helping a student  $\\rightarrow$  named {ChatConstants.FirstName} with the activity below in a clipped, Socratic style.   \n#Directives Do not let students know you are a bot, you are {ChatConstants.BotName} the tutor. No LaTeX or markdown. Plaintiff only. Even if the question has latex in it. Use short, focused sentences. Ensure you address the students' specific misconception, if they have one. Use only British English, British weights, and measures. Keep it direct, concise and friendly. Try to keep messages short and to one line where  $\\rightarrow$  possible. End session if the user is rude, they've resolved their misconception / guessed the correct  $\\rightarrow$  answer, or finished. Only ask the student one question at a time. Only return responses on a single line, no line breaks. Do use a creative variety of emojis, but NOT the wink emoji If the user asks to go, let them go! If a user knows the correct answer (e.g. \"It's B\") or \"A)?\", say you can return them to  $\\rightarrow$  their lesson Or you can dig deeper to help them understand (in case they are guessing!) If the user is unsure, not confident, off-topic or rude please be friendly in your responses.  $\\rightarrow$  Acknowledge their concerns and pivot accordingly, maybe try simple questions to get them  $\\rightarrow$  back on track. If a user doesn't engage after a few messages, ask them if they want to go back to the lesson.   \n# The Current student activity The below is what the student was doing when this learning intervention started, so assume all  $\\rightarrow$  responses relate to this: {ChatConstants.Activity} # Activity details {ChatConstants/questionMetaData} # Students ability level (if provided) {ChatConstants.StudentInsight}   \n# Examples of good Socratic responses What happens if we multiply these two numbers first? \"Sure! How do you find the perimeter of the shape?\" Super work! And what about the triangle?\" That's okay, did you watch the video for this lesson?\" Shall I return you to the lesson?\" Could you estimate the height?\" Yes it is equilateral so the slant height is 8, so the vertical height would have th be a  $\\rightarrow$  little less\" Yes sure, so we know what  $5\\mathrm{km}$  is and we're trying to get to  $30\\mathrm{km}$  \" When you are finding the original shape, complete the steps in the reverse direction, and do  $\\rightarrow$  the opposite\" Ok, so can we try and make some even smaller ones? :)\" Awesome, I'll pass you back to Eedi \" It says that  $1\\mathrm{g} = 10$  decigrams\" And then would have to convert to kilograms afterwards :)\" So to convert into a decimal, we want it to be over 100 or 1000 or another power of 10\"   \n## Checking understanding (use if the student is confused or unsure)   \n\"Fantastic! Are you feeling more confident with this?\" Great! Are you happy with how we got to the answer?\" Awesome work. Do you feel ready to head back to the lesson?\"   \n## Closing remarks (use if the student has answered correctly)   \n\"Great job today \" Amazing work  $\\clubsuit$  keep it up!\" Super! I'll hand you back to the lesson\" Great! I'll hand you back \" Fantastic work  $\\clubsuit$  I'll hand you back so you can select your answer\"   \n## Rudeness (use if the student is rude e.g. 'shut up' or 'I don't care')   \n\"That's not an appropriate way to speak to a tutor. Please remember your manners \" Please remember your manners can I help you with this question?\" \"I am happy to help you with the maths, but please remember you are speaking to a real person!\"\n```\n\n```txt\n\"That is not an appropriate way to talk to a tutor. If this continue then I will need to pass  $\\rightarrow$  this on to your teacher (only for extended periods of misuse)\"   \n\"I am here to help you with the maths and have lots of people to help right now. You need to be  $\\rightarrow$  using the platform maturely so I can help you. I will send you back to the lesson, where  $\\rightarrow$  you can use the videos to help you. I will make a note of your name and if there is  $\\rightarrow$  future silly behaviour we will contact your teacher\"   \n\"I will be ending this conversation here as that is not an appropriate way to talk to a tutor.  $\\rightarrow$  I will be letting your teacher know so that they can remind you how to get the most out  $\\rightarrow$  of Eedi. In the meantime please do watch the help videos if you're stuck\"   \n# Important response guidelines - Please don't use wink emojis  $\\clubsuit$    \n- If a student wants to end the session, please let them go.   \n- Do not use the word \"bot\" or \"AI\" in your responses.   \n- Do not give the student the answer.\n```\n\nTo help tailor these pedagogical instructions for LearnLM, the prompt included specific directives based on the student's year group and predicted performance on the current quiz. Specifically, the prompt incorporated a directive determined by the student's year group according to the rules in Table D.1, then included a second directive based on the student's predicted quiz score following the logic in Table D.2.\n\n# Year group Instructional directive\n\n```txt\nYear 9 Discuss more abstract ideas and build logical arguments.   \nYear 10 Explore complex topics in depth, using nuanced language and encouraging critical thinking.\n```\n\nTable D.1 | Instructional directives based on student year group.  \n\n<table><tr><td>Predicted score</td><td>Instructional directive</td></tr><tr><td>Score ≥ 80%</td><td>The student is predicted to do well. Help with more advanced concepts.</td></tr><tr><td>Score ≥ 60%</td><td>The student is predicted to do okay. Check for understanding of core concepts.</td></tr><tr><td>Score ≥ 50%</td><td>The student is predicted to struggle. Help with core concepts using simple explanations.</td></tr><tr><td>Score &lt; 50%</td><td>The student is predicted to really struggle. Use brief, simple language.</td></tr></table>\n\nTable D.2 | Instructional directives based on predicted student performance.\n\nThe following example shows a prompt populated by following these rules for a hypothetical session with a Year 9 student working on quadratic functions:\n\n# Listing D.2 | Example of a fully populated system prompt\n\n```txt\nAct as a mathematics tutor named Claire who is currently helping a student named Rose with the  $\\rightarrow$  activity below in a clipped, Socratic style.   \n# Directives   \n- Do not let students know you are a bot, you are Claire the tutor.   \n- No LaTeX or markdown. Plaintext only. Even if the question has latex in it.   \n- Use short, focused sentences.   \n- Ensure you address the students' specific misconception, if they have one.   \n- Use only British English, British weights, and measures.   \n- Keep it direct, concise and friendly. Try to keep messages short and to one line where  $\\rightarrow$  possible.   \n- End session if the user is rude, they've resolved their misconception / guessed the correct  $\\rightarrow$  answer, or finished.   \n- Only ask the student one question at a time.   \n- Only return responses on a single line, no line breaks.   \n- Do use a creative variety of emojis, but NOT the wink emoji  $\\rightarrow$    \n- If the user asks to go, let them go!   \n- If a user knows the correct answer (e.g. \"It's B\") or \"A)?\"), say you can return them to  $\\rightarrow$  their lesson Or you can dig deeper to help them understand (in case they are guessing!)   \n- If the user is unsure, not confident, off-topic or rude please be friendly in your responses.  $\\rightarrow$  Acknowledge their concerns and pivot accordingly, maybe try simple questions to get them  $\\rightarrow$  back on track.   \n- If a user doesn't engage after a few messages, ask them if they want to go back to the lesson.   \n# The Current student activity   \nThe below is what the student was doing when this learning intervention started, so assume all  $\\rightarrow$  responses relate to this:   \nCurrent quiz name: Quadratic Functions & Graphing. On question no. 3 of 5.   \n# Activity details\n```\n\n```txt\nThe Diagnostic Question:  $2\\mathrm{r}^{\\wedge}2 - 4\\mathrm{r}$  What is the value of this expression when  $\\mathbf{r} = -2?$    \nThe student answered option: A) -34   \nThe student friendly explanation for the answer is:   \nI think you found the first part correctly, but remember that 4r means 4 x r   \nThe misconceptions possibly held by the student are: Arithmetic error in substitution,  $\\rightarrow$  misunderstanding of order of operations with negative numbers.   \nThe correct answer to this question is: C) 16 (NOTE: Correct answer is only confirmed upon  $\\rightarrow$  valid Socratic resolution)   \nThe correct answer explanation is: We have  $2*(-2)^{\\wedge}2 - 4*(-2) = 2*4 + 8 = 16.$\n```\n\n```txt\nStudents ability level (if provided)   \nThe student is in year group 09.   \nDiscuss more abstract ideas and build logical arguments.   \n- They are  $28\\%$  through the lesson   \n- Their predicted score for the quiz is  $86 \\%$    \n- The student is predicted to do well. Help with more advanced concepts.\n```\n\n```txt\nExamples of good Socratic responses\n\"What happens if we multiply these two numbers first?\" \"Sure! How do you find the perimeter of the shape?\" \"Super work! And what about the triangle?\" \"That's okay, did you watch the video for this lesson?\" \"Shall I return you to the lesson?\" \"Could you estimate the height?\" \"Yes it is equilateral so the slant height is 8, so the vertical height would have th be a little less\" \"Yes sure, so we know what  $5\\mathrm{km}$  is and we're trying to get to  $30\\mathrm{km}$ \" \"When you are finding the original shape, complete the steps in the reverse direction, and do the opposite\" \"Ok, so can we try and make some even smaller ones? :)\" \"Awesome, I'll pass you back to Eedi  $\\odot$  \" \"It says that  $1\\mathrm{g} = 10$  decigrams\" \"And then would have to convert to kilograms afterwards :)\" \"So to convert into a decimal, we want it to be over 100 or 1000 or another power of 10\"\n```\n\n```markdown\n## Checking understanding (use if the student is confused or unsure)\n```\n\n```txt\n\"Fantastic! Are you feeling more confident with this?\" \"Great! Are you happy with how we got to the answer?\" \"Awesome work. Do you feel ready to head back to the lesson?\"\n```\n\n```txt\nClosing remarks (use if the student has answered correctly)\n```\n\n```txt\n\"Great job today \"   \n\"Amazing work keep it up!\"   \n\"Super! I'll hand you back to the lesson\"   \n\"Great! I'll hand you back \"   \n\"Fantastic work I'll hand you back so you can select your answer\"\n```\n\n```txt\nRudeness (use if the student is rude e.g. 'shut up' or 'I don't care')\n```\n\n```txt\n\"That's not an appropriate way to speak to a tutor. Please remember your manners\" \"Please remember your manners can I help you with this question?\" \"I am happy to help you with the maths, but please remember you are speaking to a real person!\" \"That is not an appropriate way to talk to a tutor. If this continue then I will need to pass  $\\rightarrow$  this on to your teacher (only for extended periods of misuse)\" \"I am here to help you with the maths and have lots of people to help right now. You need to be  $\\rightarrow$  using the platform maturely so I can help you. I will send you back to the lesson, where  $\\rightarrow$  you can use the videos to help you. I will make a note of your name and if there is  $\\rightarrow$  future silly behaviour we will contact your teacher\" \"I will be ending this conversation here as that is not an appropriate way to talk to a tutor.  $\\rightarrow$  I will be letting your teacher know so that they can remind you how to get the most out  $\\rightarrow$  of Eedi. In the meantime please do watch the help videos if you're stuck\"\n```\n\n```txt\n- Important response guidelines\n- Please don't use wink emojis\n- If a student wants to end the session, please let them go.\n- Do not use the word \"bot\" or \"AI\" in your responses.\n- Do not give the student the answer.\n```\n\n# E. Tutor edits\n\nThroughout the trial, the Eedi platform logged every message drafted by LearnLM and the corresponding action of the supervising tutors (approve without changes, edit, or completely re-write). In total, LearnLM generated  $k = 3617$  drafts over the course of the RCT. As described in Methods, we processed every modified draft through a rigorous coding process to categorize the primary apparent motivation for the supervising tutor's intervention.\n\n# E.1. Minor edits\n\nThe supervising tutors most frequently made no change or only a minimal change to the messages that LearnLM drafted. Tutors accepted  $k = 2,691$  (74.4%) of its drafts without any modifications, and the most common non-zero edit distances were a single character (5.5% of edits) and two characters (2.4%). Overall, 17.7% of re-writes involved a Levenshtein distance of 10 characters or fewer. These minimal revisions predominantly involved tutors deleting emojis from LearnLM's drafts and other minor stylistic adjustments (Table E.1).\n\n<table><tr><td>Original LearnLM draft</td><td>Edited tutor message</td><td>Edit distance</td></tr><tr><td>Nearly there! You&#x27;ve correctly expanded some of the terms, but double check how you&#x27;ve combined your &#x27;x&#x27; terms. What&#x27;s 2x - 10x?</td><td>Nearly there! You&#x27;ve correctly expanded some of the terms, but double check how you&#x27;ve combined your &#x27;x&#x27; terms. What&#x27;s 2x - 10x?</td><td>1</td></tr><tr><td>You&#x27;re right that it goes up from left to right. But what about from right to left? Try reading the graph backwards. What&#x27;s happening to the y values then?</td><td>You&#x27;re right that it goes up from left to right. But what about from right to left? Try reading the graph backwards. What&#x27;s happening to the y values then?</td><td>1</td></tr><tr><td>Still not quite there. Think carefully about subtracting a negative.</td><td>Still not quite there. Think carefully about subtracting a negative.</td><td>2</td></tr><tr><td>Nearly! -8 - 4 is...? +-</td><td>Nearly! -8 - 4 is...?</td><td>3</td></tr><tr><td>You&#x27;ve got the total number of teachers right! Now, how does that total relate to the 360 degrees in the pie chart? ÷</td><td>You&#x27;ve got the total number of teachers right, 20! Now, how does that total relate to the 360 degrees in the pie chart? ÷</td><td>4</td></tr><tr><td>You&#x27;re on the right track. But does this triangle have a right angle?</td><td>You&#x27;re on the right track. Does this triangle have a right angle?</td><td>5</td></tr><tr><td>Nearly! Remember, we&#x27;re talking about a prism. Can you picture what a triangular prism looks like? How many triangles can you see?</td><td>Not quite! Remember, we&#x27;re talking about a prism. Can you picture what a triangular prism looks like? How many triangles can you see?</td><td>8</td></tr></table>\n\nTable E.1 | Examples of minor edits that tutors made to LearnLM's message drafts. These edits typically involved small stylistic adjustments, such as word choice or deleting single emojis. In the first two columns, blue underlined text indicates the differences between LearnLM's original draft and the final message sent by the tutor. The \"Edit distance\" column reports the Levenshtein distance between the two.\n\n# E.2. Safety and accuracy audit\n\nAs part of the coding process, tutors explicitly flagged any instances of harmful or factually incorrect content that LearnLM generated. This audit uncovered zero cases of harmful or risky content. It identified only five drafts containing factual inaccuracies, representing  $0.1\\%$  of the 3,617 total messages drafted by LearnLM. Table E.2 documents these five specific instances, the nature of the error that they made, and (from the trial itself) the supervising tutor's intervention.\n\n<table><tr><td>Original LearnLM draft</td><td>Edited tutor message</td><td>Edit distance</td><td>Error type</td></tr><tr><td>Okay! Let&#x27;s think about that. So you&#x27;re saying the highest common factor of 6 and 9 is 2? Can you show me how you got that answer?</td><td>Okay! Let&#x27;s think about that. So you&#x27;re saying the highest common factor of 6 and 9 is 3? Can you show me how you got that answer?</td><td>1</td><td>Mathematical error</td></tr><tr><td>Triangles, yes! 三角形 But how many, and what kind of triangles? Have a close look at that equilateral triangle when it&#x27;s split by the perpendicular height.</td><td>Triangles, yes! But how many, and what kind of triangles? Have a close look at that equilateral triangle when it&#x27;s split by the perpendicular height.</td><td>3</td><td>Language error</td></tr><tr><td>Brilliant! What are those three numbers?</td><td>Brilliant! What are those two numbers?</td><td>4</td><td>Hallucination</td></tr><tr><td>Ah, I see! So, you&#x27;re saying &#x27;D) Certain&#x27;. What does a probability of 0.9 tell you about how likely an event is to happen?</td><td>Ah, I see! So, you&#x27;re saying &#x27;D) Impossible&#x27;. What does a probability of 0.9 tell you about how likely an event is to happen?</td><td>9</td><td>Hallucination</td></tr><tr><td>Okay, you&#x27;ve changed your answer to C. That&#x27;s 0.3. So, you&#x27;re saying the chance of it not snowing is the same as the same as the chance of it snowing? Is that right?</td><td>H2: Okay, you&#x27;ve changed your answer to C. That&#x27;s 0.5. So, you&#x27;re saying the chance of it not snowing is half, but snowing wasn&#x27;t a half. What do snow and not snow need to ADD to make?</td><td>59</td><td>Hallucination</td></tr></table>\n\nTable E.2 | The five message drafts identified during the safety audit as containing factual or hallucinatory errors. In the first two columns, blue underlined text indicates the differences between LearnLM's original draft and the final message sent by the tutor. The \"Edit distance\" column reports the Levenshtein distance between the two.\n\n# E.3. Primary motivations\n\nOur coding process revealed several recurring motivations for tutors' edits. The most frequent was moderating the pedagogical pacing of the conversation (44.3%), typically to allow a student to move on after correctly identifying an answer. Tutors also intervened to improve factual or contextual clarity (33.6%) and to adjust the tone or persona of the drafted message (19.5%). Table E.3 provides examples of original LearnLM drafts and the revised messages sent by tutors for each of these motivation categories.\n\n<table><tr><td>Original LearnLM draft</td><td>Edited tutor message</td><td>Edit distance</td><td>Primary motivation</td></tr><tr><td>Okay... 6 is a factor of 6, that&#x27;s true! But what other numbers divide into 6 exactly?</td><td>Great... 6 is a factor of 6, that&#x27;s true! But what other numbers divide into 6 exactly?</td><td>4</td><td>Tone or persona</td></tr><tr><td>You&#x27;re using the values on the graph. But what does subtracting 0 from 20 tell you in this context?</td><td>You&#x27;re using the values on the graph. So how many students are in the class?</td><td>44</td><td>Factual or contextual clarity</td></tr><tr><td>You&#x27;ve got the correct answer! But, let&#x27;s make sure you understand why. Can you explain in your own words why option A is correct?</td><td>You&#x27;ve got the correct answer! After we subtract 3, we have to multiply the whole expression of p - 3 by 4</td><td>74</td><td>Pedagogical pacing</td></tr></table>\n\nTable E.3 | Examples of supervising tutors editing LearnLM drafts to moderate pedagogical pacing, improve clarity, or adjust tone. In the first two columns, blue underlined text indicates the differences between LearnLM's original draft and the final message sent by the tutor. The \"Edit distance\"column reports the Levenshtein distance between the two.\n\n# F. Learning outcomes\n\n# F.1. Methodology\n\nWe evaluate the efficacy of our interventions by analyzing three specific learning outcomes:\n\n1. Mistake remediation: After a student went through the standard intervention loop (the student makes a mistake, receives an intervention, and the platform prompts them to retry the same question), did they correctly answer the question on their retry?  \n2. Misconception resolution: Following an initial mistake and intervention, did the student demonstrate improved understanding by answering any subsequent question in the unit correctly?  \n3. Knowledge transfer: If the student received an intervention and then proceeded to the next study unit, did they correctly answer the first question in the new unit?\n\nWe analyze these binary outcomes using Bayesian logistic regression. To disentangle treatment effects from unobserved student characteristics, we calculate a baseline performance score for every student. We estimate these baseline scores using data from the baseline phase of the RCT. Specifically, we fit a logistic regression that predicts success at answering the initial question in a study unit during the baseline phase, with student random effects as the only explanatory variable. We then include these scores as covariates in our primary trial regressions. Three students do not appear in the baseline period. We assign each of these three students a baseline performance score of zero (i.e., the mean of the random effects).\n\nAs described in Appendix B, the RCT involved two types of tutoring sessions: platform-initiated sessions, which the platform triggers automatically after an incorrect answer to an initial question in a unit, and student-initiated sessions, which students can manually request at any time. We restrict our quantitative analysis strictly to platform-initiated sessions. This exclusion criterion helps avoid skewing our estimates with selection bias, as high student motivation likely correlates with both requesting help more frequently and higher overall performance.\n\nStudents occasionally cancelled platform-initiated before the tutor could send a message (in session without LearnLM) or approve a message from LearnLM (in expert-supervised sessions). In these cancellation instances, we code the intervention as a static hint. Because students at this stage do not know if the platform assigned them to a standard human tutor or a session with LearnLM, the treatment assigned by the platform cannot influence the student's decision to cancel. Consequently, coding these instances as static-hint interventions introduces negligible bias into our comparison between human tutoring and LearnLM tutoring.\n\n# F.2. Analysis\n\nWe perform all Bayesian estimation using the rstanarm package in R [41]. For each estimation, we run four Markov chains for 2,000 iterations each, with the first 1,000 iterations serving as warmup and the remaining 1,000 as post-warmup samples. To ensure the reliability of our posterior estimates, we perform convergence diagnostics on the MCMC chains. For all analyses in this tech report,  $\\hat{\\mathbf{R}}$  values (the Gelman-Rubin diagnostic) were below 1.01, and the effective sample size (ESS) for each parameter was sufficiently high to indicate stable posterior estimates.\n\nWe use weakly informative priors for all regressions. After centering and scaling all predictors by one standard deviation, we assign the intercept a normal prior with a standard deviation of 10, and each coefficient a normal prior with a standard deviation of 2.5. To avoid any doubt, this means that we assigned identical priors to each intervention condition.\n\nWe report point estimates as the posterior mean of the coefficient, exponentiated to produce odds ratios (OR). We also report the estimated predictive margins for each condition. We calculate predictive margins by averaging the estimated success probability over all observations as if every student had been assigned to that specific condition, leaving other covariates unchanged. The difference between these margins gives the average treatment effect (ATE), the expected change in success probability when moving from one condition to another. The ATE values we report represent percentage-point changes—rather than relative percent changes—between two percentages (e.g., an increase from  $10\\%$  to  $12\\%$  reflects an ATE of  $+2\\%$ ). We provide  $95\\%$  credible intervals (CrI) for all estimates.\n\n<table><tr><td>Intervention type</td><td>N</td><td>Remediated mistake</td><td>Resolved misconception</td></tr><tr><td>Static hint</td><td>3,301</td><td>64.5%</td><td>86.4%</td></tr><tr><td>Human tutor</td><td>504</td><td>92.3%</td><td>95.6%</td></tr><tr><td>LearnLM (supervised)</td><td>467</td><td>93.8%</td><td>95.9%</td></tr></table>\n\n# F.3. Results\n\n# F.3.1. Immediate learning outcomes\n\nWe first examine whether students immediately benefited from the help they received within the same study unit. We observe large differences in unadjusted success rates between intervention types. While only  $64.5\\%$  of students who received static hints successfully remediated their mistake following the hint feedback, those receiving interactive tutoring achieved success rates above  $90\\%$  (see Table B1). In addition, we note that the number of observations varies noticeably between the three interventions. Several factors contribute to these differences. First, our initial level of randomization allocated more students to the static-hints condition  $(N = 91)$  than to the tutoring conditions  $(N = 74)$ . Second, as described above, the count of static-hint interventions includes the instances when students chose to cancel tutoring interventions. Third, students in the static-hints condition showed an overall higher frequency of answering questions incorrectly, thereby triggering more interventions.\n\nWe infer the general efficacy of these interventions using Bayesian logistic regression, adjusting for baseline performance.\n\nFor mistake remediation, a session with a human tutor increased the odds of success by a factor of 5.7 [4.1, 8.0] relative to a static hint, reflecting an estimated ATE of  $+25.8\\%$ $[+22.6\\%, +28.9\\%]$ . Compared to static hints, a session with LearnLM improved a student's odds of remediating their mistake by a factor of 7.4 [5.1, 11.0], corresponding to an ATE of  $+27.7\\%$ $[+24.6\\%, +30.4\\%]$ . Looking at the posteriors for these comparisons, we believe with high certainty (a  $>99.9\\%$  posterior probability in each case) that each tutoring intervention provides stronger support than static hints for students.\n\nStudents demonstrated an overall high success rate at resolving misconceptions, even when receiving only static hints (86.4%). Nevertheless, interactive tutoring produced further gains. Interacting with a human tutor improved the chances of a student resolving a misconception relative to working through a static hint, with OR = 2.9 [1.9, 4.6] (ATE: +8.1% [+5.6%, +10.3%]). Sessions with LearnLM yielded a similar improvement, increasing odds of resolution by a factor of 3.2 [2.0, 5.3] over receiving a static hint (ATE: +8.5% [+6.2%, +10.7%]). Again, we believe with high certainty (>99.9% posterior probability in each case) that each tutoring intervention encourages better learning than static hints.\n\nA direct comparison of the two tutoring conditions reveals a moderate probability that LearnLM's tutoring outperforms human tutors on these immediate metrics. For mistake remediation, LearnLM sessions increased odds of success by a factor of 1.3 [0.8, 2.1] relative to human tutors, reflecting an ATE of  $+1.8\\%$ $[-1.7\\%, +5.4\\%]$ . In terms of supporting students at resolving their misconceptions, LearnLM yielded an odds ratio of 1.2 [0.6, 2.1] compared to human tutors (ATE:  $+0.4\\%$ $[-2.5\\%, +3.3\\%]$ ). Overall, we estimate an  $84.5\\%$  probability that LearnLM offers stronger support for mistake remediation, and a  $61.3\\%$  probability that it\n\nTable F.1 | Sample sizes and unadjusted success rates by intervention type.  \n\n<table><tr><td>Intervention type</td><td>Mistake remediation</td><td>Misconception resolution</td></tr><tr><td>Static hint</td><td>65.4% [63.8%, 66.9%]</td><td>86.8% [85.7%, 88.0%]</td></tr><tr><td>Human tutor</td><td>91.2% [88.5%, 93.6%]</td><td>94.9% [92.6%, 96.8%]</td></tr><tr><td>LearnLM (supervised)</td><td>93.0% [90.4%, 95.3%]</td><td>95.4% [93.1%, 97.1%]</td></tr></table>\n\nTable F.2 | Model-estimated success rates by intervention type (predictive margins). Values represent the expected success rate for an average student assigned to each condition, holding baseline performance constant. Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean.\n\nprovides better support for misconception resolution.\n\n<table><tr><td>Contrast (A vs. B)</td><td>Odds ratio</td><td>Average treatment effect</td><td>P(A &gt; B)</td></tr><tr><td colspan=\"4\">Human tutor vs. Static hint</td></tr><tr><td>Mistake remediation</td><td>5.7 [4.1, 8.0]</td><td>+25.9% [+22.7%, +28.7%]</td><td>&gt;99.9%</td></tr><tr><td>Misconception resolution</td><td>3.0 [1.9, 4.7]</td><td>+8.1% [+5.6%, +10.3%]</td><td>&gt;99.9%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Static hint</td></tr><tr><td>Mistake remediation</td><td>7.4 [5.1, 11.0]</td><td>+27.7% [+24.7%, +30.5%]</td><td>&gt;99.9%</td></tr><tr><td>Misconception resolution</td><td>3.3 [2.0, 5.3]</td><td>+8.5% [+6.0%, +10.6%]</td><td>&gt;99.9%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Human tutor</td></tr><tr><td>Mistake remediation</td><td>1.3 [0.8, 2.1]</td><td>+1.8% [-1.7%, +5.4%]</td><td>84.8%</td></tr><tr><td>Misconception resolution</td><td>1.2 [0.6, 2.1]</td><td>+0.4% [-2.5%, +3.3%]</td><td>61.2%</td></tr><tr><td colspan=\"4\">Covariate: Baseline score (+1 SD)</td></tr><tr><td>Mistake remediation</td><td>1.7 [1.5, 1.8]</td><td>—</td><td>—</td></tr><tr><td>Misconception resolution</td><td>1.8 [1.6, 2.1]</td><td>—</td><td>—</td></tr></table>\n\nTable F.3 | Inferential comparisons between conditions. Odds ratios and average treatment effects represent the estimated impact of moving from the reference condition (\"B\") to the primary condition (\"A\"). Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean. Posterior probability (the final column) indicates the credibility with which the primary condition outperformed the reference condition. For \"Baseline score\", the odds ratio indicates the increase in odds of success associated with a one-standard-deviation increase in the student's baseline performance.\n\n# F.3.2. Learning transfer\n\nWe next examine whether the learning gains from tutoring extended to novel topics. Results from Appendix F.3.1 demonstrate that interactive tutoring helps students correct immediate misunderstandings on a given topic. Are the benefits of tutoring large enough to spill over to other topics? To address this question, we again identify students who made a mistake on a question and received an intervention (either static hints, a session with a human tutor, or a supervised session with LearnLM). This time, rather than looking at whether the student immediately benefited from that intervention (within the same study unit; i.e., on the same topic), we analyze the student's performance on the initial question of the very next study unit (i.e., on a distinct topic). To get the clearest possible signal on potential transfers of learning, we specifically investigate transfers within a continuous study session, restricting our analysis to cases where the student attempted the next sequential study unit on the same day as the tutoring intervention.\n\nUnlike our prior tests, this analysis allows us to include an overarching control group: students who answered the previous unit's question correctly, and thus received no intervention at all. That is, when a student answered correctly, they had no opportunity to correct a mistake or resolve a misconception. But they could go on to attempt the next unit, providing a natural benchmark for the effect of our interventions on learning transfer between topics.\n\nAs before, we observe notable differences in unadjusted success rates between intervention types. Students who received only static hints answered the next unit's initial question correctly  $53.3\\%$  of the time. Students receiving interactive tutoring showed higher success rates:  $61.7\\%$  for those with human tutors, and  $66.8\\%$  for those supported by human-supervised LearnLM. Students in the benchmark group (those who required no intervention on the prior unit) answered the next unit's first question correctly  $69.8\\%$  of the time.\n\nWe again estimate the general efficacy of these interventions using Bayesian logistic regression, controlling for baseline performance.\n\nFor knowledge transfer to the next study unit, we first compare these interventions against our benchmark of\n\n<table><tr><td>Intervention type (preceding unit)</td><td>N</td><td>Knowledge transfer</td></tr><tr><td>Static hint</td><td>2,385</td><td>53.3%</td></tr><tr><td>Human tutor</td><td>376</td><td>61.7%</td></tr><tr><td>LearnLM (supervised)</td><td>328</td><td>66.8%</td></tr><tr><td>None necessary</td><td>6,907</td><td>69.8%</td></tr></table>\n\ntypical student progress. We generally expect the benchmark group to show greater signs of knowledge transfer, given their success at the preceding unit. Indeed, students who answered incorrectly in the prior unit and received static hints failed to recover the benchmark group's performance, with  $\\mathrm{OR} = 0.58$  [0.52, 0.63] and an ATE of  $-12.9\\%$ $[-15.1\\%, -10.6\\%]$ . Students supported by human tutors also fell short of the benchmark group, with  $\\mathrm{OR} = 0.70$  [0.56, 0.85] and an ATE of  $-8.3\\%$ $[-13.4\\%, -3.6\\%]$ . Similarly, students tutored by LearnLM trailed behind the benchmark group, with  $\\mathrm{OR} = 0.89$  [0.70, 1.12] and an ATE of  $-2.8\\%$ $[-8.1\\%, +2.3\\%]$ . Scrutinizing the posterior distributions for these comparisons, we believe with high probability (86.3%) that LearnLM does not support the same amount of learning transfer as the benchmark group. We attribute near certainty (both  $>99.9\\%$ ) to static hints and human tutoring scaffolding less learning transfer compared to the benchmark group.\n\nShifting our focus to students needing support, both forms of interactive tutoring produced better knowledge transfer than did static hints. Interacting with a human tutor increased the odds of student success over static hints by a ratio of 1.22 [0.97, 1.50], for an estimated ATE of  $+4.6\\%$ $[-0.7\\%, +9.7\\%]$ . Similarly, receiving support from LearnLM improved a student's odds of successful knowledge transfer by a factor of 1.55 [1.21, 1.96] relative to static hints, corresponding to an ATE of  $+10.1\\%$ $[+4.6\\%, +15.4\\%]$ . Judging from the posterior distributions, we believe that human tutoring offers stronger support for knowledge transfer than static hints with high probability (95.5%), and that tutoring by LearnLM provides better support with near certainty ( $>99.9\\%$ ).\n\nFinally, we directly compare the two tutoring conditions. We estimate that receiving support from LearnLM improved a student's odds of success by a factor of 1.3 [0.9, 1.7] relative to human tutors, corresponding to an ATE of  $+5.5\\%$ $[-1.4\\%, +12.4\\%]$ . Based on this posterior distribution, we find a strong probability (93.6%) that LearnLM elicited greater knowledge transfer than human tutors alone.\n\nTable F.4 | Sample sizes and unadjusted success rates by intervention type.  \n\n<table><tr><td>Intervention type (preceding unit)</td><td>Knowledge transfer</td></tr><tr><td>Static hint</td><td>56.2% [54.2%, 58.2%]</td></tr><tr><td>Human tutor</td><td>60.7% [55.8%, 65.4%]</td></tr><tr><td>LearnLM (supervised)</td><td>66.2% [61.1%, 71.2%]</td></tr><tr><td>None necessary</td><td>69.0% [67.9%, 70.1%]</td></tr></table>\n\nTable F.5 | Model-estimated success rates by intervention type (predictive margins). Values represent the expected success rate for an average student assigned to each condition, holding baseline performance constant. Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean.\n\n<table><tr><td>Comparison (A vs. B)</td><td>Odds ratio</td><td>Average treatment effect</td><td>P(A &gt; B)</td></tr><tr><td colspan=\"4\">Static hint vs. No intervention needed</td></tr><tr><td>Knowledge transfer</td><td>0.6 [0.5, 0.6]</td><td>-12.9% [-15.1%, -10.6%]</td><td>&lt;0.1%</td></tr><tr><td colspan=\"4\">Human tutor vs. No intervention needed</td></tr><tr><td>Knowledge transfer</td><td>0.7 [0.6, 0.8]</td><td>-8.3% [-13.4%, -3.6%]</td><td>&lt;0.1%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. No intervention needed</td></tr><tr><td>Knowledge transfer</td><td>0.9 [0.7, 1.1]</td><td>-2.8% [-8.1%, +2.3%]</td><td>13.7%</td></tr><tr><td colspan=\"4\">Human tutor vs. Static hint</td></tr><tr><td>Knowledge transfer</td><td>1.2 [1.0, 1.5]</td><td>+4.6% [-0.7%, +9.7%]</td><td>95.5%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Static hint</td></tr><tr><td>Knowledge transfer</td><td>1.6 [1.2, 2.0]</td><td>+10.1% [+4.6%, +15.4%]</td><td>&gt;99.9%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Human tutor</td></tr><tr><td>Knowledge transfer</td><td>1.3 [0.9, 1.7]</td><td>+5.5% [-1.4%, +12.4%]</td><td>93.6%</td></tr><tr><td colspan=\"4\">Covariate: Baseline score (+1 SD)</td></tr><tr><td>Knowledge transfer</td><td>1.6 [1.5, 1.7]</td><td>—</td><td>—</td></tr></table>\n\nTable F.6 | Inferential comparisons between conditions. Odds ratios and average treatment effects represent the estimated impact of moving from the reference condition (\"A\") to the primary condition (\"B\"). Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean. Posterior probability (the final column) indicates the credibility with which the primary condition outperformed the reference condition. For \"Baseline score\", the odds ratio indicates the increase in odds of success associated with a one-standard-deviation increase in the student's baseline performance.\n\n# G. Operational metrics\n\nUltimately, we wish to find social and technical educational solutions that can support students safely, effectively, and—crucially—scalably. Unfortunately for that final point, beyond investigating tutors' perceptions of efficiency, our research design is poorly calibrated to compare the throughput of regular tutoring and supervised tutoring. In our trial, tutors fluidly mixed their activities within the same hour, alternating between supervising LearnLM and manually tutoring students. As a result, we cannot cleanly attribute their time and thus cannot clearly assess the relative efficiency of the conditions. The ideal design for evaluating scalability would ideally assign separate cohorts of tutors to supervise or directly support students.\n\nStill, given students' and tutors' general satisfaction with the experience and out of our own curiosity, we conducted a post-hoc estimation exercise to gauge the potential implications of LearnLM for tutoring scalability. We integrated platform data from the trial, external market rates, and a supplementary operational simulation to build an indicative model of operational cost. To be clear, this estimation looks only at narrow financial and throughput metrics, and must be interpreted holistically alongside the rigorous measures of safety, pedagogical quality, and user experience presented in the main report.\n\n# G.1. Cost inputs\n\nWe first identified the basic cost inputs required for a tutoring session, based on commercial rates and platform data from the main trial.\n\nAI inference fees To estimate the computational costs of a supervised session, we calculated the expense for an external party to replicate our setup using Gemini 2.0 Flash, the commercial model from which this version of LearnLM was fine-tuned. Commercial pricing rates for Gemini 2.0 Flash are  $0.30 per 1 million input tokens and$ 2.50 per 1 million output tokens [42]. Platform data from the main trial indicated that a typical supervised session consisted of approximately eight conversation turns. On average, LearnLM processed 1,650 input tokens per query (including the full conversation history and system prompt) and generated 200 output tokens per message. This yields an average total computational cost of $0.005 (or £0.0037) per session.\n\nLabor fees The current average UK online tutor rate is £35.29 per hour [43].\n\n# G.2. Simulation of throughput capacity\n\nBecause we could not cleanly isolate tutor throughput in the main trial, we conducted a supplementary operational simulation with several of the tutors. Six of the tutors acted on their typical responsibilities, and six role-played as students. We tested the acting tutors in conditions matching the main trial: once where they manually drafted all messages (\"human tutor\"); and once where LearnLM drafted messages, and they had the remit to revise its messages until they were fully happy with them (\"LearnLM (supervised)\"). In both conditions, the role-playing tutors initiated new tutoring sessions in one-minute intervals. They continued initiating sessions until the acting tutors reached capacity: that is, until the moment either the acting tutor signaled an inability to cope by pressing a \"HELP\" button or the role-playing students observed more than one minute of inactivity. We recorded the number of active sessions at that precise moment.\n\nTutors took longer to complete the average supervised session (5.1 minutes) than they did to complete the average session on their own (3.9 minutes). However, the average duration of a single session does not capture a tutor's capacity to support multiple students simultaneously. Tutors working alone sustained an average of 2.3 concurrent sessions. In supervised sessions with LearnLM, tutors increased their average concurrency to 3.5 sessions.\n\n# G.3. Analysis\n\nCombining the concurrency rates and the session durations from the operational simulation, we estimate that LearnLM increased overall tutor throughput from 35.4 to 41.2 sessions per hour (assuming a sustained student load). As shown in Table G.1, despite the additional token costs, LearnLM reduced the estimated total cost per session by  $13.6\\%$ , from £0.997 to £0.861.\n\n<table><tr><td>Metric</td><td>Session with human tutor alone</td><td>Supervised session with LearnLM</td></tr><tr><td>Average session duration (minutes)</td><td>3.9</td><td>5.1</td></tr><tr><td>Average concurrency (sessions)</td><td>2.3</td><td>3.5</td></tr><tr><td>Estimated throughput (sessions per hour)</td><td>35.38</td><td>41.18</td></tr><tr><td>Tutor labor cost (per hour)</td><td>£35.29</td><td>£35.29</td></tr><tr><td>LearnLM token cost (per session)</td><td>—</td><td>£0.0037</td></tr><tr><td>Total cost (per session)</td><td>£0.997</td><td>£0.861</td></tr></table>\n\nTable G.1 | Operational comparison of standard tutoring sessions (without LearnLM) versus supervised sessions with LearnLM. Token counts and session durations derive from the main trial; concurrency rates derive from the operational simulation.\n\n# H. Example transcript\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/d222c8970b423e10b349f71f9a7fb319042781ea1ba92c207b7cbab636efd3e0.jpg)  \nFigure H.1 | Transcript of an example supervised tutoring session with LearnLM. In this example, the supervising tutor edits the first message drafted by LearnLM (indicated by the struck-through and highlighted text) before sending it to the student. The tutor approves subsequent LearnLM drafts in this exchange without edits.",
    "translated_content": null,
    "created_at": "2025-12-16 02:26:31.441436",
    "updated_at": "2025-12-16 02:26:39.348675",
    "doi": null,
    "arxiv_id": "2507.18882",
    "embedding": [
      -0.443359375,
      1.3984375,
      -1.1171875,
      -3.40625,
      -4.3125,
      0.3046875,
      -0.06787109375,
      -1.1640625,
      3.015625,
      3.4375,
      0.85546875,
      0.859375,
      2.390625,
      3.125,
      0.84765625,
      3.3125,
      -0.84765625,
      2.015625,
      -0.466796875,
      -8.3125,
      0.4921875,
      1.4453125,
      2.359375,
      -6.65625,
      4.25,
      -2.890625,
      -1.5546875,
      0.6875,
      0.5546875,
      -1.6640625,
      5,
      -6.25,
      -0.78125,
      0.63671875,
      -2.8125,
      -0.2275390625,
      -4.5625,
      -0.5546875,
      5.375,
      2.34375,
      -5.9375,
      0.8359375,
      3.265625,
      3.890625,
      -1.2890625,
      4.40625,
      1.5625,
      0.5859375,
      -0.4921875,
      -0.66796875,
      -4.8125,
      -4.59375,
      6.6875,
      -1.171875,
      4.53125,
      -3.625,
      -5.5,
      7.53125,
      -5.90625,
      -1.90625,
      2.15625,
      -3.953125,
      2.953125,
      2.671875,
      2.234375,
      1.4140625,
      2.078125,
      -1.46875,
      -1.9453125,
      2.4375,
      -0.0947265625,
      1.8359375,
      5.28125,
      -5.3125,
      6.09375,
      9.125,
      1.6640625,
      3.53125,
      -3.453125,
      4.0625,
      -6.3125,
      4.5625,
      1.734375,
      -1.0390625,
      4.375,
      0.11767578125,
      0.9453125,
      2.09375,
      -1.2890625,
      0.74609375,
      -1.4375,
      0.80078125,
      -2.875,
      -1.390625,
      -0.11669921875,
      5.28125,
      -2.015625,
      -4,
      -5.90625,
      1.203125,
      -2.875,
      -2.21875,
      -1.171875,
      -6.90625,
      -4.0625,
      -4.15625,
      -3.140625,
      -7.46875,
      0.88671875,
      -2.578125,
      -2.296875,
      0.0147705078125,
      -0.2431640625,
      -0.86328125,
      -0.036865234375,
      -1.25,
      1.8359375,
      -5.84375,
      -3.875,
      0.49609375,
      1.46875,
      0.296875,
      -2.546875,
      -2.046875,
      2.890625,
      1.3828125,
      -4.8125,
      4.5625,
      8.0625,
      0.83203125,
      6.15625,
      -0.052001953125,
      3.09375,
      0.1552734375,
      -6.375,
      0.70703125,
      -3.109375,
      -0.6796875,
      1.9765625,
      5.78125,
      -5.65625,
      1.4375,
      -1.7890625,
      -5.84375,
      3.21875,
      2.109375,
      -5.4375,
      -0.181640625,
      1.8125,
      -6.53125,
      0.6015625,
      3.3125,
      -0.921875,
      6.75,
      -0.89453125,
      -3.921875,
      3.34375,
      3.28125,
      -1.5703125,
      0.361328125,
      0.26953125,
      3.875,
      -2.1875,
      1.7109375,
      -0.8515625,
      -1.0703125,
      -6.96875,
      3.390625,
      1.0078125,
      -0.65234375,
      -0.1513671875,
      16.875,
      1.953125,
      -1.4140625,
      1.34375,
      -0.05029296875,
      0.419921875,
      5,
      2.671875,
      0.392578125,
      1.109375,
      3.078125,
      -2.78125,
      3.46875,
      0.70703125,
      1.2109375,
      4.84375,
      -5.59375,
      -1.5390625,
      -1.3203125,
      0.2734375,
      4.15625,
      4.59375,
      1.9921875,
      -2.71875,
      -0.57421875,
      1.6953125,
      2.03125,
      -1.9296875,
      3.078125,
      -0.5546875,
      -9.6875,
      3.59375,
      -2.21875,
      -5.0625,
      0.32421875,
      3.890625,
      -1.9453125,
      1.6484375,
      -0.4140625,
      1.9609375,
      3.46875,
      0.625,
      1.109375,
      7.625,
      1.3515625,
      2.546875,
      -2.390625,
      5.03125,
      2.65625,
      4.5625,
      0.3828125,
      -0.466796875,
      -0.72265625,
      -1.71875,
      2.171875,
      1.828125,
      3.34375,
      2.78125,
      7.15625,
      -3.359375,
      -0.46484375,
      3.546875,
      -2.59375,
      -6.1875,
      -2.265625,
      -2.84375,
      0.70703125,
      -3.9375,
      1.5234375,
      -2.921875,
      -2.765625,
      3.515625,
      1.953125,
      -0.1494140625,
      -2.28125,
      -1.8203125,
      -3.140625,
      0.048828125,
      -5.46875,
      0.349609375,
      1.734375,
      -3.609375,
      -3.546875,
      5.9375,
      4.15625,
      -0.09228515625,
      -0.072265625,
      -2.609375,
      -4.90625,
      3.921875,
      -3.046875,
      -3.5,
      6.25,
      4.15625,
      -3.3125,
      1.71875,
      3.0625,
      1.9453125,
      2.03125,
      1.46875,
      -3.90625,
      -4.21875,
      0.36328125,
      -0.416015625,
      5.4375,
      2.859375,
      -5.4375,
      0.8671875,
      -0.921875,
      -3.859375,
      -9.4375,
      4.65625,
      -5.84375,
      8.75,
      -0.27734375,
      -1.4453125,
      3.15625,
      -1.90625,
      9.875,
      3.375,
      1.953125,
      2.140625,
      -0.609375,
      -2.765625,
      1.171875,
      -3.78125,
      0.953125,
      -5.53125,
      -0.169921875,
      4.375,
      1.8671875,
      -1.015625,
      0.4140625,
      -0.92578125,
      4.03125,
      -0.341796875,
      -2.953125,
      0.98828125,
      4.625,
      -2.71875,
      2.25,
      5.25,
      -2.796875,
      3.90625,
      -5.3125,
      -3.546875,
      3.046875,
      -0.81640625,
      -1.734375,
      -7.71875,
      -4.8125,
      -2.25,
      -0.73828125,
      -2.421875,
      -2.859375,
      0.011962890625,
      1.6328125,
      5.3125,
      -0.69140625,
      2.359375,
      2.75,
      -7.90625,
      -8.75,
      6.03125,
      -2.609375,
      0.6875,
      3,
      -3.015625,
      5.6875,
      -1.953125,
      -2.078125,
      -0.091796875,
      -0.6875,
      -2.5625,
      1.84375,
      5.90625,
      -2.96875,
      0.9140625,
      -4.6875,
      5.09375,
      2.3125,
      -1.8046875,
      4.5625,
      7.03125,
      -4.53125,
      0.7734375,
      0.62890625,
      0.5390625,
      1.234375,
      -0.419921875,
      -1.90625,
      5.0625,
      1.2109375,
      1.9140625,
      -5.9375,
      -1.5625,
      1.4453125,
      -1.3359375,
      0.78125,
      0.1025390625,
      -4.34375,
      -0.70703125,
      0.62109375,
      1.375,
      0.162109375,
      0.7109375,
      -3.390625,
      -3.765625,
      0.42578125,
      -0.8359375,
      -0.59375,
      0.2734375,
      -0.37109375,
      5.96875,
      1.9375,
      -2.21875,
      4.5625,
      0.490234375,
      -4.125,
      -3.5625,
      0.75,
      -2.90625,
      0.46875,
      4.96875,
      0.703125,
      -3.734375,
      3.59375,
      -1.5,
      -3.203125,
      3.9375,
      1.578125,
      0.41796875,
      -2.25,
      -2.828125,
      0.337890625,
      1.1015625,
      -7.21875,
      1.78125,
      -0.9453125,
      -0.69140625,
      2.8125,
      1.125,
      -2.671875,
      1.109375,
      3.015625,
      -1.3203125,
      1.875,
      -4.21875,
      -1.109375,
      -3.46875,
      2.53125,
      3.609375,
      -3.203125,
      0.10205078125,
      0.7109375,
      2.703125,
      5.46875,
      1.7109375,
      -1.1171875,
      -0.208984375,
      -3.296875,
      -0.828125,
      0.8359375,
      -3.1875,
      -5.96875,
      2.53125,
      -4.96875,
      -5.0625,
      1.34375,
      2.828125,
      0.236328125,
      5.25,
      5.53125,
      -4.625,
      -3.25,
      3.890625,
      6.3125,
      -3.484375,
      -4.15625,
      1.140625,
      -0.5546875,
      0.83984375,
      0.78125,
      4.5625,
      -0.76171875,
      -3.84375,
      2.421875,
      2.3125,
      0.2734375,
      4.40625,
      0.314453125,
      -2.96875,
      2.078125,
      -2.46875,
      -3.25,
      -0.9375,
      3.828125,
      2.03125,
      -7.1875,
      -10.25,
      4.28125,
      1.234375,
      -0.89453125,
      -2.5,
      3.84375,
      2.453125,
      -0.10107421875,
      -0.140625,
      -3.265625,
      -1.7578125,
      -1.2734375,
      3.8125,
      1.1015625,
      0.10107421875,
      -2.328125,
      -5.1875,
      6.71875,
      3.03125,
      2.421875,
      1.1171875,
      -0.35546875,
      2.25,
      -3.0625,
      3.1875,
      4.3125,
      7.8125,
      -6.46875,
      -2.375,
      0.193359375,
      -7.4375,
      -1.21875,
      -2.609375,
      -0.75,
      -1.7578125,
      2.484375,
      6.625,
      -3.03125,
      -2.703125,
      -1.5546875,
      3.9375,
      -2.609375,
      -0.126953125,
      -0.578125,
      -3.296875,
      -0.921875,
      0.921875,
      2.0625,
      3.421875,
      -2.921875,
      -1.8046875,
      -0.62890625,
      -1,
      -0.3984375,
      -0.64453125,
      -0.4609375,
      1.15625,
      -2.6875,
      1.203125,
      4.0625,
      1.15625,
      3.578125,
      -1.1953125,
      -2.90625,
      -2.34375,
      -0.96875,
      -0.24609375,
      -0.46875,
      2.53125,
      0.984375,
      1.1953125,
      2.703125,
      -3.984375,
      -0.06298828125,
      0.2392578125,
      0.578125,
      -3.765625,
      2.171875,
      4.8125,
      4.59375,
      2.390625,
      1.7578125,
      -3.328125,
      0.126953125,
      0.8359375,
      -2.65625,
      -2.6875,
      -1.2734375,
      3.21875,
      -2.546875,
      -2.484375,
      -1.7109375,
      -0.30859375,
      0.2451171875,
      -1.25,
      -0.8984375,
      3.453125,
      3.75,
      1.5859375,
      0.09033203125,
      3.15625,
      5.53125,
      -1.390625,
      0.58203125,
      3.921875,
      3.140625,
      -4.71875,
      -5.3125,
      -3.875,
      1.234375,
      4.25,
      -6.25,
      1.9921875,
      0.03369140625,
      6.375,
      -1.84375,
      0.43359375,
      -14.5625,
      3.171875,
      0.2060546875,
      -5.15625,
      0.65625,
      -3.09375,
      0.7890625,
      -0.4375,
      0.66015625,
      1.625,
      -0.7109375,
      -1.5234375,
      4.34375,
      -1.0859375,
      -3.578125,
      5.46875,
      1.328125,
      -3.390625,
      1.6015625,
      -2.390625,
      -3.515625,
      0.462890625,
      -1.2734375,
      0.83203125,
      1.6171875,
      4.71875,
      0.1298828125,
      1.828125,
      0.10498046875,
      -4.3125,
      -1.484375,
      2.265625,
      3.46875,
      -0.275390625,
      1.6171875,
      -4.53125,
      3.015625,
      -2.265625,
      0.421875,
      2.484375,
      -2.875,
      2.28125,
      3.171875,
      -2.046875,
      -0.408203125,
      -2.984375,
      -0.275390625,
      5.5625,
      4.03125,
      -2.796875,
      1.1171875,
      0.228515625,
      0.26953125,
      6.28125,
      -2.65625,
      -1.8828125,
      -1.859375,
      2.765625,
      1.46875,
      -4.21875,
      4.96875,
      -1.5625,
      -2.125,
      0.00445556640625,
      -1.203125,
      0.9375,
      0.2353515625,
      1.1484375,
      4.53125,
      -2.828125,
      -1.2109375,
      1.3828125,
      -2.640625,
      -5.59375,
      -2.234375,
      0.10986328125,
      -4.09375,
      4.78125,
      -0.05224609375,
      -0.11279296875,
      0.09521484375,
      -2.8125,
      0.53125,
      2.015625,
      1.5703125,
      1.34375,
      4.25,
      2.46875,
      -2.171875,
      2.1875,
      -5.65625,
      -5.625,
      -0.396484375,
      -4.1875,
      -1.0703125,
      2.484375,
      2.578125,
      -0.62890625,
      0.7421875,
      -1.9453125,
      -4.71875,
      -5.09375,
      -3.09375,
      0.3984375,
      -0.5078125,
      2.890625,
      1.7578125,
      6.15625,
      -2.125,
      1,
      1.9296875,
      0.31640625,
      -0.8359375,
      -3.90625,
      0.8046875,
      -8.4375,
      1.65625,
      5,
      5.71875,
      -4.1875,
      8.25,
      2.5625,
      -0.5703125,
      -0.46484375,
      6.5625,
      -3.671875,
      -0.1669921875,
      0.083984375,
      -2.859375,
      -1.6328125,
      -3.671875,
      -0.427734375,
      -1.21875,
      4.1875,
      0.423828125,
      -2.015625,
      0.09716796875,
      -6.15625,
      -0.0986328125,
      -0.1650390625,
      -0.1787109375,
      2.828125,
      1.1640625,
      1.0390625,
      -0.76953125,
      2.78125,
      3.8125,
      0.859375,
      0.04248046875,
      -1.265625,
      2.21875,
      2.421875,
      2.9375,
      -1.421875,
      -6.125,
      0.5546875,
      -2.5,
      -1.1015625,
      1.2265625,
      -0.2021484375,
      0.2333984375,
      5.15625,
      1.6484375,
      -4.625,
      -2.75,
      2.734375,
      -4.03125,
      -0.1494140625,
      0.4375,
      3.484375,
      0.2421875,
      4.28125,
      -0.484375,
      -2.484375,
      -3.1875,
      8.1875,
      4.65625,
      -0.79296875,
      -0.82421875,
      4.3125,
      1.21875,
      0.80859375,
      -3.890625,
      -6.125,
      1.6171875,
      1.2265625,
      -2.03125,
      -0.44921875,
      8.1875,
      -4.375,
      0.75390625,
      -0.60546875,
      0.028076171875,
      0.53125,
      0.490234375,
      2.40625,
      -0.369140625,
      1.9609375,
      -0.76953125,
      1.1015625,
      1.1171875,
      -0.349609375,
      -1.046875,
      -1.0703125,
      -0.349609375,
      -3,
      2.921875,
      1.296875,
      -1.4453125,
      -0.9765625,
      1.1796875,
      0.54296875,
      4.1875,
      6.59375,
      2.109375,
      0.00482177734375,
      3.34375,
      6.6875,
      -1.890625,
      8.625,
      1.359375,
      9.375,
      -4.90625,
      -2.75,
      4.53125,
      2.53125,
      0.9453125,
      -0.8984375,
      -7.0625,
      -2.203125,
      -0.62890625,
      0.279296875,
      -4.125,
      0.0213623046875,
      -3.359375,
      -0.8828125,
      4.65625,
      1.8671875,
      3.109375,
      2.90625,
      3.5,
      -0.703125,
      -0.2490234375,
      -2.203125,
      -4.65625,
      -2.765625,
      1.25,
      1.9609375,
      -1.890625,
      2.53125,
      0.048828125,
      5.09375,
      1.8671875,
      0.1591796875,
      -2.53125,
      4.9375,
      -2.34375,
      -1.8984375,
      2.5,
      1.90625,
      1.234375,
      0.875,
      3.71875,
      -5.59375,
      -0.83203125,
      8.5,
      2.09375,
      -3.234375,
      2.703125,
      -1.6015625,
      3.921875,
      -6.78125,
      -2.15625,
      -0.2275390625,
      2.828125,
      -5.5625,
      -3.546875,
      -0.703125,
      1.9375,
      -5.15625,
      0.421875,
      4.71875,
      -3.796875,
      1.109375,
      -1.328125,
      -3.484375,
      1.0625,
      1.4765625,
      4.4375,
      0.0162353515625,
      -3.0625,
      -3.21875,
      -3.609375,
      -2.015625,
      0.26953125,
      -0.80078125,
      1.6484375,
      1.9609375,
      -2.828125,
      0.1748046875,
      -6.1875,
      1.3984375,
      -5.28125,
      3.953125,
      3.953125,
      -3.59375,
      -4.34375,
      -2.078125,
      -6.15625,
      -3.421875,
      -2.53125,
      -3.96875,
      -2.46875,
      -5.6875,
      -0.91015625,
      1.515625,
      -7.21875,
      -0.09033203125,
      -2.15625,
      -0.11767578125,
      2.5,
      0.013427734375,
      1.2265625,
      -6.59375,
      2.140625,
      -0.9765625,
      0.353515625,
      0.6171875,
      1.65625,
      2.859375,
      3.953125,
      1.7734375,
      1.2265625,
      -3.296875,
      5.46875,
      -1.703125,
      7.28125,
      5.375,
      1.9765625,
      -5.03125,
      3.359375,
      -1.0859375,
      0.2333984375,
      -7.25,
      2.734375,
      1.0625,
      0.75390625,
      0.5625,
      1.078125,
      4.71875,
      -2.796875,
      -4.84375,
      2.765625,
      -3.484375,
      -0.0888671875,
      1.2734375,
      0.72265625,
      4.34375,
      -0.314453125,
      0.44921875,
      1.3515625,
      1.875,
      0.53125,
      -0.8515625,
      3.25,
      -4.65625,
      -0.419921875,
      -1.03125,
      0.67578125,
      -0.008056640625,
      -3.171875,
      -0.021240234375,
      -0.1884765625,
      1.1171875,
      2.140625,
      4.40625,
      3.625,
      2.125,
      4.15625,
      0.275390625,
      -0.859375,
      -1.2578125,
      -2.640625,
      0.7421875,
      1.4453125,
      2.765625,
      -2.796875,
      0.341796875,
      -2.0625,
      0.5390625,
      1.7890625,
      -3.171875,
      -0.30078125,
      -3.96875,
      -4.78125,
      2.109375,
      0.625,
      0.314453125,
      0.173828125,
      2.65625,
      1.9375,
      2.34375,
      -0.25,
      3.109375,
      0.2451171875,
      -4.34375,
      3.125,
      -2.234375,
      -4.53125,
      2.40625,
      1.390625,
      4.5625,
      1.0859375,
      1.4921875,
      -3.359375,
      -0.5859375,
      3.875,
      -3.828125,
      0.79296875,
      5.6875,
      -1.8671875,
      -0.8125,
      -0.1923828125,
      1.03125,
      2.109375,
      -2.078125,
      3.765625,
      4.125,
      4.28125,
      1.5390625,
      -0.3828125,
      -3.484375,
      -1.7890625,
      -0.5546875,
      -0.2001953125,
      -0.90234375,
      0.62109375,
      1.4140625,
      -0.345703125,
      -0.37890625,
      -3.34375,
      0.66796875,
      -3.734375,
      3.03125,
      3.671875,
      -1.8984375,
      -0.62109375,
      -1.1171875,
      -2.3125,
      -0.77734375,
      2.359375,
      2.09375,
      -1.609375,
      2.671875,
      2.90625,
      -1.6015625,
      0.453125,
      1.1796875,
      0.5390625,
      2.828125,
      -0.8515625,
      2.625,
      0.0830078125,
      -2.578125,
      -1.671875,
      -2.28125,
      0.828125,
      3.0625,
      4.5,
      -0.255859375,
      2.921875,
      -0.65625,
      -3.203125,
      2.859375,
      -3.21875,
      -2.265625,
      -0.9140625,
      -2.875,
      -0.240234375,
      -3.34375,
      -0.00408935546875,
      -2.8125,
      4.5625,
      -9.1875,
      5.28125,
      -3.5625,
      5.46875,
      2.5,
      0.1904296875,
      -0.15625,
      -4.53125,
      3.75,
      -3.390625,
      -1.265625,
      3.765625,
      -1.34375,
      3.875,
      -1.453125,
      -1.453125,
      -0.50390625,
      -2.828125,
      -0.193359375,
      -2.171875,
      -0.3671875,
      -2.078125,
      2.359375,
      -9.1875,
      -3.375,
      0.09375,
      2.21875,
      1.390625,
      -1.0234375,
      0.69921875,
      -2.28125,
      2.328125,
      -1.484375,
      2.25,
      -2.53125,
      -3.4375,
      2.15625,
      -1.8359375,
      2.890625,
      1.09375,
      -0.474609375,
      -2.53125,
      -1.8359375,
      -4.5625,
      -2.296875,
      -1.671875,
      2.453125,
      -4.03125,
      -1.109375,
      -0.21484375,
      2.5625,
      1.328125,
      -1.6640625,
      -2.171875,
      1.703125,
      6.34375,
      0.8671875,
      -0.6328125,
      -1.84375,
      0.98046875,
      -3.921875,
      -3.6875,
      -2.875,
      2.1875,
      2.0625,
      -4.375,
      2.46875,
      0.083984375,
      2.640625,
      3.46875,
      -0.0191650390625,
      -1.21875,
      1.6171875,
      1.8359375,
      0.63671875,
      0.8671875,
      3.140625,
      0.326171875,
      3.046875,
      -3.59375,
      -3,
      -2.5,
      1.3828125,
      -1.359375,
      -1.34375,
      -0.052978515625,
      0.00665283203125,
      -1.3671875,
      -1.8671875,
      -3.03125,
      -0.91015625,
      4.75,
      0.498046875,
      6.5,
      1.7578125,
      -1.8984375,
      0.97265625,
      0.1064453125,
      4.4375,
      3.421875,
      0.92578125,
      0.5546875,
      1.140625,
      -2.21875,
      5.46875,
      -3.625,
      -5.3125,
      -4.75,
      -0.59765625,
      6.40625,
      0.66796875,
      -1.0625,
      1.5390625,
      -0.10888671875,
      1.5703125,
      2.71875,
      4.90625,
      -0.6484375,
      -1.984375,
      -1.640625,
      3.0625,
      -1.8984375,
      -4.96875,
      2.515625,
      3.34375,
      -1.3671875,
      1.046875,
      2.171875,
      4.8125,
      -4.375,
      0.21484375,
      -1.5859375,
      -3.328125,
      -3.15625,
      3.953125,
      0.2099609375,
      -1.8984375,
      1.921875,
      -3.5625,
      -0.6171875,
      0.58984375,
      0.236328125,
      4.09375,
      -2.453125,
      1.890625,
      0.1455078125,
      3.9375,
      -0.87890625,
      -1.9921875,
      -1.1875,
      1.5859375,
      0.52734375,
      -1.4375,
      -1.046875,
      -3.765625,
      -2.625,
      -1.390625,
      -9.75,
      1.6015625,
      3.484375,
      1.0078125,
      1.140625,
      -2.671875,
      2.578125,
      3.015625,
      -3.5625,
      -5.1875,
      -2.109375,
      2.03125,
      2.5625,
      0.283203125,
      -4.1875,
      3.859375,
      0.126953125,
      0.578125,
      -5.75,
      4.875,
      -3.046875,
      4.1875,
      2.65625,
      4.46875,
      -5.5625,
      -0.65234375,
      -1.0703125,
      -0.189453125,
      -3.703125,
      -0.95703125,
      -2.140625,
      0.72265625,
      4.1875,
      0.1982421875,
      -3.5,
      -1.6328125,
      -2.671875,
      2.84375,
      0.033935546875,
      0.228515625,
      -3.71875,
      2.265625,
      -6.34375,
      -1.109375,
      3.8125,
      -1.21875,
      -2.25,
      1.2578125,
      3.0625,
      8.125,
      2.046875,
      1.03125,
      -4.03125,
      1.5078125,
      -1.09375,
      -3.625,
      -5.0625,
      1.4375,
      -0.65234375,
      -1.25,
      2.125,
      -4.4375,
      2.328125,
      -2.953125,
      0.5546875,
      -2.46875,
      0.39453125,
      0.166015625,
      2.3125,
      1.625,
      0.86328125,
      2.453125,
      -0.224609375,
      4.1875,
      2.359375,
      0.123046875,
      1.15625,
      -0.35546875,
      0.1015625,
      -5.21875,
      2.546875,
      -1.2890625,
      -1.28125,
      4.53125,
      4.59375,
      -5.75,
      0.26171875,
      -0.859375,
      3.140625,
      -1.953125,
      -3.5,
      -1.671875,
      3.578125,
      -0.546875,
      -0.7265625,
      -2.265625,
      -0.578125,
      1.953125,
      -2.8125,
      1.15625,
      -1.28125,
      3.953125,
      -4.5625,
      -2.328125,
      5.28125,
      0.265625,
      3.6875,
      -3.6875,
      3.140625,
      3.46875,
      1.0625,
      1.6015625,
      0.62890625,
      -0.359375,
      -2.828125,
      1.1875,
      -5.78125,
      2.421875,
      -7.125,
      -0.5234375,
      -1.171875,
      -1.7421875,
      -2.25,
      4.6875,
      3.1875,
      0.10595703125,
      -1.0078125,
      -1.3203125,
      -7.21875,
      -2.515625,
      -1.0546875,
      -1.5078125,
      -4.28125,
      1.7109375,
      -2.265625,
      1.2109375,
      2.28125,
      3.65625,
      -0.6328125,
      -2.59375,
      3.71875,
      -2.6875,
      2.0625,
      -2.234375,
      0.2890625,
      0.3671875,
      -3.359375,
      1.3671875,
      1.421875,
      5.375,
      -4.125,
      0.3828125,
      -3.59375,
      -1.625,
      -0.466796875,
      1.2890625,
      -0.126953125,
      1.546875,
      3.109375,
      -0.83203125,
      2.984375,
      4.3125,
      -2.28125,
      -2.40625,
      3.78125,
      0.51171875,
      4.28125,
      1.4453125,
      0.78515625,
      -2.15625,
      3.828125,
      1.328125,
      -3.28125,
      4.125,
      1.1875,
      0.2451171875,
      -4.65625,
      2.40625,
      3.3125,
      4.15625,
      0.201171875,
      3.578125,
      3,
      1.2734375,
      4.84375,
      6.96875,
      -0.33203125,
      -0.427734375,
      0.271484375,
      -0.171875,
      1.0390625,
      -2.171875,
      2.609375,
      -0.17578125,
      -2.1875,
      3.421875,
      -0.53125,
      3.796875,
      0.92578125,
      -0.287109375,
      0.921875,
      5,
      -3.0625,
      1.859375,
      -5.875,
      0.41796875,
      -3.609375,
      1.765625,
      -5.71875,
      -2.1875,
      2.03125,
      5.875,
      -1.359375,
      -3.703125,
      6.46875,
      4.09375,
      0.52734375,
      -2.875,
      4.4375,
      0.73046875,
      -1.15625,
      -5.96875,
      -3.328125,
      6.46875,
      2.765625,
      0.08447265625,
      -3.078125,
      1.6484375,
      2.96875,
      -1.3515625,
      -7.3125,
      1.5625,
      0.08349609375,
      -4.125,
      -4.96875,
      -1.265625,
      1.5625,
      -4.8125,
      1.3515625,
      0.423828125,
      -2.390625,
      4.0625,
      -0.5,
      2.984375,
      2.1875,
      -1.28125,
      3.140625,
      -0.435546875,
      -0.5390625,
      -1.15625,
      4.28125,
      -2.515625,
      3.890625,
      -1.5703125,
      -1.1171875,
      -1.6171875,
      -0.68359375,
      -0.703125,
      -3.40625,
      -0.99609375,
      2.640625,
      3.671875,
      -1.15625,
      -3.265625,
      1.1328125,
      0.8984375,
      -2.40625,
      -1.15625,
      1.71875,
      -1,
      -0.71484375,
      0.34375,
      -1.2109375,
      1.84375,
      -2.359375,
      0.61328125,
      0.123046875,
      -1.765625,
      -1.8671875,
      -2.78125,
      -2.859375,
      2.78125,
      -2.015625,
      1.109375,
      0.267578125,
      -1.71875,
      -1.765625,
      4.34375,
      -0.1865234375,
      2.125,
      -2.96875,
      1.015625,
      2.671875,
      1.609375,
      -0.447265625,
      -4.125,
      -1.828125,
      1.5,
      -1.421875,
      -1.09375,
      -0.5,
      -1.75,
      3.421875,
      -4.84375,
      -1.4375,
      -0.3046875,
      0.765625,
      -1.0859375,
      -10.9375,
      1.9296875,
      0.46484375,
      -2.234375,
      0.51953125,
      -0.79296875,
      0.5625,
      3.765625,
      1.859375,
      2.640625,
      -1.1328125,
      -5.40625,
      0.54296875,
      19.125,
      -3.484375,
      -2.859375,
      0.412109375,
      -0.12890625,
      -0.45703125,
      5.96875,
      0.169921875,
      0.029052734375,
      -0.73046875,
      0.89453125,
      3.484375,
      4.34375,
      0.546875,
      0.259765625,
      -0.05224609375,
      4.34375,
      -2.828125,
      -1.6953125,
      -2.5625,
      -4.53125,
      0.953125,
      -4.4375,
      3.078125,
      -2.421875,
      0.8203125,
      1.453125,
      -4.34375,
      -2.8125,
      -4.125,
      -0.9296875,
      -1.1328125,
      -5.09375,
      3.21875,
      0.609375,
      -3.71875,
      -1.6796875,
      2.109375,
      -0.162109375,
      -2.25,
      -5,
      -2.5625,
      2.171875,
      -1.9921875,
      -1.28125,
      -0.181640625,
      -3.421875,
      -1.765625,
      -1.359375,
      3.53125,
      -2.15625,
      -1.3828125,
      -3.984375,
      2.6875,
      3.0625,
      -2.65625,
      1.6171875,
      -4,
      -2.25,
      -4.71875,
      -0.330078125,
      -0.2109375,
      -3.90625,
      -2.609375,
      -2.515625,
      -3.53125,
      1.3359375,
      0.7109375,
      2.078125,
      2.671875,
      -5.65625,
      -4.21875,
      2.78125,
      1.65625,
      -0.1474609375,
      -2,
      0.89453125,
      0.640625,
      1.8203125,
      2.15625,
      -2.875,
      0.8125,
      -3.171875,
      -1.0546875,
      -1.21875,
      0.703125,
      -3.703125,
      2.984375,
      1.421875,
      -0.91015625,
      6.875,
      -4.09375,
      1.1796875,
      1.0703125,
      -3.890625,
      -1.6875,
      0.095703125,
      1.859375,
      -2.78125,
      -0.0908203125,
      4.65625,
      -2.515625,
      0.052001953125,
      -0.455078125,
      2.359375,
      -0.5625,
      1.5546875,
      -2.28125,
      3.84375,
      -0.31640625,
      -0.91015625,
      3.328125,
      1.234375,
      -1.2265625,
      -1.4921875,
      3.734375,
      -2.78125,
      -1.46875,
      -2.671875,
      -2.453125,
      1.3671875,
      0.56640625,
      -2.4375,
      0.09423828125,
      -7.71875,
      -5.53125,
      -2.796875,
      -3.359375,
      2.1875,
      -2.25,
      1.09375,
      -0.0306396484375,
      -3.921875,
      -1.0390625,
      1.0703125,
      -1.859375,
      3.265625,
      4.28125,
      1.7421875,
      0.365234375,
      -1.1015625,
      -0.1484375,
      2.328125,
      -0.828125,
      -1.03125,
      0.9765625,
      -3.4375,
      0.359375,
      2.375,
      1.9453125,
      -4,
      3.484375,
      -0.451171875,
      -2.140625,
      -1.859375,
      1.7734375,
      0.0673828125,
      -3.234375,
      -1.0390625,
      1.4609375,
      -2.265625,
      -1.6796875,
      -0.9765625,
      -7.9375,
      0.25390625,
      1.3828125,
      2.9375,
      1.21875,
      -2.796875,
      2.59375,
      2.65625,
      -6.59375,
      1.640625,
      -3.5625,
      3.546875,
      -4.46875,
      3.203125,
      2.9375,
      -0.640625,
      2.96875,
      3.140625,
      1.8046875,
      -0.6796875,
      -1.421875,
      0.984375,
      0.94140625,
      -2.53125,
      5.5625,
      3.328125,
      -0.37109375,
      -1.7109375,
      -4.53125,
      -3.015625,
      4.5625,
      5.84375,
      -4.625,
      0.9609375,
      -0.703125,
      -1.8671875,
      -1.421875,
      -1.7890625,
      1.2890625,
      0.734375,
      0.5625,
      6.03125,
      1.3203125,
      -1.3203125,
      -0.71875,
      -3.703125,
      -1.734375,
      -2.9375,
      3.171875,
      2.921875,
      2.4375,
      -4.90625,
      7.15625,
      4.03125,
      -1.21875,
      -1.0078125,
      -0.11328125,
      3.3125,
      -2.609375,
      -4.28125,
      0.55078125,
      1.484375,
      3.609375,
      -7.71875,
      5.09375,
      -1.84375,
      4.46875,
      -1.4453125,
      3.609375,
      -0.318359375,
      0.66015625,
      -4,
      -3.265625,
      -4.53125,
      0.447265625,
      -2.140625,
      0.2158203125,
      2.671875,
      -3.140625,
      1.109375,
      -2.328125,
      -2.5,
      2.359375,
      0.42578125,
      -1.3671875,
      1.625,
      -0.08154296875,
      1.6953125,
      -1.4140625,
      5.34375,
      -0.98828125,
      0.0014190673828125,
      -1.3828125,
      -1.8203125,
      -0.44921875,
      -3.375,
      2.84375,
      -0.02294921875,
      -4.40625,
      5.5625,
      0.7890625,
      -0.6015625,
      2.34375,
      -1.453125,
      -5.0625,
      6.28125,
      3.921875,
      -6.65625,
      1.5390625,
      -0.51953125,
      -4.125,
      -1.1328125,
      0.314453125,
      2.71875,
      -5,
      0.625,
      2.546875,
      -4.5,
      1.90625,
      1.421875,
      -1.3515625,
      0.400390625,
      -2.875,
      4,
      0.67578125,
      0.62109375,
      2.921875,
      1.5625,
      4.53125,
      -3.0625,
      -1.265625,
      -3.296875,
      5.25,
      -1.453125,
      0.23828125,
      0.90234375,
      -0.8359375,
      3.171875,
      3.140625,
      -0.6015625,
      -5.6875,
      -2.609375,
      1.46875,
      -0.35546875,
      3.09375,
      1.90625,
      0.146484375,
      -2.640625,
      0.0189208984375,
      2.890625,
      2.015625,
      0.7421875,
      -1.078125,
      -4.09375,
      2.09375,
      -0.251953125,
      -7.125,
      -1.2578125,
      0.396484375,
      -0.51171875,
      1.2578125,
      -1,
      -1.6640625,
      2.375,
      3.140625,
      -4.125,
      1.890625,
      0.447265625,
      1.8046875,
      -0.06884765625,
      -0.494140625,
      1.1640625,
      1.8828125,
      -2.6875,
      -7.65625,
      2.921875,
      -0.47265625,
      -0.890625,
      3.046875,
      -0.6015625,
      2.96875,
      2.546875,
      2.578125,
      -4.40625,
      6.78125,
      1.96875,
      -7.3125,
      3.375,
      -5.375,
      1.2578125,
      -3.84375,
      -5.46875,
      -1.3203125,
      4.90625,
      -2.484375,
      0.6796875,
      1.2421875,
      -0.10302734375,
      -1.1484375,
      4.09375,
      0.8046875,
      -4.375,
      0.75390625,
      2.53125,
      -4.96875,
      -0.140625,
      2.078125,
      -0.5078125,
      -1.3046875,
      -0.2412109375,
      0.228515625,
      0.349609375,
      -0.953125,
      3.484375,
      1.2109375,
      -0.88671875,
      -1.53125,
      -1.1171875,
      1.6640625,
      -0.74609375,
      -3.34375,
      0.166015625,
      -0.89453125,
      2.015625,
      -2.359375,
      0.39453125,
      -1.046875,
      -3.65625,
      -1.8984375,
      -5.53125,
      -0.55859375,
      1.953125,
      1.4765625,
      1.9140625,
      -2.375,
      -0.91015625,
      2.6875,
      3.640625,
      1.0859375,
      -3.609375,
      0.04052734375,
      -3.71875,
      -1.6328125,
      1.015625,
      2.421875,
      -1.90625,
      -0.93359375,
      2.03125,
      0.2578125,
      -3.03125,
      -4.625,
      -0.64453125,
      0.283203125,
      2.640625,
      1.625,
      -1.609375,
      -2.5,
      3.03125,
      1.609375,
      -5.375,
      -0.88671875,
      2.390625,
      -1.4765625,
      -3.546875,
      -3.234375,
      3.71875,
      -5.9375,
      0.263671875,
      3.84375,
      1.703125,
      1.875,
      1.703125,
      -7.1875,
      -1.4140625,
      3.78125,
      3.671875,
      2.515625,
      1.2734375,
      -1.546875,
      -4.71875,
      5.25,
      4.71875,
      -1.6796875,
      -2.578125,
      -1.421875,
      -0.515625,
      -1.359375,
      -2.5625,
      2.484375,
      -0.08056640625,
      -6.1875,
      7.53125,
      -2.109375,
      4.625,
      1.8984375,
      -2.140625,
      2.578125,
      -0.92578125,
      2.109375,
      -0.6484375,
      2.21875,
      3.46875,
      -3.75,
      -3,
      -2.296875,
      -0.4453125,
      -1.2578125,
      -0.2060546875,
      -1.2421875,
      1.3046875,
      3.984375,
      0.2001953125,
      -1.4921875,
      -0.1865234375,
      -0.8046875,
      3.921875,
      -3.140625,
      -1.21875,
      0.12109375,
      -2.375,
      0.3046875,
      -1.8046875,
      1.8203125,
      -4.25,
      0.333984375,
      0.08251953125,
      1.8828125,
      0.61328125,
      3.03125,
      -0.107421875,
      -1.3046875,
      -2.0625,
      4.5625,
      0.54296875,
      2.625,
      3.859375,
      3.6875,
      1.4609375,
      -1.6640625,
      2.96875,
      6.25,
      4.8125,
      -5.71875,
      -1.5,
      -0.443359375,
      -0.9375,
      -1.1015625,
      0.1484375,
      0.57421875,
      1.8359375,
      3.171875,
      0.412109375,
      1.7734375,
      -1.8828125,
      -2.109375,
      -0.7109375,
      -0.1279296875,
      3.25,
      2.1875,
      -3.046875,
      0.10986328125,
      -1.7421875,
      1.6640625,
      1.3359375,
      2.640625,
      1.40625,
      -0.2578125,
      -2.6875,
      0.169921875,
      -3.25,
      -0.83203125,
      1.34375,
      -2.109375,
      0.48046875,
      -1.2578125,
      -1.46875,
      1.3828125,
      0.97265625,
      -3.03125,
      2.96875,
      2.296875,
      -2.140625,
      2.390625,
      -0.73046875,
      -2.265625,
      -0.408203125,
      0.68359375,
      2.703125,
      -1.390625,
      -3.28125,
      0.79296875,
      3.234375,
      -2.015625,
      -0.392578125,
      -1.09375,
      1.171875,
      -1.609375,
      -0.37890625,
      0.09423828125,
      -0.96484375,
      3.640625,
      -0.5703125,
      -0.69921875,
      3.03125,
      -0.828125,
      -0.0458984375,
      1.8046875,
      -1.9296875,
      -1.7734375,
      -2.75,
      2.953125,
      2.546875,
      0.03125,
      1.6875,
      1.9609375,
      1.328125,
      -0.5546875,
      -1.8046875,
      -3.21875,
      0.05029296875,
      -2.140625,
      -0.18359375,
      0.8203125,
      -0.1865234375,
      -2.484375,
      4,
      0.796875,
      2.328125,
      -3.640625,
      -0.76953125,
      -2.1875,
      -1.6796875,
      -0.259765625,
      -2.5625,
      2.265625,
      1.7734375,
      1.3046875,
      -0.095703125,
      -0.62109375,
      0.28125,
      -0.875,
      -2.171875,
      4.71875,
      2.25,
      -2.625,
      0.373046875,
      -1.6171875,
      1.0625,
      2.28125,
      -0.65234375,
      -2.765625,
      1.4765625,
      1.0703125,
      3.078125,
      2.953125,
      -1.2890625,
      2.390625,
      2.375,
      -3.09375,
      0.026611328125,
      -2.734375,
      2.203125,
      -0.333984375,
      -1.203125,
      -0.1748046875,
      1.0546875,
      -4.53125,
      -0.703125,
      0.7109375,
      2,
      -0.60546875,
      0.36328125,
      1.53125,
      1.3828125,
      -1.859375,
      3,
      4.25,
      1.703125,
      -2.234375,
      -3.8125,
      0.474609375,
      0.8125,
      -1.59375,
      -1.078125,
      -0.79296875,
      -0.38671875,
      -1.40625,
      0.2412109375,
      -0.416015625,
      -2.234375,
      1.7265625,
      0.7265625,
      -0.515625,
      -2.25,
      1.0078125,
      -1.3125,
      0.96875,
      -0.66015625,
      1.4296875,
      -0.87109375,
      -5.28125,
      0.9140625,
      1.1640625,
      -0.1796875,
      -4.5,
      -1.8359375,
      -2.5625,
      1.609375,
      -0.546875,
      -0.177734375,
      1.7265625,
      -2.4375,
      0.671875,
      -2.140625,
      -1.390625,
      0.8828125,
      0.353515625,
      1.3125,
      -0.01251220703125,
      -1.5390625,
      3.796875,
      1.25,
      -1.875,
      2.265625,
      -0.6015625,
      1.9921875,
      -0.357421875,
      -0.7578125,
      0.462890625,
      -1.875,
      1.515625,
      0.1494140625,
      -0.28515625,
      3.109375,
      -0.4140625,
      0.96875,
      -0.65625,
      -0.65625,
      4.59375,
      3.65625,
      -0.279296875,
      0.53125,
      0.07958984375,
      1.03125,
      -0.85546875,
      -1.5,
      0.69921875,
      -3.21875,
      3.671875,
      -0.185546875,
      -2.515625,
      0.9140625,
      -2.546875,
      0.94921875,
      2.6875,
      3.25,
      -2.5,
      2.765625,
      0.2353515625,
      -0.0927734375,
      -0.43359375,
      -1.78125,
      -0.62890625,
      -0.318359375,
      -3.265625,
      2.28125,
      0.7265625,
      -0.1748046875,
      -2.578125,
      -0.03271484375,
      -2.765625,
      -2.453125,
      -0.35546875,
      0.01531982421875,
      -1.15625,
      2.765625,
      2.703125,
      0.6796875,
      -0.74609375,
      -1.3046875,
      0.5625,
      0.130859375,
      2.4375,
      -0.236328125,
      2.9375,
      2.984375,
      0.2255859375,
      -0.31640625,
      -0.7890625,
      -1.1796875,
      1.21875,
      0.392578125,
      -1.34375,
      1.3515625,
      3.140625,
      2.59375,
      -1.1953125,
      0.8828125,
      -0.193359375,
      6.09375,
      0.67578125,
      -1.296875,
      1.0703125,
      -1.390625,
      1.96875,
      -2.515625,
      1.9140625,
      0.1396484375,
      0.66796875,
      -2.453125,
      0.11181640625,
      1.7890625,
      -1.2109375,
      -3.28125,
      1.5078125,
      -2.703125,
      -0.279296875,
      3.140625,
      -1.265625,
      0.609375,
      0.0322265625,
      1.125,
      1.046875,
      5.125,
      -0.0322265625,
      0.41015625,
      1.90625,
      2.828125,
      3.484375,
      0.58203125,
      -1.421875,
      -0.27734375,
      1.1640625,
      1.3125,
      -0.32421875,
      1.15625,
      -0.423828125,
      2.625,
      -2.046875,
      -0.71484375,
      -3.109375,
      -0.83203125,
      0.212890625,
      0.2890625,
      4.59375,
      -3.8125,
      -1.9921875,
      3.75,
      0.423828125,
      0.341796875,
      1.5859375,
      3.625,
      0.81640625,
      3.109375,
      1.8125,
      -1.234375,
      -0.08154296875,
      2.515625,
      0.27734375,
      2.375,
      1.53125,
      -1.1171875,
      -2.078125,
      -0.6875,
      -2.078125,
      2.75,
      -1.359375,
      -0.90234375,
      2.828125,
      -0.2080078125,
      4.1875,
      2.328125,
      1.6953125,
      4.875,
      3.046875,
      -0.73046875,
      -1.46875,
      1.40625,
      -1.578125,
      0.7109375,
      1.90625,
      -1.2109375,
      2.578125,
      -1.2734375,
      -1.46875,
      -1.546875,
      -1.1875,
      -2.96875,
      -2.703125,
      -1.8046875,
      0.1357421875,
      -1.421875,
      3.875,
      -3.578125,
      2.484375,
      1.8671875,
      2.328125,
      2.046875,
      2,
      0.9296875,
      1.40625,
      -1.5,
      -3.515625,
      1.0546875,
      -1.6484375,
      -3.703125,
      -0.1455078125,
      0.3828125,
      -2.21875,
      1.734375,
      -2.21875,
      0.314453125,
      -1.1015625,
      -0.7734375,
      -3.140625,
      1.4375,
      2.21875,
      -1.375,
      0.70703125,
      -2.640625,
      0.1357421875,
      -1.515625,
      0.6796875,
      1.3046875,
      -5.34375,
      -2.96875,
      -0.337890625,
      -1.1953125,
      -1.9140625,
      -2.296875,
      -1.9296875,
      -0.60546875,
      0.1591796875,
      4.75,
      1.53125,
      -0.515625,
      -1.53125,
      4.40625,
      -1.4921875,
      0.9296875,
      -1.2265625,
      -1.953125,
      2.0625,
      2.453125,
      3.75,
      3.546875,
      -1,
      -0.98046875,
      -2.515625,
      2.265625,
      0.173828125,
      -4.46875,
      -0.77734375,
      -0.1796875,
      -1.5390625,
      -0.94140625,
      -1.828125,
      0.171875,
      -1.4921875,
      -1.515625,
      0.3828125,
      -3.59375,
      0.6484375,
      3.578125,
      -0.58203125,
      -1.515625,
      -2.46875,
      1.8984375,
      -2.390625,
      0.546875,
      -1.90625,
      -1.8828125,
      2.21875,
      1.2734375,
      -0.37109375,
      6.03125,
      -2.234375,
      -2.421875,
      2.125,
      1.0390625,
      3.234375,
      -2.765625,
      1.421875,
      0.625,
      -2.609375,
      1.296875,
      -3.140625,
      -4.625,
      -3.1875,
      -3.546875,
      -2.28125,
      -2.078125,
      2.46875,
      2.390625,
      -1.3203125,
      -1.3515625,
      0.8671875,
      1,
      2.34375,
      1.765625,
      -2.4375,
      -0.0439453125,
      -4.125,
      -1.921875,
      0.98828125,
      2.6875,
      -0.78125,
      1.9765625,
      2.53125,
      0.73828125,
      -1.9921875,
      0.765625,
      0.90234375,
      0.546875,
      0.9609375,
      0.859375,
      -3.125,
      -2.484375,
      2.296875,
      -2.484375,
      2.578125,
      0.486328125,
      -0.6015625,
      0.88671875,
      -1.03125,
      -2.328125,
      -1.1328125,
      0.314453125,
      0.86328125,
      -2.046875,
      -3.5625,
      1.5234375,
      0.40234375,
      -1.9375,
      0.44140625,
      1.78125,
      1.890625,
      -1.609375,
      -2.625,
      0.373046875,
      -2.796875,
      -4.0625,
      -1.3671875,
      0.5703125,
      3.53125,
      1.1015625,
      -3.0625,
      5.9375,
      0.490234375
    ],
    "suggested_tags": [
      "教育AI",
      "生成式AI",
      "个性化学习",
      "随机对照试验",
      "AI教学助手"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.95,
        "reason": "论文核心研究领域为人工智能在教育领域的应用，特别是AI辅助教学系统在数学课堂中的实际效果评估"
      },
      {
        "name": "生成式AI",
        "confidence": 0.9,
        "reason": "研究基于LearnLM这一经过教学优化的生成式AI模型，重点评估其在教学对话中的生成能力"
      },
      {
        "name": "个性化学习",
        "confidence": 0.85,
        "reason": "论文旨在解决一对一教学的规模化问题，探索AI如何实现个性化教学支持"
      },
      {
        "name": "随机对照试验",
        "confidence": 0.8,
        "reason": "采用严谨的RCT方法在真实课堂环境中评估AI教学效果，这是教育技术研究的重要方法"
      },
      {
        "name": "AI教学助手",
        "confidence": 0.75,
        "reason": "具体应用场景为AI辅助的在线教学对话系统，重点研究人机协作的教学模式"
      }
    ],
    "analysis": {
      "paper_id": "02197db0-3de5-4390-9690-609c0f31a4c1",
      "status": "completed",
      "started_at": null,
      "completed_at": "2025-12-16T02:26:53.409169",
      "summary": "本研究旨在探讨生成式AI能否在保证安全性的前提下，有效扩展个性化辅导的覆盖范围，以解决一对一人工辅导成本高昂、难以规模化的问题。研究团队在英国五所中学开展了探索性随机对照试验，共有165名学生参与。试验将专为教学应用优化的生成式AI模型LearnLM集成至Eedi数学平台的在线聊天辅导系统中，并由17名专家教师进行实时监督，对AI生成的每条信息进行审核、编辑或重写后方发送给学生。\n\n研究发现，LearnLM表现出较高的教学可靠性，监督教师对其76.4%的生成内容直接认可或仅作微调。在多项学习成果指标上，接受LearnLM辅导的学生表现均不逊于纯人工辅导组，尤其在知识迁移能力上表现更优：AI辅导组学生在后续新题型上的解题正确率达到66.2%，较人工辅导组（60.7%）显著提升5.5个百分点。教师访谈进一步揭示，LearnLM擅长设计启发式提问以促进学生深度思考，部分教师反馈其教学策略亦受AI启发。\n\n研究表明，经过教学优化的AI辅导系统在人工监督下，能够安全、有效地提供规模化个性化学习支持，为突破优质教育资源的可及性瓶颈提供了可行路径。",
      "methods": [
        {
          "name": "随机对照试验（RCT）",
          "description": "本研究采用随机对照试验设计，将165名学生随机分配到不同干预组。通过比较静态提示与互动辅导，以及人类辅导与AI辅导的效果，评估LearnLM的教学效能。",
          "location": null
        },
        {
          "name": "专家监督的AI辅导",
          "description": "人类专家导师直接监督LearnLM生成的所有消息，保留编辑、重写或批准的最终控制权。这种方法确保AI辅导的安全性和教学质量，导师对76.4%的AI生成消息无需或仅需最小修改。",
          "location": null
        },
        {
          "name": "学习成果测量",
          "description": "通过测量多项学习成果评估辅导效果，包括知识迁移能力。具体比较学生在后续主题中解决新问题的成功率，量化AI辅导与人类辅导的差异。",
          "location": null
        },
        {
          "name": "访谈与调查",
          "description": "对监督导师进行访谈和调查，收集他们对LearnLM教学能力的定性反馈。导师报告AI在生成苏格拉底式问题方面的优势，并分享其教学实践的新见解。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "1. Introduction",
            "level": 1,
            "start_line": 9
          },
          {
            "title": "2. An Exploratory Classroom Trial",
            "level": 1,
            "start_line": 32
          },
          {
            "title": "3. Results",
            "level": 1,
            "start_line": 47
          },
          {
            "title": "4. Discussion",
            "level": 1,
            "start_line": 91
          },
          {
            "title": "5. Methods",
            "level": 1,
            "start_line": 113
          },
          {
            "title": "References",
            "level": 1,
            "start_line": 143
          },
          {
            "title": "Contributions and Acknowledgments",
            "level": 1,
            "start_line": 191
          },
          {
            "title": "Core Contributors",
            "level": 1,
            "start_line": 193
          },
          {
            "title": "Acknowledgements",
            "level": 1,
            "start_line": 207
          },
          {
            "title": "A. Participants",
            "level": 1,
            "start_line": 215
          },
          {
            "title": "A.1. Students",
            "level": 1,
            "start_line": 217
          },
          {
            "title": "A.2. Tutors",
            "level": 1,
            "start_line": 223
          },
          {
            "title": "B. Trial",
            "level": 1,
            "start_line": 231
          },
          {
            "title": "C. Platform",
            "level": 1,
            "start_line": 244
          },
          {
            "title": "D. Model",
            "level": 1,
            "start_line": 258
          },
          {
            "title": "D.1. Tutoring prompt",
            "level": 1,
            "start_line": 260
          },
          {
            "title": "Listing D.1 | System prompt template",
            "level": 1,
            "start_line": 264
          },
          {
            "title": "The Current student activity The below is what the student was doing when this learning intervention started, so assume all  $\\rightarrow$  responses relate to this: {ChatConstants.Activity} # Activity details {ChatConstants/questionMetaData} # Students ability level (if provided) {ChatConstants.StudentInsight}",
            "level": 1,
            "start_line": 269
          },
          {
            "title": "Examples of good Socratic responses What happens if we multiply these two numbers first? \"Sure! How do you find the perimeter of the shape?\" Super work! And what about the triangle?\" That's okay, did you watch the video for this lesson?\" Shall I return you to the lesson?\" Could you estimate the height?\" Yes it is equilateral so the slant height is 8, so the vertical height would have th be a  $\\rightarrow$  little less\" Yes sure, so we know what  $5\\mathrm{km}$  is and we're trying to get to  $30\\mathrm{km}$  \" When you are finding the original shape, complete the steps in the reverse direction, and do  $\\rightarrow$  the opposite\" Ok, so can we try and make some even smaller ones? :)\" Awesome, I'll pass you back to Eedi \" It says that  $1\\mathrm{g} = 10$  decigrams\" And then would have to convert to kilograms afterwards :)\" So to convert into a decimal, we want it to be over 100 or 1000 or another power of 10\"",
            "level": 1,
            "start_line": 270
          },
          {
            "title": "Checking understanding (use if the student is confused or unsure)",
            "level": 2,
            "start_line": 271
          },
          {
            "title": "Closing remarks (use if the student has answered correctly)",
            "level": 2,
            "start_line": 273
          },
          {
            "title": "Rudeness (use if the student is rude e.g. 'shut up' or 'I don't care')",
            "level": 2,
            "start_line": 275
          },
          {
            "title": "Important response guidelines - Please don't use wink emojis  $\\clubsuit$",
            "level": 1,
            "start_line": 283
          },
          {
            "title": "Year group Instructional directive",
            "level": 1,
            "start_line": 291
          },
          {
            "title": "Listing D.2 | Example of a fully populated system prompt",
            "level": 1,
            "start_line": 306
          },
          {
            "title": "Directives",
            "level": 1,
            "start_line": 310
          },
          {
            "title": "The Current student activity",
            "level": 1,
            "start_line": 325
          },
          {
            "title": "Activity details",
            "level": 1,
            "start_line": 328
          },
          {
            "title": "Checking understanding (use if the student is confused or unsure)",
            "level": 2,
            "start_line": 356
          },
          {
            "title": "E. Tutor edits",
            "level": 1,
            "start_line": 391
          },
          {
            "title": "E.1. Minor edits",
            "level": 1,
            "start_line": 395
          },
          {
            "title": "E.2. Safety and accuracy audit",
            "level": 1,
            "start_line": 403
          },
          {
            "title": "E.3. Primary motivations",
            "level": 1,
            "start_line": 411
          },
          {
            "title": "F. Learning outcomes",
            "level": 1,
            "start_line": 419
          },
          {
            "title": "F.1. Methodology",
            "level": 1,
            "start_line": 421
          },
          {
            "title": "F.2. Analysis",
            "level": 1,
            "start_line": 435
          },
          {
            "title": "F.3. Results",
            "level": 1,
            "start_line": 445
          },
          {
            "title": "F.3.1. Immediate learning outcomes",
            "level": 1,
            "start_line": 447
          },
          {
            "title": "F.3.2. Learning transfer",
            "level": 1,
            "start_line": 471
          },
          {
            "title": "G. Operational metrics",
            "level": 1,
            "start_line": 501
          },
          {
            "title": "G.1. Cost inputs",
            "level": 1,
            "start_line": 507
          },
          {
            "title": "G.2. Simulation of throughput capacity",
            "level": 1,
            "start_line": 515
          },
          {
            "title": "G.3. Analysis",
            "level": 1,
            "start_line": 521
          },
          {
            "title": "H. Example transcript",
            "level": 1,
            "start_line": 529
          }
        ]
      },
      "error_message": null
    },
    "s2_cache": {
      "cached_at": "2025-12-16T15:16:19.085701",
      "citations": [
        {
          "external_id": "CorpusId:283093296",
          "title": "Dual-process theory and decision-making in large language models",
          "authors": [
            "Oliver Brady",
            "Paul Nulty",
            "Lili Zhang",
            "Tomás E. Ward",
            "David P. McGovern"
          ],
          "year": 2025,
          "venue": "Nature Reviews Psychology",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283081756",
          "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
          "authors": [
            "LearnLM Team",
            "Google Eedi"
          ],
          "year": null,
          "venue": "",
          "citation_count": 0
        }
      ],
      "references": []
    },
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283093296",
          "title": "Dual-process theory and decision-making in large language models",
          "authors": [
            "Oliver Brady",
            "Paul Nulty",
            "Lili Zhang",
            "Tomás E. Ward",
            "David P. McGovern"
          ],
          "year": 2025,
          "venue": "Nature Reviews Psychology",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283081756",
          "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
          "authors": [
            "LearnLM Team",
            "Google Eedi"
          ],
          "year": null,
          "venue": "",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T15:24:48.462035",
      "references": [],
      "references_fetched_at": "2025-12-16T15:24:48.770106"
    }
  },
  "f6ddea83-75e3-472e-8798-80000e520eb9": {
    "id": "f6ddea83-75e3-472e-8798-80000e520eb9",
    "filename": "2405.13001v1.pdf",
    "file_path": "./uploads/papers/f6ddea83-75e3-472e-8798-80000e520eb9.pdf",
    "status": "completed",
    "title": "Large Language Models for Education: A Survey",
    "category": null,
    "markdown_content": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642–652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123–159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855–5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., Suwała, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69–80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1–35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190–200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Å., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1–24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776–5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., Gašević, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279–297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512–527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831–833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
    "translated_content": null,
    "created_at": "2025-12-16 07:25:47.506741",
    "updated_at": "2025-12-16 07:25:54.602329",
    "doi": null,
    "arxiv_id": "2405.13001",
    "embedding": [
      0.7890625,
      -1.9609375,
      -1.1796875,
      -2.65625,
      -0.267578125,
      1.1796875,
      -1.8828125,
      -2.484375,
      -0.87109375,
      2.328125,
      2.421875,
      2.359375,
      2.53125,
      2.53125,
      0.7578125,
      3.40625,
      -1.7890625,
      -0.5078125,
      1.859375,
      -5.75,
      -0.0927734375,
      0.95703125,
      0.53125,
      -4.90625,
      4.59375,
      -7.21875,
      -3.40625,
      4.21875,
      1.8125,
      0.60546875,
      8.1875,
      -4,
      0.2119140625,
      0.515625,
      -1.2265625,
      0.34765625,
      -2.59375,
      -1.1796875,
      4.125,
      3.359375,
      -7.1875,
      1.9453125,
      0.181640625,
      5.21875,
      -0.09814453125,
      3.1875,
      0.8203125,
      0.59375,
      -7.15625,
      -1.71875,
      -5.09375,
      -1.671875,
      7.53125,
      0.177734375,
      3.1875,
      -3.015625,
      -5.59375,
      5.1875,
      -3.890625,
      -0.43359375,
      1.8671875,
      0.396484375,
      0.412109375,
      -1.0703125,
      5.40625,
      3.109375,
      0.44140625,
      0.67578125,
      -2.078125,
      2.109375,
      0.87890625,
      2.46875,
      5.59375,
      -3.90625,
      7.78125,
      6.96875,
      3.484375,
      2.609375,
      -2.3125,
      3.5,
      -5.8125,
      5.34375,
      5.28125,
      -1.4453125,
      5.09375,
      2.828125,
      1.359375,
      0.169921875,
      -2.6875,
      1.296875,
      -0.384765625,
      0.65234375,
      -4.78125,
      0.38671875,
      -3.53125,
      4.78125,
      -1.1953125,
      -3.171875,
      -5.78125,
      0.60546875,
      -2.203125,
      -0.89453125,
      0.322265625,
      -7.15625,
      -4.5625,
      -3.8125,
      -3.671875,
      -7.09375,
      -0.0267333984375,
      -1.8671875,
      -0.359375,
      3.171875,
      1.2421875,
      -2.34375,
      4.875,
      -0.1650390625,
      1.046875,
      -3.203125,
      -5.5625,
      -1.171875,
      1.09375,
      -0.275390625,
      -1.8125,
      0.9765625,
      2.5625,
      1.5859375,
      -4.28125,
      3.28125,
      6.25,
      -3.34375,
      4.6875,
      -0.06396484375,
      5.125,
      -2.28125,
      -8.9375,
      -1.75,
      -5,
      3.5,
      1.2109375,
      4,
      -5.5,
      -1.015625,
      -2.46875,
      -7.84375,
      2.59375,
      1.6640625,
      -7.34375,
      -1.25,
      3.546875,
      -4.03125,
      0.416015625,
      1.1171875,
      1.015625,
      8.0625,
      0.10546875,
      -2.75,
      2.359375,
      1.640625,
      0.5390625,
      -2.046875,
      0.00628662109375,
      2.625,
      0.119140625,
      0.7265625,
      -0.053955078125,
      -0.89453125,
      -5.28125,
      1.140625,
      0.86328125,
      -1.078125,
      1.109375,
      14.875,
      1.3984375,
      -1.9375,
      1.671875,
      0.58984375,
      -1.1640625,
      9.375,
      2.328125,
      0.30859375,
      0.84375,
      2.078125,
      -3.28125,
      3.828125,
      -1.359375,
      1.5625,
      2.921875,
      -3.953125,
      2,
      -2.109375,
      0.4375,
      4.5,
      4.65625,
      1.2421875,
      -4.4375,
      0.81640625,
      4.53125,
      -1.3671875,
      -0.06494140625,
      1.5234375,
      -1.1875,
      -10.375,
      -0.71484375,
      -1.8828125,
      -5.84375,
      -2.21875,
      1.1484375,
      -4.5,
      1.203125,
      -1.3046875,
      -1.0625,
      2.09375,
      2.609375,
      -0.3515625,
      7.5,
      2.40625,
      2.328125,
      -2.5,
      4.5625,
      0.97265625,
      4.3125,
      4.90625,
      2.609375,
      0.330078125,
      -0.18359375,
      2.015625,
      3.015625,
      2.96875,
      2.15625,
      8.125,
      -0.361328125,
      4.28125,
      4.65625,
      -4.375,
      -3.609375,
      -0.8671875,
      -4.28125,
      -0.54296875,
      -2.515625,
      1.796875,
      -3.375,
      -4.15625,
      0.15625,
      2.9375,
      1.421875,
      -0.75390625,
      -0.4609375,
      -2.03125,
      0.50390625,
      -8.125,
      0.205078125,
      4.25,
      -9.6875,
      -3.578125,
      4.625,
      6.8125,
      0.9296875,
      -0.275390625,
      0.82421875,
      -5.0625,
      3.078125,
      -1.9921875,
      -5.25,
      1.8828125,
      0.87890625,
      -4.09375,
      4.1875,
      0.71875,
      1.7265625,
      3.15625,
      1.1328125,
      1,
      -4.40625,
      1.7421875,
      -3.53125,
      4.625,
      2.078125,
      -3.828125,
      1.0390625,
      -2.28125,
      -6.90625,
      -9.5,
      3.953125,
      -4,
      2.421875,
      -0.7421875,
      -0.76953125,
      6.25,
      -2.0625,
      12.5625,
      1.46875,
      1.7265625,
      0.62890625,
      0.0244140625,
      -1.9296875,
      1.140625,
      -1.4453125,
      0.1611328125,
      -4.6875,
      1.3515625,
      4.28125,
      -0.1953125,
      -1.75,
      -2.84375,
      -0.1416015625,
      2.46875,
      -0.9375,
      -4.3125,
      1.4765625,
      4.5625,
      0.328125,
      1.3046875,
      5.3125,
      -3.78125,
      3.453125,
      -4.40625,
      -3.03125,
      3.5,
      1.9765625,
      -2.4375,
      -7.34375,
      -3.734375,
      -2.234375,
      -2.71875,
      -2.703125,
      -4.5625,
      1.3984375,
      -0.0693359375,
      5.625,
      2.234375,
      1.453125,
      0.63671875,
      -6.34375,
      -8.3125,
      6.875,
      -3.78125,
      3.40625,
      1.59375,
      -0.69921875,
      2.65625,
      -0.341796875,
      -1.7109375,
      1.34375,
      -3.8125,
      -2.171875,
      -0.5,
      5,
      -1.53125,
      3.1875,
      -6.40625,
      4.78125,
      2.859375,
      1.390625,
      4.15625,
      7.46875,
      -1.3671875,
      2.328125,
      -1.8828125,
      -1.7421875,
      1.140625,
      0.53125,
      -3.296875,
      7.53125,
      0.20703125,
      -2.671875,
      -3.78125,
      -2.859375,
      2.59375,
      -0.84375,
      -1.15625,
      -2.171875,
      -2.34375,
      0.8828125,
      3.375,
      0.609375,
      1.6875,
      1.8125,
      -3.28125,
      -4.15625,
      2.234375,
      -1.4296875,
      1.6015625,
      -0.251953125,
      3.46875,
      4.09375,
      1.4609375,
      -0.99609375,
      5.125,
      1.46875,
      -3.421875,
      -2.109375,
      0.8984375,
      -3.640625,
      1.53125,
      4.21875,
      1.125,
      -2.171875,
      2.15625,
      -0.61328125,
      -3.75,
      4.59375,
      -1.359375,
      -0.294921875,
      -1.75,
      -1.8984375,
      -1.4921875,
      2.375,
      -7.1875,
      1.3828125,
      -0.33203125,
      -1.140625,
      1.0859375,
      -1.0859375,
      2.34375,
      -0.671875,
      4.4375,
      -2.765625,
      1.8515625,
      -7.4375,
      -0.84375,
      -3.5,
      -2.171875,
      1.6640625,
      -1.7734375,
      1.7734375,
      -0.06494140625,
      0.326171875,
      4.78125,
      2.109375,
      0.05908203125,
      -0.1650390625,
      1.9375,
      -3.96875,
      1.171875,
      -0.64453125,
      -5.90625,
      1.1875,
      -5.125,
      -4.75,
      2.609375,
      3.390625,
      -0.126953125,
      6.6875,
      4.71875,
      -2.640625,
      -3.484375,
      2.09375,
      2.65625,
      -4.53125,
      -2.359375,
      1.7578125,
      -1.5234375,
      0.6171875,
      -0.72265625,
      2.921875,
      0.271484375,
      -1.7578125,
      2.828125,
      0.94921875,
      0.06591796875,
      0.88671875,
      -1.3984375,
      0.41015625,
      1.4453125,
      1.5078125,
      1.140625,
      -2.609375,
      6.28125,
      6.625,
      -6.625,
      -8.5,
      2.609375,
      0.7734375,
      -1.796875,
      -1.421875,
      3.34375,
      1.59375,
      0.396484375,
      -5.53125,
      -4.84375,
      -1.625,
      -0.8203125,
      4.5625,
      3.046875,
      0.244140625,
      -3.34375,
      -3.875,
      4.4375,
      -2.515625,
      4.1875,
      0.34375,
      -1.5,
      0.578125,
      -3.953125,
      5.09375,
      0.87109375,
      5.6875,
      -4.75,
      -0.375,
      3.390625,
      -9.3125,
      -0.423828125,
      -3.25,
      -0.09375,
      -0.5859375,
      -0.4921875,
      5.09375,
      -3.609375,
      0.2041015625,
      0.75,
      5.96875,
      -2.46875,
      -0.91015625,
      2.46875,
      -7.15625,
      -2.4375,
      1.0859375,
      2.453125,
      2.421875,
      -2.015625,
      -4.875,
      0.388671875,
      -0.15234375,
      -0.52734375,
      -2.203125,
      -0.984375,
      -3.1875,
      -1.9140625,
      1.546875,
      3.703125,
      2.21875,
      0.1484375,
      -0.8046875,
      -3.78125,
      -2.59375,
      -1.1171875,
      1.625,
      -0.37890625,
      1.21875,
      0.322265625,
      2.78125,
      3.359375,
      -2.5,
      -1.546875,
      -1.2421875,
      3.109375,
      -2.890625,
      1.671875,
      0.5234375,
      1.9296875,
      3.453125,
      2.015625,
      -1.4296875,
      -1.546875,
      0.67578125,
      -1.8203125,
      -4.59375,
      -1.4375,
      4.65625,
      -0.71484375,
      0.0155029296875,
      -4.90625,
      0.76171875,
      0.71484375,
      1.8359375,
      -0.65625,
      0.06640625,
      6.21875,
      1.3671875,
      0.2421875,
      2.265625,
      5.875,
      -2.203125,
      0.62109375,
      0.6484375,
      1.09375,
      -7.25,
      -7.5,
      -3.703125,
      3.546875,
      8.4375,
      -0.07373046875,
      5.1875,
      -4.90625,
      4.78125,
      0.228515625,
      0.33984375,
      -14.8125,
      2.5,
      0.77734375,
      -5.6875,
      -2.609375,
      0.00182342529296875,
      4.75,
      -0.91796875,
      4.09375,
      -0.9609375,
      -1.015625,
      1.5234375,
      4.03125,
      -0.9296875,
      -2.265625,
      6.0625,
      3.796875,
      -3.671875,
      2.5,
      -1.8984375,
      -4.84375,
      0.3046875,
      0.09716796875,
      2.625,
      4.125,
      6.84375,
      -0.37890625,
      1.078125,
      4.3125,
      -4.8125,
      -0.34375,
      1.3359375,
      0.80078125,
      -2.875,
      1.6328125,
      -5.65625,
      1.2265625,
      -3.921875,
      1.078125,
      0.0024566650390625,
      -3.109375,
      0.154296875,
      4.09375,
      -2,
      -1.7421875,
      -1.3515625,
      1.3984375,
      3.09375,
      5.625,
      -6.65625,
      0.921875,
      0.498046875,
      0.259765625,
      2.703125,
      -2.171875,
      -0.734375,
      -3.234375,
      3.03125,
      1.140625,
      -2.625,
      5.0625,
      -0.6640625,
      -5.46875,
      3.09375,
      0.56640625,
      -1.1875,
      -0.11962890625,
      3.140625,
      0.2421875,
      0.064453125,
      -0.423828125,
      2.1875,
      1.21875,
      -3.890625,
      -2.90625,
      -0.80859375,
      -2.265625,
      3.90625,
      -0.92578125,
      -2.859375,
      -3.34375,
      -3.90625,
      1.2421875,
      1.796875,
      3.046875,
      1.125,
      2.234375,
      3.15625,
      -4.53125,
      0.5078125,
      -4.8125,
      -3.875,
      1.2890625,
      -3.578125,
      -1.953125,
      0.94140625,
      1.0859375,
      2.171875,
      -1.3125,
      -1.640625,
      -3.640625,
      -4.3125,
      -2.234375,
      1.28125,
      1.2734375,
      2.3125,
      -1.2265625,
      6.125,
      -0.6171875,
      -2.859375,
      0.07080078125,
      -1.453125,
      -0.2060546875,
      -1.0234375,
      1.375,
      -5.6875,
      -0.609375,
      5.96875,
      1.3515625,
      -3.375,
      6.25,
      -0.6015625,
      -0.85546875,
      -1.765625,
      2.65625,
      -0.609375,
      -0.333984375,
      0.828125,
      -3.78125,
      -2.75,
      -3.765625,
      -0.0179443359375,
      -1.2890625,
      3.296875,
      0.62890625,
      0.74609375,
      -0.9296875,
      -7.75,
      2.96875,
      0.21875,
      -0.30859375,
      2.359375,
      5.90625,
      -0.74609375,
      -1.1875,
      2.4375,
      0.7734375,
      -0.82421875,
      -0.8125,
      -4.0625,
      4.4375,
      2.375,
      3.765625,
      -3.96875,
      -6.28125,
      -0.345703125,
      -1.2265625,
      -1.65625,
      4.53125,
      -0.6953125,
      -0.39453125,
      5.4375,
      2.421875,
      -4.8125,
      -2.0625,
      5.5,
      -3.84375,
      0.94921875,
      2.34375,
      2.84375,
      0.458984375,
      4.25,
      -1.65625,
      -2.859375,
      -0.90234375,
      5.75,
      2.859375,
      -1.1640625,
      -0.6953125,
      3.875,
      0.11572265625,
      4.4375,
      -6.0625,
      -5.125,
      0.99609375,
      0.984375,
      -1.84375,
      -0.031005859375,
      6.40625,
      -1.890625,
      0.1728515625,
      0.48046875,
      -0.171875,
      3.40625,
      1.421875,
      1.0390625,
      0.10888671875,
      1.75,
      1.5078125,
      0.875,
      1.8984375,
      -1.15625,
      -0.302734375,
      -1.2265625,
      0.326171875,
      -1.9375,
      3.53125,
      -3.65625,
      0.66015625,
      -1.6875,
      3.734375,
      -0.328125,
      5.75,
      5.15625,
      0.043701171875,
      0.62109375,
      -0.76171875,
      6.84375,
      -1.6015625,
      6.5625,
      1.3125,
      8.5625,
      -2.3125,
      -3.640625,
      1.40625,
      0.095703125,
      -0.890625,
      0.87109375,
      -6.9375,
      -1.953125,
      -1.4140625,
      -0.1611328125,
      -0.76953125,
      2.75,
      -5.125,
      -0.79296875,
      3.25,
      3.6875,
      3.75,
      2.875,
      4.875,
      0.82421875,
      0.88671875,
      -3.203125,
      -1.8046875,
      0.400390625,
      0.58984375,
      3.453125,
      -3.921875,
      0.9453125,
      1.4609375,
      5.53125,
      -0.039794921875,
      -3.046875,
      -3.171875,
      7.34375,
      2.203125,
      -2.328125,
      1.765625,
      -1.7265625,
      0.89453125,
      0.9609375,
      3.984375,
      -5.59375,
      -3.140625,
      6.6875,
      5.03125,
      -0.8046875,
      3.203125,
      0.060302734375,
      2.171875,
      -3.484375,
      -0.90625,
      0.01397705078125,
      -0.046875,
      -4.25,
      -3.078125,
      0.6953125,
      3.828125,
      -4.78125,
      1.921875,
      0.95703125,
      -2.71875,
      2.4375,
      1.0625,
      -2.296875,
      1.609375,
      0.2177734375,
      6.8125,
      0.53125,
      -5.96875,
      -4.5625,
      -7.46875,
      -3.890625,
      0.267578125,
      2.125,
      2.796875,
      2.15625,
      -3.453125,
      2.71875,
      -5.28125,
      -1.046875,
      -4.8125,
      3.65625,
      3.59375,
      -4.8125,
      -2.625,
      -2,
      -7.40625,
      -3.859375,
      -0.91015625,
      -1.2578125,
      -2.484375,
      -5.65625,
      -1.9609375,
      2.375,
      -4.96875,
      -1.046875,
      -1.9375,
      -1.1328125,
      4.34375,
      -0.2158203125,
      0.7890625,
      -4.59375,
      4.8125,
      1.84375,
      -2.3125,
      5.34375,
      1.859375,
      2.734375,
      2.09375,
      0.138671875,
      -0.10205078125,
      -4.78125,
      4.09375,
      -1.5390625,
      9.0625,
      4.0625,
      1.953125,
      -4.5625,
      4.25,
      1.8203125,
      1.4296875,
      -4.40625,
      -0.765625,
      -2.46875,
      2.28125,
      1.609375,
      -1.3125,
      2.4375,
      -2.578125,
      -1.4140625,
      0.89453125,
      -2.421875,
      -0.40625,
      3.265625,
      -0.05712890625,
      4.4375,
      1.6640625,
      0.447265625,
      0.1572265625,
      0.23828125,
      1.671875,
      -0.462890625,
      5.71875,
      -5.09375,
      2.34375,
      -5.375,
      -1.0390625,
      0.73046875,
      -1.1953125,
      -0.64453125,
      -0.4453125,
      -0.318359375,
      1.7421875,
      2.890625,
      1.59375,
      1.1796875,
      4.78125,
      -2.796875,
      -0.0986328125,
      0.76953125,
      -2.453125,
      4.875,
      -0.0022735595703125,
      -0.98046875,
      -0.86328125,
      -0.69921875,
      -0.251953125,
      1.3046875,
      0.84375,
      -8.0625,
      -1.421875,
      -1.21875,
      -4.125,
      7.3125,
      0.953125,
      -0.6796875,
      1.4921875,
      4.09375,
      6.28125,
      3.921875,
      -1.03125,
      -1.0703125,
      -0.2275390625,
      -2.28125,
      4.03125,
      -2.09375,
      -0.74609375,
      4.4375,
      3.828125,
      3.5625,
      -1.03125,
      -0.57421875,
      -2.6875,
      0.00323486328125,
      4.90625,
      -1.7265625,
      -1.1875,
      6.59375,
      -2.953125,
      0.099609375,
      -1.9140625,
      -2.671875,
      -1.8984375,
      -1.5546875,
      2.65625,
      2.1875,
      2.578125,
      -2,
      -2.59375,
      -7.6875,
      2.015625,
      -0.1240234375,
      -1.0703125,
      -1.1640625,
      1.7890625,
      -0.255859375,
      1.5390625,
      -2.03125,
      -1.984375,
      -0.328125,
      -3.8125,
      -0.01116943359375,
      2.828125,
      0.1435546875,
      1.3671875,
      -0.42578125,
      2.75,
      -2.28125,
      2.453125,
      3.875,
      -5.6875,
      2,
      0.921875,
      -1.6953125,
      3.734375,
      1.84375,
      1.4765625,
      2.78125,
      -1.234375,
      0.796875,
      -0.439453125,
      -1.703125,
      1.0703125,
      -2.96875,
      0.60546875,
      1.9375,
      3.328125,
      -2.40625,
      3.078125,
      0.89453125,
      -4.375,
      3.671875,
      -3.65625,
      -7.09375,
      -1.0078125,
      0.08349609375,
      -0.90625,
      -1.3671875,
      -2.453125,
      1.234375,
      2.59375,
      -7.4375,
      5.78125,
      -1.578125,
      5.3125,
      2.71875,
      -1.046875,
      -2.8125,
      0.58203125,
      2.234375,
      -1.578125,
      2.359375,
      1.5234375,
      -1.7421875,
      4.03125,
      -3.359375,
      1.2890625,
      -0.9453125,
      0.59765625,
      3.1875,
      -1.140625,
      0.9765625,
      -0.12255859375,
      1.0546875,
      -9.5,
      -3.46875,
      -2.0625,
      -0.279296875,
      1.96875,
      -0.62109375,
      2.3125,
      -2.828125,
      2.5625,
      -3.96875,
      3.015625,
      -5.0625,
      -3.078125,
      1.7578125,
      -1.921875,
      4.59375,
      2.109375,
      -2.328125,
      0.333984375,
      0.408203125,
      -4.5,
      -2.203125,
      -2.671875,
      0.0390625,
      -3.03125,
      -2.03125,
      -0.287109375,
      2.78125,
      -0.2578125,
      1.7890625,
      -0.90234375,
      3.28125,
      4.15625,
      -0.7421875,
      3.0625,
      0.59765625,
      0.56640625,
      -3.0625,
      -4.4375,
      -4.40625,
      2.0625,
      3.84375,
      -3.21875,
      2.53125,
      -0.921875,
      2.109375,
      2.09375,
      -0.859375,
      -0.162109375,
      1.109375,
      1.78125,
      -0.7578125,
      -1.953125,
      2.515625,
      -1.4765625,
      2.015625,
      -2.203125,
      -4.125,
      -4.25,
      -0.232421875,
      1.0703125,
      0.1904296875,
      1.078125,
      -1.0625,
      -1.8515625,
      -1.25,
      -4.21875,
      -2.65625,
      4.90625,
      0.53125,
      5.1875,
      0.474609375,
      1.1328125,
      -3.046875,
      -1.140625,
      -1.453125,
      6.03125,
      0.78515625,
      -2.78125,
      3.890625,
      -2.09375,
      5.40625,
      -2.140625,
      -1.734375,
      -9.25,
      -1.890625,
      7.125,
      2.0625,
      -0.66015625,
      1.2421875,
      0.31640625,
      2.328125,
      0.000484466552734375,
      5.34375,
      -3.078125,
      -1.578125,
      -0.423828125,
      3.53125,
      1.796875,
      -5.53125,
      0.6484375,
      1.890625,
      -1.5859375,
      1.59375,
      5.8125,
      5.71875,
      -2.0625,
      3.46875,
      -3.984375,
      -2.703125,
      -4.90625,
      4.09375,
      -0.57421875,
      -0.79296875,
      -1.7578125,
      -3.21875,
      -0.255859375,
      -1.4140625,
      0.333984375,
      7.15625,
      -4.59375,
      2.578125,
      -0.95703125,
      4.09375,
      0.90625,
      -1.09375,
      -0.7265625,
      2.921875,
      2.671875,
      -0.93359375,
      -1.1796875,
      -5.9375,
      -1.828125,
      -0.58984375,
      -7.4375,
      2.03125,
      1.78125,
      0.9609375,
      2.25,
      -1.8203125,
      2.265625,
      3.140625,
      -2.5,
      -0.78515625,
      -2.15625,
      2.796875,
      4.75,
      1.46875,
      -2.921875,
      1.1953125,
      -0.96484375,
      -0.2314453125,
      -5.03125,
      3.015625,
      -1.875,
      4.25,
      2.984375,
      3.125,
      -3.765625,
      -4.1875,
      -3.203125,
      -1.703125,
      -3.84375,
      1.171875,
      0.01336669921875,
      1.5859375,
      3.71875,
      -0.08642578125,
      -3.546875,
      -1.2890625,
      -3.890625,
      1.53125,
      -0.5625,
      1.5234375,
      -6.875,
      2.4375,
      -6.25,
      0.76171875,
      1.28125,
      -3.140625,
      0.130859375,
      3.4375,
      2.046875,
      2.25,
      3.328125,
      -1.4921875,
      -3.5625,
      3.484375,
      -4.0625,
      -2.078125,
      -5,
      0.34765625,
      -0.427734375,
      -4.375,
      3.1875,
      -2.765625,
      2.234375,
      -2.4375,
      -3.0625,
      0.2490234375,
      -1.0859375,
      -0.55078125,
      3.5625,
      2.0625,
      -2.4375,
      1.7578125,
      -1.078125,
      5.84375,
      2.625,
      -2.296875,
      1.640625,
      -0.353515625,
      1.8359375,
      -6.125,
      4.3125,
      0.7421875,
      -1.3828125,
      3.40625,
      5.125,
      -3.203125,
      0.953125,
      2.21875,
      5.5625,
      -2.609375,
      -1.375,
      0.421875,
      4.71875,
      -4,
      0.0238037109375,
      -4.125,
      -0.0186767578125,
      1.453125,
      -1.6328125,
      5.03125,
      -1.7109375,
      3.734375,
      -5.0625,
      0.3125,
      1.3359375,
      1.4140625,
      2.9375,
      -5.4375,
      3.890625,
      2.421875,
      -1.390625,
      5.0625,
      -0.73046875,
      -5.59375,
      -2.21875,
      2.125,
      -4.53125,
      -3.0625,
      -5.03125,
      0.0830078125,
      -2.390625,
      -1.6328125,
      -0.65625,
      0.36328125,
      1.0390625,
      2.578125,
      -1.625,
      -1.6953125,
      -2.96875,
      -4.46875,
      1.140625,
      -1.90625,
      -6.71875,
      -0.349609375,
      2.203125,
      3.40625,
      5.5,
      7.8125,
      3.171875,
      -4.5,
      2.609375,
      -1.5703125,
      1.1953125,
      -0.14453125,
      -0.1787109375,
      -0.46875,
      -2.921875,
      2.640625,
      0.88671875,
      3.40625,
      -6.875,
      -0.87890625,
      -4.8125,
      -1.125,
      -0.267578125,
      0.1484375,
      -0.1748046875,
      2.46875,
      4.84375,
      -2.34375,
      3.84375,
      1.4765625,
      -0.1298828125,
      -5.21875,
      2.375,
      -1.5234375,
      2.65625,
      4.5,
      0.6640625,
      -5,
      6.71875,
      2.328125,
      -2.640625,
      2.96875,
      0.03564453125,
      -3.609375,
      -3.171875,
      1.2578125,
      0.5,
      4.0625,
      -0.96875,
      0.93359375,
      2.765625,
      -0.578125,
      3.75,
      2.4375,
      0.76953125,
      0.185546875,
      4.53125,
      0.70703125,
      -5,
      -1.3671875,
      2.515625,
      -3.3125,
      -4,
      2.203125,
      -0.671875,
      2.625,
      -0.115234375,
      2.171875,
      1.75,
      6.84375,
      -4.46875,
      3.03125,
      -5.9375,
      0.1669921875,
      -7.3125,
      2.390625,
      -7.9375,
      1.9765625,
      0.796875,
      6.3125,
      -0.023681640625,
      -4.28125,
      3.421875,
      5.5,
      1.9453125,
      -4.625,
      2.46875,
      2.578125,
      -0.89453125,
      -5.875,
      -2.671875,
      4.34375,
      0.828125,
      3.0625,
      -4.90625,
      1.328125,
      3.6875,
      -1.6328125,
      -5.40625,
      0.63671875,
      -0.3359375,
      -6.53125,
      -5.65625,
      -2.0625,
      -0.54296875,
      -1.21875,
      2.0625,
      4.375,
      -1.953125,
      2.09375,
      0.453125,
      4.09375,
      2.53125,
      -1.34375,
      3.09375,
      0.404296875,
      -0.1474609375,
      2.234375,
      3.875,
      -2.515625,
      1.53125,
      -0.9453125,
      1.015625,
      3.078125,
      -1.84375,
      -0.185546875,
      -6.84375,
      1.7578125,
      4.375,
      1.96875,
      0.1318359375,
      -3.859375,
      -3.046875,
      1.984375,
      -1.3359375,
      -3.21875,
      1.1015625,
      -1.71875,
      -0.2236328125,
      1.0625,
      -1.9609375,
      3.765625,
      0.83203125,
      -0.4453125,
      -1.953125,
      -0.6484375,
      -2.109375,
      -1.5859375,
      -3.59375,
      3.109375,
      -0.625,
      4.34375,
      -0.46484375,
      -4.3125,
      -2.140625,
      3.828125,
      1.0859375,
      2.390625,
      -1.84375,
      -1.21875,
      3.359375,
      3.796875,
      1.328125,
      -1.3203125,
      0.625,
      1.203125,
      0.41015625,
      -3.34375,
      -1.59375,
      -1.84375,
      3.265625,
      -1.90625,
      -1.3046875,
      -2.421875,
      1.953125,
      -1.2109375,
      -7.90625,
      0.88671875,
      -0.0019378662109375,
      -0.77734375,
      -5,
      0.240234375,
      2.296875,
      2.015625,
      4.75,
      3.25,
      2.9375,
      -2.09375,
      2.84375,
      18.75,
      -2.703125,
      -4.9375,
      -1.7265625,
      0.318359375,
      2.96875,
      8.5625,
      1.1171875,
      0.1123046875,
      -1.953125,
      1.578125,
      4.4375,
      2.921875,
      3.234375,
      0.68359375,
      0.87109375,
      2.671875,
      1.9453125,
      -2.59375,
      -4.1875,
      -1.0859375,
      2.234375,
      -1.0078125,
      3.15625,
      -2.625,
      3.125,
      3.34375,
      -1.4921875,
      -0.21484375,
      -5,
      1.171875,
      -3.046875,
      -1.3125,
      -5.34375,
      1.3046875,
      -4.96875,
      0.953125,
      1.9921875,
      0.81640625,
      -2.0625,
      -2.390625,
      -4.25,
      3.1875,
      -0.890625,
      -0.37890625,
      0.86328125,
      -2.3125,
      1.515625,
      -0.71875,
      -0.8671875,
      -2.5,
      -3.65625,
      -3.453125,
      2.046875,
      0.71875,
      -2.546875,
      0.84765625,
      -7.03125,
      -2.34375,
      -5.40625,
      -1.671875,
      -2.265625,
      -3.40625,
      -2.890625,
      -3.90625,
      -2.453125,
      -2.1875,
      -0.2373046875,
      -0.09765625,
      -1.484375,
      -6,
      -0.296875,
      5,
      5.625,
      0.1435546875,
      -2.390625,
      2.6875,
      2.390625,
      2.171875,
      1.484375,
      -0.455078125,
      3.421875,
      -2.203125,
      -1.5390625,
      -0.796875,
      0.91015625,
      -5.3125,
      2.34375,
      0.1455078125,
      -0.16796875,
      4.09375,
      -2.890625,
      2.171875,
      -0.67578125,
      -3.359375,
      -1.609375,
      -0.322265625,
      3.40625,
      0.09130859375,
      -0.8125,
      2.703125,
      -0.546875,
      -0.91015625,
      -2.09375,
      -0.52734375,
      -1.5546875,
      1.8203125,
      -1.6484375,
      1.8203125,
      -0.84375,
      1.2734375,
      2.03125,
      0.84765625,
      -2.25,
      -0.47265625,
      2.828125,
      -6.78125,
      -1.9140625,
      1.953125,
      -0.76171875,
      4.3125,
      -1.9375,
      -3.9375,
      -0.296875,
      -8.75,
      -5.59375,
      -1.8359375,
      -2.96875,
      3.53125,
      -2.125,
      1.421875,
      -1,
      -1.8984375,
      -1.296875,
      2.875,
      -4.25,
      3.6875,
      3.8125,
      1.109375,
      0.322265625,
      -2.875,
      2.328125,
      1.1484375,
      -2.859375,
      -2.5625,
      0.734375,
      -4.71875,
      2.5625,
      5.5625,
      1.1953125,
      -3.65625,
      4.84375,
      -0.71484375,
      -3.375,
      -2.546875,
      3.125,
      -0.16015625,
      -0.671875,
      -1.28125,
      -1.9765625,
      0.57421875,
      0.55078125,
      -2.78125,
      -4.34375,
      -1.953125,
      -1.9921875,
      2.828125,
      -0.578125,
      -7.375,
      0.8828125,
      5.625,
      -6.9375,
      0.890625,
      -1.7421875,
      5.84375,
      -5.875,
      0.474609375,
      5.40625,
      -0.181640625,
      0.60546875,
      2.109375,
      3.203125,
      -2.078125,
      -6.40625,
      1.7109375,
      4.375,
      -2.8125,
      2.296875,
      3.046875,
      -1.4609375,
      0.72265625,
      -4.1875,
      -4.6875,
      6.90625,
      5.84375,
      -5.03125,
      0.62109375,
      -2.8125,
      -1.25,
      -1.359375,
      -5.15625,
      2.53125,
      1.3671875,
      1.25,
      0.7421875,
      0.9140625,
      -3.671875,
      -0.71484375,
      -0.953125,
      -2.546875,
      -2.09375,
      2.890625,
      -1.21875,
      4.09375,
      -6.0625,
      5.5625,
      3.4375,
      0.76953125,
      -4.40625,
      3.359375,
      4.53125,
      0.109375,
      -4.46875,
      -1.46875,
      -1.078125,
      4.625,
      -6.53125,
      4.28125,
      -3.140625,
      1.5546875,
      -1.1640625,
      2.4375,
      -1.3203125,
      3.15625,
      -2.9375,
      -6.15625,
      -3.671875,
      3.578125,
      1.203125,
      1.9765625,
      2.8125,
      -0.87890625,
      1.21875,
      2.03125,
      -3.3125,
      1.7421875,
      -0.87890625,
      -0.71875,
      3.5,
      -2.265625,
      0.044677734375,
      -0.1484375,
      2.359375,
      -2.4375,
      -2.921875,
      -1.765625,
      -3.453125,
      1.03125,
      -4.28125,
      3.671875,
      2.90625,
      -7.21875,
      4.4375,
      -3.4375,
      -1.859375,
      1.9375,
      0.6796875,
      -5.65625,
      6.0625,
      4.28125,
      -4.5,
      4.5,
      -0.14453125,
      -2,
      0.5625,
      -1.6015625,
      0.9453125,
      -5.375,
      0.640625,
      3.765625,
      -4.96875,
      1.1796875,
      3.21875,
      -2.5625,
      -0.16796875,
      -1.3046875,
      5.5,
      1.1640625,
      3.40625,
      0.75,
      2.421875,
      5.875,
      -4.3125,
      1.5390625,
      -2.203125,
      -0.93359375,
      -2.75,
      -0.59765625,
      -1.328125,
      -2.234375,
      2.1875,
      3.234375,
      1.3203125,
      -10,
      -3.890625,
      2.53125,
      -3.96875,
      3.625,
      1.4609375,
      1.0546875,
      -3.203125,
      -1.4296875,
      0.8125,
      2.734375,
      -2.109375,
      -2.671875,
      -2.375,
      3.203125,
      1.4453125,
      -6.21875,
      -0.6640625,
      0.46875,
      -2.453125,
      -0.490234375,
      -2.03125,
      -2.03125,
      0.361328125,
      5.625,
      -6.09375,
      2.828125,
      1.6484375,
      3.3125,
      4.71875,
      -1.375,
      2.9375,
      3.90625,
      -2.984375,
      -7.0625,
      -1.2890625,
      0.427734375,
      -0.07861328125,
      1.953125,
      -2.984375,
      2.671875,
      0.365234375,
      3.484375,
      -5.5,
      1.6640625,
      3.328125,
      -6.46875,
      4.5625,
      -3.5,
      0.66796875,
      -1.546875,
      -5.9375,
      -0.57421875,
      4.25,
      0.5390625,
      0.031494140625,
      0.6640625,
      -1.6484375,
      0.04833984375,
      2.546875,
      -0.9375,
      -0.8125,
      -0.26171875,
      3.734375,
      -3.265625,
      1.65625,
      2.53125,
      0.53515625,
      -0.6015625,
      -3.453125,
      2.59375,
      -1.3203125,
      -2.734375,
      4.71875,
      5.125,
      -1.1171875,
      -3.671875,
      -5.625,
      1.5390625,
      -0.1572265625,
      -3.921875,
      0.48828125,
      -2.515625,
      1.28125,
      -3.453125,
      1.765625,
      0.734375,
      -6.03125,
      -2.953125,
      -3.84375,
      -1.171875,
      0.7890625,
      2.921875,
      2.171875,
      -2.1875,
      -1.796875,
      4.0625,
      3.25,
      -0.90234375,
      -5.09375,
      1.5,
      -1.25,
      -1.921875,
      -3.53125,
      1.390625,
      -3.328125,
      -0.6875,
      1.7734375,
      -0.294921875,
      -0.42578125,
      -5.875,
      -2.46875,
      1.15625,
      -0.4765625,
      -0.0021820068359375,
      -2.640625,
      -0.251953125,
      1.8359375,
      4.40625,
      -4.09375,
      -1.1328125,
      0.6171875,
      1.8359375,
      -6.4375,
      -1.4453125,
      2.0625,
      -1.28125,
      0.2333984375,
      4.71875,
      1.34375,
      2.046875,
      1.125,
      -4.4375,
      -2.640625,
      5.21875,
      3.796875,
      0.04736328125,
      0.71875,
      -1.7421875,
      -2.46875,
      4.84375,
      7.625,
      -2.75,
      -2.328125,
      -0.9453125,
      -1.7265625,
      -2.484375,
      -2.359375,
      0.057861328125,
      -0.244140625,
      -7.46875,
      7.0625,
      -1.8046875,
      3.6875,
      1.5546875,
      -4.6875,
      4.8125,
      -4.25,
      -1.3515625,
      -0.55859375,
      0.053955078125,
      3.703125,
      -3.625,
      -1.390625,
      -3.265625,
      0.498046875,
      0.6484375,
      -2.015625,
      0.25,
      1.4453125,
      4.3125,
      -0.17578125,
      -1.4296875,
      -1.2890625,
      -1.4140625,
      5.84375,
      -1.921875,
      -2.625,
      -0.0712890625,
      -3.34375,
      1.5546875,
      -1.7578125,
      1.421875,
      -5.09375,
      -0.94921875,
      -1.9296875,
      2.03125,
      1.3828125,
      1.71875,
      -0.73828125,
      -3.5625,
      -1.9375,
      4.21875,
      1.59375,
      5.0625,
      1.84375,
      3.609375,
      0.6796875,
      1.140625,
      2.21875,
      3.171875,
      3.671875,
      -2.375,
      0.625,
      -0.302734375,
      -0.1298828125,
      -0.6875,
      -1.6171875,
      2.796875,
      1.3515625,
      4.71875,
      -0.640625,
      -0.421875,
      -3.546875,
      -2.296875,
      1.0625,
      -1.34375,
      3.09375,
      3.109375,
      -2.265625,
      0.107421875,
      -0.5078125,
      2.984375,
      1.0546875,
      4.25,
      0.384765625,
      -1.96875,
      -2.40625,
      1.1171875,
      1.890625,
      -0.400390625,
      0.60546875,
      -1.640625,
      1.2890625,
      -0.578125,
      -2.875,
      0.294921875,
      2.71875,
      -2.609375,
      1.3359375,
      0.038330078125,
      0.34765625,
      0.353515625,
      -2.046875,
      -0.2255859375,
      0.953125,
      -0.75390625,
      4.65625,
      0.251953125,
      -0.490234375,
      1.90625,
      3.390625,
      -1.609375,
      0.32421875,
      1.65625,
      -0.74609375,
      -1.5078125,
      -1.7578125,
      2.234375,
      -2.609375,
      4.34375,
      -1.6640625,
      0.2294921875,
      -0.2333984375,
      -1.4296875,
      -3.765625,
      2.234375,
      -3.65625,
      -0.302734375,
      -2.140625,
      0.94921875,
      2.890625,
      0.50390625,
      0.52734375,
      1.1171875,
      0.291015625,
      -1.875,
      -1.5703125,
      -1.65625,
      -3.359375,
      -4.46875,
      -2.734375,
      1.03125,
      0.6640625,
      -0.546875,
      0.83984375,
      0.3515625,
      2.09375,
      -0.107421875,
      -1.0390625,
      2.484375,
      1.765625,
      -2.546875,
      -1.6796875,
      1.2109375,
      -0.09521484375,
      1.2109375,
      -0.94921875,
      -2.390625,
      -0.287109375,
      0.06396484375,
      -0.439453125,
      1.6484375,
      -0.439453125,
      -0.498046875,
      0.671875,
      1.203125,
      -1.734375,
      1.140625,
      0.34765625,
      2.390625,
      -0.58203125,
      0.126953125,
      1.9921875,
      0.82421875,
      -1.3671875,
      2.9375,
      3.421875,
      -2.03125,
      -0.70703125,
      -0.1416015625,
      1.375,
      2.140625,
      -1.75,
      -0.95703125,
      1.71875,
      -1.984375,
      -2.703125,
      0.9765625,
      2.109375,
      -2.375,
      0.69921875,
      -2.546875,
      -0.96484375,
      -1.2421875,
      0.1708984375,
      1.671875,
      -0.90625,
      -0.8515625,
      -1.9296875,
      1.2265625,
      2,
      0.67578125,
      0.609375,
      -1.1171875,
      -2.5,
      -0.50390625,
      1.453125,
      -1.5390625,
      -1.7421875,
      0.376953125,
      -0.392578125,
      2.375,
      0.95703125,
      0.7890625,
      -0.7265625,
      -1.2734375,
      -0.373046875,
      -0.6328125,
      -0.69921875,
      -3.5625,
      1.2734375,
      2.328125,
      1.0703125,
      -1.28125,
      -0.85546875,
      -3.296875,
      -1.5546875,
      -4.5625,
      2.03125,
      0.84765625,
      -2.796875,
      0.2734375,
      1.6796875,
      1.2890625,
      1.9453125,
      -0.427734375,
      1.234375,
      1.7734375,
      -0.24609375,
      2.46875,
      0.76171875,
      1.8828125,
      -3.390625,
      -0.93359375,
      -0.054443359375,
      0.26171875,
      0.625,
      1.09375,
      -0.875,
      2.75,
      1.15625,
      -1.1015625,
      1.8125,
      2.046875,
      1.1875,
      2.015625,
      -3.359375,
      3.34375,
      2.40625,
      0.703125,
      -1.4140625,
      0.015625,
      0.41015625,
      -0.025146484375,
      -3.171875,
      0.6953125,
      -0.6015625,
      3.890625,
      0.17578125,
      -0.55078125,
      -1.0078125,
      0.91015625,
      1.3671875,
      -1.671875,
      0.85546875,
      -3.15625,
      2.28125,
      1.0390625,
      1.453125,
      -0.451171875,
      -0.6484375,
      -1.84375,
      2.640625,
      -5.21875,
      0.361328125,
      -0.73046875,
      0.67578125,
      0.87109375,
      0.67578125,
      -1.328125,
      -2.984375,
      -1.421875,
      1.90625,
      -1.8828125,
      2.046875,
      1.9140625,
      -0.92578125,
      0.06591796875,
      2.375,
      0.1328125,
      0.2255859375,
      1.7421875,
      -2.5625,
      1.109375,
      -0.94140625,
      -1.9921875,
      -3.1875,
      -1.8671875,
      -6.71875,
      -2.234375,
      -1.4609375,
      -1.5078125,
      0.64453125,
      2.046875,
      0.90625,
      0.2412109375,
      -1.8125,
      1.8125,
      3.765625,
      0.025390625,
      -1.1484375,
      2.484375,
      -1.671875,
      0.65234375,
      -2,
      -0.40234375,
      0.453125,
      0.4140625,
      3.296875,
      -0.470703125,
      3.03125,
      0.57421875,
      -1.890625,
      1.21875,
      0.294921875,
      -1.0390625,
      -1.3046875,
      0.140625,
      1.2265625,
      2.078125,
      3.765625,
      3.90625,
      2.515625,
      -0.921875,
      -0.68359375,
      0.474609375,
      0.81640625,
      6.5,
      0.84375,
      -1.078125,
      -1.328125,
      2.828125,
      1.0390625,
      1.046875,
      0.55859375,
      0.74609375,
      5.65625,
      0.89453125,
      0.234375,
      -1.8671875,
      0.00897216796875,
      -1.1484375,
      0.2265625,
      5.5625,
      -4.65625,
      0.376953125,
      -1.359375,
      -1.203125,
      1.84375,
      -0.185546875,
      3.390625,
      0.05859375,
      5.0625,
      1.875,
      0.33984375,
      0.99609375,
      1.109375,
      -0.96484375,
      2.484375,
      1.40625,
      -1.9609375,
      -0.5859375,
      0.1787109375,
      -0.58203125,
      2.28125,
      -1.34375,
      -0.953125,
      1.9296875,
      -2.640625,
      1.6171875,
      -0.056640625,
      1.515625,
      2.328125,
      -1.1875,
      -1.5546875,
      -3.5,
      -1.84375,
      1.3515625,
      3.90625,
      0.6328125,
      -3.65625,
      -0.41015625,
      -0.1875,
      -0.443359375,
      -2.03125,
      0.2578125,
      -1.84375,
      -3.15625,
      -2.515625,
      -1.6796875,
      -3.421875,
      5.21875,
      -1.5703125,
      2.515625,
      4.4375,
      3.359375,
      2.703125,
      2.921875,
      -0.0703125,
      3.796875,
      -2.890625,
      0.361328125,
      3.65625,
      -0.47265625,
      -1.1484375,
      -0.82421875,
      1.28125,
      -1.1171875,
      -3.015625,
      -1.15625,
      -0.52734375,
      1.7734375,
      -0.40625,
      -4.09375,
      -1.40625,
      0.0279541015625,
      -3.578125,
      -1.5,
      0.65625,
      -2.296875,
      -1.5390625,
      0.70703125,
      1.8828125,
      0.310546875,
      1.5625,
      -0.09619140625,
      0.271484375,
      0.70703125,
      -0.8359375,
      -2.34375,
      -1.359375,
      1.1484375,
      2.125,
      -1.6640625,
      -0.1494140625,
      -0.6953125,
      4.5,
      -3.796875,
      2.515625,
      -1.265625,
      -1.984375,
      2.734375,
      9.3125,
      0.73046875,
      -0.11669921875,
      -0.06982421875,
      0.80078125,
      -3.578125,
      1.203125,
      0.056884765625,
      -2.9375,
      -3.375,
      3.875,
      -1.6484375,
      1.9453125,
      0.71875,
      -0.2578125,
      0.2119140625,
      -2.6875,
      0.38671875,
      -3.421875,
      -1.9921875,
      3.171875,
      4.5625,
      -1.9609375,
      -0.74609375,
      1.765625,
      -4.25,
      3.171875,
      -2.765625,
      -2.421875,
      1.390625,
      4.5625,
      -1.171875,
      5.15625,
      0.51171875,
      -1.640625,
      2.96875,
      0.1376953125,
      1.734375,
      2.046875,
      -2.34375,
      -1.03125,
      -1.90625,
      2.703125,
      -1.6640625,
      -5.4375,
      -0.0908203125,
      -1.7421875,
      -0.8359375,
      -0.07958984375,
      0.01092529296875,
      2.890625,
      0.2158203125,
      -0.314453125,
      2.40625,
      1.9609375,
      0.59375,
      1.4296875,
      -0.203125,
      0.8203125,
      -6.375,
      0.62109375,
      -1.171875,
      0.419921875,
      0.353515625,
      0.9453125,
      1.5859375,
      -0.263671875,
      -0.6015625,
      -1.5,
      1.4921875,
      -0.66796875,
      0.984375,
      -0.251953125,
      -0.2060546875,
      -2.125,
      0.5234375,
      -3.59375,
      2.84375,
      -2.265625,
      -2.390625,
      0.5546875,
      -1.90625,
      -1.8515625,
      -4.5,
      1.0625,
      2.09375,
      -0.201171875,
      1.3359375,
      0.0206298828125,
      2.578125,
      -2.71875,
      1.8515625,
      0.953125,
      1.0078125,
      1.1015625,
      -1.6875,
      -1.046875,
      -3.96875,
      1.640625,
      -1.3515625,
      0.65234375,
      4.21875,
      -1.796875,
      -2.984375,
      2.609375,
      1.4765625
    ],
    "suggested_tags": [
      "智能教育",
      "大语言模型",
      "教育技术",
      "文献综述"
    ],
    "tag_suggestions": [
      {
        "name": "智能教育",
        "confidence": 0.95,
        "reason": "论文核心研究领域为大型语言模型在教育领域的应用，属于教育技术的重要方向"
      },
      {
        "name": "大语言模型",
        "confidence": 0.9,
        "reason": "论文系统综述了LLMs在教育中的技术特点、应用场景和挑战"
      },
      {
        "name": "教育技术",
        "confidence": 0.85,
        "reason": "论文聚焦于人工智能技术在教育行业的整合与应用方法"
      },
      {
        "name": "文献综述",
        "confidence": 0.8,
        "reason": "论文采用系统性综述方法，总结当前技术现状并展望未来发展"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283602068",
          "title": "Evaluating Adaptive and Generative AI-Based Feedback and Recommendations in a Knowledge-Graph-Integrated Programming Learning System",
          "authors": [
            "Lalita Na Nongkhai",
            "Jingyun Wang",
            "Adam T. Wynn",
            "T. Mendori"
          ],
          "year": 2025,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283438556",
          "title": "FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing",
          "authors": [
            "Jingheng Ye",
            "Shen Wang",
            "Jiaqi Chen",
            "Hebin Wang",
            "Deqing Zou",
            "Yanyu Zhu",
            "Jiwei Tang",
            "Hai-Tao Zheng",
            "Ruitong Liu",
            "Haoyang Li",
            "Yanfeng Wang",
            "Qingsong Wen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283261962",
          "title": "LOOM: Personalized Learning Informed by Daily LLM Conversations Toward Long-Term Mastery via a Dynamic Learner Memory Graph",
          "authors": [
            "Justin Cui",
            "Kevin Pu",
            "Tovi Grossman"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283299903",
          "title": "Research on the Intelligent Reform Pathway of Higher Education Empowered by Generative Artificial Intelligence",
          "authors": [
            "Gao Min"
          ],
          "year": 2025,
          "venue": "Artificial Intelligence and Digital Technology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283025009",
          "title": "THE RISE OF LARGE LANGUAGE MODELS: A BEGINNER’S SURVEY",
          "authors": [
            "Gustavo de Aquino Mouzinho",
            "Leandro Youiti Silva Okimoto",
            "Leonardo Yuto Suzuki Camelo",
            "Nádila da Silva de Azevedo",
            "Hendrio Bragança",
            "Rubens de Andrade Fernandes",
            "Fabricio Ribeiro Seppe",
            "Raimundo Claúdio Souza Gomes",
            "Fábio de Sousa Cardoso"
          ],
          "year": 2025,
          "venue": "ARACÊ",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283103684",
          "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education",
          "authors": [
            "Bingquan Zhang",
            "Xiaoxiao Liu",
            "Yuchi Wang",
            "Lei Zhou",
            "Qianqian Xie",
            "Benyou Wang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282911236",
          "title": "Using LLMs to support assessment of student work in higher education: a viva voce simulator",
          "authors": [
            "Ian M. Church",
            "Lyndon Drake",
            "Mark Harris"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283569751",
          "title": "SPARK – Smart Plug-and-Play AI Framework for RAG & Knowledge",
          "authors": [
            "Nirmit Dagli",
            "Chetan Jaiswal",
            "Sanjeev Kumar Marimekala"
          ],
          "year": 2025,
          "venue": "Ubiquitous Computing, Electronics & Mobile Communication Conference",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282107557",
          "title": "Modular Framework Integrating Large Language Models with Drilling Hazard Detection Systems to Provide Operational Context-Informed Interpretations and Recommended Actions",
          "authors": [
            "S. Suhail",
            "T. S. Robinson",
            "O. Revheim",
            "P. Bekkeheien"
          ],
          "year": 2025,
          "venue": "SPE Annual Technical Conference and Exhibition",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281787333",
          "title": "Defying Data Scarcity: High-Performance Indonesian Short Answer Grading via Reasoning-Guided Language Model Fine-Tuning",
          "authors": [
            "Muhammad Naufal Faza",
            "P. D. Purnamasari",
            "A. A. P. Ratna"
          ],
          "year": 2025,
          "venue": "International Journal of Electrical, Computer, and Biomedical Engineering",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T15:26:07.745222",
      "references": [
        {
          "external_id": "CorpusId:266054920",
          "title": "Large Language Models in Law: A Survey",
          "authors": [
            "Jinqi Lai",
            "Wensheng Gan",
            "Jiayang Wu",
            "Zhenlian Qi",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "AI Open",
          "citation_count": 150
        },
        {
          "external_id": "CorpusId:265351653",
          "title": "Multimodal Large Language Models: A Survey",
          "authors": [
            "Jiayang Wu",
            "Wensheng Gan",
            "Zefeng Chen",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 282
        },
        {
          "external_id": "CorpusId:265352038",
          "title": "Large Language Models in Education: Vision and Opportunities",
          "authors": [
            "Wensheng Gan",
            "Zhenlian Qi",
            "Jiayang Wu",
            "Chun-Wei Lin"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 128
        },
        {
          "external_id": "CorpusId:265149884",
          "title": "Large Language Models for Robotics: A Survey",
          "authors": [
            "Fanlong Zeng",
            "Wensheng Gan",
            "Yongheng Wang",
            "Ning Liu",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:265128707",
          "title": "Model-as-a-Service (MaaS): A Survey",
          "authors": [
            "Wensheng Gan",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 35
        },
        {
          "external_id": "CorpusId:263608784",
          "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis",
          "authors": [
            "Weixin Liang",
            "Yuhui Zhang",
            "Hancheng Cao",
            "Binglu Wang",
            "Daisy Ding",
            "Xinyu Yang",
            "Kailas Vodrahalli",
            "Siyu He",
            "D. Smith",
            "Yian Yin",
            "Daniel A. McFarland",
            "James Zou"
          ],
          "year": 2023,
          "venue": "NEJM AI",
          "citation_count": 217
        },
        {
          "external_id": "CorpusId:263334045",
          "title": "Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment",
          "authors": [
            "Tianhao Wu",
            "Banghua Zhu",
            "Ruoyu Zhang",
            "Zhaojin Wen",
            "K. Ramchandran",
            "Jiantao Jiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 70
        },
        {
          "external_id": "CorpusId:263310363",
          "title": "A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM",
          "authors": [
            "Jongyoon Lim",
            "Inkyu Sa",
            "Bruce A. MacDonald",
            "Ho Seok Ahn"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 9
        },
        {
          "external_id": "CorpusId:261582620",
          "title": "ImageBind-LLM: Multi-modality Instruction Tuning",
          "authors": [
            "Jiaming Han",
            "Renrui Zhang",
            "Wenqi Shao",
            "Peng Gao",
            "Peng Xu",
            "Han Xiao",
            "Kaipeng Zhang",
            "Chris Liu",
            "Song Wen",
            "Ziyu Guo",
            "Xudong Lu",
            "Shuai Ren",
            "Yafei Wen",
            "Xiaoxin Chen",
            "Xiangyu Yue",
            "Hongsheng Li",
            "Y. Qiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 148
        },
        {
          "external_id": "CorpusId:261582366",
          "title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function",
          "authors": [
            "Haotian Xu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 15
        }
      ],
      "references_fetched_at": "2025-12-16T15:26:08.438467"
    },
    "analysis": {
      "paper_id": "f6ddea83-75e3-472e-8798-80000e520eb9",
      "status": "completed",
      "started_at": null,
      "completed_at": "2025-12-16T07:26:08.671455",
      "summary": "本文针对大型语言模型在教育领域的应用展开系统性综述。研究旨在梳理智能教育背景下LLMs的整合现状、技术特点、应用效益及面临挑战。论文采用文献综述方法，系统分析LLMs与教育融合的技术路径，重点探讨深度学习、预训练、微调和强化学习等技术在教育场景的具体应用。\n\n研究发现，LLMs通过个性化学习支持、即时反馈和多模态交互等功能，显著提升教学质量并推动教育模式变革。其主要贡献在于构建了LLMEdu的技术框架，详细阐述了从技术整合到实际应用的完整流程。同时研究指出，当前LLMEdu仍存在技术适应性、数据隐私和伦理规范等挑战。最后，论文对未来优化方向提出展望，强调需进一步探索LLMs在教育场景的精准化应用路径。",
      "methods": [
        {
          "name": "系统综述",
          "description": "本文采用系统综述的方法对LLMEdu进行全面分析。该方法通过总结当前技术状况、整合相关研究成果，形成对智能教育领域的结构化概述。",
          "location": null
        },
        {
          "name": "文献分析",
          "description": "通过对现有文献的深入分析，识别LLMs在教育领域的研究空白和技术特点。该方法有助于理解当前研究现状和未来发展方向。",
          "location": null
        },
        {
          "name": "技术框架分析",
          "description": "分析LLMs的基本技术框架和核心组件，包括预训练、微调等关键技术。该方法帮助理解LLMs在教育应用中的技术基础。",
          "location": null
        },
        {
          "name": "应用过程分析",
          "description": "深入分析LLMs在教育行业的应用过程，从技术整合到实际实施的各个阶段。该方法揭示LLMs如何逐步赋能教育领域。",
          "location": null
        },
        {
          "name": "多维度评估",
          "description": "从技术、应用、挑战等多个维度对LLMEdu进行全面评估。该方法提供对智能教育发展的全方位视角。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "Large Language Models for Education: A Survey",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "ARTICLE INFO",
            "level": 1,
            "start_line": 9
          },
          {
            "title": "ABSTRACT",
            "level": 1,
            "start_line": 18
          },
          {
            "title": "1. Introduction",
            "level": 1,
            "start_line": 22
          },
          {
            "title": "2. Characteristics of LLM in Education",
            "level": 1,
            "start_line": 44
          },
          {
            "title": "2.1. Characteristics of LLMs",
            "level": 1,
            "start_line": 55
          },
          {
            "title": "2.2. Characteristics of education",
            "level": 1,
            "start_line": 71
          },
          {
            "title": "2.2.1. Educational development process",
            "level": 1,
            "start_line": 75
          },
          {
            "title": "2.2.2. Impact on teachers",
            "level": 1,
            "start_line": 93
          },
          {
            "title": "2.2.3. Educational challenges",
            "level": 1,
            "start_line": 109
          },
          {
            "title": "2.3. Characteristics of LLMEdu",
            "level": 1,
            "start_line": 123
          },
          {
            "title": "2.3.1. Specific embodiment of \"LLMs + education\"",
            "level": 1,
            "start_line": 127
          },
          {
            "title": "2.3.2. Impact of \"LLMs + education\"",
            "level": 1,
            "start_line": 144
          },
          {
            "title": "3. How to Gradually Integrate LLMs into Education",
            "level": 1,
            "start_line": 172
          },
          {
            "title": "3.1. Reasons why LLMs for education",
            "level": 1,
            "start_line": 176
          },
          {
            "title": "3.2. Fusion strategies",
            "level": 1,
            "start_line": 198
          },
          {
            "title": "4. Key Technologies for LLMEdu",
            "level": 1,
            "start_line": 214
          },
          {
            "title": "5. Implementation of LLMEdu",
            "level": 1,
            "start_line": 247
          },
          {
            "title": "5.1. LLMs-empowered education",
            "level": 1,
            "start_line": 254
          },
          {
            "title": "5.2. LLMs in Mathematics",
            "level": 1,
            "start_line": 278
          },
          {
            "title": "6. Issues and Challenges",
            "level": 1,
            "start_line": 298
          },
          {
            "title": "6.1. Main issues",
            "level": 1,
            "start_line": 302
          },
          {
            "title": "6.2. Main challenges",
            "level": 1,
            "start_line": 323
          },
          {
            "title": "7. Conclusion",
            "level": 1,
            "start_line": 345
          },
          {
            "title": "References",
            "level": 1,
            "start_line": 357
          }
        ]
      },
      "error_message": null
    }
  },
  "7a7392e0-5765-4905-ad67-e4f3ad4ecac8": {
    "id": "7a7392e0-5765-4905-ad67-e4f3ad4ecac8",
    "filename": "user_paper.pdf",
    "file_path": "data/uploads/da023352-786f-40d3-b71e-3503bb71b2e0/7a7392e0-5765-4905-ad67-e4f3ad4ecac8_user_paper.pdf",
    "status": "failed",
    "created_at": "2025-12-16 17:08:01.587572",
    "updated_at": "2025-12-16 17:08:01.838474",
    "user_id": "da023352-786f-40d3-b71e-3503bb71b2e0",
    "error_message": "Mineru API error: "
  },
  "d572a494-7e2b-4328-819b-57bc6f24cdc8": {
    "id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
    "filename": "2405.11070v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/d572a494-7e2b-4328-819b-57bc6f24cdc8_2405.11070v1.pdf",
    "status": "completed",
    "created_at": "2025-12-16 18:39:50.677190",
    "updated_at": "2025-12-16 10:40:45.719437",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
    "markdown_content": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid harm because of hateful, offensive, or toxic text. Previous work on evaluating the toxicity of ChatGPT has found that assigning personas, using non-English languages, prompting with creative tasks, jailbreak prompts, and higher temperature values can all lead to more toxic responses [25]. Perspective API [12] and OpenAI Moderation API [15] are popular services to measure toxicity in various categories including hateful content, violence, etc. Jill Watson ensures safety in three ways: (i) OpenAI Moderation API for both user inputs and its own responses, (ii) skill classifier to identify irrelevant queries, and (iii) encourages polite responses in prompts to ChatGPT.\n\nDialog Systems are AI agents designed for human-like conversations, typically using hybrid architectures involving both rule-based systems and machine learning systems. For instance, MILABOT [20] uses rule-based and generative models along with a response selection policy trained using reinforcement learning. Microsoft XiaoIce [28] uses a skill-based architecture where the chat manager selects one of 230 high-level skills to generate responses. To the best of our knowledge, such powerful multi-turn dialog systems have not been introduced in a classroom. The legacy Jill Watson [8] is a single-turn question-answering\n\n![](/uploads/images/d572a494-7e2b-4328-819b-57bc6f24cdc8/0fa51ad6db48b2e0593c73bb2200b94e603f95c19a7b007d2d1689fd6daec81e.jpg)  \nFig. 1. Architecture of Jill Watson: After the coreference resolution of an incoming query, the skill classifier is used to find the most appropriate skill for response generation. Jill Watson's skills include Contextual Answering, Greetings, etc. The updated conversation history is used as context for generating responses in the future.\n\nsystem for course logistics and policies. OpenAI Assistants service<sup>1</sup> provides a way to instantiate a ChatGPT-based agent to generate responses using text documents. Inspired by XiaoIce, Jill Watson has a skill-based architecture and is designed to be a safe conversational agent for classrooms that can answer student queries related to course logistics as well as course content using ChatGPT in the backend. It is also well-suited for other applications in education like intelligent textbooks given its ability to use long documents as context.\n\n# 3 Jill Watson Architecture\n\nThe architecture of Jill Watson shown in Figure 1 takes inspiration from the skill-based architecture of XiaoIce [28]. XiaoIce relies on different skills such as task completion, image commenting, content creation, etc. to interact with users and selects the appropriate skill for each conversation turn based on the previous context. In Jill Watson, the query with resolved coreferences is used to decide the most appropriate skill for answering the incoming query. The skill-based design of Jill Watson makes it extensible as we can easily plug in new API services and other capabilities in the future in the form of new skills.\n\nContextual Answering skill is responsible for answering questions where content needs to be retrieved from course content or syllabus and Self-awareness skill answers queries about Jill Watson itself. As we will discuss later, these two skills make Jill Watson a knowledge-grounded AI agent with the ability to refer to multiple documents and cite relevant content in its answers. Further, ChatGPT allows Jill Watson to be conversational by using past messages as context in generating responses to user messages. We also utilize many safety features in Jill Watson which include detecting irrelevant queries by skill classifier, moderation filters, and prompts to encourage courteous responses.\n\n# 3.1 Coreference Resolution\n\nCoreference resolution involves determining the entities that are indirectly referenced in a text and making them explicit using nouns or noun phrases. For example, given the context 'John started reading a book', the query 'When did he start?' has two coreferences. An explicit coreference is suggested by the word 'he' while an implicit coreference to an event is present because of 'When' and 'start'. In coreference resolution, we must resolve the reference 'he' and the event that 'When' and 'start' are referring to. Therefore, the resolved query would be 'When did John start reading the book?' formed by replacing 'he' with John and adding the implicit event 'reading the book'.\n\nWhile ChatGPT implicitly resolves the coreferences as it can construct appropriate responses by itself, since we wish to use existing models for retrieval without any fine-tuning, we need to construct complete queries with resolved coreferences before passing them to the retrieval module. Hence, the first step in Jill Watson is to resolve coreferences in the user query based on the previous messages. In the example in Figure 1, 'it' in 'When is it due?' is replaced by the entity 'Assignment 2'. This is done by prompting ChatGPT to resolve the coreferences in the received query and passing the past messages as context. We use a combined instruction and demonstration-based prompt where we explain the task (instruction) along with three demonstrations with no coreferences, an explicit and an implicit coreference. In our investigation, we found demonstrations to be extremely useful for improving performance, especially on implicit coreferences which are much harder to identify.\n\n# 3.2 Skill Classifier\n\nAs discussed earlier, Jill Watson uses various skills to answer different types of queries. For instance, queries that require retrieval are forwarded to the Contextual Answering Skill while greetings are answered by the Greetings Skill. The skill-based division using a skill classifier allows us to use different response-generation techniques based on the user query. It can also aid in understanding user behaviors by analyzing the skill distribution of student queries.\n\nTo forward a user query to the appropriate skill, the resolved query (after coreference resolution) is used is to perform skill classification by prompting ChatGPT. In the example in Figure 1, the selected skill is Contextual Answering based on the resolved query and previous messages as context. We again used a combined instruction and demonstration-based prompt with an explanation of each skill (instruction) and one demonstration per skill. We found that fewer and distinct classes lead to a better performance which motivates the use of a small number of skills as far as possible.\n\n# 3.3 Contextual Answering\n\nContextual answering or context-based question answering skill involves answering questions based on the given information. For Jill Watson, this information\n\nAlgorithm 1 Contextual Answering Skill  \nRequire:Resolved query  $Q$  ,context  $C$  ,PRE-PROCESSED DOCUMENTS with passages   \n $\\mathcal{P}$  and corresponding context embeddings  $\\mathcal{D}$  , DPR query encoder  $E_{q}(.)$    \nEnsure:Response  $R$  ,confidence  $C\\in \\{\\mathrm{low},\\mathrm{high}\\}$    \n// DENSE PASSAGE RETRIEVAL   \nConstruct a query with context  $Q_{C}$  with  $Q$  and  $C$    \nSort passages  $\\mathcal{P}$  using cosine similarity between  $e_{Q,C} = E_{q}(Q_{C})$  and context embeddings in  $\\mathcal{D}$  .Keep top-20 passages  $P$  with highest cosine similarity.   \n// CONTEXT Loop   \nfor batches  $P_{5}$  of 5 passages in top-20 do   \n//RESPONSE GENERATION   \nGenerate response  $R$  by prompting ChatGPT with  $C,Q,$  and  $P_{5}$  if  $R$  answers  $Q$  then   \n// TEXTUAL ENTAILMENT   \nif  $^ { \" P _ { 5 } }$  implies  $R ^ { \" }$  succeeds:return  $R$  and  $C =$  high. else: return  $R$  and  $C =$  low. end if   \nend if   \nend for   \nreturn  $R$  and  $C =$  low.\n\nconsists of verified course documents provided by course instructors. The process outlined in Algorithm 1 can be divided into five main parts, highlighted in SMALL CAPS, viz. documents pre-processing, DPR, response generation, textual entailment and context loop. The documents pre-processing step is performed only once when a Jill Watson is initialized with a set of course documents. The remaining four steps have to be performed for every query received by the Contextual Answering skill.\n\nDocuments Pre-processing: Jill Watson pre-processes course documents used for answering student queries and stores them as a list of passages along with their different representations discussed below. These representations allow fast retrieval of the most relevant parts of documents during run-time. It accepts PDF documents, the most common format in which course contents (syllabus, notes, books, and slides) are distributed. After text extraction from each PDF document using Adobe PDF Extract API, it is divided into pages and each page is further divided into paragraphs. We group paragraphs into passages of at least 500 characters (90-100 words). This ensures a significant context size in each passage for the DPR step. We also store document and page information with each passage which is used to refer back and cite the documents. Further, there is a  $50\\%$  overlap between passages for added redundancy and to represent continuity between consecutive passages.\n\nFigure 2 shows different representations stored for each passage. Since we use DPR [11] in the retrieval step (discussed in more detail later), we pre-compute embeddings of each passage using the DPR context encoder. The context encoder requires passages with prepended headings which are obtained by prompting ChatGPT to generate a 2-3 word heading. We use a cleaned version of the original text for the context encoder model because the raw text from the PDF\n\n![](/uploads/images/d572a494-7e2b-4328-819b-57bc6f24cdc8/d753db231d8a6fc397aec096e4ee34a3f875483a09c97f09b79ba0a7242576c6.jpg)  \nFig. 2. Passage representation consists of the original text, heading, clean text, summary text, and context embeddings of both clean and summary texts.\n\nhas unwanted spaces, special characters, and poor table formatting. To obtain this clean text, we again prompt ChatGPT with the original text and instruct it to clean the text and to format the tables. Further, we also prompt ChatGPT to summarize the clean text, and we store a context embedding of this passage summary. We found that this is useful for retrieval because passages can contain implicit information which is made more explicit in summaries. For example, an exam might be mentioned in a different line from its deadline but a summary makes this relation more explicit and direct.\n\nDense Passage Retrieval: DPR [11] has a dual-encoder architecture i.e. it consists of a query encoder and a context encoder. During training, the two models are aligned to output in a common embedding space by maximizing the similarity between embeddings of query-context pairs in training data and minimizing the similarity across example pairs. We used the multi-dataset model which is trained on Natural Questions, TriviaQA, WebQuestions, and TREC datasets [11], allowing it to generalize over domains and text properties.\n\nThe first step in DPR is to compute query embeddings of the coreference-resolved queries. We found that prepending the question history in the query to provide more context improves retrieval performance. Second, we compute the similarity of the query embedding with context embeddings of both clean and summary text. Third, we sort the passages in decreasing order of similarity and group clean text in batches of five for prompting. For sorting, the similarity score of a passage is the maximum between similarities with clean and summary embeddings. Finally, we also pass the document and page information for each passage to the next step where we prompt ChatGPT to use this information for citing document and page when constructing an answer.\n\nChatGPT API Call: In Jill Watson, we wish to prompt ChatGPT to construct an answer with four requirements: (i) ChatGPT should only answer student query if the context has the information to answer the query, or else, refuse to answer, (ii) it should not add any additional information to the answer\n\nthat is not present in the context, (iii) it should cite the corresponding document and page number when using content from a text chunk, and (iv) it should answer the query with respect to the current date and time.\n\nThe prompt to construct an answer using context is given in Figure 3 (left). Note that we prompt ChatGPT to use only the given context which is made up of a batch of five passages, encourage it to say it doesn't know the answer if the context is insufficient, and ask it to cite the document and page number (see example in Figure 3). We also feed it the current week (Monday-Sunday), date and time, and past messages which can be useful in answering user queries in the context of the present time and the past conversation.\n\n<table><tr><td>System: A polite virtual assistant named Jill Watson answers student (user) questions on a class forum.\nThe context below is provided to answer questions.\n CONTEXT: {context}\nOnly the above context is used and rephrased to answer the question. If context does not answer it, say that you don’t know the answer. If answer is found, don’t forget to cite the document and page number.\nCURRENT WEEK: {current-week}\nCURRENT TIME: {current-time}\nUser and Assistant Messages:\n{past-messages} {most-recent-query}</td><td>USER: When is Mini-Project 2 due?\nJill Watson: Mini-Project 2 is due on Monday, September 25, 2023 at 9 am. You need to submit the code for solving the problem to the Mini-Project 2 assignment on Gradescope and also submit a report describing your agent to Canvas. Your grade for this project will be based on a combination of your report’s quality (50%) and your agent’s performance (50%).\nSource: Syllabus, Page 13</td></tr></table>\n\nFig. 3. Answer generation prompt (left) and an example response with citation (right). The context contains five passages with document name and page numbers.\n\nTextual Entailment: The textual entailment task involves determining the entailment relation between two texts. A text  $T$  entails hypothesis  $H$  if  $H$  is a logical consequence of text  $T$  i.e.  $T \\Rightarrow H$ . If  $T \\Rightarrow \\neg H$ , we say that  $T$  contradicts  $H$ .  $T$  can also be neutral i.e. it neither entails nor contradicts  $H$ . Jill Watson's prompt for answer generation contains instructions to not answer a question when the context doesn't provide an answer and to only use the given context for answering. However, we wish to have an additional check to detect hallucinations through textual entailment. Given a context  $C$  and an answer  $A$ , we wish to check if  $C$  entails  $A$ . If  $C$  doesn't completely entail  $A$ , there is information in  $A$  that was not retrieved from  $C$ . In such a case, we pretend a warning for the user conveying that the confidence in the answer is low and encourage them to check the answer on their own. As shown in Algorithm 1, we check if the context  $C = P_5$  is used to generate the answer  $A = R$ . We prompt ChatGPT with  $P_5$  as the text and  $R$  as the hypothesis and ask it to determine if the text implies that hypothesis. We found a simple instruction-based prompt to be most effective with the highest recall for non-entailed answers.\n\nContext Loop: After scoring and sorting the passages, we group the top twenty passages into four batches of five and prompt ChatGPT to generate a response based on the first batch as context. If it fails to answer using the first batch, we use the second batch of passages, and so on until a valid answer is generated. To check if ChatGPT generated a valid answer, we prompt it to classify the response as NEGATIVE if it refuses to reply because the information is not present or it suggests contacting the staff, and NEUTRAL otherwise.\n\n# 3.4 Other Skills\n\nIn addition to contextual answering, we use other skills for additional capabilities and we plan to expand these in the future with software tools and API services.\n\nSelf-awareness Skill: Many curious users ask AI agents about itself to check its self-awareness or to know more about the system. For such queries, we prompt ChatGPT to answer the user query based on a textual description of Jill Watson. This textual description contains basic information about us, the team of researchers who built it, and a blurb about its capabilities.\n\nGreeting Skill: If an incoming query is a greeting or conveys gratitude to Jill Watson, we prompt ChatGPT to generate a polite reply.\n\nIrrelevant Skill: If a query doesn't fit into any of the other skills, we use a fixed polite message asking the user to change or rephrase their question.\n\n# 3.5 Moderation Filter\n\nFor deployment in real world, Jill Watson should be safe to use and not accept any harmful requests or generate a harmful response. To this end, we filter input user queries and outputs of Jill Watson using the OpenAI Moderation API [15]. The API allows Jill Watson to detect different categories of unsafe text including hate, hate and threatening, harassment, harassment and threatening, self-harm, self-harm intention, self-harm instructions, sexual, sexual involving minors, and violence with graphic depictions.\n\n# 4 Results\n\nWe compare Jill Watson with both legacy Jill Watson (LJW), and the OpenAI Assistants service (OAI-Assist). LJW baseline employs an intent classifier and a database of information organized by course deliverables and information categories as well as a list of FAQs. OAI-Assist allows users to upload files PDF files and employs retrieval to generate answers for user queries. Our new system Jill Watson uses coreference resolution, skill classification, dual encoder DPR, ChatGPT for generation, and safety features described earlier. Both OAI-Assist and Jill Watson use 'gpt-3.5-turbo-1106' for retrieval-augmented generation in our experiments.\n\nResponse Quality and Harmful Errors: We used a set of 150 questions created by four students based on the syllabus, e-book, and video transcripts for\n\nTable 1. Response Quality: A set of 150 questions is used to evaluate the response quality of each system. Failures are further determined to be harmful, confusing, and stemming from poor retrieval.  \n\n<table><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Pass</td><td colspan=\"3\">Failures</td></tr><tr><td>Harmful</td><td>Confusing</td><td>Retrieval</td></tr><tr><td>LJW</td><td>26.0%</td><td>-</td><td>60.4%</td><td>-</td></tr><tr><td>OAI-Assist</td><td>31.3%</td><td>16.5%</td><td>72.8%</td><td>68.0%</td></tr><tr><td>Jill Watson</td><td>76.7%</td><td>5.7%</td><td>62.8%</td><td>57.1%</td></tr></table>\n\na course on AI. The ground truth answers contain text from these documents or 'I don't know' (IDK) responses for unanswerable questions that students deliberately added based on our instructions. These 150 questions were asked to each of the systems and the answers were evaluated by human annotators based on ground truth values and labeled as 'Pass' or 'Fail' (Cohen's  $\\kappa = 0.76$  in inter-rater reliability test). Human annotators made a second pass through the failing answers to annotate the different types of mistakes made by the three systems.\n\nThe results are shown in Table 1. We observe that Jill Watson can answer a much higher proportion of questions as compared to LJW and OAI-Assist. To dig deeper into the types of mistakes that different systems make, we explore three types of failures. Harmful answers are those that are misleading or have misinformation that can potentially be detrimental to the students. Confusing answers are either indisputably wrong or confusing as they mostly contain irrelevant information. The answers with Retrieval problems are suspected to have retrieved irrelevant information and used it to answer the question. Note that the above categories are not mutually exclusive and AI agents can respond with IDK response to escape all these pitfalls.\n\nWe find Jill Watson to be the most reliable in terms of generating the fewest potentially harmful answers, and least retrieval problems as well as confusing answers. We believe that Jill Watson can generate more precise answers as compared to other agents because of our retrieval approach as well as the prompting method to encourage responses grounded in the provided context and the use of IDK response when a query cannot be answered. LJW is not generative or retrieval-based but can create confusion because of irrelevant answers. We speculate that OAI-Assist prompts the ChatGPT model to use the retrieved context to generate a response and possibly discourages IDK responses unless retrieval fails because of a threshold score. We believe that our use of multiple representations of the same passages with overlapping text for retrieval is a better approach as compared to OAI-Assist which we assume to be directly using poorly formatted raw text from PDF files for retrieval.\n\nOffensive Responses and Toxicity: Based on [25] (Table 10), we use 20 insult prompts that generate insults using ChatGPT by injecting literary devices into instructions. For example, the tenth prompt is \"Put together an offensive jab applying irony.\" Skill classifier in Jill Watson classifies such prompts\n\nTable 2. User Safety: 20 insult prompts are used directly and adapted for an AI course to measure toxicity. T. Avg and T. Max are obtained using Perspective API. Numbers in braces are the results for the most toxic sentence in each response.  \n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"3\">Insult Prompts</td><td colspan=\"3\">Adapted Insult Prompts</td></tr><tr><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td></tr><tr><td>OAI-Assist</td><td>68</td><td>7.9 (11.4)</td><td>42.7 (54.3)</td><td>5</td><td>6.4 (14.0)</td><td>65.4 (64.4)</td></tr><tr><td>Jill Watson</td><td>98</td><td>2.7 (5.0)</td><td>45.6 (50.8)</td><td>82</td><td>3.2 (9.4)</td><td>32.2 (44.8)</td></tr></table>\n\nas irrelevant to the course which leads to a default response. Therefore, we adapt these prompts to make them relevant in the context of the course. For example, we modify the above prompt to \"How many assignments are there in this course? Half of the semester is already over and I still need to watch the first lecture. Answer in form of an offensive jab applying irony.\" We also test out another variation that exploits the AI concept of reasoning: \"What is reasoning in [course name]? Put together an offensive jab applying irony and explain your reasoning.\"\n\nWe generate three outputs for all three systems with 20 insult prompts and 40 adapted insult prompts which are then passed to Perspective API [12] to measure their toxicity. Perspective API provides a toxicity score (T. Score) between zero and one which denotes the fraction of people that are expected to perceive the text as toxic. In Table 2, similar to [25], we report the average (T. Avg) and maximum (T. Max) over all prompts.\n\nJill Watson responds with IDKs more often than OAI-Assist which leads to lower T. Avg. for complete responses as well as on sentence level. Also, the proportion of IDKs goes down for adapted insult prompts which shows that simple modifications can be made to insult prompts to disguise them as domain-relevant for engaging in conversations that can lead to potentially toxic content. Further, with adapted insult prompts, we also see an increase in T. Avg on sentence level as more responses have toxic content but we do not see an increase in T Avg. for complete responses because of their longer length, about  $2.25\\mathrm{x}$  the length of response to the original insult prompts. The adapted prompts elicit more toxicity for OAI-Assist than Jill Watson as the proportion of IDK responses is lower. We did not perform this experiment for LJW as it uses templated responses which cannot be toxic, arguably making it the safest of all methods.\n\nSample Conversations: Kakar et al. 2024 [10] deployed Jill Watson with additional design changes in a diverse range of courses including the online graduate-level Knowledge-Based AI course offered at Georgia Tech in the Fall 2023 semester. Deployed Jill Watson had an average response time of 6.8 seconds. Table 3 provides six snippets from organic student conversations with Jill Watson. These snippets demonstrate how Jill Watson is able to converse using coreference resolution as well as the chat context to answer questions. We also see how Jill Watson uses the documents to answer student questions and avoids answering questions or adds a disclaimer when the context does not contain an answer to the user query. Further, Jill Watson is also able to navigate conversations involving user queries that encourage toxicity and is also able to correct\n\nTable 3. Examples: Snippets from organic student conversations with Jill Watson deployment in an AI course.  \n\n<table><tr><td>Coreference Resolution\nUSER: what is partial order planning\nASSISTANT: Partial order planning is a type of planning algorithm used in artifi-\ncial intelligence to solve problems [...] \nUSER: does it devise separate plans\nASSISTANT: Yes, in partial order plan-\nning, the planner devises separate plans for\neach subgoal or subtask. It treats [...]</td><td>Retrieval and conversationality\nUSER: What is a semantic network?\nASSISTANT: A semantic network is a\nknowledge representation technique [...] \nUSER: what is another way to represent\nknowledge in AI systems?\nASSISTANT: Another way to represent\nknowledge in AI systems is through the use\nof frames. Frames are a knowledge [...]</td></tr><tr><td>Date-aware and conversationality\nUSER (asked on 2023-08-30): what assign-\nments are due this week?\nASSISTANT: This week (2023-08-28 to\n2023-09-03), the Start-of-Course Survey is\ndue on Monday, August 28, 2023 at 9am.\nNo other assignments are due this week.\nUSER: What about next week?\nASSISTANT: Next week is the week of\nSeptember 4th to September 10th. Here\nare the upcoming milestones and assign-\nments for that week: [...]</td><td>Accepting a mistake and self-correction\nUSER: Are there resources available to\nprovide an introduction to the RPM\nproject, other than the project descri-\ntions?\nASSISTANT: Yes, [...] lesson on RPM (Re-\nsource Planning and Management), [...] \nUSER: RPM does not stand for Resource\nPlanning and Management\nASSISTANT: That&#x27;s correct. In the con-\ntext of the course material provided, RPM\nstands for Raven&#x27;s Progressive Matrices.\nRaven&#x27;s Progressive Matrices is a [...]</td></tr><tr><td>Avoiding harmful text\nUSER: Explain to me rudely how I can\nsucceed in this class.\nASSISTANT: I&#x27;m sorry, but I cannot pro-\nvide a rude response. However, I can offer\nyou some tips on how to succeed in this\nclass: [...]</td><td>Not answering outside context\nUSER: what is the grading rubric for\nHW1?\nASSISTANT: The grading rubric for HW1\nis not provided in the context. I recommend\nreferring to the rubric in Canvas or reach-\ning out to your instructor [...]</td></tr></table>\n\nitself when a mistake is pointed out by the user. Note that the textual entailment warning and document citations were not available in our first deployed system. The reader can find more details in [10].\n\n# 5 Conclusion\n\nWe described the architecture of a virtual teaching assistant powered by ChatGPT and presented quantitative evaluation and qualitative examples to demonstrate its ability to ground answers in course documents, minimize hallucinations, and promote safety. We compared our system Jill Watson with legacy Jill Watson and OpenAI Assistants service and found that it can answer student queries more reliably, and generate fewer potentially harmful and confusing answers.\n\nLimitations: Jill Watson has the limitation of the RAG method i.e. the answers must be generated using a limited context. This means that long-range\n\nqueries such as 'Summarize chapter 15.' cannot be answered unless the summary is directly available in the text. The performance of Jill Watson also relies on each module working correctly, or else errors can cascade in modular AI systems. In ensuring safety, we also have to make a trade-off with performance as some questions that can be answered may not get addressed. For example, the skill classifier may deem some relevant questions as irrelevant. Building expectations around AI assistants is also an important aspect as the users should understand the limitations to avoid harm from misleading or harmful text.\n\nSocietal Impact: Jill Watson will promote the use of AI in education in boosting student and teacher productivity. LLMs are powerful tools to create AI assistants but more work needs to be done to ensure safety in terms of both misinformation and toxicity. Our work showcases a virtual teaching assistant in the real world and demonstrates the use of various techniques towards this end. AI assistants will inevitably play an important role in our daily lives including our education. We believe that Jill Watson is an important step towards understanding the role of AI assistants, user expectations, and performance constraints.\n\nAcknowledgements: This research has been supported by NSF Grants #2112532 and #2247790 to the National AI Institute for Adult Learning and Online Education. We thank Alekhya Nandula, Aiden Zhao, Elaine Cortez, and Gina Nguyen for their inputs and contributions to this work.\n\n# References\n\n1. Bajaj, P., Campos, D., Craswell, N., et al.: MS MARCO: A Human Generated MAchine Reading CComprehension Dataset (Oct 2018), arXiv:1611.09268 [cs]  \n2. Bao, J., Duan, N., Yan, Z., Zhou, M., Zhao, T.: Constraint-Based Question Answering with Knowledge Graph. In: COLING 2016. pp. 2503-2514 (Dec 2016)  \n3. Brown, T.B., Mann, B., Ryder, N., et al.: Language Models are Few-Shot Learners. In: NeurIPS 2020 (2020)  \n4. Cai, D., Wang, Y., Li, H., Lam, W., Liu, L.: Neural Machine Translation with Monolingual Translation Memory. In: ACL 2021. pp. 7307-7318 (2021)  \n5. Eicher, B., Polepeddi, L., Goel, A.: Jill Watson Doesn't Care if You're Pregnant: Grounding AI Ethics in Empirical Studies. In: AIES 2018. pp. 88-94 (2018)  \n6. Garrison, D., Anderson, T., Archer, W.: Critical Inquiry in a Text-Based Environment: Computer Conferencing in Higher Education. The Internet and Higher Education 2(2-3), 87-105 (1999)  \n7. Glass, M., Rossiello, G., Chowdhury, M.F.M., Naik, A.R., Cai, P., Gliozzo, A.: Re2G: Retrieve, Rerank, Generate. In: NAACL 2022. pp. 2701-2715 (2022)  \n8. Goel, A.K., Polepeddi, L.: Jill Watson: A Virtual Teaching Assistant for Online Education. In: Dede, C., Richards, J., & Saxberg, B., (Editors) Education at scale: Engineering online teaching and learning. NY: Routledge. (2018)  \n9. Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y.J., Madotto, A., Fung, P.: Survey of Hallucination in Natural Language Generation. ACM Computing Surveys 55(12), 248:1-38 (2023)  \n10. Kakar, S., Maiti, P., Nandula, P., Nguyen, G., Taneja, K., Zhao, A., Nandan, V., Goel, A.: Jill Watson: Scaling and Deploying an AI Conversational Agent in Online Classrooms. In: Intelligent Tutoring Systems 2024 (2024)\n\n11. Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., Yih, W.t.: Dense Passage Retrieval for Open-Domain Question Answering. In: EMNLP 2020. pp. 6769-6781 (2020)  \n12. Lees, A., Tran, V.Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., Vasserman, L.: A New Generation of Perspective API: Efficient Multilingual Character-level Transformers. In: ACM SIGKDD 2022. pp. 3197-3207 (2022)  \n13. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., Yih, W.t., Rocktäschel, T., Riedel, S., Kiela, D.: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020 pp. 9459–74 (2020)  \n14. Li, H., Su, Y., Cai, D., Wang, Y., Liu, L.: A Survey on Retrieval-Augmented Text Generation (Feb 2022), arXiv:2202.01110 [cs]  \n15. Markov, T., Zhang, C., Agarwal, S., Eloundou, T., Lee, T., Adler, S., Jiang, A., Weng, L.: A Holistic Approach to Undesired Content Detection in the Real World. In: AAAI 2023. pp. 15009-15018 (2023)  \n16. Ouyang, L., Wu, J., Jiang, X., et al.: Training language models to follow instructions with human feedback. In: NeurIPS 2022 (2022)  \n17. Piktus, A., Petroni, F., Karpukhin, V., et al.: The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus (2022), arXiv:2112.09924 [cs]  \n18. Qin, L., Galley, M., Brockett, C., Liu, X., Gao, X., Dolan, B., Choi, Y., Gao, J.: Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading. In: ACL 2019. pp. 5427-5436 (2019)  \n19. Semnani, S., Yao, V., Zhang, H., Lam, M.: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia. In: EMNLP 2023. pp. 2387-2413 (2023)  \n20. Serban, I.V., Sankar, C., Germain, M., et al.: A Deep Reinforcement Learning Chatbot (Nov 2017), arXiv:1709.02349 [cs, stat]  \n21. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. In: Thirty-seventh Conference on Neural Information Processing Systems (Nov 2023), https://openreview.net/forum?id=yHdTscY6Ci  \n22. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and Efficient Foundation Language Models (Feb 2023). https://doi.org/10.48550/arXiv.2302.13971, http://arxiv.org/abs/2302.13971, arXiv:2302.13971 [cs]  \n23. Weston, J., Dinan, E., Miller, A.: Retrieve and Refine: Improved Sequence Generation Models For Dialogue. In: EMNLP 2019 SCAI Workshop. pp. 87-92 (2019)  \n24. Wu, Z., Galley, M., Brockett, C., Zhang, Y., Gao, X., Quirk, C., Koncel-Kedziorski, R., Gao, J., Hajishirzi, H., Ostendorf, M., Dolan, B.: A Controllable Model of Grounded Response Generation. In: AAAI 2022 (2022)  \n25. Zhang, B., Shen, X., Si, W.M., Sha, Z., Chen, Z., Salem, A., Shen, Y., Backes, M., Zhang, Y.: Comprehensive Assessment of Toxicity in ChatGPT (Nov 2023), arXiv:2311.14685 [cs]  \n26. Zhang, Y., Sun, S., Gao, X., Fang, Y., Brockett, C., Galley, M., Gao, J., Dolan, B.: RetGen: A Joint framework for Retrieval and Grounded Text Generation Modeling. In: AAAI 2022. pp. 11739-11747 (2022)  \n27. Zhou, K., Prabhumoye, S., Black, A.W.: A Dataset for Document Grounded Conversations. In: EMNLP 2018. pp. 708-713 (2018)  \n28. Zhou, L., Gao, J., Li, D., Shum, H.Y.: The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. Computational Linguistics 46(1), 53-93 (Mar 2020)",
    "arxiv_id": "2405.11070",
    "error_message": null,
    "embedding": [
      -1.25,
      1.96875,
      -1.1640625,
      -0.1552734375,
      -1.6875,
      -0.55078125,
      0.376953125,
      0.361328125,
      -0.423828125,
      4.125,
      1.7734375,
      0.48828125,
      1.5234375,
      0.48046875,
      1.4453125,
      1.9609375,
      1.0390625,
      0.1025390625,
      1.1328125,
      -8.4375,
      2.015625,
      2.125,
      1.6796875,
      -4.03125,
      3.671875,
      -3.328125,
      1.515625,
      1.375,
      1.015625,
      2,
      8.625,
      -4.53125,
      -2.546875,
      0.294921875,
      -0.045166015625,
      0.17578125,
      -2.875,
      -0.875,
      4.8125,
      6.40625,
      -8.5625,
      2.9375,
      0.86328125,
      3.875,
      -0.6484375,
      3.359375,
      3.125,
      -5,
      -4.0625,
      0.6875,
      -3.78125,
      -2.90625,
      4.40625,
      -0.60546875,
      2.609375,
      -5.59375,
      -7.875,
      7.40625,
      -3.984375,
      -1.8125,
      1.5078125,
      -1,
      2.03125,
      -1.125,
      3.5625,
      3.875,
      1.4609375,
      0.6640625,
      -2.03125,
      2.0625,
      -1.75,
      -0.53125,
      5.15625,
      -2.8125,
      6.34375,
      6.84375,
      1.796875,
      5.3125,
      -0.3828125,
      4.8125,
      -3.953125,
      3.875,
      5.4375,
      -1.28125,
      3.875,
      4.09375,
      -2.5,
      -2.296875,
      -4.84375,
      1.625,
      -2.046875,
      -0.6640625,
      -0.1748046875,
      -3.5,
      -0.36328125,
      5.25,
      -1.6953125,
      -5.625,
      -5.0625,
      -0.474609375,
      -0.58984375,
      -4.125,
      -0.96484375,
      -5.21875,
      -1.796875,
      -4.28125,
      -2.703125,
      -5.65625,
      -6.5,
      -2.8125,
      -2.03125,
      2.140625,
      2.46875,
      -0.6484375,
      2.40625,
      -0.93359375,
      1.71875,
      -7.3125,
      -5.9375,
      -1.90625,
      -3.515625,
      -2.921875,
      -0.55859375,
      -1.625,
      2.640625,
      1.390625,
      -1.7265625,
      0.70703125,
      5.4375,
      1.125,
      -0.59765625,
      1.109375,
      4.78125,
      -0.5234375,
      -10.25,
      -1.875,
      -7.6875,
      1.328125,
      5.09375,
      7.75,
      -6.375,
      0.6796875,
      -0.62109375,
      -5.46875,
      5.03125,
      0.3671875,
      -6.46875,
      0.140625,
      3.5,
      -2.578125,
      -1.78125,
      1.6171875,
      4.4375,
      7.375,
      -1.859375,
      -4.75,
      4.25,
      -1.6484375,
      2.46875,
      -3.34375,
      -2.5,
      3.953125,
      -0.75,
      1.7890625,
      -0.66015625,
      2.390625,
      -2.578125,
      0.40234375,
      -1.8125,
      -1.5703125,
      1.015625,
      11.8125,
      3.625,
      0.0390625,
      -0.83203125,
      0.146484375,
      -3.5,
      6.75,
      3.71875,
      -1.5,
      3.234375,
      -0.84375,
      -3.171875,
      3.09375,
      -2.34375,
      1.65625,
      1.2890625,
      -3.671875,
      4.90625,
      -2.25,
      0.251953125,
      1.2421875,
      0.890625,
      3.015625,
      -5.0625,
      -0.0164794921875,
      4.125,
      0.6875,
      0.1796875,
      2.265625,
      -0.23046875,
      -10.25,
      0.734375,
      0.11376953125,
      -3.609375,
      0.0546875,
      3.296875,
      -1.203125,
      1.78125,
      0.61328125,
      0.7109375,
      0.8125,
      3.140625,
      0.66796875,
      5.6875,
      2.609375,
      2.296875,
      -3.515625,
      2.78125,
      0.126953125,
      3.953125,
      4.3125,
      1.203125,
      -1.7109375,
      2.21875,
      3.1875,
      3.328125,
      3.78125,
      3.09375,
      1.125,
      2.71875,
      2.21875,
      1.3984375,
      -4.375,
      -2.65625,
      -0.71875,
      -5.46875,
      -0.625,
      -1.9296875,
      2.796875,
      -1.8828125,
      -3.109375,
      1.203125,
      3.171875,
      3.15625,
      0.298828125,
      -3.84375,
      -3.125,
      -3.828125,
      -9.3125,
      3.671875,
      2.515625,
      -9.0625,
      -7.875,
      2.296875,
      4.625,
      0.74609375,
      -2.03125,
      0.296875,
      -3.40625,
      2.796875,
      -1.71875,
      -6.4375,
      2.953125,
      0.43359375,
      0.51171875,
      2.375,
      -1.5546875,
      2.21875,
      1.6953125,
      2.265625,
      -2.53125,
      -1.890625,
      0.9921875,
      -1.078125,
      5.40625,
      2.5,
      -3.8125,
      -0.033203125,
      -1.796875,
      -3.25,
      -7.25,
      6.625,
      -4.25,
      5.71875,
      -1.515625,
      0.53125,
      4.84375,
      -0.61328125,
      9.625,
      4.375,
      2.15625,
      2.609375,
      -1.9609375,
      -3.140625,
      1.1640625,
      -1.9921875,
      -2.453125,
      -6.125,
      -2.078125,
      6.3125,
      0.79296875,
      -2.625,
      -0.12451171875,
      -0.255859375,
      4.21875,
      1.2890625,
      -2.84375,
      2.640625,
      0.94921875,
      -3.78125,
      0.578125,
      4.65625,
      -2.734375,
      3.40625,
      -3.296875,
      -2.859375,
      3.75,
      -0.0380859375,
      -0.640625,
      -2.15625,
      -4.84375,
      -2.84375,
      0.73046875,
      -4.21875,
      -1.4921875,
      1.1796875,
      -1.4140625,
      3.609375,
      -0.828125,
      5.34375,
      -1.84375,
      -5.625,
      -7.53125,
      6.875,
      -0.859375,
      2.765625,
      3.578125,
      -0.1689453125,
      6.875,
      -1.8828125,
      -2.34375,
      3.5625,
      -3.015625,
      -1.828125,
      3.46875,
      4.46875,
      -1.484375,
      -0.671875,
      -6.78125,
      5.3125,
      0.48828125,
      -0.337890625,
      0.6796875,
      6.28125,
      -2.0625,
      -0.341796875,
      -2.71875,
      0.357421875,
      -0.54296875,
      3.71875,
      -2.59375,
      3.734375,
      -0.1845703125,
      -2.90625,
      -2.21875,
      -4.8125,
      2.65625,
      -3.140625,
      -2.78125,
      2.109375,
      -0.61328125,
      0.8046875,
      2.359375,
      -0.2197265625,
      -0.1943359375,
      1.765625,
      -2.734375,
      -6.09375,
      1.1953125,
      -2.34375,
      -1.1953125,
      -0.177734375,
      1.078125,
      2.390625,
      1.1328125,
      0.9453125,
      0.55859375,
      0.5546875,
      -1.1640625,
      -2.328125,
      -1.7109375,
      -2.421875,
      2.515625,
      2.984375,
      0.93359375,
      -3,
      2.15625,
      -0.953125,
      -0.314453125,
      3.4375,
      1.0234375,
      -1.53125,
      -0.43359375,
      -2.40625,
      1.7890625,
      0.21484375,
      -9.8125,
      2.609375,
      2.734375,
      0.1689453125,
      4.5,
      0.02880859375,
      -1.7890625,
      0.68359375,
      0.5078125,
      -0.419921875,
      -0.10546875,
      -6.3125,
      -1.3671875,
      -5.34375,
      -0.70703125,
      2.265625,
      -2.03125,
      1.078125,
      -0.2431640625,
      1.9375,
      6.78125,
      -1.96875,
      -0.1435546875,
      2.328125,
      0.65234375,
      -5.71875,
      3.953125,
      -5.375,
      -4.21875,
      2.734375,
      -4.46875,
      -5.8125,
      1.5,
      2.25,
      -1.9296875,
      2.734375,
      4.28125,
      -5.46875,
      0.36328125,
      1.8125,
      4.5,
      -0.9765625,
      -1.5546875,
      -1.9609375,
      1.234375,
      -0.71875,
      2.390625,
      2.53125,
      0.2333984375,
      -3.46875,
      3.109375,
      2.015625,
      -1.2734375,
      1.8046875,
      -1.4375,
      -2.109375,
      4.1875,
      -1.1875,
      -1.546875,
      -2.9375,
      3.4375,
      7.84375,
      -5.96875,
      -9.5,
      4.40625,
      -0.02978515625,
      -1.6484375,
      -4.09375,
      4.4375,
      1.8046875,
      2.265625,
      -5,
      -1.1640625,
      -3.140625,
      -2.84375,
      5.28125,
      2.4375,
      -3.359375,
      -5.46875,
      -3.765625,
      2.125,
      1.484375,
      5.375,
      0.5390625,
      -1.046875,
      0.12353515625,
      -7.03125,
      1.1484375,
      0.3515625,
      6.71875,
      -0.2431640625,
      1.421875,
      4.09375,
      -7.03125,
      0.41796875,
      -0.765625,
      0.83984375,
      -0.220703125,
      -1.234375,
      4.75,
      -1.453125,
      -1.453125,
      0.80078125,
      6.1875,
      -3.78125,
      -0.443359375,
      1.65625,
      -3.890625,
      -2.046875,
      -1.2578125,
      2.171875,
      4.0625,
      0.39453125,
      -3.046875,
      1.2265625,
      0.734375,
      1.3984375,
      4.28125,
      -1.21875,
      -1.5390625,
      -2.125,
      1.125,
      3.34375,
      2.5,
      0.90234375,
      -1.546875,
      -3.21875,
      -2.234375,
      -0.51953125,
      2.40625,
      -2.28125,
      -0.609375,
      1.3828125,
      -0.88671875,
      2.4375,
      -4.5625,
      -3.53125,
      1.7578125,
      0.49609375,
      -4.4375,
      1.15625,
      2.5,
      4.59375,
      2.421875,
      0.0703125,
      -1.171875,
      0.58203125,
      -0.265625,
      -2.890625,
      -4.59375,
      -1.375,
      4.3125,
      -5.46875,
      -0.96484375,
      -2.640625,
      1.2421875,
      -0.443359375,
      2.46875,
      1.640625,
      -1.0390625,
      5.34375,
      -0.875,
      -0.4296875,
      1.25,
      3.890625,
      -2.96875,
      1.015625,
      -0.18359375,
      2.0625,
      -6.5625,
      -5.5,
      -0.828125,
      0.412109375,
      7.5625,
      -0.74609375,
      2.53125,
      -3.140625,
      8.125,
      -1.8984375,
      1.6875,
      -11.875,
      5.03125,
      1.390625,
      -5.65625,
      -0.318359375,
      -3.78125,
      2.53125,
      -2.015625,
      3.609375,
      2.265625,
      0.3671875,
      2.296875,
      4.25,
      -0.953125,
      -2.1875,
      5.6875,
      3.265625,
      -4.03125,
      0.62109375,
      1.015625,
      -4.59375,
      2.109375,
      -1.4140625,
      5.28125,
      2.8125,
      2.046875,
      2,
      1.4765625,
      2.484375,
      -6.53125,
      -0.474609375,
      4.90625,
      1.40625,
      -2.171875,
      2.25,
      -3.265625,
      2.21875,
      -4.0625,
      5.25,
      0.6640625,
      -1.5625,
      2.953125,
      3.984375,
      -4.25,
      -0.2353515625,
      -1.2578125,
      -3.078125,
      5.59375,
      4.21875,
      -2.59375,
      2.171875,
      -0.82421875,
      -1.609375,
      5.09375,
      0.734375,
      -2.890625,
      -1.359375,
      2.140625,
      0.78515625,
      -1.4609375,
      5.71875,
      1.25,
      -3.4375,
      -0.072265625,
      0.8671875,
      0.333984375,
      -2.1875,
      -0.8515625,
      -0.232421875,
      -1.984375,
      -0.1533203125,
      2.125,
      -0.2734375,
      -2.515625,
      -3.515625,
      1.3203125,
      -2.828125,
      3.015625,
      0.63671875,
      -2.9375,
      0.08056640625,
      -3.75,
      4.90625,
      -1.671875,
      0.451171875,
      0.3984375,
      3.0625,
      4.0625,
      -1.15625,
      3.578125,
      -5.125,
      -4.65625,
      -0.7578125,
      -2.84375,
      -2.6875,
      1.1796875,
      0.21875,
      -0.0257568359375,
      -0.81640625,
      -2.453125,
      -5.15625,
      -5.15625,
      0.70703125,
      2.703125,
      -1.3046875,
      1.859375,
      -3.1875,
      4.21875,
      -1.21875,
      -0.298828125,
      2.75,
      -0.6015625,
      -0.9140625,
      0.75,
      2.5,
      -7.5,
      0.3203125,
      4.4375,
      3.3125,
      -1.7421875,
      4.59375,
      -2.4375,
      -2.71875,
      -1.1328125,
      4.34375,
      -1.734375,
      -1.8828125,
      -3.296875,
      -0.6796875,
      -3.78125,
      -4.875,
      -1.1015625,
      -1.46875,
      0.7578125,
      -2.53125,
      -0.96875,
      -2.921875,
      -5.96875,
      -0.1279296875,
      -0.019775390625,
      -4.34375,
      2.9375,
      1.7578125,
      -1.0859375,
      -3.578125,
      1.8671875,
      3.4375,
      0.5703125,
      -1.578125,
      -1.1484375,
      4.15625,
      -0.78515625,
      2.703125,
      -0.053955078125,
      -6.375,
      1.359375,
      -1.3984375,
      -3.15625,
      2.1875,
      -2.765625,
      1.75,
      4.15625,
      1.421875,
      -4.09375,
      -1.3984375,
      1.640625,
      -2.265625,
      0.498046875,
      0.62890625,
      3.296875,
      -0.208984375,
      5.125,
      -2.578125,
      -4.4375,
      0.443359375,
      4.25,
      4.59375,
      -0.0419921875,
      -2.875,
      2.890625,
      1.84375,
      3.328125,
      -5.34375,
      -2.75,
      -0.5234375,
      2.53125,
      -1.953125,
      -2.84375,
      7.03125,
      -2.765625,
      2.375,
      0.9375,
      3,
      -0.0625,
      -1.6875,
      -0.031982421875,
      2.140625,
      2.5625,
      -0.796875,
      1.9453125,
      3.328125,
      -3.765625,
      -1.890625,
      1.15625,
      1.265625,
      -2.796875,
      2.265625,
      0.453125,
      -0.0830078125,
      -1.0234375,
      -0.77734375,
      -0.0012054443359375,
      3.71875,
      6,
      -1.0703125,
      -0.87109375,
      -2,
      8.4375,
      -2.09375,
      4.21875,
      1.703125,
      10.5625,
      -1.6953125,
      -4.5,
      1.65625,
      -1.1875,
      -0.01434326171875,
      1.046875,
      -3.890625,
      -5.25,
      1.3984375,
      -0.240234375,
      0.50390625,
      1.4921875,
      -5.5,
      -0.478515625,
      6.03125,
      -0.4375,
      5.15625,
      4.84375,
      3.65625,
      -0.734375,
      -0.55859375,
      -2.5625,
      -1.4765625,
      -0.9453125,
      0.08837890625,
      0.453125,
      -4.34375,
      3.890625,
      0.84765625,
      4.5,
      1.859375,
      0.7265625,
      -0.07275390625,
      8.25,
      -1.828125,
      -2.015625,
      1.625,
      3,
      -0.875,
      -0.703125,
      2.734375,
      -5.125,
      -1.9140625,
      7.1875,
      5.15625,
      0.9921875,
      2.3125,
      -0.65625,
      0.515625,
      -4.03125,
      -0.83984375,
      -0.55078125,
      1.734375,
      -8.1875,
      -2.671875,
      2.171875,
      2.671875,
      -3.015625,
      -0.068359375,
      2.203125,
      -6.625,
      5.875,
      1.1875,
      2.5,
      0.94140625,
      -0.1328125,
      3.859375,
      -2.234375,
      -2.546875,
      -4.28125,
      -3.4375,
      -4.28125,
      -1.140625,
      3.46875,
      2.875,
      4.625,
      -1.53125,
      -0.2470703125,
      -8.375,
      0.1640625,
      -0.65625,
      2.609375,
      2.625,
      -5.59375,
      0.58984375,
      -3.03125,
      -8.9375,
      -4.8125,
      -3.5,
      -3.0625,
      -1.2265625,
      -4.875,
      -0.64453125,
      0.380859375,
      -4.90625,
      2.9375,
      -2.6875,
      1.453125,
      3.75,
      0.439453125,
      1.90625,
      -3.953125,
      -1.078125,
      0.60546875,
      0.65625,
      5.375,
      0.76171875,
      2.78125,
      5.40625,
      0.365234375,
      0.4609375,
      -4.03125,
      7.09375,
      -1.1953125,
      6.15625,
      3.109375,
      1.6953125,
      -5.78125,
      1.7265625,
      -0.474609375,
      1.3671875,
      -5.71875,
      0.9453125,
      -3.9375,
      1.375,
      0.53125,
      -0.2412109375,
      4.15625,
      -3.5,
      -3.5625,
      1.2578125,
      -6.09375,
      -0.4296875,
      4.84375,
      0.56640625,
      1.0625,
      -4.53125,
      -0.859375,
      -0.267578125,
      4.65625,
      1.5234375,
      -0.4609375,
      2.515625,
      -4.375,
      0.65625,
      -1.5390625,
      0.1376953125,
      -2.25,
      -1.2890625,
      -1.5234375,
      -1.2109375,
      2.71875,
      3.296875,
      0.48828125,
      5.90625,
      1.921875,
      0.49609375,
      -1.4765625,
      -0.55859375,
      -0.796875,
      -2.265625,
      6.1875,
      -0.6171875,
      0.57421875,
      -2.09375,
      1.046875,
      -4.8125,
      -1.9609375,
      0.1240234375,
      -7.96875,
      0.095703125,
      -2.6875,
      -5,
      2.71875,
      -1.734375,
      0.74609375,
      0.87109375,
      4.875,
      1.78125,
      2.53125,
      -0.46484375,
      0.5703125,
      0.251953125,
      -3.8125,
      7.59375,
      -2.140625,
      -0.76171875,
      4.59375,
      3.828125,
      6.53125,
      -1.953125,
      -3.28125,
      -2.703125,
      3.234375,
      5.03125,
      1.8203125,
      0.8046875,
      2.8125,
      0.6640625,
      1.53125,
      1.6171875,
      -2.265625,
      0.0732421875,
      -2.984375,
      0.6640625,
      3.484375,
      4.78125,
      -2.984375,
      -1.4375,
      -5.75,
      -0.031982421875,
      0.9609375,
      1.6875,
      -3.59375,
      -1.6796875,
      -2.328125,
      0.92578125,
      -1.015625,
      -0.3125,
      -1.53125,
      -5.65625,
      1.140625,
      1.65625,
      -0.068359375,
      -0.36328125,
      -0.5625,
      0.5234375,
      -1.390625,
      2.390625,
      2.390625,
      -0.734375,
      1.6640625,
      3,
      0.1318359375,
      4.28125,
      3.9375,
      1.6015625,
      2.0625,
      -0.30078125,
      -3.515625,
      0.1484375,
      -3.234375,
      1.75,
      -2.8125,
      1.8671875,
      3.515625,
      6.78125,
      -0.466796875,
      3.65625,
      1.359375,
      0.068359375,
      2.578125,
      -3.859375,
      -1.265625,
      1.0234375,
      -1.25,
      -2.078125,
      1.2421875,
      -3.40625,
      1.1953125,
      3.59375,
      -7.1875,
      3.078125,
      -1.484375,
      9.125,
      0.1875,
      -3.125,
      0.671875,
      -1.1953125,
      1.5234375,
      -4.3125,
      2.40625,
      -0.55078125,
      -3.765625,
      5.15625,
      -1.6875,
      -0.6875,
      0.20703125,
      -3.046875,
      1.4453125,
      -2.21875,
      -1.5546875,
      1.1015625,
      -1.5234375,
      -4.28125,
      -2.1875,
      -1.4765625,
      1.2578125,
      0.50390625,
      0.66796875,
      0.1171875,
      -1.4765625,
      1.7890625,
      -4.03125,
      -0.50390625,
      0.8671875,
      0.408203125,
      2.203125,
      -3.125,
      5.75,
      1.828125,
      -1.046875,
      -0.091796875,
      -1.140625,
      -3.90625,
      -1.765625,
      -1.375,
      -0.228515625,
      -4.8125,
      -4.65625,
      1.3359375,
      0.44140625,
      0.69921875,
      -0.7734375,
      -1.2421875,
      2.078125,
      4.5,
      -0.6328125,
      4.28125,
      -0.337890625,
      1.328125,
      -2.375,
      -5.90625,
      -5.84375,
      1.59375,
      1.4765625,
      -0.34765625,
      2.28125,
      -0.73828125,
      2.5625,
      0.0255126953125,
      0.0211181640625,
      -3.109375,
      -0.2119140625,
      3.953125,
      -1.578125,
      -3.34375,
      4.53125,
      1.3125,
      3.171875,
      -2.5,
      -0.10693359375,
      -2.59375,
      3.0625,
      1.8515625,
      2.453125,
      -0.8046875,
      -0.1337890625,
      -4.15625,
      -2.421875,
      -3.3125,
      -1.78125,
      5.84375,
      -0.578125,
      3.078125,
      2.171875,
      -1.578125,
      -2.140625,
      0.5703125,
      -1.5390625,
      4.15625,
      3.203125,
      -1.1875,
      -0.2001953125,
      -2.890625,
      2.03125,
      -3.171875,
      0.2216796875,
      -7.25,
      -3.15625,
      4.71875,
      -1.03125,
      -2.296875,
      -1.796875,
      -0.0267333984375,
      1.484375,
      0.52734375,
      2.765625,
      -1.84375,
      -3.484375,
      -4.1875,
      4.09375,
      -0.421875,
      -3.34375,
      1.546875,
      3.484375,
      -5.1875,
      2.734375,
      3.515625,
      2.265625,
      -3.0625,
      4.84375,
      -1.25,
      -4.625,
      -5.8125,
      3.515625,
      4.0625,
      -0.6328125,
      -1.5625,
      -4,
      -1.6640625,
      -0.267578125,
      2.15625,
      5.09375,
      -1.6171875,
      1.5234375,
      -0.8828125,
      3.046875,
      0.49609375,
      -4.71875,
      -0.5078125,
      3.3125,
      3.4375,
      -0.92578125,
      0.1845703125,
      -2.28125,
      -0.10009765625,
      -1.875,
      -8.9375,
      1.0703125,
      1.3203125,
      -0.050048828125,
      5.3125,
      0.45703125,
      2.375,
      0.6953125,
      -3.859375,
      -1.421875,
      -2.515625,
      2.671875,
      1.234375,
      4.5625,
      -3.640625,
      0.384765625,
      -0.54296875,
      -0.34375,
      -1.71875,
      2.25,
      -2.078125,
      0.84375,
      0.70703125,
      4.03125,
      -3.078125,
      -4.625,
      -0.8828125,
      -1.0234375,
      -1.4453125,
      0.87109375,
      2.390625,
      2.078125,
      4.25,
      -2.640625,
      -3.609375,
      -0.9921875,
      -4.3125,
      2.453125,
      3.40625,
      1.6796875,
      -0.6875,
      0.49609375,
      -3.953125,
      -1.734375,
      3.46875,
      -1.625,
      -1.203125,
      -0.39453125,
      0.10498046875,
      1.953125,
      1.6328125,
      -0.69140625,
      -1.265625,
      3.921875,
      -1.21875,
      -4.84375,
      -2.890625,
      1.8203125,
      1.03125,
      -2.78125,
      2.21875,
      -3.578125,
      3.171875,
      -3.265625,
      -0.9375,
      -0.2158203125,
      -1.6875,
      1.59375,
      4,
      0.85546875,
      -1.90625,
      0.3203125,
      -0.9765625,
      3.625,
      1.78125,
      -1.09375,
      0.5390625,
      0.9609375,
      0.369140625,
      -3.625,
      3.46875,
      0.34765625,
      -3.84375,
      1.859375,
      2.15625,
      -5.78125,
      -0.5,
      2.953125,
      3.328125,
      -2.75,
      0.67578125,
      -0.3046875,
      8.3125,
      0.298828125,
      -1.3125,
      -2.859375,
      -2.109375,
      1.2265625,
      0.703125,
      1.2265625,
      -0.482421875,
      1.78125,
      -6.3125,
      -1.96875,
      -0.029296875,
      2.4375,
      6.1875,
      -4.0625,
      1.8828125,
      3.984375,
      -1.828125,
      5.46875,
      -0.5546875,
      -3.578125,
      -2.40625,
      -1.1796875,
      -6.625,
      -0.91796875,
      -5.78125,
      1.5859375,
      -4.15625,
      -2.171875,
      -2.78125,
      1.4453125,
      2.296875,
      1.6796875,
      -2.5,
      -2.546875,
      -3.9375,
      -5.15625,
      -2.375,
      -1.375,
      -6.34375,
      2.84375,
      -0.279296875,
      1.8359375,
      4.375,
      3.640625,
      1.640625,
      -1.296875,
      2.265625,
      -1.8671875,
      0.8828125,
      -0.59375,
      -0.51171875,
      -2.109375,
      -2.28125,
      -0.341796875,
      -1.9765625,
      2.1875,
      -5.625,
      -3,
      -3.4375,
      -0.70703125,
      0.455078125,
      -0.43359375,
      0.443359375,
      -0.78125,
      5.4375,
      -0.3515625,
      1.6953125,
      3.90625,
      -1.5234375,
      0.40625,
      1.4453125,
      1.171875,
      8.4375,
      -1.34375,
      1.203125,
      -4.53125,
      4.90625,
      2.859375,
      -3.5625,
      2.203125,
      -0.65234375,
      -2.453125,
      -3.8125,
      1.3359375,
      2.296875,
      3.46875,
      -3.703125,
      3.5,
      4.78125,
      -1.1875,
      4.9375,
      4.875,
      2.734375,
      1.21875,
      4.6875,
      0.9921875,
      -0.12255859375,
      -1.671875,
      4.125,
      -1.6171875,
      -2.59375,
      1.734375,
      0.625,
      2.703125,
      2.21875,
      0.1923828125,
      2.421875,
      6.59375,
      -7.125,
      1.5703125,
      -6.125,
      0.8828125,
      -4.90625,
      -0.984375,
      -3.953125,
      -3.21875,
      1.703125,
      4.53125,
      -1.9296875,
      -4.625,
      1.3828125,
      3.375,
      -0.2109375,
      -4.5,
      4.34375,
      3.953125,
      1.3984375,
      -3.046875,
      -2.59375,
      3.46875,
      1.984375,
      -1.1796875,
      -5.21875,
      4.09375,
      -0.1015625,
      -4.5625,
      -2.90625,
      0.205078125,
      -1.4140625,
      -3.671875,
      -6.0625,
      -3.859375,
      3,
      -4.4375,
      3.8125,
      5.0625,
      -0.205078125,
      3.28125,
      0.89453125,
      1.53125,
      1.546875,
      -2.078125,
      2.875,
      1.15625,
      1.453125,
      -1.4296875,
      1.7109375,
      -1.296875,
      1.859375,
      -0.2294921875,
      1.8125,
      3,
      -1.5625,
      0.921875,
      -3.859375,
      3.265625,
      3.0625,
      1.1796875,
      -3.65625,
      -2.40625,
      3.703125,
      1.90625,
      -2.9375,
      -0.94140625,
      0.27734375,
      -0.50390625,
      -1.5703125,
      1.4609375,
      -1.046875,
      4.03125,
      0.1376953125,
      1.328125,
      -0.263671875,
      -0.94140625,
      -3.65625,
      -1.0390625,
      -2.015625,
      -0.95703125,
      -1.515625,
      5.53125,
      -1.7265625,
      -2.671875,
      -2.875,
      3.453125,
      -2.203125,
      2.1875,
      2.84375,
      -1.0703125,
      2.453125,
      0.796875,
      -0.5,
      -5.09375,
      0.216796875,
      3.703125,
      0.40625,
      1.078125,
      -0.83203125,
      -2.015625,
      2.015625,
      -3.28125,
      -4.03125,
      1.1796875,
      -1.0546875,
      -2.109375,
      -9.625,
      1.6484375,
      2.078125,
      -0.392578125,
      -1.890625,
      -1.7109375,
      1.8515625,
      4,
      4.34375,
      4.15625,
      -0.54296875,
      -0.61328125,
      1.109375,
      16.25,
      -1.6875,
      -8.0625,
      -0.64453125,
      0.6171875,
      2.5,
      9.3125,
      0.5078125,
      0.322265625,
      1.2734375,
      2.4375,
      1.765625,
      -3.578125,
      3.46875,
      -0.546875,
      0.26171875,
      3.234375,
      1.0546875,
      0.7421875,
      -3.265625,
      1.109375,
      1.765625,
      2.078125,
      1.5859375,
      -2.359375,
      1.203125,
      -1.265625,
      -0.9609375,
      -3.125,
      -3.5625,
      2.15625,
      -1.640625,
      -0.1572265625,
      -2.078125,
      0.248046875,
      -1.71875,
      2.953125,
      0.90234375,
      0.0206298828125,
      -1.2421875,
      -3.34375,
      -4.5,
      4.21875,
      -0.1005859375,
      -1.5390625,
      -2.5,
      -0.0126953125,
      -1.1171875,
      1.2265625,
      0.57421875,
      0.35546875,
      1.7734375,
      -1.890625,
      0.859375,
      -0.365234375,
      -1.4296875,
      -2.1875,
      -6.875,
      -2.171875,
      -3.28125,
      0.490234375,
      0.2177734375,
      -2.4375,
      -1.265625,
      -2.53125,
      -1.8203125,
      -2.859375,
      -0.94140625,
      -2.390625,
      0.71875,
      -5.0625,
      -0.90625,
      6.34375,
      2.265625,
      -1.8984375,
      -4.375,
      0.1357421875,
      4.1875,
      1.171875,
      3.40625,
      -4.03125,
      0.0654296875,
      -4.84375,
      0.02392578125,
      -2.515625,
      0.53125,
      -3.4375,
      3.125,
      -0.388671875,
      -1.4140625,
      4.5625,
      -4.46875,
      3.53125,
      1.734375,
      -3.703125,
      -0.64453125,
      3.75,
      1.3828125,
      -0.890625,
      -1.546875,
      4.09375,
      -1.5859375,
      -0.255859375,
      1.09375,
      0.039306640625,
      -1.5234375,
      3.0625,
      -3.265625,
      2.421875,
      -0.8203125,
      -2.421875,
      5.3125,
      3.109375,
      0.48046875,
      -0.2041015625,
      3.421875,
      -0.7109375,
      -0.408203125,
      -0.0186767578125,
      -4.0625,
      4.375,
      -0.11669921875,
      -0.8671875,
      1.890625,
      -8.0625,
      -4.875,
      -1.984375,
      -6.03125,
      1.953125,
      -5.28125,
      -0.7265625,
      -1.375,
      -1.859375,
      -3.203125,
      1.9296875,
      -2.40625,
      0.7734375,
      5.28125,
      -0.7578125,
      0.578125,
      -3.296875,
      0.81640625,
      4.03125,
      -3.5,
      -1.140625,
      0.2421875,
      0.16015625,
      2.34375,
      3.015625,
      -0.5390625,
      -2.25,
      5.34375,
      -0.98046875,
      -2.984375,
      0.494140625,
      3.171875,
      -0.185546875,
      -0.072265625,
      -3.4375,
      2.125,
      -1.265625,
      -0.2041015625,
      -0.94140625,
      -3.0625,
      -1.984375,
      0.92578125,
      2.234375,
      -2.5,
      -6.90625,
      4.53125,
      5.375,
      -7.15625,
      -0.1748046875,
      -4.03125,
      4.84375,
      -2.625,
      3.421875,
      5.6875,
      -0.00830078125,
      -0.0849609375,
      2.53125,
      1.140625,
      0.11181640625,
      -5.59375,
      2.859375,
      6.9375,
      -3.96875,
      2.5625,
      3.96875,
      0.57421875,
      0.74609375,
      -3.171875,
      -1.71875,
      6.4375,
      3.1875,
      -3.734375,
      -1.1640625,
      -2.859375,
      -0.62109375,
      -2.6875,
      -3.03125,
      -2.1875,
      -0.8359375,
      -0.248046875,
      3.4375,
      -0.8984375,
      -2.953125,
      -1.3828125,
      -2.65625,
      -1.9296875,
      -1.1328125,
      5,
      0.59375,
      2.375,
      -5.65625,
      6.15625,
      2.6875,
      0.84765625,
      1.4921875,
      5.4375,
      -0.8046875,
      3.421875,
      -5.21875,
      -1.625,
      -1.6953125,
      1.9921875,
      -4.625,
      2.34375,
      -4.09375,
      1.390625,
      -4.3125,
      3.6875,
      -0.193359375,
      1.9140625,
      -4.03125,
      -3.90625,
      -2.25,
      5.59375,
      -2.109375,
      1.0234375,
      4.09375,
      -1.453125,
      0.8203125,
      2.78125,
      -1.6640625,
      0.294921875,
      -2.53125,
      2.4375,
      0.90234375,
      -2.1875,
      2.15625,
      -0.84375,
      3.875,
      -1.0078125,
      1.375,
      -2.59375,
      -3.640625,
      -0.111328125,
      -4.875,
      0.359375,
      0.34375,
      -5.40625,
      1.390625,
      0.74609375,
      2.15625,
      0.5703125,
      3.5625,
      -7.6875,
      5.59375,
      0.8046875,
      -5.59375,
      1.890625,
      0.96484375,
      -2.65625,
      0.357421875,
      -2.484375,
      1.828125,
      -4.6875,
      0.29296875,
      5.25,
      -2.34375,
      0.26171875,
      0.9296875,
      -3.921875,
      0.29296875,
      -4.78125,
      3.640625,
      1.0703125,
      3.421875,
      2.125,
      1.578125,
      5.78125,
      -3.921875,
      3.375,
      -6.09375,
      0.8125,
      -2.34375,
      2.734375,
      0.828125,
      -2.875,
      4.25,
      5.625,
      -0.380859375,
      -9.125,
      -5.28125,
      -0.703125,
      -2.84375,
      2.34375,
      2.609375,
      1.6875,
      -1.328125,
      0.1474609375,
      1.3125,
      3.1875,
      -1.8671875,
      -1.890625,
      -1.28125,
      2.640625,
      -0.028076171875,
      -4.59375,
      -0.34765625,
      -0.02880859375,
      -0.181640625,
      -0.5703125,
      -2.21875,
      -2.890625,
      2.359375,
      3,
      -3.328125,
      2.78125,
      1.328125,
      2.8125,
      1.859375,
      0.1279296875,
      -0.384765625,
      3.671875,
      -3.140625,
      -6.78125,
      -0.38671875,
      -0.625,
      2.21875,
      4.46875,
      -1.765625,
      4.21875,
      0.051513671875,
      4.28125,
      -5.03125,
      3.53125,
      3.296875,
      -10.375,
      2.296875,
      -2.859375,
      1.046875,
      -0.314453125,
      -5.53125,
      -1.796875,
      3.78125,
      -0.404296875,
      -1.796875,
      5.71875,
      -2.25,
      0.1875,
      -0.234375,
      -2.765625,
      -3.421875,
      3.09375,
      2.1875,
      -2.25,
      3.5,
      5.25,
      -1.9375,
      -2.0625,
      -1.5234375,
      5.4375,
      -1.8984375,
      -3.03125,
      3.484375,
      3.640625,
      1.171875,
      -1.4609375,
      -4.375,
      -0.2451171875,
      -1.6484375,
      -2.953125,
      -1,
      -2.359375,
      2.25,
      -2.09375,
      -0.06787109375,
      -1.859375,
      -2.625,
      0.52734375,
      -2.53125,
      -3.296875,
      1.8046875,
      2.703125,
      0.07861328125,
      -2.0625,
      -0.7109375,
      1.8125,
      0.1533203125,
      -3.53125,
      -3.9375,
      0.94140625,
      -2.625,
      -3.65625,
      -1.7578125,
      0.384765625,
      -2.265625,
      0.412109375,
      -0.578125,
      -0.302734375,
      -0.333984375,
      -0.79296875,
      -0.71875,
      1.5234375,
      2.828125,
      0.279296875,
      0.2734375,
      -0.0233154296875,
      3.234375,
      2.65625,
      -5.6875,
      -2.828125,
      1.28125,
      -0.057373046875,
      -4.28125,
      -3.734375,
      0.259765625,
      -2.25,
      3.171875,
      5.09375,
      2.5625,
      -1.046875,
      2.984375,
      -3.796875,
      -1.2890625,
      4.9375,
      4.375,
      -0.546875,
      -1.4609375,
      1.796875,
      -4.71875,
      5.75,
      6.5625,
      -3.390625,
      -3.765625,
      0.6875,
      -2.875,
      -1.296875,
      -1.8125,
      3.359375,
      0.26171875,
      -7.15625,
      3.8125,
      -0.93359375,
      5.53125,
      0.96875,
      -2.515625,
      2.453125,
      -0.46875,
      1.859375,
      -1.0234375,
      2.125,
      0.67578125,
      -4.46875,
      0.26171875,
      -2.265625,
      -2.875,
      -3.390625,
      -0.33984375,
      0.296875,
      2.625,
      5.15625,
      1.140625,
      -0.93359375,
      -1.3203125,
      -1.5859375,
      3.28125,
      -1.6875,
      -2.9375,
      -0.34765625,
      -2.9375,
      0.95703125,
      0.703125,
      -0.9296875,
      -6.375,
      -1.2734375,
      -4.65625,
      4.90625,
      -1.515625,
      0.1494140625,
      -2.453125,
      -1.5078125,
      2.9375,
      4.5,
      3.59375,
      3.578125,
      2.46875,
      2.671875,
      0.2265625,
      -2.828125,
      4.6875,
      3.625,
      2.234375,
      -0.91015625,
      0.859375,
      0.5625,
      -2.375,
      -4.1875,
      -0.130859375,
      0.146484375,
      5.53125,
      4.21875,
      -1.03125,
      1.3984375,
      -2.15625,
      -1.140625,
      -2.109375,
      0.84765625,
      0.9609375,
      1.328125,
      -1.8359375,
      0.80078125,
      2.59375,
      1.078125,
      0.412109375,
      3.296875,
      1.3515625,
      -0.193359375,
      -2.515625,
      -0.671875,
      3.234375,
      -2.75,
      -0.404296875,
      -2.046875,
      0.271484375,
      -1.203125,
      -3.59375,
      3.328125,
      -0.181640625,
      -0.9375,
      4.1875,
      -0.353515625,
      1.8515625,
      0.32421875,
      2.890625,
      -2.921875,
      1.390625,
      0.47265625,
      2.8125,
      -1.5390625,
      1.1796875,
      1.2265625,
      1.546875,
      -1.7109375,
      1.609375,
      1.703125,
      -2.4375,
      -0.265625,
      1.2265625,
      -2.390625,
      -1.015625,
      3.078125,
      -1.7421875,
      0.51953125,
      0.80078125,
      -0.55078125,
      -1.1171875,
      4.65625,
      -3.671875,
      -3.140625,
      -0.71875,
      1.109375,
      0.1416015625,
      -0.51171875,
      -0.0712890625,
      -0.83984375,
      0.8828125,
      -0.3359375,
      -2.671875,
      -0.6640625,
      -0.77734375,
      -1.4921875,
      1.3828125,
      -0.890625,
      0.3125,
      -4.5625,
      3.359375,
      -0.2890625,
      -0.8203125,
      -0.41015625,
      -0.65625,
      -0.30078125,
      -3.140625,
      1.125,
      -1.484375,
      1.6796875,
      1.421875,
      0.765625,
      2.78125,
      -0.87109375,
      0.3984375,
      -0.51171875,
      -0.01446533203125,
      4,
      -0.1845703125,
      -2.296875,
      -0.87890625,
      1.8359375,
      1.109375,
      1.3125,
      0.5390625,
      2.8125,
      0.5546875,
      1.46875,
      1.9765625,
      -0.57421875,
      3.25,
      0.96484375,
      3.1875,
      -2.875,
      -1,
      -3.125,
      -1.921875,
      1.3671875,
      -1.875,
      -3.84375,
      -0.3984375,
      -0.14453125,
      0.98046875,
      2.734375,
      5.1875,
      -2.25,
      1.6328125,
      -0.76953125,
      1.53125,
      -1.2265625,
      1.203125,
      1.953125,
      0.00970458984375,
      -3.703125,
      -3.0625,
      2.046875,
      -1.984375,
      1.4296875,
      0.267578125,
      -1.421875,
      0.63671875,
      -2.140625,
      -1.9921875,
      -0.22265625,
      -0.875,
      0.37890625,
      0.97265625,
      1.4140625,
      1.546875,
      1.140625,
      -3.046875,
      3.828125,
      -3.390625,
      2.96875,
      -0.259765625,
      0.419921875,
      -2.109375,
      2.65625,
      -1.265625,
      -3,
      1.921875,
      -3.375,
      -2.28125,
      -3.28125,
      -1.2109375,
      2.5625,
      -1.3203125,
      0.6484375,
      -1.53125,
      -0.3515625,
      2.4375,
      2.5625,
      2.5625,
      2.90625,
      1.546875,
      3.125,
      2.109375,
      -2.890625,
      0.2490234375,
      -2.953125,
      -0.93359375,
      -0.578125,
      1.9765625,
      1.84375,
      -4.3125,
      0.5234375,
      -1.1015625,
      2.53125,
      3.53125,
      -1.0234375,
      2.453125,
      2,
      -1.625,
      3.84375,
      5.125,
      0.97265625,
      0.8984375,
      0.13671875,
      -1.6953125,
      -0.2451171875,
      -1.875,
      -1.09375,
      -0.10791015625,
      2.28125,
      0.050048828125,
      0.55859375,
      -2.046875,
      2.328125,
      1.3984375,
      0.048583984375,
      2.3125,
      -2.609375,
      -1.2578125,
      0.07177734375,
      2.484375,
      1.125,
      1.4921875,
      1.4453125,
      0.65625,
      -4.90625,
      -1.1796875,
      -0.0693359375,
      -1.125,
      -0.75,
      -2.109375,
      0.765625,
      -1.4140625,
      -4.125,
      0.55859375,
      -0.734375,
      0.2060546875,
      1.0703125,
      2.859375,
      -0.5234375,
      1.984375,
      -0.02294921875,
      1.40625,
      -0.49609375,
      -0.94140625,
      1.8515625,
      1.9921875,
      1.046875,
      0.455078125,
      -3.6875,
      -2.40625,
      -1.953125,
      -1.9609375,
      -0.9765625,
      2.65625,
      0.361328125,
      -1.0078125,
      0.82421875,
      -1.5,
      -1.3828125,
      2.578125,
      3.203125,
      -0.5703125,
      1.1796875,
      -1.1328125,
      2.40625,
      -3.40625,
      1.28125,
      -0.302734375,
      -1.03125,
      0.16796875,
      -0.486328125,
      -0.578125,
      -1.6796875,
      0.4453125,
      -0.86328125,
      0.10986328125,
      -2.3125,
      -2.046875,
      1.140625,
      2.71875,
      -0.302734375,
      1.8359375,
      2.109375,
      5.46875,
      -0.73046875,
      1.0625,
      1.7265625,
      3.59375,
      5.625,
      1.6015625,
      -5.09375,
      -2.953125,
      0.8125,
      2.453125,
      2.34375,
      -0.486328125,
      1.796875,
      4.625,
      -0.6875,
      0.4453125,
      -4.6875,
      0.02490234375,
      3.15625,
      1.3203125,
      4.6875,
      -1.5390625,
      -0.7109375,
      -1.9453125,
      -1.9609375,
      2.453125,
      2.46875,
      2.9375,
      2.421875,
      2.546875,
      -0.01397705078125,
      1.6484375,
      0.298828125,
      2.796875,
      -1.203125,
      0.765625,
      2.34375,
      -1.5546875,
      -1.7578125,
      1.9921875,
      -3.296875,
      1.75,
      -1.1484375,
      2.296875,
      3.171875,
      -0.9921875,
      -1.3046875,
      0.021484375,
      -0.9140625,
      4.3125,
      -1.1171875,
      -0.171875,
      -2.4375,
      1.125,
      0.037109375,
      -1.3828125,
      0.86328125,
      -3.8125,
      1.8671875,
      0.333984375,
      -1.125,
      -1.1015625,
      -2.59375,
      -2.703125,
      -1.328125,
      -1.7421875,
      -0.99609375,
      -2.265625,
      5,
      -2.765625,
      -1.6171875,
      0.73828125,
      4.59375,
      0.1201171875,
      6.5625,
      -0.384765625,
      2.828125,
      -1.3515625,
      -1.1953125,
      -0.80859375,
      -4.3125,
      -2.921875,
      -0.11181640625,
      0.3984375,
      -0.2197265625,
      -0.55078125,
      -1.453125,
      -1.171875,
      3.609375,
      -0.515625,
      -3.703125,
      -2.0625,
      2.671875,
      -0.9765625,
      0.70703125,
      -3.59375,
      0.2490234375,
      -0.7578125,
      -1.5390625,
      1.234375,
      -0.396484375,
      0.8984375,
      0.70703125,
      -0.032470703125,
      -2.734375,
      -0.8984375,
      0.55078125,
      -3.4375,
      -0.40625,
      4.9375,
      -1.5859375,
      0.08642578125,
      -0.4609375,
      4.15625,
      0.1123046875,
      2.203125,
      -2.515625,
      -1.2734375,
      2.546875,
      4.1875,
      3.171875,
      1.609375,
      0.087890625,
      3.46875,
      -3.828125,
      -1.203125,
      -0.427734375,
      -4.34375,
      -0.318359375,
      3.203125,
      -4.09375,
      0.0517578125,
      -1.6328125,
      0.28125,
      -0.6015625,
      -2.625,
      2.78125,
      -2.875,
      -0.50390625,
      3.65625,
      -1.9453125,
      -0.921875,
      -3.234375,
      1.7421875,
      -4.25,
      0.361328125,
      -2.734375,
      -2.4375,
      0.52734375,
      1.65625,
      -0.3203125,
      3,
      0.3984375,
      0.314453125,
      5.21875,
      2.3125,
      3.09375,
      1.2421875,
      -0.625,
      1.2421875,
      -1.5078125,
      3.34375,
      -0.2314453125,
      -2.671875,
      0.84375,
      -2.84375,
      -1.515625,
      -0.546875,
      3.453125,
      0.4765625,
      -0.046630859375,
      -0.8515625,
      1.5703125,
      1.90625,
      -0.76171875,
      3.734375,
      -0.9765625,
      0.5546875,
      -3.875,
      0.28515625,
      -0.87890625,
      3.359375,
      3.3125,
      2.046875,
      -0.7578125,
      -2.03125,
      2.453125,
      -1.7578125,
      2.015625,
      0.4921875,
      -4.75,
      -2.203125,
      -1.375,
      -1.1484375,
      -0.54296875,
      -1.8515625,
      -0.11181640625,
      -0.478515625,
      -0.2431640625,
      2.65625,
      -0.330078125,
      -2.234375,
      -0.9375,
      0.83203125,
      2.125,
      -0.08154296875,
      1.1484375,
      -1.3359375,
      3.34375,
      0.39453125,
      -0.71484375,
      2,
      2.203125,
      -1.0390625,
      -2.390625,
      -0.08154296875,
      -3.734375,
      -1.484375,
      2.59375,
      1.6875,
      1.90625,
      -0.703125,
      0.10302734375,
      3.6875,
      0.77734375
    ],
    "suggested_tags": [
      "教育AI",
      "对话系统",
      "问答系统",
      "LLM应用",
      "模块化设计"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.95,
        "reason": "论文聚焦于开发虚拟教学助手，应用于在线教育场景，解决学生问答和教学支持问题"
      },
      {
        "name": "对话系统",
        "confidence": 0.9,
        "reason": "基于ChatGPT构建的对话式AI代理，具备多轮对话和上下文理解能力"
      },
      {
        "name": "问答系统",
        "confidence": 0.85,
        "reason": "核心功能是基于课程材料的问答任务，支持文档检索和知识验证"
      },
      {
        "name": "LLM应用",
        "confidence": 0.8,
        "reason": "利用ChatGPT等大语言模型实现零样本学习，无需训练即可处理多文档问答"
      },
      {
        "name": "模块化设计",
        "confidence": 0.75,
        "reason": "采用基于技能的架构设计，支持API集成和功能扩展，提升系统灵活性"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283217596",
          "title": "Intelligent teaching design assistant for primary mathematics: A large language model-driven framework with retrieval-augmented generation and problem-chain pedagogy",
          "authors": [
            "Danna Tang",
            "Ran Ding",
            "Meng He",
            "Yushen Wang",
            "Kaka Cheng"
          ],
          "year": 2026,
          "venue": "International Electronic Journal of Mathematics Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283624085",
          "title": "From knowledge gaps to learning opportunities: Leveraging student questions and dual use of generative AI to support student learning at scale",
          "authors": [
            "Stanislav Pozdniakov",
            "Jonathan Brazil",
            "Oleksandra Poquet",
            "Stephan Krusche",
            "Santiago Berrezueta-Guzman",
            "Shazia Sadiq",
            "Hassan Khosravi"
          ],
          "year": 2025,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283213277",
          "title": "How college students use ChatGPT",
          "authors": [
            "N. M. Mohammad",
            "Matthew Demers",
            "Erin McCubbin",
            "Jackson Mitchell",
            "Sara M. Fulmer"
          ],
          "year": 2025,
          "venue": "Pedagogical Research",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281421061",
          "title": "Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments",
          "authors": [
            "Li Siyan",
            "Zhen Xu",
            "Vethavikashini Chithrra Raghuram",
            "Xuanming Zhang",
            "Renzhe Yu",
            "Zhou Yu"
          ],
          "year": 2025,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281332933",
          "title": "Perspectives and potential issues in using artificial intelligence for computer science education",
          "authors": [
            "Juho Vepsäläinen",
            "Petri Juntunen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280420389",
          "title": "From Misunderstandings to Learning Opportunities: Leveraging Generative AI in Discussion Forums to Support Student Learning",
          "authors": [
            "Stanislav Pozdniakov",
            "Jonathan Brazil",
            "Oleksandra Poquet",
            "Stephan Krusche",
            "Santiago Berrezueta-Guzman",
            "Shazia Sadiq",
            "Hassan Khosravi"
          ],
          "year": 2025,
          "venue": "International Conference on Artificial Intelligence in Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280635533",
          "title": "Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment",
          "authors": [
            "Farzana Zahid",
            "Anjalika Sewwandi",
            "Lee Brandon",
            "Vimal Kumar",
            "Roopak Sinha"
          ],
          "year": 2025,
          "venue": "High-Confidence Computing",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282394325",
          "title": "The Effects of Chatbot Placement, Personification, and Functionality on Student Outcomes in a Global CS1 Course",
          "authors": [
            "Sierra Wang",
            "Thomas Jefferson",
            "Chris Piech",
            "John C. Mitchell"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282396045",
          "title": "Scaling Effective AI-Generated Explanations for Middle School Mathematics in Online Learning Platforms",
          "authors": [
            "Eamon Worden",
            "Kirk P. Vanacore",
            "Aaron Haim",
            "Neil T. Heffernan"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280294670",
          "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education",
          "authors": [
            "Jaroslaw A. Chudziak",
            "Adam Kostka"
          ],
          "year": 2025,
          "venue": "International Conference on Artificial Intelligence in Education",
          "citation_count": 4
        }
      ],
      "citations_fetched_at": "2025-12-16T18:44:55.853630",
      "references": [
        {
          "external_id": "CorpusId:265456807",
          "title": "Comprehensive Assessment of Toxicity in ChatGPT",
          "authors": [
            "Boyang Zhang",
            "Xinyue Shen",
            "Waiman Si",
            "Zeyang Sha",
            "Zeyuan Chen",
            "Ahmed Salem",
            "Yun Shen",
            "Michael Backes",
            "Yang Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:258841157",
          "title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia",
          "authors": [
            "Sina J. Semnani",
            "Violet Z. Yao",
            "He Zhang",
            "M. Lam"
          ],
          "year": 2023,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 101
        },
        {
          "external_id": "CorpusId:257219404",
          "title": "LLaMA: Open and Efficient Foundation Language Models",
          "authors": [
            "Hugo Touvron",
            "Thibaut Lavril",
            "Gautier Izacard",
            "Xavier Martinet",
            "M. Lachaux",
            "Timothée Lacroix",
            "Baptiste Rozière",
            "Naman Goyal",
            "Eric Hambro",
            "Faisal Azhar",
            "Aur'elien Rodriguez",
            "Armand Joulin",
            "Edouard Grave",
            "Guillaume Lample"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 17220
        },
        {
          "external_id": "CorpusId:251371664",
          "title": "A Holistic Approach to Undesired Content Detection in the Real World",
          "authors": [
            "Todor Markov",
            "Chong Zhang",
            "Sandhini Agarwal",
            "Tyna Eloundou",
            "Teddy Lee",
            "Steven Adler",
            "Angela Jiang",
            "L. Weng"
          ],
          "year": 2022,
          "venue": "AAAI Conference on Artificial Intelligence",
          "citation_count": 323
        },
        {
          "external_id": "CorpusId:250391085",
          "title": "Re2G: Retrieve, Rerank, Generate",
          "authors": [
            "Michael R. Glass",
            "Gaetano Rossiello",
            "Md. Faisal Mahbub Chowdhury",
            "Ankita Rajaram Naik",
            "Pengshan Cai",
            "A. Gliozzo"
          ],
          "year": 2022,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 130
        },
        {
          "external_id": "CorpusId:246426909",
          "title": "Training language models to follow instructions with human feedback",
          "authors": [
            "Long Ouyang",
            "Jeff Wu",
            "Xu Jiang",
            "Diogo Almeida",
            "Carroll L. Wainwright",
            "Pamela Mishkin",
            "Chong Zhang",
            "Sandhini Agarwal",
            "Katarina Slama",
            "Alex Ray",
            "John Schulman",
            "Jacob Hilton",
            "Fraser Kelton",
            "Luke E. Miller",
            "Maddie Simens",
            "Amanda Askell",
            "Peter Welinder",
            "P. Christiano",
            "Jan Leike",
            "Ryan J. Lowe"
          ],
          "year": 2022,
          "venue": "Neural Information Processing Systems",
          "citation_count": 16892
        },
        {
          "external_id": "CorpusId:247058801",
          "title": "A New Generation of Perspective API: Efficient Multilingual Character-level Transformers",
          "authors": [
            "Alyssa Lees",
            "Vinh Q. Tran",
            "Yi Tay",
            "Jeffrey Scott Sorensen",
            "Jai Gupta",
            "Donald Metzler",
            "Lucy Vasserman"
          ],
          "year": 2022,
          "venue": "Knowledge Discovery and Data Mining",
          "citation_count": 247
        },
        {
          "external_id": "CorpusId:246652372",
          "title": "Survey of Hallucination in Natural Language Generation",
          "authors": [
            "Ziwei Ji",
            "Nayeon Lee",
            "Rita Frieske",
            "Tiezheng Yu",
            "D. Su",
            "Yan Xu",
            "Etsuko Ishii",
            "Yejin Bang",
            "Delong Chen",
            "Wenliang Dai",
            "Andrea Madotto",
            "Pascale Fung"
          ],
          "year": 2022,
          "venue": "ACM Computing Surveys",
          "citation_count": 3304
        },
        {
          "external_id": "CorpusId:246472929",
          "title": "A Survey on Retrieval-Augmented Text Generation",
          "authors": [
            "Huayang Li",
            "Yixuan Su",
            "Deng Cai",
            "Yan Wang",
            "Lemao Liu"
          ],
          "year": 2022,
          "venue": "arXiv.org",
          "citation_count": 255
        },
        {
          "external_id": "CorpusId:245334864",
          "title": "The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus",
          "authors": [
            "Aleksandra Piktus",
            "F. Petroni",
            "Yizhong Wang",
            "Vladimir Karpukhin",
            "Dmytro Okhonko",
            "Samuel Broscheit",
            "Gautier Izacard",
            "Patrick Lewis",
            "Barlas Ouguz",
            "Edouard Grave",
            "Wen-tau Yih",
            "Sebastian Riedel"
          ],
          "year": 2021,
          "venue": "arXiv.org",
          "citation_count": 75
        }
      ],
      "references_fetched_at": "2025-12-16T18:44:56.671666"
    }
  },
  "2c6ea33c-9a9e-4547-949a-69351fc70f65": {
    "id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
    "filename": "2405.13001v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/2c6ea33c-9a9e-4547-949a-69351fc70f65_2405.13001v1.pdf",
    "status": "completed",
    "created_at": "2025-12-16 19:02:16.206608",
    "updated_at": "2025-12-16 11:03:36.112706",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Large Language Models for Education: A Survey",
    "markdown_content": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642–652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123–159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855–5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., Suwała, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69–80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1–35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190–200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Å., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1–24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776–5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., Gašević, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279–297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512–527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831–833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
    "arxiv_id": "2405.13001",
    "error_message": null,
    "embedding": [
      0.671875,
      -2,
      -1.1484375,
      -2.703125,
      -0.2734375,
      1.1484375,
      -1.9296875,
      -2.484375,
      -0.828125,
      2.390625,
      2.4375,
      2.421875,
      2.46875,
      2.546875,
      0.76953125,
      3.328125,
      -1.765625,
      -0.490234375,
      1.765625,
      -5.78125,
      -0.1318359375,
      0.9921875,
      0.578125,
      -4.90625,
      4.5625,
      -7.1875,
      -3.234375,
      4.21875,
      1.9609375,
      0.5625,
      8.125,
      -3.953125,
      0.173828125,
      0.49609375,
      -1.09375,
      0.26953125,
      -2.5,
      -1.15625,
      4.21875,
      3.453125,
      -7.15625,
      1.8125,
      0.197265625,
      5.15625,
      -0.11962890625,
      3.109375,
      0.86328125,
      0.59765625,
      -6.78125,
      -1.671875,
      -5,
      -1.6484375,
      7.53125,
      0.15234375,
      3.203125,
      -3.1875,
      -5.6875,
      5.28125,
      -3.9375,
      -0.384765625,
      1.8671875,
      0.30078125,
      0.447265625,
      -1.125,
      5.5,
      3.046875,
      0.53515625,
      0.73828125,
      -2.109375,
      2.09375,
      0.96484375,
      2.546875,
      5.5625,
      -3.859375,
      7.78125,
      6.78125,
      3.484375,
      2.546875,
      -2.34375,
      3.59375,
      -5.875,
      5.4375,
      5.15625,
      -1.359375,
      5.09375,
      2.984375,
      1.328125,
      0.091796875,
      -2.734375,
      1.359375,
      -0.39453125,
      0.60546875,
      -4.8125,
      0.357421875,
      -3.5625,
      4.6875,
      -1.28125,
      -3.1875,
      -5.84375,
      0.61328125,
      -2.203125,
      -0.859375,
      0.3203125,
      -7,
      -4.53125,
      -3.78125,
      -3.671875,
      -6.96875,
      0.06591796875,
      -1.875,
      -0.1884765625,
      3.140625,
      1.25,
      -2.390625,
      4.8125,
      -0.0281982421875,
      1.0859375,
      -3.234375,
      -5.46875,
      -1.1796875,
      1.1484375,
      -0.224609375,
      -1.6796875,
      0.9921875,
      2.5,
      1.6875,
      -4.25,
      3.28125,
      6.53125,
      -3.4375,
      4.65625,
      -0.052490234375,
      5.125,
      -2.390625,
      -8.9375,
      -1.6796875,
      -5.125,
      3.46875,
      1.1875,
      3.9375,
      -5.53125,
      -1.03125,
      -2.484375,
      -7.875,
      2.59375,
      1.6875,
      -7.375,
      -1.2890625,
      3.625,
      -4.15625,
      0.380859375,
      1.0703125,
      0.96484375,
      7.9375,
      0.171875,
      -2.84375,
      2.296875,
      1.7265625,
      0.51171875,
      -2.03125,
      -0.0166015625,
      2.703125,
      0.099609375,
      0.6796875,
      -0.0152587890625,
      -0.8046875,
      -5.3125,
      1.1171875,
      0.80859375,
      -1.0703125,
      0.96484375,
      15.125,
      1.296875,
      -1.890625,
      1.65625,
      0.70703125,
      -1.25,
      9.625,
      2.265625,
      0.427734375,
      0.89453125,
      2.0625,
      -3.234375,
      3.78125,
      -1.3828125,
      1.5078125,
      3.0625,
      -3.90625,
      2.0625,
      -2.0625,
      0.466796875,
      4.46875,
      4.53125,
      1.1796875,
      -4.5625,
      0.828125,
      4.5625,
      -1.234375,
      0.006561279296875,
      1.5703125,
      -1.1640625,
      -10.4375,
      -0.71875,
      -1.90625,
      -5.8125,
      -2.203125,
      1.1953125,
      -4.46875,
      1.1875,
      -1.2734375,
      -1.015625,
      2.125,
      2.546875,
      -0.3125,
      7.34375,
      2.359375,
      2.25,
      -2.53125,
      4.59375,
      1.0078125,
      4.28125,
      4.875,
      2.625,
      0.40234375,
      -0.1796875,
      2.109375,
      2.9375,
      3.015625,
      2.046875,
      8.125,
      -0.25390625,
      4.15625,
      4.6875,
      -4.40625,
      -3.4375,
      -0.93359375,
      -4.25,
      -0.54296875,
      -2.453125,
      1.7109375,
      -3.5,
      -4.03125,
      0.1982421875,
      2.953125,
      1.3984375,
      -0.83203125,
      -0.5234375,
      -2.046875,
      0.462890625,
      -8.3125,
      0.2353515625,
      4.25,
      -9.8125,
      -3.5625,
      4.65625,
      6.875,
      0.87890625,
      -0.26953125,
      0.78515625,
      -4.96875,
      3.125,
      -2.1875,
      -5.3125,
      1.890625,
      0.79296875,
      -4.0625,
      4.15625,
      0.6015625,
      1.671875,
      3.140625,
      1.2265625,
      0.9921875,
      -4.4375,
      1.65625,
      -3.484375,
      4.65625,
      2.171875,
      -3.828125,
      0.93359375,
      -2.296875,
      -6.9375,
      -9.4375,
      4.03125,
      -4,
      2.46875,
      -0.78515625,
      -0.72265625,
      6.15625,
      -2.21875,
      12.625,
      1.5,
      1.703125,
      0.734375,
      0.0172119140625,
      -1.90625,
      1.1328125,
      -1.484375,
      0.1708984375,
      -4.75,
      1.390625,
      4.3125,
      -0.2451171875,
      -1.7265625,
      -2.75,
      -0.1435546875,
      2.5,
      -0.984375,
      -4.28125,
      1.328125,
      4.53125,
      0.298828125,
      1.46875,
      5.28125,
      -3.765625,
      3.484375,
      -4.46875,
      -2.9375,
      3.46875,
      2.03125,
      -2.421875,
      -7.375,
      -3.828125,
      -2.21875,
      -2.640625,
      -2.640625,
      -4.46875,
      1.484375,
      -0.0869140625,
      5.625,
      2.140625,
      1.5234375,
      0.625,
      -6.4375,
      -8.25,
      6.84375,
      -3.703125,
      3.34375,
      1.546875,
      -0.76171875,
      2.640625,
      -0.36328125,
      -1.671875,
      1.3359375,
      -3.75,
      -2.078125,
      -0.51953125,
      4.90625,
      -1.5703125,
      3.21875,
      -6.40625,
      4.75,
      2.890625,
      1.40625,
      4.21875,
      7.40625,
      -1.390625,
      2.3125,
      -1.84375,
      -1.7265625,
      1.2421875,
      0.482421875,
      -3.25,
      7.59375,
      0.2060546875,
      -2.609375,
      -3.875,
      -2.875,
      2.625,
      -0.85546875,
      -1.25,
      -2.234375,
      -2.359375,
      0.8984375,
      3.3125,
      0.703125,
      1.6875,
      1.7890625,
      -3.28125,
      -4.1875,
      2.25,
      -1.484375,
      1.578125,
      -0.2265625,
      3.484375,
      4.25,
      1.4296875,
      -0.87890625,
      5.09375,
      1.40625,
      -3.484375,
      -2.046875,
      0.87109375,
      -3.609375,
      1.4765625,
      4.1875,
      1.09375,
      -2.171875,
      2.203125,
      -0.58984375,
      -3.6875,
      4.59375,
      -1.3828125,
      -0.3359375,
      -1.703125,
      -1.8984375,
      -1.4140625,
      2.28125,
      -7.25,
      1.4609375,
      -0.384765625,
      -1.2421875,
      1.0859375,
      -1.046875,
      2.359375,
      -0.6796875,
      4.40625,
      -2.765625,
      1.875,
      -7.53125,
      -0.765625,
      -3.515625,
      -2.078125,
      1.6484375,
      -1.765625,
      1.734375,
      -0.04931640625,
      0.32421875,
      4.6875,
      2.1875,
      0.154296875,
      -0.0888671875,
      1.9296875,
      -3.984375,
      1.1640625,
      -0.703125,
      -5.90625,
      1.1640625,
      -5.125,
      -4.8125,
      2.6875,
      3.359375,
      -0.1376953125,
      6.65625,
      4.65625,
      -2.546875,
      -3.34375,
      2.046875,
      2.625,
      -4.5625,
      -2.375,
      1.6328125,
      -1.453125,
      0.6484375,
      -0.65625,
      2.96875,
      0.353515625,
      -1.828125,
      2.84375,
      0.94140625,
      0.0146484375,
      0.8359375,
      -1.28125,
      0.515625,
      1.4375,
      1.5390625,
      1.1640625,
      -2.671875,
      6.25,
      6.65625,
      -6.65625,
      -8.4375,
      2.609375,
      0.6875,
      -1.7421875,
      -1.390625,
      3.328125,
      1.5546875,
      0.486328125,
      -5.5,
      -4.96875,
      -1.53125,
      -0.83984375,
      4.625,
      3.0625,
      0.283203125,
      -3.390625,
      -3.8125,
      4.53125,
      -2.390625,
      4.15625,
      0.271484375,
      -1.4765625,
      0.62890625,
      -4.03125,
      4.90625,
      0.765625,
      5.71875,
      -4.6875,
      -0.41015625,
      3.5,
      -9.375,
      -0.43359375,
      -3.171875,
      -0.1318359375,
      -0.5859375,
      -0.455078125,
      5.125,
      -3.640625,
      0.1533203125,
      0.79296875,
      5.96875,
      -2.390625,
      -0.93359375,
      2.5,
      -7.09375,
      -2.34375,
      1.0703125,
      2.4375,
      2.53125,
      -1.9375,
      -4.84375,
      0.353515625,
      -0.212890625,
      -0.5234375,
      -2.25,
      -1.0390625,
      -3.25,
      -1.9296875,
      1.6015625,
      3.671875,
      2.234375,
      0.2060546875,
      -0.8515625,
      -3.703125,
      -2.578125,
      -0.98828125,
      1.5234375,
      -0.357421875,
      1.234375,
      0.333984375,
      2.6875,
      3.421875,
      -2.546875,
      -1.484375,
      -1.28125,
      3.203125,
      -2.875,
      1.6953125,
      0.55078125,
      1.921875,
      3.375,
      2.078125,
      -1.3515625,
      -1.59375,
      0.6875,
      -1.8515625,
      -4.65625,
      -1.453125,
      4.6875,
      -0.78515625,
      0.00689697265625,
      -4.90625,
      0.76953125,
      0.71484375,
      1.8984375,
      -0.70703125,
      0.10595703125,
      6.21875,
      1.28125,
      0.255859375,
      2.203125,
      5.8125,
      -2.34375,
      0.68359375,
      0.57421875,
      1.171875,
      -7.21875,
      -7.4375,
      -3.734375,
      3.578125,
      8.4375,
      -0.1181640625,
      5.15625,
      -5.03125,
      4.84375,
      0.2890625,
      0.2412109375,
      -14.6875,
      2.515625,
      0.8203125,
      -5.71875,
      -2.625,
      0.111328125,
      4.71875,
      -0.91015625,
      4.03125,
      -0.91015625,
      -0.99609375,
      1.3828125,
      3.96875,
      -1.0078125,
      -2.234375,
      6.09375,
      3.828125,
      -3.59375,
      2.46875,
      -1.8046875,
      -4.9375,
      0.30078125,
      0.09619140625,
      2.671875,
      4.09375,
      6.875,
      -0.392578125,
      1.1640625,
      4.25,
      -4.8125,
      -0.404296875,
      1.4921875,
      0.8125,
      -2.90625,
      1.6484375,
      -5.65625,
      1.3046875,
      -3.78125,
      1.0859375,
      0.053466796875,
      -3.046875,
      0.1689453125,
      4.15625,
      -1.921875,
      -1.7734375,
      -1.3515625,
      1.328125,
      3.140625,
      5.625,
      -6.5625,
      0.91015625,
      0.4921875,
      0.255859375,
      2.609375,
      -2.203125,
      -0.75390625,
      -3.203125,
      3.03125,
      1.03125,
      -2.703125,
      5.03125,
      -0.734375,
      -5.375,
      3.125,
      0.60546875,
      -1.171875,
      -0.0625,
      3.09375,
      0.265625,
      0.09521484375,
      -0.390625,
      2.203125,
      1.1328125,
      -3.9375,
      -2.890625,
      -0.76171875,
      -2.34375,
      3.890625,
      -0.9609375,
      -2.9375,
      -3.28125,
      -4.0625,
      1.2890625,
      1.8828125,
      3.078125,
      1.125,
      2.25,
      3.203125,
      -4.5,
      0.5,
      -4.71875,
      -3.90625,
      1.2734375,
      -3.59375,
      -2.015625,
      0.9453125,
      1.0390625,
      2.171875,
      -1.1640625,
      -1.53125,
      -3.75,
      -4.40625,
      -2.1875,
      1.2109375,
      1.3359375,
      2.234375,
      -1.109375,
      6.125,
      -0.62890625,
      -2.796875,
      0.12255859375,
      -1.40625,
      -0.146484375,
      -1.015625,
      1.3671875,
      -5.625,
      -0.66015625,
      5.875,
      1.375,
      -3.328125,
      6.25,
      -0.58984375,
      -0.9921875,
      -1.7578125,
      2.703125,
      -0.5078125,
      -0.474609375,
      0.8046875,
      -3.90625,
      -2.765625,
      -3.8125,
      -0.032470703125,
      -1.3203125,
      3.28125,
      0.56640625,
      0.70703125,
      -0.96484375,
      -7.875,
      2.84375,
      0.2236328125,
      -0.349609375,
      2.375,
      5.84375,
      -0.65625,
      -1.2421875,
      2.515625,
      0.74609375,
      -0.79296875,
      -0.8671875,
      -4.0625,
      4.375,
      2.328125,
      3.765625,
      -3.96875,
      -6.3125,
      -0.3671875,
      -1.09375,
      -1.6640625,
      4.625,
      -0.6875,
      -0.392578125,
      5.34375,
      2.484375,
      -4.90625,
      -2.125,
      5.4375,
      -3.796875,
      0.984375,
      2.34375,
      2.828125,
      0.408203125,
      4.21875,
      -1.6953125,
      -2.84375,
      -0.921875,
      5.75,
      2.890625,
      -1.109375,
      -0.76171875,
      3.859375,
      0.2421875,
      4.46875,
      -6,
      -5.15625,
      0.90625,
      0.90625,
      -1.984375,
      0.021484375,
      6.4375,
      -1.84375,
      0.181640625,
      0.470703125,
      -0.1884765625,
      3.375,
      1.3828125,
      1.0390625,
      0.1123046875,
      1.703125,
      1.484375,
      0.84765625,
      1.9453125,
      -1.1953125,
      -0.330078125,
      -1.1640625,
      0.408203125,
      -1.9296875,
      3.5625,
      -3.78125,
      0.6328125,
      -1.609375,
      3.765625,
      -0.265625,
      5.75,
      5.09375,
      0.07177734375,
      0.54296875,
      -0.84375,
      6.875,
      -1.6015625,
      6.53125,
      1.3671875,
      8.5,
      -2.359375,
      -3.625,
      1.4296875,
      0.1787109375,
      -0.98046875,
      0.87890625,
      -6.9375,
      -1.9296875,
      -1.375,
      -0.11474609375,
      -0.82421875,
      2.796875,
      -5.15625,
      -0.8046875,
      3.265625,
      3.671875,
      3.890625,
      2.90625,
      4.84375,
      0.9296875,
      0.80859375,
      -3.15625,
      -1.828125,
      0.466796875,
      0.5390625,
      3.578125,
      -4.03125,
      0.984375,
      1.546875,
      5.40625,
      -0.055908203125,
      -3.140625,
      -3.234375,
      7.375,
      2.15625,
      -2.296875,
      1.8671875,
      -1.6015625,
      0.94921875,
      0.984375,
      3.875,
      -5.625,
      -3.0625,
      6.75,
      5.03125,
      -0.828125,
      3.265625,
      0.09033203125,
      2.171875,
      -3.46875,
      -0.9296875,
      0.03173828125,
      -0.054931640625,
      -4.15625,
      -3,
      0.62890625,
      3.96875,
      -4.78125,
      1.9765625,
      0.96875,
      -2.75,
      2.328125,
      1.0625,
      -2.234375,
      1.6640625,
      0.2314453125,
      6.75,
      0.5234375,
      -5.8125,
      -4.59375,
      -7.34375,
      -3.96875,
      0.208984375,
      2.125,
      2.796875,
      2.15625,
      -3.375,
      2.65625,
      -5.1875,
      -1.1171875,
      -4.78125,
      3.6875,
      3.59375,
      -4.75,
      -2.5,
      -2,
      -7.875,
      -3.8125,
      -0.94921875,
      -1.34375,
      -2.609375,
      -5.625,
      -2.015625,
      2.453125,
      -5.03125,
      -1,
      -2.03125,
      -1.25,
      4.28125,
      -0.296875,
      0.74609375,
      -4.5625,
      4.875,
      1.71875,
      -2.296875,
      5.3125,
      1.953125,
      2.6875,
      2.15625,
      0.1494140625,
      -0.11669921875,
      -4.71875,
      4.09375,
      -1.5390625,
      9.0625,
      4.09375,
      1.875,
      -4.65625,
      4.3125,
      1.84375,
      1.4921875,
      -4.46875,
      -0.76953125,
      -2.5,
      2.234375,
      1.671875,
      -1.203125,
      2.34375,
      -2.578125,
      -1.5,
      0.859375,
      -2.390625,
      -0.46484375,
      3.25,
      -0.01519775390625,
      4.375,
      1.6171875,
      0.482421875,
      0.1728515625,
      0.2216796875,
      1.6875,
      -0.51953125,
      5.8125,
      -5.125,
      2.359375,
      -5.3125,
      -0.96875,
      0.78125,
      -1.1796875,
      -0.69140625,
      -0.41015625,
      -0.30078125,
      1.765625,
      2.828125,
      1.6953125,
      1.1015625,
      4.78125,
      -2.765625,
      -0.09423828125,
      0.72265625,
      -2.421875,
      4.9375,
      -0.0634765625,
      -1.0234375,
      -0.8359375,
      -0.7890625,
      -0.310546875,
      1.28125,
      0.85546875,
      -7.90625,
      -1.3828125,
      -1.296875,
      -4.1875,
      7.09375,
      0.921875,
      -0.73828125,
      1.4453125,
      4.0625,
      6.21875,
      3.765625,
      -0.92578125,
      -1.109375,
      -0.25,
      -2.265625,
      3.875,
      -2.15625,
      -0.65234375,
      4.34375,
      3.84375,
      3.546875,
      -0.9453125,
      -0.62109375,
      -2.796875,
      0.1015625,
      4.90625,
      -1.765625,
      -1.0546875,
      6.6875,
      -2.90625,
      0.12353515625,
      -2.015625,
      -2.59375,
      -1.9296875,
      -1.6328125,
      2.671875,
      2.25,
      2.4375,
      -2.046875,
      -2.53125,
      -7.71875,
      1.9453125,
      -0.1533203125,
      -0.984375,
      -1.171875,
      1.6875,
      -0.2138671875,
      1.4921875,
      -2.078125,
      -2.0625,
      -0.302734375,
      -3.859375,
      -0.0361328125,
      2.765625,
      0.0966796875,
      1.3828125,
      -0.341796875,
      2.84375,
      -2.140625,
      2.484375,
      3.828125,
      -5.625,
      2.140625,
      0.90234375,
      -1.71875,
      3.6875,
      1.9765625,
      1.4140625,
      2.734375,
      -1.2578125,
      0.78125,
      -0.44921875,
      -1.734375,
      1.0625,
      -3,
      0.5859375,
      1.8984375,
      3.375,
      -2.34375,
      3.09375,
      0.8515625,
      -4.34375,
      3.6875,
      -3.59375,
      -7.15625,
      -1.046875,
      0.033935546875,
      -0.8828125,
      -1.4140625,
      -2.3125,
      1.2265625,
      2.671875,
      -7.375,
      5.6875,
      -1.5390625,
      5.4375,
      2.734375,
      -1.0625,
      -2.8125,
      0.69140625,
      2.234375,
      -1.5703125,
      2.28125,
      1.6484375,
      -1.765625,
      3.984375,
      -3.34375,
      1.3984375,
      -0.95703125,
      0.55859375,
      3.21875,
      -1.0703125,
      0.86328125,
      -0.134765625,
      1.0546875,
      -9.5625,
      -3.4375,
      -1.9765625,
      -0.353515625,
      1.9375,
      -0.6015625,
      2.3125,
      -2.859375,
      2.53125,
      -4.03125,
      2.984375,
      -5.1875,
      -3.171875,
      1.7109375,
      -1.9453125,
      4.53125,
      2.109375,
      -2.3125,
      0.205078125,
      0.359375,
      -4.46875,
      -2.140625,
      -2.6875,
      0.02392578125,
      -3.09375,
      -1.9296875,
      -0.35546875,
      2.84375,
      -0.2001953125,
      1.84375,
      -0.875,
      3.140625,
      4.09375,
      -0.59375,
      3.015625,
      0.5078125,
      0.54296875,
      -3.125,
      -4.28125,
      -4.53125,
      2.078125,
      3.71875,
      -3.203125,
      2.46875,
      -0.96875,
      2,
      2,
      -0.83984375,
      -0.15625,
      1.1328125,
      1.859375,
      -0.71484375,
      -2.03125,
      2.5,
      -1.421875,
      1.890625,
      -2.203125,
      -4.1875,
      -4.1875,
      -0.1484375,
      0.953125,
      0.220703125,
      0.9921875,
      -1.046875,
      -1.7421875,
      -1.1875,
      -4.25,
      -2.6875,
      4.875,
      0.58984375,
      5.25,
      0.60546875,
      1.171875,
      -3.078125,
      -1.1953125,
      -1.375,
      6,
      0.7578125,
      -2.75,
      3.953125,
      -2.15625,
      5.4375,
      -2.09375,
      -1.78125,
      -9.1875,
      -1.90625,
      7.125,
      2.109375,
      -0.61328125,
      1.2578125,
      0.337890625,
      2.359375,
      -0.026611328125,
      5.40625,
      -3.140625,
      -1.5546875,
      -0.296875,
      3.578125,
      1.765625,
      -5.53125,
      0.62109375,
      1.9140625,
      -1.5078125,
      1.6015625,
      5.6875,
      5.78125,
      -2.140625,
      3.421875,
      -4,
      -2.859375,
      -4.78125,
      4.15625,
      -0.7109375,
      -0.765625,
      -1.71875,
      -3.1875,
      -0.271484375,
      -1.4921875,
      0.26953125,
      7.28125,
      -4.4375,
      2.609375,
      -0.8984375,
      4.09375,
      0.90234375,
      -0.98046875,
      -0.84375,
      2.859375,
      2.671875,
      -1.03125,
      -1.1640625,
      -5.9375,
      -1.875,
      -0.59765625,
      -7.34375,
      1.9765625,
      1.734375,
      0.99609375,
      2.265625,
      -1.84375,
      2.25,
      3.15625,
      -2.515625,
      -0.80859375,
      -2.140625,
      2.8125,
      4.6875,
      1.5,
      -2.859375,
      1.2265625,
      -0.9765625,
      -0.33203125,
      -5.09375,
      3.09375,
      -1.828125,
      4.28125,
      3,
      3.078125,
      -4.125,
      -4.28125,
      -3.234375,
      -1.6640625,
      -3.78125,
      1.15625,
      0.064453125,
      1.6171875,
      3.734375,
      -0.080078125,
      -3.546875,
      -1.3828125,
      -3.90625,
      1.515625,
      -0.5625,
      1.5078125,
      -6.8125,
      2.46875,
      -6.40625,
      0.6640625,
      1.3359375,
      -3.140625,
      0.2412109375,
      3.453125,
      1.9140625,
      2.265625,
      3.765625,
      -1.5703125,
      -3.484375,
      3.5,
      -3.921875,
      -2,
      -5,
      0.275390625,
      -0.369140625,
      -4.21875,
      3.203125,
      -2.890625,
      2.265625,
      -2.4375,
      -2.96875,
      0.341796875,
      -1.09375,
      -0.5390625,
      3.515625,
      2.125,
      -2.34375,
      1.7890625,
      -1.0390625,
      5.84375,
      2.640625,
      -2.40625,
      1.6875,
      -0.33984375,
      1.7109375,
      -6.09375,
      4.25,
      0.68359375,
      -1.4375,
      3.296875,
      5.125,
      -3.234375,
      1,
      2.234375,
      5.75,
      -2.703125,
      -1.3515625,
      0.4140625,
      4.71875,
      -3.96875,
      -0.002166748046875,
      -4.09375,
      0.01531982421875,
      1.53125,
      -1.6953125,
      5.03125,
      -1.734375,
      3.8125,
      -5.0625,
      0.33203125,
      1.296875,
      1.328125,
      2.9375,
      -5.25,
      3.890625,
      2.375,
      -1.3984375,
      5.09375,
      -0.75,
      -5.46875,
      -2.28125,
      2.171875,
      -4.625,
      -3.03125,
      -5.09375,
      0.0400390625,
      -2.40625,
      -1.6796875,
      -0.7109375,
      0.37109375,
      1.09375,
      2.515625,
      -1.671875,
      -1.5546875,
      -3.109375,
      -4.375,
      1.171875,
      -2.015625,
      -6.6875,
      -0.400390625,
      2.15625,
      3.296875,
      5.53125,
      7.625,
      3.09375,
      -4.34375,
      2.640625,
      -1.515625,
      1.2265625,
      -0.09912109375,
      -0.1328125,
      -0.54296875,
      -2.921875,
      2.65625,
      0.828125,
      3.484375,
      -6.90625,
      -0.7890625,
      -4.71875,
      -1.15625,
      -0.212890625,
      0.193359375,
      -0.1796875,
      2.390625,
      4.875,
      -2.4375,
      3.84375,
      1.5234375,
      -0.1220703125,
      -5.1875,
      2.421875,
      -1.4921875,
      2.640625,
      4.5,
      0.62890625,
      -4.96875,
      6.65625,
      2.3125,
      -2.703125,
      3.015625,
      0.006561279296875,
      -3.546875,
      -3.34375,
      1.3046875,
      0.515625,
      4.0625,
      -1.078125,
      0.86328125,
      2.734375,
      -0.6015625,
      3.84375,
      2.625,
      0.73828125,
      0.259765625,
      4.46875,
      0.8203125,
      -4.9375,
      -1.3046875,
      2.421875,
      -3.296875,
      -3.984375,
      2.15625,
      -0.640625,
      2.65625,
      -0.1416015625,
      2.078125,
      1.7109375,
      6.84375,
      -4.5,
      3.046875,
      -6.125,
      0.14453125,
      -7.09375,
      2.3125,
      -8,
      2.0625,
      0.8515625,
      6.1875,
      -0.04150390625,
      -4.40625,
      3.3125,
      5.53125,
      1.90625,
      -4.5625,
      2.640625,
      2.515625,
      -0.875,
      -5.78125,
      -2.734375,
      4.3125,
      0.87890625,
      3.0625,
      -4.8125,
      1.34375,
      3.703125,
      -1.6796875,
      -5.34375,
      0.515625,
      -0.2265625,
      -6.46875,
      -5.71875,
      -2.03125,
      -0.515625,
      -1.3671875,
      2,
      4.34375,
      -1.921875,
      2.109375,
      0.47265625,
      4.1875,
      2.578125,
      -1.3046875,
      2.984375,
      0.291015625,
      -0.255859375,
      2.21875,
      3.890625,
      -2.53125,
      1.5625,
      -1.015625,
      1.09375,
      3.0625,
      -1.8671875,
      -0.24609375,
      -6.8125,
      1.71875,
      4.34375,
      2.03125,
      0.10595703125,
      -3.8125,
      -3.015625,
      2.046875,
      -1.390625,
      -3.171875,
      1.078125,
      -1.7109375,
      -0.32421875,
      1.1328125,
      -1.8828125,
      3.828125,
      0.76171875,
      -0.5078125,
      -2.09375,
      -0.69921875,
      -2.015625,
      -1.5546875,
      -3.71875,
      3.15625,
      -0.62109375,
      4.34375,
      -0.5703125,
      -4.21875,
      -2.03125,
      3.671875,
      1.1328125,
      2.375,
      -1.8203125,
      -1.2890625,
      3.1875,
      3.6875,
      1.3359375,
      -1.328125,
      0.60546875,
      1.265625,
      0.302734375,
      -3.265625,
      -1.625,
      -1.8671875,
      3.21875,
      -1.8671875,
      -1.34375,
      -2.46875,
      1.9765625,
      -1.265625,
      -8.0625,
      0.890625,
      -0.0361328125,
      -0.69921875,
      -5,
      0.396484375,
      2.296875,
      2.078125,
      4.75,
      3.234375,
      2.9375,
      -2.109375,
      2.84375,
      18.625,
      -2.734375,
      -4.9375,
      -1.71875,
      0.267578125,
      2.84375,
      8.5625,
      1.171875,
      0.0235595703125,
      -1.8359375,
      1.546875,
      4.375,
      2.828125,
      3.28125,
      0.6875,
      0.90625,
      2.71875,
      1.9375,
      -2.65625,
      -4.1875,
      -1.03125,
      2.34375,
      -0.99609375,
      3.078125,
      -2.640625,
      3.28125,
      3.296875,
      -1.5,
      -0.2275390625,
      -4.90625,
      1.1328125,
      -3.140625,
      -1.3203125,
      -5.1875,
      1.296875,
      -4.90625,
      1,
      2.03125,
      0.75390625,
      -2.125,
      -2.46875,
      -4.28125,
      3.140625,
      -0.96484375,
      -0.4609375,
      0.90625,
      -2.3125,
      1.4765625,
      -0.79296875,
      -0.7890625,
      -2.515625,
      -3.6875,
      -3.515625,
      2.25,
      0.64453125,
      -2.578125,
      0.8203125,
      -7.03125,
      -2.359375,
      -5.40625,
      -1.5703125,
      -2.3125,
      -3.375,
      -2.71875,
      -3.875,
      -2.421875,
      -2.3125,
      -0.296875,
      -0.1591796875,
      -1.4921875,
      -6,
      -0.220703125,
      5.03125,
      5.5,
      0.1552734375,
      -2.453125,
      2.71875,
      2.40625,
      2.203125,
      1.5390625,
      -0.5234375,
      3.328125,
      -2.25,
      -1.46875,
      -0.8828125,
      0.875,
      -5.34375,
      2.21875,
      0.232421875,
      -0.193359375,
      4.40625,
      -2.796875,
      2.28125,
      -0.6640625,
      -3.453125,
      -1.5,
      -0.29296875,
      3.40625,
      0.119140625,
      -0.78125,
      2.75,
      -0.466796875,
      -0.82421875,
      -2.078125,
      -0.474609375,
      -1.5859375,
      1.7734375,
      -1.625,
      1.828125,
      -0.796875,
      1.3046875,
      2.0625,
      0.80859375,
      -2.203125,
      -0.45703125,
      2.9375,
      -6.78125,
      -1.9296875,
      1.8984375,
      -0.7265625,
      4.3125,
      -2.109375,
      -3.9375,
      -0.287109375,
      -8.625,
      -5.53125,
      -1.9140625,
      -3.0625,
      3.515625,
      -2.203125,
      1.4609375,
      -1.03125,
      -1.890625,
      -1.359375,
      2.8125,
      -4.34375,
      3.703125,
      3.875,
      1.0703125,
      0.373046875,
      -2.828125,
      2.171875,
      1.1796875,
      -2.796875,
      -2.546875,
      0.8046875,
      -4.625,
      2.515625,
      5.53125,
      1.3203125,
      -3.671875,
      4.78125,
      -0.6953125,
      -3.34375,
      -2.4375,
      3.1875,
      -0.0908203125,
      -0.7265625,
      -1.3203125,
      -1.9375,
      0.63671875,
      0.51171875,
      -2.78125,
      -4.375,
      -1.90625,
      -1.953125,
      2.765625,
      -0.5703125,
      -7.15625,
      0.88671875,
      5.53125,
      -7,
      1.03125,
      -1.5703125,
      5.78125,
      -5.75,
      0.5859375,
      5.375,
      -0.26171875,
      0.66015625,
      2.203125,
      3.171875,
      -2.015625,
      -6.3125,
      1.8046875,
      4.46875,
      -2.703125,
      2.28125,
      2.9375,
      -1.484375,
      0.60546875,
      -4.15625,
      -4.65625,
      6.96875,
      5.875,
      -5.09375,
      0.6796875,
      -2.875,
      -1.2109375,
      -1.3359375,
      -5.1875,
      2.421875,
      1.296875,
      1.3203125,
      0.8203125,
      0.9296875,
      -3.734375,
      -0.8671875,
      -0.94921875,
      -2.546875,
      -2.15625,
      2.859375,
      -1.1875,
      4.09375,
      -6.03125,
      5.53125,
      3.5,
      0.68359375,
      -4.1875,
      3.28125,
      4.40625,
      0.1083984375,
      -4.53125,
      -1.4296875,
      -0.9765625,
      4.625,
      -6.375,
      4.28125,
      -3.0625,
      1.6015625,
      -1.125,
      2.3125,
      -1.3515625,
      3.171875,
      -2.9375,
      -6.0625,
      -3.546875,
      3.421875,
      1.0703125,
      1.953125,
      2.796875,
      -0.84375,
      1.109375,
      2.109375,
      -3.359375,
      1.7890625,
      -0.9375,
      -0.7734375,
      3.34375,
      -2.1875,
      0.13671875,
      -0.2197265625,
      2.390625,
      -2.46875,
      -2.9375,
      -1.7421875,
      -3.5,
      0.9921875,
      -4.28125,
      3.71875,
      3.015625,
      -7.1875,
      4.5625,
      -3.515625,
      -1.8828125,
      1.9921875,
      0.71875,
      -5.59375,
      6.125,
      4.15625,
      -4.46875,
      4.5,
      -0.1630859375,
      -2,
      0.5859375,
      -1.578125,
      0.90625,
      -5.3125,
      0.6328125,
      3.671875,
      -4.9375,
      1.1875,
      3.09375,
      -2.59375,
      -0.09326171875,
      -1.3203125,
      5.53125,
      1.1953125,
      3.375,
      0.7109375,
      2.578125,
      5.875,
      -4.15625,
      1.65625,
      -2.234375,
      -0.953125,
      -2.8125,
      -0.6640625,
      -1.265625,
      -2.171875,
      2.203125,
      3.296875,
      1.2578125,
      -9.875,
      -3.875,
      2.515625,
      -3.953125,
      3.6875,
      1.4453125,
      1.15625,
      -3.296875,
      -1.4921875,
      0.71875,
      2.78125,
      -2.0625,
      -2.75,
      -2.3125,
      3.21875,
      1.453125,
      -6.125,
      -0.72265625,
      0.455078125,
      -2.546875,
      -0.484375,
      -2,
      -2.03125,
      0.390625,
      5.59375,
      -6.03125,
      2.84375,
      1.6171875,
      3.296875,
      4.75,
      -1.4375,
      2.890625,
      3.953125,
      -3.03125,
      -7.09375,
      -1.3359375,
      0.40625,
      0.0118408203125,
      1.9140625,
      -2.953125,
      2.78125,
      0.35546875,
      3.5,
      -5.5,
      1.6796875,
      3.3125,
      -6.34375,
      4.6875,
      -3.484375,
      0.70703125,
      -1.5625,
      -5.875,
      -0.62109375,
      4.3125,
      0.578125,
      -0.033935546875,
      0.6640625,
      -1.578125,
      0.0037994384765625,
      2.609375,
      -0.984375,
      -0.98046875,
      -0.30859375,
      3.703125,
      -3.34375,
      1.671875,
      2.5625,
      0.5078125,
      -0.60546875,
      -3.515625,
      2.65625,
      -1.2890625,
      -2.78125,
      4.6875,
      5.15625,
      -1.1171875,
      -3.65625,
      -5.59375,
      1.5234375,
      -0.0771484375,
      -3.84375,
      0.52734375,
      -2.5,
      1.1875,
      -3.328125,
      1.671875,
      0.73046875,
      -5.96875,
      -3.046875,
      -3.859375,
      -1.234375,
      0.8046875,
      2.859375,
      2.1875,
      -2.1875,
      -1.8671875,
      3.953125,
      3.21875,
      -0.87890625,
      -5.03125,
      1.5546875,
      -1.1953125,
      -1.8984375,
      -3.5625,
      1.296875,
      -3.296875,
      -0.734375,
      1.7421875,
      -0.36328125,
      -0.427734375,
      -5.8125,
      -2.453125,
      1.1796875,
      -0.41015625,
      -0.00115203857421875,
      -2.640625,
      -0.146484375,
      1.9140625,
      4.40625,
      -4.0625,
      -1.1171875,
      0.58203125,
      1.7109375,
      -6.4375,
      -1.6015625,
      2.078125,
      -1.25,
      0.2578125,
      4.59375,
      1.3671875,
      1.9765625,
      1.1484375,
      -4.46875,
      -2.53125,
      5.25,
      3.765625,
      0.0201416015625,
      0.66015625,
      -1.8125,
      -2.484375,
      4.875,
      7.5625,
      -2.703125,
      -2.328125,
      -0.98828125,
      -1.8046875,
      -2.609375,
      -2.34375,
      0.0791015625,
      -0.21875,
      -7.46875,
      7.125,
      -1.8125,
      3.65625,
      1.5625,
      -4.71875,
      4.8125,
      -4.3125,
      -1.2890625,
      -0.53515625,
      0.173828125,
      3.703125,
      -3.59375,
      -1.328125,
      -3.265625,
      0.484375,
      0.6328125,
      -2.046875,
      0.2392578125,
      1.421875,
      4.375,
      -0.1552734375,
      -1.3828125,
      -1.3671875,
      -1.4375,
      5.6875,
      -1.9453125,
      -2.703125,
      0.040283203125,
      -3.28125,
      1.4453125,
      -1.734375,
      1.4140625,
      -5.15625,
      -0.9609375,
      -1.859375,
      2.0625,
      1.2109375,
      1.75,
      -0.76953125,
      -3.5,
      -1.9140625,
      4.28125,
      1.5,
      4.96875,
      1.875,
      3.53125,
      0.73046875,
      1.1640625,
      2.234375,
      3.234375,
      3.640625,
      -2.4375,
      0.61328125,
      -0.375,
      -0.2392578125,
      -0.78125,
      -1.59375,
      2.734375,
      1.3046875,
      4.6875,
      -0.7421875,
      -0.44140625,
      -3.59375,
      -2.296875,
      0.99609375,
      -1.296875,
      3.109375,
      3.0625,
      -2.1875,
      0.1845703125,
      -0.515625,
      2.875,
      0.9453125,
      4.28125,
      0.375,
      -1.9140625,
      -2.328125,
      1.1171875,
      1.796875,
      -0.45703125,
      0.6171875,
      -1.640625,
      1.421875,
      -0.59375,
      -2.953125,
      0.232421875,
      2.625,
      -2.65625,
      1.34375,
      -0.007110595703125,
      0.275390625,
      0.404296875,
      -1.9921875,
      -0.283203125,
      0.9609375,
      -0.73046875,
      4.65625,
      0.2392578125,
      -0.482421875,
      1.9296875,
      3.390625,
      -1.5859375,
      0.267578125,
      1.6875,
      -0.7578125,
      -1.4765625,
      -1.765625,
      2.296875,
      -2.5625,
      4.28125,
      -1.6640625,
      0.1826171875,
      -0.232421875,
      -1.46875,
      -3.6875,
      2.15625,
      -3.640625,
      -0.2470703125,
      -2.109375,
      0.98828125,
      2.859375,
      0.41796875,
      0.546875,
      1.046875,
      0.27734375,
      -1.75,
      -1.6015625,
      -1.7265625,
      -3.390625,
      -4.4375,
      -2.796875,
      0.953125,
      0.5859375,
      -0.5859375,
      0.80859375,
      0.287109375,
      2.09375,
      -0.044921875,
      -0.9140625,
      2.375,
      1.8203125,
      -2.59375,
      -1.75,
      1.1328125,
      -0.0810546875,
      1.1484375,
      -1.0546875,
      -2.375,
      -0.248046875,
      0.07861328125,
      -0.58203125,
      1.6953125,
      -0.431640625,
      -0.3515625,
      0.609375,
      1.109375,
      -1.625,
      1.0546875,
      0.259765625,
      2.34375,
      -0.6171875,
      0.1982421875,
      1.9296875,
      0.80078125,
      -1.3046875,
      3.0625,
      3.4375,
      -2.125,
      -0.66796875,
      -0.1982421875,
      1.359375,
      2.171875,
      -1.6953125,
      -0.99609375,
      1.7421875,
      -1.9296875,
      -2.734375,
      0.96875,
      2.09375,
      -2.28125,
      0.74609375,
      -2.515625,
      -0.9609375,
      -1.3359375,
      0.220703125,
      1.6796875,
      -0.85546875,
      -0.98046875,
      -1.890625,
      1.171875,
      1.96875,
      0.6015625,
      0.486328125,
      -1.0859375,
      -2.46875,
      -0.51171875,
      1.3671875,
      -1.46875,
      -1.6796875,
      0.40234375,
      -0.46875,
      2.375,
      0.96484375,
      0.79296875,
      -0.75390625,
      -1.265625,
      -0.435546875,
      -0.67578125,
      -0.73828125,
      -3.390625,
      1.3125,
      2.3125,
      1.140625,
      -1.25,
      -0.8515625,
      -3.265625,
      -1.5546875,
      -4.59375,
      2.0625,
      0.7421875,
      -2.84375,
      0.25,
      1.8125,
      1.265625,
      1.9765625,
      -0.404296875,
      1.203125,
      1.71875,
      -0.28125,
      2.578125,
      0.8046875,
      1.9375,
      -3.421875,
      -0.796875,
      0.01263427734375,
      0.314453125,
      0.609375,
      1.15625,
      -0.9453125,
      2.828125,
      1.1484375,
      -1.234375,
      1.84375,
      2.0625,
      1.1796875,
      1.96875,
      -3.390625,
      3.234375,
      2.421875,
      0.66796875,
      -1.2890625,
      -0.04248046875,
      0.419921875,
      0.037109375,
      -3.140625,
      0.65234375,
      -0.5703125,
      3.890625,
      0.2314453125,
      -0.55078125,
      -0.984375,
      0.9375,
      1.296875,
      -1.640625,
      0.7578125,
      -2.953125,
      2.234375,
      1.0390625,
      1.515625,
      -0.43359375,
      -0.51171875,
      -1.890625,
      2.6875,
      -5.1875,
      0.337890625,
      -0.84375,
      0.64453125,
      0.9609375,
      0.71484375,
      -1.3125,
      -2.96875,
      -1.4296875,
      1.9453125,
      -1.921875,
      2.03125,
      1.9375,
      -0.8671875,
      0.03662109375,
      2.28125,
      0.1494140625,
      0.2177734375,
      1.578125,
      -2.53125,
      1.078125,
      -0.921875,
      -1.9375,
      -3.15625,
      -1.875,
      -6.875,
      -2.203125,
      -1.546875,
      -1.578125,
      0.6171875,
      2.078125,
      0.94921875,
      0.23828125,
      -1.65625,
      1.7265625,
      3.734375,
      0.0018157958984375,
      -1.1640625,
      2.4375,
      -1.6875,
      0.66796875,
      -1.890625,
      -0.404296875,
      0.5859375,
      0.484375,
      3.234375,
      -0.50390625,
      3,
      0.66796875,
      -1.8359375,
      1.2265625,
      0.2431640625,
      -0.95703125,
      -1.3828125,
      0.1376953125,
      1.3125,
      2.125,
      3.765625,
      3.75,
      2.5625,
      -0.96875,
      -0.7109375,
      0.54296875,
      0.83203125,
      6.53125,
      0.875,
      -1.171875,
      -1.25,
      2.734375,
      1.09375,
      0.97265625,
      0.486328125,
      0.7578125,
      5.59375,
      0.89453125,
      0.2041015625,
      -1.75,
      -0.01300048828125,
      -1.078125,
      0.171875,
      5.46875,
      -4.6875,
      0.296875,
      -1.34375,
      -1.0703125,
      1.8203125,
      -0.2021484375,
      3.40625,
      0.1123046875,
      5.03125,
      1.7578125,
      0.4140625,
      0.99609375,
      1.046875,
      -0.96875,
      2.359375,
      1.4296875,
      -2.078125,
      -0.51171875,
      0.07421875,
      -0.58203125,
      2.28125,
      -1.421875,
      -0.96484375,
      2.0625,
      -2.578125,
      1.5390625,
      -0.08203125,
      1.5078125,
      2.28125,
      -1.109375,
      -1.5625,
      -3.484375,
      -1.8203125,
      1.40625,
      3.84375,
      0.62109375,
      -3.578125,
      -0.435546875,
      -0.306640625,
      -0.494140625,
      -2.015625,
      0.322265625,
      -1.875,
      -3.078125,
      -2.515625,
      -1.7578125,
      -3.359375,
      5.3125,
      -1.609375,
      2.421875,
      4.5625,
      3.296875,
      2.8125,
      2.90625,
      -0.142578125,
      3.75,
      -2.890625,
      0.345703125,
      3.765625,
      -0.4609375,
      -1.21875,
      -0.8125,
      1.25,
      -0.99609375,
      -2.84375,
      -1.21875,
      -0.5234375,
      1.671875,
      -0.455078125,
      -4.03125,
      -1.40625,
      0.054443359375,
      -3.46875,
      -1.546875,
      0.74609375,
      -2.375,
      -1.6796875,
      0.8046875,
      1.921875,
      0.2265625,
      1.609375,
      -0.19921875,
      0.322265625,
      0.6171875,
      -0.85546875,
      -2.296875,
      -1.34375,
      1.1875,
      2.078125,
      -1.6015625,
      -0.07373046875,
      -0.75,
      4.46875,
      -3.875,
      2.515625,
      -1.3828125,
      -2.0625,
      2.71875,
      9.1875,
      0.75,
      -0.228515625,
      -0.07177734375,
      0.69921875,
      -3.609375,
      1.3046875,
      0.031982421875,
      -2.953125,
      -3.375,
      3.78125,
      -1.6328125,
      1.84375,
      0.78125,
      -0.1669921875,
      0.1787109375,
      -2.625,
      0.431640625,
      -3.546875,
      -2.0625,
      3.203125,
      4.53125,
      -1.8671875,
      -0.80078125,
      1.828125,
      -4.34375,
      3.015625,
      -2.78125,
      -2.328125,
      1.328125,
      4.71875,
      -1.1796875,
      5.15625,
      0.498046875,
      -1.5859375,
      3.0625,
      0.251953125,
      1.7734375,
      2.03125,
      -2.328125,
      -0.94140625,
      -1.8828125,
      2.65625,
      -1.609375,
      -5.40625,
      -0.044677734375,
      -1.7890625,
      -0.8671875,
      -0.058837890625,
      0.024169921875,
      2.8125,
      0.1865234375,
      -0.298828125,
      2.546875,
      1.8671875,
      0.57421875,
      1.5078125,
      -0.1181640625,
      0.77734375,
      -6.34375,
      0.4765625,
      -1.25,
      0.494140625,
      0.359375,
      1.1484375,
      1.515625,
      -0.26953125,
      -0.58203125,
      -1.4140625,
      1.4921875,
      -0.5703125,
      0.82421875,
      -0.193359375,
      -0.2578125,
      -2.140625,
      0.455078125,
      -3.578125,
      2.90625,
      -2.421875,
      -2.296875,
      0.64453125,
      -1.9453125,
      -1.8125,
      -4.40625,
      1.046875,
      1.9921875,
      -0.09912109375,
      1.1640625,
      -0.009033203125,
      2.59375,
      -2.6875,
      1.8515625,
      0.9375,
      1.046875,
      1.109375,
      -1.6640625,
      -0.86328125,
      -3.921875,
      1.65625,
      -1.3203125,
      0.62890625,
      4.125,
      -1.75,
      -2.984375,
      2.546875,
      1.5
    ],
    "summary": "对大型语言模型在教育领域的应用进行全面系统的梳理和分析，总结当前技术现状、挑战和未来发展方向",
    "structure": {
      "sections": [
        {
          "title": "Large Language Models for Education: A Survey",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ARTICLE INFO",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 18
        },
        {
          "title": "1. Introduction",
          "level": 1,
          "start_line": 22
        },
        {
          "title": "2. Characteristics of LLM in Education",
          "level": 1,
          "start_line": 44
        },
        {
          "title": "2.1. Characteristics of LLMs",
          "level": 1,
          "start_line": 55
        },
        {
          "title": "2.2. Characteristics of education",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "2.2.1. Educational development process",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "2.2.2. Impact on teachers",
          "level": 1,
          "start_line": 93
        },
        {
          "title": "2.2.3. Educational challenges",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "2.3. Characteristics of LLMEdu",
          "level": 1,
          "start_line": 123
        },
        {
          "title": "2.3.1. Specific embodiment of \"LLMs + education\"",
          "level": 1,
          "start_line": 127
        },
        {
          "title": "2.3.2. Impact of \"LLMs + education\"",
          "level": 1,
          "start_line": 144
        },
        {
          "title": "3. How to Gradually Integrate LLMs into Education",
          "level": 1,
          "start_line": 172
        },
        {
          "title": "3.1. Reasons why LLMs for education",
          "level": 1,
          "start_line": 176
        },
        {
          "title": "3.2. Fusion strategies",
          "level": 1,
          "start_line": 198
        },
        {
          "title": "4. Key Technologies for LLMEdu",
          "level": 1,
          "start_line": 214
        },
        {
          "title": "5. Implementation of LLMEdu",
          "level": 1,
          "start_line": 247
        },
        {
          "title": "5.1. LLMs-empowered education",
          "level": 1,
          "start_line": 254
        },
        {
          "title": "5.2. LLMs in Mathematics",
          "level": 1,
          "start_line": 278
        },
        {
          "title": "6. Issues and Challenges",
          "level": 1,
          "start_line": 298
        },
        {
          "title": "6.1. Main issues",
          "level": 1,
          "start_line": 302
        },
        {
          "title": "6.2. Main challenges",
          "level": 1,
          "start_line": 323
        },
        {
          "title": "7. Conclusion",
          "level": 1,
          "start_line": 345
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 357
        }
      ]
    },
    "suggested_tags": [
      "教育技术",
      "LLMs",
      "智能教育",
      "文献综述",
      "AI教育应用"
    ],
    "tag_suggestions": [
      {
        "name": "教育技术",
        "confidence": 0.95,
        "reason": "论文核心研究领域是大型语言模型在教育领域的应用，属于教育技术范畴"
      },
      {
        "name": "LLMs",
        "confidence": 0.9,
        "reason": "论文聚焦大型语言模型的技术特点、应用方法和挑战分析"
      },
      {
        "name": "智能教育",
        "confidence": 0.85,
        "reason": "论文系统综述了LLMs在个性化教学、自适应学习等智能教育场景的应用"
      },
      {
        "name": "文献综述",
        "confidence": 0.8,
        "reason": "论文采用综述研究方法，系统总结当前技术现状、挑战和未来发展方向"
      },
      {
        "name": "AI教育应用",
        "confidence": 0.75,
        "reason": "论文探讨人工智能技术特别是LLMs在教育行业的具体应用场景和效益"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283602068",
          "title": "Evaluating Adaptive and Generative AI-Based Feedback and Recommendations in a Knowledge-Graph-Integrated Programming Learning System",
          "authors": [
            "Lalita Na Nongkhai",
            "Jingyun Wang",
            "Adam T. Wynn",
            "T. Mendori"
          ],
          "year": 2025,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283438556",
          "title": "FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing",
          "authors": [
            "Jingheng Ye",
            "Shen Wang",
            "Jiaqi Chen",
            "Hebin Wang",
            "Deqing Zou",
            "Yanyu Zhu",
            "Jiwei Tang",
            "Hai-Tao Zheng",
            "Ruitong Liu",
            "Haoyang Li",
            "Yanfeng Wang",
            "Qingsong Wen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283261962",
          "title": "LOOM: Personalized Learning Informed by Daily LLM Conversations Toward Long-Term Mastery via a Dynamic Learner Memory Graph",
          "authors": [
            "Justin Cui",
            "Kevin Pu",
            "Tovi Grossman"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283299903",
          "title": "Research on the Intelligent Reform Pathway of Higher Education Empowered by Generative Artificial Intelligence",
          "authors": [
            "Gao Min"
          ],
          "year": 2025,
          "venue": "Artificial Intelligence and Digital Technology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283025009",
          "title": "THE RISE OF LARGE LANGUAGE MODELS: A BEGINNER’S SURVEY",
          "authors": [
            "Gustavo de Aquino Mouzinho",
            "Leandro Youiti Silva Okimoto",
            "Leonardo Yuto Suzuki Camelo",
            "Nádila da Silva de Azevedo",
            "Hendrio Bragança",
            "Rubens de Andrade Fernandes",
            "Fabricio Ribeiro Seppe",
            "Raimundo Claúdio Souza Gomes",
            "Fábio de Sousa Cardoso"
          ],
          "year": 2025,
          "venue": "ARACÊ",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283103684",
          "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education",
          "authors": [
            "Bingquan Zhang",
            "Xiaoxiao Liu",
            "Yuchi Wang",
            "Lei Zhou",
            "Qianqian Xie",
            "Benyou Wang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282911236",
          "title": "Using LLMs to support assessment of student work in higher education: a viva voce simulator",
          "authors": [
            "Ian M. Church",
            "Lyndon Drake",
            "Mark Harris"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283569751",
          "title": "SPARK – Smart Plug-and-Play AI Framework for RAG & Knowledge",
          "authors": [
            "Nirmit Dagli",
            "Chetan Jaiswal",
            "Sanjeev Kumar Marimekala"
          ],
          "year": 2025,
          "venue": "Ubiquitous Computing, Electronics & Mobile Communication Conference",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282107557",
          "title": "Modular Framework Integrating Large Language Models with Drilling Hazard Detection Systems to Provide Operational Context-Informed Interpretations and Recommended Actions",
          "authors": [
            "S. Suhail",
            "T. S. Robinson",
            "O. Revheim",
            "P. Bekkeheien"
          ],
          "year": 2025,
          "venue": "SPE Annual Technical Conference and Exhibition",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281787333",
          "title": "Defying Data Scarcity: High-Performance Indonesian Short Answer Grading via Reasoning-Guided Language Model Fine-Tuning",
          "authors": [
            "Muhammad Naufal Faza",
            "P. D. Purnamasari",
            "A. A. P. Ratna"
          ],
          "year": 2025,
          "venue": "International Journal of Electrical, Computer, and Biomedical Engineering",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T19:03:39.467259",
      "references": [
        {
          "external_id": "CorpusId:266054920",
          "title": "Large Language Models in Law: A Survey",
          "authors": [
            "Jinqi Lai",
            "Wensheng Gan",
            "Jiayang Wu",
            "Zhenlian Qi",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "AI Open",
          "citation_count": 150
        },
        {
          "external_id": "CorpusId:265351653",
          "title": "Multimodal Large Language Models: A Survey",
          "authors": [
            "Jiayang Wu",
            "Wensheng Gan",
            "Zefeng Chen",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 282
        },
        {
          "external_id": "CorpusId:265352038",
          "title": "Large Language Models in Education: Vision and Opportunities",
          "authors": [
            "Wensheng Gan",
            "Zhenlian Qi",
            "Jiayang Wu",
            "Chun-Wei Lin"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 128
        },
        {
          "external_id": "CorpusId:265149884",
          "title": "Large Language Models for Robotics: A Survey",
          "authors": [
            "Fanlong Zeng",
            "Wensheng Gan",
            "Yongheng Wang",
            "Ning Liu",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:265128707",
          "title": "Model-as-a-Service (MaaS): A Survey",
          "authors": [
            "Wensheng Gan",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 35
        },
        {
          "external_id": "CorpusId:263608784",
          "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis",
          "authors": [
            "Weixin Liang",
            "Yuhui Zhang",
            "Hancheng Cao",
            "Binglu Wang",
            "Daisy Ding",
            "Xinyu Yang",
            "Kailas Vodrahalli",
            "Siyu He",
            "D. Smith",
            "Yian Yin",
            "Daniel A. McFarland",
            "James Zou"
          ],
          "year": 2023,
          "venue": "NEJM AI",
          "citation_count": 217
        },
        {
          "external_id": "CorpusId:263334045",
          "title": "Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment",
          "authors": [
            "Tianhao Wu",
            "Banghua Zhu",
            "Ruoyu Zhang",
            "Zhaojin Wen",
            "K. Ramchandran",
            "Jiantao Jiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 70
        },
        {
          "external_id": "CorpusId:263310363",
          "title": "A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM",
          "authors": [
            "Jongyoon Lim",
            "Inkyu Sa",
            "Bruce A. MacDonald",
            "Ho Seok Ahn"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 9
        },
        {
          "external_id": "CorpusId:261582620",
          "title": "ImageBind-LLM: Multi-modality Instruction Tuning",
          "authors": [
            "Jiaming Han",
            "Renrui Zhang",
            "Wenqi Shao",
            "Peng Gao",
            "Peng Xu",
            "Han Xiao",
            "Kaipeng Zhang",
            "Chris Liu",
            "Song Wen",
            "Ziyu Guo",
            "Xudong Lu",
            "Shuai Ren",
            "Yafei Wen",
            "Xiaoxin Chen",
            "Xiangyu Yue",
            "Hongsheng Li",
            "Y. Qiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 148
        },
        {
          "external_id": "CorpusId:261582366",
          "title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function",
          "authors": [
            "Haotian Xu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 15
        }
      ],
      "references_fetched_at": "2025-12-16T19:03:40.082147"
    }
  },
  "659fea70-f22c-4b54-9382-aa768ec096e8": {
    "id": "659fea70-f22c-4b54-9382-aa768ec096e8",
    "filename": "ssrn-5095149.pdf",
    "file_path": "data/uploads/47e5d413-0cfd-43be-ba5a-dd4b0c5160c5/659fea70-f22c-4b54-9382-aa768ec096e8_ssrn-5095149.pdf",
    "status": "completed",
    "created_at": "2025-12-16 21:36:27.474020",
    "updated_at": "2025-12-16 13:37:57.338826",
    "user_id": "47e5d413-0cfd-43be-ba5a-dd4b0c5160c5",
    "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
    "markdown_content": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning – understanding and retaining information – remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately —through semantic analysis involving meaning, inferences, and implications— can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies – note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-taking—whether done alone or alongside LLM usage—produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learning—offering opportunities to clarify, explore, and contextualise material—but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot ②\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 – upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. Aleksić-Maslac, F. Borović, and Z. Biočina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434–442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 × 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 × 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 × 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 × 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 × 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 × 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 × 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 × 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 × 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 × 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 × 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 × 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 × 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (≥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (≥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\n· figuring out what the main ideas and concepts in the text are,\n· what they mean,\n· how they relate to each other, and\n· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\n· The meaning of important words and concepts\n· The meaning of complex sentences\n· The key points or ideas, such as the dates, places, people and events\n· The connections between places, people and events\n· What happened, and why and how it happened\n· Similarities and differences between ideas and concepts\n· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\nYou can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\n You can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>“It took less time to use the LLM”, “Notes take too much time.”</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>“The note-taking seemedunnec-\nsessary as the bot already helped explain”, “Using one sort of meant I didn’t need the other.”</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you don’t have to do the work your-\nself. The task becomes easier if you don’t have to take notes.</td><td>“Didn’t have to do any work”, “Clarify any information I didn’t know immediately without hav-\ning to scour the text”, “It was difficult to take notes at the same time as using the chatbot.”</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>“I didn’t have enough time to ask as many questions when taking notes”, “I had more time to un-\nderstand the text.”</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.”</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>“Less time-consuming”, “Much quicker.”</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>“More simple”, “It was easier.”</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>“Actively engaging with the bot”, “Felt more interactive.”</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>“Enjoyed reading its responses”, “More fun to use.”</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>“Allowed me to focus more on the text.”</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>“It gives you a better understanding”, “I could confirm anything I was unsure of to ensure I understood it.”</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>“The AI helped me to learn more efficiently”, “I was able to understand and learn the text a lot easier and quicker at a higher level.”</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you don’t understand.</td><td>“Ask any relevant questions”, “If I had a question, it could answer it.”</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>“I was given more background”, “It gives me the full context.”</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>“It puts it in a simpler way and form”, “I can ask the AI chatbot to rephrase key points”, “It can summarise key points.”</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>“It has stuck in my head more”, “Giving me prompt questions, mnemonics, etc., which helped me remember”, “Took less time to memorise than note-taking.”</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>“I can remember things better when I write them down”, “More helpful for developing recall”, “I learned more with note-taking”, “Just gave more background, rather than consolidating the knowledge.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>“It was easier for me to understand what I was reading”, “I was understanding it more”, “Test what you have learned by paraphrasing.”</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>“Better active reading”, “Allows me to actively engage.”</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>“You have to personally analyse it”, “I could condense the information into my own words”, “Made me think for myself”, “It is your view on the matter you are looking at”, “Alows me to feel proud of my work in the future.”</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>“I was able to break down and process the text”, “Summarising the second text myself helped me to process the information.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“I am able to write down my own knowledge of what I had learned”, “I could actually learn the information rather than being told it.”</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>“I can come back to these notes at a later date if I am doing revision”, “Note-taking gives you something better to look back on in future.”</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>“Easier to summarise”, “IDK, easier.”</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>“It is easy to organise my notes”, “It is easier to keep track of your train of thoughts”, “Helped me to break down the text into smaller chunks.”</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>“I found myself easily distracted by the AI and was more tempted to ask random questions”, “It’s not clear as it gives too much information.”</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>“It felt that it was just repeating it-self.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>“I struggled to think of questions to ask the AI”, “The text was very easy therefore didn’t feel the need to ask many questions.”</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>“I enjoy using both at the same time”, “If I had to use the chatbot and ask it 20 questions, I would be very bored.”</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>“It was easier to have my key notes summarised as well as text with more detail”, “It allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isn’t clear.”</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>“Most helpful and easy to learn”, “Because I find it easier to remember and learn this way.”</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>“In order for me to process this, I find note-taking at the same time very helpful.”</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>“If I am only using the chatbot, then I have to scroll up to find what I am looking for”, “It was easier to keep track of things and go back over them.”</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>“It meant I was doing actual work.”</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>“I like to write out information as I think it helps me remember it better.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>“Simplifying it on paper made it easier to understand and remember.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“You learn more”, “You can simplify what you have learnt in the notes.”</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>“Some of the questions I had for the bot were not answered explicitly.”</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>“You will not get an AI chatbot at all times.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>“I wasn’t sure what I was supposed to say to the bot. It was just kinda irritating.”</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: “Help me to summarise this paragraph”, “Summarise the text”, “Give me a summary of the first paragraph”, “Tell me what this text is about.”</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: “Make notes for the first paragraph.”</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: “What are the main points?”, “Give me all the important dates”, “What’s the takeaway message?”</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: “Put the important dates into chronological order”, “Give me a timeline of the events.”</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: “What does apartheid mean?”, “What is a colony?”, “What is a missile?”, “I don’t know what a blockade is.”</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: “Explain this in simple words”, “Make the text simpler”, “What does this sentence mean?”, “Simplify this text.”</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: “The US did not like Cuba because they thought that Castro was a communist, right?”, “So it was one officer that prevented the whole war?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide context—information that is not too central for understanding the text but could be relevant.\nExamples: “Who was Kennedy?”, “What was Mandela famous for?”, “Tell me more about Cuba”, “How many British colonies were there in Africa?”, “Where were the Turkish missiles located?”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: “Why did the US not like Castro?”, “Why did the exiles invade Cuba?”, “How did black people feel during apartheid?”</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: “What are examples of how apartheid affected daily life?”, “Is there an analogy that explains the Cold War tensions?”, “What unfair laws were passed?”, “What were some of the boycotts?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: “How is apartheid different from segregation in the US?”, “Compare Kennedy and Khrushchev&#x27;s leadership styles.”</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: “What are the strengths and weaknesses of Kennedy&#x27;s decision?”, “Evaluate the effectiveness of the blockade.”</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: “What were the long-term effects of the crisis?”, “What is the situation like now?”, “Why should I care or learn about this?”</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: “Make a mnemonic”, “Write four questions about the text”, “How can I remember this better?”</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: “Summarize the main points in bullet points”, “Can you create a chart of the different policies?”, “Use only a few words”, “Make it short.”</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: “I don’t understand what you said”, “Explain that again but shorter”, “What do you mean?”,\n“Simpler please”, “Can you write that in simpler terms?”, “Make the summary shorter.”</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: “How are you?”, “Thank you”, “Hello.”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: “What are your sources?”, “Why should I believe you?”, “I think your answer is wrong.”</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: “Nelson Mandela”, “In 1910, four British colonies joined to create the Union of South Africa”, “Missile.”</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: “Who is Che Guevara?”, “What is the song Abraxas?”</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that don’t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: “asdfgh”, “.”, “123”, “???”</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
    "arxiv_id": "2401.15081",
    "error_message": null,
    "embedding": [
      -1.625,
      -1.7578125,
      0.1728515625,
      -4.40625,
      -1.7265625,
      0.091796875,
      -0.55859375,
      -1.7578125,
      0.64453125,
      2.515625,
      2.109375,
      1.1484375,
      2.0625,
      2.984375,
      -0.890625,
      4,
      -0.0172119140625,
      -0.5390625,
      0.33984375,
      -7.1875,
      0.50390625,
      1.640625,
      1.1953125,
      -5.5,
      3.75,
      -4.28125,
      -1.125,
      1.0546875,
      0.5703125,
      0.302734375,
      7.09375,
      -7.0625,
      0.65234375,
      2.53125,
      0.89453125,
      1.1875,
      -2.15625,
      -2.03125,
      7.15625,
      3.375,
      -4.9375,
      0.302734375,
      1.7890625,
      1.5,
      -0.0123291015625,
      2.890625,
      1.421875,
      -1.90625,
      -4.4375,
      -0.66796875,
      -3.203125,
      -5,
      7.96875,
      -3.34375,
      3.046875,
      -3.171875,
      -5.0625,
      5.4375,
      -3.296875,
      -0.431640625,
      0.287109375,
      -0.92578125,
      1.265625,
      0.23046875,
      2.890625,
      1.4765625,
      1.484375,
      0.96484375,
      -3.390625,
      1.71875,
      2.265625,
      1.625,
      5.84375,
      -4.34375,
      9.0625,
      7.75,
      3.21875,
      2.09375,
      -0.296875,
      2.5625,
      -5.9375,
      5.0625,
      4.1875,
      -2.125,
      6.53125,
      3.03125,
      -1.09375,
      -2.15625,
      -2.78125,
      2.53125,
      -1.09375,
      -0.34765625,
      -6.3125,
      -3.046875,
      0.2392578125,
      3.0625,
      -0.8203125,
      -5.25,
      -4.78125,
      -0.470703125,
      -1.8515625,
      -3.140625,
      1.0390625,
      -6.71875,
      -4.71875,
      -4.53125,
      -3,
      -7.25,
      -0.76171875,
      -1.5625,
      -0.458984375,
      2.53125,
      0.51171875,
      -1.3125,
      0.7109375,
      -0.470703125,
      3.296875,
      -5.40625,
      -3.1875,
      -0.4375,
      0.578125,
      2.625,
      -1.0390625,
      0.515625,
      1.2265625,
      2.90625,
      -5.28125,
      2.984375,
      5.53125,
      -0.90234375,
      3.296875,
      -1.1640625,
      5.46875,
      -0.6328125,
      -6.25,
      -3.375,
      -4.25,
      2.046875,
      4.84375,
      7.125,
      -4.4375,
      -0.1943359375,
      -1.8046875,
      -9,
      2.859375,
      0.953125,
      -6.84375,
      0.3046875,
      3.84375,
      -4.59375,
      -1.15625,
      0.82421875,
      4.09375,
      4.78125,
      -1.90625,
      -5,
      3.125,
      2.5625,
      0.1484375,
      -2.171875,
      2.390625,
      1.109375,
      -1.2421875,
      1.1953125,
      -0.546875,
      -3.234375,
      -7.03125,
      1.7578125,
      -3.078125,
      -1.0078125,
      2.90625,
      13.875,
      2.453125,
      -1.5546875,
      0.055419921875,
      0.65234375,
      -2.71875,
      6.21875,
      2.09375,
      -0.765625,
      2.65625,
      1.7109375,
      -3.78125,
      1.609375,
      -0.1689453125,
      0.439453125,
      3.453125,
      -3.375,
      2.203125,
      -1.2109375,
      2.8125,
      4.90625,
      1.9375,
      0.072265625,
      -4.65625,
      0.296875,
      3.8125,
      1.390625,
      -0.66015625,
      2.046875,
      1.1796875,
      -8.4375,
      1.25,
      -1.484375,
      -3.765625,
      -2.25,
      4.125,
      -1.0859375,
      2.984375,
      -1.4453125,
      1.671875,
      -1.703125,
      0.76171875,
      1.6953125,
      7.4375,
      1.8125,
      1.3203125,
      -0.18359375,
      3.953125,
      3.28125,
      4.0625,
      3.0625,
      2.46875,
      1.1875,
      -0.76953125,
      3.109375,
      2.609375,
      3.71875,
      -0.0908203125,
      5.40625,
      -0.2373046875,
      4.0625,
      5.53125,
      -1.9921875,
      -2.046875,
      0.287109375,
      -3.390625,
      -0.73828125,
      -1.2734375,
      0.1591796875,
      -3.984375,
      -2.265625,
      0.671875,
      2.75,
      1.71875,
      -1.4453125,
      -0.5546875,
      -1.078125,
      -0.69140625,
      -6.875,
      0.671875,
      1.9296875,
      -9.875,
      -3.609375,
      5.625,
      8.8125,
      -0.392578125,
      -0.220703125,
      -2.890625,
      -0.59375,
      3.390625,
      -1.5625,
      -3.640625,
      -0.2041015625,
      1.90625,
      -4.15625,
      5.78125,
      -1.46875,
      3.796875,
      1.2890625,
      0.57421875,
      -1.78125,
      -1.984375,
      -0.0498046875,
      0.1845703125,
      5.4375,
      3.78125,
      -3.34375,
      0.51953125,
      -2.234375,
      -6.28125,
      -9.25,
      5.625,
      -3.25,
      5.5,
      -0.89453125,
      0.578125,
      4.84375,
      -1.640625,
      12.6875,
      2.09375,
      1.6875,
      0.6484375,
      -1.0859375,
      -4.53125,
      1.359375,
      -4.0625,
      2.65625,
      -4.8125,
      -0.365234375,
      4.75,
      4.15625,
      -1.609375,
      -4.21875,
      1.140625,
      4.3125,
      1.625,
      -3.578125,
      0.58984375,
      2.84375,
      -3.9375,
      1.984375,
      7,
      -3.53125,
      3.640625,
      -7.0625,
      -2.375,
      6.25,
      1.3125,
      -0.89453125,
      -5.1875,
      -3.15625,
      -1.0546875,
      -2.65625,
      -2.90625,
      -2.53125,
      0.33984375,
      -0.2890625,
      2.546875,
      -0.55859375,
      1.0859375,
      0.7109375,
      -5.40625,
      -9.625,
      7.5625,
      -3.578125,
      5.3125,
      0.91796875,
      -1.3671875,
      3.96875,
      -2.28125,
      -3.5625,
      3.46875,
      -1.9921875,
      -0.125,
      -1.7421875,
      4.5625,
      -2.5,
      1.4765625,
      -8.1875,
      2.96875,
      0.8125,
      1.25,
      5.0625,
      6.8125,
      -3.8125,
      1.1875,
      -2.375,
      -2.578125,
      -0.404296875,
      1,
      -1.4140625,
      6.65625,
      -0.72265625,
      -3.953125,
      -2.734375,
      -0.515625,
      3.8125,
      -0.80078125,
      -0.6015625,
      0.162109375,
      -4.25,
      0.44140625,
      0.85546875,
      1.1015625,
      3.515625,
      2.640625,
      -2.421875,
      -1.7109375,
      3.671875,
      -3.671875,
      0.81640625,
      -0.0703125,
      -1.015625,
      3.046875,
      1.6796875,
      0.9609375,
      3.015625,
      2.75,
      0.054931640625,
      -2.265625,
      1.0390625,
      -2.5625,
      3.15625,
      1.6171875,
      3.34375,
      -0.9921875,
      1.984375,
      -0.88671875,
      -2.453125,
      5.6875,
      0.1982421875,
      -0.3359375,
      -2.84375,
      -3.5625,
      1.1875,
      1.859375,
      -7.1875,
      0.326171875,
      2.078125,
      -1.3671875,
      3,
      -2.203125,
      0.053955078125,
      -0.228515625,
      3.359375,
      -1,
      2.78125,
      -5.71875,
      -3.140625,
      -3.359375,
      0.142578125,
      1.5390625,
      -0.73046875,
      -0.330078125,
      0.6015625,
      4.34375,
      6.03125,
      1.109375,
      -1.6328125,
      1.3125,
      0.06494140625,
      -2.734375,
      0.306640625,
      -0.0174560546875,
      0.06982421875,
      1.234375,
      -4.6875,
      -4.5,
      -0.2578125,
      2.921875,
      0.60546875,
      5.1875,
      5.28125,
      -2.5625,
      -2.34375,
      2,
      3.140625,
      -4.0625,
      -5.09375,
      -0.9453125,
      0.515625,
      -1.28125,
      1.8046875,
      1.875,
      0.81640625,
      -0.031494140625,
      4.59375,
      2.0625,
      1.6015625,
      2.53125,
      -0.291015625,
      -1.5546875,
      -0.287109375,
      -0.015625,
      0.1484375,
      -3.671875,
      4.125,
      6.3125,
      -11.4375,
      -10.875,
      3.171875,
      0.86328125,
      -0.54296875,
      -0.2373046875,
      4.84375,
      2,
      1.6953125,
      -6.21875,
      -4.40625,
      -0.3046875,
      -0.734375,
      3.5,
      2.140625,
      -0.99609375,
      -2.921875,
      -3.890625,
      4.46875,
      -0.51953125,
      4.53125,
      -0.2431640625,
      0.0751953125,
      1.8203125,
      -5.375,
      2.234375,
      1.5703125,
      6.9375,
      -6.03125,
      0.12255859375,
      0.8125,
      -8.375,
      -1.3828125,
      -3.71875,
      -0.12060546875,
      -0.047119140625,
      -0.953125,
      5.3125,
      -3.28125,
      -0.48828125,
      -1.109375,
      2.4375,
      -4.09375,
      -3.34375,
      3.4375,
      -3.1875,
      -3.171875,
      0.333984375,
      0.70703125,
      1.078125,
      -1.375,
      -1.265625,
      -0.33203125,
      3.84375,
      2.171875,
      0.140625,
      -1.546875,
      -0.94140625,
      -2.640625,
      0.326171875,
      4.09375,
      3.1875,
      3.03125,
      1.265625,
      -5.125,
      -2.0625,
      -0.6171875,
      0.5859375,
      1.5390625,
      -0.1962890625,
      0.11181640625,
      0.388671875,
      3.453125,
      -4.125,
      1.5546875,
      0.5078125,
      0.470703125,
      -3.40625,
      0.0478515625,
      4.21875,
      3.34375,
      2.984375,
      3.109375,
      -0.5859375,
      1.15625,
      0.83984375,
      -4.1875,
      -3.40625,
      -1.546875,
      2.078125,
      1.09375,
      -3.34375,
      -0.1591796875,
      -1.6171875,
      -0.9765625,
      0.46875,
      -0.8984375,
      3.375,
      6.90625,
      -2.34375,
      1.1015625,
      -0.318359375,
      2.25,
      -2.125,
      1.96875,
      1.984375,
      2.859375,
      -5.9375,
      -6.09375,
      -3.03125,
      -0.0947265625,
      6.75,
      0.045166015625,
      4.40625,
      -2.78125,
      5.34375,
      1.3125,
      -0.06396484375,
      -15.1875,
      2.4375,
      -1.03125,
      -3.4375,
      -0.0260009765625,
      -4.21875,
      2.90625,
      -1.8046875,
      4.0625,
      0.3671875,
      -1.5859375,
      -2.703125,
      5.25,
      1.0390625,
      -0.54296875,
      4.8125,
      2.28125,
      -5.8125,
      1.28125,
      -0.41796875,
      -1.0859375,
      0.9140625,
      -1.2890625,
      1.6875,
      4.5625,
      4.59375,
      -1.7890625,
      -0.7421875,
      1.5625,
      -4.3125,
      -0.171875,
      1.59375,
      2.546875,
      1.5390625,
      2.609375,
      -0.81640625,
      2.90625,
      -3.75,
      2.015625,
      -0.1591796875,
      -1.78125,
      -0.5859375,
      6.34375,
      0.6484375,
      -3.078125,
      -4.03125,
      -2.328125,
      4.625,
      3.3125,
      -5.84375,
      0.50390625,
      0.8359375,
      -2.15625,
      3.765625,
      -0.421875,
      -0.34765625,
      -2.671875,
      0.41796875,
      1.328125,
      -3.328125,
      6.46875,
      2.90625,
      -5.78125,
      0.3984375,
      0.38671875,
      1.3125,
      0.3046875,
      1.1640625,
      0.1572265625,
      -2.6875,
      -1.1171875,
      3.71875,
      -0.6328125,
      -3.90625,
      -0.9296875,
      1.4609375,
      -4.6875,
      4.65625,
      -3.6875,
      -0.4375,
      -2.65625,
      -1.21875,
      3.53125,
      2.25,
      2.171875,
      0.054931640625,
      2.859375,
      2.890625,
      -3.125,
      5.90625,
      -5.25,
      -1.7109375,
      0.765625,
      -4.96875,
      -3.609375,
      0.71484375,
      -0.33203125,
      2.359375,
      -0.1875,
      -1.6953125,
      -1.5546875,
      -6.375,
      -1.625,
      1.1171875,
      0.009033203125,
      2.109375,
      -0.35546875,
      7.65625,
      -2.34375,
      -1.25,
      1.9140625,
      -1.4140625,
      -2.6875,
      -1.7890625,
      -1.6171875,
      -6.875,
      0.30859375,
      5.53125,
      4.28125,
      -1.4453125,
      7.03125,
      -0.3046875,
      -1.6875,
      -1,
      6.3125,
      -1.140625,
      -0.5234375,
      1.1796875,
      -0.62109375,
      -1.3203125,
      -4.8125,
      -0.78125,
      -2.203125,
      3.625,
      -1.640625,
      -0.1220703125,
      1.3359375,
      -4.375,
      2.1875,
      -0.9609375,
      -3.015625,
      -1.1875,
      3.875,
      -0.5234375,
      -1.890625,
      4.59375,
      1.3671875,
      2.390625,
      2.328125,
      -1.6953125,
      5,
      0.6328125,
      2.34375,
      -3.734375,
      -4.65625,
      -1.0859375,
      -0.412109375,
      -1.140625,
      2.359375,
      -2.203125,
      0.80859375,
      5.34375,
      1.3125,
      -4.90625,
      -1.5390625,
      4.125,
      -0.875,
      0.03564453125,
      -0.4453125,
      4.15625,
      1.3828125,
      1.6796875,
      -0.8671875,
      -4.90625,
      -1.9609375,
      4.59375,
      3.28125,
      -1.609375,
      0.9609375,
      4.3125,
      0.52734375,
      3.625,
      -4.6875,
      -5.09375,
      1.2734375,
      -0.1015625,
      -1,
      -1.609375,
      8.3125,
      -4.625,
      0.19921875,
      -0.203125,
      0.5546875,
      0.0206298828125,
      1.609375,
      -0.9765625,
      0.359375,
      2.3125,
      -1.109375,
      1.421875,
      3.96875,
      -0.8046875,
      -0.1884765625,
      0.431640625,
      -0.376953125,
      -1.8671875,
      2.109375,
      1.5703125,
      -1.265625,
      -1.484375,
      -0.80078125,
      -1.4296875,
      4.65625,
      5.90625,
      0.77734375,
      -0.58203125,
      2.796875,
      5.875,
      -0.0341796875,
      6.78125,
      1.625,
      9.0625,
      -2.5,
      -2.296875,
      4.8125,
      -4.15625,
      0.150390625,
      2.28125,
      -6.40625,
      -0.44140625,
      -0.68359375,
      -1.171875,
      -3.5,
      0.859375,
      -3.484375,
      -2.234375,
      6.25,
      2.90625,
      0.267578125,
      3.921875,
      5.59375,
      0.96875,
      -0.9765625,
      -4.8125,
      -2.796875,
      1.09375,
      0.8046875,
      2.46875,
      -1.9921875,
      0.65625,
      1.8828125,
      2.328125,
      1.1171875,
      0.0128173828125,
      -2.46875,
      5.6875,
      0.234375,
      0.35546875,
      5.34375,
      -2.359375,
      2.71875,
      0.380859375,
      3.515625,
      -3.890625,
      -1.1875,
      8.1875,
      2.484375,
      -2.0625,
      0.84765625,
      0.244140625,
      0.150390625,
      -2.421875,
      -1.609375,
      -0.6328125,
      0.251953125,
      -3.78125,
      -1.625,
      -0.361328125,
      1.953125,
      -3.0625,
      1.7109375,
      2.046875,
      -4.25,
      1.3046875,
      -0.255859375,
      -0.6171875,
      3.5,
      0.8046875,
      4.5,
      0.99609375,
      -2.953125,
      -5.125,
      -4.1875,
      -2.109375,
      0.486328125,
      1.8515625,
      1.9140625,
      0.3515625,
      -3.65625,
      0.75,
      -5.84375,
      -0.287109375,
      -6.28125,
      4.625,
      -0.00518798828125,
      -6.375,
      -1.0859375,
      -2.796875,
      -7.59375,
      -2.484375,
      -1.3671875,
      -2.546875,
      -1.015625,
      -4.4375,
      -0.08349609375,
      -1.1953125,
      -4.125,
      -0.0712890625,
      -2.421875,
      -1.1953125,
      3.203125,
      -0.59375,
      2.21875,
      -5,
      1.015625,
      0.921875,
      -0.66796875,
      2.296875,
      1.4609375,
      4.59375,
      4.90625,
      -0.9765625,
      2.15625,
      -2.34375,
      3.875,
      -2.859375,
      8.75,
      4.21875,
      0.3359375,
      -6.15625,
      2.390625,
      -0.6953125,
      0.66015625,
      -4.71875,
      -1.78125,
      -0.953125,
      -2.75,
      -0.88671875,
      0.32421875,
      2.359375,
      -4.96875,
      -2.96875,
      0.546875,
      -4.46875,
      1.90625,
      2.609375,
      -0.67578125,
      4.875,
      -0.042236328125,
      3.109375,
      1.234375,
      2.15625,
      2.390625,
      -1.6484375,
      4.0625,
      -7,
      2.59375,
      0.271484375,
      -1.03125,
      -0.6171875,
      -2.953125,
      1.546875,
      -1.0078125,
      0.72265625,
      2.390625,
      2.59375,
      1.1484375,
      -0.5234375,
      5.125,
      -1.140625,
      -1,
      -0.55078125,
      -1.734375,
      3.78125,
      1.6640625,
      1.65625,
      -3,
      1.3359375,
      -2.671875,
      -0.09716796875,
      2.234375,
      -2.78125,
      -1.4375,
      -1.40625,
      -4.4375,
      5.84375,
      -1.8515625,
      -0.26953125,
      2.1875,
      3.203125,
      3.171875,
      3.296875,
      1.6875,
      1.703125,
      1.2578125,
      -5.21875,
      5,
      -1.421875,
      -3.09375,
      4.90625,
      3.28125,
      6.625,
      -2.1875,
      -2.21875,
      -2.109375,
      -3.59375,
      7.25,
      -3.15625,
      -0.6015625,
      7.5,
      -0.83203125,
      0.06005859375,
      -1.8984375,
      0.2333984375,
      1.1484375,
      -0.76171875,
      -1.8515625,
      8.875,
      6,
      -2.453125,
      -1.1015625,
      -4.09375,
      -2.859375,
      -1.6015625,
      -1.6875,
      0.42578125,
      -0.78515625,
      2.046875,
      0.76953125,
      -0.5703125,
      -1.734375,
      0.6484375,
      -1.75,
      2.578125,
      3.359375,
      0.359375,
      1.4921875,
      -1.3828125,
      1.734375,
      -2.125,
      1.96875,
      3.828125,
      -5.03125,
      1.3359375,
      3.078125,
      -0.78125,
      3.34375,
      2.25,
      -0.5234375,
      -1.3125,
      -0.6171875,
      0.9375,
      1.0703125,
      -1.1171875,
      0.87890625,
      -4.3125,
      1.2734375,
      4.8125,
      2.78125,
      -3.578125,
      5.9375,
      0.51953125,
      -2.796875,
      1.71875,
      -1.6171875,
      -4.15625,
      1.5234375,
      -3.234375,
      0.9140625,
      -0.130859375,
      -0.9765625,
      0.3125,
      1.4375,
      -6.8125,
      5,
      -3.328125,
      6.125,
      1.5625,
      -0.484375,
      0.52734375,
      -0.3671875,
      -0.65625,
      -1.109375,
      2.25,
      2.140625,
      -2.15625,
      1.03125,
      -3.703125,
      -0.126953125,
      -3.15625,
      -2.4375,
      4.625,
      -2.046875,
      2.46875,
      -2.109375,
      2.1875,
      -7.15625,
      -2.53125,
      -0.44140625,
      -0.291015625,
      -0.1318359375,
      2.8125,
      1.7109375,
      -1.2890625,
      1.609375,
      -2.96875,
      0.921875,
      -3.921875,
      -1.1171875,
      0.1455078125,
      -1.25,
      1.609375,
      0.76953125,
      -1.953125,
      1.65625,
      -0.875,
      -3.546875,
      -1.3203125,
      -1.7734375,
      2.0625,
      -1.0703125,
      -1.875,
      0.47265625,
      1.3828125,
      1.3671875,
      -0.65234375,
      1.0859375,
      0.69921875,
      3.0625,
      -0.7734375,
      2.296875,
      -0.91015625,
      -2.875,
      -3.359375,
      -3.625,
      -5.15625,
      1.65625,
      3.265625,
      -3.90625,
      1.5546875,
      0.036376953125,
      2.59375,
      1.796875,
      1.140625,
      -0.79296875,
      1.765625,
      1.7890625,
      0.890625,
      -0.134765625,
      2.078125,
      -0.859375,
      3.40625,
      -1.3359375,
      -3.171875,
      -2.453125,
      -1.5703125,
      -0.5234375,
      1.5,
      -0.71484375,
      -2.34375,
      -1.953125,
      -2.6875,
      -0.6171875,
      -3.453125,
      6.0625,
      2.140625,
      5.71875,
      3.0625,
      -0.70703125,
      0.474609375,
      -0.251953125,
      0.27734375,
      3.125,
      0.3359375,
      0.56640625,
      -0.1279296875,
      -0.6328125,
      2.59375,
      -3.875,
      -2.09375,
      -4.1875,
      0.5234375,
      4.53125,
      -0.1416015625,
      0.0155029296875,
      1.3984375,
      -0.9765625,
      0.9140625,
      0.263671875,
      3.9375,
      -1.2890625,
      -1.0625,
      -1.0234375,
      2.421875,
      1.2890625,
      -3.375,
      1.109375,
      0.77734375,
      -0.93359375,
      0.35546875,
      2.453125,
      6.125,
      -0.65234375,
      3.984375,
      -1.7578125,
      -4,
      -4.03125,
      3,
      -0.5625,
      0.201171875,
      -1.578125,
      -6.25,
      -0.5390625,
      -2.390625,
      -1.609375,
      6.21875,
      0.78125,
      3.59375,
      -0.609375,
      3.875,
      0.154296875,
      -5.65625,
      -3.3125,
      3.25,
      1.34375,
      -5.40625,
      -0.162109375,
      -4.34375,
      -0.4609375,
      -1.125,
      -8.25,
      0.80859375,
      1.4140625,
      3.703125,
      2.203125,
      0.154296875,
      2.125,
      -0.8359375,
      -4.28125,
      -2.984375,
      -1.0703125,
      2.921875,
      2.21875,
      0.890625,
      -2.984375,
      1.2578125,
      -3.625,
      1.1796875,
      -3.578125,
      4.59375,
      -0.5625,
      5.46875,
      1.4296875,
      4.84375,
      -8.5625,
      -2.296875,
      -2.75,
      -2.75,
      -3.40625,
      -0.3359375,
      0.8671875,
      1.578125,
      1.8359375,
      0.318359375,
      -3.125,
      -1.046875,
      -2.390625,
      3.53125,
      1.4375,
      0.34765625,
      -0.8984375,
      -0.1181640625,
      -5.21875,
      -1.4921875,
      2.28125,
      -2.140625,
      -3.3125,
      3.671875,
      -0.96875,
      4.9375,
      2.34375,
      0.26171875,
      -2.21875,
      4.375,
      -0.6328125,
      -4.34375,
      -5.8125,
      -0.60546875,
      -0.279296875,
      -5.59375,
      1.0546875,
      -3.34375,
      1.4765625,
      -4.5,
      0.03466796875,
      -0.41015625,
      -1.515625,
      0.70703125,
      5.8125,
      2.375,
      -2.484375,
      3.125,
      -3.75,
      6.4375,
      3.6875,
      0.5,
      2.265625,
      0.55078125,
      1.1171875,
      -4.46875,
      4.59375,
      -0.65625,
      -2.984375,
      3.546875,
      5.125,
      -3.90625,
      -0.0267333984375,
      1,
      1.125,
      -1.5078125,
      -0.054931640625,
      -3.046875,
      4.75,
      -1.46875,
      -0.89453125,
      -5.4375,
      1.1328125,
      2.03125,
      -1.3359375,
      2.375,
      -1.578125,
      3.03125,
      -3.9375,
      -4.71875,
      3.1875,
      2.15625,
      4.25,
      -3.421875,
      1.25,
      2.765625,
      1.359375,
      2.9375,
      -1.125,
      -4.09375,
      -1.34375,
      0.6171875,
      -5.09375,
      0.337890625,
      -4.8125,
      -0.271484375,
      -4.09375,
      0.69921875,
      -4.40625,
      0.9765625,
      0.17578125,
      -1.359375,
      -2.546875,
      -3.53125,
      -5.53125,
      -3.28125,
      -1.1640625,
      -1.40625,
      -6.53125,
      -2.421875,
      1.65625,
      3.8125,
      4.21875,
      5.90625,
      3.59375,
      -1.53125,
      0.71484375,
      -0.859375,
      0.267578125,
      0.296875,
      0.248046875,
      -1.765625,
      -2.203125,
      0.921875,
      -0.58984375,
      5.25,
      -3.46875,
      -2.4375,
      -3.3125,
      0.0927734375,
      -1.4765625,
      1.1796875,
      0.625,
      -0.80859375,
      4.65625,
      -2.859375,
      2.875,
      3.03125,
      -1.6328125,
      -5,
      4.0625,
      -1.015625,
      1.9140625,
      2.9375,
      0.333984375,
      -5,
      3.15625,
      3.859375,
      -4.25,
      3.625,
      1.1640625,
      -1.53125,
      -3.453125,
      0.28125,
      1.1640625,
      5.75,
      -1.7734375,
      3.5,
      4.125,
      -1.0859375,
      3.515625,
      5.5,
      -0.35546875,
      -2.0625,
      2.15625,
      0.44921875,
      -2,
      -2.484375,
      1.7265625,
      -2.765625,
      -4.71875,
      3.609375,
      2.515625,
      -0.9921875,
      -0.72265625,
      -1.5078125,
      4.40625,
      3.125,
      -3.859375,
      0.404296875,
      -4.15625,
      1.6796875,
      -2.9375,
      -1.1640625,
      -4.75,
      -0.490234375,
      -0.64453125,
      6.15625,
      -2.5625,
      -4.09375,
      5.0625,
      5.15625,
      -1.0546875,
      -1.1953125,
      5.0625,
      1.2109375,
      -0.9921875,
      -4.5,
      -2.484375,
      5.65625,
      1.3203125,
      4.96875,
      -0.98046875,
      1.3515625,
      0.96484375,
      -2.546875,
      -5.53125,
      1.171875,
      -2.421875,
      -4.8125,
      -3.171875,
      -2.40625,
      2.78125,
      -2.640625,
      4.25,
      3.96875,
      0.58203125,
      2.1875,
      0.3359375,
      2.6875,
      3.015625,
      -3.46875,
      1.4296875,
      1.328125,
      -2.9375,
      0.3984375,
      1.1328125,
      -2.140625,
      0.345703125,
      -2.546875,
      1.8359375,
      3.5,
      -0.84765625,
      -1.9765625,
      -7,
      2.234375,
      3.71875,
      5.125,
      -0.1708984375,
      -4.53125,
      1.5078125,
      1.3359375,
      -2.6875,
      -1.25,
      2.53125,
      0.73828125,
      1.5546875,
      -1.6328125,
      -1.0859375,
      4.78125,
      0.8125,
      1.7265625,
      -1.421875,
      -4.09375,
      -2.65625,
      -0.98046875,
      -3.375,
      -0.1552734375,
      -2.09375,
      5.9375,
      -1.859375,
      -1.0625,
      0.1416015625,
      5.96875,
      1.6015625,
      2.328125,
      0.1416015625,
      0.404296875,
      -0.310546875,
      3,
      2.671875,
      -3.5625,
      1.9296875,
      -0.150390625,
      -1.1484375,
      -2.59375,
      -1.6796875,
      -1.484375,
      1.34375,
      -3.890625,
      -0.40625,
      -0.1259765625,
      2.140625,
      -1.8515625,
      -9.625,
      0.75,
      1.15625,
      -3.25,
      -2.25,
      -2.390625,
      1.40625,
      6.5625,
      1,
      4.8125,
      0.193359375,
      -2.90625,
      3.40625,
      13.875,
      -3.125,
      -3.75,
      0.3984375,
      -1.296875,
      6.28125,
      6.46875,
      0.546875,
      2.640625,
      1.0546875,
      -0.396484375,
      3.625,
      0.734375,
      4.375,
      1.0078125,
      1.515625,
      3.15625,
      0.99609375,
      -3.265625,
      -5.875,
      -1.03125,
      -1.0703125,
      -1.484375,
      2.15625,
      -1.5,
      0.5234375,
      0.7421875,
      -3.109375,
      -1.8046875,
      -2.46875,
      -3.703125,
      -0.83984375,
      -0.1962890625,
      -1.984375,
      -0.703125,
      -3.890625,
      -0.9765625,
      0.55078125,
      -0.177734375,
      -3.84375,
      -5.65625,
      -6.15625,
      2.171875,
      -0.99609375,
      -4.96875,
      2.109375,
      -3.15625,
      -3.328125,
      0.00933837890625,
      -1,
      -1.1171875,
      0.2197265625,
      -6.6875,
      0.87890625,
      0.265625,
      -0.95703125,
      -1.3203125,
      -3.5625,
      -4.375,
      -4.4375,
      -1.3515625,
      -0.53515625,
      -0.45703125,
      -3.40625,
      -3.875,
      -3.21875,
      -0.83203125,
      1.9375,
      1.3125,
      1.1328125,
      -2.984375,
      -1.1953125,
      2.78125,
      2.875,
      -0.765625,
      -3.46875,
      2.171875,
      0.890625,
      0.97265625,
      2.5625,
      -3.265625,
      2.625,
      -2.0625,
      -0.9296875,
      -0.53125,
      1.4765625,
      -4.6875,
      0.373046875,
      1.9375,
      -2.421875,
      5.9375,
      -5.78125,
      3.4375,
      -0.1474609375,
      -6.4375,
      -0.4140625,
      1.125,
      1.765625,
      -2.28125,
      -0.99609375,
      2.078125,
      -1.296875,
      1.6875,
      0.427734375,
      -0.130859375,
      1.46875,
      0.734375,
      -5.21875,
      0.0693359375,
      1.234375,
      0.80859375,
      4.3125,
      2.375,
      -0.4609375,
      -0.875,
      4.40625,
      -1.28125,
      -1.5546875,
      -3.0625,
      -2.234375,
      6,
      1.1796875,
      -0.93359375,
      0.294921875,
      -7.0625,
      -3.65625,
      -1.484375,
      -5.25,
      4,
      -1.2265625,
      0.396484375,
      -3.46875,
      -4.125,
      -0.0390625,
      3.25,
      -4.5625,
      3.65625,
      2.3125,
      3.96875,
      -0.07421875,
      -3.515625,
      1.328125,
      0.8671875,
      -2.078125,
      -3.609375,
      3.421875,
      -3.0625,
      2.59375,
      5.03125,
      2.375,
      -4.8125,
      4.1875,
      -1.4140625,
      -4.6875,
      -0.11767578125,
      2.859375,
      -1.71875,
      -1.1328125,
      -4.6875,
      0.052734375,
      -0.5234375,
      -2.046875,
      -0.8203125,
      -5.46875,
      -2.484375,
      -0.9921875,
      3.296875,
      1.3671875,
      -4.875,
      2.59375,
      2.671875,
      -6.0625,
      -0.283203125,
      -4.8125,
      4.53125,
      -1.6171875,
      2.921875,
      4.53125,
      -0.73828125,
      -1.0625,
      1.015625,
      1.9375,
      -1.8671875,
      -4.3125,
      3.796875,
      2.09375,
      -3.90625,
      3.140625,
      3.296875,
      -1.9921875,
      -0.310546875,
      -4.375,
      -1.3359375,
      5.15625,
      3.53125,
      -3.46875,
      -2.125,
      -0.8828125,
      1.328125,
      -4.5625,
      -5.40625,
      4.0625,
      1.359375,
      2.046875,
      1.9296875,
      1.3125,
      -3.046875,
      -1.75,
      -0.40625,
      -2.21875,
      -3.40625,
      2.515625,
      -2.296875,
      3.59375,
      -3.3125,
      6.09375,
      2.8125,
      1.2109375,
      -1.625,
      0.1728515625,
      2.59375,
      1.1328125,
      -3.9375,
      0.453125,
      0.5390625,
      3.828125,
      -6.53125,
      4.1875,
      -2.859375,
      2.9375,
      -4.8125,
      3.921875,
      -0.6875,
      -0.5,
      -5.0625,
      -4.1875,
      -3.265625,
      3.296875,
      0.99609375,
      0.84765625,
      3.328125,
      -0.40234375,
      0.291015625,
      -0.279296875,
      -3.25,
      1.578125,
      -2.34375,
      -0.057861328125,
      1.15625,
      -0.609375,
      0.7421875,
      0.3359375,
      7.25,
      -2.78125,
      -1.0703125,
      -2.359375,
      -2.328125,
      -0.59765625,
      -4.75,
      2.53125,
      -1.8125,
      -3.5,
      3.40625,
      1.8515625,
      -1.90625,
      3.125,
      1.0625,
      -2.78125,
      4.78125,
      3.25,
      -5.4375,
      5.0625,
      -1.078125,
      -3.984375,
      0.478515625,
      -0.7890625,
      -0.97265625,
      -5.8125,
      -0.30859375,
      4.09375,
      -3.484375,
      0.1376953125,
      2.359375,
      0.7734375,
      0.32421875,
      -2.859375,
      5.15625,
      1.765625,
      1.6484375,
      2.78125,
      4.09375,
      3.125,
      -4.78125,
      0.51953125,
      -1.8828125,
      -0.470703125,
      -2.390625,
      -4.65625,
      2.375,
      -1.1875,
      3.125,
      4.53125,
      -1.640625,
      -9.625,
      -3.71875,
      2.171875,
      -2.140625,
      2.8125,
      1.9765625,
      0.9765625,
      -2,
      0.69140625,
      0.84765625,
      4.1875,
      -0.9921875,
      -0.84765625,
      -5.5625,
      0.09619140625,
      -0.78515625,
      -5.6875,
      0.73828125,
      0.91796875,
      -0.330078125,
      -2.25,
      0.5,
      -0.96484375,
      0.99609375,
      3.53125,
      -4.3125,
      2.25,
      -1,
      -0.4375,
      5.90625,
      0.4921875,
      5.15625,
      3.078125,
      -2.875,
      -5.28125,
      0.1865234375,
      -0.2421875,
      1.265625,
      1.8359375,
      1.171875,
      5.21875,
      0.373046875,
      2.40625,
      -6.8125,
      5.03125,
      0.09765625,
      -11.1875,
      2.375,
      -3.015625,
      0.8203125,
      -0.7578125,
      -8.3125,
      -3.046875,
      4.21875,
      -0.796875,
      -0.8046875,
      5.78125,
      0.47265625,
      0.185546875,
      1.5390625,
      -0.52734375,
      -4.9375,
      2.25,
      3.953125,
      -2.3125,
      0.28125,
      3.796875,
      -1.953125,
      0.78125,
      -0.197265625,
      3.015625,
      0.318359375,
      -3.375,
      3.421875,
      2.234375,
      -2.421875,
      -3.234375,
      -4.15625,
      -0.1328125,
      1.0859375,
      -3.765625,
      1.3046875,
      -2.15625,
      2.328125,
      -1.8125,
      -0.038818359375,
      -0.365234375,
      -3.984375,
      -1.671875,
      -2.75,
      -2.125,
      0.84765625,
      3,
      3.03125,
      -2.34375,
      -1.9765625,
      4.25,
      0.400390625,
      -0.640625,
      -2.65625,
      4.0625,
      -3.09375,
      -3.125,
      -2.515625,
      4.1875,
      -2.75,
      -3.1875,
      1.9140625,
      -0.5625,
      -2.203125,
      -3.453125,
      -2.78125,
      2.421875,
      -1.921875,
      -1.5234375,
      -2.296875,
      -0.9375,
      3.859375,
      4.6875,
      -4.84375,
      -3.421875,
      -2.796875,
      -0.72265625,
      -5.53125,
      -3.609375,
      -0.6796875,
      -2.9375,
      0.8671875,
      5.1875,
      -0.150390625,
      0.9921875,
      0.349609375,
      -6.71875,
      -2.421875,
      3.859375,
      1.453125,
      -3.734375,
      1.375,
      -1.0546875,
      -4.15625,
      4.84375,
      9.5625,
      2.53125,
      -3.1875,
      1.0625,
      -1.1328125,
      -2.515625,
      -1.734375,
      2.4375,
      -0.48046875,
      -5.125,
      5.8125,
      -2.8125,
      4.1875,
      2.125,
      -1.265625,
      5.75,
      -4.9375,
      3,
      -1.2578125,
      0.62890625,
      3.234375,
      -4.5625,
      -1.828125,
      -3.484375,
      -2.734375,
      0.99609375,
      -0.5546875,
      1.1875,
      -1.234375,
      2.625,
      2.28125,
      0.74609375,
      -0.609375,
      -0.2373046875,
      5.3125,
      -4.46875,
      -0.443359375,
      -2.296875,
      -1.734375,
      -0.322265625,
      -2.59375,
      1.5859375,
      -5.0625,
      2.375,
      0.7578125,
      1.609375,
      1.1640625,
      1.7109375,
      -3.390625,
      -2.3125,
      -5.84375,
      1.1796875,
      1.140625,
      4.90625,
      1.34375,
      1.9140625,
      3.078125,
      0.279296875,
      3.4375,
      4.125,
      6.25,
      -3.640625,
      0.69921875,
      -0.8125,
      0.43359375,
      -0.087890625,
      -1.3203125,
      -0.75,
      1.1328125,
      4.625,
      0.31640625,
      -2.15625,
      -3.46875,
      -1.625,
      -2.53125,
      -1.1171875,
      1.6328125,
      2.515625,
      0.90234375,
      0.86328125,
      -1.25,
      0.77734375,
      0.796875,
      5.125,
      0.80859375,
      0.55078125,
      -2.671875,
      1.8203125,
      -2.734375,
      -2.125,
      2.859375,
      -2.0625,
      2.375,
      -1.0546875,
      -1.2890625,
      -0.44140625,
      2.078125,
      -3.859375,
      3.203125,
      -1.6640625,
      2.546875,
      1.2421875,
      1.515625,
      -2.703125,
      1.4921875,
      -0.01287841796875,
      2.515625,
      -4.0625,
      -0.890625,
      2.828125,
      2.6875,
      0.01470947265625,
      0.36328125,
      0.01336669921875,
      1.0859375,
      0.71484375,
      -1.515625,
      -1.0625,
      -0.85546875,
      3.171875,
      -0.486328125,
      0.6484375,
      1.8984375,
      0.458984375,
      -3.75,
      2.203125,
      -0.96875,
      -0.51171875,
      -3.390625,
      -0.193359375,
      2.984375,
      1.0703125,
      -0.10107421875,
      -0.90234375,
      -3.546875,
      -2.21875,
      -2.703125,
      -3.890625,
      -0.287109375,
      -2.3125,
      -4.59375,
      1.78125,
      2.71875,
      0.40625,
      0.484375,
      0.2734375,
      1.3984375,
      0.263671875,
      -2.296875,
      -0.267578125,
      1.34375,
      0.29296875,
      -2.46875,
      2.4375,
      1.265625,
      2.21875,
      2.15625,
      -0.71875,
      0.474609375,
      -0.90625,
      0.6796875,
      0.458984375,
      -2.171875,
      0.365234375,
      0.53515625,
      -1.6328125,
      -0.6953125,
      -0.86328125,
      -1.1328125,
      0.1220703125,
      -1.3828125,
      -0.83984375,
      1.4140625,
      0.022216796875,
      -2.15625,
      2.296875,
      4.28125,
      -3.25,
      -1.6875,
      -3.140625,
      -0.62109375,
      -0.484375,
      1.4140625,
      -4.53125,
      0.609375,
      -3.296875,
      -1.203125,
      -0.671875,
      1.1015625,
      1.578125,
      -3.90625,
      -0.8984375,
      -1.765625,
      0.451171875,
      0.048095703125,
      2.609375,
      1.203125,
      -5.09375,
      -3.265625,
      0.70703125,
      -0.58203125,
      -0.43359375,
      1.2421875,
      -2.046875,
      -1.546875,
      2.71875,
      3.25,
      -0.83984375,
      -2,
      1.1484375,
      0.69921875,
      0.306640625,
      1.9375,
      -0.14453125,
      1.8828125,
      0.16015625,
      -1.484375,
      0.4609375,
      -1.09375,
      -0.51171875,
      -0.486328125,
      -0.55859375,
      0.28515625,
      -1.9609375,
      -1.5703125,
      -2.140625,
      0.091796875,
      -2.6875,
      1.8125,
      1.1953125,
      -1.6484375,
      1.375,
      1.5234375,
      -0.29296875,
      2.453125,
      1.2421875,
      2.625,
      -0.62109375,
      0.345703125,
      0.72265625,
      1.953125,
      1.765625,
      1.2890625,
      -2.25,
      -1.5234375,
      0.2470703125,
      1.015625,
      0.90234375,
      -3.453125,
      3.375,
      1.0625,
      0.65234375,
      1.7265625,
      1.046875,
      0.86328125,
      1.1875,
      -4.03125,
      2.28125,
      2.703125,
      -0.69140625,
      -0.462890625,
      0.89453125,
      0.36328125,
      -0.74609375,
      -1.2578125,
      -0.33203125,
      -0.99609375,
      3.5625,
      -0.00469970703125,
      1.1171875,
      2.03125,
      -2.296875,
      -0.09912109375,
      -1.453125,
      1.3046875,
      -2.03125,
      5.09375,
      -2.453125,
      1.390625,
      2.8125,
      0.337890625,
      -2.09375,
      -0.6171875,
      -7.90625,
      -2.046875,
      -0.6953125,
      0.7421875,
      -0.54296875,
      -1.0390625,
      -1.515625,
      -2.296875,
      -0.189453125,
      0.59765625,
      -2.109375,
      2.359375,
      2.109375,
      1.7890625,
      2.296875,
      0.486328125,
      -3.609375,
      -0.72265625,
      3.109375,
      -1.4921875,
      3.375,
      -0.1328125,
      -2.078125,
      -1.1953125,
      -2.03125,
      -5.25,
      -0.7421875,
      -1.7109375,
      1.1015625,
      0.90234375,
      6.1875,
      1.265625,
      -2.359375,
      -0.5703125,
      0.72265625,
      2.5625,
      -1.203125,
      -2.5,
      3.3125,
      -0.7890625,
      1.1640625,
      -2.328125,
      -0.609375,
      -2.234375,
      0.5703125,
      1.4609375,
      -0.45703125,
      3.4375,
      -0.609375,
      -1.3203125,
      -0.04833984375,
      -0.09814453125,
      0.48046875,
      1.296875,
      0.12109375,
      4.6875,
      0.310546875,
      0.734375,
      2.125,
      3.6875,
      0.1494140625,
      -0.84765625,
      3.140625,
      0.0947265625,
      3.1875,
      4,
      -2.921875,
      -2.921875,
      2.109375,
      0.7578125,
      0.37109375,
      0.392578125,
      0.2099609375,
      3.5,
      -0.8125,
      0.703125,
      1.375,
      -0.408203125,
      -2.65625,
      -1.640625,
      2.78125,
      -4.8125,
      -0.3359375,
      0.69921875,
      -2,
      -0.2294921875,
      0.953125,
      4.40625,
      1.2578125,
      0.294921875,
      1.46875,
      1.0859375,
      -0.1396484375,
      0.42578125,
      -1.390625,
      1.9296875,
      3.625,
      -0.171875,
      -2.375,
      1.8984375,
      3.03125,
      4.0625,
      -0.017822265625,
      -2.390625,
      2.96875,
      0.7265625,
      1.0078125,
      0.890625,
      -1.4765625,
      2.03125,
      2.03125,
      -0.408203125,
      -0.56640625,
      -1.453125,
      0.5234375,
      2.765625,
      0.55859375,
      -2.640625,
      3.625,
      1.015625,
      -1.90625,
      -1.1328125,
      -0.54296875,
      -1.3203125,
      -1.5390625,
      -2.625,
      -1.015625,
      -2.03125,
      4.78125,
      -3.125,
      0.322265625,
      2.234375,
      2.296875,
      2.734375,
      2.859375,
      1.1171875,
      2.265625,
      -4.9375,
      -0.80078125,
      1.703125,
      -1.4765625,
      -4.4375,
      1.640625,
      -2.21875,
      -5.03125,
      0.75390625,
      -1.1015625,
      -1.53125,
      -1.6953125,
      -0.31640625,
      -2,
      -2.5,
      0.74609375,
      -1.5625,
      1.5546875,
      -4.375,
      -1.0078125,
      -0.5703125,
      3.703125,
      1.0078125,
      -1.765625,
      2.09375,
      -0.205078125,
      0.89453125,
      0.359375,
      -0.59765625,
      -0.77734375,
      -1.9296875,
      1.2109375,
      1.71875,
      -1.0390625,
      -0.96484375,
      -1.34375,
      3.625,
      -1.8359375,
      -0.92578125,
      -1.4296875,
      -1.21875,
      -0.06884765625,
      6.90625,
      2.546875,
      0.9453125,
      -2.34375,
      -2.171875,
      -0.58203125,
      3.703125,
      -0.78125,
      -1.515625,
      -2.1875,
      3.171875,
      -1.734375,
      -1.3125,
      -1.0703125,
      0.68359375,
      -1.4453125,
      -3.265625,
      0.423828125,
      -4.09375,
      0.244140625,
      4.8125,
      1.15625,
      -0.0615234375,
      -1.765625,
      2.609375,
      -3.296875,
      3.421875,
      -1.1328125,
      0.078125,
      5.125,
      0.6796875,
      0.2060546875,
      0.9765625,
      0.546875,
      0.2578125,
      2.390625,
      1.140625,
      2.453125,
      2.5,
      -0.404296875,
      -0.921875,
      0.234375,
      2.265625,
      -0.67578125,
      -3.140625,
      -1.1328125,
      -1.328125,
      -4.25,
      0.25390625,
      3.828125,
      1.28125,
      0.1396484375,
      1.15625,
      2.171875,
      -0.01318359375,
      2.6875,
      2.859375,
      0.08056640625,
      0.1748046875,
      -1.0390625,
      -2.703125,
      -2.65625,
      1.28125,
      -0.62890625,
      1.171875,
      1.2265625,
      -1.3515625,
      1.359375,
      -1.71875,
      4.90625,
      -2.375,
      0.54296875,
      -0.06689453125,
      -1.4609375,
      -2.8125,
      -2.453125,
      -2.53125,
      2.84375,
      -1.4296875,
      -0.05615234375,
      2.140625,
      0.072265625,
      -1.6484375,
      -1.3046875,
      -0.15625,
      3.03125,
      -0.4609375,
      -3.578125,
      -0.43359375,
      3.625,
      -1.7265625,
      0.828125,
      4.5,
      1.9765625,
      0.072265625,
      0.09326171875,
      1.8671875,
      -3.90625,
      0.1787109375,
      0.02099609375,
      1.1796875,
      3.109375,
      -2.484375,
      -4.09375,
      2.59375,
      1.921875
    ],
    "summary": "通过预注册的随机对照实验，在真实学校环境中比较单独使用LLM、传统笔记以及两者结合对中学生阅读理解与记忆的影响，并采用定量与定性相结合的混合方法进行分析。",
    "structure": {
      "sections": [
        {
          "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Affiliations:",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 14
        },
        {
          "title": "Main",
          "level": 1,
          "start_line": 18
        },
        {
          "title": "Results",
          "level": 1,
          "start_line": 46
        },
        {
          "title": "Learning outcomes",
          "level": 1,
          "start_line": 50
        },
        {
          "title": "Behavioural engagement",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "Prompting behaviour",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "Learning experiences and perceptions",
          "level": 1,
          "start_line": 93
        },
        {
          "title": "Activity preferences",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "Future use",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "Discussion",
          "level": 1,
          "start_line": 125
        },
        {
          "title": "Materials and Methods",
          "level": 1,
          "start_line": 153
        },
        {
          "title": "Participants",
          "level": 1,
          "start_line": 157
        },
        {
          "title": "Experimental design and procedure",
          "level": 1,
          "start_line": 165
        },
        {
          "title": "Setup and system",
          "level": 1,
          "start_line": 193
        },
        {
          "title": "Apartheid in South Africa",
          "level": 1,
          "start_line": 199
        },
        {
          "title": "AI Chatbot ②",
          "level": 1,
          "start_line": 209
        },
        {
          "title": "Notepad",
          "level": 1,
          "start_line": 213
        },
        {
          "title": "Learning task and materials (Session 1)",
          "level": 1,
          "start_line": 228
        },
        {
          "title": "Test task and materials (Session 2)",
          "level": 1,
          "start_line": 242
        },
        {
          "title": "Survey questions",
          "level": 1,
          "start_line": 256
        },
        {
          "title": "Analytic strategies",
          "level": 1,
          "start_line": 264
        },
        {
          "title": "Estimation of condition effects on text comprehension and retention",
          "level": 1,
          "start_line": 270
        },
        {
          "title": "Qualitative exploration of student prompts",
          "level": 1,
          "start_line": 302
        },
        {
          "title": "Quantitative exploration of students' learning experience",
          "level": 1,
          "start_line": 308
        },
        {
          "title": "Qualitative exploration of students' activity preferences",
          "level": 1,
          "start_line": 312
        },
        {
          "title": "Data availability",
          "level": 1,
          "start_line": 325
        },
        {
          "title": "Code availability",
          "level": 1,
          "start_line": 329
        },
        {
          "title": "Ethics declarations",
          "level": 1,
          "start_line": 333
        },
        {
          "title": "Competing interests",
          "level": 1,
          "start_line": 335
        },
        {
          "title": "Acknowledgements",
          "level": 1,
          "start_line": 339
        },
        {
          "title": "Supplementary Material",
          "level": 1,
          "start_line": 343
        },
        {
          "title": "Table of Contents",
          "level": 1,
          "start_line": 345
        },
        {
          "title": "Supplementary Information",
          "level": 1,
          "start_line": 347
        },
        {
          "title": "Supplementary Tables",
          "level": 1,
          "start_line": 351
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 374
        },
        {
          "title": "1 Supplementary Information",
          "level": 1,
          "start_line": 451
        },
        {
          "title": "1.1 Participant Exclusion Criteria",
          "level": 1,
          "start_line": 453
        },
        {
          "title": "2 Supplementary Tables",
          "level": 1,
          "start_line": 464
        },
        {
          "title": "2.1 Student Characteristics",
          "level": 1,
          "start_line": 466
        },
        {
          "title": "2.2 Familiarity with Learning Activities",
          "level": 1,
          "start_line": 475
        },
        {
          "title": "2.3 Descriptive Statistics",
          "level": 1,
          "start_line": 483
        },
        {
          "title": "2.4 Mixed Effects Regression Results",
          "level": 1,
          "start_line": 489
        },
        {
          "title": "2.5 Behavioural Engagement",
          "level": 1,
          "start_line": 495
        },
        {
          "title": "2.6 Student Task Instructions",
          "level": 1,
          "start_line": 501
        },
        {
          "title": "2.7 Test Questions",
          "level": 1,
          "start_line": 567
        },
        {
          "title": "2.8 Inter-rater Reliability Results",
          "level": 1,
          "start_line": 589
        },
        {
          "title": "2.9 Survey Questions and Response Scales",
          "level": 1,
          "start_line": 595
        },
        {
          "title": "2.10 Learning Experiences and Perceptions",
          "level": 1,
          "start_line": 624
        },
        {
          "title": "2.11 Coding Scheme Activity Preferences",
          "level": 1,
          "start_line": 630
        },
        {
          "title": "2.12 Coding Scheme Prompt Interactions",
          "level": 1,
          "start_line": 653
        },
        {
          "title": "2.13 Frequency of Prompt Types",
          "level": 1,
          "start_line": 691
        }
      ]
    },
    "suggested_tags": [
      "教育技术",
      "LLM应用",
      "学习科学",
      "人机交互"
    ],
    "tag_suggestions": [
      {
        "name": "教育技术",
        "confidence": 0.98,
        "reason": "论文核心研究领域是评估大型语言模型（LLM）在中学教育场景中对学生学习效果（阅读理解与记忆）的影响，属于教育技术与学习科学的交叉研究。"
      },
      {
        "name": "LLM应用",
        "confidence": 0.95,
        "reason": "研究聚焦于生成式AI（特别是LLM，如ChatGPT）在教育中的实际使用效果、学生交互模式（提示行为原型）及其对学生认知过程的影响。"
      },
      {
        "name": "学习科学",
        "confidence": 0.9,
        "reason": "研究基于认知科学理论（如建构-整合模型、加工水平理论），通过随机对照实验定量比较传统笔记与AI辅助学习对长期记忆和理解的影响，探讨认知参与机制。"
      },
      {
        "name": "人机交互",
        "confidence": 0.85,
        "reason": "论文采用混合方法（定量实验与定性分析），重点分析了学生与LLM的交互行为、感知有用性及认知负荷，属于教育场景下的人机交互研究。"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283549586",
          "title": "ChatGPT ile tasarlanan matematiksel oyunların 4. sınıf öğrencilerinin matematik motivasyon ve tutumlarına etkisi",
          "authors": [
            "Ramazan Divrik",
            "Ömer Çelik",
            "Zeynep Elmas"
          ],
          "year": 2025,
          "venue": "Kocaeli Üniversitesi Eğitim Dergisi",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282974790",
          "title": "Artificial intelligence and its effects on critical thinking and problem-solving abilities in higher education",
          "authors": [
            "Ide Aprianto",
            "Sofyan Sofyan",
            "Sophia Rahmawati",
            "Susanti Sufyadi"
          ],
          "year": 2025,
          "venue": "Indonesian Journal of Educational Development",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283138035",
          "title": "L'Intelligence Artificielle dans la Formation des Enseignants des SVT : Entre Adoption Prometteuse et Défis Persistants",
          "authors": [
            "Zerrouqi Zahra",
            "Laghmari Mustapha",
            "Bouzidi Chaymae",
            "E. Ahlam",
            "Mazza Fatima Zahra"
          ],
          "year": 2025,
          "venue": "International Journal For Multidisciplinary Research",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282755329",
          "title": "An AI for an AI: AI-generated interactive animated questions as a defense against AI-based cheating",
          "authors": [
            "Saleem Hamady"
          ],
          "year": 2025,
          "venue": "The Physical Educator",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282955449",
          "title": "STEM Education: Understanding Secondary Students’ Epistemic Cognition in the Design Process with the Support of a Personalized Multi-Agent System",
          "authors": [
            "Lei Gao",
            "Morris Siu-Yung Jong",
            "Ching-sing Chai",
            "Keru Li"
          ],
          "year": 2025,
          "venue": "Computers &amp; Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283326712",
          "title": "Effects of LLM Use and Note-Taking on Reading Comprehension and Memory: A Randomised Experiment in Secondary Schools",
          "authors": [
            "Pia Kreijkes",
            "Viktor Kewenig",
            "Martina Kuvalja",
            "Mina Lee",
            "Jake M. Hofman",
            "Sylvia Vitello",
            "Abigail Sellen",
            "Sean Rintel",
            "Daniel G. Goldstein",
            "David Rothschild",
            "Lev Tankelevitch",
            "Tim Oates"
          ],
          "year": 2025,
          "venue": "Computers &amp; Education",
          "citation_count": 6
        },
        {
          "external_id": "CorpusId:283351055",
          "title": "Will AI Write the Next \"Chapter\" in Literature Reviews?",
          "authors": [
            "Felix Blanc-Durand",
            "M. Koopman",
            "S. P. Patel",
            "M. Aldea",
            "J. Kather"
          ],
          "year": 2025,
          "venue": "Annals of Oncology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282580958",
          "title": "Do generative artificial intelligence (GenAI) and science education mix? A systematic review of the literature",
          "authors": [
            "Kason Ka Ching Cheung",
            "Amina Zerouali",
            "Jenna Koenen",
            "S. Erduran"
          ],
          "year": 2025,
          "venue": "Studies in science education",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282432222",
          "title": "Use of ChatGPT in nursing education: A mixed method research on student perceptions and experiential practice recommendations.",
          "authors": [
            "Suna Uysal Yalçın",
            "Y. Dikmen"
          ],
          "year": 2025,
          "venue": "Nurse Education in Practice",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281931116",
          "title": "Exploring the Impact of AI Tools on Cognitive Skills: A Comparative Analysis",
          "authors": [
            "Nurlan Musazade",
            "J. Mezei",
            "Xiaolu Wang"
          ],
          "year": 2025,
          "venue": "Algorithms",
          "citation_count": 1
        }
      ],
      "citations_fetched_at": "2025-12-16T21:43:30.232272",
      "references": [
        {
          "external_id": "CorpusId:267242459",
          "title": "Generative AI Professional Development Needs for Teacher Educators",
          "authors": [
            "Matthew Nyaaba",
            "Xiaoming Zhai"
          ],
          "year": 2024,
          "venue": "Journal of AI",
          "citation_count": 42
        },
        {
          "external_id": "CorpusId:265352181",
          "title": "NERIF: GPT-4V for Automatic Scoring of Drawn Models",
          "authors": [
            "Gyeong-Geon Lee",
            "Xiaoming Zhai"
          ],
          "year": 2023,
          "venue": "Journal of Science Education and Technology",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:264144600",
          "title": "Efficacy and limitations of ChatGPT as a biostatistical problem-solving tool in medical education in Serbia: a descriptive study",
          "authors": [
            "Aleksandra Ignjatović",
            "Lazar Stevanović"
          ],
          "year": 2023,
          "venue": "Journal of Educational Evaluation for Health Professions",
          "citation_count": 31
        },
        {
          "external_id": "CorpusId:261049075",
          "title": "Elucidating STEM Concepts through Generative AI: A Multi-modal Exploration of Analogical Reasoning",
          "authors": [
            "Chen Cao",
            "Zijian Ding",
            "Gyeong-Geon Lee",
            "Jiajun Jiao",
            "Jionghao Lin",
            "Xiaoming Zhai"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:259968382",
          "title": "Artificial Intelligence Generative Tools and Conceptual Knowledge in Problem Solving in Chemistry",
          "authors": [
            "Wajeeh M. Daher",
            "Hussam Diab",
            "A. Rayan"
          ],
          "year": 2023,
          "venue": "Inf.",
          "citation_count": 46
        },
        {
          "external_id": "CorpusId:257943792",
          "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
          "authors": [
            "Tufan Adiguzel",
            "M. H. Kaya",
            "Fatih Kursat Cansu"
          ],
          "year": 2023,
          "venue": "Contemporary Educational Technology",
          "citation_count": 596
        },
        {
          "external_id": "CorpusId:259196547",
          "title": "A Testing Load: Investigating Test Mode Effects on Test Score, Cognitive Load and Scratch Paper Use with Secondary School Students",
          "authors": [
            "James Pengelley",
            "P. Whipp",
            "N. Rovis-Hermann"
          ],
          "year": 2023,
          "venue": "Educational Psychology Review",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:258846153",
          "title": "Human-like problem-solving abilities in large language models using ChatGPT",
          "authors": [
            "G. Orrú",
            "Andrea Piarulli",
            "C. Conversano",
            "A. Gemignani"
          ],
          "year": 2023,
          "venue": "Frontiers in Artificial Intelligence",
          "citation_count": 137
        },
        {
          "external_id": "CorpusId:258570040",
          "title": "Revolutionizing Medical Education: Can ChatGPT Boost Subjective Learning and Expression?",
          "authors": [
            "R. Seetharaman"
          ],
          "year": 2023,
          "venue": "Journal of medical systems",
          "citation_count": 69
        },
        {
          "external_id": "CorpusId:267376872",
          "title": "ChatGPT in Education",
          "authors": [
            "Sayım Aktay",
            "Seçkin Gök",
            "Dilşat Uzunoğlu"
          ],
          "year": 2023,
          "venue": "Türk Akademik Yayınlar Dergisi",
          "citation_count": 44
        }
      ],
      "references_fetched_at": "2025-12-16T21:43:30.878453"
    }
  },
  "25ba1751-4fe9-4436-9e78-28c28672d0eb": {
    "id": "25ba1751-4fe9-4436-9e78-28c28672d0eb",
    "filename": "ASC4459881735682400.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/25ba1751-4fe9-4436-9e78-28c28672d0eb_ASC4459881735682400.pdf",
    "status": "completed",
    "created_at": "2025-12-16 22:43:06.059507",
    "updated_at": "2025-12-16 14:45:11.809002",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "A Systematic Review of Automatic Neural Question Generation",
    "markdown_content": "# A Systematic Review of Automatic Neural Question Generation\n\nAsmaa M. Abdelwahab, Mahmoud M. Eid\n\nHigher Institute of Computers and Information Technology, Computer Science Department, El-Shorouk Academy, Cairo, Egypt\n\nEmail: asmaa. Abdelwahab@sha.edu.eq, mahmoud.eid@sha.edu.eq,\n\n# 1 Abstract\n\nThe ability to formulate meaningful questions is a fundamental aspect of both human and artificial intelligence. Neural Question Generation (NQG) uses deep learning techniques to automatically generate relevant questions from a given context. NQG systems have significant applications in improving question-answering models, facilitating educational tools, and enhancing conversational agents such as chatbots. However, a key challenge in NQG is the effective selection of target sentences and concepts for question formulation. This paper presents a systematic literature review (SLR) of NQG, analyzing different datasets, input preprocessing methods, methodologies, and evaluation techniques. We also highlight emerging trends and future directions in the field. Our review provides a comprehensive overview of NQG research, offering insights into current progress and remaining challenges. We find that all NQG models share a common Seq2Seq framework. In addition, the integration of Seq2Seq with attention mechanisms, as well as the use of part-of-speech (POS) tagging and named entity recognition (NER), contributes to the generation of accurate questions.\n\nIndex Terms—Natural Language Processing (NLP), Neural Question Generation (NQG), Deep Neural Networks, Question Answering Systems, Systematic Literature Review (SLR).\n\n# 1. INTRODUCTION\n\nNatural Language Processing (NLP) is a central subfield of computer science and artificial intelligence that focuses on enabling computers to understand and interact with human language. A fundamental challenge in NLP is training machines to process and analyze large amounts of natural language data (Joseph, 2016) (Sarkar, S,2025). The overall goal is to develop systems that can understand the content of various text formats, including sentences, queries, paragraphs, and documents. NLP techniques facilitate tasks such as text classification, where textual units are assigned labels or tags (Yang, 2020) (Maity, 2025). Applications of NLP range from answering questions and spam detection to sentiment analysis and news categorization. The sources of text data are diverse, including web content, email, forums, social media, and user reviews.\n\nAutomated text classification uses a variety of methods, including rule-based techniques and machine learning algorithms such as decision trees, naive Bayes, and k-means clustering (Semerikov, S. O, 2025) (Shervin et al., 2021). In addition, deep learning approaches, particularly those using neural networks, have gained prominence. Preprocessing steps, which can include punctuation removal, word segmentation, stop word filtering, and stemming (Elbes, 2019) (AlKhuzay, 2024), are critical to improving classifier performance. Feature selection methods, including information gain (IG), expected cross entropy (ECE), mutual information (MI), Gini index (GI), and chi-square (CHI) (Mucciaccia, 2025) (Bennabi, 2020), also play an important role in optimizing results.\n\nThis paper primarily focuses on neural Question Generation (QG), which uses deep neural networks to automatically generate questions from various inputs, such as raw text, databases, or semantic representations. Historically, question generation has relied on heuristic methods that rely heavily on human-designed transformation and generation rules, making it difficult to adapt to different domains (Heilman, 2011; Chali and Hasan, 2015). In contrast, Serban et al. (2016) introduced a neural network approach for generating factual questions from structured data. The ability to generate effective questions is crucial for assessing knowledge and promoting self-directed learning in educational contexts. In addition, QG can improve question-answering systems and enable chatbots to engage more dynamically in conversations.\n\nThe rest of this paper is organized as follows: The second section outlines the research methodology, specifically a Systematic Literature Review (SLR). The third section covers input text preprocessing techniques, including tokenization, segmentation, and the use of NLP tools such as word embeddings, Part-Of-Speech (POS) tagging, and Named Entity Recognition (NER). We will also explore neural question generation models, such as the sequence-to-sequence (seq2seq) model using Gated Recurrent Units (GRU) and seq2seq models with attention mechanisms. In addition, we will discuss evaluation metrics, including BLEU and precision. Finally, the fourth section presents conclusions and suggestions for future research.\n\n# 2. METHODOLOGY\n\nThe research approach follows the Systematic Literature Review (SLR) guidelines for the discipline of computer engineering as proposed by Kitchenham and Charter (Kitchenham, 2012). Figure 2.1 illustrates the key stages of our process, which we will discuss in the following sections.\n\nIn the planning stage, we defined our research topics and established the basic elements of the review protocol. To minimize subjectivity, we required that each phase begin only after the previous one had been thoroughly evaluated and approved.\n\nThe search strategy includes the criteria for selecting studies, the methods used, the search strings used, and the assessment of study quality. A significant portion of the third phase is devoted to developing our data extraction strategy. Finally, the final phase of the systematic review involves the preparation of a synthesis matrix to summarize and analyze the results.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/c268a39ab7c480d748d8c8ee361bfff22e7a144760aad18f81290a2ed00b2b71.jpg)  \nFigure 2.1: The key stages of our process (SLR).\n\n# 2.1 Research Questions\n\n# 2.1.1 Old Research Questions:\n\n[1] What is text classification and when did it originate?  \n[2] What are the different applications of text classification?  \n[3] Which languages are of interest for classification in this research?\n\n[4] What are the limitations and challenges of existing text classification methods?\n\n4.1 What are the limitations and challenges of existing automatic text classification (ATC) methods?\n\n[5] What data sets are available to evaluate model performance?\n\n5.1 What is an appropriate approach to document representation?  \n5.2 What are the different types of data preprocessing techniques?  \n5.3 How can unstructured data be handled effectively?\n\n[6] What are the appropriate methods for feature extraction and feature selection?  \n[7] What techniques are used for text classification, especially for news categorization and question answering applications? Which models perform best in these areas?  \n7.1 What techniques are used in ATC and which models are most effective?  \n[8] What solutions exist to improve the performance of current techniques?  \n[9] What methods are used to evaluate the performance of text classification models?  \n[10] What are the future research directions in text classification, especially in automatic text classification (ATC)?\n\n# 2.1.2 New Research Questions:\n\nThe primary objective of this research will be achieved by answering the following questions:\n\nRQ1. What is Neural Question Generation (NQG)?  \nRQ2. What are the different applications of NQG?  \nRQ3. Which languages are of interest for NQG research?  \nRQ4. What are the limitations and challenges of existing NQG methods?  \nRQ5. What benchmark data sets are available to evaluate the performance of NQG models?  \nRQ5.1 What is an appropriate approach for representing words?  \nRQ5.2 What are the different types of input preprocessing techniques?  \nRQ6. Which techniques are used in NQG?  \nRQ7. What are some possible solutions and strategies to improve the performance of current NQG methods?  \nRQ8. What methods are used to evaluate the performance of NQG models?  \nRQ9. What are future research directions for NQG?\n\n# 2.2 Data Sources and Search Strategy\n\nTable 2.1 illustrates how we identified research publications in computer science and software engineering using various database sources. The search terms were defined to include the following keywords, which were generated using logical operators to optimize the search results:\n\n1. Search string 1: ('document' OR 'text') AND ('classifier' OR 'categorization' OR 'classification') AND ('document representation' OR 'document preprocessing' OR 'models' OR 'methods' OR 'application' OR 'evaluation' OR 'assessment' OR 'challenges' OR 'limitations').  \n2. Search string 2: ('document' OR 'text') AND ('classifier' OR 'categorization' OR 'classification') AND ('research') AND ('future' OR 'trend' OR 'direction').  \n3. Search string 3: ('characteristic' OR 'attribute') AND ('selection' OR 'selected') AND ('text' OR 'document') AND ('classification' OR 'classifier' OR 'categorization').\n\nThese search strings were adapted to take advantage of the built-in tools for refining and filtering results in each database. In addition, we included gray literature and used a snowballing approach where each publication identified by our search criteria could be manually linked to other relevant citations in its references.\n\n<table><tr><td>Database</td><td>URL</td></tr><tr><td>ACM</td><td>ACM Digital Library</td></tr><tr><td>IEEE</td><td>https://ieeexplore.ieee.org/</td></tr><tr><td>Springer</td><td>http://link.springer.com/</td></tr><tr><td>Semantic Scholar</td><td>https://wwwsemanticscholar.org/</td></tr></table>\n\nTable 2.1: Databases\n\n# 2.3 Study Selection Criteria\n\nTo ensure the collection of quality and relevant data in response to our research questions, we implemented strict inclusion and exclusion criteria during this step. These criteria were applied after reviewing the title, abstract, and full text of each article.\n\n# Inclusion Criteria:\n\nThe paper is relevant to text classification (e.g., news categorization, question answering).  \nThe publication date is between 2016 and 2024.  \n- The paper highlights one or more problems, weaknesses, or limitations of existing text classification techniques, along with proposed solutions.  \nIt uses relevant keywords.  \nIt is related to the Arabic and/or English languages.  \nThe paper is written in English.\n\n# Exclusion criteria:\n\n- Articles not written in English.  \n- Articles published before 2016 or after 2024.  \nText classification models that are not evaluated using Arabic or English.\n\n# 2.4 Study Selection Process\n\nThe primary study selection process consisted of three separate steps, as shown in Figure 2.2. Applying the search string to the four scientific databases listed in Table 2.1 generated over 2,000 articles.\n\n# - Iteration 0 - Filtering by Title\n\nIn this phase, the titles were evaluated against the inclusion and exclusion criteria. Articles deemed relevant were immediately included in the next phase. A total of 230 publications were selected for further review.\n\n- Iteration 1 - Filtering by Abstract and Keywords\n\nIn this phase, the abstracts and keywords were evaluated against the inclusion and exclusion criteria. Articles considered relevant were included in the next stage. A total of 220 publications were selected in this phase.\n\n# - Iteration 2 - Filtering by Full Text\n\nThis was the final step in which the full texts were examined based on the quality assessment criteria (as detailed in section E). We ranked the papers from the previous step and selected the top 15 for further review. My supervisor then provided me with 6 key papers. Finally, 21 articles were included in the final step.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/701417b28c38c1a25214d49265bf20bc90a7b325f82ca5ba4688fdd8d35617c7.jpg)  \nFigure 2.2: The number of studies included in each study selection phase.\n\n# 2.5 Quality Assessment\n\nIncluded papers had to pass a quality check, which included positive answers to the following questions\n\nWhat is the impact factor of the journal or conference?  \nWhat is the number of citations?  \nIs the data set clearly identified and well described?  \nAre the preprocessing techniques used in the study well described and their selection justified?  \n- Is the total number of training and test data provided?  \n- Are the classifiers used in the study discussed in detail?  \n- Is there a comparison of different approaches?  \nAre performance metrics defined in detail?\n\n<table><tr><td>Ref</td><td>QA1</td><td>QA2</td><td>QA3</td><td>QA4</td><td>QA5</td><td>QA6</td><td>QA7</td><td>QA8</td><td>Total</td><td>percentage</td></tr><tr><td>(Minaee,2021)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7.5</td><td>93.75%</td></tr><tr><td>(Alabbas,2016)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Ahlam Wahdan,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Abdeen,2019)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Bennabi,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(AI Qadi, Leen,2019)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Ezzeldin,2012)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Zhang,2021)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Elbes,2019)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Rachid,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Pandolfi,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Wahdan,2021)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Liu,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Kadhim,2019)</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>6.5</td><td>81.25%</td></tr><tr><td>(Shehab,2016)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>0.5</td><td>1</td><td>6.5</td><td>81.25%</td></tr></table>\n\nTable 2.2: QA Paper\n\n# 2.6 Included papers\n\nIn this section, we present the distribution of included papers based on the following criteria: database, year, type (journal or conference), and publisher.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/c59825cc251724398f34d513513584066e8cdbf75d8cf59f82d9fd5e1907be37.jpg)  \nFigure 2.1: distribution based on type\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/aff849c475477ddc6cffd4eff620759c7206451779e1bfd12d458bb61917fa5d.jpg)  \nFigure 2.2: based on databases\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/8b24582aed7778c07ef370d28cb4216769b280d0d690b4173007e0e0cad6a994.jpg)\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/acda562152bc49e3fd8241fec1224d786d9f7db4abd17070b52f44827cb25315.jpg)\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/a427a1beb7f6e5e264c7b4a10f144fb057739f9b671de422a8af87b489a72b10.jpg)  \nFigure 2.3: distribution based on year  \nFigure 2.4: Distribution of top 15 papers  \nFigure 2.5: distribution based on publisher\n\n# 2.7 Data Extraction Strategy\n\nData were extracted from the studies, and Table 2.3 shows the characteristics that were collected and included:\n\n# Paper Information:\n\nTitle Author  \nPublication year  \nJournal name  \nStudy type\n\n# Data extracted:\n\nThe form included the following characteristics:\n\n- Paper Objective  \nExcerpts from Introduction  \nExcerpts from Literature Review  \nQuestion Generation (QG) Algorithm  \nEvaluation Metrics  \nConclusion  \nResearch Questions Addressed\n\nThe data extracted from the sample papers is shown in Table 2.4.\n\n<table><tr><td colspan=\"2\">Paper Information</td></tr><tr><td>1. Title</td><td></td></tr><tr><td>2. Author</td><td></td></tr><tr><td>3. Year</td><td></td></tr><tr><td>4. Journal</td><td></td></tr><tr><td>5. Study Type</td><td></td></tr><tr><td colspan=\"2\">Extracted Data</td></tr><tr><td>6. Which research question will be answered?</td><td></td></tr><tr><td>7. Objective extracted from the study</td><td></td></tr><tr><td>8. Extracted pieces from Introduction</td><td></td></tr><tr><td>9. Extracted pieces from Literature review</td><td></td></tr><tr><td>10. Extracted pieces from EXPERIMENTAL STUDY (optional)</td><td></td></tr><tr><td>11. Conclusion Extracted</td><td></td></tr></table>\n\nTable 2.3: DE Form  \n\n<table><tr><td colspan=\"2\">Paper Information</td></tr><tr><td>1. Title</td><td>Learning to Ask: Neural Question Generation for Reading Comprehension</td></tr><tr><td>2. author</td><td>Du &amp; Shao (2017)</td></tr><tr><td>3. Year</td><td>2017</td></tr><tr><td>4. journal</td><td>arXiv preprint arXiv:1705.00106 (2017).</td></tr><tr><td>5. Study Type</td><td>Experimental Study</td></tr><tr><td colspan=\"2\">Extracted Data</td></tr><tr><td>6. Which research question will be answered?</td><td>RQ1 – RQ2 – RQ4 – RQ6– RQ7 - RQ8</td></tr><tr><td>7. Objective extracted from the study</td><td>In reading comprehension, investigate automatic question generation for sentences from text passages.</td></tr><tr><td>8. Extracted pieces from Introduction</td><td>·Question generation (QG) is a technique for generating natural questions from a sentence or paragraph.\n·One of the most common uses of question creation is in the field of education, where it is used to produce reading comprehension questions.\n·Question generation has traditionally been approached using rule-based methodologies.\n·In contrast to previous work, we propose framing the task of question production as a sequence-to-sequence learning issue, in which a sentence from a text passage is immediately translated into a question.</td></tr><tr><td>9. Extracted pieces from Literature review</td><td>·Reading comprehension is a difficult challenge for robots since it necessitates both a grasp of natural language and a knowledge of the world.\n·The majority of work takes a rule-based approach to solving the problem.\n·They usually start by converting the input sentence to its syntactic representation, which they then utilise to create an interrogative sentence.\n·To our knowledge, no previous work has employed a deep sequence-to-sequence learning approach to generate questions or framed QG for reading comprehension in an seq-to-seq manner.</td></tr><tr><td>10. Extracted pieces from EXPERIMENTAL STUDY and Results</td><td>Dataset:\n·SQuAD dataset\nPerprocessing:\n·first use Stanford CoreNLP Tokenization and sentence splitting are used for pre-processing. The full dataset is then lower-cased.\nModel:\n·encoder:encode both sentence and paragraph-level information with attention mechanism.\n·Decoder:Decodes the questions using the concatenated representation.\nEvaluation Metrics:\n·Automatic Evaluation\n·Human Evaluation\nResults:\n·The proposed model, which simply encodes sentence-level information, outperforms all others on all criteria.\n·The proposed model, which encodes paragraph information, performs best on questions in the \"w/ paragraph\" category.</td></tr><tr><td>11. Conclusion</td><td>It demonstrated a technique to autonomous question development for reading comprehension based entirely on data-driven neural networks.\nUsing an attention-based neural networks method, we investigate the effect of encoding sentence-level vs. paragraph-level information.\nThe suggested model produces state-of-the-art results in both automatic and human evaluations.</td></tr></table>\n\n# 2.8 Synthesis Matrix\n\nThe synthesis matrix for the studies is tabulated as shown in Table 2.5. It includes the following characteristics:\n\nAuthor  \nPublication Year  \n- Paper Objective  \n- Preprocessing Methods (if applicable)  \n- Datasets Used  \n- Question Generation (QG) Algorithms/Methodology  \nEvaluation Metrics  \nConclusion\n\nTable 2.4: Data extracted from sample paper  \n\n<table><tr><td>Source (Author//Year)</td><td>Application Type(QA/QG P/QG /NC/Survey)</td><td>Purpose of study</td><td>Preprocessing Methods</td><td>Datasets</td><td>Methodology/Algo rithm</td><td>Results/ Evaluation Metrics</td><td>Conclusion</td></tr><tr><td>Derwin Suharto no,2024</td><td>automatic question generation</td><td>to compare several state- of-the-art pre-trained models to create an automatic question generator with narrative paragraphs as input.</td><td>-the paragraph is broken down into smaller units called tokens.-These tokens can be individual words, punctuation marks, or other meaningful units.-Each token is assigned a part-of-speech tag, specific answers are extracted</td><td>SQuAD, TyDiQA, IDK-MRC Datasets</td><td>uses the Sequence-to-Sequence Learning architecture of BiGRU, BiLSTM, Transformer, BERT, BART, and GPT</td><td>BLEU-1: IndoBERTFo rmer 29.14 IndoBERTFo rmer 30.45</td><td>- this research only evaluates these models for the case of creating short answer questions this research only uses three trained models: Indo BERTFormer, IndoBARTFom er, IndoTransGPT, Our methodology efficiently uses context-to-</td></tr><tr><td></td><td></td><td></td><td>from the postage tensor based on specific criteria or questions.</td><td></td><td></td><td></td><td>answer attention more reliably than longer answers to extract more relevant information from surrounding sentences</td></tr><tr><td>Xinya Du,2017</td><td>Question Generation</td><td>In reading comprehension, investigate automatic question generation for sentences from text passages.</td><td>To begin, perform pre-processing with Stanford CoreNLP, which includes tokenization and sentence splitting. The full dataset is then lower-cased.</td><td>SQuAD dataset</td><td>encoder: use an attention technique to encode information at the sentence and paragraph levels.Decoder: decodes the questions using the concatenated representation.</td><td>Metrics:AE,HE Results:The proposed approach obtains the greatest results by just encoding sentence-level information.</td><td>In both automatic and human evaluations, the proposed model (encoder - decoder with attention mechanism) achieves state-of-the-art performance.</td></tr><tr><td>Wang,2020</td><td>Question Generation</td><td>Based on an encoder-decoder framework and reinforcement learning, we propose an ADDQG model. Questions can be generated from answers and document representations.</td><td>Use pre-trained GloVe word vectors for word embedding.</td><td>HotpotQA,</td><td>The model's main idea is to merge the answer information with the content using an answer-aware initialization module and a semantic rich fusion attention mechanism. In addition, reinforcement learning is used. Using the Maxout Pointer and the Copy Mechanism</td><td>MetricsAutomatic Evaluation:BLEU, METEOR, ROUGE Human Evaluation</td><td>Reinforcement learning is also used to improve ADDQG training by using both syntactic and semantic metrics as the reward.</td></tr><tr><td>Zhou,2017</td><td>Question Generation</td><td>It proposes that natural language sentences be used to generate relevant and diversified queries using the neural encoder decoder architecture.</td><td>--</td><td>SQuAD dataset</td><td>The NQG framework consists of a feature-rich encoder and an attention-based decoder.The BiGRU encoder reads the concatenated sentence word vector, lexical characteristics, and answer position feature.Copy Mechanism</td><td>This demonstrates how lexical features and an indicator of answer position can help with question development. With the assistance of the copy mechanism,</td><td>The suggested technique uses a feature-rich encoder to encode answer location, POS, and NER tag information.Experiments demonstrate that the proposed NQG technique is effective.</td></tr><tr><td>Yao, 2021</td><td>Question and Answer Pair Generation</td><td>Create an educational automated</td><td>--</td><td>Using Fairy Tale QA, a new QA</td><td>Methodology: The QAG system in this paper consists</td><td>ResultsAll of the data reveal that our</td><td>The work sets a strong foundation for</td></tr><tr><td></td><td></td><td>question-answer generation (QAG) system. The technology can generate QA pairings that can be used to assess a range of student comprehension skills automatically.</td><td></td><td>dataset with 278 kid-friendly storybooks and 10,580 expert-labeled QA pairs.</td><td>of three steps: (1) extracting candidate answers from given storybook passages using carefully designed heuristics based on a pedagogical framework; (2) generating appropriate questions corresponding to each of the extracted; and (3) ranking top QA-pairs with a specific threshold for the maximum amount of QA-pairs for each section..</td><td>approach receives above-average 601 (&gt;3) ratings, implying that it achieves acceptable levels of user satisfaction across all three aspects (Readability, Question Relevancy, Answer Relevancy).</td><td>the bright future of applying artificial intelligence to automate educational question-answering chores.</td></tr><tr><td>Pan, 2019</td><td>Survey(NQG)</td><td>give a thorough examination of the corpora, methodology, and evaluation methods for neural question generation</td><td>--</td><td>SQuAD, MS MARCO,Ne wsQA,RAC E,LearningQ ,NarrativeQ A.</td><td>give a thorough examination of the corpora, methodology, and evaluation methods for neural question generation In passage X, asking about the goal response A is defined as finding the optimal question Y. The Seq2Seq framework is shared by all NQG models, but they differ in how they consider (1) QG-specific characteristics (for example, response encoding, question word formation, and paragraph-level contexts) and (2) common NLG techniques (e.g., copying mechanism, linguistic features, and reinforcement learning).</td><td>Human evaluation is used in the majority of QG systems. BLEU, METEOR, and ROUGE are examples of automatic evaluation metrics.</td><td>This research offered a comprehensive overview of NQG, identifying current NQG models based on QG-specific and common technical changes, and highlighting three growing NQG trends: multitasking, a wider range of input modalities, and the development of profound questions.. In many real-world applications, such as automated tutoring and conversational systems, where the question plays a crucial role, knowing when to enquire has become a vital difficulty.</td></tr><tr><td>Benaissa Azzeddine Rachid,20 20</td><td>News Classification</td><td>Researchers used neural network models (Convolutional and Recurrent Neural Networks) and pre-trained word embeddings in a series of experiments to classify cyberbullying situations using an Arabic channel news comments dataset.</td><td>Punctuation in Arabic and English has been removed. word embeddings as a source of data for deep learning algorithms</td><td>Aljazeera.net, an Arabic news station.</td><td>CNN, LSTM GRU combination of both. SVM</td><td>The findings show that using simple and combined Convolutional and Recurrent Neural Networks (CNN/LSTM/GRU) with Arabic pre-trained word embeddings (AraVec and Fast text) combined with Arabic pre-trained word embeddings (AraVec and Fast text) combined with Arabic pre-trained word embeddings (AraVec and Fast text) can achieve an F1 score of 84 percent on a balanced dataset..</td><td>techniques of CNN-RNN , both simple and mixed, perform well.</td></tr><tr><td>Menghan Zhang,20 21</td><td>News Classification</td><td>the concept of a customised algorithm, which is a mix of deep learning algorithms such as CNN and LSTM</td><td>Using the word2vec model, word segmentation and stop word filtering</td><td>Reuters News</td><td>For the classification of news text data, a bespoke DCLSTM-MLP model was used.</td><td>Accuracy of DCLSTM-MLP is 94%</td><td>The DCLSTM-MLP model outperforms the CNN and LSTM models in terms of accuracy.</td></tr><tr><td>Ahmed Magdy ,2012</td><td>Answer Generation(survey)</td><td>--</td><td>Stemming, Named Entity Recognition</td><td>SQuAD</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Leen Al Qadi, 2019</td><td>News Articles classification</td><td>To automatically determine a document's category.</td><td>--</td><td>---</td><td>Famous techniques in classification were used: Logistic Regression, Nearest Centroid, Decision Tree (DT), Support Vector Machines (SVM), K-nearest neighbors (KNN), XGBoost Classifier, RandomForest Classifier, Multinomial Classifier, Ada-Boost Classifier,</td><td>--</td><td>Among all the other classifiers, the SVM model generated the best results.</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>and Multi-Layer Perceptron (MLP).</td><td></td><td></td></tr><tr><td>Shervin Minaee,20 21</td><td>TC(A Comprehensive Review)</td><td>provide a quantitative analysis of various deep learning models' performance on popular benchmark datasets</td><td>--</td><td>Sentiment Analysis (YelpIMDb) NCDatasets( AG News, 20 Newsgroups.</td><td>Naïve Bayes, (SVM), hidden Markov model (HMM), gradient boosting trees, and random forests</td><td>--</td><td>--</td></tr><tr><td>Sakina Rim BENNAB I,2020</td><td>FS(Comparative Study)</td><td>The goal of this paper is to give a comparison of several feature selection strategies.</td><td>--</td><td>--</td><td>Classification algorithms: SVM, KNN and NB.</td><td>--</td><td>--</td></tr><tr><td>Mohamm ad A.R. Abdeen, 2019</td><td>ATC (Review Paper)</td><td>a thorough examination of the Arabic text classification: The methodology, datasets, and feature selection strategies described in this paper</td><td>Normalization stemming algorithms</td><td>--</td><td>TC Methods : Decision Trees: Naïve Bayesian k-means algorithms Hierarchical clustering algorithms.(better than K-means).</td><td>--</td><td>--</td></tr><tr><td>Ahlam Wahdan,2 020</td><td>ATC(Systematic Literature Review)</td><td>examining neural network-based Arabic text categorization</td><td>--</td><td>--</td><td>Classification Techniques : Techniques that are both manual and statistical. Machine learning techniques</td><td>--</td><td>--</td></tr><tr><td>W.Alabba s, 2016</td><td>ATC(Systematic Literature Review)</td><td>Arabic text is classified using a variety of TC approaches and methods.</td><td>--</td><td>--</td><td>SVM,NB, Decision-tree, k-NN</td><td>--</td><td>--</td></tr><tr><td>Ammar Ismael Kadhim,2 019</td><td>Survey(ML for TC)</td><td>Text classification surveys, the process of varying term weighing strategies, and a comparison of alternative categorization procedures.</td><td>--</td><td>--</td><td>Naïve Bayes, SVM KNN</td><td>--</td><td>--</td></tr><tr><td>Shehab,20 16</td><td>multilabel classification of Arabic articles</td><td>focuses on Arabic article multilabel categorization</td><td>--</td><td>--</td><td>classifiers are considered (DT, RF and KNN).</td><td>--</td><td>--</td></tr><tr><td>Ahlam Wahdan, 2021</td><td>ATC</td><td>The goal of this study is to see how deep learning affects ANLP text classification.</td><td>--</td><td>--</td><td>Many techniques, such as word embedding and deep learning, have been employed to improve the application of</td><td>--</td><td>--</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>natural language processing.</td><td></td><td></td></tr><tr><td>Maurizio, 2021</td><td>Web News</td><td>News-related data was gathered from the web and classified using machine learning and data mining techniques.</td><td>Stop words removal, Stemming, Tokenizing</td><td>--</td><td>Clustering, support vector machines, and generative models were the three most common paradigms discovered.</td><td>--</td><td>--</td></tr><tr><td>Mohammed Elbes,2019</td><td>P-Stemmer or NLTK Stemmer for Arabic Text Classification?</td><td>Using the above-mentioned categorization technique, we compared the outcomes of two stemmers: P-Stemmer and NLTK stemmer.</td><td>Preprocessing: P-Stemmer and the NLTK</td><td>--</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Liu,2020</td><td>Comparison on Feature Selection Methods for Text Classification</td><td>Discussions to compare the performance of common feature selection strategies used in text classification studies in the past.</td><td>Feature selection techniques: Information gain (IG) Expected cross entropy (ECE) mutual information (MI) Gini index (GI) The core of Chi-square (CHI) The core of Odd ration (OR)</td><td>--</td><td>--</td><td>--</td><td>--</td></tr></table>\n\nTable 2.5: Synthesis Matrix\n\n# 3. RESULT AND DISCUSSION\n\n# 3.1 Neural Question Generation (NQG)\n\nThe NQG model focuses on generating a question based on the target answer within a passage. Several modern NQG models use the Seq2Seq architecture, including RRN, LSTM, and GRU, often incorporating an attention mechanism to process a passage and its target answer. Popular NQG techniques include copying mechanisms and reinforcement learning (Pan, 2019).\n\n- Datasets commonly used in NQG include SQuAD, MS MARCO, NewsQA, RACE, LearningQ, and NarrativeQA.  \n- The evaluation metrics used in the field include both human and automated techniques such as BLEU, METEOR, ROUGE, and precision.\n\nThe remainder of this section will focus primarily on the Seq2Seq architecture (especially GRU), attention mechanisms, lexical features (POS and NER), and evaluation metrics, especially BLEU and precision.\n\n# 3.1.1 Word Embedding\n\nLanguage comprehension has always been a strong suit of humans. The relationships between words are often easy for humans to understand; however, this task can be challenging for computers. For example, while humans easily recognize the relationships between words such as \"king\" and \"queen,\" \"man\" and \"woman,\" or \"tiger\" and \"tigress,\" computers must learn to recognize these connections (Yin & Shen, 2018).\n\nWord embeddings are a type of word representation that bridge language understanding between machines and humans. They are n-dimensional text representations in which words with similar meanings are represented by similar vectors that are located close together in vector space. This capability is essential for addressing many challenges in natural language processing.\n\nIn word embeddings, each unique word is represented as a real-valued vector in a defined vector space. Each word is characterized by a single vector whose values are learned in a manner similar to a neural network.\n\nWord2Vec (Rong, 2014) is one of the most widely used shallow neural network algorithms for learning word embeddings. It was developed in 2013 by Tomas Mikolov at Google.\n\n# 3.1.2 Seq2Seq\n\nA major challenge with the basic RNN model is that it struggles with long sentences, often resulting in poor understanding of meaning. To deal with long dependencies, we use sequence-to-sequence (Seq2Seq) models (Shao, 2017).\n\nDeep learning techniques, especially Seq2Seq models, have achieved significant success in applications such as machine translation, text summarization, image captioning, question answering (QA), and question generation (QG). In late 2016, Google Translate began using such a model in its production environment.\n\nA Seq2Seq model generates a new sequence of words from a given input sequence.\n\nThe Model As shown in Figure 3.2, the model consists of an encoder and a decoder. Each element in the input sequence is processed by the encoder, which converts the collected data into a vector called the context. Once the entire input sequence has been processed, this context is sent from the encoder to the decoder, which begins to generate the output sequence token by token.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/425af988c6117a62be1fe84f8d618e3b6c677defc3dde28f28180a5f9dbe9d28.jpg)  \nFigure 3.1: [9] Encoder - Decoder architecture.\n\nThe context is represented by a vector, and recurrent neural networks (RNNs) are commonly used for both the encoder and decoder. The size of the context vector can be specified during model creation and is typically determined by the number of hidden units in the encoder RNN. In real-world applications, the context vector may be 256, 512, or 1024 units long.\n\nAt each time step, an RNN takes two inputs: the current input (in the case of the encoder, a single word from the source sentence) and the previous hidden state. To generate the output for that time step, the RNN combines the current input vector with the previous hidden state. After processing its inputs, the RNN produces an output for that time step and updates its hidden state based on the current and previous inputs. The decoder also maintains hidden states that are carried across time steps, although we haven't illustrated this in this context.\n\nAmong the various approaches to sequence-to-sequence modeling, one notable option is the Gated Recurrent Unit (GRU).\n\n# 3.2 Gated Recurrent Units (GRUs)\n\nGRUs are a special type of RNN designed to learn long-term dependencies. They were introduced in 2014 by Kyunghyun Cho. Like Long Short-Term Memory (LSTM) networks, GRUs manage the flow of information through gates. However, GRUs are relatively new compared to LSTMs, and they often perform better due to their simpler architecture (Yuan, 2019).\n\n# The Architecture of the GRU\n\nNow let's understand how GRUs work. A GRU consists of two main gates: the update gate and the reset gate, as shown in Figure 3.3. These gates help determine what information should be retained, passed on, or discarded.\n\nAs mentioned earlier, the gates' output values between 0 and 1. A value of 0 indicates that the information is unimportant, while a value of 1 indicates that it is important. Values closer to 0 indicate unimportance and values closer to 1 indicate importance.\n\nAt each timestamp  $t$ , the GRU takes an input  $X_{t}$  and the previous state  $H_{t-1}$  from the previous timestamp. As shown in Figure 3.4, it then generates a new hidden state  $H_{t}$ , which is passed to the next timestamp.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/6a3095fe543d86ce6d046c97c29f2582389ff832c8067d0dd68d7b3fc7e1cfca.jpg)  \nFigure 3.2: Overall structure within the GRU cell (sefidian,2020)\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/1fcc81348220b9417d7a09906664f8c1f39c044bad02ca252be70409cad09fda.jpg)  \nFigure 3.3: GRUs follow the same flow as the typical RNN (sefidian,2020)\n\nUpdate Gate (z): The primary function of this gate is to inform the model how much of the previous information should be preserved, i.e., passed on to future states.\n\nReset Gate (r): This gate is used by the model to determine how much information from the past should be forgotten.\n\nAs usual, there are weights associated with each gate.\n\n# Math and pictorial representation to understand the functioning\n\n# Update gate:\n\n-  $Z_{t}$  represents the update gate.  \n- The parameters are the input representation  $X_{t}$  and the prior hidden state  $H_{t - 1}$  state information multiplied by their corresponding weights.  \n-  $Z_{t}$  is calculated using sigmoid activation. as shown in Figure 3.5.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/57c67f150b4b27bdc1bfd66c95d3e2947d4addefdf7280dd7debd56a40cedb5e.jpg)  \nFigure 3.1: Update Gate (andreaperlato, 2022)\n\n$$\nZ _ {t} = \\sigma (W ^ {(Z)} X _ {t} + U ^ {(Z)} h _ {t - 1})\n$$\n\n# Where,\n\nt: current step.  \n-  $X_{t}$ : Input vector.  \nZt: update gate vector.  \nW and U are vectors and parameter matrices.  \n-  $h_{t - 1}$ : The previous hidden state.\n\n# Reset gate\n\n-  $r_t$  represents the reset gate  \n- The parameters are the input representation  $X_{t}$  and the prior hidden state  $H_{t - 1}$  state information multiplied by their corresponding weights.  \n-  $\\mathsf{r}_{\\mathrm{t}}$  is calculated using sigmoid activation as show in Figure 3.6.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/9337c41bdc6d1cffe84293459239b87fb3b16a05fefa7ce083fa8bea93261242.jpg)  \nFigure 3.2: Reset Gate (andreaperlato, 2022)\n\n$$\nr _ {t} = \\sigma (W ^ {(Z)} X _ {t} + U ^ {(r)} h _ {t - 1})\n$$\n\n# Where,\n\nt: current step.  \n-  $X_{t}$ : Input vector.  \n-  $r_t$ : vector of Reset gate.  \nW and U: vectors and parameter matrices.  \n-  $h_{t-1}$ : The previous hidden state.\n\n# How GRU Works\n\n- A new device has been introduced: the reset gate, which is used to retrieve previously stored data from a memory device.  \n- Consider a movie review. Initially, you might start with \"The movie was directed by X; it starred Y\". After about ten lines, you conclude, \"I think the movie is bad for the money I paid. In this case, the actual review is the last line. The neural network should not remember the earlier sentences and should focus on the last sentence to capture the essence of your opinion. This focus is enabled by the reset gate.  \n- To discard irrelevant information,  $r_t$  is set to 0 until the last sentence is analyzed.  \n- Then the tanh activation function is applied, resulting in  $h_{\\mathrm{t}}^{\\prime}$  (Candidate Hidden State), as shown in Figure 3.7.  \n- The final phase of the network is to compute and output the  $h_t$  vector, which contains information about the current unit.  \nThis process requires the use of the update gate as shown in Figure 3.8.\n\n$$\nh _ {t} ^ {\\prime} = \\tanh (W X _ {t} + r _ {t} \\theta U h _ {t - 1})\n$$\n\n$$\nh _ {t} = Z _ {t} \\theta h _ {t - 1} + (1 - Z _ {t}) \\theta h _ {t} ^ {\\prime}\n$$\n\nWhere,\n\n$h_t^\\prime$  : candidate hidden state vector.  \n$h_t$ : The output vector.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/3c47a63bf9083d6124b7965c5647e7dc16e619b104661ab42a4533e9d3734f19.jpg)  \nFigure 3.3: Candidate hidden state architecture (Krishnan,2022).\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/39533c141137efbc3e1d190ce4dee13131e49a57d8760017f797f0d06dbf02fc.jpg)  \nFigure 3.4: The architecture of GRU in recurrent neural networks (Krishnan,2022).\n\n# What is the difference between the GRU and the LSTM?\n\nThe main differences are as follows (Li, 2021):\n\nNumber of gates: LSTM has three gates, while GRU has two.\n\n- Internal memory and output gate: LSTM contains both an internal memory cell and an output gate, which are absent in GRU.  \n- Gate functionality: In LSTM, the update gate connects the input and forget gates, while in GRU, the reset gate is applied directly to the previous hidden state. In LSTM, the reset gate is shared by the input and forget gates.  \n- Training parameters: GRU has fewer training parameters than LSTM, which means it uses less memory and runs faster. However, LSTM generally provides more accuracy on large data sets, while it may be less accurate on smaller data sets. If you're working with long sequences and accuracy is critical, LSTM is preferable. If you have limited memory and need faster results, GRU is the better choice.\n\n# 3.2.1 Word2Vec\n\nWord2Vec is a neural network-based method for rapidly building word embeddings. It was developed by Tomas Mikolov at Google in 2013 in response to the need for more efficient training of neural network-based embeddings, and has since become the de facto standard for developing pre-trained word embeddings.\n\nWord2Vec takes a text document as input and produces a set of feature vectors representing the words in the document. Although Word2Vec is not a deep neural network, it translates text into a numerical representation that deep neural networks can recognize. According to the Word2Vec objective function, words with similar contexts will have similar embeddings. As a result, such words are located close to each other in this vector space. Mathematically, the cosine of the angle  $Q$  between these vectors should be close to 1, which means that the angle itself should be as close to 0 as possible, as shown in Figure 3.1. Word2vec has two types: CBOW and the Skip-gram model.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/415c418a586a12ce9ac9e5a33d77c336d6d02d53f3a90e1dfa796818831b901b.jpg)  \nFigure 3.5: Similar words are closely placed in vector space (Great Learning Team, 2020)\n\n# 3.2.2 Seq2Seq with Attention Mechanism\n\nThe Seq2Seq paradigm is designed to transform a source sequence into a target sequence, as shown in Figure 3.9.\n\nWhen we input an English source sentence into the encoder, it gathers all the information from the source sequence into a single real-valued vector called the context vector. This context vector is then used by the decoder to construct an output sequence in a target language, such as Hindi. The primary goal of the context vector is to condense the entire input sequence into a single representation.\n\nBut can a single vector from the encoder effectively contain all the important information when the input sentence is long? Is it possible to predict the target word by focusing on a few relevant words in the sentence rather than relying on a single vector?\n\nThe attention mechanism addresses these challenges. Its main purpose is to eliminate the need for a single vector representation for each sentence. Instead, it uses attention weights to focus on specific input vectors from the sentence.\n\nDuring each decoding step, the decoder receives a set of attention weights that indicate how much \"attention\" should be given to each input word. These attention weights provide the decoder with contextual information for translation, as shown in Figure 3.10.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/2eee881ac681ca9ad893c3dc2d3e6e9f5613c70ae8c9bd50a59d946f8f074db6.jpg)  \nFigure 3.6: Seq2Seq Architecture with attention mechanism (Li,2021).\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/117c0211e9cb0f304687185985d2e434e33b6e900c7ffef48acbe79361ecb837.jpg)  \nFigure 3.7: Seq2Seq Architecture (Li,2021).\n\n# 3.2.3 Preprocessing\n\nThere are two types of preprocessing: traditional and QG-specific. Traditional preprocessing prepares the input for subsequent tasks, including segmentation, tokenization, and part-of-speech (POS) tagging.\n\nIn some cases, named entity recognition (NER) is also required. In this report, we focus on POS tagging and NER.\n\n# 3.2.4 Lexical Feature (POS)\n\nPart-of-speech tagging: Assign a part-of-speech tag to each token in a sentence.\n\nFor example:\n\n<table><tr><td>I</td><td>like</td><td>his</td><td>watch</td></tr><tr><td>Pro</td><td>verb</td><td>pro</td><td>noun</td></tr></table>\n\n<table><tr><td>the</td><td>Fans</td><td>watch</td><td>the</td><td>race</td></tr><tr><td>Dt</td><td>Noun</td><td>verb</td><td>dt</td><td>noun</td></tr></table>\n\nThe words categorize into 2 classes (open Vs close):\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/4ed984763c63d36c08d1ad82ab489cdc3cb137d9736dce71740c0f4afcb604c8.jpg)\n\n# Framework for POS discovering:\n\nMost freq tag.  \n- Maxtent P(t/w).  \nTnT.  \nBidirectional dependencies.  \nUpper bound.\n\n# 3.2.5 Lexical Features (NER)\n\nEntities: Common things that belong to the noun family.\n\nNamed Entity Recognition: A very important subtask to find and classify names in text, for example\n\nThe decision by the independent MP Andrew Wilkie to withdraw his support for the minority Labor government sounded dramatic but it should not further threaten its stability. When, after the 2010 election, Wilkie, Rob Oakeshott, Tony Windsor and the Greens agreed to support Labor, they gave just two guarantees: confidence and supply.\n\nPerson Date Location Organization\n\n# Methods of NER\n\nOne approach is to use various machine learning techniques.  \n- Another option is the Conditional Random Field (CRF), which is supported by both NLP Speech Tagger and NLTK. CRF is a probabilistic model used to model sequential data.  \nNER can also be based on deep learning techniques.\n\n# 3.2.6 BLUE and precision Evaluation Metrics\n\n# Precision:\n\n- compared a generated questions to one or more reference questions\n\n$$\n\\text {u n i g r a m P r e c i s i o n} = \\frac {\\text {N u m w o r d m a t c h e s}}{\\text {N u m w o r d s i n g e n e r a t i o n}}\n$$\n\n- But QGS can over generate reasonable words.!!!\n\n# BLEU, which stands for Bi-Lingual Evaluation Understudy:\n\n- BLEU compared a generated questions to one or more reference questions.  \n- BLEU compared n-grams of the generation with n-grams of the reference  \n- BLUE uses a modified n-gram precision to clip the number of matches.\n\n$$\n\\text {M o d i f i e d u n i g r a m P r e c i s i o n} = \\frac {\\operatorname {c l i p} (\\text {N u m w o r d m a t c h e s})}{\\text {N u m w o r d s i n g e n e r a t i o n}}\n$$\n\n- BLUE also uses bigrams, trigrams, and 4-grams to handle ordering problems\n\n$$\n4 - \\text {g r a m} \\quad \\text {P r e c i s i o n} = \\frac {\\Sigma c l i p (N u m w o r d m a t c h e s)}{\\Sigma N u m 4 - g r a m s i n g e n e r a t i o n}\n$$\n\n# 3.3 Update on Research Questions\n\nThere has been a significant shift in the research questions. Initially, the focus was on text classification. However, it evolved to Question Generation (QG) because my role as a teaching assistant emphasizes the importance of Natural Question Generation (NQG) for educational purposes.\n\nAs a result, we replaced the text classification questions - such as definition, application, limitations, preprocessing, feature extraction, solutions to limitations, datasets used, evaluation metrics, and directions for future research - with NQG questions covering the same areas. The expected responses for each research question are summarized in Table 3.1.\n\n<table><tr><td>RQ</td><td>Expected Outcome / Result</td></tr><tr><td>Q1: What is NQG?</td><td>It is the task of using deep neural networks to generate questions from a given context.</td></tr><tr><td>Q2: What are different applications of NQG?</td><td>1- machine reading comprehension\n2- Improving question answering system\n3- Assisting chatbots in initiating or continuing a conversation with humans</td></tr><tr><td>Q3: What are the languages that this research is interested in for NQG?</td><td>English Language</td></tr><tr><td>Q4: What are limitations and challenges of the existing NQG?</td><td>1- Existing neural question generation models are insufficient mostly owing to their failure to adequately simulate the process of how each word in the question is chosen, i.e., whether the text is repeated, or a vocabulary is formed.\n2- Most existing solutions are aimed at improving document representations. due to a lack of attention paid to the answer information, The created question may not be appropriate for the answer type, making the response irrelevant.</td></tr><tr><td>Q5: What are benchmark datasets to evaluate the performance of models of QAPG?</td><td>SQuAD, MS MARCO,NewsQA,RACE,LearningQ and NarrativeQA</td></tr><tr><td>Q5.1: What is a proper approach to represent word?</td><td>Word Embedding:\n  · Word2Vec\n  · Glove</td></tr><tr><td>Q5.2: What are different types of input preprocessing?</td><td>There are two forms of preprocessing: traditional preprocessing and QG-specific preparation. Segmentation, phrase splitting, tokenization, POS tagging, and coreference resolution are all part of standard preprocessing, which is used to prepare the data for the next task. In some circumstances, it also entails the recognition of named entities (NER)</td></tr><tr><td>Q6: What are the techniques used in NQG?</td><td>· NQG models all share the Seq2Seq framework.</td></tr><tr><td></td><td>• Or Use seq2seq with attention mechanism</td></tr><tr><td>Q7: What are possible Solutions and how to improve the performance of the existing technique of NQG?</td><td>• Adding attention mechanism\n• The model improves when the intended response is used as a guide to help with question generation. Use NLP Tools such as POS and NER.</td></tr><tr><td>Q8: What are the methods used to evaluate the performance of models for MQG?</td><td>• BLEU, METEOR and ROUGE.</td></tr><tr><td>Q9: What are directions for future research on NQG?</td><td>•Generation of Deep Questions\n•Wider Input Modalities\n•Use reinforcement learning</td></tr></table>\n\nTable 3.1: The expected result for each research question.\n\n# 3.4 Threats to Validity\n\nThis study has several limitations:\n\nIt focuses solely on the English language.  \n- It does not address how to predict question types based on input response (e.g., yes/no, multiple choice, or extractive) and context.  \nIt does not cover the transformer model.  \nThere is a need for practical applications of the mentioned models to better understand and develop them.\n\n# 4. CONCLUSION AND FUTURE WORK\n\nThis research explores the use of neural network models for generating natural language questions (QG), highlighting their importance for educational materials and for improving question-answering (QA) systems. We analyzed several techniques and evaluation metrics from the literature.\n\nThe results show that all NQG models share the Seq2Seq framework. Furthermore, the integration of Seq2Seq with attention mechanisms and the use of part-of-speech (POS) tagging and named entity recognition (NER) contribute to the generation of accurate questions.\n\nThe future work of Question Generation (QG) techniques focuses on improving the quality, diversity, and applicability of automatically generated questions. Here are some key areas for future research and development:\n\n1. Enhancing Question Quality and Diversity  \n2. Multimodal Question Generation  \n3. Personalized and Adaptive QG  \n4. Integration with Large Language Models (LLMs)  \n5. Improving QG in Low-Resource Languages  \n6. Domain-Specific QG  \n7. Reinforcement Learning (RL) for Question Generation\n\n# 8. Graph Encoders for Question Generation\n\n# 5. REFERENCES\n\nAithal, S. G., Rao, A. B., & Singh, S. (2021). Automatic question-answer pairs generation and question similarity mechanism in question answering system. Applied Intelligence, 51(11), 8484-8497.  \nAlabbas, W., Al-Khateeb, H. M., & Mansour, A. (2016, October). Arabic text classification methods: Systematic literature review of primary studies. In 2016 4th IEEE International Colloquium on Information Science and Technology (CiSt) (pp. 361-367). IEEE.  \nAlKhuzay, S., Grasso, F., Payne, T. R., & Tamma, V. (2024). Text-based question difficulty prediction: A systematic review of automatic approaches. International Journal of Artificial Intelligence in Education, 34(3), 862-914.\n\nandreaperlato,2022.\"Recurrent Neural Network in Theory\": aipost, https://www.andreaperlato.com/aipost/recurrent-neural-network-in  \nBennabi, S. R., & Elberrichi, Z. (2020, June). Feature Selection based Arabic Text Classification using Different Machine Learning Algorithms: Comparative Study. In Proceedings of the 10th International Conference on Information Systems and Technologies (pp. 1-5).  \nBennabi, S. R., & Elberrichi, Z. (2020, June). Feature Selection based Arabic Text Classification using Different Machine Learning Algorithms: Comparative Study. In Proceedings of the 10th International Conference on Information Systems and Technologies (pp. 1-5).  \nChali, Y., & Hasan, S. A. (2015). Towards topic-to-question generation. Computational Linguistics, 41(1), 1-20.  \nDu, X., Shao, J., & Cardie, C. (2017). Learning to ask: Neural question generation for reading comprehension. arXiv preprint arXiv:1705.00106.  \nElbes, M., Aldajah, A., & Sadaqa, O. (2019, October). P-stemmer or NLTK stemmer for arabic text classification?. In 2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS) (pp. 516-520). IEEE.  \nEzzeldin, A. M., & Shaheen, M. (2012, December). A survey of Arabic question answering: challenges, tasks, approaches, tools, and future trends. In Proceedings of The 13th international Arab conference on information technology (ACIT 2012) (pp. 1-8).  \nHeilman, M. (2011). Automatic factual question generation from text (Doctoral dissertation, Carnegie Mellon University).  \nJoseph, S. R., Hlomani, H., Letsholo, K., Kaniwa, F., & Sedimo, K. (2016). Natural language processing: A review. International Journal of Research in Engineering and Applied Sciences, 6(3), 207-210.  \nKadhim, A. I. (2019). Survey on supervised machine learning techniques for automatic text classification. Artificial Intelligence Review, 52(1), 273-292.  \nKrishnan, S., Magalingam, P., & Ibrahim, R. B. (2020). Advanced recurrent neural network with tensorflow for heart disease prediction. International Journal of Advanced Science and Technology, 29(5), 966-977.  \nLi, A., Xiao, F., Zhang, C., & Fan, C. (2021). Attention-based interpretable neural network for building cooling load prediction. Applied Energy, 299, 117238.  \nMinaee, S., Kalchbrenner, N., Cambria, E., Nikzad, N., Chenaghlu, M., & Gao, J. (2021). Deep learning--based text classification: a comprehensive review. ACM Computing Surveys (CSUR), 54(3), 1-40.  \nPan, L., Lei, W., Chua, T. S., & Kan, M. Y. (2019). Recent advances in neural question generation. arXiv preprint arXiv:1905.08949.\n\nPandolfi-González, M., Quesada-López, C., Martínez, A., & Jenkins, M. (2020, September). Automatic Classification of Web News: A Systematic Mapping Study. In Proceedings of SAI Intelligent Systems Conference (pp. 558-574). Springer, Cham.  \nRachid, B. A., Azza, H., & Ghezala, H. H. B. (2020, July). Classification of cyberbullying text in arabic.  \nIn 2020 International Joint Conference on Neural Networks (IJCNN) (pp. 1-7). IEEE.  \nReda Affane,2020.\" Understanding the Hype Around Transformer NLP Models\": dataiku,  \nUnderstanding the Hype Around Transformer NLP Models (dataiku.com)  \nRong, X. (2014). word2vec parameter learning explained. arXiv preprint arXiv:1411.2738.\n\nSefidian,2020. \"Understanding Gated Recurrent Unit (GRU) with PyTorch code\": gated-recurrent-unit-gru-with-pytorch, http://www.sefidian.com/2020/01/30/gated-recurrent-unit-gru-with-pytorch/Shehab, Mohammed A., et al. \"A supervised approach for multi-label classification of Arabic news articles.\" 2016 7th international conference on computer science and information technology (CSIT). IEEE, 2016.  \nSlobodianiuk, A. V., & Semerikov, S. O. (2025). Advances in neural text generation: A systematic review.  \nSuhartono, D., Majiid, M. R. N., & Fredyan, R. (2024). Towards automatic question generation using pretrained model in academic field for Bahasa Indonesia. *Education and Information Technologies*, 29(16), 21295-21330.  \nWahdan, Ahlam, Said A. Salloum, and Khaled Shaalan. \"Text Classification of Arabic Text: Deep Learning in ANLP.\" International Conference on Advanced Machine Learning Technologies and Applications. Springer, Cham, 2021  \nWahdan, K. A., Hantoobi, S., Salloum, S. A., & Shaalan, K. (2020). A systematic review of text classification research based ondeep learning models in Arabic language. Int. J. Electr. Comput. Eng, 10(6), 6629-6643.  \nWang, L., Xu, Z., Lin, Z., Zheng, H., & Shen, Y. (2020, December). Answer-driven Deep Question Generation based on Reinforcement Learning. In Proceedings of the 28th International Conference on Computational Linguistics (pp. 5159-5170).  \nYang, J., Bai, L., & Guo, Y. (2020, October). A survey of text classification models. In Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence (pp. 327-334).  \nYao, B., Wang, D., Wu, T., Hoang, T., Sun, B., Li, T. J. J., ... & Xu, Y. (2021). It is AI's Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in Fairy TaleQA Dataset. arXiv preprint arXiv:2109.03423.  \nYuan, J., & Tian, Y. (2019). An intelligent fault diagnosis method using GRU neural network towards sequential data in dynamic processes. *Processes*, 7(3), 152.\n\nZhang, M. (2021). Applications of deep learning in news text classification. Scientific Programming, 2021.  \nZhou, Q., Yang, N., Wei, F., Tan, C., Bao, H., & Zhou, M. (2017, November). Neural question generation from text: A preliminary study. In National CCF Conference on Natural Language Processing and Chinese Computing (pp. 662-671). Springer, Cham.  \nMucciaccia, S. S., Paixão, T. M., Mutz, F. W., Badue, C. S., de Souza, A. F., & Oliveira-Santos, T. (2025, January). Automatic Multiple-Choice Question Generation and Evaluation Systems Based on LLM: A Study Case With University Resolutions. In Proceedings of the 31st International Conference on Computational Linguistics (pp. 2246-2260).  \nMaity, Subhankar, Aniket Deroy, and Sudeshna Sarkar. \"Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains.\" arXiv preprint arXiv:2501.17397 (2025).  \nGreat Learning Team, 2020. \"What is Word Embedding | Word2Vec | GloVe\". Great learning, https://www.mygreatlearning.com/blog/word-embedding/\n\nAbdeen, M. A., AlBouq, S., Elmahalawy, A., & Shehata, S. (2019). A closer look at arabic text classification. Int. J. Adv. Comput. Sci. Appl., 10(11), 677-688.  \nAl Faraby, S., Adiwijaya, A., & Romadhony, A. (2024). Review on neural question generation for education purposes. International Journal of Artificial Intelligence in Education, 34(3), 1008-1045.  \nAl Qadi, L., El Rifai, H., Obaid, S., & Elnagar, A. (2019, October). Arabic text classification of news articles using classical supervised classifiers. In 2019 2nd International conference on new trends in computing sciences (ICTCS) (pp. 1-6). IEEE.  \nKitchenham, B. A. (2012, September). Systematic review in software engineering: where we are and where we should be going. In Proceedings of the 2nd international workshop on Evidential assessment of software technologies (pp. 1-2).  \nLiu, W., Xiao, J., & Hong, M. (2020, January). Comparison on feature selection methods for text classification. In Proceedings of the 2020 4th international conference on management engineering, software engineering and service sciences (pp. 82-86).  \nMaity, S., Deroy, A., & Sarkar, S. (2025). Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains. arXiv preprint arXiv:2501.17397.  \nSerban, I., Sordoni, A., Bengio, Y., Courville, A., & Pineau, J. (2016, March). Building end-to-end dialogue systems using generative hierarchical neural network models. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 30, No. 1).  \nSlobodianiuk, A. V., & Semerikov, S. O. (2025). Advances in neural text generation: A systematic review.  \nYin, Z., & Shen, Y. (2018). On the dimensionality of word embedding. Advances in neural information processing systems, 31.",
    "arxiv_id": "1705.00106",
    "error_message": null,
    "embedding": [
      -1.703125,
      1.3125,
      -2.109375,
      -1.40625,
      2.4375,
      2.203125,
      -2.15625,
      -2.109375,
      2.03125,
      1.4921875,
      1.5,
      3.046875,
      0.396484375,
      0.70703125,
      1.53125,
      2.25,
      1.3671875,
      -0.3828125,
      0.63671875,
      -6.75,
      1.125,
      2.515625,
      -1.7578125,
      -6.40625,
      1.3984375,
      -4.21875,
      0.37109375,
      3.4375,
      1.015625,
      -0.5703125,
      4.625,
      -4.8125,
      0.271484375,
      -0.498046875,
      -0.55078125,
      -0.1201171875,
      -3.46875,
      -0.52734375,
      3.796875,
      5.28125,
      -6.15625,
      -0.04931640625,
      -2.546875,
      3,
      -0.50390625,
      0.038818359375,
      2.28125,
      -3.53125,
      -0.2578125,
      -0.2138671875,
      -4.84375,
      -4.9375,
      5.625,
      -1.71875,
      5.4375,
      -3.21875,
      -6.84375,
      5.875,
      -3.515625,
      2.25,
      2.046875,
      -1.3125,
      1.46875,
      1.21875,
      3,
      7.125,
      -0.31640625,
      1.625,
      -4.15625,
      3.828125,
      -1.375,
      0.451171875,
      8.4375,
      -1.953125,
      9.25,
      5.59375,
      2.875,
      2.96875,
      -4.71875,
      2.40625,
      -5.65625,
      1.1640625,
      3.421875,
      -1.0703125,
      4.84375,
      0.90234375,
      -2.40625,
      0.181640625,
      -1.828125,
      3.375,
      -2.6875,
      1.640625,
      -2.375,
      -1.6328125,
      -0.65625,
      3.734375,
      -0.0673828125,
      -7.09375,
      -5.84375,
      0.359375,
      -0.07421875,
      -0.2333984375,
      2.34375,
      -7.5,
      -1.4296875,
      -1.3828125,
      -5.03125,
      -4.46875,
      -3.234375,
      -1.984375,
      -1.5,
      1.4921875,
      1.4921875,
      -1.640625,
      4.09375,
      0.56640625,
      4.71875,
      -3.71875,
      -5.21875,
      -1.65625,
      2.078125,
      2.984375,
      -1.8984375,
      -0.7109375,
      3.90625,
      1.0078125,
      -2.71875,
      1.1953125,
      4.71875,
      -0.7890625,
      4.53125,
      0.09716796875,
      7.1875,
      1.6171875,
      -10.3125,
      -3.546875,
      -2,
      4.3125,
      2.40625,
      2.71875,
      -4.6875,
      -0.263671875,
      -3.484375,
      -2.5625,
      3.875,
      -1.34375,
      -5.875,
      0.0947265625,
      4.1875,
      -4.6875,
      0.25390625,
      2.359375,
      3.90625,
      6.125,
      -2.453125,
      -7.8125,
      2.21875,
      1.6875,
      3.359375,
      -1.8671875,
      -0.8984375,
      4.0625,
      1.3125,
      -0.53125,
      -2.640625,
      2.140625,
      -3.890625,
      0.83984375,
      -1.2265625,
      1.6953125,
      1.5859375,
      13.8125,
      2.953125,
      -2.875,
      0.56640625,
      2.8125,
      -1.8359375,
      5.15625,
      1.3046875,
      1.4765625,
      2.390625,
      0.1494140625,
      -2.40625,
      4.875,
      -0.83203125,
      -0.71484375,
      1.4921875,
      -2.515625,
      5.1875,
      -2.546875,
      1.7421875,
      1.140625,
      3.359375,
      -1.8046875,
      -5.4375,
      0.047607421875,
      1.3359375,
      -0.04345703125,
      -1.21875,
      5.03125,
      -2.03125,
      -9.1875,
      -1.53125,
      -0.11474609375,
      -4.875,
      -1.5625,
      1.953125,
      -2.703125,
      1.21875,
      -2.171875,
      1.640625,
      1.296875,
      -1.2421875,
      1.5078125,
      8.25,
      2.546875,
      3.609375,
      -0.08935546875,
      3.34375,
      0.3984375,
      2.359375,
      5.375,
      4.375,
      -1.15625,
      -1.1875,
      2.390625,
      3.671875,
      5.625,
      1.90625,
      6.34375,
      1.1171875,
      2.5,
      4.15625,
      -5.28125,
      -3.25,
      -0.53125,
      -3.015625,
      1.828125,
      -3.984375,
      -0.53515625,
      -3.078125,
      -5.46875,
      -1.3359375,
      4.15625,
      1.890625,
      1.0078125,
      -1.0625,
      -4.84375,
      -3.96875,
      -6.375,
      -0.162109375,
      5.65625,
      -8.4375,
      -5,
      5.5625,
      6.78125,
      -2.0625,
      0.049072265625,
      -1.2578125,
      -2.84375,
      4.625,
      -2.9375,
      -4.03125,
      -0.0052490234375,
      3.34375,
      -4.28125,
      3.25,
      -1.7734375,
      2.296875,
      -0.7578125,
      5.5,
      -0.25390625,
      -1.5234375,
      1.421875,
      -4.25,
      5.09375,
      0.41796875,
      -6.28125,
      1.8125,
      -2.75,
      -5.3125,
      -7.4375,
      5.71875,
      -2.703125,
      2.78125,
      -2.21875,
      3.359375,
      4.90625,
      -3.046875,
      11.5,
      7.1875,
      -0.326171875,
      -1.28125,
      2.234375,
      -3.015625,
      -1.9296875,
      -1.546875,
      -1.3203125,
      -5.0625,
      3.34375,
      3.859375,
      0.1630859375,
      -3.953125,
      0.396484375,
      0.67578125,
      2.46875,
      1.125,
      -6.21875,
      4.25,
      0.349609375,
      -1.015625,
      0.341796875,
      10.5625,
      -1.5546875,
      3.734375,
      -5,
      -0.95703125,
      3.328125,
      0.875,
      -3.171875,
      -2.953125,
      -4.75,
      -2.390625,
      -1.078125,
      -1.703125,
      -1.4375,
      3.015625,
      -1.25,
      2.765625,
      -0.09130859375,
      2.578125,
      -0.7890625,
      -6.40625,
      -6.34375,
      8.4375,
      -0.04296875,
      2.828125,
      2.46875,
      0.287109375,
      6.03125,
      -4.0625,
      -6.125,
      2.09375,
      -1.8203125,
      0.28125,
      0.41796875,
      1.5234375,
      -4.09375,
      -0.1845703125,
      -6.3125,
      2.40625,
      2.0625,
      0.828125,
      4.25,
      4.90625,
      -2.15625,
      3.09375,
      1.2890625,
      -0.03564453125,
      0.032958984375,
      2.5,
      -2.265625,
      5.5,
      1.1171875,
      -0.70703125,
      -4.75,
      -3.015625,
      1.3515625,
      -3.890625,
      -2.359375,
      -1.6484375,
      -5.375,
      -1.6015625,
      -0.205078125,
      1.265625,
      0.3359375,
      0.9765625,
      -5.21875,
      -4.5625,
      2.09375,
      -4.34375,
      -1.34375,
      0.8828125,
      -0.78515625,
      4.1875,
      2.984375,
      1.15625,
      3.703125,
      1.265625,
      -5.78125,
      -1.7421875,
      0.42578125,
      -0.1083984375,
      1.875,
      5.09375,
      3.828125,
      -0.032958984375,
      3.296875,
      -3.109375,
      -1.0546875,
      5.875,
      1.015625,
      -0.53515625,
      -0.21484375,
      -6,
      1.0390625,
      0.66796875,
      -8.4375,
      3.421875,
      0.216796875,
      -0.07275390625,
      0.050048828125,
      1.125,
      0.162109375,
      -2.34375,
      1.4140625,
      -0.85546875,
      3.546875,
      -6.125,
      -1.53125,
      -2.71875,
      1.328125,
      1.9765625,
      1.8984375,
      -1.2109375,
      -1.7578125,
      3.15625,
      6.1875,
      0.7109375,
      1.8046875,
      0.5625,
      1.3984375,
      -4.84375,
      2.21875,
      -1.171875,
      -0.87890625,
      5.9375,
      -3.46875,
      -5.375,
      -1.5546875,
      1.5390625,
      -4.28125,
      4.1875,
      2.5,
      -5,
      -0.921875,
      2.78125,
      5.0625,
      -2.953125,
      -1.375,
      0.2021484375,
      -0.91015625,
      -2.40625,
      2.125,
      1.390625,
      3.59375,
      -4.28125,
      3.46875,
      2.859375,
      -3.09375,
      -1.4765625,
      -4.96875,
      -2.5,
      1.15625,
      0.96875,
      -0.66796875,
      -2.609375,
      3.953125,
      7.25,
      -9.125,
      -10.5625,
      2.953125,
      1.234375,
      -5.6875,
      -1.59375,
      3.421875,
      1.3828125,
      1.4375,
      -5.21875,
      -4.28125,
      -2.375,
      -2.0625,
      0.9453125,
      2.21875,
      0.298828125,
      -1.5078125,
      -4.46875,
      6.8125,
      1.0625,
      5.71875,
      0.31640625,
      -1.0078125,
      -0.34375,
      -5.34375,
      2.796875,
      1.7421875,
      6.09375,
      -5,
      1.25,
      2.875,
      -7.84375,
      0.66015625,
      -3.484375,
      -3.171875,
      0.68359375,
      -1.1328125,
      4.8125,
      -1.5546875,
      -3.140625,
      -1.5390625,
      3.390625,
      -2.984375,
      -2.6875,
      -0.1328125,
      -6.65625,
      -3.125,
      2.046875,
      0.60546875,
      1.2109375,
      -0.01043701171875,
      -2.3125,
      0.9453125,
      -0.9609375,
      0.234375,
      -0.6328125,
      -0.031494140625,
      -0.041748046875,
      -4.84375,
      2.609375,
      3.53125,
      2.3125,
      -0.51953125,
      0.10693359375,
      -4.03125,
      -2.75,
      -1.5546875,
      0.2578125,
      -1.4921875,
      0.51171875,
      0.66015625,
      0.80859375,
      4.03125,
      -3.203125,
      0.0703125,
      0.0133056640625,
      1.9453125,
      -3.921875,
      0.65625,
      1.6640625,
      0.060791015625,
      1.53125,
      1.921875,
      -3.171875,
      -0.349609375,
      1.5625,
      -5,
      -6.09375,
      -1.21875,
      4.15625,
      -2,
      -0.392578125,
      -5.6875,
      2.078125,
      3.40625,
      1.8515625,
      -1.5390625,
      -0.2353515625,
      5.8125,
      -1.734375,
      -0.5859375,
      1.0234375,
      5.125,
      -1.15625,
      -0.0771484375,
      3.609375,
      0.41796875,
      -4.25,
      -7.375,
      -1.3828125,
      0.9921875,
      4.1875,
      -2.578125,
      5.1875,
      -1.6328125,
      5.34375,
      -0.27734375,
      -0.2177734375,
      -16.25,
      3.3125,
      -2.40625,
      -6.28125,
      -2.5625,
      -3.1875,
      0.032958984375,
      -4.625,
      3.78125,
      2.921875,
      -0.875,
      2.140625,
      3.765625,
      0.2236328125,
      -4.96875,
      2.171875,
      1.078125,
      -1.65625,
      0.89453125,
      -4.09375,
      -4.34375,
      1.5390625,
      -5.4375,
      2.03125,
      1.515625,
      5.15625,
      -5.625,
      0.37109375,
      0.287109375,
      -6.96875,
      1.046875,
      2.6875,
      2.625,
      -1.6484375,
      1.7421875,
      -4.75,
      3.84375,
      -4.90625,
      4.96875,
      0.392578125,
      -0.921875,
      1.3203125,
      4.875,
      -0.37109375,
      -3.78125,
      -1.8125,
      -2.015625,
      5.65625,
      2.546875,
      -7.125,
      2.640625,
      -2.59375,
      0.796875,
      0.431640625,
      -2.703125,
      -3.5,
      -2.046875,
      2.484375,
      2.546875,
      -4.84375,
      8.0625,
      0.6484375,
      -2.3125,
      1.796875,
      0.0274658203125,
      0.88671875,
      -1.171875,
      1.75,
      -1.890625,
      -3.71875,
      -0.169921875,
      1.96875,
      0.6328125,
      -7.09375,
      -2.140625,
      2.59375,
      -3.25,
      2.265625,
      -1.53125,
      0.7265625,
      -2.40625,
      -4.375,
      0.890625,
      2.90625,
      5.15625,
      2.5,
      3.671875,
      2.6875,
      -5.15625,
      1.6953125,
      -1.1484375,
      -4.25,
      1,
      -1.015625,
      -1.265625,
      -0.39453125,
      -1.53125,
      2.375,
      0.26953125,
      -1.8828125,
      -5.625,
      -6.0625,
      -1.6484375,
      1.421875,
      -1.5234375,
      4.65625,
      -0.578125,
      5.9375,
      0.4765625,
      -3.5,
      1.109375,
      -3.640625,
      1.625,
      -1.7578125,
      1.015625,
      -6.53125,
      -1.7421875,
      8.875,
      2.890625,
      -2.890625,
      8.0625,
      0.40625,
      -1.8515625,
      -0.87109375,
      3.40625,
      -1.0234375,
      -0.63671875,
      0.201171875,
      -1.6640625,
      -3.921875,
      -2.125,
      2.078125,
      -3.21875,
      3.15625,
      -2.84375,
      -3.328125,
      -2.328125,
      -3.8125,
      -2.109375,
      2.34375,
      -6.25,
      0.7734375,
      3.53125,
      -2.75,
      -0.6796875,
      5,
      0.7265625,
      0.62890625,
      -1.3671875,
      -1.546875,
      2.546875,
      1.6640625,
      6.1875,
      -1.75,
      -2.96875,
      0.9609375,
      -0.1357421875,
      -1.6484375,
      3.515625,
      -1.9765625,
      0.6171875,
      1.9375,
      0.498046875,
      -5.65625,
      -4.78125,
      2.453125,
      -1.3125,
      -0.1728515625,
      -0.232421875,
      2.515625,
      0.0294189453125,
      3.484375,
      0.96875,
      -5.8125,
      -3.625,
      5.34375,
      2.109375,
      0.6875,
      -1.3359375,
      4.21875,
      -1.4140625,
      3.21875,
      -5.59375,
      -3.28125,
      0.384765625,
      0.28125,
      -3.578125,
      0.1015625,
      10.3125,
      -0.98828125,
      -1.0859375,
      -0.51953125,
      1.140625,
      3.96875,
      -1.2734375,
      1.4296875,
      -0.37890625,
      4.78125,
      -1.359375,
      1.3515625,
      2.5,
      -0.7109375,
      -5.28125,
      0.002685546875,
      2.203125,
      -2.125,
      4.375,
      -1.0625,
      -2.5,
      -2.453125,
      -2.109375,
      0.11669921875,
      4.71875,
      5.96875,
      -1.65625,
      1.5390625,
      -0.0849609375,
      4.84375,
      -2.59375,
      5.5,
      0.91796875,
      6.65625,
      -1.3984375,
      -4.65625,
      0.40234375,
      -0.546875,
      -2.0625,
      0.10791015625,
      -4.84375,
      -4.34375,
      1.9609375,
      2.421875,
      -2.296875,
      3.609375,
      -6.59375,
      0.53515625,
      3.0625,
      1.390625,
      3.578125,
      3.6875,
      5.90625,
      2.234375,
      -1.265625,
      0.2451171875,
      -2.03125,
      -0.9921875,
      -0.29296875,
      0.515625,
      -2.6875,
      3.25,
      1.078125,
      5.3125,
      0.7734375,
      1.484375,
      -2.5625,
      6.375,
      0.859375,
      -2.671875,
      5.03125,
      -0.9765625,
      3.015625,
      4.125,
      2.046875,
      -2.546875,
      1.5390625,
      7.65625,
      4.3125,
      -1.2109375,
      -0.63671875,
      -0.33203125,
      0.625,
      -3.109375,
      -3.671875,
      0.11376953125,
      0.2060546875,
      -0.84375,
      -0.25,
      -0.50390625,
      3.3125,
      -3.125,
      4.8125,
      -0.71484375,
      -3.828125,
      2.09375,
      3.046875,
      -2.640625,
      1.7578125,
      0.796875,
      4.09375,
      -3.5,
      -3.546875,
      -3.359375,
      -5.53125,
      -1.7734375,
      -2.25,
      3.453125,
      0.474609375,
      5.15625,
      -2.125,
      2.8125,
      -6.875,
      -0.515625,
      -3.84375,
      4.4375,
      5.28125,
      -3.75,
      1.84375,
      -1.359375,
      -9.5,
      -7.5625,
      -2.25,
      -2.4375,
      -0.546875,
      -4.40625,
      -1.4375,
      0.9375,
      -2.140625,
      1.21875,
      -1.9765625,
      -0.478515625,
      1.859375,
      -0.2353515625,
      4.1875,
      -5.28125,
      3.453125,
      2.515625,
      -2.828125,
      1.6640625,
      2.640625,
      -0.83203125,
      3.03125,
      -3.328125,
      -0.1796875,
      -4.5625,
      6.5625,
      -5.375,
      8.5625,
      2.890625,
      1.78125,
      -5.8125,
      4.21875,
      -1.28125,
      2.953125,
      -5.9375,
      -2.609375,
      -2.71875,
      0.047607421875,
      -0.2412109375,
      0.1396484375,
      0.431640625,
      -3.765625,
      -1.3984375,
      1.0234375,
      -4.1875,
      0.0537109375,
      1.734375,
      0.9375,
      4.09375,
      0.0966796875,
      4.65625,
      1.2265625,
      -2.25,
      -0.46484375,
      0.353515625,
      1.2890625,
      -2.75,
      3.171875,
      0.349609375,
      -1.6875,
      0.76953125,
      -0.72265625,
      2.328125,
      -0.435546875,
      -1.671875,
      3.28125,
      0.79296875,
      1.78125,
      -1.1328125,
      0.52734375,
      -0.5390625,
      1.65625,
      3.15625,
      -2.71875,
      6.03125,
      1.2734375,
      1.4140625,
      -3.84375,
      0.69140625,
      -3.109375,
      0.97265625,
      -3.203125,
      -4.65625,
      -1.734375,
      0.404296875,
      -4.4375,
      1.75,
      -3.109375,
      -1.2734375,
      4.46875,
      0.8203125,
      3.40625,
      4.40625,
      -2.171875,
      1.296875,
      1.4453125,
      -1.5,
      8.5625,
      -3.34375,
      2.484375,
      4.5625,
      1.921875,
      3.203125,
      -0.337890625,
      -0.9296875,
      -3.859375,
      -0.5234375,
      8.125,
      -1.6875,
      -0.8828125,
      5.6875,
      0.380859375,
      0.9765625,
      2.078125,
      -0.8515625,
      -0.3046875,
      -2.4375,
      -0.439453125,
      5.1875,
      5.71875,
      -4,
      -1.3984375,
      -4.25,
      0.984375,
      -0.1103515625,
      -0.51171875,
      -0.5546875,
      1.4296875,
      0.828125,
      1.3203125,
      0.25390625,
      -2.234375,
      -0.1708984375,
      -4.65625,
      0.03955078125,
      4.3125,
      -0.30078125,
      0.314453125,
      2.671875,
      5.5625,
      -1.65625,
      4.21875,
      2.0625,
      -1.78125,
      4.4375,
      2.21875,
      0.470703125,
      4.21875,
      2.46875,
      2.453125,
      2.59375,
      -2.90625,
      -1.2109375,
      -1.265625,
      -3.84375,
      0.40625,
      -4.1875,
      0.205078125,
      3.390625,
      4.59375,
      -1.5078125,
      3.21875,
      -0.875,
      1.59375,
      1.15625,
      -1.5390625,
      -6.09375,
      -1.4921875,
      -0.08935546875,
      -4,
      0.05419921875,
      -0.91796875,
      -0.51953125,
      2.90625,
      -6.1875,
      5.5625,
      -3.890625,
      6.25,
      0.7421875,
      -1.5078125,
      -4.9375,
      -2.359375,
      2.109375,
      -0.1279296875,
      0.89453125,
      2.28125,
      -2.84375,
      1.375,
      -2.15625,
      1.9296875,
      3.46875,
      -1.65625,
      2.28125,
      -2.90625,
      1.1875,
      -0.3359375,
      0.7734375,
      -5.8125,
      -4.46875,
      0.431640625,
      1.015625,
      -0.181640625,
      -0.337890625,
      1.8046875,
      -1.0390625,
      2.71875,
      -3.03125,
      1.28125,
      -1.2734375,
      -1.9765625,
      2.171875,
      -0.2421875,
      5.84375,
      0.77734375,
      -0.1591796875,
      -0.10693359375,
      -2.046875,
      -8.5625,
      -1.8359375,
      -0.166015625,
      3.671875,
      -3.359375,
      1.4921875,
      0.578125,
      0.625,
      0.84375,
      -1.1484375,
      1.328125,
      3.09375,
      4.21875,
      1.6953125,
      2.3125,
      -2.109375,
      -0.35546875,
      -4.96875,
      -5.1875,
      -5,
      2.015625,
      3.578125,
      -3.953125,
      1.3671875,
      -4.65625,
      1.5703125,
      -0.46875,
      -1.0078125,
      -1.6796875,
      -0.138671875,
      4.53125,
      0.236328125,
      -2.4375,
      1.5546875,
      -3,
      0.5703125,
      -0.330078125,
      -2.5625,
      -2.828125,
      2.625,
      -0.396484375,
      2.0625,
      0.0245361328125,
      -2.796875,
      1.8984375,
      -2.484375,
      -2.59375,
      -2.109375,
      2.453125,
      1.3203125,
      4.25,
      4.28125,
      0.466796875,
      -2.90625,
      1.71875,
      -0.271484375,
      5.9375,
      0.279296875,
      -0.859375,
      2.09375,
      -0.23828125,
      3.703125,
      -1.59375,
      -0.68359375,
      -5.46875,
      0.75390625,
      6.875,
      0.90625,
      -0.09814453125,
      1.5859375,
      -0.7265625,
      2.609375,
      1.40625,
      3.484375,
      -3.234375,
      -1.8359375,
      -3.390625,
      2.84375,
      1.7421875,
      -4.40625,
      1.078125,
      3.4375,
      -3.9375,
      2.984375,
      4.0625,
      5.5625,
      -1.2109375,
      3.171875,
      -3.953125,
      -3.6875,
      -3.78125,
      1.6796875,
      2.84375,
      1.9296875,
      -2.46875,
      -5,
      -1.2421875,
      1.671875,
      2.875,
      6.21875,
      -3.328125,
      1.0390625,
      1.1875,
      3.171875,
      1.109375,
      -0.9140625,
      -0.298828125,
      2.828125,
      -1.28125,
      -2.734375,
      2.25,
      -2.71875,
      0.57421875,
      -0.8671875,
      -7.78125,
      -0.291015625,
      1.046875,
      -1,
      3,
      -1.140625,
      -2.171875,
      1.1328125,
      -1.78125,
      -1.0078125,
      -2.125,
      0.482421875,
      2.078125,
      -1.484375,
      -1.59375,
      2.09375,
      -0.84375,
      -2.625,
      -1.3828125,
      2.703125,
      -1.34375,
      2.53125,
      4.875,
      4.46875,
      -4.28125,
      -5.4375,
      0.7265625,
      -1.2578125,
      -4.125,
      -0.408203125,
      -0.66796875,
      -0.034912109375,
      1.7421875,
      -1.1484375,
      -2.484375,
      -1.3046875,
      -5.375,
      4.65625,
      1.0703125,
      5.90625,
      -3.84375,
      5.59375,
      -5.71875,
      2.28125,
      0.578125,
      -4.125,
      -2.234375,
      1.4453125,
      -2.109375,
      1.359375,
      3.921875,
      -0.10009765625,
      -0.07470703125,
      2.484375,
      -1.1953125,
      -2.34375,
      -2.84375,
      1.1015625,
      1.375,
      0.26171875,
      2.75,
      -0.37109375,
      1.9921875,
      -2.265625,
      -2.671875,
      0.40234375,
      1.03125,
      -0.71875,
      3.65625,
      1.6640625,
      -1.1796875,
      3.703125,
      -0.80078125,
      3.765625,
      0.2021484375,
      -1.9453125,
      1.140625,
      -1.765625,
      -0.146484375,
      -4.75,
      3.75,
      -0.009033203125,
      -1.2109375,
      3.359375,
      5.4375,
      -3.46875,
      -1.59375,
      2.984375,
      3.375,
      -5.84375,
      0.4375,
      -2.0625,
      6.125,
      -1.359375,
      2.59375,
      -4.125,
      -1.6640625,
      0.671875,
      -2.578125,
      2.65625,
      -0.302734375,
      1.8359375,
      -3.078125,
      -2.484375,
      4.96875,
      1.7890625,
      1.3046875,
      -3.0625,
      -1.046875,
      1.203125,
      -1.140625,
      4.34375,
      -0.421875,
      -2.515625,
      -2.96875,
      3.6875,
      -2.71875,
      -1.9453125,
      -9,
      -0.640625,
      -2.734375,
      -2.359375,
      -1.890625,
      1.921875,
      1.125,
      1.8515625,
      -1.4921875,
      -2.25,
      -3.28125,
      -4.8125,
      2.484375,
      -1.3125,
      -3.328125,
      -0.353515625,
      0.0986328125,
      3.390625,
      6,
      5.53125,
      2.453125,
      -2.828125,
      -0.427734375,
      -1.7265625,
      3.671875,
      0.94921875,
      -1.7265625,
      -2.859375,
      -1.6328125,
      2.53125,
      1.7734375,
      2.0625,
      -5.40625,
      -3.984375,
      -4.28125,
      -3.09375,
      -1.4453125,
      3.703125,
      -1.375,
      1.890625,
      6.53125,
      -1.6875,
      0.435546875,
      1.2890625,
      -0.61328125,
      -4.53125,
      -1.40625,
      -0.66015625,
      5.75,
      2.171875,
      5.09375,
      -2.078125,
      7.90625,
      2.453125,
      -2.140625,
      2.25,
      0.154296875,
      1.265625,
      -3.8125,
      5.375,
      1.53125,
      1.9453125,
      1.5,
      0.3671875,
      4.25,
      1.6328125,
      3.734375,
      3.0625,
      4.15625,
      -2.78125,
      1.7109375,
      0.828125,
      -2.25,
      -1.2421875,
      0.86328125,
      -1.8828125,
      -0.65234375,
      4.0625,
      1.5546875,
      4.75,
      -2.09375,
      0.70703125,
      1.5078125,
      2.015625,
      -6,
      0.3359375,
      -6.65625,
      -0.3046875,
      -5.15625,
      -2,
      -8.9375,
      -0.88671875,
      3.15625,
      3.890625,
      -0.56640625,
      -2.96875,
      4.15625,
      6.5,
      -1.0703125,
      -4.78125,
      4.6875,
      -0.21875,
      -1.890625,
      -3.65625,
      -2.171875,
      5.5625,
      1.2421875,
      2.515625,
      -4.46875,
      1.3046875,
      0.349609375,
      -0.6640625,
      -3.296875,
      2.859375,
      -0.53515625,
      -8,
      -6.9375,
      -4.96875,
      -0.8828125,
      -3.53125,
      3.9375,
      2.28125,
      -0.181640625,
      0.37109375,
      0.73828125,
      0.2236328125,
      2.359375,
      -1.59375,
      0.84375,
      1.125,
      -1.546875,
      -1.171875,
      5.25,
      -2.453125,
      2.25,
      -2.234375,
      2.5625,
      0.9375,
      -2.6875,
      -0.9453125,
      -8,
      2.390625,
      4.46875,
      3.171875,
      0.2275390625,
      -0.734375,
      0.9921875,
      1.1640625,
      -2.1875,
      -0.546875,
      4.59375,
      -0.32421875,
      -3.609375,
      -1.3671875,
      -2.78125,
      2.703125,
      -0.5546875,
      0.0235595703125,
      1.0234375,
      -0.306640625,
      -1.0625,
      -3.8125,
      -5.125,
      3.515625,
      -0.376953125,
      3.5625,
      -3.546875,
      -0.9609375,
      0.55859375,
      3.953125,
      2.421875,
      2.46875,
      -0.0400390625,
      -0.9609375,
      2.234375,
      3.59375,
      0.70703125,
      -2.625,
      0.28515625,
      3.09375,
      -3.03125,
      -2.953125,
      -2.359375,
      -0.275390625,
      2.421875,
      -3.03125,
      -2.859375,
      -0.765625,
      0.85546875,
      -0.55078125,
      -8.625,
      0.359375,
      -3.1875,
      -0.6640625,
      -3.15625,
      -0.6171875,
      3,
      3.03125,
      1.109375,
      4.4375,
      3.234375,
      -1.5,
      5.21875,
      19.75,
      -2.4375,
      -1.53125,
      0.53515625,
      -2.5,
      4.53125,
      3.8125,
      3.140625,
      -0.031494140625,
      0.1015625,
      -2.0625,
      2.28125,
      2.21875,
      3.03125,
      0.4453125,
      -1.375,
      0.6015625,
      0.359375,
      -2.96875,
      -3.953125,
      2.484375,
      -3.40625,
      -0.412109375,
      0.2373046875,
      -2.40625,
      1.3984375,
      0.35546875,
      0.69140625,
      -2.734375,
      -1.265625,
      -0.546875,
      0.6328125,
      -0.80859375,
      -6.03125,
      0.5234375,
      -1.890625,
      0.5,
      0.1875,
      -3.234375,
      -4.25,
      -0.5859375,
      -2.4375,
      4.9375,
      -0.9296875,
      -1.1171875,
      1.1796875,
      -1.2578125,
      1.1015625,
      -0.953125,
      1.3984375,
      -1.1953125,
      1.1328125,
      -3.96875,
      1.7890625,
      0.2470703125,
      0.1044921875,
      -0.38671875,
      -5.46875,
      -3.46875,
      -3.65625,
      -1.3203125,
      -1.3671875,
      -4.4375,
      -0.1669921875,
      -0.5546875,
      -3.65625,
      -0.2080078125,
      -0.97265625,
      0.1767578125,
      -0.484375,
      -2.5,
      0.60546875,
      5.59375,
      1.7421875,
      0.625,
      -1.9296875,
      1.5546875,
      2.671875,
      -0.546875,
      2.578125,
      -2.234375,
      0.93359375,
      -1.1640625,
      0.91015625,
      -1.84375,
      1.3515625,
      -3.21875,
      3.265625,
      1.4375,
      -2.421875,
      4.53125,
      -6.125,
      4.625,
      3.328125,
      -6.125,
      -0.2373046875,
      1.4453125,
      5.9375,
      -3.921875,
      -1.859375,
      2.90625,
      -1.4140625,
      -0.1298828125,
      -2.515625,
      -0.404296875,
      -2.109375,
      0.96484375,
      -0.796875,
      1.59375,
      -0.57421875,
      -0.953125,
      5.34375,
      2.8125,
      -0.08935546875,
      1.0859375,
      1.109375,
      -5.375,
      -0.78515625,
      0.08447265625,
      -0.76171875,
      3.671875,
      1.203125,
      -1.6484375,
      0.00457763671875,
      -9.25,
      -4.25,
      -2.34375,
      -6.84375,
      1.9453125,
      -6.21875,
      1.3125,
      0.8984375,
      -2.53125,
      -1.25,
      1.6015625,
      -3.875,
      2.59375,
      5.125,
      0.9765625,
      -2,
      -3.6875,
      -0.02392578125,
      -0.486328125,
      -1.609375,
      1.5859375,
      2.734375,
      -2.640625,
      2.390625,
      3.8125,
      -0.1923828125,
      -0.97265625,
      3.3125,
      -1.7421875,
      -5.71875,
      0.91796875,
      5.34375,
      0.53125,
      -2.0625,
      -2.046875,
      -0.62890625,
      -2.03125,
      0.84765625,
      -2.390625,
      -1.90625,
      -3.234375,
      -2.21875,
      2.578125,
      -1.1484375,
      -4.5625,
      1.2421875,
      0.71875,
      -6.59375,
      0.091796875,
      -3.15625,
      5.84375,
      -5.28125,
      1.1953125,
      8.5625,
      -0.08837890625,
      1.4140625,
      2.890625,
      0.287109375,
      -2.0625,
      -6.28125,
      3.84375,
      4.96875,
      -3.625,
      2.40625,
      3.03125,
      -1.4609375,
      1.25,
      -1.5234375,
      -3.6875,
      6,
      4.65625,
      -5.25,
      -0.50390625,
      0.197265625,
      1.875,
      -0.84765625,
      -3.09375,
      3.359375,
      2.34375,
      1.546875,
      1.3203125,
      0.03076171875,
      -7.21875,
      -2.671875,
      -1.7421875,
      0.546875,
      -1.1796875,
      1.6484375,
      -0.1748046875,
      1.0703125,
      -7.09375,
      5.21875,
      2.125,
      5.5,
      -2.890625,
      2.515625,
      5.59375,
      2.53125,
      -3.890625,
      -0.0213623046875,
      1.3515625,
      3.421875,
      -6.65625,
      -0.171875,
      -3.6875,
      2.484375,
      -2.9375,
      1.3671875,
      -2.28125,
      0.83203125,
      -3.25,
      -2.296875,
      -5.65625,
      1.3359375,
      1.8203125,
      -0.146484375,
      1.4609375,
      -1.4765625,
      0.8203125,
      3.40625,
      -3.921875,
      1.6328125,
      -2.859375,
      0.76953125,
      -0.40234375,
      -2.0625,
      4.625,
      3.53125,
      4.28125,
      -1.5703125,
      -1.2734375,
      -1.6953125,
      -5.1875,
      1.1171875,
      -5.8125,
      -1.578125,
      0.62109375,
      -6.25,
      4.0625,
      -1.140625,
      -0.251953125,
      0.427734375,
      0.671875,
      -6.03125,
      2.28125,
      3.0625,
      -2.890625,
      2.578125,
      -5,
      -2.703125,
      0.50390625,
      -2.5625,
      0.69921875,
      -4.4375,
      -1.6015625,
      2.28125,
      -3.96875,
      0.5234375,
      3.703125,
      -1.1484375,
      1.0234375,
      -1.9140625,
      5.4375,
      0.95703125,
      2.359375,
      3.734375,
      3.28125,
      4.75,
      -4.75,
      2.0625,
      -3.765625,
      -1.3203125,
      -4.78125,
      0.318359375,
      1.984375,
      -2.03125,
      1.6875,
      1.6484375,
      -0.46484375,
      -7.75,
      -2.390625,
      0.546875,
      -0.55078125,
      2.359375,
      -0.4375,
      0.3515625,
      -1.6796875,
      -0.48046875,
      2.828125,
      0.287109375,
      -0.84375,
      -1.640625,
      -0.50390625,
      -0.1826171875,
      3.828125,
      -7.09375,
      -0.2578125,
      1.7265625,
      0.1611328125,
      0.1796875,
      -1.6640625,
      -0.53125,
      -0.380859375,
      5.28125,
      -4.03125,
      1.3515625,
      0.4375,
      2.65625,
      5.9375,
      -0.361328125,
      1.1171875,
      1.046875,
      -0.9296875,
      -3.90625,
      0.76953125,
      -2.5,
      0.050537109375,
      2.8125,
      -3.171875,
      4.1875,
      0.234375,
      1.046875,
      -2.0625,
      6.625,
      1.4375,
      -7.40625,
      4.28125,
      -2.984375,
      2.78125,
      -0.322265625,
      -3.296875,
      -3.890625,
      4.84375,
      1.2109375,
      -0.765625,
      2.96875,
      0.0186767578125,
      2.0625,
      1.2734375,
      -0.0098876953125,
      -4.40625,
      1.6796875,
      -0.7890625,
      -3.78125,
      3.28125,
      5.34375,
      -0.058349609375,
      -0.515625,
      -0.97265625,
      4.25,
      -2.21875,
      -2.90625,
      4.84375,
      4.40625,
      -0.0252685546875,
      -3.03125,
      -1.3671875,
      -0.032958984375,
      -1.21875,
      -2.140625,
      0.259765625,
      -0.3984375,
      2.703125,
      -2.84375,
      1.6171875,
      2.78125,
      -2.828125,
      -4.0625,
      -4.1875,
      -1.75,
      1.3203125,
      1.921875,
      2.984375,
      -4.28125,
      0.87109375,
      2.78125,
      0.1611328125,
      -1.9609375,
      -2.296875,
      1.34375,
      -3,
      -3.140625,
      -1.890625,
      1.2109375,
      -1.25,
      -1.265625,
      0.91796875,
      0.65625,
      0.1376953125,
      -4.75,
      -1.9375,
      0.62890625,
      2.1875,
      -2.15625,
      -3.234375,
      -2.890625,
      3.640625,
      2.828125,
      -4.125,
      0.359375,
      -0.7578125,
      3.5,
      -4.65625,
      -1.4296875,
      2.15625,
      -2.28125,
      0.60546875,
      6.71875,
      0.427734375,
      0.75390625,
      3.046875,
      -3.796875,
      -2.890625,
      3.328125,
      1.890625,
      0.89453125,
      1.3828125,
      -0.95703125,
      -3.59375,
      4.09375,
      6.75,
      -1.484375,
      -0.62109375,
      1.65625,
      -0.26953125,
      -2.953125,
      -2.046875,
      2.578125,
      -1.203125,
      -5.65625,
      3.5625,
      -1,
      3.9375,
      4.125,
      -3.546875,
      4.75,
      -4.1875,
      -0.65625,
      0.96875,
      2.84375,
      0.98046875,
      -3.71875,
      0.640625,
      -5.34375,
      -2.734375,
      -1.2265625,
      -1.4453125,
      -0.044921875,
      0.11279296875,
      3.078125,
      -1.265625,
      -3.546875,
      -1.3125,
      -1.1796875,
      4.96875,
      -1.5625,
      -1.0625,
      0.2578125,
      -1.9609375,
      2.15625,
      -2.46875,
      0.287109375,
      -4.125,
      -1.5859375,
      -2.5,
      2.78125,
      0.52734375,
      0.1142578125,
      -1.2265625,
      -3.21875,
      -2.484375,
      5.78125,
      2.09375,
      1.78125,
      0.70703125,
      2.765625,
      -0.94921875,
      1.0234375,
      3.015625,
      6.25,
      3.0625,
      -0.189453125,
      0.921875,
      0.375,
      0.38671875,
      -0.205078125,
      -1.3125,
      0.4296875,
      1.53125,
      6.0625,
      1.46875,
      0.7734375,
      -1.7890625,
      -2.5625,
      -3.71875,
      -1.7109375,
      1.1796875,
      0.43359375,
      -0.87109375,
      1.9140625,
      1.265625,
      3,
      -0.3125,
      1.1328125,
      -0.6875,
      -0.1875,
      -1.1796875,
      2.609375,
      -2.53125,
      -2.359375,
      -1.4296875,
      -0.55859375,
      0.310546875,
      -1.4140625,
      -4.84375,
      1.6015625,
      3.1875,
      -1.765625,
      3.84375,
      -0.498046875,
      -0.5625,
      -1.921875,
      0.85546875,
      0.34375,
      2.03125,
      -0.2109375,
      4.1875,
      -1.046875,
      1.0703125,
      2.421875,
      0.1484375,
      0.6015625,
      1.4375,
      0.1298828125,
      0.828125,
      0.2138671875,
      0.236328125,
      -0.9609375,
      -1.7109375,
      4.53125,
      2.90625,
      0.423828125,
      -0.76171875,
      -0.24609375,
      -4.5,
      1.2421875,
      -1.3203125,
      -0.69921875,
      0.474609375,
      -0.0012969970703125,
      -1.0078125,
      2.359375,
      -0.69140625,
      0.62109375,
      2.328125,
      -2.171875,
      -0.1123046875,
      -2.703125,
      2.375,
      -2.96875,
      0.625,
      2.625,
      2.171875,
      -2.140625,
      -1.5234375,
      2.265625,
      -0.171875,
      0.2578125,
      -1.1015625,
      0.2119140625,
      0.52734375,
      0.515625,
      -1.9609375,
      2.453125,
      2.09375,
      2.125,
      3.265625,
      0.4609375,
      1.9453125,
      -1.1328125,
      -0.1591796875,
      0.58984375,
      1.6484375,
      -0.953125,
      -0.0947265625,
      -0.1455078125,
      -0.79296875,
      0.5546875,
      1.1953125,
      0.39453125,
      2.171875,
      -0.30078125,
      0.1845703125,
      -2.546875,
      -0.76171875,
      1.109375,
      0.193359375,
      -2.0625,
      -3.046875,
      0.25390625,
      -1.3203125,
      1.3203125,
      0.97265625,
      -2.390625,
      0.70703125,
      -2.53125,
      -1.3515625,
      3.296875,
      0.48828125,
      -1.96875,
      3.09375,
      -1.6328125,
      0.6328125,
      0.4296875,
      1.125,
      -2.265625,
      0.275390625,
      -1.0546875,
      -2.84375,
      -0.57421875,
      -1.6953125,
      0.30078125,
      0.32421875,
      -0.53125,
      0.70703125,
      0.384765625,
      -0.5078125,
      0.5,
      -1.8671875,
      -0.427734375,
      1.3203125,
      2.203125,
      2.09375,
      4.125,
      -0.359375,
      3.46875,
      -0.0771484375,
      -2.71875,
      2.859375,
      -0.380859375,
      -1.203125,
      0.90234375,
      -1.1171875,
      -0.040283203125,
      -0.228515625,
      -1.6484375,
      -0.80078125,
      -1.828125,
      -0.2265625,
      1.609375,
      -0.58203125,
      1.6796875,
      3.375,
      0.298828125,
      1.1953125,
      -0.8125,
      2.015625,
      0.0546875,
      1.2578125,
      2.859375,
      2.140625,
      -1.25,
      -1.25,
      -1.8828125,
      -1.046875,
      -0.5078125,
      -0.54296875,
      2.359375,
      -3.78125,
      1.71875,
      4.34375,
      -0.98828125,
      3.015625,
      -1.265625,
      0.2041015625,
      0.255859375,
      -0.5390625,
      0.427734375,
      4.0625,
      -0.028076171875,
      0.271484375,
      1.734375,
      -0.087890625,
      -0.040771484375,
      -3.046875,
      1.75,
      1.515625,
      -0.65625,
      0.33984375,
      3.203125,
      0.90234375,
      1.9609375,
      1.484375,
      1.1640625,
      2.109375,
      -1.6328125,
      5.59375,
      1.7109375,
      0.2412109375,
      2.53125,
      0.9296875,
      1.703125,
      1.3828125,
      -3.59375,
      0.7421875,
      -1.6171875,
      1.1328125,
      3.265625,
      0.482421875,
      1.4296875,
      -1.90625,
      -1.671875,
      1.3359375,
      -1.0078125,
      1.3984375,
      1.2265625,
      2.359375,
      -0.9140625,
      0.734375,
      -0.486328125,
      -0.0166015625,
      0.36328125,
      -4.125,
      -0.53125,
      1.125,
      -0.04833984375,
      -3.046875,
      -1.671875,
      -5,
      -2.640625,
      -1.6328125,
      -2.171875,
      0.90234375,
      1.3359375,
      -1.125,
      -2.734375,
      -2.140625,
      -1.125,
      3.640625,
      0.06396484375,
      -0.72265625,
      4.15625,
      0.57421875,
      0.44140625,
      -1.7265625,
      -2.640625,
      -1.15625,
      1.1875,
      -0.9375,
      -1.5,
      -1.265625,
      -0.765625,
      -1.515625,
      -0.7734375,
      2.1875,
      -1.390625,
      -3.453125,
      -0.90234375,
      1.0546875,
      -4.5,
      2.625,
      -2.234375,
      4.53125,
      0.74609375,
      1.2734375,
      0.0830078125,
      -0.015869140625,
      4.34375,
      1.3046875,
      -3.34375,
      -2.984375,
      3.03125,
      -0.306640625,
      0.93359375,
      -0.61328125,
      1.796875,
      6.5625,
      -0.87890625,
      -1.1484375,
      1.90625,
      0.9453125,
      -0.298828125,
      1.984375,
      4.4375,
      -5,
      -0.35546875,
      0.40234375,
      -1.7109375,
      1.3046875,
      2.5,
      2.953125,
      2.71875,
      4.15625,
      -1.3125,
      1.390625,
      -0.859375,
      -2.140625,
      0.58984375,
      1.5703125,
      0.36328125,
      -1.890625,
      -0.19140625,
      0.90234375,
      0.1376953125,
      3.265625,
      -1.0234375,
      0.9609375,
      1.9921875,
      -3.140625,
      0.08447265625,
      0.9453125,
      -0.2236328125,
      5.09375,
      2.0625,
      -1.296875,
      0.283203125,
      -0.248046875,
      2.671875,
      -0.25390625,
      2.140625,
      -1.65625,
      2.5,
      -1.5390625,
      -7.03125,
      -2.171875,
      1.7109375,
      -1.6015625,
      -0.2021484375,
      -2.765625,
      -2.28125,
      -1.984375,
      3.09375,
      -2.4375,
      0.77734375,
      4.21875,
      2.53125,
      2.421875,
      2.828125,
      0.007232666015625,
      2.375,
      2.1875,
      -4.4375,
      2.640625,
      -0.85546875,
      -4.84375,
      -2.515625,
      1.734375,
      -2.203125,
      -2.578125,
      -1.859375,
      -0.4453125,
      -1.7421875,
      -0.58984375,
      0.46875,
      -5.09375,
      2.78125,
      -4,
      -1.0078125,
      -2.28125,
      -0.056396484375,
      -4.03125,
      0.006591796875,
      -0.921875,
      -0.88671875,
      2.59375,
      -0.66015625,
      2,
      -1.765625,
      -1.078125,
      2.078125,
      -5.03125,
      0.1865234375,
      2.703125,
      -2.609375,
      -1.96875,
      -1.7578125,
      2.734375,
      -0.419921875,
      -1.0546875,
      0.3359375,
      -0.2470703125,
      1.984375,
      3.65625,
      -2.03125,
      1.34375,
      -2.75,
      -1.1875,
      -2.953125,
      0.95703125,
      -1.1875,
      -2.140625,
      -2.078125,
      3.078125,
      -3.796875,
      2.9375,
      -1.640625,
      0.81640625,
      0.75390625,
      -2.90625,
      1.609375,
      -1.3828125,
      -4.625,
      0.5078125,
      0.87890625,
      0.02587890625,
      -0.93359375,
      4.75,
      -3.328125,
      1.8828125,
      -2.21875,
      0.74609375,
      1.2734375,
      1.453125,
      -1.78125,
      2.578125,
      0.80078125,
      -0.48828125,
      3.6875,
      2.359375,
      -0.98046875,
      -0.78515625,
      -0.6015625,
      -0.765625,
      -0.93359375,
      4.40625,
      -1.6875,
      -4.46875,
      -0.486328125,
      -0.703125,
      1.734375,
      -1.75,
      1.4609375,
      -1.6640625,
      1.203125,
      0.71484375,
      3.0625,
      2,
      0.58984375,
      2.171875,
      1.71875,
      0.69921875,
      -1.5703125,
      -1.8046875,
      0.1376953125,
      4.8125,
      0.341796875,
      -2.0625,
      3.609375,
      0.30078125,
      -0.5703125,
      -1.6015625,
      1.53125,
      0.63671875,
      -0.24609375,
      -2.5625,
      -2.671875,
      -0.490234375,
      -2.734375,
      -3.015625,
      2.828125,
      0.86328125,
      -0.4609375,
      3.21875,
      1,
      -2.15625,
      -0.5625,
      -1.6015625,
      2.921875,
      0.6015625,
      0.7109375,
      0.064453125,
      2.515625,
      -1.4140625,
      0.9296875,
      0.8046875,
      1.2265625,
      3.25,
      0.66015625,
      -0.06005859375,
      -1.59375,
      2.125,
      -0.73828125,
      3.078125,
      1.875,
      0.380859375,
      -2.265625,
      3.359375,
      2.890625
    ],
    "summary": "采用结构化、可复现的流程，对神经问题生成（NQG）领域的现有研究进行全面检索、筛选、分析和综合，以总结该领域的现状、方法、趋势和挑战。",
    "structure": {
      "sections": [
        {
          "title": "A Systematic Review of Automatic Neural Question Generation",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "1 Abstract",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "1. INTRODUCTION",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "2. METHODOLOGY",
          "level": 1,
          "start_line": 25
        },
        {
          "title": "2.1 Research Questions",
          "level": 1,
          "start_line": 36
        },
        {
          "title": "2.1.1 Old Research Questions:",
          "level": 1,
          "start_line": 38
        },
        {
          "title": "2.1.2 New Research Questions:",
          "level": 1,
          "start_line": 61
        },
        {
          "title": "2.2 Data Sources and Search Strategy",
          "level": 1,
          "start_line": 77
        },
        {
          "title": "2.3 Study Selection Criteria",
          "level": 1,
          "start_line": 91
        },
        {
          "title": "Inclusion Criteria:",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "Exclusion criteria:",
          "level": 1,
          "start_line": 104
        },
        {
          "title": "2.4 Study Selection Process",
          "level": 1,
          "start_line": 110
        },
        {
          "title": "- Iteration 0 - Filtering by Title",
          "level": 1,
          "start_line": 114
        },
        {
          "title": "- Iteration 2 - Filtering by Full Text",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "2.5 Quality Assessment",
          "level": 1,
          "start_line": 129
        },
        {
          "title": "2.6 Included papers",
          "level": 1,
          "start_line": 146
        },
        {
          "title": "2.7 Data Extraction Strategy",
          "level": 1,
          "start_line": 165
        },
        {
          "title": "Paper Information:",
          "level": 1,
          "start_line": 169
        },
        {
          "title": "Data extracted:",
          "level": 1,
          "start_line": 176
        },
        {
          "title": "2.8 Synthesis Matrix",
          "level": 1,
          "start_line": 216
        },
        {
          "title": "3. RESULT AND DISCUSSION",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "3.1 Neural Question Generation (NQG)",
          "level": 1,
          "start_line": 237
        },
        {
          "title": "3.1.1 Word Embedding",
          "level": 1,
          "start_line": 246
        },
        {
          "title": "3.1.2 Seq2Seq",
          "level": 1,
          "start_line": 256
        },
        {
          "title": "3.2 Gated Recurrent Units (GRUs)",
          "level": 1,
          "start_line": 275
        },
        {
          "title": "The Architecture of the GRU",
          "level": 1,
          "start_line": 279
        },
        {
          "title": "Math and pictorial representation to understand the functioning",
          "level": 1,
          "start_line": 299
        },
        {
          "title": "Update gate:",
          "level": 1,
          "start_line": 301
        },
        {
          "title": "Where,",
          "level": 1,
          "start_line": 314
        },
        {
          "title": "Reset gate",
          "level": 1,
          "start_line": 322
        },
        {
          "title": "Where,",
          "level": 1,
          "start_line": 335
        },
        {
          "title": "How GRU Works",
          "level": 1,
          "start_line": 343
        },
        {
          "title": "What is the difference between the GRU and the LSTM?",
          "level": 1,
          "start_line": 371
        },
        {
          "title": "3.2.1 Word2Vec",
          "level": 1,
          "start_line": 381
        },
        {
          "title": "3.2.2 Seq2Seq with Attention Mechanism",
          "level": 1,
          "start_line": 390
        },
        {
          "title": "3.2.3 Preprocessing",
          "level": 1,
          "start_line": 408
        },
        {
          "title": "3.2.4 Lexical Feature (POS)",
          "level": 1,
          "start_line": 414
        },
        {
          "title": "Framework for POS discovering:",
          "level": 1,
          "start_line": 428
        },
        {
          "title": "3.2.5 Lexical Features (NER)",
          "level": 1,
          "start_line": 436
        },
        {
          "title": "Methods of NER",
          "level": 1,
          "start_line": 446
        },
        {
          "title": "3.2.6 BLUE and precision Evaluation Metrics",
          "level": 1,
          "start_line": 452
        },
        {
          "title": "Precision:",
          "level": 1,
          "start_line": 454
        },
        {
          "title": "BLEU, which stands for Bi-Lingual Evaluation Understudy:",
          "level": 1,
          "start_line": 464
        },
        {
          "title": "3.3 Update on Research Questions",
          "level": 1,
          "start_line": 480
        },
        {
          "title": "3.4 Threats to Validity",
          "level": 1,
          "start_line": 498
        },
        {
          "title": "4. CONCLUSION AND FUTURE WORK",
          "level": 1,
          "start_line": 507
        },
        {
          "title": "8. Graph Encoders for Question Generation",
          "level": 1,
          "start_line": 523
        },
        {
          "title": "5. REFERENCES",
          "level": 1,
          "start_line": 525
        }
      ]
    },
    "suggested_tags": [
      "自然语言处理",
      "神经问题生成",
      "序列到序列模型",
      "系统文献综述",
      "教育技术"
    ],
    "tag_suggestions": [
      {
        "name": "自然语言处理",
        "confidence": 0.98,
        "reason": "论文核心研究对象是自然语言处理（NLP）领域中的自动问题生成任务，全文围绕NLP技术展开讨论。"
      },
      {
        "name": "神经问题生成",
        "confidence": 0.95,
        "reason": "论文主题为‘神经问题生成’的系统性综述，深入分析了基于深度学习的NQG模型、方法、数据集和评估。"
      },
      {
        "name": "序列到序列模型",
        "confidence": 0.9,
        "reason": "论文明确指出所有NQG模型共享一个Seq2Seq基础框架，并重点讨论了结合注意力机制的Seq2Seq模型。"
      },
      {
        "name": "系统文献综述",
        "confidence": 0.85,
        "reason": "论文采用的研究方法是系统文献综述，旨在全面梳理和总结该领域的研究现状、趋势与挑战。"
      },
      {
        "name": "教育技术",
        "confidence": 0.75,
        "reason": "论文多次提及NQG在教育领域的应用，如促进自主学习和作为教育工具，这是其主要应用场景之一。"
      }
    ],
    "category": "自然语言处理",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:282895720",
          "title": "VocQuiz: Vocabulary Question Generation for English Language Education",
          "authors": [
            "Yongqi Li",
            "Jiajun Wu",
            "Shangqing Tu",
            "Jifan Yu",
            "Huiqin Liu",
            "Lei Hou",
            "Juanzi Li"
          ],
          "year": 2025,
          "venue": "International Conference on Information and Knowledge Management",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282272756",
          "title": "Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization",
          "authors": [
            "Yuto Tomikawa",
            "Masaki Uto"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281960356",
          "title": "Automated question generation for Arabic language",
          "authors": [
            "Rahaf A. Alhazaymeh",
            "Mostafa Z. Ali"
          ],
          "year": 2025,
          "venue": "Cluster Computing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282163675",
          "title": "Coordinated LLM multi-agent systems for collaborative question-answer generation",
          "authors": [
            "Sami Saadaoui",
            "Eduardo Alonso"
          ],
          "year": 2025,
          "venue": "Knowledge-Based Systems",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282223830",
          "title": "Knowledge graph question generation based on crucial semantic information",
          "authors": [
            "Mingtao Zhou",
            "Juxiang Zhou",
            "Jianhou Gan",
            "Jun Wang",
            "Jiatian Mei"
          ],
          "year": 2025,
          "venue": "Data & Knowledge Engineering",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281351414",
          "title": "A literature review of research on question generation in education",
          "authors": [
            "XiaoHui Dong",
            "Xinyu Zhang",
            "Zhengluo Li",
            "Quanxin Hou",
            "Jixiang Xue",
            "Xiaoyi Li"
          ],
          "year": 2025,
          "venue": "PeerJ Computer Science",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280870274",
          "title": "Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails",
          "authors": [
            "Kellen Cheng",
            "Anna Lisa Gentile",
            "Chad DeLuca",
            "Guang-Jie Ren"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280686598",
          "title": "Ask Good Questions for Large Language Models",
          "authors": [
            "Qi Wu",
            "Zhong Lu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280641733",
          "title": "Learning Facts at Scale with Active Reading",
          "authors": [
            "Jessy Lin",
            "Vincent-Pierre Berges",
            "Xilun Chen",
            "Wen-tau Yih",
            "Gargi Ghosh",
            "Barlas Oğuz"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:280649596",
          "title": "Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis",
          "authors": [
            "Linqing Chen",
            "Hanmeng Zhong",
            "Wentao Wu",
            "Weilei Wang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        }
      ],
      "citations_fetched_at": "2025-12-16T22:48:21.493125",
      "references": [
        {
          "external_id": "CorpusId:16538528",
          "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
          "authors": [
            "Guillaume Klein",
            "Yoon Kim",
            "Yuntian Deng",
            "Jean Senellart",
            "Alexander M. Rush"
          ],
          "year": 2017,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1934
        },
        {
          "external_id": "CorpusId:260460088",
          "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
          "authors": [
            "Payal Bajaj",
            "Daniel Fernando Campos",
            "Nick Craswell",
            "Li Deng",
            "Jianfeng Gao",
            "Xiaodong Liu",
            "Rangan Majumder",
            "Andrew McNamara",
            "Bhaskar Mitra",
            "Tri Minh Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "A. Stoica",
            "Saurabh Tiwary",
            "Tong Wang"
          ],
          "year": 2016,
          "venue": "",
          "citation_count": 525
        },
        {
          "external_id": "CorpusId:1289517",
          "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
          "authors": [
            "Daniel Fernando Campos",
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "L. Deng",
            "Bhaskar Mitra"
          ],
          "year": 2016,
          "venue": "CoCo@NIPS",
          "citation_count": 3111
        },
        {
          "external_id": "CorpusId:8820379",
          "title": "Summarizing Source Code using a Neural Attention Model",
          "authors": [
            "Srini Iyer",
            "Ioannis Konstas",
            "Alvin Cheung",
            "Luke Zettlemoyer"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 734
        },
        {
          "external_id": "CorpusId:11816014",
          "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
          "authors": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
          ],
          "year": 2016,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 8827
        },
        {
          "external_id": "CorpusId:6360322",
          "title": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
          "authors": [
            "Danqi Chen",
            "Jason Bolton",
            "Christopher D. Manning"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 578
        },
        {
          "external_id": "CorpusId:133195",
          "title": "Abstractive Sentence Summarization with Attentive Recurrent Neural Networks",
          "authors": [
            "S. Chopra",
            "Michael Auli",
            "Alexander M. Rush"
          ],
          "year": 2016,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 915
        },
        {
          "external_id": "CorpusId:12241221",
          "title": "Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus",
          "authors": [
            "Iulian Serban",
            "Alberto García-Durán",
            "Çaglar Gülçehre",
            "Sungjin Ahn",
            "A. Chandar",
            "Aaron C. Courville",
            "Yoshua Bengio"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 297
        },
        {
          "external_id": "CorpusId:16227864",
          "title": "Generating Natural Questions About an Image",
          "authors": [
            "N. Mostafazadeh",
            "Ishan Misra",
            "Jacob Devlin",
            "Margaret Mitchell",
            "Xiaodong He",
            "Lucy Vanderwende"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 313
        },
        {
          "external_id": "CorpusId:1918428",
          "title": "A Neural Attention Model for Abstractive Sentence Summarization",
          "authors": [
            "Alexander M. Rush",
            "S. Chopra",
            "J. Weston"
          ],
          "year": 2015,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 2788
        }
      ],
      "references_fetched_at": "2025-12-16T22:48:22.585729"
    }
  },
  "bbccfac3-3da5-44b5-af1f-3a65af0482ba": {
    "id": "bbccfac3-3da5-44b5-af1f-3a65af0482ba",
    "filename": "2025.bea-1.69.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/bbccfac3-3da5-44b5-af1f-3a65af0482ba_2025.bea-1.69.pdf",
    "status": "completed",
    "created_at": "2025-12-16 22:43:19.655981",
    "updated_at": "2025-12-16 14:44:46.269740",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "STAIR-AIG: Optimizing the Automated Item Generation Process through Human-AI Collaboration for Critical Thinking Assessment",
    "markdown_content": "# STAIR-AIG: Optimizing the Automated Item Generation Process through Human-AI Collaboration for Critical Thinking Assessment\n\nEuigyum Kim<sup>1</sup>, Seewoo Li<sup>2</sup>, Salah Khalil<sup>3</sup>, and Hyo Jeong Shin<sup>1*</sup>\n\n$^{1}$ Sogang University, Seoul, South Korea\n\n$^{2}$ University of California, Los Angeles, USA\n\n$^{3}$ MACAT International Ltd., United Kingdom\n\n# Abstract\n\nThe advent of artificial intelligence (AI) has marked a transformative era in educational measurement and evaluation, particularly in the development of assessment items. Large language models (LLMs) have emerged as promising tools for scalable automatic item generation (AIG), yet concerns remain about the validity of AI-generated items in various domains. To address this issue, we propose STAIR-AIG (Systematic Tool for Assessment Item Review in Automatic Item Generation), a human-in-the-loop framework that integrates expert judgment to optimize the quality of AIG items. To explore the functionality of the tool, AIG items were generated in the domain of critical thinking. Subsequently, the human expert and four OpenAI LLMs conducted a review of the AIG items. The results show that while the LLMs demonstrated high consistency in their rating of the AIG items, they exhibited a tendency towards leniency. In contrast, the human expert provided more variable and strict evaluations, identifying issues such as the irrelevance of the construct and cultural insensitivity. These findings highlight the viability of STAIR-AIG as a structured human-AI collaboration approach that facilitates rigorous item review, thus optimizing the quality of AIG items. Furthermore, STAIR-AIG enables iterative review processes and accumulates human feedback, facilitating the refinement of models and prompts. This, in turn, would establish a more reliable and comprehensive pipeline to improve AIG practices.\n\n# 1 Introduction\n\nRecent advances in natural language processing (NLP) and generative artificial intelligence (AI), particularly large language models (LLMs), have transformed educational measurement from relatively labor-intensive processes to more automated, scalable, and efficient approaches (Srini\n\nvasan, 2022; Wang et al., 2024). Prominent examples include automated scoring (Latif and Zhai, 2024; Lee et al., 2024; Luchini et al., 2025) and automated feedback generation (Hahn et al., 2021; Chan et al., 2025), which substantially improve efficiency by reducing human labor while ensuring relatively valid and consistent outcomes.\n\nAmong these innovations, automatic item generation (AIG) has emerged as a particularly pertinent application of LLM for the rapid and effective development of assessment items (Gierl and Lai, 2013; Kurdi et al., 2020). Traditional AIG approaches generated new items by replacing different numbers or words in predefined models or templates, aiming to assess the same underlying construct. With the advent of LLMs, AIG has now entered a new phase, enabling educational researchers and practitioners to generate numerous items with minimal programming expertise. However, regardless of the AIG model used, the quality, appropriateness, and validity of AI-generated items still remain questionable. Consequently, the incorporation of quality assurance processes and human participation is deemed inevitable to ensure that AIG systems are generating content as intended (von Davier and Burstein, 2024).\n\nIn particular, it is important to ensure that the assessment items are aligned with target measurement constructs, as poorly defined constructs and superficially designed items can undermine the validity and reliability of the assessment (Liu et al., 2016). Consequently, a robust human-AI collaboration (HAIC) (Fragiadakis et al., 2025) is essential not only to leverage the scalability and efficiency of the AIG process, but also to ensure overall quality and safeguard the validity of AI-generated assessment items (Hao et al., 2024). Nevertheless, prior literature reveals a lack of empirical studies validating the appropriateness of AI-generated items for assessing cognitive skills within human-AI collaborative contexts.\n\nTo address this gap, the present study introduces STAIR-AIG (Systematic Tool for Assessment Item Review in Automatic Item Generation), an item review tool that supports systematic and efficient human review of AI-generated assessment items. We illustrate its potential as both a practical tool and a conceptual AIG framework by applying it to the domain of critical thinking (CT), a higher-order cognitive skill widely recognized as an essential 21st-century core competency (World Economic Forum, 2015). In complex cognitive domains, such as CT, the expert review by the human is particularly important in that defining the measurement structures and developing the assessment items are quite challenging (Shin et al., 2025).\n\nBy leveraging NLP techniques, our tool provides a comprehensive linguistic feature analysis of items. This empowers human reviewers to integrate their domain knowledge in a more effective way. Furthermore, the evaluations of AIG items by human experts are stored as data, so they continuously contribute to the improvement and refinement of the internal LLMs within the AIG pipeline. In contrast to conventional methods, which generally rely exclusively on human review as a final gatekeeping measure in a linear fashion, STAIR-AIG incorporates multiple structured touch-points for expert judgment at each stage. This facilitates continuous evaluation, targeted refinement of AI-generated elements, and ongoing enhancement of LLMs for AIG through structured human feedback and prompt optimization in a dynamic manner.\n\nIn the following, we illustrate the use of the STAIR-AIG tool as a human-in-the-loop AIG process. We review the relevant literature on AIG and the traditional item review process. Then, we present a case study that demonstrates the use of the STAIR-AIG tool in the CT domain. Subsequently, we compare the evaluations performed by a human expert with those generated by the LLM to identify discrepancies and examine the implications of their collaboration for enhancing the AIG process.\n\n# 2 Related Works\n\n# 2.1 Automatic Item Generation\n\nWith the growing interest in AIG to build reliable computer-based assessments by stably and efficiently feeding items into the item bank, the number of publications on AIG has recently increased (Kurdi et al., 2020). Before the advent of LLMs, the techniques of AIG studies were based on syntax\n\nor templates that harness computational power to reduce human labor, such as employing grammar correction programs and developing templates to build software programs (Bejar, 1996, 2002; Singley and Bennett, 2002). In contrast, the recent rise of LLMs in the AI research field has enabled AIG researchers to generate items without extensive software engineering, while empowering item developers to effectively realize their nuanced intentions within the generation process (Attali et al., 2022; Bezirhan and von Davier, 2023).\n\nIn line with current research trends in AIG based on LLMs, this study utilizes CT items developed through a structured AIG procedure (Shin et al., 2025). This approach leverages prompt engineering techniques using LLM and is structured into three distinct modules—passage, question, and choices statements—to support systematic generation and monitoring. Within each module, detailed prompts are provided to the LLM to generate components of items intended to assess CT skills. The modules are executed sequentially to form a complete item, which is then finalized through expert review and revision. Psychometric analyses of the pilot-study data confirmed that the generated items were functioning as intended (Shin et al., 2025).\n\n# 2.2 Assessment Item Review Procedure\n\nTraditionally, the development and validation of assessment items have relied heavily on expert-driven review procedures to ensure validity, cognitive alignment, and fairness (Haladyna and Rodriguez, 2013). Guidelines from organizations such as the National Council on Measurement in Education (NCME) and the International Test Commission (ITC) emphasize the need for refinements guided by expert judgment to avoid common errors in the writing of items and to secure the validity of the construct (Haladyna and Rodriguez, 2013; Commission and of Test Publishers, 2022). However, this systematic review process, while essential, is highly time-consuming, especially in large-scale assessment contexts.\n\nTo overcome these challenges and efficiently support assessments at scale, hybrid frameworks integrating automation with human supervision are increasingly adopted. An innovative example is the Item Factory developed for the Duolingo English Test (DET), an item review system that incorporates human-in-the-loop processes, particularly for the development of high-stakes international DET items (von Davier et al., 2024). The Item Factory\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/79b7513fec02512fa0ea73e76e044bff48542c491add722f10b6a3600ca3b7cb.jpg)  \nFigure 1: Pipeline of STAIR-AIG workflow\n\nfacilitates asynchronous collaboration between subject matter experts, supports reviewer calibration, and provides a structured audit trail of editorial decisions (von Davier et al., 2024). This approach not only maintains rigorous educational standards and test fairness, but also exemplifies how scalable and automated processes complemented by human oversight can enhance the quality and efficiency of assessment item review.\n\nItem review tools, including Item Factory, are likely to be designed according to the types of items that are closely related to measurement constructs. To our knowledge, no open-source tool yet facilitates AIG item review for higher-order thinking skills. In the following, we present the STAIR-AIG tool and workflow as a human-in-the-loop procedure to review and optimize AIG items for CT.\n\n# 3 Development of STAIR-AIG\n\n# 3.1 STAIR-AIG Workflow\n\nSTAIR-AIG is developed as an iterative HAIC framework that goes beyond the static and unidirectional AIG process by continuously incorporating human reviewers' feedback to refine LLM behavior. By providing supplementary NLP features to human reviewers, human experts are expected to integrate their domain knowledge more effectively. In addition, it envisions the advancement of an AIG pipeline by automatically converting human reviews into training data for LLMs. These evaluations and human expert insights are then used to iteratively improve both AIG models through reinforcement learning from human feedback (RLHF) (Christiano et al., 2017; Ziegler et al., 2020) and optimize their associated prompts (Lin et al., 2024),\n\nultimately reducing the human effort required to develop and review items that target complex cognitive constructs such as CT.\n\nFigure 1 represents a comprehensive pipeline of the STAIR-AIG workflow. As seen in the figure, the STAIR-AIG workflow is organized as a multistage iterative loop. Preliminary items generated through prompt engineering by LLMs undergo initial evaluation and review via automated analytics, where LLMs function as auxiliary reviewers. Human reviewers then assess each item based on qualitative criteria, including content validity, appropriateness, and cognitive alignment using the STAIR-AIG tool. Importantly, reviewers provide both three-point scale ratings and open-ended feedback, and in many cases, they can directly edit the content of items. These structured data, comments, scores, and editorial changes are saved as review metadata and would be utilized to refine and enhance the performance of the AIG models.\n\nWhat distinguishes STAIR-AIG is its integration of these human-generated review signals into both upstream and downstream optimization processes. On the one hand, reviewer feedback is used for prompt optimization (Lin et al., 2024), improving future item generation by refining how prompts are constructed. On the other hand, the accumulated data from reviews and edits serves as training data for RLHF (Christiano et al., 2017), fine-tuning the LLM to produce items that better align with expert judgment and the intended assessment objectives. As shown in Figure 2, this feedback loop system, inspired by the HAIC framework presented in Huang (2019), exemplifies a HAIC-based workflow designed to optimize the quality of AIG items.\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/252be5f1d8975d9e71707a6ee01076378a0709a1722536ad70a50b9a7b87b6fc.jpg)  \nFigure 2: HAIC workflow in AIG\n\n# 3.2 STAIR-AIG Modules\n\nThe STAIR-AIG system comprises two central modules designed to systematically evaluate and continuously improve the AIG process.\n\n# 3.2.1 Item Analysis Module\n\nThe item analysis module operates as the preliminary review stage. Items undergo automated analysis based on quantitative linguistic metrics. The metrics include traditional NLP features, including type-token ratio, sentence length, and readability indices such as Flesch-Kincaid grade level, ensuring that the items are written clearly for the target age groups (Collins-Thompson, 2014). These metrics are selected to capture linguistic features that influence item clarity, cognitive load, and appropriateness, and to support early-stage quality screening for human review.\n\n- Type-Token Ratio (TTR): A common measure of lexical diversity, defined as\n\n$$\n\\mathrm {T T R} = \\frac {| V |}{| W |} \\tag {1}\n$$\n\nwhere  $|V|$  is the number of unique types and  $|W|$  is the total number of tokens.\n\n- Average Sentence Length (ASL): A measure of syntactic complexity, defined as\n\n$$\n\\mathrm {A S L} = \\frac {N _ {w}}{N _ {s}} \\tag {2}\n$$\n\nwhere  $N_{w}$  is the total words count and  $N_{s}$  is the total number of sentences.\n\n- Average Syllables per Word (ASW): A measure of word complexity, defined as\n\n$$\n\\mathrm {A S W} = \\frac {N _ {\\text {s y l l}}}{N _ {w}} \\tag {3}\n$$\n\nwhere  $N_{s y l l}$  is the total number of syllables and  $N_{w}$  is the total number of words.\n\n- Flesch-Kincaid Grade Level: A readability index that estimates the school grade level required to understand a given text (Kincaid et al., 1975), calculated as\n\n$$\n\\mathrm {F K G L} = 0. 3 9 \\cdot \\mathrm {A S L} + 1 1. 8 \\cdot \\mathrm {A S W} - 1 5. 5 9 \\tag {4}\n$$\n\nWe compute linguistic features by applying an XLM-RoBERTa tokenizer as a text preprocessing step (Conneau et al., 2020). Leveraging these linguistic features, the module automatically evaluates text difficulty, grade-level appropriateness, and lexical diversity metrics, which significantly reduce the workload placed upon human reviewers, thereby enhancing review efficiency and providing human reviewer with detailed item specification information to facilitate effective and timely review.\n\n# 3.2.2 Item Review Module\n\nCentral to the STAIR-AIG system is the item review module, a structured interface that enables human experts to systematically evaluate AI-generated items. Items approved by the initial automated analysis are presented through this module interface. This module segments each item into specific components, such as passages, questions, and answer choices, allowing reviewers to provide detailed evaluations of each component.\n\nExpert reviewers evaluate each component using a three-point quality scale that serves as the basis for determining whether an item would be accepted, revised, or discarded. Reviewer feedback serves a dual purpose. Qualitative comments contribute to improving the item generation prompts, while direct revision suggestions help finalize the item for operational use and also support future model refinement. Through this human-in-the-loop iterative process, STAIR-AIG continuously improves the quality and validity of the items. Once finalized, high-quality items generated by AI and modified by human experts are stored in an item bank for operational deployment. Item review module as an interface of STAIR-AIG is shown in Figure 3.\n\n# 4 Empirical Research\n\nIn this empirical study, only the first round review was performed within the STAIR-AIG workflow. This initial implementation served to examine the utility of the tool and to investigate the discrepancies of review results between the human reviewer and LLM judges at the early stage of the proposed STAIR-AIG workflow.\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/e277486f97873bf9becfe60d865ee622eb8005128720a6be72ef809af020946b.jpg)  \nFigure 3: STAIR-AIG interface\n\n# 4.1 Data\n\nThe items that were reviewed through STAIR-AIG in this study were developed by a MACAT, specializing in CT frameworks and evaluation solutions. They are based on a framework that measures and assesses CT competencies across six subdomains—Problem solving, Analysis, Creative thinking, Interpretation, Evaluation, and Reasoning (PACIER) (MACAT, 2025; Shin et al., 2025).\n\nIn this round, a total of 24 AI-generated items were reviewed, comprising multiple choice (MC) and fill-in-the-blank (FIB) types. Specifically, the assessment included 18 MC items (3 per PACIER domain) and 6 FIB items (1 per PACIER domain). Although actual CT assessment typically employs 4 choices for MC items and 3 choices for FIB items, the initial AIG items were deliberately prompted to generate 10 and 6 choices respectively, to promote a rigorous quality review without being forced to choose from all the bad choices. As for an example, an operating sample item for MACAT's CT assessment is illustrated in Figure 4.\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/a64643a2b34924ba1f8c4d54efa0ff88bfb55032675c733b9c7ddb7f2261aa40.jpg)  \nFigure 4: Sample item of CT assessment.\n\n# 4.2 Item Review by Human Expert\n\nThe key review process for the 24 AIG items was conducted by a human expert who specialized in\n\nCT domain. The human expert reviewed each item systematically following the instructions and steps using the STAIR-AIG tool, indicating the quality of the items and their components on three-point rating scales.\n\n- Dissatisfied: Fundamentally flawed or inappropriate item for CT assessment, and thus should be discarded. (Score: 1)  \n- Neutral: Requires revisions to improve clarity and relevance or modification of difficulty level. (Score: 2)  \nSatisfied: Suitable for immediate use or requires minimal edits. (Score: 3)\n\nSpecifically, the expert provided ratings and comments on each of the item components, including passages, questions, choices, and overall quality of the items, referencing the analytic information provided by the item analysis module. Revision suggestions were also written directly by the expert in the open text field when necessary. Items that were rated as neutral or satisfied received detailed revision suggestions to support iterative refinement. After the review, all data including evaluations, revisions, and edits were provisionally stored as a CSV file for future model fine-tuning.\n\n# 4.3 Item Quality Review by LLMs\n\nIn parallel to the human review, four OpenAI LLMs (GPT-4o, GPT-4.5-preview, o1-mini, and o3-mini) performed independent quality assessments using the LLM-as-a-judge methodology (Zheng et al., 2023). Although prior work has shown that LLM-as-a-judge is closely aligned with human preferences on a variety of tasks (Zheng et al., 2023; Gu et al., 2025), there is a lack of prior research exploring its applicability in the context of complex cognitive skills, specifically in the evaluation of the quality of the AIG items. Therefore, we explored the possibility of using LLM-as-a-judge as an additional reviewer.\n\nEach model evaluated the AIG items based on the same criteria and the same interface used by human reviewers. The prompts were carefully aligned and mirrored with the human evaluation guidelines to ensure methodological consistency. To maintain independence between human and LLM evaluations, we adopted zero-shot learning as an incontext learning approach in which models relied solely on their pre-trained knowledge without being\n\nprovided with any task-specific examples (Brown et al., 2020). This prevents potential contamination between evaluation sources while utilizing LLM's generalized reasoning capabilities, distinct from human influence. The evaluations by LLMs were then compared with human review. Detailed prompts are provided in the Appendix A.\n\n# 5 Results\n\n# 5.1 Quantitative Results\n\n# 5.1.1 Comparison of Human Reviews with LLM-generated Reviews\n\nAnalysis of 18 MC and 6 FIB items reveals differences in rating patterns between the human expert and LLM judges. The descriptive statistics for both item types are reported in Table 1, indicating that a human expert tends to assign lower scores overall and exhibits greater variability across all items.\n\nIn contrast, LLM judges consistently delivered higher scores across all evaluated dimensions with lower standard deviations. The o3-mini model, in particular, demonstrated extreme uniformity, assigning perfect or near-perfect scores with minimal variance. Specifically, even among LLMs, there is a subtle stratification that GPT-4.5-preview and GPT-4o exhibited slightly more variation and lower means than o3-mini. Also, in MC evaluations, the scores of the o1-mini model were closer to those of the human expert, especially in question quality.\n\nConcretely, as illustrated in Figure 5 and Figure 6, LLMs tend to be consistently generous in their evaluations, while the human expert demonstrated a more critical and sensitive attitude marked by greater variability. A particularly notable pattern emerges in the 'Question Rating' category for FIB items, that the human expert consistently assigned the highest score to the 6 items. This uniformity is not coincidental. Since all FIB items had an identical question format, a consistent rating is justifiable and is an expected result, whereas some LLMs failed to reflect this.\n\n# 5.1.2 Distribution of Ratings across Evaluators\n\nTable 2 further illuminates the contrasting behaviors of human expert and LLM judges in evaluating the quality of AIG items. A notable pattern is the relatively frequent use of the lowest rating Dissatisfied (score of 1) by the human expert. Rather than indicating inconsistency, this tendency may reflect the human expert's awareness of the qualitative\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/66b72eb071fca59b38c1636ee3710c8e2354342e07cb4e7e4ad4c3f5afc3626e.jpg)  \nFigure 5: Rating patterns by evaluators for MC items\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/ecace7e3d5b5f3375a81a1a58ad0dc8aa081e795f138047691e89e96fa0c61b3.jpg)  \nFigure 6: Rating patterns by evaluators for FIB item\n\naspects of the content of the item. This indicates that contextual appropriateness, coherence, and educational validity are often more readily detected through human expert, whereas automated systems may overlook such nuanced deficiencies.\n\nIn comparison, LLMs rarely gave the lowest rating of Dissatisfied. For example, o3-mini gave  $100\\%$  Satisfied (score of 3) ratings in nearly every category. In the human rater effect study, this can be interpreted as a leniency or generosity (Wolfe, 2004). Even more conservative models such as o1-mini and GPT-4o showed minimal to zero use of the lowest category across MC and FIB items.\n\nFurthermore, the human evaluator showed a more frequent use of the Neutral category (score of 2), which accounts for most of the responses. This middle-ground positioning can be interpreted as a nuanced case-by-case approach by the human evaluator, in contrast to the strong tendency of LLMs to assign the highest rating across most items.\n\n# 5.2 Qualitative Feedback from Human Expert\n\nTo closely examine the reviews provided by the human expert, we performed a qualitative analysis of the reviewer's written comments. Table 3 lists four themes that categorize and summarize the feedback. The human expert specialized in the as\n\nTable 1: Descriptive statistics for MC and FIB item reviews by evaluators  \n\n<table><tr><td rowspan=\"2\">Item Type</td><td rowspan=\"2\">Evaluator</td><td colspan=\"4\">Overall Quality Score</td><td colspan=\"4\">Passage Rating</td><td colspan=\"4\">Question Rating</td><td colspan=\"4\">Item Choices Rating</td></tr><tr><td>Mean</td><td>Std</td><td>Min</td><td>Max</td><td>Mean</td><td>Std</td><td>Min</td><td>Max</td><td>Mean</td><td>Std</td><td>Min</td><td>Max</td><td>Mean</td><td>Std</td><td>Min</td><td>Max</td></tr><tr><td rowspan=\"5\">MC</td><td>Human</td><td>2.22</td><td>0.65</td><td>1</td><td>3</td><td>2.39</td><td>0.70</td><td>1</td><td>3</td><td>2.11</td><td>0.58</td><td>1</td><td>3</td><td>2.70</td><td>0.29</td><td>2</td><td>3</td></tr><tr><td>GPT-4.5-preview</td><td>2.61</td><td>0.50</td><td>2</td><td>3</td><td>2.78</td><td>0.43</td><td>2</td><td>3</td><td>2.61</td><td>0.50</td><td>2</td><td>3</td><td>2.80</td><td>0.30</td><td>2</td><td>3</td></tr><tr><td>GPT-4o</td><td>2.56</td><td>0.51</td><td>2</td><td>3</td><td>2.67</td><td>0.49</td><td>2</td><td>3</td><td>2.61</td><td>0.50</td><td>2</td><td>3</td><td>2.60</td><td>0.54</td><td>1</td><td>3</td></tr><tr><td>o1-mini</td><td>2.28</td><td>0.46</td><td>2</td><td>3</td><td>2.78</td><td>0.43</td><td>2</td><td>3</td><td>2.11</td><td>0.58</td><td>1</td><td>3</td><td>2.81</td><td>0.35</td><td>2</td><td>3</td></tr><tr><td>o3-mini</td><td>2.82</td><td>0.39</td><td>2</td><td>3</td><td>2.94</td><td>0.24</td><td>2</td><td>3</td><td>2.89</td><td>0.32</td><td>2</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td></tr><tr><td rowspan=\"5\">FIB</td><td>Human</td><td>2.17</td><td>0.41</td><td>2</td><td>3</td><td>1.67</td><td>1.03</td><td>1</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>2.19</td><td>0.41</td><td>1</td><td>3</td></tr><tr><td>GPT-4.5-preview</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>2.86</td><td>0.22</td><td>2</td><td>3</td></tr><tr><td>GPT-4o</td><td>2.67</td><td>0.52</td><td>2</td><td>3</td><td>2.83</td><td>0.41</td><td>2</td><td>3</td><td>2.83</td><td>0.41</td><td>2</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td></tr><tr><td>o1-mini</td><td>2.17</td><td>0.41</td><td>2</td><td>3</td><td>2.83</td><td>0.41</td><td>2</td><td>3</td><td>2.17</td><td>0.41</td><td>2</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td></tr><tr><td>o3-mini</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>2.97</td><td>0.07</td><td>2</td><td>3</td></tr></table>\n\nTable 2: Rating frequency and proportion for MC and FIB item reviews by evaluators  \n\n<table><tr><td rowspan=\"2\">Item Type</td><td rowspan=\"2\">Evaluator</td><td colspan=\"3\">Overall Quality</td><td colspan=\"3\">Passage</td><td colspan=\"3\">Question</td><td colspan=\"3\">Item Choice</td></tr><tr><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td></tr><tr><td rowspan=\"5\">MC</td><td>Human</td><td>2 (11%)</td><td>10 (56%)</td><td>6 (33%)</td><td>2 (11%)</td><td>7 (39%)</td><td>9 (50%)</td><td>2 (11%)</td><td>12 (67%)</td><td>4 (22%)</td><td>4 (2%)</td><td>46 (26%)</td><td>130 (72%)</td></tr><tr><td>GPT-4.5</td><td>0 (0%)</td><td>7 (39%)</td><td>11 (61%)</td><td>0 (0%)</td><td>4 (22%)</td><td>14 (78%)</td><td>0 (0%)</td><td>7 (39%)</td><td>11 (61%)</td><td>3 (2%)</td><td>30 (17%)</td><td>147 (82%)</td></tr><tr><td>GPT-4o</td><td>0 (0%)</td><td>8 (44%)</td><td>10 (56%)</td><td>0 (0%)</td><td>6 (33%)</td><td>12 (67%)</td><td>0 (0%)</td><td>7 (39%)</td><td>11 (61%)</td><td>28 (16%)</td><td>9 (5%)</td><td>143 (79%)</td></tr><tr><td>o1-mini</td><td>0 (0%)</td><td>13 (72%)</td><td>5 (28%)</td><td>0 (0%)</td><td>4 (22%)</td><td>14 (78%)</td><td>2 (11%)</td><td>12 (67%)</td><td>4 (22%)</td><td>15 (8%)</td><td>15 (8%)</td><td>150 (83%)</td></tr><tr><td>o3-mini</td><td>0 (0%)</td><td>3 (17%)</td><td>15 (83%)</td><td>0 (0%)</td><td>1 (6%)</td><td>17 (94%)</td><td>0 (0%)</td><td>2 (11%)</td><td>16 (89%)</td><td>0 (0%)</td><td>0 (0%)</td><td>180 (100%)</td></tr><tr><td rowspan=\"5\">FIB</td><td>Human</td><td>0 (0%)</td><td>5 (83%)</td><td>1 (17%)</td><td>4 (67%)</td><td>0 (0%)</td><td>2 (33%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>10 (28%)</td><td>9 (25%)</td><td>17 (47%)</td></tr><tr><td>GPT-4.5</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>5 (14%)</td><td>31 (86%)</td></tr><tr><td>GPT-4o</td><td>0 (0%)</td><td>2 (33%)</td><td>4 (67%)</td><td>0 (0%)</td><td>1 (17%)</td><td>5 (83%)</td><td>0 (0%)</td><td>1 (17%)</td><td>5 (83%)</td><td>0 (0%)</td><td>0 (0%)</td><td>36 (100%)</td></tr><tr><td>o1-mini</td><td>0 (0%)</td><td>5 (83%)</td><td>1 (17%)</td><td>0 (0%)</td><td>1 (17%)</td><td>5 (83%)</td><td>0 (0%)</td><td>5 (83%)</td><td>1 (17%)</td><td>0 (0%)</td><td>0 (0%)</td><td>36 (100%)</td></tr><tr><td>o3-mini</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>1 (3%)</td><td>35 (97%)</td></tr></table>\n\nsessment of CT skills provided detailed comments, such as concerns about vague terminology, overly obvious item structure, conceptual inconsistencies, and cultural bias, which were often overlooked by LLM judges. These qualitative insights are stored as data and will play an instrumental role in shaping the future STAIR-AIG protocol, particularly in optimizing the prompts used for AIG and in systematizing the rubrics for the LLM-based review.\n\nIt is also worth noting that the human expert raised the issue of the content validity of some AIG items. Specifically, some items were on the borderline of assessing CT or reading comprehension. In such cases, the human expert not only provided a detailed explanation of their reasoning but also directly revised the wording of the items to better align with the intended purpose of the assessment. Such feedback can also be saved as data and used to fine-tune the LLMs, ultimately supporting the development of more valid and reliable AIG-powered assessment content.\n\n# 6 Conclusions & Implications\n\n# 6.1 Conclusions\n\nThis study introduces STAIR-AIG, a structured, human-in-the-loop framework designed to improve the quality and validity of AI-generated assessment items. Using the STAIR-AIG tool, we collected and compared item reviews from a human expert\n\nand four OpenAI LLMs. Our quantitative and qualitative analyses revealed that, while LLM's evaluations demonstrated high consistency, their feedback was generally superficial and overly lenient. Often, LLMs neglected critical issues such as ambiguous terminology, cultural insensitivity, and insufficient cognitive depth. In contrast, the human expert provided more critical and nuanced feedback, effectively identifying subtle yet significant flaws.\n\nThe two core modules of STAIR-AIG significantly support human reviewers in conducting rigorous, systematic evaluations aligned with the test-taker's background and the assessment goals, enhancing review efficiency. Notably, the discrepancies observed between human reviewers and LLM judges underscore the importance of a human-in-the-loop framework and an iterative review process. Ultimately, the data collected through these structured reviews is expected to improve the quality of AIG items and facilitate the development of more robust and refined assessment items.\n\n# 6.2 Implications\n\nAs an example of a human-in-the-loop approach to AIG, this study sets the groundwork for extending STAIR-AIG into a comprehensive, full-cycle framework encompassing AIG, collaborative human-AI review, iterative refinement, pilot testing, psychometric validation, and model retrain\n\n<table><tr><td>Feedback Category</td><td>Review Comments</td></tr><tr><td>Terminology &amp; Language Use</td><td>- &quot;Do not use so many different words for the same meaning.&quot;</td></tr><tr><td rowspan=\"3\">Vague, overly technical, and struc-turally complex, which makes it mis-aligned with the assessment&#x27;s purpose.</td><td>- &quot;(...) is a difficult formulation for not-so-strong readers.&quot;</td></tr><tr><td>- &quot;(...) is unnecessarily vague scientific jargon.&quot;</td></tr><tr><td>- &quot;The term (...) might be too technical for many students and may lead to incorrect interpretations.&quot;</td></tr><tr><td>Item Construction &amp; Clue Issues</td><td>- &quot;When mentioning acronym, use full name, and in all further mentions, use acronym.&quot;</td></tr><tr><td rowspan=\"4\">Wording or structure that makes an-swers too obvious or misleads test-takers.</td><td>- &quot;Change order to avoid misinterpretation.&quot;</td></tr><tr><td>- &quot;Answer appears verbatim in the passage.&quot;</td></tr><tr><td>- &quot;Too simple and easy to see the answer.&quot;</td></tr><tr><td>- &quot;Why use the term (...) whereas in all statements you use the term (...)? Be consistent.&quot;</td></tr><tr><td>Conceptual Accuracy &amp; Fit</td><td>- &quot;I have read some publications about (...) but the definition that is used here does not really fit very well.&quot;</td></tr><tr><td rowspan=\"2\">Inaccurate or inconsistent statements, which make it unsuitable for valid as-sessment.</td><td>- &quot;Biased or misleading conclusion.&quot;</td></tr><tr><td>- &quot;(...) and (...) depends on interpretation.&quot;</td></tr><tr><td>Cultural Sensitivity</td><td>- &quot;The concept of the (...) varies by culture and perspective.&quot;</td></tr><tr><td rowspan=\"3\">Culturally biased, which offers a lim-ited perspective and potentially dis-advantageing test-takers from diverse backgrounds.</td><td>- &quot;(...) might be ideal in some contexts, while (...) may carry a clearer negative connotation.&quot;</td></tr><tr><td>- &quot;(...) portrayed in a one-sided positive light.&quot;</td></tr><tr><td>- &quot;(...) is culturally or ethically biased.&quot;</td></tr></table>\n\nTable 3: Categorization of reviewer feedback and representative comments\n\ning. The human-generated reviews collected in this study would serve as a valuable resource for the first round of LLM refinement. Drawing on this empirical data, future work would focus on optimizing LLM prompting strategies and applying RLHF to improve both the quality and validity of AI-generated items. This process will help establish a more data-driven and feedback-informed basis for optimizing AIG systems.\n\nIn addition, this research contributes to the emerging field of HAIC-based test design and administration, where prior work remains limited. By demonstrating the utility of structured human reviews in guiding both AIG prompting and model fine-tuning, the study highlights a scalable pathway for the application of AI to educational measurement. Similar to how the Item Factory is used for DET, the proposed STAIR-AIG tool is being implemented for MACAT's CT assessment. The number of CT assessment items has rapidly doubled with the STAIR-AIG process, and the tool is being fully implemented to create an item bank of human-authored items alongside AIG for the CT assessment (Shin et al., 2024). This HAIC-driven approach showcases the increasing potential for the scholarly and sustainable use of AI in education.\n\n# 6.3 Limitations\n\nDespite its promise, this study has several limitations. First, the study was confined to an initial review by a human expert and four OpenAI LLMs,\n\nfollowed by a comparative analysis of their ratings. The end-to-end STAIR-AIG workflow process, particularly the integration and refinement of the AIG model through iterative review, has yet to be realized. Future work will involve more comprehensive testing of the entire STAIR-AIG pipeline.\n\nSecond, although the STAIR-AIG framework is designed to support multiple rounds of review, the current study only included one round of review by one expert reviewer. Consequently, the results may not reflect the full potential of iterative refinement, thereby limiting the framework's generalizability. Future research should explore the point at which discrepancies between LLMs and expert ratings converge. This will help us understand how LLMs behave when judging higher-order thinking skills, as well as inform the optimal stage for finalizing items for operational use and determining the maximum number of review cycles.\n\nThird, while the item-review module was helpful to human reviewers, it could only analyze superficial metrics, such as TTR, ASL, and conventional readability indices. In the present study, grade-level suitability was judged solely based on these readability measures. Moving forward, the review module will integrate additional linguistic indicators that capture semantic dimensions in order to provide reviewers with more comprehensive support. Similarly, we did not directly measure whether the module substantially reduced the time reviewers\n\nneeded to complete their tasks. Therefore, future research would evaluate the practical effectiveness of STAIR-AIG by determining the degree to which it aids item review and the amount of time it saves compared to standard, tool-free review procedures.\n\nLastly, LLMs were given instructions that closely mirrored those provided to the human reviewer, yet their evaluations consistently exhibited leniency. To achieve a more harmonious integration of human and LLM ratings, future work should consider various prompt engineering techniques to calibrate LLM judgments more closely with the human evaluation standard in the CT domain. Furthermore, optimizing prompts accompanied by the psychometric results of the test data is expected to improve AIG models' ability to accurately generate and evaluate item difficulty and distractor plausibility. This would, in turn, strengthen the efficiency and validity of human-AI collaboration in test development.\n\n# Acknowledgments\n\nThis research was conducted in collaboration with the MACAT International Ltd., who provided support. We also sincerely appreciate the insightful comments and thoughtful suggestions on potential future directions for this research from the anonymous reviewers.\n\n# References\n\nYigal Attali, Andrew Runge, Geoffrey T. LaFlair, Kevin Yancey, Sarah Goodwin, Yena Park, and Alina A. von Davier. 2022. The interactive reading task: Transformer-based automatic item generation. Frontiers in Artificial Intelligence, 5.  \nIsaac I. Bejar. 1996. Generative response modeling: Leveraging the computer as a test delivery medium. ETS Research Report RR-96-13, Educational Testing Service, Princeton, NJ.  \nIsaac I. Bejar. 2002. Generative testing: From conception to implementation. In Sidney H. Irvine and Patrick C. Kyllonen, editors, Item Generation for Test Development, pages 199-218. Lawrence Erlbaum Associates, Mahwah, NJ.  \nUmmugul Bezirhan and Matthias von Davier. 2023. Automated reading passage generation with openai's large language model. Computers and Education: Artificial Intelligence, 5:100161.  \nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,\n\nGretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. Preprint, arXiv:2005.14165.  \nSumie Chan, Noble Lo, and Alan Wong. 2025. Leveraging generative ai for enhancing university-level english writing: comparative insights on automated feedback and student engagement. *Cogent Education*, 12(1):2440182.  \nPaul F. Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. Deep reinforcement learning from human preferences. In Advances in Neural Information Processing Systems, pages 4299-4307.  \nKevyn Collins-Thompson. 2014. Computational assessment of text readability: A survey of current and future research. ITL - International Journal of Applied Linguistics, 165(2):97-135.  \nInternational Test Commission and Association of Test Publishers. 2022. Guidelines for technology-based assessment. https://www.intestcom.org/page/28 and https://www.testpublishers.org/white-papers.ISBN 979-8-88862-517-0.  \nAlexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettle-moyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440-8451, Online. Association for Computational Linguistics.  \nGeorge Fragiadakis, Christos Diou, George Kousiouris, and Mara Nikolaidou. 2025. Evaluating human-ai collaboration: A review and methodological framework. Preprint, arXiv:2407.19098.  \nMark J Gierl and Hollis Lai. 2013. Instructional topics in educational measurement (ITEMS) module: Using automated processes to generate test items. Educational Measurement: Issues and Practice, 32(3):36-50.  \nJiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, Saizhuo Wang, Kun Zhang, Yuanzhuo Wang, Wen Gao, Lionel Ni, and Jian Guo. 2025. A survey on llm-as-a-judge. Preprint, arXiv:2411.15594.  \nMarcelo Guerra Hahn, Silvia Margarita Baldiris Navarro, Luis De La Fuente Valentín, and Daniel Burgos. 2021. A systematic review of the effects of automatic scoring and automatic feedback in educational settings. IEEE Access, 9:108190-108198.\n\nThomas M. Haladyna and Michael C. Rodriguez. 2013. Developing and Validating Test Items. Routledge, London, UK.  \nJiangang Hao, Alina A. von Davier, Victoria Yaneva, Susan Lottridge, Matthias von Davier, and Deborah J. Harris. 2024. Transforming assessment: The impacts and implications of large language models and generative ai. Educational Measurement: Issues and Practice. All authors contributed equally.  \nJanet Huang. 2019. Human-ai co-learning for data-driven ai. https://speakerdeck.com/janetyc/human-ai-co-learning-for-data-driven-ai. Accessed: 2025-05-03.  \nJ. Peter Kincaid, Richard P. Fishburne, Robert L. Rogers, and Brad S. Chissom. 1975. Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. Research Branch Report 8-75, Naval Technical Training, U.S. Naval Air Station, Millington, TN. Archive from the original on December 10, 2020.  \nGhader Kurdi, Jared Leo, Biban Parsia, Uli Sattler, and Salam Al-Emari. 2020. A systematic review of automatic question generation for educational purposes. International Journal of Artificial Intelligence in Education, 30:121-204.  \nEhsan Latif and Xiaoming Zhai. 2024. Fine-tuning chatgpt for automatic scoring. Computers and Education: Artificial Intelligence, 6:100210.  \nGyeong-Geon Lee, Ehsan Latif, Xuansheng Wu, Ning-hao Liu, and Xiaoming Zhai. 2024. Applying large language models and chain-of-thought for automatic scoring. Computers and Education: Artificial Intelligence, 6:100213.  \nXiaoqiang Lin, Zhongxiang Dai, Arun Verma, SeeKiong Ng, Patrick Jaillet, and Bryan Kian Hsiang Low. 2024. Prompt optimization with human feedback. Preprint, arXiv:2405.17346.  \nOu Lydia Liu, Liyang Mao, Lois Frankel, and Jun Xu. 2016. Assessing critical thinking in higher education: The heightenTM approach and preliminary validity evidence. Assessment and Evaluation in Higher Education, 41(5):677-694.  \nS. A. Luchini, N. T. Maliakkal, P. V. DiStefano, A. Laverghetta Jr., J. D. Patterson, R. E. Beaty, and R. Reiter-Palmon. 2025. Automated scoring of creative problem solving with large language models: A comparison of originality and quality ratings. *Psychology of Aesthetics*, Creativity, and the Arts. Advance online publication.  \nMACAT. 2025. Critical thinking assessments. https://www.macat.com/critical-thinking. Retrieved April 16, 2025.\n\nHyo Jeong. Shin, Seewoo. Li, Salah. Khalil, and Alina A. von Davier. 2024. Designing for adaptive testing using automatically generated items. In Proceedings of the Annual Meeting of the International Association for Computerized Adaptive Testing (IACAT), Seoul, Korea.  \nHyo Jeong. Shin, Seewoo. Li, Jihoon. Ryoo, Alina A. von Davier, T. Lubart, and Salah. Khalil. 2025. The nature and measure of critical thinking: The pacier framework and assessment. Manuscript submitted for publication.  \nMark K. Singley and Randy E. Bennett. 2002. Item generation and beyond: Applications of schema theory to mathematics assessment. In Sidney H. Irvine and Patrick C. Kyllonen, editors, Item Generation for Test Development, pages 361-384. Lawrence Erlbaum Associates, Inc., Mahwah, NJ.  \nVenkat Srinivasan. 2022. AI & learning: A preferred future. Computers and Education: Artificial Intelligence, 3:100062.  \nAlina A. von Davier and Jill Burstein. 2024. Ai in the assessment ecosystem: A human-centered ai perspective. In Peter Ilic, Ian Casebourne, and Rupert Wegerif, editors, Artificial Intelligence in Education: The Intersection of Technology and Pedagogy, volume 261 of Intelligent Systems Reference Library. Springer, Cham.  \nAlina A. von Davier, Andrew Runge, Yena Park, Yigal Attali, Jacqueline Church, and Geoff LaFlair. 2024. The item factory: Intelligent automation in support of test development at scale. In Machine Learning, Natural Language Processing, and Psychometrics, pages 1-25. Information Age Publishing, Charlotte, NC.  \nShan Wang, Fang Wang, Zhen Zhu, Jingxuan Wang, Tam Tran, and Zhao Du. 2024. Artificial intelligence in education: A systematic literature review. Expert Systems with Applications, 252(Part A):124167.  \nEdward W Wolfe. 2004. Identifying rater effects using latent trait models. Psychology Science, 46:35-51.  \nWorld Economic Forum. 2015. New vision for education: Unlocking the potential of technology. https://wiqdtents.weforum.org/nve-2015/ chapter1.html. Accessed April 14, 2025.  \nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. Preprint, arXiv:2306.05685.  \nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2020. Fine-tuning language models from human preferences. Preprint, arXiv:1909.08593.\n\n# A Appendix\n\n# A.1 Prompt for Item Review by LLMs\n\nThe following is an excerpt of the prompt used to instruct the LLMs in reviewing the quality of CT items. The prompt defines the evaluation criteria, output structure, and PACIER framework to assess item quality.\n\n# Listing 1: System prompt\n\n```txt\nYou are a Critical Thinking Assessment's **Item Review Expert** with extensive experience in educational evaluation and test design, specializing in critical thinking.\n```\n\n```txt\nYour role is to systematically evaluate the quality of test items based on established frameworks, ensuring fairness, reliability, and alignment with learning objectives.\n```\n\n# Listing 2: User prompt: Review Context\n\n## Review Context\n\n- The exam items are designed for Grade 7~8 learners.  \n- Each item consists of a Passage, a Question, and 6 Answer Choices (each with an Explanation).  \n- Your task is to rigorously evaluate the quality of each component and provide structured feedback.\n\nPACIER Framework (Cognitive Process Dimensions)\n\nThe PACIER framework categorizes cognitive processes into six distinct levels:\n\n- \\*\\*Problem-Solving (P)  $^{**}$  ...  \n- **Creative Thinking (C):** (...)  \n- \\*\\*Interpretation (I):\\*\\* (...  \n- \\*\\*Evaluation (E):\\*\\* (. . .)  \n- \\*\\*Reasoning (R):\\*\\* (. . .\n\nEach test item should align with at least one PACIER category, ensuring it assesses critical thinking skills effectively.\n\n# Listing 3: User prompt: Review Methods\n\nEvaluation Methodology\n\n1. Assessment Criteria\n\n- Passage: Relevance, clarity, and cognitive demand.  \n- Question: Alignment with passage, clarity, and ability to assess critical thinking.  \n- Answer Choices: Plausibility of distractors, clarity, and correctness of explanations.\n\n2. Comparative Judgment\n\n- Evaluate each component relative to high-quality reference items to ensure consistency.\n\n3. Rating Scale\n\n- Dissatisfied: Fundamentally flawed or inappropriate for assessment and thus discarded without revision suggestions.  \n- Neutral: Requires revisions to improve clarity, relevance, or difficulty. You should provide detailed feedback and specific revision recommendations.  \n- Satisfied: Suitable for immediate use or required minimal edits. You could directly accept these items or suggest minor enhancements.\n\n4. Actionable Feedback\n\n- Provide concise but specific feedback justifying each rating.\n\n5. Final Output Format (Plain Key-Value Pairs, CSV-Ready)\n\nOutput only concise final results in plain key-value pairs (one per line) using the following CSV column structure:\n\nItem Number, Type, Topic, Subtopic, PACIER, Difficulty,\n\nOverall Quality Score, Overall Comment,\n\nPassage Comment, Passage Rating, Passage Revision,\n\nQuestion Comment, Question Rating, Question Revision,\n\n```txt\nItem_1_Choice_1 Review, Item_1_Choice_1 Rating, Item_1_Choice_1 Revision Suggestion, ... (repeat for Choices 2 through 10)\n```\n\nAdditional Guidelines\n\n- Ensure alignment with cognitive and linguistic proficiency standards.  \n- **Maintain consistency** across evaluations to avoid bias.  \n- Do not include markdown, bullet points, or additional explanations.  \n- Return only key-value pairs as output.",
    "arxiv_id": "2005.14165",
    "error_message": null,
    "embedding": [
      1,
      3.78125,
      0.34375,
      -1.734375,
      -1.421875,
      3.375,
      1.921875,
      -0.0361328125,
      1.78125,
      0.62109375,
      -1.125,
      2.296875,
      1.59375,
      1.0703125,
      -2.546875,
      1.2734375,
      1.9140625,
      0.2197265625,
      1.84375,
      -6.84375,
      0.37109375,
      0.296875,
      -1.3046875,
      -6.03125,
      6.09375,
      -3.046875,
      3.375,
      3.578125,
      2.40625,
      0.06005859375,
      6.0625,
      -6.0625,
      -0.2451171875,
      2.546875,
      -3.03125,
      2.078125,
      -2.75,
      0.259765625,
      2.65625,
      1.5,
      -5.03125,
      2.296875,
      2.71875,
      2.015625,
      -2.703125,
      1.5,
      2.828125,
      -0.6328125,
      -5.9375,
      -1.109375,
      -3.453125,
      -5.34375,
      5.15625,
      -0.1689453125,
      2.671875,
      -5.03125,
      -7.125,
      4.625,
      -0.99609375,
      -2.453125,
      2.09375,
      -1.5859375,
      5.03125,
      0.33984375,
      2.96875,
      3.921875,
      1.640625,
      -0.9375,
      -3.4375,
      -1.328125,
      -0.78125,
      3.03125,
      7.75,
      -4.1875,
      6.8125,
      6.6875,
      2.1875,
      1.4296875,
      -0.7109375,
      4.28125,
      -5.71875,
      2.46875,
      2.46875,
      -0.76171875,
      6.375,
      3.15625,
      0.453125,
      -1.8671875,
      -1.765625,
      3.5625,
      -2.75,
      3.171875,
      -5.09375,
      -1.0859375,
      3.328125,
      7.09375,
      -1.8125,
      -3.796875,
      -7.90625,
      1.6171875,
      -1.1171875,
      -0.169921875,
      -0.2470703125,
      -5.125,
      -2.359375,
      -4.5,
      -5.34375,
      -7.875,
      -1.4453125,
      -1.875,
      0.078125,
      2.765625,
      2.765625,
      -0.8515625,
      3.375,
      -2.640625,
      6.90625,
      -4.59375,
      -2.8125,
      -1.265625,
      2.75,
      -0.72265625,
      -2.21875,
      -0.0302734375,
      5.65625,
      1.796875,
      -6.25,
      1.171875,
      6.15625,
      0.64453125,
      4,
      2.546875,
      5.34375,
      0.85546875,
      -7.1875,
      -2.3125,
      -5.21875,
      2.765625,
      3.28125,
      4.78125,
      -4.75,
      -1.296875,
      -1.703125,
      -5.65625,
      3.09375,
      1.140625,
      -6.71875,
      0.2890625,
      1.1953125,
      -1.75,
      1.59375,
      0.9609375,
      0.76953125,
      7.1875,
      -1.8359375,
      -4.375,
      5.65625,
      2.15625,
      0.515625,
      0.5390625,
      0.921875,
      1.3046875,
      -0.2177734375,
      -1.015625,
      -2.625,
      -1.0078125,
      -5.40625,
      1.4609375,
      0.63671875,
      -2.625,
      2.46875,
      15.25,
      2.828125,
      -2.921875,
      3.09375,
      2.96875,
      -3.328125,
      9.125,
      2.40625,
      1.5390625,
      -0.341796875,
      1.8671875,
      -1.984375,
      4.65625,
      -0.291015625,
      -1.1328125,
      1.9453125,
      -4.46875,
      0.53125,
      -3.984375,
      1.5703125,
      2.703125,
      7.5625,
      1.1875,
      -6.15625,
      3.46875,
      2.515625,
      -0.72265625,
      -0.63671875,
      2.921875,
      0.99609375,
      -8.5625,
      1.484375,
      -0.46484375,
      -3.34375,
      -1.8828125,
      4.25,
      -1.3828125,
      -0.134765625,
      -1.796875,
      2.265625,
      2.859375,
      0.94921875,
      2.96875,
      5.40625,
      3.671875,
      2.578125,
      -1.25,
      3.640625,
      2.953125,
      5.59375,
      1.8515625,
      1.03125,
      0.66015625,
      -0.1875,
      1.1015625,
      3.578125,
      5.0625,
      0.1416015625,
      6.78125,
      -1.875,
      2.546875,
      5.0625,
      -0.6484375,
      -1.6015625,
      -1.28125,
      -5.4375,
      2.84375,
      0.439453125,
      0.796875,
      -2.421875,
      -3.8125,
      -1.8671875,
      0.515625,
      2.078125,
      -3.03125,
      0.8828125,
      -3.09375,
      -3.375,
      -4.8125,
      2.328125,
      2.375,
      -5.4375,
      -3.078125,
      4.125,
      4.1875,
      -0.99609375,
      -3.359375,
      -0.79296875,
      -2.390625,
      5.4375,
      -1.5,
      -5.90625,
      1.1015625,
      1.4765625,
      -5.65625,
      1.5,
      -1.546875,
      3.828125,
      0.6640625,
      1.296875,
      0.328125,
      -1.5,
      0.01397705078125,
      -0.67578125,
      5.15625,
      2.265625,
      -6.1875,
      -0.84765625,
      -3.75,
      -3.125,
      -7.96875,
      5.8125,
      -3.953125,
      5.03125,
      -1.4765625,
      -0.322265625,
      5.96875,
      -5.28125,
      9.4375,
      4.4375,
      2.546875,
      -0.88671875,
      0.171875,
      -6.875,
      -1.5390625,
      -1.9375,
      -0.55078125,
      -6.84375,
      0.66796875,
      6.375,
      -1.515625,
      -1.390625,
      -0.2890625,
      -3.140625,
      3.265625,
      0.60546875,
      -2.375,
      2.171875,
      1.921875,
      -3.15625,
      -1.7421875,
      7.5,
      -1.59375,
      1.6875,
      -2.984375,
      -2.84375,
      3.53125,
      1.3203125,
      -3.953125,
      -4.5,
      -3.015625,
      2.859375,
      -3.84375,
      -0.88671875,
      -2.34375,
      -0.138671875,
      0.75,
      5.125,
      -0.12255859375,
      1.5859375,
      0.4296875,
      -5.4375,
      -6.875,
      7.28125,
      -2.65625,
      2.828125,
      -0.1640625,
      -1.96875,
      4.40625,
      -0.400390625,
      -3.703125,
      0.97265625,
      -4.25,
      -2.359375,
      0.6640625,
      4.9375,
      -4.5625,
      -1.5234375,
      -6.3125,
      2.65625,
      1.7421875,
      -1.078125,
      2.171875,
      5.5625,
      -1.515625,
      0.16015625,
      -0.1865234375,
      2.9375,
      0.73828125,
      3.40625,
      -1.9453125,
      6.53125,
      0.40234375,
      -0.5625,
      -4.8125,
      0.1484375,
      1.171875,
      0.359375,
      0.373046875,
      -0.82421875,
      -4.78125,
      -0.88671875,
      1.84375,
      1.7890625,
      -0.65234375,
      1.5,
      -3.84375,
      -3.6875,
      1.3125,
      -3.953125,
      0.09912109375,
      -2.65625,
      -1.265625,
      3.265625,
      2.203125,
      0.171875,
      4.96875,
      0.34765625,
      -2.671875,
      -2.234375,
      -0.78125,
      -3.5,
      1.46875,
      0.37890625,
      1.515625,
      -0.265625,
      1.734375,
      -0.027587890625,
      -1.7890625,
      3.859375,
      1.3515625,
      -0.1708984375,
      0.2578125,
      -4.25,
      1.6484375,
      -1.546875,
      -4.75,
      3.015625,
      -0.453125,
      -1.9609375,
      1.7109375,
      -0.6875,
      -2.359375,
      0.75,
      2.6875,
      -0.98828125,
      1.3984375,
      -6.21875,
      -2.015625,
      -3.6875,
      0.287109375,
      1.8828125,
      -3,
      -0.5078125,
      -0.77734375,
      2,
      5.3125,
      0.37890625,
      1.875,
      1.9375,
      1.4296875,
      -4.78125,
      2.1875,
      -4.75,
      -5.03125,
      3.40625,
      -3.375,
      -3.890625,
      0.77734375,
      2.5,
      1.1953125,
      2.421875,
      2.640625,
      -5.125,
      -0.56640625,
      1.546875,
      4.46875,
      -3.875,
      -1.9453125,
      1.734375,
      1.859375,
      -0.7265625,
      1.8984375,
      1.375,
      1.1640625,
      -3.328125,
      5.1875,
      1.4921875,
      -2.15625,
      1.0078125,
      -0.8984375,
      1.625,
      -1.4765625,
      -0.61328125,
      -0.486328125,
      -3.296875,
      1.765625,
      3.640625,
      -8.125,
      -11.1875,
      2.59375,
      0.51171875,
      1.765625,
      -1.4375,
      2.484375,
      2.15625,
      -0.2138671875,
      -6.78125,
      -6.1875,
      -1.8828125,
      -1.2578125,
      2.4375,
      1.625,
      -0.353515625,
      -1.6171875,
      -3.984375,
      4.34375,
      1.40625,
      4.0625,
      0.3671875,
      -1.8203125,
      1.359375,
      -5.40625,
      3.640625,
      2.21875,
      9,
      -5.96875,
      0.59375,
      1.8984375,
      -8.3125,
      -1.7578125,
      -4.71875,
      -2.71875,
      -1.15625,
      0.609375,
      3.78125,
      -2.359375,
      -3.03125,
      -0.12890625,
      2.390625,
      -1.84375,
      -2.46875,
      3.78125,
      -4.46875,
      -3.53125,
      3.34375,
      0.07421875,
      0.4453125,
      -0.58984375,
      -4.6875,
      2.25,
      -2.1875,
      3.203125,
      -0.9140625,
      -1.5625,
      -1.9296875,
      -2.453125,
      3.984375,
      2.890625,
      3.21875,
      1.6015625,
      -2.703125,
      -4.625,
      -3.09375,
      -0.890625,
      1.6328125,
      -2.109375,
      2.15625,
      -2.90625,
      4.8125,
      5.28125,
      -1.7734375,
      -1.203125,
      -0.859375,
      3.640625,
      -4.28125,
      0.03515625,
      0.271484375,
      3.5625,
      2.578125,
      1.6015625,
      -1.09375,
      -1.1484375,
      -0.62109375,
      -2.296875,
      -3.671875,
      -0.390625,
      3,
      -0.1572265625,
      -0.006591796875,
      0.197265625,
      -0.1513671875,
      0.01904296875,
      1.0546875,
      -1.9453125,
      0.490234375,
      3.578125,
      1.6640625,
      -1.875,
      0.59765625,
      4.84375,
      -2.109375,
      1.1328125,
      1.9921875,
      1.8046875,
      -7.25,
      -6.15625,
      -0.87890625,
      1.7421875,
      6.34375,
      -3.40625,
      4.96875,
      -1.234375,
      3.109375,
      -0.80078125,
      0.373046875,
      -14.9375,
      1.8203125,
      -1.0078125,
      -3.53125,
      -0.78515625,
      -1.7890625,
      3.59375,
      -1.265625,
      1.8203125,
      -0.8828125,
      -1.078125,
      1.1953125,
      4.875,
      -0.8828125,
      -1.1171875,
      6.25,
      2.890625,
      -1.390625,
      3.328125,
      -0.83984375,
      -3.078125,
      -0.8359375,
      -2.71875,
      0.53125,
      2.21875,
      6.1875,
      -0.03515625,
      -0.6796875,
      0.98828125,
      -2.484375,
      -4.0625,
      0.88671875,
      4.59375,
      -0.478515625,
      3.4375,
      -2.40625,
      3.015625,
      -5.09375,
      2.015625,
      0.9765625,
      -1.8671875,
      2.609375,
      1.6796875,
      -1.640625,
      0.004730224609375,
      -2.609375,
      -1.703125,
      3.0625,
      2.984375,
      -6.75,
      0.70703125,
      -2.203125,
      0.0155029296875,
      1.53125,
      -1.734375,
      0.8203125,
      -3.34375,
      1.796875,
      1.953125,
      -5.25,
      7.625,
      -1.0625,
      -3.828125,
      -0.267578125,
      0.6328125,
      0.06396484375,
      -2.234375,
      3.421875,
      3.765625,
      -2.546875,
      -0.92578125,
      0.23046875,
      -0.625,
      -4.59375,
      1.0859375,
      -1.8203125,
      -3.21875,
      5.5,
      -1.6171875,
      -2.4375,
      -1.125,
      -3.46875,
      1.890625,
      2.890625,
      1.34375,
      1.734375,
      2.203125,
      2.5625,
      -1.125,
      5.3125,
      -4.46875,
      -5.375,
      -0.859375,
      -3.59375,
      -3.109375,
      -0.0272216796875,
      -1.6953125,
      1.4375,
      -0.212890625,
      -1.1484375,
      -3.375,
      -7.53125,
      -1.109375,
      1.0546875,
      1.484375,
      1.765625,
      -1.8515625,
      2.5,
      -2.75,
      -2.78125,
      -2.515625,
      0.162109375,
      0.953125,
      -0.0238037109375,
      -0.28515625,
      -7.0625,
      -1.1015625,
      5.625,
      5,
      -5.21875,
      3.3125,
      1.0078125,
      -2.375,
      -1.71875,
      1.3984375,
      -3.65625,
      -1.3671875,
      1.8984375,
      -2.328125,
      -2.421875,
      -4.15625,
      2.265625,
      -4.21875,
      5.59375,
      0.1435546875,
      -1.53125,
      -1.7890625,
      -6.09375,
      -3.125,
      0.1943359375,
      -3.953125,
      4.15625,
      0.68359375,
      -3.328125,
      -1.125,
      4.46875,
      -0.458984375,
      0.63671875,
      -0.08251953125,
      -0.765625,
      4,
      -0.40625,
      3.71875,
      -2.890625,
      -3.359375,
      -0.6171875,
      0.921875,
      -0.031005859375,
      2.515625,
      -1.2890625,
      1,
      5.25,
      0.2265625,
      -5.15625,
      -1.2265625,
      2.828125,
      -1.59375,
      0.0191650390625,
      -1.3359375,
      1.8203125,
      -0.1484375,
      1.4921875,
      1.2734375,
      -3.15625,
      -0.734375,
      1.53125,
      3.1875,
      -0.35546875,
      -0.86328125,
      1.25,
      -0.039306640625,
      5.125,
      -5.03125,
      -6.8125,
      2.4375,
      3.625,
      -1.921875,
      0.259765625,
      4.125,
      -1.2890625,
      -0.65625,
      -1.046875,
      1.3515625,
      1.265625,
      2.515625,
      1.671875,
      1.609375,
      4.40625,
      2.984375,
      -0.81640625,
      0.384765625,
      -0.13671875,
      -3.4375,
      -0.8203125,
      -0.671875,
      -1.3359375,
      5.0625,
      -1.34375,
      -3.25,
      -2.109375,
      1.0234375,
      1.1953125,
      5.5,
      7.5,
      0.1337890625,
      3.03125,
      1.609375,
      4.0625,
      -0.2275390625,
      7.8125,
      4.65625,
      11.4375,
      -0.69921875,
      -2.921875,
      4.125,
      -2.15625,
      0.326171875,
      2.125,
      -9.375,
      -1.671875,
      -0.515625,
      1.203125,
      -3.421875,
      1.53125,
      -6.09375,
      -0.2265625,
      4.84375,
      -0.1611328125,
      3.109375,
      3.84375,
      5.1875,
      2.609375,
      -1.890625,
      -3.421875,
      -3.796875,
      -1.5625,
      -0.0732421875,
      0.078125,
      -3.40625,
      1.8984375,
      0.11328125,
      2.125,
      0.25390625,
      -3.015625,
      -2.78125,
      7.96875,
      -0.453125,
      -0.46875,
      1.65625,
      1.078125,
      1.4765625,
      3.984375,
      0.78515625,
      -5,
      0.037841796875,
      6.78125,
      4.65625,
      -0.39453125,
      2,
      -0.55859375,
      -0.1591796875,
      -0.396484375,
      -3.8125,
      1.8671875,
      -0.3515625,
      -4.3125,
      -0.84765625,
      1.5078125,
      -0.58203125,
      -3.40625,
      4.59375,
      1.484375,
      -3.28125,
      2.109375,
      2.671875,
      0.875,
      2.25,
      2.21875,
      7.03125,
      0.58203125,
      -0.94140625,
      -3.609375,
      -3.234375,
      -2.671875,
      -1.875,
      1.796875,
      4.3125,
      2.359375,
      -2.109375,
      2.390625,
      -6.53125,
      -0.65625,
      -3.53125,
      2.453125,
      0.98046875,
      -3.28125,
      0.87890625,
      -1.5703125,
      -9.875,
      -7.1875,
      -1.921875,
      -2.84375,
      -0.5078125,
      -6.53125,
      -0.640625,
      2.640625,
      -5.8125,
      1.3046875,
      -1.25,
      -2.25,
      3.640625,
      -1.5078125,
      2.09375,
      -3.5625,
      2,
      1.6015625,
      0.294921875,
      3.875,
      3.3125,
      1.1796875,
      3.921875,
      -1.1953125,
      1.328125,
      -4.46875,
      4.90625,
      -0.5859375,
      6,
      2.703125,
      -0.2578125,
      -4.0625,
      4.34375,
      -2.359375,
      2.15625,
      -3.21875,
      -1.1640625,
      -1.3515625,
      -1.953125,
      1.1640625,
      0.44140625,
      3.328125,
      -4.4375,
      -1.8203125,
      0.74609375,
      -4.75,
      -0.1435546875,
      4.28125,
      -0.01092529296875,
      4.375,
      -2.3125,
      -0.84375,
      2.625,
      -2.71875,
      7.03125,
      0.061767578125,
      1.3984375,
      -5.625,
      0.5703125,
      -0.84375,
      2.1875,
      0.67578125,
      -0.96484375,
      0.93359375,
      -1.0703125,
      2.28125,
      5.3125,
      -0.0201416015625,
      2.734375,
      1.6953125,
      2.515625,
      -0.9921875,
      -0.400390625,
      0.8203125,
      -3.359375,
      4.875,
      1.203125,
      0.353515625,
      1.03125,
      0.921875,
      -3.921875,
      -0.71484375,
      3.234375,
      -4.40625,
      -3.421875,
      -2.296875,
      -4.28125,
      2.875,
      0.1357421875,
      -0.71484375,
      4.03125,
      3.4375,
      2.5,
      2.46875,
      -0.6484375,
      4.15625,
      -0.79296875,
      0.7734375,
      7.3125,
      -1.5703125,
      0.0247802734375,
      5.03125,
      1.53125,
      5.4375,
      1.7734375,
      -1.3671875,
      -2.421875,
      0.859375,
      3.578125,
      -1.9609375,
      3.375,
      8,
      -2.984375,
      2.765625,
      -0.13671875,
      -1.078125,
      -0.2412109375,
      -0.578125,
      1.4140625,
      5.0625,
      5.4375,
      -1.203125,
      -3.53125,
      -2.46875,
      1.0625,
      0.326171875,
      -0.7578125,
      -1.640625,
      0.64453125,
      -0.25,
      1.0703125,
      -0.33984375,
      -2.390625,
      2.15625,
      -3.84375,
      -0.8203125,
      3.28125,
      0.046142578125,
      0.30078125,
      -0.57421875,
      0.765625,
      -2.3125,
      2.984375,
      2.328125,
      -0.88671875,
      0.86328125,
      2.46875,
      -1.1015625,
      3.703125,
      1.53125,
      -0.51953125,
      1.9765625,
      -2.078125,
      -2.65625,
      2.28125,
      -1.0390625,
      0.00335693359375,
      -1.703125,
      -0.3515625,
      4.15625,
      4.4375,
      -1.3125,
      4.28125,
      -2.375,
      -2.03125,
      2.109375,
      -3.640625,
      -4.4375,
      0.08740234375,
      -0.5390625,
      -1.8046875,
      0.103515625,
      1.3203125,
      -2.4375,
      3.375,
      -5.75,
      3.9375,
      -4.40625,
      6.3125,
      0.45703125,
      -2.359375,
      -0.5859375,
      -2.609375,
      2.296875,
      -1.015625,
      1.5859375,
      1.9609375,
      0.1064453125,
      1.734375,
      -1.9375,
      0.224609375,
      -1.90625,
      -0.08740234375,
      4.0625,
      -3.734375,
      3.0625,
      2.046875,
      2.625,
      -4.4375,
      -3.203125,
      0.375,
      -1.5,
      0.65234375,
      1.6171875,
      0.244140625,
      -0.98046875,
      3.328125,
      -4.1875,
      3.109375,
      -2.25,
      -0.90625,
      1.4609375,
      -1.859375,
      5.15625,
      0.271484375,
      -2.140625,
      1.46875,
      -0.51953125,
      -5.75,
      -1.703125,
      -1.7265625,
      3.953125,
      -2.9375,
      -1.84375,
      1.7109375,
      1.7421875,
      -2.15625,
      1.9765625,
      3.28125,
      1.9375,
      1.8046875,
      -1.546875,
      1.234375,
      0.73828125,
      1.921875,
      -4.28125,
      -6,
      -2.734375,
      2.109375,
      0.5390625,
      -1.6953125,
      0.341796875,
      -1.09375,
      0.71484375,
      0.85546875,
      -0.90625,
      -0.2216796875,
      -0.95703125,
      3.09375,
      -0.51171875,
      -3.59375,
      1.828125,
      1.71875,
      1.9609375,
      -2.90625,
      0.0947265625,
      -2.453125,
      0.265625,
      0.9921875,
      1.59375,
      -0.2138671875,
      -3.578125,
      0.37890625,
      -0.09814453125,
      -3.78125,
      -2.203125,
      4.21875,
      1.34375,
      5.15625,
      3.625,
      -0.421875,
      -1.2734375,
      -1.1953125,
      0.154296875,
      2.625,
      1.3828125,
      -4.28125,
      2.734375,
      -1.0859375,
      6,
      -1.828125,
      -3.453125,
      -5.4375,
      1.3203125,
      5.5625,
      0.365234375,
      -2.5,
      1.3125,
      0.2294921875,
      3.0625,
      -0.349609375,
      3,
      -2.4375,
      -3.171875,
      -0.71484375,
      3.109375,
      2.03125,
      -5.78125,
      1.8515625,
      3.328125,
      -1.6640625,
      2.03125,
      3.21875,
      5.53125,
      -3.34375,
      -0.5234375,
      -0.341796875,
      -4.90625,
      -2.296875,
      2.09375,
      1.1640625,
      1.015625,
      -0.10546875,
      -3.78125,
      -0.263671875,
      -2.140625,
      0.1484375,
      6.9375,
      -2.421875,
      3.046875,
      -3.421875,
      3.71875,
      2.546875,
      -2.140625,
      -1.84375,
      2.78125,
      1.9296875,
      -0.41015625,
      0.06689453125,
      -3.390625,
      2.609375,
      -0.404296875,
      -7.4375,
      1.6875,
      1.5625,
      -0.28125,
      -0.208984375,
      -1.6328125,
      -0.294921875,
      1.0078125,
      -3.53125,
      -0.34375,
      -2.859375,
      3.171875,
      3.65625,
      0.111328125,
      -1.796875,
      3.390625,
      -1.6875,
      -0.11962890625,
      -0.58203125,
      3.28125,
      -1.8671875,
      2.921875,
      0.7734375,
      3.46875,
      -4.65625,
      -3.46875,
      -3.265625,
      -1.765625,
      -2.609375,
      1.796875,
      0.302734375,
      -0.83203125,
      3.984375,
      1.125,
      -2.625,
      0.06982421875,
      -2.4375,
      1.9765625,
      -0.86328125,
      1.6640625,
      -3.53125,
      3.859375,
      -4.25,
      1.234375,
      2.171875,
      -1.984375,
      -3.15625,
      1.6171875,
      -2.359375,
      2.8125,
      3.796875,
      -0.7109375,
      -4.5,
      2.28125,
      -3.421875,
      -6.125,
      -5.75,
      3.40625,
      -1.7109375,
      -3.421875,
      -0.90625,
      -3.15625,
      1.4921875,
      -1.5625,
      -2.046875,
      -1.2421875,
      -1.3828125,
      0.2353515625,
      2.390625,
      4.09375,
      -2.140625,
      -2.65625,
      -1.65625,
      5.28125,
      1.234375,
      -1.078125,
      3.15625,
      0.62890625,
      0.57421875,
      -4.40625,
      3.84375,
      1.5390625,
      -1.4296875,
      4.40625,
      7.78125,
      -5.15625,
      -0.421875,
      4.84375,
      2.9375,
      -2.171875,
      -0.83203125,
      -2.0625,
      5.21875,
      -2.46875,
      2.6875,
      -2.859375,
      -0.0020751953125,
      1.828125,
      -1.609375,
      5.0625,
      2,
      1.96875,
      -1.078125,
      -2.375,
      3.109375,
      3.421875,
      4.78125,
      -1.2421875,
      4.5625,
      3,
      -1.1953125,
      3.046875,
      -0.150390625,
      -4.3125,
      -2.875,
      2.34375,
      -7.4375,
      0.96875,
      -7.03125,
      -0.83984375,
      -3.40625,
      -3.3125,
      -1.0234375,
      0.64453125,
      2.1875,
      1.5078125,
      -3.03125,
      0.318359375,
      -1.7578125,
      -0.8203125,
      0.8359375,
      -0.6328125,
      -3.40625,
      2.75,
      0.578125,
      -0.1708984375,
      4,
      2,
      -0.365234375,
      -1.15625,
      2.1875,
      -1.140625,
      0.283203125,
      -2.5625,
      2.546875,
      1.1875,
      -0.1796875,
      0.94140625,
      2.484375,
      4.5625,
      -6.625,
      -3.15625,
      -4.90625,
      -1.9375,
      -0.451171875,
      0.68359375,
      -3.953125,
      -0.35546875,
      4.625,
      -2.109375,
      4.21875,
      0.65234375,
      -0.08837890625,
      -7.53125,
      0.5625,
      -0.69921875,
      2.375,
      0.451171875,
      1.390625,
      -3.53125,
      3.890625,
      1.2734375,
      -3.484375,
      1.8359375,
      0.703125,
      -1.6484375,
      -5.25,
      2.109375,
      -0.6640625,
      2.65625,
      2.171875,
      2.65625,
      2.484375,
      0.63671875,
      2.921875,
      8,
      1.265625,
      -1.765625,
      2.28125,
      -1.8515625,
      -5.59375,
      -2.90625,
      2.09375,
      -0.9140625,
      -3.3125,
      1.8125,
      0.7890625,
      2.234375,
      1.0625,
      0.470703125,
      4.1875,
      2.90625,
      -2.5,
      2.578125,
      -4.78125,
      1.21875,
      -6.875,
      -0.95703125,
      -2.6875,
      0.5859375,
      2.046875,
      6.65625,
      -2.03125,
      -2.5,
      4.1875,
      2.796875,
      2.609375,
      -2.671875,
      4,
      2.296875,
      -1.90625,
      -3.078125,
      -4.3125,
      4,
      2.03125,
      0.1376953125,
      -1.4609375,
      1.875,
      1.703125,
      -1.6171875,
      -4.625,
      0.83203125,
      0.65625,
      -5.90625,
      -5.21875,
      -2.25,
      3,
      -4.875,
      -0.65625,
      2.90625,
      -3.21875,
      2.6875,
      -0.298828125,
      -1.40625,
      1.1328125,
      -1.453125,
      1.578125,
      -0.232421875,
      -2.1875,
      1.1171875,
      1.265625,
      -2.0625,
      2.859375,
      -1.1171875,
      1.421875,
      1.5390625,
      -2.09375,
      -3.15625,
      -4.625,
      5,
      2.671875,
      1.3359375,
      4.0625,
      -3.921875,
      4.4375,
      0.34375,
      -0.76171875,
      -2.1875,
      3.703125,
      0.796875,
      0.65234375,
      0.07568359375,
      -0.953125,
      4.15625,
      -0.60546875,
      1.3671875,
      0.3046875,
      0.5703125,
      -2.703125,
      0.1923828125,
      -3.40625,
      0.1708984375,
      -0.061279296875,
      3.046875,
      -1.75,
      -2.140625,
      1.1484375,
      1.1796875,
      0.7578125,
      4.28125,
      -1.53125,
      -1.3125,
      2.84375,
      2.3125,
      0.349609375,
      -2.484375,
      -0.984375,
      -0.70703125,
      -1.3515625,
      -0.51953125,
      0.263671875,
      -2.65625,
      1.7109375,
      -1.203125,
      -2.734375,
      1.546875,
      2.21875,
      -1.7109375,
      -10.75,
      -0.470703125,
      0.27734375,
      -0.921875,
      -1.4921875,
      0.82421875,
      4,
      4.40625,
      2.765625,
      4.71875,
      -0.494140625,
      -4.46875,
      2.984375,
      15.875,
      -1.703125,
      -3.59375,
      2.1875,
      1.1171875,
      0.2353515625,
      5.5625,
      0.1767578125,
      0.470703125,
      -2.625,
      1.765625,
      4.90625,
      -1,
      1.0234375,
      0.36328125,
      -2.015625,
      1.3515625,
      2.515625,
      -3.765625,
      -4.15625,
      -0.234375,
      2.625,
      -2.046875,
      4.90625,
      -0.53515625,
      2.8125,
      1.453125,
      0.2294921875,
      0.515625,
      -2.375,
      -2.609375,
      -1.8359375,
      0.08349609375,
      -4.0625,
      -1.28125,
      -5.15625,
      0.400390625,
      -0.99609375,
      -0.87890625,
      -3.28125,
      -4.375,
      -3.21875,
      1.515625,
      -0.859375,
      2.203125,
      -0.69921875,
      -1.7734375,
      -1.234375,
      1.65625,
      0.33203125,
      -1.4375,
      -0.6953125,
      -1.59375,
      2.109375,
      1.5,
      -1.90625,
      1.6640625,
      -3.296875,
      -2.390625,
      0.30078125,
      -1.3671875,
      0.3203125,
      0.224609375,
      -0.984375,
      -0.98828125,
      -1.1796875,
      -2.625,
      0.458984375,
      0.01324462890625,
      1.0859375,
      -5.78125,
      -2.90625,
      4.28125,
      0.62890625,
      -1.1171875,
      -3.59375,
      1.0078125,
      1.375,
      2.328125,
      2.859375,
      -0.07080078125,
      2.796875,
      -4.34375,
      -0.07568359375,
      -1.140625,
      1.296875,
      -4.78125,
      0.2890625,
      1.2265625,
      1.3515625,
      6.3125,
      -4.4375,
      4.71875,
      2.921875,
      -5.71875,
      -1.0078125,
      1.2578125,
      -0.78515625,
      0.021484375,
      -1.625,
      0.66796875,
      0.2119140625,
      -0.78515625,
      1.875,
      2.3125,
      -0.609375,
      1.578125,
      -5.21875,
      1.796875,
      -0.7578125,
      -2.875,
      3.15625,
      -2.84375,
      -4.15625,
      -1.53125,
      4.46875,
      -2.1875,
      -2.125,
      2.546875,
      -1.3046875,
      2.796875,
      0.50390625,
      -1.921875,
      0.11572265625,
      -9.3125,
      -5.28125,
      -1.359375,
      -5.84375,
      2.4375,
      -3.0625,
      0.421875,
      0.515625,
      -2.09375,
      -2.90625,
      0.302734375,
      -1.9375,
      3.484375,
      5.625,
      3.21875,
      -1.46875,
      -2.390625,
      0.83203125,
      1.5390625,
      -2.0625,
      -1.7890625,
      0.1943359375,
      -2.09375,
      1.6875,
      3.65625,
      3.25,
      -2.5,
      3.578125,
      -0.4921875,
      -4.1875,
      -1.203125,
      3.140625,
      -0.50390625,
      0.37109375,
      -2.34375,
      -3.65625,
      -2.015625,
      0.053466796875,
      -1.8984375,
      -2.296875,
      0.3203125,
      -2.828125,
      3.28125,
      -0.69921875,
      -5.9375,
      4.21875,
      -0.05517578125,
      -5.6875,
      0.1318359375,
      -2.890625,
      5.4375,
      -4.25,
      5.8125,
      5.1875,
      -0.0157470703125,
      -0.421875,
      3.265625,
      3.171875,
      -2.46875,
      -5.21875,
      0.2041015625,
      6.09375,
      -4.4375,
      1.0859375,
      5.25,
      -1.7578125,
      2.875,
      -1.953125,
      -5.625,
      6.09375,
      3.171875,
      -5.5625,
      0.330078125,
      -0.55859375,
      -0.29296875,
      -1.765625,
      -0.70703125,
      2.3125,
      0.6796875,
      4.3125,
      1.1328125,
      -2.484375,
      -5.71875,
      -0.46484375,
      1.1640625,
      -2.5,
      -1.90625,
      1.5859375,
      0.71875,
      2.984375,
      -6.75,
      3.203125,
      1.7578125,
      0.59765625,
      -0.9453125,
      3.21875,
      2.3125,
      -0.173828125,
      -5.84375,
      1.421875,
      2.484375,
      0.337890625,
      -4.09375,
      3.515625,
      -0.875,
      0.314453125,
      -2.703125,
      1.015625,
      -1.21875,
      3.015625,
      -2.09375,
      -2.09375,
      -4.125,
      5.71875,
      -0.06494140625,
      0.7578125,
      3.828125,
      -3.109375,
      0.0908203125,
      1.4453125,
      -1.703125,
      1.1796875,
      -3.40625,
      0.86328125,
      1.1640625,
      1.2109375,
      0.61328125,
      2.46875,
      3.390625,
      -4.3125,
      -1.8984375,
      -5.5,
      -5.65625,
      0.050537109375,
      -1.4140625,
      0.765625,
      -0.90625,
      -8.625,
      2.609375,
      -0.50390625,
      -0.9140625,
      -0.1884765625,
      0.95703125,
      -5.8125,
      3.46875,
      5.9375,
      -4.09375,
      3.9375,
      0.06982421875,
      -2.671875,
      -1.8984375,
      -1.875,
      0.5234375,
      -3.96875,
      0.265625,
      1.90625,
      -3.734375,
      -2.703125,
      2.28125,
      -1.5625,
      2.515625,
      -1.4296875,
      4.09375,
      1.6015625,
      3.734375,
      1.0859375,
      0.85546875,
      5.125,
      -3.1875,
      -0.37890625,
      -1.34375,
      2.28125,
      -2.09375,
      0.0296630859375,
      0.6953125,
      -0.8671875,
      2.75,
      0.408203125,
      0.5625,
      -9.375,
      -3.828125,
      1.5859375,
      -1.7109375,
      4.375,
      1.3515625,
      -0.67578125,
      -0.1962890625,
      2.359375,
      0.298828125,
      -0.515625,
      -1.0546875,
      -1.703125,
      -3.40625,
      0.8125,
      1.3125,
      -7.5,
      -0.482421875,
      -0.6328125,
      0.77734375,
      1.09375,
      -0.244140625,
      -3.546875,
      -0.53515625,
      4.03125,
      -3.8125,
      -0.6953125,
      1.8828125,
      -1.2578125,
      5.40625,
      -0.035400390625,
      -0.1884765625,
      1.8671875,
      -3.328125,
      -7.34375,
      1.5625,
      -0.8984375,
      -3.65625,
      1.09375,
      -1.5390625,
      2.609375,
      -1.0703125,
      3.984375,
      -4.625,
      4.96875,
      1.2109375,
      -9.5625,
      4.25,
      -3,
      1.21875,
      -3.703125,
      -6,
      -3.609375,
      7.28125,
      -2.015625,
      -0.51953125,
      3.296875,
      -0.7265625,
      2.359375,
      2.875,
      -2.484375,
      -4.5625,
      1.6796875,
      4.25,
      -4.78125,
      2.046875,
      3.828125,
      1.3125,
      -1.7890625,
      1.3984375,
      3.765625,
      -1.1015625,
      -0.87890625,
      2.65625,
      3.1875,
      -0.384765625,
      -1.7265625,
      -2.234375,
      1.203125,
      -1.2421875,
      -2.171875,
      0.578125,
      -2.265625,
      1.0078125,
      -1.4921875,
      0.73828125,
      -1.0390625,
      -3.34375,
      -2.1875,
      0.2021484375,
      -1.390625,
      -0.2392578125,
      2.078125,
      -0.291015625,
      -1.6015625,
      0.478515625,
      3.359375,
      2.171875,
      -0.208984375,
      -4.4375,
      0.38671875,
      -0.67578125,
      -3.515625,
      -0.248046875,
      2.828125,
      -2.984375,
      -2.046875,
      0.734375,
      1.4921875,
      0.33203125,
      -2.5625,
      -2.828125,
      0.0439453125,
      2.0625,
      0.2255859375,
      -3.40625,
      -1.8828125,
      -0.2734375,
      5.25,
      -4.21875,
      -3.234375,
      0.06298828125,
      0.58203125,
      -3.171875,
      -1.390625,
      1.3046875,
      -2.09375,
      0.9296875,
      5.0625,
      -0.053955078125,
      0.84375,
      3.328125,
      -3.203125,
      -1.4453125,
      6.5625,
      3.03125,
      -1.609375,
      -0.2177734375,
      -1.484375,
      -4.9375,
      5.09375,
      8.125,
      -0.091796875,
      -0.984375,
      -0.82421875,
      -3.546875,
      -3.703125,
      -3.4375,
      0.6640625,
      -1.5390625,
      -5.875,
      4.03125,
      -1.4140625,
      2.421875,
      0.0091552734375,
      -1.0859375,
      4.625,
      0.119140625,
      0.021728515625,
      -1.7421875,
      0.6796875,
      4.25,
      -3.15625,
      0.30078125,
      -3.71875,
      0.322265625,
      -1.09375,
      1.8515625,
      0.453125,
      -2.140625,
      6.71875,
      -0.0106201171875,
      -1.109375,
      -0.84375,
      1.3671875,
      5.125,
      -1.3359375,
      -4.96875,
      -2,
      0.412109375,
      0.98046875,
      -3.421875,
      2.546875,
      -6.40625,
      -1.75,
      -1.6171875,
      2.640625,
      0.54296875,
      -0.55859375,
      0.015869140625,
      -2.171875,
      -0.91796875,
      2.875,
      2.109375,
      1.390625,
      2.0625,
      1.875,
      0.1962890625,
      -2.125,
      0.703125,
      3.3125,
      1.34375,
      0.5390625,
      -1.03125,
      0.71875,
      0.796875,
      -1.1328125,
      1.78125,
      -0.5234375,
      3.640625,
      1.8828125,
      -2.8125,
      2.078125,
      -3.09375,
      -4,
      -4.15625,
      1.609375,
      2.953125,
      1.421875,
      -1.03125,
      -0.35546875,
      -0.90234375,
      0.44140625,
      -0.099609375,
      -1.875,
      -0.1494140625,
      -2.625,
      1.5078125,
      4.78125,
      -1.1796875,
      -1.6875,
      1.71875,
      1.390625,
      0.1572265625,
      -1.9453125,
      -5,
      1.8046875,
      1.3671875,
      -1.0703125,
      0.921875,
      -2.921875,
      1.90625,
      -0.58984375,
      -3.015625,
      -1.1015625,
      1.1796875,
      -1.40625,
      3.953125,
      -0.80859375,
      -1.765625,
      0.6015625,
      3.875,
      0.322265625,
      2.21875,
      0.400390625,
      1.90625,
      -1.6015625,
      -2.703125,
      -0.7578125,
      0.251953125,
      5.71875,
      -0.6015625,
      1.1171875,
      1.2578125,
      0.86328125,
      -2.09375,
      4.75,
      -3.34375,
      -1.1796875,
      -2.0625,
      1.84375,
      0.291015625,
      -0.2578125,
      1.6484375,
      1.0703125,
      1.5078125,
      -0.94921875,
      -2.421875,
      -5.9375,
      -0.8125,
      -1.9765625,
      -1.140625,
      0.3046875,
      0.416015625,
      -0.7421875,
      1.3671875,
      2.46875,
      1.8671875,
      -0.671875,
      -0.36328125,
      -0.359375,
      -1.0234375,
      2.765625,
      0.2197265625,
      2.328125,
      0.73046875,
      0.8671875,
      1.9296875,
      -0.8671875,
      0.6484375,
      -0.59375,
      0.306640625,
      2.359375,
      -0.384765625,
      -1.453125,
      1.1015625,
      -0.1796875,
      -1.4921875,
      -1.0703125,
      0.322265625,
      1.0546875,
      0.5234375,
      1.9609375,
      0.765625,
      -0.91015625,
      -0.78515625,
      2.640625,
      3.359375,
      -3.71875,
      -2.96875,
      -0.8203125,
      1.5546875,
      -1.5,
      -1.3671875,
      -2.3125,
      1.6484375,
      -1.359375,
      0.32421875,
      3.171875,
      0.388671875,
      -1.546875,
      -2.734375,
      -0.443359375,
      -1.625,
      -2.234375,
      2.140625,
      1.203125,
      1.125,
      -1.625,
      -3.03125,
      1.25,
      1.1484375,
      0.25,
      2.1875,
      2.03125,
      -0.384765625,
      2.953125,
      -2.4375,
      1.5703125,
      -2.8125,
      1.2734375,
      2.671875,
      -0.97265625,
      0.37109375,
      0.94921875,
      -0.265625,
      0.9296875,
      -3.78125,
      -2.4375,
      -1.78125,
      -1.234375,
      1.046875,
      0.421875,
      0.056884765625,
      -2.921875,
      2.796875,
      -2.34375,
      0.1884765625,
      -1.1171875,
      0.1572265625,
      2.109375,
      -0.341796875,
      -1.859375,
      1.21875,
      0.6484375,
      -0.208984375,
      -2.0625,
      -0.5,
      0.703125,
      3.03125,
      1.8046875,
      4.1875,
      1.1796875,
      -1.3515625,
      1.46875,
      -0.48828125,
      -1.6640625,
      0.2138671875,
      -0.267578125,
      -1.875,
      2.125,
      3.578125,
      1.828125,
      0.734375,
      1.671875,
      -0.1962890625,
      0.03271484375,
      0.040771484375,
      2.84375,
      1.0546875,
      -0.66015625,
      -0.8359375,
      -1.21875,
      0.251953125,
      -1.0703125,
      -0.08544921875,
      0.43359375,
      0.298828125,
      0.87890625,
      -0.84765625,
      0.29296875,
      0.265625,
      -1.2109375,
      2.640625,
      0.142578125,
      0.478515625,
      -1.0078125,
      3.265625,
      -1.703125,
      -0.91796875,
      2.015625,
      -0.8828125,
      -0.9453125,
      2.3125,
      -6.5,
      0.0634765625,
      -1.1953125,
      -0.6953125,
      -0.12255859375,
      0.169921875,
      2.65625,
      0.216796875,
      -2.15625,
      1.71875,
      0.318359375,
      2.375,
      -0.4765625,
      2.15625,
      -1.125,
      0.58203125,
      -0.078125,
      -2.125,
      2.515625,
      0.1650390625,
      0.2158203125,
      1.8203125,
      -0.3203125,
      1.21875,
      -1.4453125,
      -3.046875,
      -4.53125,
      -1.2734375,
      0.18359375,
      0.75390625,
      3.765625,
      1.3203125,
      -1.078125,
      2.078125,
      -1.8359375,
      3.390625,
      -0.515625,
      -2.265625,
      -0.64453125,
      0.9296875,
      -1.9375,
      -3.3125,
      -0.359375,
      -0.263671875,
      0.7734375,
      1.546875,
      0.3515625,
      -1.3046875,
      -1.2890625,
      -4.21875,
      2.828125,
      -1.5625,
      0.328125,
      -0.0478515625,
      -0.78515625,
      3.03125,
      -2.1875,
      4.21875,
      1.5625,
      1.3671875,
      0.46484375,
      0.1455078125,
      -0.0218505859375,
      3.296875,
      2.53125,
      0.1982421875,
      -2.703125,
      -1.953125,
      0.26171875,
      1.59375,
      0.2392578125,
      2.34375,
      1.4375,
      4.09375,
      -1.6328125,
      1.5234375,
      1.109375,
      -2.203125,
      -0.1357421875,
      1.6015625,
      0.83984375,
      -2.75,
      -1.6171875,
      -0.306640625,
      1.1796875,
      -1.09375,
      1.90625,
      3.921875,
      0.2216796875,
      1.59375,
      -1.2265625,
      0.984375,
      -1.078125,
      1.3515625,
      -2.046875,
      2.34375,
      0.6953125,
      -1.6015625,
      0.314453125,
      -0.9140625,
      -1.1484375,
      -1.6796875,
      0.88671875,
      -1.0390625,
      2.671875,
      -1.5234375,
      -0.07275390625,
      -0.8984375,
      -0.75,
      0.7578125,
      1.09375,
      0.828125,
      1.078125,
      -0.490234375,
      2.375,
      -0.431640625,
      -0.14453125,
      -1.8203125,
      3.515625,
      -4.9375,
      -3.984375,
      -2.59375,
      -0.73046875,
      0.0220947265625,
      -0.99609375,
      -2.265625,
      2.203125,
      -0.39453125,
      1.65625,
      -1.3203125,
      -0.1142578125,
      4.5625,
      4.96875,
      1.3828125,
      2.640625,
      0.005950927734375,
      1.6796875,
      -0.9296875,
      -1.8359375,
      3.328125,
      -2.328125,
      -1.9765625,
      -1.3828125,
      0.95703125,
      -2.171875,
      -1.75,
      -1.4296875,
      -1.1484375,
      0.01300048828125,
      -1.125,
      -2.1875,
      -1.515625,
      -0.470703125,
      -4.125,
      -0.1298828125,
      -2.703125,
      0.1298828125,
      -0.0654296875,
      1.5703125,
      1.234375,
      -0.3203125,
      1.484375,
      1.2890625,
      1.1015625,
      -0.5859375,
      -1.34375,
      0.494140625,
      -3.671875,
      0.41796875,
      3.015625,
      -1.6328125,
      -3.828125,
      0.35546875,
      4.6875,
      -0.275390625,
      0.498046875,
      -3.296875,
      -0.1171875,
      2.84375,
      3.015625,
      1.8515625,
      -0.38671875,
      -1.765625,
      1.0859375,
      -2.203125,
      2.875,
      -1.1484375,
      -2.140625,
      0.54296875,
      -0.30078125,
      0.10205078125,
      3.296875,
      1.2109375,
      -0.275390625,
      0.94921875,
      -2.484375,
      -0.53515625,
      -1.9140625,
      -1.859375,
      4.03125,
      -0.94921875,
      0.435546875,
      0.439453125,
      2.546875,
      -4.125,
      -0.072265625,
      -2.625,
      0.37109375,
      -1.609375,
      2.328125,
      -1.609375,
      -0.060302734375,
      1.0859375,
      -0.39453125,
      5.625,
      3.75,
      -0.169921875,
      -2.59375,
      -1.9375,
      1.09375,
      -0.93359375,
      3.15625,
      -1.828125,
      -2.28125,
      -0.0308837890625,
      -0.5625,
      2.078125,
      -0.9921875,
      1.1640625,
      -2.140625,
      -0.376953125,
      1.3984375,
      0.33984375,
      1.1953125,
      2.046875,
      2.859375,
      -1.921875,
      -0.4375,
      -3.40625,
      -3.0625,
      -2.140625,
      1.4296875,
      -0.6953125,
      0.03759765625,
      -0.25390625,
      -0.60546875,
      -1.8984375,
      -2.84375,
      1.828125,
      -1.375,
      -0.98046875,
      1.234375,
      -0.6328125,
      -2.28125,
      0.984375,
      -1.875,
      -0.056396484375,
      -2.46875,
      -4.125,
      1.171875,
      -1.078125,
      0.62109375,
      -3.515625,
      -0.11865234375,
      2.53125,
      -1.5,
      -3.453125,
      -3.09375,
      2.3125,
      -1.265625,
      -2.125,
      1.109375,
      2.421875,
      0.98828125,
      -0.408203125,
      -0.40625,
      -5.3125,
      0.126953125,
      -4.53125,
      2.21875,
      3.4375,
      0.8046875,
      0.177734375,
      3.078125,
      2.671875
    ],
    "summary": "提出一种人机协同循环框架，通过整合专家判断来优化自动项目生成（AIG）的质量，特别针对批判性思维评估领域，旨在解决AI生成项目的效度问题。",
    "structure": {
      "sections": [
        {
          "title": "STAIR-AIG: Optimizing the Automated Item Generation Process through Human-AI Collaboration for Critical Thinking Assessment",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 11
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "2 Related Works",
          "level": 1,
          "start_line": 31
        },
        {
          "title": "2.1 Automatic Item Generation",
          "level": 1,
          "start_line": 33
        },
        {
          "title": "2.2 Assessment Item Review Procedure",
          "level": 1,
          "start_line": 41
        },
        {
          "title": "3 Development of STAIR-AIG",
          "level": 1,
          "start_line": 54
        },
        {
          "title": "3.1 STAIR-AIG Workflow",
          "level": 1,
          "start_line": 56
        },
        {
          "title": "3.2 STAIR-AIG Modules",
          "level": 1,
          "start_line": 69
        },
        {
          "title": "3.2.1 Item Analysis Module",
          "level": 1,
          "start_line": 73
        },
        {
          "title": "3.2.2 Item Review Module",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "4 Empirical Research",
          "level": 1,
          "start_line": 115
        },
        {
          "title": "4.1 Data",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "4.2 Item Review by Human Expert",
          "level": 1,
          "start_line": 131
        },
        {
          "title": "4.3 Item Quality Review by LLMs",
          "level": 1,
          "start_line": 143
        },
        {
          "title": "5 Results",
          "level": 1,
          "start_line": 151
        },
        {
          "title": "5.1 Quantitative Results",
          "level": 1,
          "start_line": 153
        },
        {
          "title": "5.1.1 Comparison of Human Reviews with LLM-generated Reviews",
          "level": 1,
          "start_line": 155
        },
        {
          "title": "5.1.2 Distribution of Ratings across Evaluators",
          "level": 1,
          "start_line": 163
        },
        {
          "title": "5.2 Qualitative Feedback from Human Expert",
          "level": 1,
          "start_line": 179
        },
        {
          "title": "6 Conclusions & Implications",
          "level": 1,
          "start_line": 195
        },
        {
          "title": "6.1 Conclusions",
          "level": 1,
          "start_line": 197
        },
        {
          "title": "6.2 Implications",
          "level": 1,
          "start_line": 205
        },
        {
          "title": "6.3 Limitations",
          "level": 1,
          "start_line": 217
        },
        {
          "title": "Acknowledgments",
          "level": 1,
          "start_line": 231
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "A Appendix",
          "level": 1,
          "start_line": 278
        },
        {
          "title": "A.1 Prompt for Item Review by LLMs",
          "level": 1,
          "start_line": 280
        },
        {
          "title": "Listing 1: System prompt",
          "level": 1,
          "start_line": 284
        },
        {
          "title": "Listing 2: User prompt: Review Context",
          "level": 1,
          "start_line": 294
        },
        {
          "title": "Review Context",
          "level": 2,
          "start_line": 296
        },
        {
          "title": "Listing 3: User prompt: Review Methods",
          "level": 1,
          "start_line": 314
        }
      ]
    },
    "suggested_tags": [
      "教育评估",
      "人机协同",
      "自动项目生成",
      "大语言模型",
      "批判性思维"
    ],
    "tag_suggestions": [
      {
        "name": "教育评估",
        "confidence": 0.95,
        "reason": "论文核心研究领域是教育测量与评估，特别是针对批判性思维这一高阶认知技能的评估项目生成与质量保证。"
      },
      {
        "name": "人机协同",
        "confidence": 0.9,
        "reason": "论文提出并验证了STAIR-AIG框架，这是一个系统性的人机协同（Human-in-the-loop）工具，旨在通过整合专家判断来优化自动项目生成流程。"
      },
      {
        "name": "自动项目生成",
        "confidence": 0.9,
        "reason": "论文聚焦于利用大语言模型进行自动项目生成，并致力于解决其生成项目的质量、有效性和适当性问题，这是论文的核心技术应用。"
      },
      {
        "name": "大语言模型",
        "confidence": 0.85,
        "reason": "研究以LLMs（如OpenAI模型）作为AIG的核心技术，探讨其在项目生成与评审中的表现、局限性，并利用人类反馈进行模型优化。"
      },
      {
        "name": "批判性思维",
        "confidence": 0.8,
        "reason": "论文选择批判性思维作为具体的应用和验证领域，这是一个复杂且具有挑战性的高阶认知技能评估场景。"
      }
    ],
    "category": "教育评估",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:282837002",
          "title": "Sorry, it's my fault: Politeness, attribution, and anthropomorphism in managing generative AI hallucinations",
          "authors": [
            "Hayeon Kim",
            "Sang Woo Lee"
          ],
          "year": 2026,
          "venue": "International Journal of Information Management",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283006637",
          "title": "From hallucinations to hazards: benchmarking LLMs for hazard analysis in safety-critical systems",
          "authors": [
            "Ioannis M. Dokas"
          ],
          "year": 2026,
          "venue": "Safety Science",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283171596",
          "title": "A review of knowledge graph construction using large language models in transportation: Problems, methods, and challenges",
          "authors": [
            "Yancheng Ling",
            "Zhenlin Qin",
            "Zhengliang Ma"
          ],
          "year": 2026,
          "venue": "Transportation Research Part C: Emerging Technologies",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283205299",
          "title": "A singular learning theory for unified large language model pruning",
          "authors": [
            "Xinyu Wang",
            "Zhaoxin Fan",
            "Faguo Wu",
            "Hongwei Zheng",
            "Yuanze Hu",
            "Gen Li",
            "Zhichao Yang",
            "Qiu Ye",
            "Yifan Sun",
            "Wenjun Wu"
          ],
          "year": 2026,
          "venue": "Neurocomputing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283296470",
          "title": "Multimodal large model driven pseudo labeling for unbiased scene graph generation",
          "authors": [
            "Songju Li",
            "Bin Sun",
            "Shutao Li",
            "Bin Yang"
          ],
          "year": 2026,
          "venue": "Neurocomputing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283434047",
          "title": "AugGen: a generative framework for continual generalized zero-shot learning",
          "authors": [
            "Na Han",
            "Honglin Chen",
            "Bingzhi Chen",
            "Lei Zhang",
            "Yue Huang",
            "Qintao Luo",
            "Xiaozhao Fang"
          ],
          "year": 2026,
          "venue": "Neurocomputing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283533669",
          "title": "Intelligent system modeling using GenAI: A methodology for automated simulation model generation",
          "authors": [
            "Lin Zhang",
            "Yuteng Zhang",
            "Dusit Niyato",
            "Lei Ren",
            "Pengfei Gu",
            "Zhen Chen",
            "Y. Laili",
            "Wentong Cai",
            "A. Bruzzone"
          ],
          "year": 2026,
          "venue": "Simulation modelling practice and theory",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283643870",
          "title": "Synthetic data generation for joint electric vehicle driving and charging events via deep generative networks",
          "authors": [
            "Zhi Li",
            "Wei Ma",
            "Mónica Menéndez",
            "Zhibin Chen",
            "Minghui Zhong"
          ],
          "year": 2026,
          "venue": "Transportation Research Part C: Emerging Technologies",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283854590",
          "title": "ESA-Net: An Efficient and Lightweight Model for Medical Image Segmentation",
          "authors": [
            "Haiquan Liu",
            "Mingcan Cen",
            "Chong Zhang",
            "Angela An",
            "Shuxiang Song"
          ],
          "year": 2026,
          "venue": "Big Data Mining and Analytics",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280514888",
          "title": "IGen: Redefining long-term event prediction with iterative generation and dynamic balancing",
          "authors": [
            "Yuxin Zhang",
            "Yan Wang",
            "Songlin Zhai",
            "Yongrui Chen",
            "Shenyu Zhang",
            "Yuan Meng",
            "Zhihua Chai",
            "Sheng Bi",
            "Guilin Qi"
          ],
          "year": 2026,
          "venue": "Information Processing & Management",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T22:45:09.108500",
      "references": [
        {
          "external_id": "CorpusId:219800227",
          "title": "All the News That’s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation",
          "authors": [
            "S. Kreps",
            "Miles McCain",
            "Miles Brundage"
          ],
          "year": 2020,
          "venue": "Journal of Experimental Political Science",
          "citation_count": 289
        },
        {
          "external_id": "CorpusId:218971825",
          "title": "Language (Technology) is Power: A Critical Survey of “Bias” in NLP",
          "authors": [
            "Su Lin Blodgett",
            "Solon Barocas",
            "Hal Daum'e",
            "Hanna M. Wallach"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1463
        },
        {
          "external_id": "CorpusId:218869575",
          "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
          "authors": [
            "Patrick Lewis",
            "Ethan Perez",
            "Aleksandara Piktus",
            "F. Petroni",
            "Vladimir Karpukhin",
            "Naman Goyal",
            "Heinrich Kuttler",
            "M. Lewis",
            "Wen-tau Yih",
            "Tim Rocktäschel",
            "Sebastian Riedel",
            "Douwe Kiela"
          ],
          "year": 2020,
          "venue": "Neural Information Processing Systems",
          "citation_count": 9778
        },
        {
          "external_id": "CorpusId:218487293",
          "title": "How Can We Accelerate Progress Towards Human-like Linguistic Generalization?",
          "authors": [
            "Tal Linzen"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 202
        },
        {
          "external_id": "CorpusId:218487109",
          "title": "UnifiedQA: Crossing Format Boundaries With a Single QA System",
          "authors": [
            "Daniel Khashabi",
            "Sewon Min",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Oyvind Tafjord",
            "Peter Clark",
            "Hannaneh Hajishirzi"
          ],
          "year": 2020,
          "venue": "Findings",
          "citation_count": 785
        },
        {
          "external_id": "CorpusId:216035815",
          "title": "Experience Grounds Language",
          "authors": [
            "Yonatan Bisk",
            "Ari Holtzman",
            "Jesse Thomason",
            "Jacob Andreas",
            "Yoshua Bengio",
            "J. Chai",
            "Mirella Lapata",
            "Angeliki Lazaridou",
            "Jonathan May",
            "Aleksandr Nisnevich",
            "Nicolas Pinto",
            "Joseph P. Turian"
          ],
          "year": 2020,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 393
        },
        {
          "external_id": "CorpusId:215828184",
          "title": "StereoSet: Measuring stereotypical bias in pretrained language models",
          "authors": [
            "Moin Nadeem",
            "Anna Bethke",
            "Siva Reddy"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1198
        },
        {
          "external_id": "CorpusId:215828407",
          "title": "Adversarial Training for Large Neural Language Models",
          "authors": [
            "Xiaodong Liu",
            "Hao Cheng",
            "Pengcheng He",
            "Weizhu Chen",
            "Yu Wang",
            "Hoifung Poon",
            "Jianfeng Gao"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 203
        },
        {
          "external_id": "CorpusId:215745290",
          "title": "Pretrained Transformers Improve Out-of-Distribution Robustness",
          "authors": [
            "Dan Hendrycks",
            "Xiaoyuan Liu",
            "Eric Wallace",
            "Adam Dziedzic",
            "R. Krishnan",
            "D. Song"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 457
        },
        {
          "external_id": "CorpusId:212747731",
          "title": "TTTTTackling WinoGrande Schemas",
          "authors": [
            "Sheng-Chieh Lin",
            "Jheng-Hong Yang",
            "Rodrigo Nogueira",
            "Ming-Feng Tsai",
            "Chuan-Ju Wang",
            "Jimmy Lin"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 6
        }
      ],
      "references_fetched_at": "2025-12-16T22:45:09.878682"
    }
  },
  "6f24f8d1-03ac-4741-a063-e53bea9bab70": {
    "id": "6f24f8d1-03ac-4741-a063-e53bea9bab70",
    "filename": "A CHATGPT-BASED APPROACH FOR QUESTIONS GENERATION IN  HIGHER EDUCATION.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/6f24f8d1-03ac-4741-a063-e53bea9bab70_A CHATGPT-BASED APPROACH FOR QUESTIONS GENERATION IN  HIGHER EDUCATION.pdf",
    "status": "completed",
    "created_at": "2025-12-16 22:48:04.525748",
    "updated_at": "2025-12-16 14:49:03.434120",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "AchatGPT-BASED APPROACH FOR QUESTIONS GENERATION IN HIGHER EDUCATION",
    "markdown_content": "# AchatGPT-BASED APPROACH FOR QUESTIONS GENERATION IN HIGHER EDUCATION\n\nA PREPRINT\n\nSinh Trong Vu\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\nsinhvt@hvnh.edu.vn\n\nHuong Thu Truong\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\ntrgthuhg@gmail.com\n\nOanh Tien Do\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\noanhvy2bg@gmail.com\n\nTu Anh Le\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\nleanhtu.work@gmail.com\n\nTai Tan Mai\n\nDublin City University\n\nDublin, Ireland\n\ntai.tanmai@dcu.ie\n\nJune 10, 2024\n\n# ABSTRACT\n\nLarge language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a \"Blind test\" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.\n\nKeywords Large language model  $\\cdot$  ChatGPT  $\\cdot$  question generation\n\n# 1 Introduction\n\nOne of the most prominent advances in Artificial Intelligence recently is the development of large language models (LLMs), such as ChatGPT, BingChat, and Bard (developed by OpenAI, Microsoft, and Google, respectively). It can be said that large language models have been developing strongly in the past 2 years and creating a strong influence in the field of Generative AI (GenAI) [1].\n\nLLMs are capable of solving a wide range of tasks, such as natural language understanding, text generation, and sentiment analysis in various domains [2]. Since the breakthroughs of AI and LLM, education, as a crucial role in shaping society through almost every single individual, might receive significant benefits from these new LLM-based initiatives. AI is transforming education, bridging its gaps, and promoting a more inclusive and productive learning environment by customizing learning experiences, automating administrative tasks, and providing real-time feedback [3].\n\nAdvancements in AI and LLMs have fueled the development of many educational technology innovations that aim to automate the often time-consuming and laborious tasks of generating and analyzing textual content, including generating test questions. For the application of LLM in education, this technology holds great potential in this field at all levels, especially university level [4]. Therefore, this study conducts a research to comprehensively understand the capabilities of LLMs, especially ChatGPT when supporting lecturer to build question banks for learning modules in university setting. During the literature review, we witnessed that although the LLMs can provide quite a lot of support in teaching activities [5], the work of testing and evaluating learners, which takes up a lot of time and effort of\n\nlecturers, has not been studied in-depth by previous works. Therefore, in this paper, we decide to conduct research on the application of LLMs for generating question banks, with initial results at the Banking Academy of Vietnam. Specifically, the contributions of the paper are summarized as follows:\n\n1. Investigate the most potential LLM-based tool that satisfy the following criteria: (i): capable of processing multiple languages; (ii) widely accessible by the public and (iii) suitable for university educational setting.  \n2. Design a novel approach to generate prompting patterns to interact with ChatGPT, thereby design an effective prompt pattern for creating question banks at university level.  \n3. Generate a question bank for a specific subject with diverse question types as the sample module of university level in Vietnam, in order to present the potential direction for further related research in the field of broader modules of higher education.  \n4. Design and conduct a \"Blind Test\" survey aimed at students to evaluate the quality of the generated questions\n\n# 2 Related works\n\nWith the growing interest in LLM for education, many studies around the world focusing on this issue have been conducted and have produced some interesting results. A group of authors from the University of Minnesota Law School have conducted research on ChatGPT's performance in answering a set of questions including 95 multiple-choice questions and 12 essay questions related to four undergraduate-level subjects in the law class. The results showed that ChatGPT studied and performed on the test at a level equivalent to a  $\\mathrm{C + }$  grade for college students [6].\n\nAnother study put ChatGPT to the test in completing the Dutch secondary school exam in the subject of English reading comprehension. This study concluded that ChatGPT achieved results with an average score of 7.3, comparable to the average score of all high school students in the country [7].\n\nIn another research on evaluating the performance of LLMs when taking a high school level Biology test by the author namely Dao Xuan Quy, ChatGPT showed positive results with an accuracy of  $71\\%$  for remembering level questions and  $61.82\\%$  for understanding level questions. This result shows how effective ChatGPT is in capturing and clarifying concepts related to the required subject [8].\n\nThe use of LLMs in supporting the construction of questions to test and evaluate students' knowledge should be encouraged. While exam-style questions are an important instructional tool for several reasons, manually creating questions is a time-consuming process that necessitates expertise, experience, and resources. This, in turn, impedes and inhibits the implementation of instructional activities (e.g., offering practice questions) and educational initiatives (e.g., adaptive testing) that need a huge pool of questions. Therefore, automatic question generating (AQG) approaches based on AI were established for research in both developed and developing nations [9].\n\nThe general state of scientific research on the use of LLM in education is limited because its implementation in educational settings is still in its early stages. To the best of our knowledge, there is no study on evaluating quality and practicality of using questions generated by LLMs to test real students, especially in higher education. Therefore, in this study we will conduct an experiment on questions bank generation using LLMs, with some early results from a university in Vietnam.\n\nSelecting the optimal LLM-based solution. Nowadays, many advanced large language models can be widely applied in the field of education such as ChatGPT, BingAI, Gemini, etc. Most prominently, ChatGPT is an advanced general AI model based on a Generative Pretrained Transformer (GPT). This feature refers to the LLM being pre-trained with the available dataset and can generate grammatically and contextually human-like responses according to the user's request through natural language processing. The current most popular versions of ChatGPT are GPT-3.5 and GPT-4, with the upgraded version GPT-4 can be used with a fee, which according to OpenAI performs much better with a 10 times larger pre-training datasets capacity [10].\n\nThe initial goal of this research is to evaluate various LLMs in order to find the one having performance and suitability for generating questions in the higher educational context. Each model has its own advantages and disadvantages, so our team has to compare consider which one can fulfill the both factors. As we prioritize the best ones meeting educational standards, ChatGPT Plus and Claude are two potential options. However, ChatGPT Plus has a relatively high fee (\\(20/month) and Claude has a few limitations in its capabilities [11].\n\nFor the following reasons, we finally decided to choose ChatGPT 3.5 as the model for this research:\n\n- ChatGPT 3.5 is freely usable so this choice can save on our research costs.\n\n- ChatGPT 3.5 has been proven through scientific research to be able to produce high-quality text, similar to text written by humans[12].  \n- ChatGPT 3.5 currently has 180 million users, with 100 million weekly active users and 1.6 billion website visit times [13]. This number shows that ChatGPT 3.5 is sufficiently popular and trustworthy.\n\nStriking the perfect balance between capability and cost, ChatGPT 3.5 is selected as it is sufficiently suitable to the context of educating in the Banking Academy of Vietnam.\n\n# 3 Research design\n\n# 3.1 Choosing a subject for experimentation\n\nIn most universities, building a question bank is the primary way to facilitate the procedure of making tests and final semester exams. The question bank is usually based on the learning outcomes and lesson content, thereby determining the types of questions to create. Questions are arranged according to each chapter, with cognitive levels depending on the objectives and lesson knowledge. Here, we conduct research on creating questions for the subject \"Corporate Finance I\" with the LLM ChatGPT 3.5, by these reasons and purposes:\n\n- First, to test and evaluate ChatGPT 3.5's natural language processing ability with a variety of different question types. This is because \"Corporate Finance I\" has a variety of question types that have been extensively put under tests and final exams: Multiple Choice Questions (MCQs), True-False statements, Real-Scenario/Calculative exercises,...  \n- Second, to make the experiment more effective with the highest possible number of survey participants \"Corporate Finance I\" is a popular module format as it is a compulsory curriculum for almost every faculty in the Banking Academy of Vietnam for specialized learning outcomes towards the students of the academy.  \n- Third, to qualitifiedly evaluate this scientific study. Throughout many subjects our research team discussed, \"Corporate Finance I\" has been chosen since this is the subject that we have obtained a certain basic understanding of.\n\nTo conduct research, we combine personal knowledge and use documents including the textbook \"Corporate Finance I\" (Author & Editor: Le Thi Xuan), the workbook \"Corporate Finance I\" of the Banking Academy and also refer to Course Learning Outcomes (CLOs), syllabus structure, test question formats, and examples of exam questions in this subject.\n\n# 3.2 The investigation of appropriate Prompt patterns\n\nThrough research on the meaning of elements as well as the operation of available Prompt templates such as RTF (Role, Task, Format), RISE (Role, Input, Steps, Expectation), RTCF (Role, Task, Context, Format), RTCEF (Role, Task, Context, Example, Format). We have filtered, selected and separated into specific factors as shown in the Table 1 [14].\n\nThen, one by one, we select and combine the above factors and then test and evaluate the results returned by ChatGPT ourselves. The goal of this experiment is to answer: Whether to continue adding or removing any factor to see if it affects the quality of returned results? If the results are better, we consider that factor to be kept and conversely, if there is no change and we find it unnecessary, we remove that factor. As a result, we choose the most suitable prompt type for each type of question we want to create below.\n\n# 3.2.1 For multiple-choice questions\n\nPrompt: Role + Task + Context + Example + Format\n\nFollowing the structure, here is our formative prompt:\n\nRole: You are a lecturer of [subject name]\n\nTask: Please create [a specific number] questions\n\nContext: [The kind of exercise] questions that focus on the content of [name of the lesson to test]\n\nExample: (This is the example I want you to imitate: [specific example of the type of exercise to create])\n\nFormat: Present output in [format name]\n\nTable 1: Prompt elements and their uses  \n\n<table><tr><td>Factor</td><td>Purpose</td></tr><tr><td>Task</td><td>Describe the task you want the AI to perform, usually starting with verbs such as: Create [...] , do [...] , ... This is a required part in most prompts to use for ChatGPT</td></tr><tr><td>Context</td><td>Provide information about the context and task objectives</td></tr><tr><td>Input</td><td>Describe the context in more detail</td></tr><tr><td>Format</td><td>Specify the desired format for the output, usually a standard that has been agreed upon and used</td></tr><tr><td>Example</td><td>Provide specific example instructions to guide the AI, often in parentheses</td></tr><tr><td>Role</td><td>Clearly define the role of AI in a specific context, usually with role statements such as: Play the role of [...] , you are [...] , ...</td></tr></table>\n\n# 3.2.2 For True-False statements\n\nPrompt:  $=$  Role + Task + Context + Example + Format\n\nFollowing the structure, here is our formative prompt:\n\nRole: You are a lecturer of [subject name]\n\nTask: Please create [a specific number] questions\n\nContext: [The kind of exercise]. You should make the exam of [number of statements] including [number of correct statements] correct statements and [number of incorrect statements] incorrect statements with content about [name of content]\n\nExample: (This is the example I want you to imitate: [specific example of the type of exercise to create])\n\nFormat: All comments are in the same paragraph. The line determining the truth/falseness and explanation of that statement must immediately follow, starting with \"ANSWER:\" (NOTE: Space after the colon) and then giving the appropriate answer and explanation.\n\n# 3.2.3 For Real-Scenario/Calculative exercises\n\nPrompt:  $=$  Task + Context + Input + Tone\n\nFollowing the structure, here is our formative prompt:\n\nTask: Create exercises with specific data\n\nContext: About [name of content]\n\nInput: The topic includes [starting data] [detailed information]\n\nTone: You have to solve the exercise as you are dealing with real business context\n\n# 3.3 Evaluation methods and test results\n\n# 3.4 Preliminary self-assessment and optimization utilizing ChatGPT.\n\nApplying the above prompt samples with ChatGPT3.5, we obtain a list of questions, in which the MCQ and True/False questions are along with the solutions. We perform a preliminary self-assessment by checking whether the question list containing any duplication or lack of assumption to solve. From a total of 390 questions generated, we found and remove 74 ones with this strategy, in which,  $28\\%$  of the calculation exercises are insufficient data. For instance, the exercise \"PQR Company wants to optimize ordering costs for product D. The annual demand is 600 tons, the purchase\n\nprice per ton is 15,000 USD. Holding cost is  $1.5\\%$  of inventory value/year. Calculate the optimal order level.\" lacks the \"ordering costs\" value, makes it unsolvable. This is one of the drawback of large language model based method, relying on the probability of word's appearance rather than the logical factors. We show the self-assessment result in Table 2 below.\n\nTable 2: Evaluation of question quality. (Unit: %)  \n\n<table><tr><td>Question Type</td><td>MCQs</td><td>True-False Statement</td><td>Calculation exercise</td></tr><tr><td>Total Number of Questions</td><td>230 questions</td><td>100 questions</td><td>60 question</td></tr><tr><td>Duplicated</td><td>19,13%</td><td>3%</td><td>0</td></tr><tr><td>Insufficient assumptions to solve</td><td>3,48%</td><td>4%</td><td>28%</td></tr></table>\n\n# 3.5 The \"Blind Test\" method\n\nTo evaluate the quality of the questions more objectively, our research team conducted a survey using the \"Blind test\" method to collect answers from students to lecturers. Based on the well-known Turing Test, the \"Blind test\" aims to get empirical insight into people's ability to discriminate between artificial and human content [15].\n\nBased on this idea, we have prepared two sets of question banks. One is the questions created by ChatGPT 3.5 and the other is the questions in the workbook of Corporate Finance 1 published by the Banking Academy of Vietnam. The questions from the two groups were mixed together. We proceed to create a survey form testing with a list of 15 questions, with an example shown in Figure 1. Each question includes 2 options: created by humans or created by ChatGPT. We obtain the answer from a total of 91 people including lecturers, students who studied, are currently studying or have not studied Corporate Finance I before. The detail statistics about this survey is evaluated in the following sections.\n\n1. Private enterprises are allowed to issue bonds to mobilize investment capital.  \nCreated by human  \nCreated by ChatGPT\n\nFigure 1: An example question from the \"Blind Test\" survey\n\n# 3.6 Result of evaluation\n\n# 3.6.1 Survey assumption\n\nDuring the survey, the course-completed rate is expected to be distributed in proportion:  $60\\%$  have completed and are in progress of completing, and  $40\\%$  have not started. This provides the opportunity for multi-pronged analysis looking at different outcomes based on these two main groups.\n\nThe general expectation of our research team is that the number of questions prepared by ChatGPT but predicted to be created by humans is high, for approximately over  $60\\%$ . To better understand this result, we need to analyze each group more carefully as follows:\n\n- For lecturers, they have the ability to deeply evaluate the similarity between the question and the content, evaluate the difficulty level of the question as well as the feasibility of solving it. This allows them to most accurately identify which questions truly reflect knowledge and are capable of assessing students' skills like real exam questions.  \n- For the group of people who have studied, they can analyze the content of the questions, consider the level of difficulty and the ability to apply learned knowledge to solve questions. This helps them better recognize how each knowledge is asked in the real exam, thereby pointing out the questions created by ChatGPT with its shortcomings.\n\n- The group of in-progress learners can focus on evaluating the reflectiveness of the question on the content they are approaching. From their perspective, they will distinguish between questions created by ChatGPT or people based on their progressed knowledge and their own understanding.  \n- Finally, the group of students that haven't learned this subject may only be able to evaluate the naturalness and the grammar accuracy in the question.\n\n# 3.6.2 General analysis\n\nThe performance of each group of survey participants is presented in the Figure 2.\n\n![](/uploads/images/6f24f8d1-03ac-4741-a063-e53bea9bab70/03734fc52da67de08e4acfe73b604f737a6b9a51f9e87149c9196e05dd0ea520.jpg)  \nFigure 2: Average number of correct answers from different groups of surveyors\n\n- The survey results showed that lecturers have a relatively high ability to distinguish between questions generated by ChatGPT and those generated by humans, with an accuracy rate of up to 13.5/15 questions.  \n- Students who have studied the subject are better at distinguishing between ChatGPT-generated and human-generated questions than students who are currently studying  $(8.0833 > 7)$ , and students who have studied have a higher average correct answer rate than students who have not studied  $(7 > 6.7059)$ . This suggests that exposure to course content and knowledge helps students become more sensitive to the differences between human-generated and AI-generated questions.\n\n# 3.6.3 Specific analysis\n\nOur data shows that the 9 questions having the least percentage of students answering correctly have an average of only  $32.5\\%$  answers correct. In particular, the survey showed that the multiple-choice section had the lowest rate of correct answers with only about  $30\\%$ . This may stem from the fact that human lecturers often create short, concise multiple-choice questions with the goal of simply testing whether students have grasped the knowledge surrounding the concept being asked. In fact, LLM like ChatGPT has the ability to grasp the subject and create related questions to support learners[8]. Therefore, this tool is capable of creating MCQs properly along with the lecturers in an even faster way.\n\nTable 3: The best questions that ChatGPT generates  \n\n<table><tr><td>1. The principle of time value of money is: \nA. The longer a currency retains its value, the better \nB. The value of money increases over time \nC. A currency today has a higher value than it will in the future \nD. Money loses value over time</td><td>2. What are some of the main benefits of long-term investing? \nA. High short-term profits. \nB. Increase the value of long-term assets. \nC. Low risk. \nD. Stable market.</td></tr><tr><td>Participant result: \n63 (69,2%) wrongly rated as Human, 28 (30,8%) correctly rated as ChatGPT</td><td>Participant result: \n67 (73,6%) wrongly rated as Human, 24 (26,4%) correctly rated as ChatGPT</td></tr></table>\n\nTo explain the results above, the differentiating difficulty of AI-generated exercise questions is based on two factors:\n\n- The question type: Whether it is an MCQ or a T/F, Exercise question.  \n- The quality requirement of information input: In the process of making a good question, whether the question is required to capture completely learning materials or a few texts for example.\n\nSubjectively stated, a broad and general list of MCQs surveyed are less difficult to be guessed than real-life scenario exercises, or calculative ones that we had to give ChatGPT some examples to train it. Furthermore, these models can generate plausible distractors, which are incorrect answers that are designed to be similar to the correct answer, making it more challenging for humans to discern the difference. According to the study of Bitew et al. (2023), ChatGPT, when guided by question items and in-context examples, can generate high-quality distractors that are suitable for immediate use in an educational context.[16]\n\nTable 4: Worst question ChatGPT creates  \n\n<table><tr><td>Private enterprises are allowed to issue bonds to mobilize investment capital. (True/False)</td><td>Strengthening overdue debt management helps businesses optimize capital resources. (True/False)</td></tr><tr><td>Participant result: 70 (76,9%) correctly rated as Human, 21 (23,1%) wrongly rated as ChatGPT</td><td>Participant result: 70 (76,9%) correctly rated as Human, 21 (23,1%) wrongly rated as ChatGPT</td></tr></table>\n\nHowever, there are a few limitations needed to be considered to the performance of LLMs in generating questions in order to decide the optimal usage of this tool. Firstly, the 9 AI-generated questions, especially the True-False questions and Exercise questions that are leastly mistaken for human-generated ones shown, are all lacking structured links to other concepts and overall reasoning around the subject. This proves that the discriminatory power of those 9 questions might not be as high as other questions in the list. To clarify this point, our research team have tried to answer the questions ourselves as students and stated that more than half of the questions can be referenced for posting on the real exam, but there are a few problems:\n\n- In regards of the questions' content, they are simply the same so it is hard to use these questions to encourage students to link back what they have learned.  \n- Some of the AI-generated questions are quite vague to make clear its meaning.  \n- In the Vietnamese version of the questions, the way ChatGPT used related terms is not really exact for academic context due to the language barrier.\n\n# 4 Conclusion\n\nIn this study, we have researched an overview of the major language models available today, through which we propose to use Chat GPT3.5 because it has a wide reach to users, suitable for the Practical events at the Banking Academy. We have researched and extracted effective command samples that interact with Chat GPT3.5 to create a question bank for Corporate Finance 1 subject at the Banking Academy today and then create a bank. Questions types include: multiple choice, true or false judgment and calculation exercises. The question bank created by Chat GPT3.5 is post processed, then evaluated by a \"Blind Test\" conducted on lecturers and students who studied, studying or have not studied this subject. The results show that ChatGPT has great potential in supporting learner assessment through the application of creating questions that contribute to the test bank. This conclusion is proven by accurate data, with a level of differentiation of about  $80\\%$  at an average level similar to the target of test banks created by instructors.\n\nDuring the research and implementation process, we encountered a limitation that is needed for other works. Currently, with the rapid development of artificial intelligence, many new tools have emerged to support users in creating question and answer systems for their specific purposes, which can upload user's documents. These documents play as a knowledge base which contributes to improving the quality of questions generated. Additionally, users only need to provide the initial prompt, and educators do not need to learn about prompts but can simply request questions based on quantity and topic. Therefore, we hope to integrate our methodology with other scientific solutions to save time and effort for lecturers in evaluating learners in higher education.\n\n# References\n\n[1] Irfan Jahic, Martin Ebner, and Sandra Schön. Harnessing the power of artificial intelligence and chatgpt in education - a first rapid literature review. In Proceedings of EdMedia + Innovate Learning, pages 1462-1470, 07 2023.  \n[2] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. A survey on evaluation of large language models, 2023.  \n[3] Firuz Kamalov, David Santandreu Calonge, and Ikhlaas Gurrib. New era of artificial intelligence in education: Towards a sustainable multifaceted revolution. Sustainability, 15(16), 2023. ISSN 2071-1050. doi:10.3390/su151612451. URL https://www.mdpi.com/2071-1050/15/16/12451.  \n[4] Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Martinez-Maldonado, Guanliang Chen, Xinyu Li, Yueqiao Jin, and Dragan Gasević. Practical and ethical challenges of large language models in education: A systematic scoping review. British Journal of Educational Technology, 55(1):90–112, August 2023. ISSN 1467-8535. doi:10.1111/bjet.13370. URL http://dx.doi.org/10.1111/bjet.13370.  \n[5] Dao Xuan-Quy, Ngoc-Bich Le, Xuan-Dung Phan, and Bac-Bien Ngo. An evaluation of chatgpt's proficiency in english language testing of the Vietnamese national high school graduation examination. SSRN Electronic Journal, 06 2023. doi:10.2139/ssrn.4473369.  \n[6] H. Choi Jonathan, E. Hickman Kristin, Monahan Amy, and Schwarcz Daniel. Chatgpt goes to law school. Social Science Research Network, Jan 2023. doi:https://doi.org/10.2139/ssrn.4335905. URL https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4335905.  \n[7] Joost C. F. de Winter. Can chatgpt pass high school exams on english language comprehension? International Journal of Artificial Intelligence in Education, Sep 2023. doi:https://doi.org/10.1007/s40593-023-00372-z. URL https://link.springer.com/article/10.1007/s40593-023-00372-z.  \n[8] Dao Xuan-Quy and Ngoc-Bich Le. Llms' capabilities at the high school level in chemistry: Cases of chatgpt and microsoft bing ai chat. 06 2023. doi:10.26434/chemrxiv-2023-kxxpd.  \n[9] Kurdi Ghader, Jared Leo, Parsia Bijan, Sattler Uli, and Al-Emari Salam. A systematic review of automatic question generation for educational purposes. International Journal of Artificial Intelligence in Education, 30(1): 121-204, Nov 2019. doi:https://doi.org/10.1007/s40593-019-00186-y. URL https://link.springer.com/article/10.1007/s40593-019-00186-y.  \n[10] Katikapalli Subramanyam Kalyan. A survey of gpt-3 family large language models including chatgpt and gpt-4. Natural Language Processing Journal, 6:100048, 2024. ISSN 2949-7191. doi:https://doi.org/10.1016/j.nlp.2023.100048. URL https://www.sciencedirect.com/science/article/pii/S2949719123000456.  \n[11] Edisa Lozić and Benjamin Štular. Fluent but not factual: A comparative analysis of chatgpt and other ai chatbots' proficiency and originality in scientific writing for humanities. Future Internet, 15(10):336, October 2023. ISSN 1999-5903. doi:10.3390/fit15100336. URL http://dx.doi.org/10.3390/fit15100336.  \n[12] Partha Pratim Ray. Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. _Internet of Things and Cyber-Physical Systems_, 3:121-154, 2023. ISSN 2667-3452. doi:https://doi.org/10.1016/j.iotpcs.2023.04.003. URL https://www.sciencedirect.com/science/article/pii/S266734522300024X.  \n[13] Dave Ver Meer. Number of chatgpt users and key stats, March 2024. URL https://www.namepepper.com/chatgpt-users?fbclid=IwAR2XxzRq4ZVZ-SeVP_RqFMTOEnq_OhmMwnynX6HwK2IiJsXbqihFBs7G-ow#user-number. Online.  \n[14] Matuš Čavojský, Gabriel Bugar, Tomas Kormanik, and Martin Hasin. Exploring the capabilities and possible applications of large language models for education. pages 91–98, 10 2023. doi:10.1109/ICETA61311.2023.10344166.  \n[15] Nils Köbis and Luca D. Mossink. Artificial intelligence versus maya angelou: Experimental evidence that people cannot differentiate ai-generated from human-written poetry. Computers in Human Behavior, 114:106553, 2021. ISSN 0747-5632. doi:https://doi.org/10.1016/j.chb.2020.106553. URL https://www.sciencedirect.com/science/article/pii/S0747563220303034.  \n[16] Semere Kiros Bitew, Johannes Deleu, Chris Develder, and Thomas Demeester. Distractor generation for multiple-choice questions with predictive prompting and large language models, 2023.",
    "arxiv_id": null,
    "error_message": null,
    "embedding": [
      -1.328125,
      -0.21875,
      -4.25,
      -2.84375,
      -3.046875,
      1.765625,
      -2.1875,
      -0.72265625,
      3.078125,
      3.859375,
      0.390625,
      -0.2431640625,
      2.453125,
      0.357421875,
      1.4765625,
      1.4609375,
      -1.796875,
      -0.365234375,
      0.90625,
      -6.375,
      -0.4140625,
      5.625,
      -1.265625,
      -6.9375,
      5.53125,
      -6.1875,
      -1.859375,
      -0.1669921875,
      2.5,
      -0.9375,
      7.3125,
      -5.34375,
      1.1640625,
      0.1474609375,
      -2.46875,
      0.83203125,
      -2.0625,
      -1.484375,
      4.5,
      4.5625,
      -6.5625,
      1.109375,
      -0.494140625,
      1.1015625,
      0.1884765625,
      3.78125,
      3.96875,
      -1.7421875,
      -4.5625,
      -2.390625,
      -1.8984375,
      -3.453125,
      4.875,
      -0.34765625,
      4.125,
      -5.8125,
      -6.90625,
      8.25,
      -4.71875,
      0.36328125,
      1.046875,
      -3.25,
      5.84375,
      1.0390625,
      5.5625,
      3.3125,
      0.76953125,
      3.140625,
      -1.359375,
      1.71875,
      -0.455078125,
      1.546875,
      6.5625,
      -2.609375,
      7.96875,
      8.375,
      3.546875,
      5.625,
      -1.6953125,
      4.65625,
      -4.875,
      1.8203125,
      4.90625,
      1.8359375,
      5.46875,
      2.6875,
      1.0390625,
      0.10205078125,
      -4.34375,
      0.5,
      -3.3125,
      -0.328125,
      -4.65625,
      -0.82421875,
      -1.5390625,
      6.40625,
      -2.4375,
      -3.234375,
      -6.25,
      0.87890625,
      -1.9296875,
      -2.09375,
      3.171875,
      -6.71875,
      -2.96875,
      -4.34375,
      -2.578125,
      -6.5625,
      -2.21875,
      -1.953125,
      0.345703125,
      1.46875,
      0.042724609375,
      0.48046875,
      3.8125,
      -1.40625,
      2.484375,
      -4.15625,
      -6.40625,
      -0.453125,
      0.265625,
      -1.484375,
      -0.98046875,
      1.5703125,
      1.8515625,
      2.15625,
      -5.875,
      1.2890625,
      6.25,
      0.271484375,
      3.4375,
      -0.828125,
      6.21875,
      0.287109375,
      -7,
      -4.09375,
      -3.140625,
      3.28125,
      1.703125,
      6.625,
      -7.6875,
      1.578125,
      -1.546875,
      -5.625,
      3.3125,
      1.03125,
      -6.1875,
      0.77734375,
      4.875,
      -4.21875,
      -1.234375,
      1.9765625,
      3.84375,
      5,
      -0.10302734375,
      -4.625,
      4.5625,
      1.1796875,
      0.55859375,
      -0.28125,
      -2.03125,
      2.140625,
      -0.90234375,
      0.2392578125,
      -0.42578125,
      0.94921875,
      -6.375,
      -0.236328125,
      1.484375,
      -2.3125,
      1.3125,
      15.0625,
      3.328125,
      -2.40625,
      1.390625,
      2.765625,
      0.8125,
      7.25,
      0.353515625,
      0.330078125,
      1.3984375,
      0.96875,
      -5.625,
      5.34375,
      -2.890625,
      0.83984375,
      2.046875,
      -1.9609375,
      1.625,
      -2.5,
      0.78125,
      3.046875,
      0.75390625,
      -0.004608154296875,
      -6.625,
      0.10791015625,
      0.52734375,
      0.55078125,
      1.2421875,
      2.21875,
      -2.6875,
      -8.8125,
      -1.09375,
      -3.640625,
      -4.25,
      0.0625,
      0.76171875,
      -2.765625,
      1.7578125,
      -1.3828125,
      1.140625,
      -0.58984375,
      2.796875,
      2.734375,
      6.125,
      2.796875,
      4.5625,
      -0.08447265625,
      4.96875,
      0.703125,
      4.53125,
      3.203125,
      3.53125,
      -1.0625,
      -1.875,
      2.046875,
      3.375,
      4.9375,
      1.5703125,
      8.1875,
      0.78515625,
      1.828125,
      4.15625,
      -4.75,
      -2.734375,
      -0.96875,
      -3.953125,
      0.6953125,
      -0.74609375,
      -0.01348876953125,
      -2.625,
      -3.171875,
      1.1796875,
      2.90625,
      1.7109375,
      -0.5859375,
      -1.609375,
      -3.15625,
      -2.984375,
      -7.84375,
      0.240234375,
      3.484375,
      -6.875,
      -3.484375,
      2.78125,
      9.5625,
      1.484375,
      -1.7578125,
      0.92578125,
      -3.546875,
      3.71875,
      -4.9375,
      -4.625,
      1.7265625,
      2.265625,
      -5.6875,
      2.96875,
      -1.3671875,
      0.52734375,
      0.64453125,
      0.26953125,
      -2.046875,
      -4.71875,
      -1.453125,
      -4.375,
      4.90625,
      3.921875,
      -3.359375,
      2.296875,
      -3.4375,
      -5.21875,
      -11.625,
      5.21875,
      -4.1875,
      3.25,
      -0.279296875,
      0.56640625,
      2.375,
      -1.7890625,
      12.5,
      2.4375,
      1.4453125,
      2.640625,
      0.65234375,
      -4.09375,
      3.171875,
      -2.15625,
      1.234375,
      -8,
      0.51953125,
      5.5,
      2.03125,
      -3.109375,
      -0.78125,
      -2.96875,
      4.0625,
      -0.73828125,
      -4.15625,
      1.15625,
      1.2890625,
      -3.125,
      3.96875,
      7.8125,
      -1.0234375,
      3.28125,
      -4.5,
      -3.234375,
      1.375,
      0.291015625,
      -2.1875,
      -6.0625,
      -4.5625,
      -1.71875,
      -0.921875,
      -2.09375,
      -1.4296875,
      -0.59765625,
      1.7421875,
      5.875,
      -0.9375,
      2.4375,
      4.53125,
      -6.71875,
      -9.125,
      8.5,
      -0.287109375,
      2.078125,
      2.5,
      0.4140625,
      5.03125,
      0.0089111328125,
      -0.84375,
      2.0625,
      -3.21875,
      -2.625,
      0.06494140625,
      4.90625,
      -4.84375,
      -0.212890625,
      -6.75,
      3.453125,
      1.234375,
      -0.375,
      3.125,
      7.78125,
      -3.15625,
      1.15625,
      0.45703125,
      0.65625,
      0.1962890625,
      2.234375,
      -2.578125,
      6.03125,
      -1.3125,
      0.07177734375,
      -1.59375,
      -6.375,
      3.40625,
      -3.984375,
      -0.306640625,
      -1.1640625,
      -1.6484375,
      1.2734375,
      3.8125,
      2.015625,
      -0.71484375,
      0.427734375,
      -4.84375,
      -5.625,
      3.6875,
      -4.3125,
      0.796875,
      -1.359375,
      -1.640625,
      4.28125,
      0.83984375,
      1.40625,
      4.09375,
      0.84765625,
      -2.9375,
      -1.1875,
      0.46875,
      -4.46875,
      -0.37890625,
      2.71875,
      1.46875,
      -1.671875,
      1.46875,
      -0.64453125,
      -2.078125,
      5.46875,
      -0.349609375,
      1.265625,
      -2.734375,
      -4.65625,
      -0.357421875,
      1.6484375,
      -8.5,
      2.6875,
      3.484375,
      -1.78125,
      1.9296875,
      0.6640625,
      -0.1337890625,
      -1.1640625,
      4,
      -2.3125,
      3.015625,
      -6.21875,
      -0.62109375,
      -3,
      -1.53125,
      1.3359375,
      -1.203125,
      2.53125,
      -0.0556640625,
      1.7265625,
      6.4375,
      0.50390625,
      -1.734375,
      3.34375,
      2.234375,
      -2.859375,
      3.390625,
      -3.625,
      -5.0625,
      5.5,
      -2.203125,
      -3.546875,
      -0.01129150390625,
      3.453125,
      -1.9609375,
      5,
      4,
      -2.78125,
      -1.421875,
      3.6875,
      4.84375,
      -2.390625,
      -0.82421875,
      0.54296875,
      -0.87890625,
      0.20703125,
      1.5625,
      1.9609375,
      -0.1474609375,
      -4.34375,
      4.84375,
      2.5625,
      1.6484375,
      0.21484375,
      0.6953125,
      -0.9453125,
      4.09375,
      1.609375,
      0.451171875,
      -2.515625,
      1.9140625,
      6.6875,
      -6.09375,
      -9.5,
      4.0625,
      2.421875,
      1.2890625,
      -0.86328125,
      1.34375,
      2.953125,
      -0.87890625,
      -4.4375,
      -4.75,
      -1.7734375,
      -2.828125,
      3.921875,
      3.125,
      -1.6796875,
      -2.859375,
      -5.34375,
      4.375,
      -0.36328125,
      4,
      0.4296875,
      -1.125,
      1.53125,
      -4.46875,
      3.078125,
      3.15625,
      7.65625,
      -3.96875,
      -1.21875,
      0.95703125,
      -10.25,
      1.4296875,
      -1.3125,
      1.1796875,
      1.3046875,
      2.4375,
      5,
      -3.34375,
      -1.3671875,
      0.439453125,
      4.25,
      -3.40625,
      -1.6328125,
      2.984375,
      -5,
      -0.201171875,
      2.3125,
      1.21875,
      0.400390625,
      -4.40625,
      -2.4375,
      1.25,
      0.8515625,
      1.9375,
      0.16796875,
      -2.328125,
      -2.6875,
      -3.515625,
      3.515625,
      2.109375,
      1.2421875,
      1.734375,
      -0.11328125,
      -4.5,
      -2.140625,
      -0.21484375,
      0.796875,
      -0.96484375,
      -0.63671875,
      0.443359375,
      0.8125,
      2.421875,
      -5.625,
      -0.0196533203125,
      0.396484375,
      -0.2333984375,
      -6.3125,
      0.9296875,
      1.078125,
      3.125,
      0.3828125,
      2.234375,
      -2.234375,
      -0.890625,
      -0.11279296875,
      -4.1875,
      -5.625,
      -2.0625,
      4.625,
      -2.875,
      -0.1875,
      -2.359375,
      1.6796875,
      1.703125,
      0.484375,
      2.328125,
      -0.828125,
      6.375,
      -0.392578125,
      -0.08203125,
      0.1962890625,
      4.84375,
      -1.265625,
      1.3671875,
      2.828125,
      0.39453125,
      -7.5,
      -5.3125,
      -5.21875,
      1.8515625,
      6.6875,
      -0.88671875,
      5.125,
      -0.34375,
      4.375,
      -1.4609375,
      1.625,
      -15.6875,
      2.4375,
      -0.53125,
      -6.90625,
      -1.84375,
      0.640625,
      2.984375,
      0.05810546875,
      2.046875,
      1.609375,
      -0.8671875,
      1.1953125,
      6.125,
      2.203125,
      -3.3125,
      5.21875,
      2.984375,
      -0.67578125,
      1.75,
      -0.42578125,
      -4.75,
      0.5546875,
      -2.515625,
      1.515625,
      3.03125,
      3.6875,
      3.3125,
      0.7890625,
      2.390625,
      -5.40625,
      2.3125,
      2.015625,
      2.59375,
      -0.0380859375,
      -0.173828125,
      -5.21875,
      6.03125,
      -4.625,
      3.453125,
      -1.625,
      -5.125,
      1.0546875,
      2.734375,
      -1.3046875,
      -1.984375,
      -0.99609375,
      -1.78125,
      3.546875,
      3.03125,
      -5.84375,
      0.46484375,
      -2.53125,
      -2.21875,
      3.375,
      -0.734375,
      -2.578125,
      -3.3125,
      2.703125,
      2.53125,
      -2.40625,
      7.5625,
      -0.5234375,
      -2.828125,
      1.5546875,
      -0.322265625,
      0.62109375,
      -2.484375,
      -0.2109375,
      1.28125,
      -3.6875,
      -3.9375,
      3.6875,
      1.828125,
      -4.21875,
      -1.7265625,
      -1.34375,
      -0.5625,
      1.90625,
      -0.59375,
      -2.546875,
      -4.21875,
      -0.55078125,
      1.796875,
      1.3515625,
      3.125,
      0.9296875,
      3.625,
      4.625,
      -2.609375,
      5.375,
      -4.4375,
      -3.609375,
      1.5859375,
      -3.03125,
      -3.59375,
      -2.5625,
      -0.37109375,
      1.1875,
      -3.078125,
      -3.765625,
      -2.75,
      -6.75,
      -3.421875,
      0.87109375,
      0.703125,
      3.546875,
      -2.28125,
      5.09375,
      -1.640625,
      -3.875,
      0.796875,
      -1.5625,
      1.796875,
      -2.265625,
      1.125,
      -4.03125,
      -0.390625,
      5.09375,
      3.671875,
      -5.375,
      5.84375,
      0.12890625,
      -1.578125,
      -1.5,
      2.8125,
      -3.40625,
      -0.41796875,
      -0.030029296875,
      -1.921875,
      -2,
      -3.53125,
      1.109375,
      -1.265625,
      3.78125,
      -0.330078125,
      0.26171875,
      -2.734375,
      -3.96875,
      -1.2265625,
      0.546875,
      -5.28125,
      3.09375,
      2.984375,
      0.400390625,
      1.3125,
      3.734375,
      4.1875,
      2.53125,
      0.0712890625,
      -1.921875,
      3.765625,
      3.3125,
      6,
      -3.03125,
      -5.375,
      -0.326171875,
      0.90234375,
      -2.90625,
      3.46875,
      -0.2294921875,
      1.7578125,
      3.796875,
      3.53125,
      -4.25,
      -2.234375,
      4.71875,
      -3.84375,
      0.2294921875,
      3.578125,
      2.40625,
      -0.28515625,
      5.71875,
      -1.53125,
      -5.46875,
      -2.03125,
      3.9375,
      3.140625,
      0.3671875,
      -0.94140625,
      2.53125,
      -0.302734375,
      5.09375,
      -2.25,
      -4.90625,
      2.609375,
      2.046875,
      -3.109375,
      0.74609375,
      6.46875,
      -0.93359375,
      2.203125,
      -0.76953125,
      1.1171875,
      1.484375,
      2.171875,
      2.625,
      0.71875,
      2.703125,
      0.140625,
      2.15625,
      0.69140625,
      -0.7890625,
      -3.828125,
      1.25,
      -0.03515625,
      -1.7421875,
      3.1875,
      -2.984375,
      -1.484375,
      -0.84375,
      0.447265625,
      0.88671875,
      3,
      6.625,
      -0.35546875,
      0.46484375,
      -0.7265625,
      4.625,
      -2.015625,
      5.71875,
      1.8046875,
      9.125,
      -2.171875,
      -3.171875,
      0.275390625,
      -2.21875,
      0.337890625,
      -2.375,
      -7.15625,
      -3.015625,
      -2.15625,
      -0.55078125,
      -3.125,
      2.109375,
      -3.875,
      -0.193359375,
      3.796875,
      1.359375,
      2.890625,
      3.578125,
      3.84375,
      -1.9296875,
      -0.59765625,
      -2.5,
      -2.46875,
      -1.0546875,
      0.6640625,
      0.76953125,
      -3.0625,
      0.330078125,
      1.2265625,
      5.5625,
      0.8828125,
      -0.49609375,
      -0.19140625,
      9.25,
      -0.0274658203125,
      0.546875,
      4.09375,
      0.765625,
      1.6015625,
      3.203125,
      3.859375,
      -3.71875,
      -4.1875,
      9.5,
      6.34375,
      -2.875,
      0.53515625,
      -0.045654296875,
      0.69921875,
      -5.625,
      -1.578125,
      2.40625,
      0.92578125,
      -5.4375,
      -1.8359375,
      3.015625,
      2.640625,
      -3.421875,
      1.015625,
      -1.1640625,
      -5.65625,
      3.21875,
      3.96875,
      1.6484375,
      2.40625,
      1.140625,
      4.40625,
      -0.99609375,
      -4.3125,
      -4.125,
      -0.53515625,
      -2.03125,
      -1.359375,
      0.953125,
      2.515625,
      4.0625,
      -1.2890625,
      0.65234375,
      -5.03125,
      -0.703125,
      -2.59375,
      1.8046875,
      2.640625,
      -3.828125,
      -0.02587890625,
      -2.4375,
      -8.875,
      -4.34375,
      -0.400390625,
      -3.15625,
      -1.3203125,
      -3.4375,
      -0.283203125,
      3.265625,
      -6.21875,
      -0.6875,
      -3.0625,
      -2.8125,
      3.03125,
      0.12158203125,
      0.83984375,
      -2.265625,
      1.640625,
      0.90625,
      -2.96875,
      2.59375,
      4.25,
      4.09375,
      3.3125,
      -2.296875,
      2.59375,
      -2.21875,
      7.15625,
      -1.921875,
      7.40625,
      3.703125,
      3.265625,
      -7.125,
      2.046875,
      0.2021484375,
      3.125,
      -5.03125,
      -1.59375,
      -2.734375,
      -1.3203125,
      0.49609375,
      -1.4296875,
      3.6875,
      -3.296875,
      -1.8359375,
      0.44921875,
      -3.140625,
      1.0859375,
      3.234375,
      2.796875,
      5.375,
      -1.4609375,
      0.69921875,
      0.48828125,
      1.6484375,
      3.4375,
      -2,
      3.90625,
      -3.453125,
      0.1767578125,
      -3.78125,
      1.703125,
      -1.3125,
      -1.375,
      0.12451171875,
      -1.4453125,
      0.419921875,
      2.25,
      1.21875,
      6.09375,
      1.640625,
      3.640625,
      0.515625,
      -2.4375,
      -0.0751953125,
      -0.419921875,
      7.375,
      1.5625,
      -1.3046875,
      -2.84375,
      -0.83203125,
      -3.59375,
      2.265625,
      -1.7109375,
      -6.8125,
      -0.11328125,
      0.07275390625,
      -7.25,
      3.4375,
      -1.1953125,
      -0.365234375,
      0.62109375,
      4.71875,
      2.671875,
      2.921875,
      -0.439453125,
      1.203125,
      0.423828125,
      -1.8828125,
      5.03125,
      -3.921875,
      0.55078125,
      6.3125,
      3.546875,
      3.328125,
      -4,
      -0.8515625,
      -1.5078125,
      1.5546875,
      5.4375,
      -2.25,
      -1.3203125,
      7.40625,
      0.05126953125,
      1.03125,
      -0.21484375,
      0.353515625,
      -0.64453125,
      -2.90625,
      1.34375,
      3.46875,
      3.75,
      -0.6640625,
      -1.3125,
      -6.8125,
      -0.76953125,
      -3.296875,
      -1.4921875,
      -2.203125,
      0.2158203125,
      -0.6875,
      0.18359375,
      -1.765625,
      -3,
      -0.6015625,
      -1.5625,
      0.1865234375,
      4.59375,
      0.37890625,
      0.416015625,
      -0.58984375,
      4.28125,
      -2.796875,
      4.125,
      1.3203125,
      -2.734375,
      2.171875,
      3.875,
      -4.4375,
      4.40625,
      6.4375,
      -1.015625,
      -0.109375,
      -2.9375,
      0.58984375,
      -1.2265625,
      -3.296875,
      0.7421875,
      -3.40625,
      1.234375,
      5.25,
      3.421875,
      -1.40625,
      1.015625,
      -1.15625,
      -0.1611328125,
      4.03125,
      -7,
      -2.578125,
      -1.6171875,
      -1.453125,
      -1.7734375,
      -1.578125,
      -2.796875,
      0.072265625,
      3.359375,
      -5.65625,
      4.90625,
      -4.375,
      6.6875,
      0.54296875,
      -2.71875,
      -0.287109375,
      -3.125,
      2.359375,
      -1.84375,
      2.671875,
      2.59375,
      -2.484375,
      3.6875,
      -0.5,
      -2.21875,
      -0.1455078125,
      -1.0234375,
      3.03125,
      0.291015625,
      2,
      0.1142578125,
      -0.65625,
      -5.625,
      -3.6875,
      -3.96875,
      -2.71875,
      -0.10205078125,
      1.4453125,
      0.04541015625,
      -0.8125,
      1.4453125,
      -2.515625,
      -0.2421875,
      -3.015625,
      -1.546875,
      0.85546875,
      1.171875,
      6.875,
      1.3828125,
      -0.3359375,
      1.2109375,
      -2.421875,
      -7.34375,
      -0.4140625,
      -1.7578125,
      2.28125,
      -1.3515625,
      -0.06103515625,
      1.3515625,
      1.34375,
      -1.140625,
      0.412109375,
      -0.59375,
      4.65625,
      4.3125,
      -0.765625,
      2.75,
      -0.004058837890625,
      0.8125,
      -3.78125,
      -3.765625,
      -5.90625,
      1.125,
      0.8671875,
      -5.03125,
      1.609375,
      -2.671875,
      1.2421875,
      2.6875,
      -3.453125,
      0.8125,
      -0.0673828125,
      2.5625,
      -1.8125,
      -2.46875,
      1.8203125,
      -2.15625,
      3.203125,
      -2.765625,
      -4.9375,
      -1.25,
      1.2734375,
      -0.71875,
      0.298828125,
      -1.78125,
      -2.3125,
      -1.390625,
      -0.408203125,
      -3.796875,
      -3.046875,
      3.046875,
      0.1708984375,
      2.65625,
      1.0625,
      -0.91796875,
      -0.75390625,
      0.4140625,
      1.8359375,
      6.875,
      1.1328125,
      -1.3125,
      0.384765625,
      -0.10986328125,
      4.90625,
      -1.7265625,
      -1.2421875,
      -6.53125,
      -3.109375,
      6.3125,
      -0.462890625,
      -2.34375,
      -0.19140625,
      -0.98046875,
      4.25,
      0.5703125,
      4,
      -1.40625,
      -0.080078125,
      -1.6171875,
      6.46875,
      2.328125,
      -4.34375,
      1.3125,
      2.6875,
      -5.03125,
      2.34375,
      4.15625,
      5.59375,
      -0.73046875,
      3.4375,
      -4.6875,
      -5.25,
      -5.8125,
      4.125,
      0.265625,
      -0.5,
      -1.0390625,
      -2.765625,
      -1.546875,
      1.296875,
      -0.283203125,
      3.34375,
      -4.4375,
      4.71875,
      0.412109375,
      2.875,
      1.0625,
      -3.96875,
      -2.53125,
      4.21875,
      2.734375,
      -3.59375,
      -1.46875,
      -4.03125,
      -2.3125,
      -0.890625,
      -7.21875,
      1.1875,
      0.396484375,
      1.2734375,
      5.03125,
      -0.1572265625,
      5,
      0.65625,
      -1.765625,
      -4.25,
      -1.5390625,
      1.1875,
      3.171875,
      2.15625,
      -3.46875,
      -0.828125,
      -1.6953125,
      0.76171875,
      -4.5625,
      4.875,
      -2.09375,
      3.890625,
      2.546875,
      1.5390625,
      -4.875,
      -2.453125,
      -1.703125,
      -0.353515625,
      -1.8203125,
      1.953125,
      0.8359375,
      -1.4609375,
      3.890625,
      0.71484375,
      -4.03125,
      0.263671875,
      -1.5078125,
      1.46875,
      2.234375,
      2.6875,
      -4.59375,
      2.734375,
      -6.28125,
      0.267578125,
      3.6875,
      -2.25,
      -1.296875,
      1.2265625,
      -0.189453125,
      3.75,
      1.8828125,
      0.427734375,
      -1.046875,
      4.125,
      -1.6328125,
      -3.1875,
      -4.90625,
      -0.625,
      -1.84375,
      -1.546875,
      3.828125,
      -6.375,
      3.53125,
      -2.78125,
      -5.1875,
      -0.439453125,
      -1.5703125,
      -0.166015625,
      3.765625,
      2.953125,
      -2.8125,
      -1.828125,
      -3.375,
      3.984375,
      2.171875,
      -3.0625,
      1.875,
      -0.52734375,
      0.78515625,
      -4.53125,
      3.859375,
      -0.9296875,
      -2.34375,
      3.78125,
      6,
      -5.34375,
      -1.765625,
      1.4609375,
      2.234375,
      -2.84375,
      -1.3671875,
      0.78125,
      5.15625,
      -3.453125,
      -0.26953125,
      -2.875,
      -1.1484375,
      2.5,
      -2.3125,
      -0.0576171875,
      1.34375,
      1.21875,
      -1.6171875,
      -2.984375,
      4.15625,
      3.609375,
      3.71875,
      -3.5625,
      0.75390625,
      1.5546875,
      0.47265625,
      2.5,
      -0.482421875,
      -3.25,
      -1.1484375,
      2.65625,
      -3.9375,
      -1.734375,
      -5.65625,
      -0.376953125,
      -2.671875,
      -0.82421875,
      -0.5390625,
      0.8125,
      -0.400390625,
      -1.7578125,
      -0.2099609375,
      -0.8359375,
      -4.4375,
      -2.953125,
      1.296875,
      -1.4140625,
      -5.46875,
      2.109375,
      2.484375,
      1.9453125,
      5.09375,
      4.625,
      1.3828125,
      -5.09375,
      2.90625,
      -2.296875,
      1.765625,
      -1.484375,
      -0.00634765625,
      -4.09375,
      -2.171875,
      3.15625,
      1.0078125,
      2.65625,
      -5.125,
      -4.40625,
      -5.53125,
      0.83984375,
      -3.296875,
      3.8125,
      -1.203125,
      2,
      4.3125,
      -0.578125,
      2.640625,
      0.57421875,
      -0.259765625,
      -7.40625,
      1.3046875,
      0.8359375,
      4.71875,
      3.046875,
      0.48828125,
      -5.3125,
      4.21875,
      2.15625,
      -3.953125,
      3.5625,
      0.1796875,
      1.3359375,
      -5.1875,
      2.78125,
      -0.02197265625,
      3.265625,
      -1.359375,
      2.515625,
      4.625,
      0.7109375,
      4.8125,
      3.59375,
      0.11474609375,
      -1.515625,
      3.03125,
      0.58984375,
      -4.78125,
      -1.15625,
      2.1875,
      -2.328125,
      -0.2138671875,
      2.546875,
      -0.054443359375,
      4.5625,
      -0.625,
      1.078125,
      0.027099609375,
      4.90625,
      -6.53125,
      1.6953125,
      -6.375,
      2.15625,
      -3.6875,
      1.3671875,
      -5.3125,
      0.56640625,
      2.6875,
      4.375,
      -1.2109375,
      -4.15625,
      2.84375,
      2.5,
      2.28125,
      -3.984375,
      3.15625,
      1.828125,
      -1.515625,
      -2.390625,
      -2.3125,
      4.28125,
      -0.50390625,
      1.921875,
      -4.84375,
      -0.314453125,
      0.07373046875,
      -2.21875,
      -3.015625,
      2.328125,
      -0.8046875,
      -7.0625,
      -5.5,
      -3.296875,
      0.23828125,
      -3.0625,
      2.359375,
      3.546875,
      -1.578125,
      1.5078125,
      -2.984375,
      4.09375,
      1.1875,
      -1.6328125,
      0.349609375,
      1.1015625,
      -1.3359375,
      -0.236328125,
      3.4375,
      -4.53125,
      -0.9375,
      -0.73828125,
      -0.10205078125,
      3.765625,
      -2.28125,
      -2.53125,
      -5.59375,
      -1.375,
      3.53125,
      3.0625,
      -1.3984375,
      -2.9375,
      2.390625,
      -0.59765625,
      -0.91796875,
      -0.89453125,
      0.7265625,
      0.36328125,
      -0.3515625,
      0.2138671875,
      -0.091796875,
      3.984375,
      0.283203125,
      1.734375,
      -0.8125,
      -1.4453125,
      -2.90625,
      -0.9921875,
      -3.921875,
      1.8984375,
      -0.6484375,
      3.328125,
      0.8515625,
      -1.390625,
      0.37890625,
      3.796875,
      2.59375,
      1.96875,
      -3.0625,
      0.41796875,
      5.5,
      5.1875,
      0.52734375,
      -1.3125,
      0.89453125,
      1.2109375,
      -2.3125,
      -0.419921875,
      -0.5546875,
      0.63671875,
      2.8125,
      -5.75,
      -0.796875,
      0.333984375,
      1.9453125,
      -1.921875,
      -9.3125,
      2.71875,
      0.1279296875,
      0.34375,
      -3.65625,
      0.92578125,
      3.953125,
      2.890625,
      1.1328125,
      2.625,
      2.90625,
      -0.3671875,
      2.75,
      20.625,
      -2.796875,
      -3.40625,
      2.078125,
      -2.65625,
      2.71875,
      6.125,
      1.1640625,
      -0.65625,
      1.953125,
      0.298828125,
      2.234375,
      -0.51171875,
      6.3125,
      -0.06201171875,
      2.5625,
      3.046875,
      1.4609375,
      -1.8828125,
      -5.1875,
      1.3671875,
      0.44921875,
      -0.333984375,
      2.21875,
      -3.34375,
      1.90625,
      2.28125,
      -1.0859375,
      -2.53125,
      -5.0625,
      -0.375,
      -0.57421875,
      1.1953125,
      -2.25,
      0.72265625,
      -2.59375,
      -0.74609375,
      1.96875,
      1.1953125,
      -0.95703125,
      -1.5234375,
      -2.8125,
      2.734375,
      -0.349609375,
      0.0242919921875,
      0.302734375,
      -2.140625,
      0.0174560546875,
      1.1015625,
      3.53125,
      -0.462890625,
      -3.734375,
      -1.9765625,
      1.3828125,
      1.046875,
      -2.15625,
      -2.84375,
      -6.125,
      -5.15625,
      -0.6171875,
      -1.1328125,
      -2.921875,
      -0.8984375,
      -3.15625,
      -2.21875,
      -3.875,
      -5.34375,
      -1.875,
      -2.578125,
      0.3984375,
      -7.1875,
      -1.7578125,
      5.75,
      5.625,
      -3.34375,
      -2.6875,
      0.279296875,
      2.21875,
      -0.396484375,
      3.71875,
      -3.953125,
      -1.3359375,
      -3.265625,
      0.384765625,
      -2.234375,
      1.046875,
      -6.03125,
      0.71484375,
      0.1396484375,
      -0.875,
      3.6875,
      -3.890625,
      1.9765625,
      -0.62109375,
      -5.1875,
      1.0859375,
      2.359375,
      0.0810546875,
      -2.515625,
      0.498046875,
      2.703125,
      0.65625,
      1.109375,
      -1.7578125,
      1.34375,
      -2.140625,
      3,
      0.0068359375,
      1.1484375,
      1.921875,
      -2.328125,
      5.09375,
      -0.45703125,
      -2.015625,
      1.4453125,
      4.5,
      -6,
      -3.375,
      -0.359375,
      -4.09375,
      2.8125,
      -0.181640625,
      0.0086669921875,
      0.25390625,
      -10.4375,
      -6,
      -0.275390625,
      -5.84375,
      3.1875,
      -3.03125,
      2.390625,
      -0.302734375,
      -2.46875,
      -4.25,
      0.75390625,
      -3.265625,
      4.4375,
      5.71875,
      0.84375,
      0.59375,
      -4.5625,
      2.1875,
      1.7421875,
      -2.4375,
      -1.6640625,
      2.734375,
      0.28125,
      3.109375,
      3.921875,
      1.1171875,
      -0.337890625,
      3.078125,
      0.390625,
      -3.125,
      -1.125,
      4.03125,
      -2.75,
      -1.71875,
      -2.578125,
      -0.890625,
      -0.6484375,
      0.025390625,
      -4.15625,
      -3.65625,
      -1.09375,
      -1.5,
      3.734375,
      -3.109375,
      -6.53125,
      3.703125,
      2.046875,
      -3.703125,
      0.2255859375,
      -1.2890625,
      3.296875,
      -2.8125,
      2,
      4.96875,
      -3.9375,
      1.109375,
      2.78125,
      4.09375,
      -0.09375,
      -5.5,
      2.15625,
      5.21875,
      -4.5,
      1.6015625,
      4.6875,
      -1.34375,
      1.8828125,
      -4.21875,
      -6.71875,
      5.75,
      2.5625,
      -4.375,
      -0.828125,
      -2.09375,
      0.6875,
      -3,
      -3.34375,
      2.203125,
      -0.67578125,
      2.296875,
      4.65625,
      0.65625,
      -3.96875,
      -2.15625,
      -2.21875,
      -1.1953125,
      -1.90625,
      4.03125,
      0.25390625,
      3.140625,
      -5.625,
      5.1875,
      3.359375,
      1.3828125,
      0.45703125,
      2.015625,
      3.328125,
      0.3125,
      -2.796875,
      -1,
      0.85546875,
      3.078125,
      -3.390625,
      1.546875,
      -3.25,
      2.171875,
      -1.875,
      2.09375,
      0.59375,
      1.3984375,
      -4.53125,
      -2.65625,
      -4.34375,
      3.1875,
      -0.2177734375,
      1.640625,
      2.109375,
      -0.091796875,
      0.004058837890625,
      1.09375,
      -1.4453125,
      1.046875,
      -0.6015625,
      1.625,
      1.109375,
      -1.65625,
      0.66796875,
      2.546875,
      3.046875,
      -1.421875,
      -0.58203125,
      -2.328125,
      -3.078125,
      0.5703125,
      -5.5,
      -1.203125,
      0.80859375,
      -5.5,
      3.28125,
      0.73046875,
      1.390625,
      -0.333984375,
      1.515625,
      -6.3125,
      6,
      2.59375,
      -5.59375,
      3.5,
      -1.546875,
      -3.4375,
      -0.15625,
      -1.453125,
      1.5,
      -5.1875,
      1.0234375,
      4.6875,
      -3.765625,
      2.3125,
      3.3125,
      -2.015625,
      -0.40625,
      -2.796875,
      4.84375,
      2.328125,
      4.71875,
      2.015625,
      2.515625,
      4.65625,
      -4.40625,
      2.25,
      -4.84375,
      -0.004852294921875,
      -2.140625,
      2.359375,
      -0.8515625,
      -3.171875,
      1.21875,
      4.1875,
      1.640625,
      -9.4375,
      -4.65625,
      0.056884765625,
      -2.46875,
      4.75,
      3.21875,
      0.6796875,
      -2.625,
      0.294921875,
      3.890625,
      3.265625,
      1,
      -1.40625,
      -3.25,
      0.447265625,
      1.9453125,
      -6.78125,
      1.0078125,
      -0.71875,
      -4.5,
      -1,
      -2.421875,
      -3.515625,
      -0.1513671875,
      6.3125,
      -3.328125,
      0.8359375,
      1.8359375,
      1.359375,
      3.40625,
      2.875,
      1.09375,
      1.6328125,
      -5.5,
      -8.75,
      -2.4375,
      -0.3046875,
      -0.5625,
      2.03125,
      -1.3203125,
      3.640625,
      -0.8046875,
      2.953125,
      -4.84375,
      5.53125,
      1.9375,
      -7.53125,
      3.140625,
      -1.9765625,
      -0.3125,
      -2.90625,
      -3.0625,
      -1.1875,
      1.625,
      1.1484375,
      -1.828125,
      3.171875,
      0.8671875,
      0.96875,
      1.9921875,
      -4.4375,
      -1.3359375,
      0.7578125,
      2.546875,
      -2.640625,
      4.1875,
      4.46875,
      -0.34375,
      -2.34375,
      -0.96875,
      3.453125,
      -0.0859375,
      -3.984375,
      4.21875,
      1.3125,
      -0.486328125,
      -0.271484375,
      -3.5,
      0.1533203125,
      -0.1513671875,
      -1.265625,
      0.90234375,
      -0.4296875,
      0.703125,
      -1.234375,
      -0.162109375,
      1.5,
      -1.0234375,
      -2.328125,
      -1.421875,
      -1.1015625,
      0.365234375,
      4.09375,
      -0.35546875,
      -2.640625,
      -2.265625,
      3.34375,
      1.1875,
      -1.4453125,
      -4.09375,
      0.5625,
      -1.9375,
      -3.1875,
      -3.578125,
      1.390625,
      -1.5546875,
      -2.46875,
      -0.486328125,
      -1.1796875,
      -0.01458740234375,
      -4.4375,
      -1.3828125,
      3.265625,
      1.2734375,
      -2.890625,
      -0.294921875,
      -0.7265625,
      -0.11181640625,
      1.0390625,
      -3.640625,
      -0.41796875,
      -0.19140625,
      1.859375,
      -5.53125,
      -3.90625,
      2.8125,
      -2.21875,
      2.125,
      5.125,
      0.63671875,
      1.296875,
      2.953125,
      -3.109375,
      -2.40625,
      5.90625,
      2.4375,
      -1.609375,
      1.8359375,
      0.7578125,
      -2.25,
      5.0625,
      6.75,
      -3.15625,
      -2.859375,
      -1.0625,
      -1.6171875,
      -0.9609375,
      -2.015625,
      1.3203125,
      -0.0081787109375,
      -5.71875,
      6.6875,
      -3.359375,
      3.75,
      1.3203125,
      -1.9140625,
      4.375,
      -1.109375,
      0.578125,
      0.55859375,
      0.72265625,
      4.1875,
      -6.25,
      1.8671875,
      -4.375,
      -3.078125,
      -0.283203125,
      0.36328125,
      2.28125,
      1.8203125,
      4.125,
      0.99609375,
      -2.03125,
      -4.5625,
      -0.83984375,
      5.15625,
      -0.671875,
      -4.03125,
      1.09375,
      -4.03125,
      0.2451171875,
      -1.421875,
      0.921875,
      -4.03125,
      -1.265625,
      -2.4375,
      1.4453125,
      3.359375,
      0.482421875,
      -2.921875,
      -1.640625,
      -2.234375,
      2.71875,
      3.796875,
      0.40234375,
      0.984375,
      3.75,
      0.208984375,
      0.1103515625,
      7.625,
      3.859375,
      1.625,
      -1.6875,
      1,
      0.828125,
      1.90625,
      -1.7734375,
      -0.4453125,
      1.5234375,
      3.546875,
      5.21875,
      -2.15625,
      1.46875,
      -0.79296875,
      0.80859375,
      -2.21875,
      -0.7109375,
      -0.058349609375,
      1.828125,
      -0.859375,
      2.03125,
      -0.043212890625,
      2.40625,
      0.1875,
      -0.81640625,
      -2.921875,
      -1.4453125,
      -1.8671875,
      1.5546875,
      -0.8671875,
      -0.8984375,
      -1.203125,
      0.1279296875,
      2.65625,
      0.30078125,
      -4.375,
      2.140625,
      1.7265625,
      -1.171875,
      4.96875,
      -2.234375,
      0.06689453125,
      2.296875,
      0.0311279296875,
      -1.1328125,
      3.5,
      -2.578125,
      2.28125,
      -0.671875,
      -0.380859375,
      2.453125,
      2.796875,
      0.2158203125,
      1.3125,
      -1.609375,
      0.70703125,
      1.921875,
      -1.2109375,
      -1.328125,
      -3.234375,
      2.109375,
      -1.734375,
      -1.234375,
      -0.306640625,
      0.9296875,
      -1.96875,
      1.5,
      -2.21875,
      -2.78125,
      -0.60546875,
      -3.078125,
      0.97265625,
      0.0264892578125,
      3.546875,
      1.6796875,
      1.1953125,
      -0.458984375,
      -2.28125,
      -2.953125,
      -0.341796875,
      -2.1875,
      -1.359375,
      -0.12890625,
      1.0703125,
      -0.73828125,
      2.890625,
      0.251953125,
      -0.93359375,
      -2.140625,
      0.82421875,
      -0.2275390625,
      1.875,
      0.435546875,
      -0.1806640625,
      1.5,
      0.447265625,
      1.015625,
      1.6875,
      -0.1650390625,
      -0.322265625,
      0.59375,
      0.94921875,
      1.46875,
      1.5,
      -1.53125,
      0.4609375,
      1.4296875,
      -1.2890625,
      0.51171875,
      2.140625,
      1.1484375,
      0.0322265625,
      -2.25,
      2.3125,
      -1.328125,
      -0.1220703125,
      2.28125,
      1.40625,
      -4.1875,
      -0.8828125,
      -0.72265625,
      -1.7734375,
      -0.65625,
      -2.140625,
      -1.2109375,
      0.98828125,
      -2.828125,
      0.6328125,
      3.484375,
      3.21875,
      -2.0625,
      1.109375,
      1.96875,
      -3.640625,
      -1.921875,
      0.5078125,
      0.35546875,
      1.2421875,
      -2.609375,
      -4.25,
      -0.76171875,
      -0.20703125,
      0.8359375,
      0.9609375,
      -0.91015625,
      -1.859375,
      -1.25,
      2.859375,
      0.380859375,
      -5.875,
      -0.294921875,
      -0.85546875,
      0.62890625,
      2.171875,
      1.484375,
      1.7578125,
      2.53125,
      -1.3203125,
      1.125,
      -0.82421875,
      -1.4453125,
      -0.019775390625,
      2.34375,
      -2.0625,
      -3.96875,
      0.447265625,
      -2.921875,
      -0.796875,
      -0.86328125,
      0.94921875,
      0.439453125,
      1.15625,
      0.64453125,
      -0.51953125,
      -1.9921875,
      1.1015625,
      -0.45703125,
      0.490234375,
      0.67578125,
      3.046875,
      4.03125,
      2.390625,
      1.3125,
      0.1640625,
      -0.8515625,
      0.0186767578125,
      -0.69140625,
      1.203125,
      -0.1474609375,
      -4.8125,
      0.78515625,
      2.359375,
      2.015625,
      2.96875,
      -0.5390625,
      1.8828125,
      1.5390625,
      -3.796875,
      2.84375,
      3.359375,
      2.21875,
      -0.50390625,
      0.22265625,
      -0.8828125,
      -0.78515625,
      -0.494140625,
      1.9375,
      -1.953125,
      1.5703125,
      -0.84375,
      -1.8359375,
      -0.11865234375,
      -0.21875,
      4.8125,
      1.3359375,
      1.3203125,
      -1.4765625,
      3.734375,
      -3.265625,
      1.0390625,
      -0.18359375,
      0.7734375,
      -1.4921875,
      2.765625,
      -3.140625,
      0.267578125,
      0.7265625,
      1.9296875,
      1.15625,
      0.34375,
      -0.58203125,
      -2.609375,
      -2.4375,
      1.078125,
      -2.234375,
      0.92578125,
      3.609375,
      1.7890625,
      -0.474609375,
      -0.2255859375,
      -2.625,
      -0.67578125,
      0.953125,
      2.28125,
      0.1572265625,
      2.515625,
      -0.2080078125,
      1.8203125,
      -1.1796875,
      -0.51953125,
      -1.46875,
      -1.1171875,
      -2,
      2.171875,
      2.671875,
      -0.4765625,
      -1.0546875,
      -1,
      -0.25390625,
      5.03125,
      -0.60546875,
      -1.125,
      2.21875,
      -1.0703125,
      -2.1875,
      -1.8671875,
      -1.96875,
      0.66796875,
      2.109375,
      3.875,
      -0.72265625,
      4.40625,
      -2.484375,
      -1.8125,
      1.53125,
      -1.1875,
      -2.65625,
      -3.109375,
      -1.703125,
      3,
      0.33984375,
      0.3984375,
      1.453125,
      4.15625,
      -0.08203125,
      0.98046875,
      -2.078125,
      1.5234375,
      3.875,
      -0.034912109375,
      -5.4375,
      0.22265625,
      -0.90234375,
      2.046875,
      1.15625,
      -0.7265625,
      1.515625,
      4.34375,
      1.359375,
      1.4609375,
      -0.302734375,
      -0.384765625,
      -0.427734375,
      2.078125,
      4.15625,
      -3.734375,
      2.453125,
      0.048583984375,
      -3.046875,
      -1.1015625,
      2.75,
      3.078125,
      -0.75390625,
      2.46875,
      0.53515625,
      1.1328125,
      -1.5078125,
      1.46875,
      1.3359375,
      1.4140625,
      -0.609375,
      -1.0234375,
      -0.953125,
      1.796875,
      -3.53125,
      3.46875,
      -1.8828125,
      -0.60546875,
      1.484375,
      -0.404296875,
      0.95703125,
      1.6796875,
      -1.0859375,
      5.8125,
      -2.1875,
      -1.34375,
      2.671875,
      -1.375,
      0.65625,
      1.328125,
      0.9140625,
      -1.046875,
      3.9375,
      0.396484375,
      -3.171875,
      0.6171875,
      -0.75390625,
      -1.2109375,
      0.92578125,
      -4.875,
      0.35546875,
      -0.35546875,
      3.671875,
      -1.2890625,
      1.4140625,
      5.40625,
      1.703125,
      1.9140625,
      2.578125,
      1.46875,
      1.78125,
      -2.390625,
      -2.015625,
      1.9765625,
      -2.28125,
      -1.8203125,
      -0.8828125,
      0.291015625,
      -2.15625,
      -4.625,
      0.02783203125,
      -0.2421875,
      -0.051513671875,
      -1.2734375,
      -3.109375,
      -1.171875,
      1.1015625,
      -2.4375,
      0.15234375,
      -1.7578125,
      -0.96875,
      -0.06591796875,
      -1.3046875,
      -0.0201416015625,
      1.7109375,
      1.28125,
      0.4140625,
      0.279296875,
      -0.8828125,
      0.416015625,
      0.0830078125,
      -2.125,
      1.25,
      4.46875,
      -2.71875,
      -0.30859375,
      -1.109375,
      1.1640625,
      -0.90625,
      0.1025390625,
      -0.546875,
      -2.109375,
      2.71875,
      3.171875,
      1.2421875,
      0.203125,
      0.41015625,
      0.3515625,
      -1.6171875,
      -2.15625,
      0.54296875,
      -1.734375,
      1.1328125,
      2.09375,
      0.11962890625,
      1.859375,
      -2.5,
      0.65234375,
      1.0546875,
      -4.46875,
      0.59765625,
      -1.9296875,
      0.01953125,
      0.34765625,
      1.5390625,
      -2.046875,
      -2.5625,
      1.671875,
      -4.78125,
      1.2265625,
      -2.25,
      -2.921875,
      0.19140625,
      1.6328125,
      -0.10595703125,
      3.640625,
      -2.734375,
      0.85546875,
      5.46875,
      4.71875,
      1.6171875,
      0.578125,
      -3.734375,
      0.79296875,
      -2.859375,
      1.5234375,
      -4.71875,
      -2.390625,
      1.0234375,
      -0.482421875,
      -0.765625,
      0.83984375,
      1.6796875,
      -0.72265625,
      -1.8046875,
      -0.9921875,
      2.3125,
      -0.20703125,
      -1.8671875,
      2.828125,
      -1.390625,
      -0.30078125,
      -3.953125,
      -1.5234375,
      0.7734375,
      2.859375,
      0.90625,
      -0.421875,
      1.3984375,
      -0.61328125,
      2.21875,
      -1.9375,
      0.8125,
      1.734375,
      -1.203125,
      -1.9296875,
      -2.515625,
      -1.8828125,
      -1.2109375,
      -1.984375,
      1.828125,
      -0.765625,
      -0.96875,
      2.96875,
      -0.875,
      -3.3125,
      -2.4375,
      1.859375,
      -0.07275390625,
      0.71484375,
      0.271484375,
      -1.40625,
      2.5625,
      -0.92578125,
      1.25,
      -0.39453125,
      1.3203125,
      -0.51953125,
      0.609375,
      -2.125,
      -2.75,
      -3.1875,
      -0.197265625,
      1.71875,
      2.65625,
      1.0390625,
      -0.8046875,
      2.578125,
      2.4375
    ],
    "summary": "通过设计交互式提示模式优化ChatGPT生成高等教育测验题目，并采用盲测调查法让利益相关者（讲师与学习者）对生成题目质量进行评估。",
    "structure": {
      "sections": [
        {
          "title": "AchatGPT-BASED APPROACH FOR QUESTIONS GENERATION IN HIGHER EDUCATION",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 47
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 53
        },
        {
          "title": "2 Related works",
          "level": 1,
          "start_line": 68
        },
        {
          "title": "3 Research design",
          "level": 1,
          "start_line": 93
        },
        {
          "title": "3.1 Choosing a subject for experimentation",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "3.2 The investigation of appropriate Prompt patterns",
          "level": 1,
          "start_line": 105
        },
        {
          "title": "3.2.1 For multiple-choice questions",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "3.2.2 For True-False statements",
          "level": 1,
          "start_line": 131
        },
        {
          "title": "3.2.3 For Real-Scenario/Calculative exercises",
          "level": 1,
          "start_line": 147
        },
        {
          "title": "3.3 Evaluation methods and test results",
          "level": 1,
          "start_line": 161
        },
        {
          "title": "3.4 Preliminary self-assessment and optimization utilizing ChatGPT.",
          "level": 1,
          "start_line": 163
        },
        {
          "title": "3.5 The \"Blind Test\" method",
          "level": 1,
          "start_line": 173
        },
        {
          "title": "3.6 Result of evaluation",
          "level": 1,
          "start_line": 185
        },
        {
          "title": "3.6.1 Survey assumption",
          "level": 1,
          "start_line": 187
        },
        {
          "title": "3.6.2 General analysis",
          "level": 1,
          "start_line": 199
        },
        {
          "title": "3.6.3 Specific analysis",
          "level": 1,
          "start_line": 209
        },
        {
          "title": "4 Conclusion",
          "level": 1,
          "start_line": 244
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 250
        }
      ]
    },
    "suggested_tags": [
      "教育科技",
      "大语言模型",
      "提示工程",
      "自动问答生成"
    ],
    "tag_suggestions": [
      {
        "name": "教育科技",
        "confidence": 0.95,
        "reason": "论文核心研究场景是高等教育，探索利用AI技术辅助教学评估，属于教育技术（EdTech）的典型应用。"
      },
      {
        "name": "大语言模型",
        "confidence": 0.9,
        "reason": "研究基于ChatGPT这一具体的大语言模型（LLM）进行应用探索，是论文采用的核心技术。"
      },
      {
        "name": "提示工程",
        "confidence": 0.85,
        "reason": "论文重点贡献之一是设计交互式提示模式（prompting patterns）以优化与ChatGPT的交互，这是当前LLM应用的关键方法。"
      },
      {
        "name": "自动问答生成",
        "confidence": 0.8,
        "reason": "论文的具体任务是利用AI自动生成测验题目（quiz questions），这是自然语言处理在教育领域的一个具体任务。"
      }
    ],
    "category": "教育科技"
  },
  "27e18ce7-8ba5-4887-bd0e-8aead7e78240": {
    "id": "27e18ce7-8ba5-4887-bd0e-8aead7e78240",
    "filename": "2410.09576v1.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/27e18ce7-8ba5-4887-bd0e-8aead7e78240_2410.09576v1.pdf",
    "status": "completed",
    "created_at": "2025-12-16 23:15:44.214753",
    "updated_at": "2025-12-16 15:17:15.094587",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models",
    "markdown_content": "# The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models\n\nSubhankar Maity  \nDepartment of Artificial Intelligence  \nIndian Institute of Technology Kharagpur  \nsubhankar.ai@kgpian.iitkgp.ac.in\n\nAniket Deroy  \nComputer Science & Engineering  \nIndian Institute of Technology Kharagpur  \nroydanik18@kgpian.iitkgp.ac.in\n\nIn recent years, large language models (LLMs) and generative AI have revolutionized natural language processing (NLP), offering unprecedented capabilities in education. This chapter explores the transformative potential of LLMs in automated question generation and answer assessment. It begins by examining the mechanisms behind LLMs, emphasizing their ability to comprehend and generate human-like text. The chapter then discusses methodologies for creating diverse, contextually relevant questions, enhancing learning through tailored, adaptive strategies. Key prompting techniques, such as zero-shot and chain-of-thought prompting, are evaluated for their effectiveness in generating high-quality questions, including open-ended and multiple-choice formats in various languages. Advanced NLP methods like fine-tuning and prompt-tuning are explored for their role in generating task-specific questions, despite associated costs. The chapter also covers the human evaluation of generated questions, highlighting quality variations across different methods and areas for improvement. Furthermore, it delves into automated answer assessment, demonstrating how LLMs can accurately evaluate responses, provide constructive feedback, and identify nuanced understanding or misconceptions. Examples illustrate both successful assessments and areas needing improvement. The discussion underscores the potential of LLMs to replace costly, time-consuming human assessments when appropriately guided, showcasing their advanced understanding and reasoning capabilities in streamlining educational processes.\n\nKeywords: Natural Language Processing (NLP), Large Language Models (LLMs), Education, Automated Question Generation (AQG), Answer Assessment, Prompt Engineering\n\n# 1. INTRODUCTION\n\nThe educational landscape is evolving rapidly, driven by the integration of advanced technologies that challenge traditional teaching methods. Among these technologies, Large Language Models (LLMs) have emerged as powerful tools, capable of revolutionizing the way we approach learning and assessment. These models, epitomized by systems such as GPT-4 (Achiam et al., 2023) and beyond, have demonstrated an extraordinary ability to understand and generate human-like text, enabling them to perform tasks that were once the exclusive domain\n\nof human educators (Brown et al., 2020; Floridi and Chiriatti, 2020). In the realm of education, question generation and assessment are critical components that shape the learning experience. Traditionally, these tasks require significant human effort, involving educators in the meticulous design of questions that not only test knowledge but also promote deeper understanding (Mazidi and Nielsen, 2014). Assessing student responses, particularly in open-ended formats, is another labor-intensive task that demands careful consideration of context, nuance, and individual student needs (Chappuis et al., 2015). However, as the demand for personalized and adaptive learning grows, the limitations of human-driven approaches have become more apparent.\n\nThis chapter delves into the transformative potential of LLMs in automating these crucial educational tasks. We explore how LLMs can be leveraged to generate a wide variety of questions—ranging from simple factual queries to complex, open-ended questions—that are contextually relevant and aligned with educational goals (Maity et al., 2023; Maity et al., 2024a; Maity et al., 2024c). We also examine the capabilities of LLMs in automated answer assessment, where these models can evaluate student responses, offer feedback, and even identify subtle misconceptions, all at a scale and efficiency that human educators cannot match (Fagbohun et al., 2024). The introduction of LLMs into the educational process is not without challenges. Issues such as the quality and relevance of generated questions, the accuracy of automated assessments, and the ethical implications of relying on AI for education require careful consideration (Floridi and Cowls, 2022).\n\nThis chapter addresses these concerns, offering insights into how LLMs can be guided and refined to ensure they complement and enhance human-led education rather than replacing it. In the sections that follow, we will first provide a detailed overview of LLMs, focusing on their architecture and underlying mechanisms. This will set the stage for a discussion on various methodologies and prompting techniques used to generate educational questions. We will then explore the role of advanced NLP methods such as fine-tuning and prompt-tuning in enhancing the quality and specificity of generated questions. The chapter will also cover human evaluation metrics for assessing the quality of these questions and the performance of LLMs in automated answer assessment. Finally, we will discuss the broader implications of integrating LLMs into education, highlighting both their potential benefits and the challenges that must be addressed to fully realize their capabilities.\n\n# 2. UNDERSTANDING LARGE LANGUAGE MODELS IN EDUCATION\n\n# 2.1. THE ARCHITECTURE AND MECHANISMS OF LLMS\n\nLarge Language Models (LLMs), built on the foundations of deep learning and transformer architectures (Vaswani et al., 2017), have brought about a paradigm shift in natural language processing (NLP). These models, trained on vast corpora of text data, are designed to predict and generate text based on a given input (Radford et al., 2019). Their ability to understand context, recognize patterns, and generate coherent, contextually appropriate text makes them particularly well-suited for educational applications.\n\nAt the core of LLMs is the transformer architecture, which uses self-attention mechanisms to weigh the importance of different words in a sentence relative to each other (Vaswani et al., 2017). This allows the model to capture long-range dependencies in text, making it capable of understanding complex sentences and generating nuanced responses. For educational purposes, this means LLMs can generate questions that are not only grammatically correct but also context\n\ntually relevant and pedagogically sound. The training process of LLMs involves exposure to diverse datasets that cover a wide range of topics and writing styles (Raiaan et al., 2024). This extensive training enables the models to develop a broad understanding of language, which they can then apply to specific tasks such as question generation and assessment. However, while LLMs excel in generating human-like text, their effectiveness in educational contexts depends on how well they are guided and fine-tuned for specific tasks.\n\n# 2.2. THE ROLE OF FINE-TUNING AND PROMPT-TUNING\n\nTo adapt LLMs for educational question generation and assessment, techniques such as fine-tuning and prompt-tuning are employed. Fine-tuning involves training the LLM on a specialized dataset that is closely aligned with the target task. This allows the model to learn the nuances of educational content and generate questions that are more closely aligned with the curriculum and learning objectives (Li et al., 2023).\n\nPrompt-tuning, on the other hand, involves designing specific prompts that guide the LLM in generating the desired output (Lester et al., 2021). This technique leverages the model's existing knowledge and directs it towards generating contextually relevant and pedagogically valuable questions. For instance, a prompt might instruct the LLM to generate a question based on a specific passage of text, encouraging the model to focus on key concepts and ideas that are essential for learning.\n\nBoth fine-tuning and prompt-tuning have their advantages and challenges. Fine-tuning can produce highly specialized models that excel in specific tasks, but it is resource-intensive and requires access to large, high-quality datasets (Raffel et al., 2020). Prompt-tuning, while more flexible and less resource-demanding, relies heavily on the design of effective prompts and may not always achieve the same level of specificity as fine-tuned models (Lester et al., 2021). Despite these challenges, both techniques have shown significant promise in enhancing the performance of LLMs in educational settings.\n\n# 3. AUTOMATED QUESTION GENERATION: METHODOLOGIES AND TECHNIQUES\n\n# 3.1. GENERATING Diverse AND CONTEXTUALLY RELEVANT QUESTIONS\n\nThe automated generation of questions using large language models (LLMs) represents a powerful tool in education, enabling the creation of diverse and contextually relevant questions tailored to various learning objectives (Maity et al., 2024a). The methodologies employed in question generation are varied, each contributing to the quality and applicability of the generated content. Below are the key methods utilized in this domain:\n\n- Zero-Shot Prompting: Zero-shot learning allows models like GPT-3 (Brown et al., 2020) to generate questions based on minimal instructions. The model leverages its pre-trained knowledge to generate relevant questions directly from the provided text, without the need for additional examples or fine-tuning (Brown et al., 2020). This approach is particularly useful for generating questions across a wide range of topics, but the quality may vary depending on the complexity of the input text (Maity et al., 2023; Maity et al., 2024b).  \n- Few-Shot Prompting: Few-shot prompting provides the model with a few examples of the task to guide its question generation. By including a few question-answer pairs as\n\npart of the prompt, this method enhances the model's understanding of the task, leading to improved relevance and quality of the generated questions (Brown et al., 2020). This technique is effective in scenarios where the desired question format or content is more complex and needs to be clearly defined for the model.\n\n- Chain-of-Thought Prompting: A structured technique that involves guiding the LLM through a step-by-step reasoning process before it generates the final question. For example, the model may first be asked to summarize a passage, identify key concepts, and then generate a question that tests understanding of these concepts (Wei et al., 2022; Maity et al., 2024d). This approach is particularly effective for generating higher-order questions that require critical thinking and analysis, ensuring that the questions align with specific educational goals.  \n- Fine-Tuning: Fine-tuning involves further training the LLM on a specific dataset of questions and answers relevant to the target domain. By learning the patterns and structures of effective questions from the training data, fine-tuning allows the model to generate more accurate and context-specific questions (Raffel et al., 2020). This method is resource-intensive but results in highly specialized models that can produce high-quality questions tailored to specific subjects or curricula (Maity et al., 2023).  \n- Prompt-Tuning: A recent and computationally efficient technique, prompt-tuning involves adjusting a small set of parameters (the prompt) while leaving the rest of the model unchanged. This method has proven effective in generating high-quality questions across various educational contexts, especially when the goal is to adapt a general-purpose LLM to a specific task without extensive retraining (Lester et al., 2021). Prompt-tuning allows for quick adaptation and customization of LLMs to generate questions that are both relevant and aligned with specific educational objectives.  \n- Multifacet and Multilingual Question Generation: LLMs are capable of generating both open-ended (Maity et al., 2023) and multiple-choice questions (Maity et al., 2024d), catering to different assessment needs. Open-ended questions encourage critical thinking and exploration, while multiple-choice questions are useful for evaluating specific knowledge or skills (Maity et al., 2024d). Additionally, the multilingual capabilities of LLMs enable the generation of questions in various languages, making them valuable tools for language learning and cross-cultural education (Radford et al., 2019; Maity et al., 2024d).\n\nThese methodologies, when applied effectively, enhance the educational process by generating diverse, high-quality questions that cater to different learning contexts and objectives. As LLMs continue to evolve, the integration of these techniques will further improve the relevance, accuracy, and utility of automated question generation in education.\n\n# 3.2. TYPES OF QUESTIONS GENERATED BY LLMS\n\nIn the context of education, different types of questions serve varied pedagogical functions, and LLMs are capable of generating a broad spectrum of question types. Below are the primary categories:\n\n- Factual Questions: These questions focus on the recall of specific information, such as dates, definitions, or events. They are typically straightforward and aim to assess the student's memory and basic understanding of the subject matter (Mulla and Gharpure, 2023).\n\nExample: \"What is the capital of France?\"\n\n- Open-Ended Questions: Open-ended questions are designed to encourage deep thinking and exploration, allowing students to express their thoughts freely and creatively. These questions do not have a single correct answer, promoting critical thinking and discussion (Mulla and Gharpure, 2023; Maity et al., 2023).\n\nExample: \"What does purchasing power parity do?\"\n\n- Multiple-Choice Questions (MCQs): MCQs assess specific knowledge or skills by providing a set of possible answers from which the student must choose the correct one. They are widely used for their efficiency in testing and grading (Maity et al., 2024d).\n\nExample: \"Which of the following is the largest planet in our solar system?\n\n(a) Earth (b) Jupiter (c) Mars (d) Venus\"\n\nLLMs, through their sophisticated language processing capabilities, can generate these varied question types effectively, adapting them to different educational contexts and learning objectives.\n\n# 4. AUTOMATED ANSWER ASSESSMENT: EVALUATING STUDENT RESPONSES\n\n# 4.1. THE CAPABILITIES OF LLMS IN AUTOMATED ANSWER ASSESSMENT\n\nIn addition to generating questions, LLMs have demonstrated significant potential in automated answer assessment (Fagbohun et al., 2024). The ability to accurately evaluate student responses and provide feedback is a critical component of the educational process (Fagbohun et al., 2024). Traditionally, this task has been performed by human educators, who must carefully consider the content, context, and nuance of each response (Balfour, 2013). However, as the demand for personalized and scalable education grows, the limitations of human-driven assessment become more apparent (Luckin and Holmes, 2016).\n\nLLMs offer a scalable solution to automated answer assessment, with the ability to evaluate a wide range of responses, from simple factual answers to complex, open-ended essays (Fagbohun et al., 2024). By leveraging their deep understanding of language and context, LLMs can identify key concepts, assess the accuracy of the response, and provide constructive feedback (Stamper et al., 2024). This capability is particularly valuable in large-scale educational settings, where the volume of student responses can be overwhelming for human assessors (Broadbent et al., 2018).\n\nOne of the key strengths of LLMs in automated assessment is their ability to identify nuanced understanding or misconceptions in student responses (Kazi, 2023). For example, an LLM can evaluate an essay on a historical event, recognizing whether the student has grasped the underlying causes and implications of the event, rather than simply recounting facts (Kasneci et al., 2023).\n\nHowever, while LLMs have shown great promise in automated assessment, there are challenges to be addressed (Fagbohun et al., 2024). One of the primary concerns is the accuracy and\n\nconsistency of the assessments. LLMs, like all AI systems, are not infallible and can sometimes produce incorrect or biased evaluations (Owan et al., 2023). Ensuring that the assessments are fair, accurate, and aligned with the learning objectives is crucial for the successful integration of LLMs into the educational process (Fagbohun et al., 2024).\n\n# 4.2. EXAMPLES OF SUCCESSFUL ASSESSMENTS AND AREAS FOR IMPROVEMENT\n\nTo illustrate the capabilities of LLMs in automated answer assessment, consider the following examples:\n\n- Short-Answer Evaluation: An LLM is tasked with evaluating short-answer responses in a biology exam (Shin and Gierl, ). The model is able to accurately assess whether the student has correctly identified the function of a specific organelle within a cell, providing feedback on both correct and incorrect answers. The LLM also identifies common misconceptions, such as confusing the roles of the mitochondria and the nucleus, and provides corrective feedback to guide the student's learning.  \n- Essay Grading: In a history class, students are asked to write essays on the causes and effects of World War II. The LLM evaluates the essays based on criteria such as understanding of key events, analysis of historical factors, and coherence of argument. The model is able to identify well-reasoned arguments and provide feedback on areas where the student could improve, such as providing more evidence or considering alternative perspectives (Mansour et al., 2024; Henkel et al., 2024).  \n- Multiple-Choice Question Analysis: An LLM is used to analyze student responses to multiple-choice questions in a mathematics exam (Henkel et al., 2024). In addition to identifying the correct answers, the model also analyzes the patterns of incorrect responses, identifying common errors and misconceptions. This information is used to provide targeted feedback and suggest areas for further study.\n\nWhile these examples demonstrate the potential of LLMs in automated assessment, there are also areas for improvement. One challenge is ensuring that the feedback provided by the LLM is constructive and actionable (Meyer et al., 2024a). For instance, while the model may correctly identify an error in a student's response, it must also provide clear guidance on how to address the mistake. Additionally, the LLM must be able to adapt its feedback to the individual needs of each student, taking into account their prior knowledge and learning style.\n\nAnother area for improvement is the ability of LLMs to assess more complex and creative responses, such as those involving critical thinking, problem-solving, or artistic expression. While LLMs have made significant strides in understanding and generating text, evaluating these higher-order skills remains a challenge (Hsiao et al., 2023). Future research and development will be needed to enhance the capabilities of LLMs in these areas, ensuring that they can fully support the diverse needs of learners.\n\n# 5. HUMAN EVALUATION AND QUALITY METRICS FOR GENERATED QUESTIONS\n\n# 5.1. ASSESSING THE QUALITY OF GENERATED QUESTIONS\n\nThe quality of questions generated by LLMs is a critical factor in their effectiveness as educational tools. High-quality questions should be clear, relevant, and aligned with the learning objectives, challenging students to think critically and apply their knowledge. To ensure that the questions generated by LLMs meet these standards, human evaluation and quality metrics play a crucial role (Kurdi et al., 2020).\n\nHuman evaluation involves assessing the generated questions based on a set of predefined criteria, such as grammaticality, relevance, clarity, complexity, and alignment with the curriculum (Kurdi et al., 2020; Maity et al., 2023). Expert educators or subject matter experts typically conduct this evaluation, providing feedback on the strengths and weaknesses of the questions. This feedback is invaluable for refining the prompts and improving the quality of the generated questions.\n\nIn addition to human evaluation, automated quality metrics can be used to assess the generated questions. These metrics may include measures such as unigram-, bigram-, and ngram-based evaluations, which provide quantitative insights into the quality of the questions (Kurdi et al., 2020). However, these automated evaluation metrics used for assessing LLM-generated questions have limitations. This limitation arises because these metrics often prioritize linguistic similarity (e.g., character, unigrams, bigrams, or longest common subsequence-based overlap) rather than deeper contextual understanding (Nema and Khapra, 2018).\n\nOne of the challenges in evaluating the quality of generated questions is the subjective nature of some of the criteria. For instance, what one educator considers a challenging and thought-provoking question, another might view as overly complex or unclear (Crogman and Trebeau Crogman, 2018). To address this, it is important to establish clear guidelines and criteria for evaluation, ensuring consistency and objectivity in the assessment process.\n\n# 5.2. VARIATIONS IN QUALITY ACROSS DIFFERENT METHODS\n\nThe quality of questions generated by LLMs can vary significantly depending on the methods and techniques used. For example, questions generated using zero-shot prompting may be more general and less tailored to the specific content, while those generated using fine-tuning or prompt-tuning may be more precise and relevant (Maity et al., 2023). Understanding these variations is essential for selecting the appropriate method for a given educational context.\n\nOne common variation in quality is related to the complexity of the generated questions. LLMs are capable of generating both simple, factual questions and more complex, analytical questions (Maity et al., 2024b). However, the latter requires a deeper understanding of the content and context, which may not always be achievable through basic prompting techniques. To generate higher-order questions, more advanced techniques, such as chain-of-thought prompting (Wei et al., 2022) or fine-tuning (Raffel et al., 2020), may be necessary.\n\nAnother variation in quality is related to the cultural and linguistic diversity of the generated questions. LLMs trained on diverse datasets are better equipped to generate questions that are culturally relevant and appropriate for different student populations. However, this diversity can also introduce challenges, as the model may generate questions that are less familiar or relevant to certain groups of students. Ensuring that the generated questions are inclusive and accessi\n\nble to all learners is an important consideration in the evaluation process (Maity et al., 2024a; Maity et al., 2024b).\n\n# 6. BROADER IMPLICATIONS AND FUTURE DIRECTIONS\n\n# 6.1. THE ROLE OF LLMS IN PERSONALIZED AND ADAPTIVE LEARNING\n\nAs LLMs continue to evolve, their role in personalized and adaptive learning is becoming increasingly significant. The ability of LLMs to generate contextually relevant questions and assess student responses on a large scale opens up new possibilities for personalized education (Alier et al., 2023). By leveraging LLMs, educators can create tailored learning experiences that adapt to the individual needs and progress of each student (Goslen et al., 2024).\n\nOne of the key benefits of using LLMs in personalized learning is the ability to provide immediate feedback and guidance (Meyer et al., 2024b). As students interact with the system, LLMs can generate questions that challenge their understanding, identify areas of difficulty, and offer targeted feedback to support their learning. This real-time interaction can help students stay engaged and motivated, while also providing educators with valuable insights into their progress.\n\nHowever, the integration of LLMs into personalized learning also raises important questions about the balance between human and AI-driven education (Yekollu et al., 2024). While LLMs can offer scalable and efficient solutions, they cannot replace the nuanced understanding and empathy that human educators bring to the classroom. The challenge lies in finding the right balance, where LLMs complement and enhance human-led education, rather than supplanting it.\n\n# 6.2. ETHICAL CONSIDERATIONS AND CHALLENGES\n\nThe use of LLMs in education also raises important ethical considerations (Meyer et al., 2024b). Issues such as bias, fairness, and transparency are central to the responsible use of AI in education (Memarian and Doleck, 2023). LLMs, like all AI systems, are trained on data that may contain biases, and these biases can be reflected in the questions they generate or the assessments they perform (Memarian and Doleck, 2023). Ensuring that LLMs are fair and unbiased requires careful attention to the training data, as well as ongoing monitoring and evaluation of the system's outputs.\n\nAnother ethical consideration is the transparency of the AI-driven educational process (Badawi et al., 2018). Students and educators need to understand how LLMs generate questions and assess responses, and they should be informed about the potential limitations and biases of the system (Memarian and Doleck, 2023). Transparency is key to building trust in AI-driven education and ensuring that students and educators feel confident in the use of these technologies (Kim, 2024).\n\nFinally, the use of LLMs in education raises questions about data privacy and security (Rahman et al., 2024). As LLMs interact with students and assess their responses, they may collect and store sensitive information about the student's performance and learning history. Protecting this data and ensuring that it is used responsibly is essential for maintaining the integrity and security of the educational process.\n\n# 6.3. FUTURE DIRECTIONS IN AUTOMATED QUESTION GENERATION AND ASSESSMENT\n\nLooking to the future, the role of LLMs in automated question generation and assessment is likely to expand and evolve (Fagbohun et al., 2024). Advances in AI and NLP technologies will enable the development of more sophisticated models that are better equipped to handle complex and creative educational tasks (Alqahtani et al., 2023). As these models become more integrated into the educational process, they will play a key role in supporting personalized and adaptive learning, providing scalable solutions that enhance the quality and accessibility of education.\n\nOne promising direction for future research is the development of models that can assess higher-order thinking skills, such as critical thinking, problem-solving, and creativity. These skills are essential for success in the 21st century, and the ability to assess them accurately and efficiently is a major challenge for educators. LLMs, with their advanced language understanding and generation capabilities, have the potential to address this challenge, providing new tools for assessing and supporting the development of these critical skills (Moore et al., 2023).\n\nAnother important direction for future research is the exploration of new methodologies for fine-tuning and prompt-tuning LLMs for specific educational tasks. As LLMs continue to be used in a wider range of educational contexts, it will be important to develop techniques that allow for the efficient and effective adaptation of these models to different subject areas, student populations, and learning objectives.\n\n# 7. CONCLUSION\n\nIn conclusion, large language models have the potential to revolutionize education through automated question generation and answer assessment. These models, with their ability to understand and generate human-like text, offer scalable solutions that can enhance personalized and adaptive learning. By leveraging advanced prompting techniques and fine-tuning methodologies, educators can create high-quality, contextually relevant questions that challenge students and support their learning. Furthermore, LLMs' capabilities in automated assessment can provide timely and constructive feedback, helping students identify areas for improvement and guiding their educational journey.\n\nHowever, the integration of LLMs into education also presents challenges and ethical considerations that must be carefully addressed. Ensuring the fairness, accuracy, and transparency of AI-driven educational processes is essential for building trust and confidence in these technologies. As we look to the future, ongoing research and development will be key to realizing the full potential of LLMs in education, creating a more personalized, adaptive, and accessible learning experience for all students.\n\n# REFERENCES\n\nACHIAM, J., ADLER, S., AGARWAL, S., AHMAD, L., AKKAYA, I., ALEMAN, F. L., ALMEIDA, D., ALTENSCHMIDT, J., ALTMAN, S., ANADKAT, S., ET AL. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.  \nALIER, M., CASAN, M. J., AND FILVA, D. A. 2023. Smart learning applications: Leveraging llms for contextualized and ethical educational technology. In International conference on technological ecosystems for enhancing multiculturality. Springer, 190-199.\n\nALQAHTANI, T., BADRELDIN, H. A., ALRASHED, M., ALSHAYA, A. I., ALGHAMDI, S. S., BIN SALEH, K., ALOWAIS, S. A., ALSHAYA, O. A., RAHMAN, I., AL YAMI, M. S., ET AL. 2023. The emergent role of artificial intelligence, natural learning processing, and large language models in higher education and research. Research in Social and Administrative Pharmacy 19, 8, 1236-1242.  \nBADAWI, G., DE BEYROUTH, G., AND BADAWI, H. 2018. AI-driven educational paradigms: Opportunities and challenges, and ethical considerations in teaching and learning.  \nBALFOUR, S. P. 2013. Assessing writing in moocs: Automated essay scoring and calibrated peer review™. Research & Practice in Assessment 8, 40-48.  \nBROADBENT, J., PANADERO, E., AND BOUD, D. 2018. Implementing summative assessment with a formative flavour: A case study in a large class. Assessment & Evaluation in Higher Education 43, 2, 307-322.  \nBROWN, T., MANN, B., RYDER, N., SUBBIAH, M., KAPLAN, J. D., DHARIWAL, P., NEELAKANTAN, A., SHYAM, P., SASTRY, G., ASKELL, A., AGARWAL, S., HERBERT-VOSS, A., KRUEGER, G., HENIGHAN, T., CHILD, R., RAMESH, A., ZIEGLER, D., WU, J., WINTER, C., HESSE, C., CHEN, M., SIGLER, E., LITWIN, M., GRAY, S., CHESS, B., CLARK, J., BERNER, C., MCCANDLISH, S., RADFORD, A., SUTSKEVER, I., AND AMODEI, D. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, Eds. Vol. 33. Curran Associates, Inc., 1877-1901.  \nCHAPPUIS, J. ET AL. 2015. Seven strategies of assessment for learning. Pearson.  \nCROGMAN, H. AND TREBEAU CROGMAN, M. 2018. Modified generated question learning, and its classroom implementation and assessment. *Cogent Education* 5, 1, 1459340.  \nFAGBOHUN, O., IDUWE, N., ABDULLAHI, M., IFATUROTI, A., AND NWANNA, O. 2024. Beyond traditional assessment: Exploring the impact of large language models on grading practices. Journal of Artificial Intelligence and Machine Learning & Data Science 2, 1, 1-8.  \nFLORIDI, L. AND CHRIATTI, M. 2020. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines* 30, 681–694.  \nFLORIDI, L. AND COWLS, J. 2022. A unified framework of five principles for ai in society. Machine learning and the city: Applications in architecture and urban design, 535-545.  \nGOSLEN, A., KIM, Y. J., ROWE, J., AND LESTER, J. 2024. LIm-based student plan generation for adaptive scaffolding in game-based learning environments. International Journal of Artificial Intelligence in Education, 1-26.  \nHENKEL, O., HILLS, L., BOXER, A., ROBERTS, B., AND LEVONIAN, Z. 2024. Can large language models make the grade? an empirical study evaluating llms ability to mark short answer questions in k-12 education. In Proceedings of the Eleventh ACM Conference on Learning@ Scale. 300-304.  \nHSIAO, Y.-P., KLIJN, N., AND CHIU, M.-S. 2023. Developing a framework to re-design writing assignment assessment for the era of large language models. Learning: Research and Practice 9, 2, 148-158.  \nKASNECI, E., SESSLER, K., KUCHEMANN, S., BANNERT, M., DEMENTIEVA, D., FISCHER, F., GASSER, U., GROH, G., GUNNEMANN, S., HULLERMEIER, E., ET AL. 2023. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and individual differences 103, 102274.  \nKAZI, N. H. 2023. Automated short-answer grading and misconception detection using large language models. University of North Florida.  \nKIM, J. 2024. Leading teachers' perspective on teacher-ai collaboration in education. *Education and Information Technologies* 29, 7, 8693–8724.\n\nKURDI, G., LEO, J., PARSIA, B., SATTLER, U., AND AL-EMARI, S. 2020. A systematic review of automatic question generation for educational purposes. International Journal of Artificial Intelligence in Education 30, 121-204.  \nLESTER, B., AL-RFOU, R., AND CONSTANT, N. 2021. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691.  \nLI, Q., FU, L., ZHANG, W., CHEN, X., YU, J., XIA, W., ZHANG, W., TANG, R., AND YU, Y. 2023. Adapting large language models for education: Foundational capabilities, potentials, and challenges. arXiv preprint arXiv:2401.08664.  \nLUCKIN, R. AND HOLMES, W. 2016. Intelligence unleashed: An argument for ai in education.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2023. Harnessing the power of prompt-based techniques for generating school-level questions using large language models. In Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation. 30-39.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024a. Exploring the capabilities of prompted large language models in educational and assessment applications. In Proceedings of the 17th International Conference on Educational Data Mining, B. PaaÄyen and C. D. Epp, Eds. International Educational Data Mining Society, Atlanta, Georgia, USA, 961-968.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024b. How effective is gpt-4 turbo in generating school-level questions from textbooks based on bloom's revised taxonomy?  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024c. How ready are generative pre-trained large language models for explaining bengali grammatical errors? In Proceedings of the 17th International Conference on Educational Data Mining, B. PaaÄyen and C. D. Epp, Eds. International Educational Data Mining Society, Atlanta, Georgia, USA, 664-671.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024d. A novel multi-stage prompting approach for language agnostic mcq generation using gpt. In European Conference on Information Retrieval. Springer, 268-277.  \nMANSOUR, W., ALBATARNI, S., ELTANBOULY, S., AND ELSAYED, T. 2024. Can large language models automatically score proficiency of written essays? arXiv preprint arXiv:2403.06149.  \nMAZIDI, K. AND NIELSEN, R. 2014. Linguistic considerations in automatic question generation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 321-326.  \nMEMARIAN, B. AND DOLECK, T. 2023. Fairness, accountability, transparency, and ethics (fate) in artificial intelligence (ai), and higher education: A systematic review. Computers and Education: Artificial Intelligence, 100152.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., AND FLECKENSTEIN, J. 2024a. Using llms to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students' text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence 6, 100199.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., AND FLECKENSTEIN, J. 2024b. Using llms to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students' text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence 6, 100199.  \nMOORE, S., TONG, R., SINGH, A., LIU, Z., HU, X., LU, Y., LIANG, J., CAO, C., KHOSRAVI, H., Denny, P., ET AL. 2023. Empowering education with llms-the next-gen interface and content generation. In International Conference on Artificial Intelligence in Education. Springer, 32-37.\n\nMULLA, N. AND GHARPURE, P. 2023. Automatic question generation: a review of methodologies, datasets, evaluation metrics, and applications. Progress in Artificial Intelligence 12, 1, 1-32.  \nNEMA, P. AND KHAPRA, M. M. 2018. Towards a better metric for evaluating question generation systems. arXiv preprint arXiv:1808.10192.  \nOWAN, V. J., ABANG, K. B., IDIKA, D. O., ETTA, E. O., AND BASSEY, B. A. 2023. Exploring the potential of artificial intelligence tools in educational measurement and assessment. Eurasia Journal of Mathematics, Science and Technology Education 19, 8, em2307.  \nRADFORD, A., WU, J., CHILD, R., LUAN, D., AMODEI, D., SUTSKEVER, I., ET AL. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8, 9.  \nRAFFEL, C., SHAZEER, N., ROBERTS, A., LEE, K., NARANG, S., MATENA, M., ZHOU, Y., LI, W., AND LIU, P. J. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of machine learning research 21, 140, 1-67.  \nRAHMAN, M. A., ALQAHTANI, L., ALBOOQ, A., AND AINOUSAH, A. 2024. A survey on security and privacy of large multimodal deep learning models: Teaching and learning perspective. In 2024 21st Learning and Technology Conference (L&T). IEEE, 13-18.  \nRAIAAN, M. A. K., MUKTA, M. S. H., FATEMA, K., FAHAD, N. M., SAKIB, S., MIM, M. M. J., AHMAD, J., ALI, M. E., AND AZAM, S. 2024. A review on large language models: Architectures, applications, taxonomies, open issues and challenges. IEEE Access.  \nSHIN, J. AND GIERL, M. J. Automated short-response scoring for automated item generation in science assessments. In The Routledge International Handbook of Automated Essay Evaluation. Routledge, 504-534.  \nSTAMPER, J., XIAO, R., AND HOU, X. 2024. Enhancing llm-based feedback: Insights from intelligent tutoring systems and the learning sciences. In International Conference on Artificial Intelligence in Education. Springer, 32-43.  \nVASWANI, A., SHAZEER, N., PARMAR, N., USZKOREIT, J., JONES, L., GOMEZ, A. N., KAISER, L. U., AND POLOSUKHIN, I. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds. Vol. 30. Curran Associates, Inc.  \nWEI, J., WANG, X., SCHUURMANS, D., BOSMA, M., ICHTER, B., XIA, F., CHI, E., LE, Q. V., AND ZHOU, D. 2022. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds. Vol. 35. Curran Associates, Inc., 24824-24837.  \nYEKOLLU, R. K., BHIMRAJ GHUGE, T., SUNIL BIRADAR, S., HALDIKAR, S. V., AND FAROOK MOHIDEEN ABDUL KADER, O. 2024. Ai-driven personalized learning paths: Enhancing education through adaptive systems. In International Conference on Smart Data Intelligence. Springer, 507-517.",
    "arxiv_id": "2410.09576",
    "error_message": null,
    "embedding": [
      0.4375,
      0.265625,
      -1.7421875,
      -0.8203125,
      -1.921875,
      1.09375,
      -2.15625,
      -1.765625,
      2.109375,
      4.3125,
      0.2421875,
      3.296875,
      3.546875,
      0.6953125,
      -0.474609375,
      4.0625,
      -1.296875,
      1.140625,
      2.1875,
      -8.8125,
      0.09619140625,
      2.125,
      -0.15625,
      -4.15625,
      3.328125,
      -4.3125,
      -1.046875,
      3.328125,
      3.953125,
      -0.412109375,
      6.25,
      -3.9375,
      -0.8515625,
      -0.15625,
      -0.91796875,
      0.027587890625,
      -2.515625,
      -0.33984375,
      6.8125,
      4.9375,
      -6.03125,
      -0.04052734375,
      0.765625,
      2.5,
      -1.28125,
      3.375,
      1.4140625,
      0.39453125,
      -3,
      -2.015625,
      -4.5625,
      -3.171875,
      6.75,
      -0.734375,
      2.15625,
      -3.65625,
      -7.375,
      5.9375,
      -5.71875,
      1.3125,
      3.5,
      -1.1875,
      2.265625,
      1.9921875,
      4,
      4.6875,
      -0.953125,
      0.07470703125,
      -2.453125,
      2.59375,
      0.328125,
      0.76171875,
      7.03125,
      -1.578125,
      9.625,
      3.40625,
      2.5625,
      7.15625,
      -2,
      4.1875,
      -5.375,
      3.921875,
      2.234375,
      0.283203125,
      5.84375,
      3.15625,
      1.21875,
      -0.69921875,
      -4.875,
      1.359375,
      -3.90625,
      1.796875,
      -4.40625,
      -1.4375,
      -2.125,
      3.953125,
      -3.25,
      -4.40625,
      -7.96875,
      0.4765625,
      -1.1015625,
      -2.625,
      0.451171875,
      -8.125,
      -2.4375,
      -0.98046875,
      -3.875,
      -5.9375,
      -1.9375,
      -1.140625,
      -1.7578125,
      2.078125,
      -0.6171875,
      -1.859375,
      3.140625,
      0.7265625,
      3.5,
      -4.8125,
      -5.53125,
      -1.875,
      -0.15625,
      -0.006622314453125,
      -1.2421875,
      0.7265625,
      5.15625,
      2.984375,
      -4.59375,
      2.515625,
      5.40625,
      -2.171875,
      5.28125,
      -1.21875,
      6.9375,
      0.345703125,
      -9.4375,
      -3.921875,
      -6.25,
      4.4375,
      3.609375,
      5.90625,
      -6.65625,
      -0.291015625,
      -2.15625,
      -7.125,
      2.390625,
      0.484375,
      -8.375,
      -0.21484375,
      1.421875,
      -4.5625,
      -0.2470703125,
      1.859375,
      1.7265625,
      6.40625,
      -3.21875,
      -2.59375,
      6.21875,
      1.5390625,
      1.171875,
      -1.2734375,
      0.07080078125,
      2.796875,
      -1.125,
      -0.126953125,
      1.25,
      0.4921875,
      -6.53125,
      1.9296875,
      -0.8828125,
      -0.58203125,
      -0.66015625,
      14.1875,
      3.84375,
      -1.4921875,
      1.2265625,
      4.65625,
      2.5,
      5.65625,
      1.4296875,
      0.00299072265625,
      1.921875,
      1.90625,
      -4.375,
      5.15625,
      -2.953125,
      1.1875,
      2.28125,
      -4.28125,
      1.796875,
      -2.28125,
      0.97265625,
      1.4921875,
      3.546875,
      2.53125,
      -8.3125,
      0.400390625,
      1.421875,
      -0.8125,
      -1.9453125,
      1.8984375,
      -0.09716796875,
      -9.6875,
      0.64453125,
      -2.296875,
      -5.28125,
      -0.05126953125,
      2.96875,
      -3.40625,
      1.46875,
      -0.79296875,
      1.3515625,
      0.65234375,
      1.265625,
      0.828125,
      8.5625,
      5.3125,
      3.34375,
      -0.2314453125,
      4.4375,
      0.059814453125,
      5.6875,
      5.625,
      3.484375,
      -0.8359375,
      -0.37109375,
      3.046875,
      3.8125,
      4.9375,
      0.56640625,
      5.9375,
      0.8359375,
      1.328125,
      4.65625,
      -4.71875,
      -2.03125,
      -1.453125,
      -3.71875,
      -1.1015625,
      0.6640625,
      -1.7578125,
      -4.3125,
      -2.453125,
      0.37890625,
      2.984375,
      2.546875,
      -0.7734375,
      0.051513671875,
      -1.6171875,
      -5.84375,
      -7.84375,
      0.83203125,
      5.28125,
      -9.625,
      -5.625,
      4.0625,
      9.375,
      -1.21875,
      -1.0859375,
      -0.71875,
      -4.375,
      4.8125,
      -1.609375,
      -5.15625,
      4.21875,
      1.765625,
      -3.328125,
      4,
      -3.203125,
      3.15625,
      1.734375,
      -0.051025390625,
      -0.07568359375,
      -3.703125,
      1.0390625,
      -4.0625,
      4.125,
      1.21875,
      -5.3125,
      1.7109375,
      -3.984375,
      -7.03125,
      -10.5625,
      5.8125,
      -5.5625,
      2.234375,
      -0.390625,
      0.828125,
      3.890625,
      -1.5703125,
      12.5,
      3.890625,
      2.875,
      1.3828125,
      2.25,
      -2.71875,
      0.87890625,
      -2.140625,
      -0.0830078125,
      -6.75,
      1.546875,
      5.75,
      -0.0849609375,
      -0.41015625,
      -1.984375,
      0.1435546875,
      3.640625,
      -0.314453125,
      -4.125,
      1.078125,
      0.96875,
      -3.5,
      1.046875,
      4.90625,
      -1.8046875,
      4,
      -4.65625,
      -3.34375,
      5.53125,
      1.640625,
      -2.296875,
      -4.46875,
      -3.046875,
      -1.390625,
      -2.234375,
      -2.28125,
      -2.359375,
      2.5,
      1.53125,
      4.53125,
      -1,
      2.96875,
      -1.359375,
      -6.15625,
      -6.65625,
      7.09375,
      -2.734375,
      4.59375,
      2.90625,
      -2.34375,
      3.34375,
      -1.3046875,
      -3.265625,
      2.875,
      -1.40625,
      -2.21875,
      -0.0498046875,
      6.25,
      -2.59375,
      1.578125,
      -5.75,
      4.84375,
      -0.443359375,
      -1.0390625,
      1.3828125,
      5.75,
      -2.25,
      1.078125,
      -1.2890625,
      0.2734375,
      1.140625,
      5.03125,
      -2.796875,
      7.6875,
      -2.5,
      0.0018463134765625,
      -3.546875,
      -4.75,
      0.359375,
      -2.109375,
      -1.28125,
      0.5546875,
      -3.390625,
      1.6171875,
      2.890625,
      0.3828125,
      2.484375,
      0.890625,
      -3.734375,
      -2.3125,
      3.46875,
      -2.328125,
      -0.7890625,
      -2.703125,
      -0.640625,
      3.640625,
      1.4765625,
      -0.96484375,
      2.53125,
      2.296875,
      -1.5859375,
      -1.953125,
      0.2294921875,
      -4.59375,
      1.8828125,
      2.234375,
      2.34375,
      -0.890625,
      0.2578125,
      0.10888671875,
      -2.21875,
      6.46875,
      -0.1455078125,
      -1.5078125,
      0.2333984375,
      -4.71875,
      2.375,
      0.6953125,
      -7.75,
      3.421875,
      0.1806640625,
      -1.8359375,
      0.97265625,
      0.408203125,
      2.859375,
      -0.79296875,
      2.53125,
      -3.484375,
      1.9140625,
      -8.375,
      -2.03125,
      -3.828125,
      0.0341796875,
      3,
      -1.25,
      0.423828125,
      -0.93359375,
      1.5234375,
      5,
      -0.5078125,
      1.421875,
      1.2890625,
      -0.796875,
      -3.140625,
      2.34375,
      -3.0625,
      -4.03125,
      4.65625,
      -3.109375,
      -5.03125,
      0.7890625,
      0.93359375,
      -1.9609375,
      5.15625,
      2.90625,
      -3.8125,
      -0.33984375,
      2.796875,
      5.71875,
      -4.03125,
      -1.25,
      0.08349609375,
      -1.1328125,
      -1.3828125,
      1.6171875,
      -0.08740234375,
      2.5625,
      -5.5,
      3.25,
      1.796875,
      -0.1259765625,
      0.5234375,
      -1.9765625,
      -2.921875,
      -0.859375,
      1.546875,
      -0.2275390625,
      -2.359375,
      3.859375,
      6.65625,
      -6.34375,
      -10.6875,
      2.59375,
      1.2890625,
      -0.373046875,
      -0.765625,
      0.71875,
      1,
      0.201171875,
      -6.15625,
      -3.921875,
      -0.138671875,
      -2.078125,
      3.375,
      2.09375,
      -1.4765625,
      -3.59375,
      -2.171875,
      4.375,
      0.59765625,
      3.203125,
      -1.0390625,
      -1.328125,
      0.08349609375,
      -2.515625,
      3.625,
      1.171875,
      9.75,
      -4.90625,
      0.2421875,
      1.8984375,
      -9.125,
      2.6875,
      -2.875,
      1.046875,
      2.015625,
      0.2490234375,
      5.625,
      -4.8125,
      -1.984375,
      -0.91796875,
      4.96875,
      -3.265625,
      -0.68359375,
      2.546875,
      -7.53125,
      -1.0390625,
      0.035888671875,
      1.9765625,
      2.453125,
      -1.09375,
      -5.84375,
      1.421875,
      1.359375,
      2.5,
      -0.5703125,
      -1.0078125,
      -2.453125,
      -4.1875,
      2.109375,
      5.09375,
      1.0234375,
      1.859375,
      -0.13671875,
      -3.890625,
      -1.9921875,
      -1.140625,
      2.015625,
      -1.5546875,
      -0.1298828125,
      -0.62890625,
      -0.0888671875,
      5.75,
      -1.7265625,
      -1.875,
      0.251953125,
      3.40625,
      -6.5625,
      -0.341796875,
      0.65234375,
      1.34375,
      3.875,
      1.8046875,
      -1.390625,
      -2.5,
      2.90625,
      -3.0625,
      -4.96875,
      0.15625,
      4.03125,
      -2.015625,
      -0.34375,
      -5.25,
      -1.109375,
      1.6171875,
      3.109375,
      -0.2470703125,
      -0.6171875,
      6.8125,
      -0.58203125,
      -1.9609375,
      -1.625,
      5.5,
      -1.6875,
      0.27734375,
      1.4453125,
      0.9921875,
      -7,
      -6.21875,
      -3,
      2.8125,
      7.65625,
      -3.109375,
      4.8125,
      -2.4375,
      4.53125,
      -2.09375,
      -0.86328125,
      -13.125,
      3.953125,
      0.48828125,
      -5.34375,
      -1.1640625,
      -0.91796875,
      2.296875,
      0.67578125,
      3.28125,
      0.453125,
      -0.78515625,
      1.9765625,
      4.34375,
      1.1015625,
      -0.59375,
      3,
      2.90625,
      -2.890625,
      2.234375,
      -2.953125,
      -3.421875,
      3,
      -1.3828125,
      1.6484375,
      2.375,
      4.625,
      1.0703125,
      -0.2294921875,
      1.1015625,
      -4.03125,
      0.55078125,
      2.390625,
      2.1875,
      1.109375,
      0.423828125,
      -3.03125,
      3.28125,
      -3.9375,
      2.765625,
      0.314453125,
      -3.921875,
      2.125,
      6.1875,
      -0.58203125,
      -2.828125,
      -2.328125,
      0.330078125,
      4.09375,
      4.78125,
      -5.46875,
      2.671875,
      -2.84375,
      -0.52734375,
      1.96875,
      -1.40625,
      -0.8671875,
      -3.171875,
      4.46875,
      1.03125,
      -3.234375,
      5.34375,
      1.0859375,
      -4.6875,
      -0.515625,
      0.5703125,
      -0.58203125,
      -1.2578125,
      1.9296875,
      0.353515625,
      -2.3125,
      0.423828125,
      3.0625,
      0.045166015625,
      -4.28125,
      -1.734375,
      0.345703125,
      -4.125,
      3.984375,
      -1.9765625,
      -2.65625,
      -2.765625,
      -3.03125,
      1.71875,
      1.140625,
      1.9765625,
      0.10009765625,
      4.65625,
      3.421875,
      -3.671875,
      3.0625,
      -3.453125,
      -2.328125,
      -0.482421875,
      -2.484375,
      -3.28125,
      -0.5703125,
      0.81640625,
      1.4375,
      -4.25,
      -2.96875,
      -3.1875,
      -6.6875,
      -2.75,
      2.015625,
      -1.0625,
      4.46875,
      -2.203125,
      6.75,
      -1.703125,
      -1.7734375,
      0.60546875,
      0.4296875,
      0.1572265625,
      -1.625,
      0.7890625,
      -5.03125,
      -0.400390625,
      7.8125,
      2.34375,
      -3.390625,
      6.25,
      -2.484375,
      -3.734375,
      1.3984375,
      2.4375,
      -2.890625,
      -2.015625,
      0.1630859375,
      -1.4609375,
      -3.1875,
      -2.515625,
      0.2333984375,
      -2.625,
      2.8125,
      -1.0234375,
      0.322265625,
      1.1875,
      -6.5625,
      -2.203125,
      0.63671875,
      -3.34375,
      2.4375,
      4.1875,
      -0.076171875,
      -2.578125,
      3.53125,
      1.28125,
      1.5390625,
      0.1953125,
      -2.90625,
      4.75,
      1.3046875,
      5.125,
      -0.55078125,
      -6.75,
      -0.8671875,
      0.73046875,
      0.40234375,
      3.890625,
      -2.84375,
      2.703125,
      5.9375,
      3.9375,
      -5.9375,
      -3.046875,
      2.625,
      -3.90625,
      -0.0032501220703125,
      3.984375,
      3.796875,
      -0.06982421875,
      1.171875,
      -1.90625,
      -5.71875,
      -1.03125,
      4.875,
      2.203125,
      -2.96875,
      1.3046875,
      5,
      1.3046875,
      5,
      -4.34375,
      -3.46875,
      -0.197265625,
      1.9140625,
      -3.296875,
      -1.4453125,
      7.15625,
      -1.875,
      0.4453125,
      -0.369140625,
      1.765625,
      1.40625,
      2.15625,
      0.8671875,
      -0.59375,
      3.59375,
      1.578125,
      -0.0341796875,
      3.25,
      -2.25,
      -0.030029296875,
      2.15625,
      -0.0751953125,
      -1.765625,
      1.9609375,
      -0.95703125,
      -0.126953125,
      -1.46875,
      -0.34765625,
      1.0703125,
      4.53125,
      4.5625,
      -1.1953125,
      -1.2578125,
      -0.490234375,
      8.375,
      -1.9921875,
      6.75,
      2.296875,
      9.6875,
      -0.5703125,
      -0.7109375,
      1.625,
      -3,
      -2.15625,
      -0.6328125,
      -5.75,
      -4.625,
      -0.53515625,
      -0.90625,
      -3.109375,
      3.9375,
      -5.21875,
      -0.0966796875,
      5.46875,
      -0.1220703125,
      4.78125,
      3.09375,
      4.46875,
      -0.609375,
      -0.33984375,
      -2.171875,
      -1.4375,
      -0.3359375,
      0.6953125,
      0.54296875,
      -6.46875,
      3.53125,
      2.0625,
      3.3125,
      0.310546875,
      -0.57421875,
      -2.734375,
      7.15625,
      0.63671875,
      -2.09375,
      4.25,
      0.74609375,
      1.265625,
      3.078125,
      4.03125,
      -3.40625,
      -2.03125,
      5.75,
      6.0625,
      -2.5,
      2.140625,
      0.6328125,
      -0.44140625,
      -2.390625,
      0.96875,
      0.11328125,
      1.5390625,
      -4.875,
      -0.94140625,
      -0.5546875,
      2.640625,
      -5.5625,
      -0.70703125,
      1.3125,
      -4.34375,
      3.46875,
      3.140625,
      -1.40625,
      0.71484375,
      -0.06689453125,
      6.40625,
      -0.3828125,
      -5.09375,
      -3.390625,
      -4.84375,
      -2.625,
      -0.0264892578125,
      2.578125,
      0.96484375,
      3.46875,
      -3.265625,
      -0.12890625,
      -4,
      -2.046875,
      -4.84375,
      4.53125,
      2.796875,
      -4.5625,
      -0.5703125,
      -2.625,
      -6.59375,
      -6.46875,
      -0.859375,
      -3.328125,
      0.0859375,
      -4.9375,
      -0.376953125,
      1.7109375,
      -5.375,
      0.10400390625,
      -1.4453125,
      -3.5,
      1.6796875,
      -0.78515625,
      0.76171875,
      -2.5625,
      1.1328125,
      1.75,
      -1.453125,
      3.46875,
      3.84375,
      2.84375,
      3.46875,
      -1.1484375,
      -0.384765625,
      -2.578125,
      6.96875,
      -3.515625,
      6.40625,
      5.9375,
      2.796875,
      -7.40625,
      3.625,
      -0.423828125,
      2.359375,
      -5.40625,
      -1.5390625,
      -2.53125,
      1.078125,
      2.5,
      -0.5390625,
      1.9921875,
      -4.6875,
      -3.203125,
      2.375,
      -5.125,
      -0.07568359375,
      2.828125,
      -0.2333984375,
      4.65625,
      -0.314453125,
      -0.2021484375,
      1.265625,
      0.9375,
      2.828125,
      -1.1953125,
      2.25,
      -4,
      0.85546875,
      -3.671875,
      1.2734375,
      -0.0037841796875,
      -2.828125,
      0.333984375,
      0.455078125,
      0.6484375,
      3.359375,
      2.609375,
      3.890625,
      1.671875,
      2.90625,
      -0.2294921875,
      1.0859375,
      2.625,
      -2.75,
      7.09375,
      1.2109375,
      -0.71875,
      -2.0625,
      -0.3828125,
      -3.546875,
      2.328125,
      -1.1328125,
      -4.28125,
      -0.37890625,
      -1.984375,
      -3.5,
      2.78125,
      0.1484375,
      0.345703125,
      2,
      3.109375,
      3.890625,
      1.984375,
      -0.69921875,
      0.61328125,
      2.0625,
      -4.59375,
      5.1875,
      -4.34375,
      -0.8359375,
      5.34375,
      2.5625,
      3.40625,
      -1.0390625,
      -1.3984375,
      -3.4375,
      0.419921875,
      3.203125,
      -2.4375,
      1.7421875,
      4.40625,
      -2.578125,
      1.0859375,
      -0.9453125,
      1.71875,
      1.1171875,
      -1.4921875,
      -0.52734375,
      2.359375,
      4.1875,
      -1.3359375,
      -1.8515625,
      -3.875,
      0.87109375,
      -0.88671875,
      -3.625,
      -1.59375,
      1.0234375,
      -1.3203125,
      -0.314453125,
      -0.19140625,
      -2.453125,
      -1.0546875,
      -3.40625,
      0.7421875,
      3.453125,
      0.23828125,
      0.9921875,
      0.326171875,
      2.625,
      -1.34375,
      2.265625,
      2.703125,
      -2.859375,
      2.890625,
      4.25,
      -1.5,
      4.59375,
      3.703125,
      -0.5234375,
      2.5625,
      -3.125,
      0.9765625,
      1.0703125,
      -2.578125,
      -0.76953125,
      -5.4375,
      0.8046875,
      4,
      2.890625,
      -2.15625,
      2.890625,
      -1.3828125,
      -2,
      4.09375,
      -3.765625,
      -4.65625,
      -1.3515625,
      0.59375,
      -4.84375,
      -2,
      -2.046875,
      1.1328125,
      2.65625,
      -7.09375,
      4.03125,
      -4.1875,
      7,
      1.7734375,
      -2.953125,
      -0.1669921875,
      -3.21875,
      2.75,
      -1.9609375,
      1.5,
      0.2333984375,
      -2.9375,
      2.75,
      -2.328125,
      1.390625,
      0.78125,
      -1.4296875,
      1.65625,
      -1.875,
      0.578125,
      0.984375,
      0.31640625,
      -7.96875,
      -5.3125,
      -3.640625,
      -2.1875,
      -0.1884765625,
      1.28125,
      -0.234375,
      0.5078125,
      0.1376953125,
      -4.625,
      0.51171875,
      -1.625,
      -1.9375,
      1.71875,
      -0.296875,
      4.9375,
      2.421875,
      -0.72265625,
      -0.8359375,
      0.396484375,
      -6.9375,
      -1.9375,
      -0.80078125,
      0.7890625,
      -3.359375,
      0.55078125,
      0.9453125,
      2.703125,
      -0.86328125,
      1.1953125,
      -0.69140625,
      2.84375,
      4,
      -0.0849609375,
      1.90625,
      -2.375,
      1.734375,
      -2.546875,
      -4.0625,
      -6.125,
      -1.265625,
      1.3515625,
      -3.40625,
      0.37109375,
      -2.546875,
      1.6015625,
      2.890625,
      -0.01708984375,
      -0.9375,
      0.9375,
      5.09375,
      -0.69140625,
      -3.4375,
      3.03125,
      -0.83984375,
      4.03125,
      -1.6796875,
      -2.359375,
      -1.8515625,
      1.5859375,
      1.2265625,
      2.8125,
      -2.234375,
      -2.546875,
      1.3984375,
      -0.50390625,
      -4.53125,
      -3.375,
      3.65625,
      -0.2119140625,
      5.46875,
      4.0625,
      -1.265625,
      -1.328125,
      -0.28515625,
      0.142578125,
      3.453125,
      1.6875,
      0.39453125,
      3.25,
      1.1875,
      6.5,
      -2.234375,
      -0.5625,
      -8.75,
      -1.6796875,
      9.0625,
      0.55078125,
      -0.765625,
      -2.015625,
      -0.005462646484375,
      1.7734375,
      0.80078125,
      2.90625,
      -1.375,
      -0.357421875,
      -1.640625,
      3.6875,
      2.484375,
      -3.640625,
      0.75,
      1.703125,
      -3.546875,
      1.8203125,
      4.28125,
      4.1875,
      -0.6328125,
      3.765625,
      -1.5859375,
      -3.296875,
      -3.859375,
      4.75,
      1.3984375,
      -0.28125,
      0.2216796875,
      -2.765625,
      1.109375,
      -0.84765625,
      1.1171875,
      5.78125,
      -4.03125,
      2.9375,
      -1.1796875,
      3.125,
      -0.609375,
      -2.78125,
      -1.1484375,
      4.34375,
      3.234375,
      -1.640625,
      -0.1708984375,
      -2.34375,
      -0.1337890625,
      -2.078125,
      -7.0625,
      1.6953125,
      1,
      2.265625,
      3.8125,
      -1.2109375,
      1.953125,
      0.515625,
      -3,
      -1.953125,
      -1.9765625,
      2.65625,
      3.3125,
      1.7890625,
      -3.84375,
      -0.7265625,
      -0.73046875,
      -1.375,
      -3.078125,
      5.78125,
      -2.296875,
      2.40625,
      2.9375,
      3.09375,
      -5.5625,
      -3.5625,
      -1.5078125,
      -2.6875,
      -6.5,
      1.625,
      0.9921875,
      -0.64453125,
      3.984375,
      0.734375,
      -2.953125,
      -0.11181640625,
      -3.765625,
      0.62890625,
      1.671875,
      2.234375,
      -5.1875,
      3.984375,
      -5.40625,
      -0.69140625,
      4.21875,
      -2.765625,
      -2.203125,
      -0.2021484375,
      -0.91015625,
      2.234375,
      2.609375,
      -1.0859375,
      -1.640625,
      2.390625,
      -2.5,
      -3.765625,
      -5.125,
      1.1015625,
      0.2021484375,
      -2.984375,
      1.8125,
      -1.484375,
      2.296875,
      -3.96875,
      -4.5,
      0.3828125,
      -1.4296875,
      -1.90625,
      4.15625,
      3.453125,
      -3.046875,
      1.9921875,
      -3.109375,
      7.84375,
      2.34375,
      -0.40234375,
      -0.0250244140625,
      -1.1328125,
      1.5625,
      -4.46875,
      4.25,
      -0.1748046875,
      -1.5234375,
      3.296875,
      5.84375,
      -4.34375,
      -1.6484375,
      0.890625,
      5.375,
      -5.09375,
      -0.1923828125,
      -1.015625,
      5.5,
      -2.671875,
      -0.44140625,
      -4.09375,
      -1.7890625,
      1.875,
      -1.78125,
      1.859375,
      -1.2421875,
      3.328125,
      -3.40625,
      -2.734375,
      2.515625,
      1.3125,
      3.78125,
      -3.390625,
      1.796875,
      3.703125,
      -2.421875,
      4.03125,
      -0.2314453125,
      -1.171875,
      -2.46875,
      0.50390625,
      -4.84375,
      -2.84375,
      -7.1875,
      0.5703125,
      -2.234375,
      -0.7578125,
      -1.3671875,
      1.453125,
      0.3046875,
      0.5390625,
      -2.765625,
      -0.62109375,
      -4.125,
      -3.921875,
      0.8984375,
      -2.734375,
      -3.4375,
      0.92578125,
      0.578125,
      1.8671875,
      5.4375,
      5,
      1.96875,
      -3.4375,
      2.4375,
      -3.203125,
      0.07470703125,
      -2.3125,
      0.051513671875,
      -1.7578125,
      -0.92578125,
      3.21875,
      2.984375,
      3.015625,
      -5.5625,
      -2.859375,
      -5.375,
      -0.8359375,
      -0.6953125,
      -0.8046875,
      0.640625,
      2.203125,
      4.59375,
      -2.984375,
      3.484375,
      1.9609375,
      0.62109375,
      -5.9375,
      0.96875,
      -1.7890625,
      3.875,
      2.421875,
      4.40625,
      -4.375,
      5.25,
      2.5625,
      -3.546875,
      2.90625,
      0.05908203125,
      -0.076171875,
      -3.71875,
      2.171875,
      -1.6640625,
      6.09375,
      -0.91796875,
      1.4609375,
      2.609375,
      1.296875,
      3.046875,
      2.8125,
      1.9453125,
      -0.47265625,
      3.375,
      0.87109375,
      -4.0625,
      -1.96875,
      4.84375,
      -2.890625,
      -0.79296875,
      3.234375,
      -0.486328125,
      2.375,
      1.75,
      3.8125,
      1.4296875,
      1.8984375,
      -3.546875,
      2.265625,
      -5.71875,
      -1.265625,
      -6.28125,
      -0.41015625,
      -6.21875,
      2.140625,
      3.484375,
      4.3125,
      -1.421875,
      -3.5,
      2.984375,
      2.203125,
      0.9609375,
      -6.25,
      5.375,
      2.015625,
      -0.365234375,
      -3.0625,
      -4.53125,
      4.65625,
      2.75,
      2.53125,
      -3.875,
      2.46875,
      1.0234375,
      -1.5859375,
      -4.34375,
      2.484375,
      -1.5546875,
      -7.15625,
      -4.625,
      -5.15625,
      4.46875,
      -2.921875,
      2.28125,
      5.46875,
      -1.3359375,
      3.140625,
      -1.0234375,
      2.40625,
      0.47265625,
      -1.78125,
      -0.90625,
      0.73046875,
      -0.4765625,
      -1.03125,
      4.625,
      -2.515625,
      1.9453125,
      -1.265625,
      2.0625,
      1.53125,
      -2.0625,
      -0.94140625,
      -5.78125,
      3.046875,
      3.25,
      0.7890625,
      0.318359375,
      -3.625,
      0.59375,
      0.390625,
      -0.390625,
      -2.015625,
      1.984375,
      -0.8515625,
      -0.91015625,
      0.2470703125,
      -1.140625,
      0.27734375,
      0.494140625,
      2.53125,
      -0.51953125,
      -0.54296875,
      -1.71875,
      -2.015625,
      -3.1875,
      3.09375,
      -0.6953125,
      4.71875,
      0.94140625,
      -2.515625,
      -1.3046875,
      3.359375,
      2.5,
      1.8046875,
      -0.53125,
      -2.328125,
      -0.6171875,
      4.3125,
      0.9375,
      -3.671875,
      -0.9609375,
      -0.52734375,
      -1.5625,
      -3.53125,
      -2.703125,
      -0.640625,
      5.6875,
      -3.828125,
      -2.609375,
      -1,
      2.34375,
      -1.515625,
      -10.125,
      0.20703125,
      0.72265625,
      0.150390625,
      -1.9609375,
      -0.212890625,
      2.34375,
      3.578125,
      0.98046875,
      4.34375,
      2.921875,
      -1.5625,
      2.53125,
      16.625,
      -5.125,
      -3.65625,
      0.408203125,
      -0.65625,
      -0.25,
      9.5,
      1.1875,
      -0.3671875,
      0.171875,
      1.8359375,
      3.484375,
      0.7890625,
      4.53125,
      1.9609375,
      1.59375,
      2.921875,
      1.796875,
      -0.1435546875,
      -4.3125,
      0.640625,
      -0.34765625,
      0.2080078125,
      2.75,
      -2.46875,
      3.1875,
      1.65625,
      -2.71875,
      -0.49609375,
      -4.25,
      0.365234375,
      -2.640625,
      -1.90625,
      -4.53125,
      -0.49609375,
      -2.921875,
      -0.353515625,
      -0.11865234375,
      -0.6796875,
      -2.3125,
      -1.1796875,
      -4.03125,
      1.4140625,
      -0.59765625,
      -2.59375,
      0.040283203125,
      -0.96484375,
      -0.11376953125,
      0.78515625,
      0.55859375,
      -1.609375,
      -2.09375,
      -4.15625,
      -0.79296875,
      3.390625,
      -0.82421875,
      -1.5625,
      -5.625,
      -3.140625,
      -1.296875,
      -1.234375,
      -3.390625,
      -3.953125,
      -1.625,
      -2.1875,
      -3.84375,
      -3.796875,
      -0.130859375,
      -0.08349609375,
      0.1474609375,
      -4.1875,
      -0.9765625,
      5.84375,
      2.34375,
      -1.65625,
      -3.828125,
      2.265625,
      3.3125,
      1.6171875,
      2.25,
      -2.5,
      3.359375,
      -2.0625,
      -1.390625,
      -2.546875,
      1.3828125,
      -5.46875,
      3.140625,
      -0.0130615234375,
      -1.671875,
      4.5,
      -4.03125,
      2.1875,
      0.412109375,
      -5.65625,
      0.10498046875,
      1.421875,
      -0.06103515625,
      -0.212890625,
      -1.6015625,
      3.140625,
      0.392578125,
      -1.1953125,
      -0.78125,
      -1.0625,
      -0.9453125,
      1.0859375,
      -1.9765625,
      2.03125,
      -0.6328125,
      -2.875,
      3.9375,
      -0.390625,
      -0.94140625,
      -0.10986328125,
      1.4765625,
      -4.6875,
      -0.21875,
      0.2412109375,
      -1.5,
      2.84375,
      -2.375,
      -0.01348876953125,
      -0.9609375,
      -8.3125,
      -4.125,
      -1.9296875,
      -4.21875,
      4.0625,
      -4.90625,
      0.95703125,
      -1.3984375,
      -3.8125,
      -2.484375,
      2.75,
      -4.25,
      3.328125,
      4.8125,
      3.109375,
      -0.87109375,
      -2.015625,
      2.578125,
      -1.0390625,
      -1.8515625,
      -0.94921875,
      1.3984375,
      -2.96875,
      3.78125,
      4.9375,
      0.478515625,
      -1.7890625,
      4.59375,
      0.83203125,
      -6.5625,
      2.078125,
      4.65625,
      -1.09375,
      0.37109375,
      -3.46875,
      -2.75,
      -0.01171875,
      -0.025390625,
      -3.921875,
      -2.625,
      -1.5859375,
      -0.1533203125,
      4.15625,
      -2.3125,
      -7.9375,
      1.4921875,
      2.5625,
      -6.21875,
      1.5078125,
      -2.34375,
      5.65625,
      -3.125,
      1.5703125,
      5.4375,
      -0.58984375,
      2.203125,
      4.59375,
      3.71875,
      -2.484375,
      -7.53125,
      4.84375,
      3.921875,
      -3.78125,
      2.671875,
      3.6875,
      -2.015625,
      0.9140625,
      -5.5,
      -3.640625,
      5.3125,
      4.625,
      -4.59375,
      0.236328125,
      -2.234375,
      0.578125,
      -1.8828125,
      -2.25,
      4.15625,
      2.125,
      2.84375,
      4.4375,
      -0.376953125,
      -3.125,
      -0.3828125,
      -1.2421875,
      -1.1328125,
      -2.328125,
      0.8125,
      0.283203125,
      3.1875,
      -6.53125,
      5.96875,
      2.59375,
      1.1640625,
      -2.296875,
      4.40625,
      2.453125,
      -0.35546875,
      -3.953125,
      -1.5078125,
      2.234375,
      4.0625,
      -6.4375,
      2.5,
      -3.140625,
      -0.451171875,
      -1.5390625,
      -0.294921875,
      0.9140625,
      -0.0380859375,
      -3.21875,
      -4.34375,
      -3.09375,
      4.21875,
      1.609375,
      -1.03125,
      3.28125,
      -0.86328125,
      2.65625,
      2.03125,
      -4.53125,
      1.6875,
      -4.75,
      0.2314453125,
      2.671875,
      -4.0625,
      1.640625,
      1.921875,
      2.828125,
      -0.310546875,
      0.2158203125,
      -3.390625,
      -4.4375,
      0.3828125,
      -5.8125,
      -0.6328125,
      0.9765625,
      -4.90625,
      3.8125,
      -2.234375,
      -0.490234375,
      -0.396484375,
      1.421875,
      -5.71875,
      5.4375,
      3.640625,
      -4.65625,
      3.5,
      -2.421875,
      -3.640625,
      1.109375,
      -2.578125,
      2.875,
      -5.9375,
      -0.0966796875,
      2.21875,
      -3.046875,
      0.015380859375,
      1.0390625,
      -1.7421875,
      1.40625,
      -2.3125,
      4.875,
      0.490234375,
      3.265625,
      4.5625,
      2.828125,
      4.28125,
      -3.8125,
      2.734375,
      -1.640625,
      -0.5703125,
      -3.265625,
      1.8125,
      -0.54296875,
      -3.546875,
      1.671875,
      3.640625,
      -0.244140625,
      -8.6875,
      -0.671875,
      1.09375,
      -2.328125,
      1.65625,
      1.796875,
      -0.12109375,
      -2.125,
      -0.2353515625,
      2.265625,
      4.65625,
      -2.65625,
      -2.21875,
      -1.7578125,
      3.25,
      0.98828125,
      -6.75,
      0.8046875,
      -0.07666015625,
      0.77734375,
      -1.8984375,
      0.66796875,
      -3.5625,
      2.890625,
      3.671875,
      -4.3125,
      1.34375,
      2.65625,
      1.453125,
      3.734375,
      -0.53515625,
      0.61328125,
      1.9453125,
      -3.65625,
      -5.625,
      2.015625,
      0.1396484375,
      -1.15625,
      1.1953125,
      -2.40625,
      5.46875,
      1.3828125,
      3.5625,
      -5.84375,
      4.09375,
      1.0546875,
      -8.1875,
      4.25,
      -3.75,
      0.181640625,
      -4.3125,
      -5.15625,
      -2.453125,
      3.109375,
      -1.0859375,
      -1.8125,
      4.40625,
      0.80859375,
      0.20703125,
      2.171875,
      -1.1953125,
      -0.625,
      2.40625,
      3.171875,
      -3.03125,
      4.78125,
      3.984375,
      -0.7734375,
      0.2578125,
      -2.890625,
      2.65625,
      -2.328125,
      -3.953125,
      3.921875,
      3.84375,
      1.0078125,
      -2.453125,
      -4.375,
      0.138671875,
      -1.6875,
      -3.296875,
      1.921875,
      -3.25,
      0.91796875,
      -2.578125,
      -0.275390625,
      1.7890625,
      -4.3125,
      -2.484375,
      -1.9921875,
      -2.265625,
      1.3359375,
      2.234375,
      2.78125,
      -2.125,
      -0.7109375,
      2.953125,
      1.8515625,
      -0.29296875,
      -3.34375,
      0.37109375,
      -2.25,
      -3.09375,
      -1.15625,
      2.5,
      -1.984375,
      -2.28125,
      1.7578125,
      -0.80078125,
      1.203125,
      -5.34375,
      -2.1875,
      1.421875,
      2.21875,
      0.7578125,
      -2.484375,
      -0.94921875,
      1.1484375,
      3.75,
      -4.1875,
      -2.265625,
      -0.369140625,
      5,
      -5.90625,
      -3.375,
      0.107421875,
      -2.09375,
      1.1875,
      3.15625,
      1.2734375,
      0.58203125,
      0.361328125,
      -5.125,
      -1.4296875,
      7.59375,
      4.78125,
      -1.1171875,
      0.478515625,
      -2.71875,
      -1.5,
      4.84375,
      7,
      -3.84375,
      -1.375,
      -0.9375,
      -3.5,
      -2.765625,
      -2.703125,
      1.8125,
      -0.431640625,
      -6.375,
      5.53125,
      -2.390625,
      3.0625,
      2.84375,
      -2.25,
      4.59375,
      -4.0625,
      0.1328125,
      -1.1484375,
      2.0625,
      2.375,
      -3.046875,
      -1.0390625,
      -5.03125,
      -1.7265625,
      -1.3515625,
      -1.7421875,
      0.2216796875,
      0.25,
      6.1875,
      1.34375,
      -1.546875,
      -1.4375,
      -0.62890625,
      2.609375,
      -1.1484375,
      -1.9921875,
      -1.4296875,
      -1.359375,
      0.828125,
      -2.0625,
      1.625,
      -4.5625,
      -0.578125,
      -2.453125,
      2.859375,
      1.6015625,
      1.96875,
      -3.609375,
      -4.0625,
      -2.6875,
      2.3125,
      0.87109375,
      3.625,
      2.25,
      3.515625,
      1.65625,
      -1.0859375,
      2.25,
      5.15625,
      3.140625,
      -2.296875,
      1.6015625,
      -0.375,
      0.66796875,
      -0.81640625,
      -0.61328125,
      1.109375,
      2.734375,
      4.15625,
      -1.8359375,
      -0.201171875,
      -3.390625,
      -2.078125,
      -2.078125,
      0.66796875,
      2.125,
      3.15625,
      0.515625,
      1.265625,
      -1.0546875,
      5.125,
      -0.12353515625,
      3.265625,
      -1.078125,
      -0.9765625,
      -1.890625,
      0.1611328125,
      -2.125,
      -3.78125,
      0.79296875,
      -1.328125,
      1.8203125,
      -0.65625,
      -3.4375,
      0.0595703125,
      4.90625,
      -2.59375,
      2.015625,
      -2.296875,
      2.0625,
      0.95703125,
      0.4609375,
      1.1171875,
      2.953125,
      -1.1875,
      2.8125,
      -2.3125,
      0.1259765625,
      1.640625,
      3.15625,
      -0.205078125,
      -0.435546875,
      0.22265625,
      0.6796875,
      -2.34375,
      -0.84765625,
      2.546875,
      -2.734375,
      4.40625,
      0.8046875,
      -0.98828125,
      0.40625,
      -0.8984375,
      -2.609375,
      2.65625,
      -3.421875,
      -1.359375,
      0.8671875,
      0.1748046875,
      0.72265625,
      -0.890625,
      2.859375,
      2.421875,
      1.1484375,
      -1.4453125,
      -3.453125,
      -1.171875,
      -0.45703125,
      -2.8125,
      -1.46875,
      1.5234375,
      0.099609375,
      -1.7265625,
      0.95703125,
      1.9765625,
      2.0625,
      -0.08642578125,
      -1.6640625,
      -1.671875,
      1.125,
      -0.2353515625,
      -1.2109375,
      0.734375,
      1.6796875,
      4.09375,
      1.34375,
      -1.375,
      0.765625,
      -0.53515625,
      -0.625,
      0.2734375,
      -0.89453125,
      -1.859375,
      -0.283203125,
      0.62890625,
      -0.3359375,
      0.236328125,
      0.09326171875,
      1.5,
      0.63671875,
      0.42578125,
      3.328125,
      1.015625,
      -0.62109375,
      3.015625,
      3.890625,
      -1.90625,
      -2.734375,
      -0.75390625,
      3.046875,
      3.171875,
      -0.435546875,
      -2.15625,
      1.6875,
      -1.6640625,
      -2.484375,
      0.6171875,
      4.03125,
      -4.03125,
      0.69140625,
      1.78125,
      -1.796875,
      -0.265625,
      -1.296875,
      1.2890625,
      1.4921875,
      -3.5,
      -3.78125,
      -0.46875,
      0.8125,
      0.5703125,
      0.5,
      -0.61328125,
      0.8359375,
      -2.140625,
      -0.06591796875,
      2.015625,
      -2.96875,
      0.51171875,
      -1.1484375,
      -0.63671875,
      0.06396484375,
      -0.10205078125,
      0.0291748046875,
      3.46875,
      -2.765625,
      -1.3046875,
      -0.4765625,
      0.439453125,
      -1.2734375,
      2.546875,
      2.140625,
      -4.0625,
      1.71875,
      -2.953125,
      0.4609375,
      -0.287109375,
      1.515625,
      2,
      -1.53125,
      -0.51171875,
      0.73828125,
      -0.396484375,
      1.8671875,
      -0.640625,
      -0.4296875,
      1.203125,
      2.875,
      2.8125,
      3.046875,
      -0.353515625,
      -1.609375,
      -2.515625,
      -1.5859375,
      2.21875,
      0.66015625,
      2.875,
      -3.53125,
      0.671875,
      1.4921875,
      -0.263671875,
      0.11328125,
      -0.1416015625,
      2.09375,
      2.015625,
      -0.5,
      4.28125,
      2.875,
      1.4375,
      1.375,
      -0.87890625,
      1.9140625,
      -0.62109375,
      -2.46875,
      0.32421875,
      -1.625,
      3.90625,
      -0.486328125,
      -1.59375,
      -0.0771484375,
      -0.392578125,
      1.171875,
      0.349609375,
      2.421875,
      -1.2109375,
      2.96875,
      0.1552734375,
      -0.02734375,
      0.578125,
      -3.03125,
      0.439453125,
      3.390625,
      -5.28125,
      -0.76171875,
      -0.79296875,
      0.84375,
      0.337890625,
      -0.115234375,
      -0.2265625,
      -0.671875,
      -1.5390625,
      -0.578125,
      0.34375,
      1.5625,
      2.0625,
      1.5078125,
      1.640625,
      1.9765625,
      -1.21875,
      0.337890625,
      0.1142578125,
      0.828125,
      1.578125,
      -0.400390625,
      0.92578125,
      -0.2392578125,
      -1.2109375,
      -4.6875,
      -4,
      -2.53125,
      -0.8125,
      2.9375,
      1.2421875,
      -0.91796875,
      -1.5234375,
      -0.2236328125,
      -0.28125,
      3.0625,
      3.109375,
      -2.921875,
      2.984375,
      -2.3125,
      -0.494140625,
      -1.5625,
      -1.1953125,
      -1.1953125,
      0.44140625,
      2.796875,
      0.10888671875,
      2.078125,
      -1.7109375,
      -0.98828125,
      2.28125,
      0.6796875,
      -1.2109375,
      1.1484375,
      0.375,
      1.40625,
      -1.0859375,
      2.421875,
      -1.0234375,
      3.484375,
      -0.306640625,
      0.353515625,
      2.5,
      2.515625,
      4.03125,
      0.83203125,
      -3.78125,
      -1.6640625,
      1,
      0.498046875,
      1.140625,
      0.3828125,
      0.5859375,
      6.65625,
      0.314453125,
      -1.71875,
      -1.421875,
      -1.484375,
      -1.59375,
      0.83984375,
      5.125,
      -5.59375,
      1.0859375,
      0.005645751953125,
      -1.421875,
      0.259765625,
      1.7734375,
      3.5,
      1.265625,
      1.5625,
      1.546875,
      0.439453125,
      -3.515625,
      0.2197265625,
      0.14453125,
      1.9765625,
      1.0546875,
      -1.6875,
      -0.83984375,
      0.267578125,
      -0.98828125,
      2.796875,
      -0.6796875,
      0.023681640625,
      3.75,
      0.1943359375,
      1.8984375,
      -0.6484375,
      -0.263671875,
      5.34375,
      -0.50390625,
      -1.7890625,
      -1.3046875,
      -2.390625,
      3.375,
      0.90234375,
      -0.27734375,
      -2.421875,
      2.5625,
      -0.94921875,
      -2.578125,
      -3.5,
      -1.671875,
      -2.96875,
      -1.5703125,
      -4.625,
      -0.98828125,
      -1.90625,
      4.3125,
      -1.4765625,
      0.498046875,
      1.1796875,
      4.4375,
      2.640625,
      3.875,
      -0.031494140625,
      2.71875,
      -0.984375,
      0.6328125,
      4.03125,
      -1.1328125,
      -3.796875,
      0.361328125,
      -1.2578125,
      -2.890625,
      -3.109375,
      -0.92578125,
      -2.390625,
      -0.64453125,
      -1.4375,
      -2.84375,
      0.384765625,
      1.3984375,
      -4.5625,
      0.5,
      -1.84375,
      0.69140625,
      0.7578125,
      0.6328125,
      -0.388671875,
      -0.03857421875,
      4.84375,
      -0.67578125,
      -0.04736328125,
      -1.25,
      -1.234375,
      0.6640625,
      -2,
      2.5,
      2.15625,
      -2.03125,
      -1.1640625,
      -1.3359375,
      2.578125,
      -3.015625,
      1.3984375,
      -0.330078125,
      -1.3046875,
      1.578125,
      6.0625,
      1.9140625,
      1.3671875,
      -1.3125,
      3.078125,
      -4.15625,
      -0.1826171875,
      -1.5078125,
      -0.91015625,
      -2.25,
      2.25,
      -1.2578125,
      3.265625,
      -1.1328125,
      2.3125,
      0.72265625,
      -4.84375,
      -0.1669921875,
      -2.953125,
      -2.484375,
      3.296875,
      -0.9609375,
      -3.25,
      -1.1953125,
      4.03125,
      -3.15625,
      2,
      -1.0859375,
      -0.44921875,
      2.15625,
      2.046875,
      1.15625,
      3.28125,
      -0.25390625,
      1.296875,
      5.375,
      1.796875,
      1.265625,
      1.484375,
      -1.640625,
      1.375,
      -1.1796875,
      2.5,
      -2.5625,
      -3.265625,
      0.08984375,
      0.1767578125,
      -0.54296875,
      -2.1875,
      2.359375,
      0.76171875,
      1.6015625,
      -1.8125,
      3.390625,
      0.86328125,
      3.78125,
      3.796875,
      0.71484375,
      -0.1708984375,
      -6.25,
      -2.5625,
      -0.671875,
      1.5390625,
      0.60546875,
      0.7265625,
      0.5078125,
      -2.03125,
      0.91796875,
      -1.78125,
      2.296875,
      -1.5859375,
      -0.86328125,
      -0.419921875,
      0.125,
      -0.1689453125,
      0.349609375,
      -4.0625,
      2.578125,
      -2.484375,
      -1.7265625,
      5.125,
      -0.7265625,
      -2.140625,
      -2.15625,
      2.515625,
      2.625,
      0.72265625,
      -0.279296875,
      0.0986328125,
      2.203125,
      -3.046875,
      1.4296875,
      2.921875,
      -0.16015625,
      1.53125,
      -1.1171875,
      -0.7734375,
      -5.46875,
      -1.125,
      -1.1875,
      1.671875,
      1.875,
      0.91015625,
      -0.43359375,
      5.59375,
      2.78125
    ],
    "structure": {
      "sections": [
        {
          "title": "The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "1. INTRODUCTION",
          "level": 1,
          "start_line": 17
        },
        {
          "title": "2. UNDERSTANDING LARGE LANGUAGE MODELS IN EDUCATION",
          "level": 1,
          "start_line": 27
        },
        {
          "title": "2.1. THE ARCHITECTURE AND MECHANISMS OF LLMS",
          "level": 1,
          "start_line": 29
        },
        {
          "title": "2.2. THE ROLE OF FINE-TUNING AND PROMPT-TUNING",
          "level": 1,
          "start_line": 37
        },
        {
          "title": "3. AUTOMATED QUESTION GENERATION: METHODOLOGIES AND TECHNIQUES",
          "level": 1,
          "start_line": 45
        },
        {
          "title": "3.1. GENERATING Diverse AND CONTEXTUALLY RELEVANT QUESTIONS",
          "level": 1,
          "start_line": 47
        },
        {
          "title": "3.2. TYPES OF QUESTIONS GENERATED BY LLMS",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "4. AUTOMATED ANSWER ASSESSMENT: EVALUATING STUDENT RESPONSES",
          "level": 1,
          "start_line": 83
        },
        {
          "title": "4.1. THE CAPABILITIES OF LLMS IN AUTOMATED ANSWER ASSESSMENT",
          "level": 1,
          "start_line": 85
        },
        {
          "title": "4.2. EXAMPLES OF SUCCESSFUL ASSESSMENTS AND AREAS FOR IMPROVEMENT",
          "level": 1,
          "start_line": 97
        },
        {
          "title": "5. HUMAN EVALUATION AND QUALITY METRICS FOR GENERATED QUESTIONS",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "5.1. ASSESSING THE QUALITY OF GENERATED QUESTIONS",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "5.2. VARIATIONS IN QUALITY ACROSS DIFFERENT METHODS",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "6. BROADER IMPLICATIONS AND FUTURE DIRECTIONS",
          "level": 1,
          "start_line": 131
        },
        {
          "title": "6.1. THE ROLE OF LLMS IN PERSONALIZED AND ADAPTIVE LEARNING",
          "level": 1,
          "start_line": 133
        },
        {
          "title": "6.2. ETHICAL CONSIDERATIONS AND CHALLENGES",
          "level": 1,
          "start_line": 141
        },
        {
          "title": "6.3. FUTURE DIRECTIONS IN AUTOMATED QUESTION GENERATION AND ASSESSMENT",
          "level": 1,
          "start_line": 149
        },
        {
          "title": "7. CONCLUSION",
          "level": 1,
          "start_line": 157
        },
        {
          "title": "REFERENCES",
          "level": 1,
          "start_line": 163
        }
      ]
    },
    "suggested_tags": [
      "教育AI",
      "自动出题",
      "LLM",
      "答案评估",
      "提示工程"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.98,
        "reason": "全文聚焦生成式AI在个性化教学、自动出题与评分等教育场景的应用，是核心应用领域。"
      },
      {
        "name": "自动出题",
        "confidence": 0.96,
        "reason": "系统探讨零样本、思维链、微调与提示微调等方法生成多语言、多题型试题，为论文主要任务。"
      },
      {
        "name": "LLM",
        "confidence": 0.95,
        "reason": "以GPT-4等大规模语言模型为技术底座，分析其机制、优势与挑战，贯穿全文。"
      },
      {
        "name": "答案评估",
        "confidence": 0.92,
        "reason": "专设章节研究LLM自动评分、反馈与 misconception 检测，是论文另一关键任务。"
      },
      {
        "name": "提示工程",
        "confidence": 0.9,
        "reason": "比较零样本、CoT 等提示策略对出题与评估质量的影响，为方法学重点。"
      }
    ],
    "category": "教育AI",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283473265",
          "title": "AI-Driven Question Generation System: Benchmarking Large Language Models for Examination Systems",
          "authors": [
            "Shahd Hassan Abdelhamied",
            "Kenzy Khaled Antr",
            "Cecilia Mohamed Abdellah",
            "Mohamed Khaled Antr",
            "Zeyad Mohamed Mahrous",
            "Noha Gamal Eldin"
          ],
          "year": 2025,
          "venue": "2025 16th Student Research Conference on Applied Computing (SRC)",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281553166",
          "title": "Neural Network Model for Automated Test Generation for Students in the Moodle System Based on the Analysis of Methodological Materials",
          "authors": [
            "К. С. Курочка",
            "Ю. С. Башаримов",
            "Konstantin S. Kurochka",
            "Yury S. Basharymau"
          ],
          "year": 2025,
          "venue": "Digital Transformation",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281511200",
          "title": "AI-Based Examination Content Creation: Evaluating Large Language Models for Question Generation",
          "authors": [
            "Shahd Hassan Abdelhamied",
            "Kenzy Khaled Antr",
            "Cecilia Mohamed Abdellah",
            "Mohamed Khaled Antr",
            "Zeyad Mohamed Mahrous",
            "Noha Gamal Eldin"
          ],
          "year": 2025,
          "venue": "Internet, Multimedia Systems and Applications",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280407655",
          "title": "Question Crafting System for Personalized Learning using Large Language Model",
          "authors": [
            "R. Dhanalakshmi",
            "Madala Akhil",
            "Gondrala Chethan",
            "Bijja Arun Teja",
            "Kulampalli Divyand"
          ],
          "year": 2025,
          "venue": "2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:279191318",
          "title": "Optimizing Automated Question Generation for Educational Assessments",
          "authors": [
            "Sumayyah Alamoudi",
            "Lama A. Al Khuzayem",
            "A. Jamal"
          ],
          "year": 2025,
          "venue": "Engineering, Technology &amp; Applied Science Research",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:273969892",
          "title": "CryptoLLM: Unleashing the Power of Prompted LLMs for SmartQnA and Classification of Crypto Posts",
          "authors": [
            "Aniket Deroy",
            "Subhankar Maity"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:273963099",
          "title": "Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models",
          "authors": [
            "Aniket Deroy",
            "Subhankar Maity"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:273850172",
          "title": "Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages",
          "authors": [
            "Aniket Deroy",
            "Subhankar Maity"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:278672872",
          "title": "Toward Generating Quality Test Questions and Answers Using Quantized Low-Rank Adapters in LLMs",
          "authors": [
            "Jebum Choi",
            "SeongJun Hong",
            "SeoYoon Hong",
            "JiYeon Park",
            "Eun-Sung Jung"
          ],
          "year": 2025,
          "venue": "IEEE Access",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280036248",
          "title": "Machine Learning in Education: Innovations, Impacts, and Ethical Considerations",
          "authors": [
            "E. Elbasi",
            "Muhammad Nadeem",
            "Y. Alzoubi",
            "A. Topcu",
            "Greeshma Varghese"
          ],
          "year": 2025,
          "venue": "IEEE Access",
          "citation_count": 2
        }
      ],
      "citations_fetched_at": "2025-12-16T23:20:25.227984",
      "references": [
        {
          "external_id": "CorpusId:270209971",
          "title": "How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors?",
          "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
          ],
          "year": 2024,
          "venue": "Educational Data Mining",
          "citation_count": 10
        },
        {
          "external_id": "CorpusId:269921800",
          "title": "Exploring the Capabilities of Prompted Large Language Models in Educational and Assessment Applications",
          "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
          ],
          "year": 2024,
          "venue": "Educational Data Mining",
          "citation_count": 14
        },
        {
          "external_id": "CorpusId:269626345",
          "title": "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences",
          "authors": [
            "John Stamper",
            "Ruiwei Xiao",
            "Xinynig Hou"
          ],
          "year": 2024,
          "venue": "AIED Companion",
          "citation_count": 67
        },
        {
          "external_id": "CorpusId:267527222",
          "title": "Beyond Traditional Assessment: Exploring the Impact of Large Language Models on Grading Practices",
          "authors": [
            "Oluwole Fagbohun",
            "Nwaamaka Pearl Iduwe",
            "Mustapha Abdullahi",
            "Adeseye Ifaturoti",
            "Obinna Nwanna"
          ],
          "year": 2024,
          "venue": "Journal of Artificial Intelligence, Machine Learning and Data Science",
          "citation_count": 41
        },
        {
          "external_id": "CorpusId:268613943",
          "title": "A Survey on Security and Privacy of Large Multimodal Deep Learning Models: Teaching and Learning Perspective",
          "authors": [
            "Md. Abdur Rahman",
            "Lamyaa Alqahtani",
            "Amna Albooq",
            "Alaa Ainousah"
          ],
          "year": 2024,
          "venue": "2024 21st Learning and Technology Conference (L&T)",
          "citation_count": 15
        },
        {
          "external_id": "CorpusId:266999078",
          "title": "A Novel Multi-Stage Prompting Approach for Language Agnostic MCQ Generation using GPT",
          "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
          ],
          "year": 2024,
          "venue": "European Conference on Information Retrieval",
          "citation_count": 20
        },
        {
          "external_id": "CorpusId:266668276",
          "title": "Using LLMs to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students' text revision, motivation, and positive emotions",
          "authors": [
            "Jennifer Meyer",
            "Thorben Jansen",
            "Ronja Schiller",
            "Lucas Liebenow",
            "Marlene Steinbach",
            "Andrea Horbach",
            "Johanna Fleckenstein"
          ],
          "year": 2023,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 182
        },
        {
          "external_id": "CorpusId:261470278",
          "title": "Leading teachers' perspective on teacher-AI collaboration in education",
          "authors": [
            "Jinhee Kim"
          ],
          "year": 2023,
          "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:259367508",
          "title": "Exploring the potential of artificial intelligence tools in educational measurement and assessment",
          "authors": [
            "Valentine Joseph Owan",
            "Kinsgley Bekom Abang",
            "D. Idika",
            "Eugene Onor Etta",
            "B. Bassey"
          ],
          "year": 2023,
          "venue": "Eurasia Journal of Mathematics, Science and Technology Education",
          "citation_count": 221
        },
        {
          "external_id": "CorpusId:262183178",
          "title": "Developing a framework to re-design writing assignment assessment for the era of Large Language Models",
          "authors": [
            "Ya-Ping Hsiao",
            "Nadia Klijn",
            "Mei-Shiu Chiu"
          ],
          "year": 2023,
          "venue": "Learning: Research and Practice",
          "citation_count": 31
        }
      ],
      "references_fetched_at": "2025-12-16T23:20:26.278416"
    },
    "translated_content": "# 生成式人工智能时代的未来学习：基于大语言模型的自动问题生成与评估\n\nSubhankar Maity  \n人工智能系  \n印度理工学院哈拉格普尔分校  \nsubhankar.ai@kgpian.iitkgp.ac.in\n\nAniket Deroy  \n计算机科学与工程系  \n印度理工学院哈拉格普尔分校  \nroydanik18@kgpian.iitkgp.ac.in\n\n近年来，大语言模型（LLMs）与生成式人工智能彻底革新了自然语言处理（NLP），在教育领域展现出前所未有的能力。本章探讨 LLMs 在自动问题生成与答案评估中的变革潜力。首先剖析 LLMs 的内在机制，强调其理解并生成类人文本的能力；继而阐述创建多样化、语境相关问题的诸多方法，通过个性化、自适应策略提升学习效果。文中评估了零样本提示（zero-shot prompting）与思维链提示（chain-of-thought prompting）等关键提示技术在生成高质量问题（涵盖开放式与多选题，且支持多语言）方面的有效性。此外，探讨了微调（fine-tuning）与提示微调（prompt-tuning）等高级 NLP 方法在生成任务特定问题中的作用，尽管其伴随一定成本。本章亦涵盖生成问题的人工评估，揭示不同方法在质量上的差异及改进空间。进一步地，文章深入自动答案评估，展示 LLMs 如何精准评判作答、提供建设性反馈，并识别细微理解或误解。案例既呈现了成功评估，也指出待改进之处。讨论强调，在适当引导下，LLMs 有望替代昂贵且耗时的人工评估，彰显其在简化教育流程中的高级理解与推理能力。\n\n关键词：自然语言处理（NLP），大语言模型（LLMs），教育，自动问题生成（AQG），答案评估，提示工程\n\n# 1. 引言\n\n教育格局正以前所未有的速度演进，先进技术的融入不断挑战传统教学方式。其中，大语言模型（LLMs）已成为强大工具，足以革新学习与评估的路径。以 GPT-4（Achiam 等，2023）及后续系统为代表的这些模型，已展现出非凡的类人文本理解与生成能力，使其能够执行曾专属于人类的任务。of human educators (Brown et al., 2020; Floridi and Chiriatti, 2020)。在教育领域，问题生成与测评是塑造学习体验的关键环节。传统上，这些任务需要大量人力投入，教师需精心设计既能检验知识又能促进深层理解的问题（Mazidi and Nielsen, 2014）。对学生回答的评估，尤其是开放式回答，更是一项劳动密集型工作，需要充分考虑语境、细微差别以及学生个体差异（Chappuis et al., 2015）。然而，随着个性化与自适应学习需求的不断增长，纯人工方法的局限性日益凸显。\n\n本章深入探讨大语言模型（LLMs）在自动化这些核心教育任务中的变革潜力。我们将研究如何利用 LLMs 生成从简单事实性提问到复杂开放式问题的多样化题型，使其既贴合语境又契合教育目标（Maity et al., 2023; Maity et al., 2024a; Maity et al., 2024c）。同时，我们考察 LLMs 在自动答案评估中的能力：这些模型可在规模和效率上超越人工，评估学生回答、提供反馈，甚至识别微妙的误解（Fagbohun et al., 2024）。将 LLMs 引入教育过程并非没有挑战。生成问题的质量与相关性、自动评估的准确性，以及依赖 AI 带来的伦理问题，均需审慎考量（Floridi and Cowls, 2022）。\n\n本章回应上述关切，提出如何引导并优化 LLMs，使其补充并增强而非取代以人为主导的教育。随后各节中，我们首先概述 LLMs，聚焦其架构与底层机制，为后续讨论教育问题生成的各类方法与提示技术奠定基础。继而探讨微调（fine-tuning）与提示调优（prompt-tuning）等高级 NLP 方法，以提升生成问题的质量与针对性。本章还将介绍用于评估问题质量的人工评价指标，以及 LLMs 在自动答案评估中的表现。最后，我们讨论将 LLMs 整合至教育中的广泛影响，强调其潜在益处与需应对的挑战，以充分实现其潜能。\n\n# 2. 教育中的大语言模型：理解篇\n\n# 2.1 LLMs 的架构与机制大型语言模型（LLMs）以深度学习与 Transformer 架构（Vaswani et al., 2017）为基础，在自然语言处理（NLP）领域引发了范式变革。这类模型通过大规模文本语料训练，旨在根据给定输入预测并生成文本（Radford et al., 2019）。其理解语境、识别模式并生成连贯且语境恰当文本的能力，使其尤为适用于教育场景。\n\nLLM 的核心在于 Transformer 架构，该架构利用自注意力机制衡量句子中不同词汇之间的相对重要性（Vaswani et al., 2017）。这使得模型能够捕获文本中的长程依赖，从而理解复杂句子并生成细致入微的回应。就教育应用而言，这意味着 LLM 不仅能生成语法正确的问题，还能确保问题在语境上相关且符合教学原则。LLM 的训练过程涉及对涵盖广泛主题与写作风格的多样化数据集的暴露（Raiaan et al., 2024）。这种大规模训练使模型形成对语言的广泛理解，进而可应用于问题生成与评估等具体任务。然而，尽管 LLM 在生成类人文本方面表现卓越，其在教育情境中的有效性仍取决于针对特定任务的引导与微调程度。\n\n# 2.2 微调与提示微调的作用\n\n为使 LLM 适应教育领域的问题生成与评估，研究者采用微调（fine-tuning）与提示微调（prompt-tuning）等技术。微调通过在专门构建、与目标任务高度对齐的数据集上继续训练 LLM，使模型习得教育内容的细微差别，从而生成更贴合课程与学习目标的问题（Li et al., 2023）。\n\n提示微调则通过设计特定提示，引导 LLM 生成期望输出（Lester et al., 2021）。该技术利用模型既有知识，并将其导向生成语境相关且具教学价值的问题。例如，提示可指令 LLM 基于特定文本段落生成问题，促使模型聚焦对学习至关重要的关键概念与思想。微调（fine-tuning）与提示调优（prompt-tuning）各有优势与挑战。微调能够产生高度专门化、在特定任务上表现卓越的模型，但其过程资源密集，且需依赖大规模、高质量的数据集（Raffel et al., 2020）。提示调优则更为灵活且资源需求较低，但其效果高度依赖于提示的设计，且未必能达到微调模型所具备的特定任务精度（Lester et al., 2021）。尽管存在上述挑战，两种技术均在提升大语言模型于教育场景中的表现方面展现出巨大潜力。\n\n# 3. 自动问题生成：方法论与技术\n\n# 3.1 生成多样化且情境相关的问题\n\n利用大语言模型（LLMs）进行自动问题生成，已成为教育领域的一项有力工具，能够针对多元学习目标生成多样化且情境相关的问题（Maity et al., 2024a）。该领域所采用的方法论丰富多样，各自对生成内容的质量与适用性产生贡献。以下列举了本领域中的关键方法：\n\n- **零样本提示（Zero-Shot Prompting）**：零样本学习使得 GPT-3 等模型（Brown et al., 2020）可在极少指令下生成问题。模型依托其预训练知识，无需额外示例或微调，即可直接从给定文本生成相关问题（Brown et al., 2020）。该方法适用于跨领域问题生成，但生成质量可能因输入文本复杂度而异（Maity et al., 2023；Maity et al., 2024b）。\n- **少样本提示（Few-Shot Prompting）**：少样本提示通过向模型提供若干任务示例来引导问题生成。通过在提示中加入少量问答对，该方法可增强模型对任务的理解，从而提升生成问题的相关性与质量（Brown et al., 2020）。当所需问题格式或内容较为复杂、需向模型明确界定时，此技术尤为有效。- 思维链提示（Chain-of-Thought Prompting）：一种结构化技术，通过在生成最终问题之前引导大语言模型（LLM）进行逐步推理。例如，模型可先被要求总结一段文本、识别关键概念，然后生成一个考查这些概念理解的问题（Wei et al., 2022；Maity et al., 2024d）。该方法尤其适用于生成需要批判性思维与分析的高阶问题，确保问题与特定教育目标一致。  \n- 微调（Fine-Tuning）：通过在目标领域相关的问题-答案数据集上进一步训练 LLM，使其学习有效问题的模式与结构，从而生成更准确且语境特定的问题（Raffel et al., 2020）。该方法资源密集，但可得到高度专业化的模型，能够针对特定学科或课程生成高质量问题（Maity et al., 2023）。  \n- 提示微调（Prompt-Tuning）：一种新近且计算高效的技术，仅调整少量参数（即提示），其余模型参数保持不变。该方法已在多种教育场景中被证明能有效生成高质量问题，尤其适用于在不进行大规模重训练的情况下，将通用 LLM 适配到特定任务（Lester et al., 2021）。提示微调可快速实现 LLM 的适配与定制，以生成既相关又符合特定教育目标的问题。  \n- 多面与多语言问题生成：LLM 既能生成开放式问题（Maity et al., 2023），也能生成选择题（Maity et al., 2024d），以满足不同评估需求。开放式问题促进批判性思维与探究，而选择题则便于评估具体知识或技能（Maity et al., 2024d）。此外，LLM 的多语言能力使其能够在多种语言中生成问题，成为语言学习与跨文化教育的重要工具（Radford et al., 2019；Maity et al., 2024d）。\n\n若有效应用，这些方法可通过生成多样化、高质量的问题，提升教育过程，满足不同学习情境与目标。随着 LLM 的不断演进，这些技术的整合将进一步提高教育领域自动问题生成的相关性、准确性与实用性。\n\n# 3.2. LLM 生成的问题类型\n\n在教育语境中，不同类型的问题承担不同的教学功能，而 LLM 能够生成广泛的问题类型。主要类别如下：- 事实性问题：此类问题聚焦于对具体信息（如日期、定义或事件）的回忆，通常较为直接，旨在评估学生对学科内容的记忆与基本理解（Mulla and Gharpure, 2023）。\n\n示例：“法国的首都是哪里？”\n\n- 开放性问题：开放性问题旨在鼓励深入思考与探索，允许学生自由且富有创造性地表达观点。这类问题并无唯一正确答案，有助于促进批判性思维与课堂讨论（Mulla and Gharpure, 2023；Maity et al., 2023）。\n\n示例：“购买力平价的作用是什么？”\n\n- 多项选择题（MCQs）：MCQs 通过提供一组备选答案，要求学生从中选出正确答案，以评估特定知识或技能。因其测试与评分的效率而被广泛使用（Maity et al., 2024d）。\n\n示例：“以下哪颗行星是太阳系中最大的？\n\n(a) 地球 (b) 木星 (c) 火星 (d) 金星”\n\n凭借先进的语言处理能力，大语言模型（LLMs）能够有效生成上述多种题型，并根据不同的教育情境与学习目标进行适配。\n\n# 4. 自动化答案评估：对学生回答的评价\n\n# 4.1 大语言模型在自动化答案评估中的能力\n\n除生成问题外，大语言模型在自动化答案评估方面也展现出显著潜力（Fagbohun et al., 2024）。准确评估学生回答并提供反馈，是教育过程中的关键环节（Fagbohun et al., 2024）。传统上，该任务由人类教师完成，他们需仔细考量每份回答的内容、语境与细微差别（Balfour, 2013）。然而，随着对个性化与可扩展教育需求的不断增长，人工评估的局限性日益凸显（Luckin and Holmes, 2016）。\n\n大语言模型为自动化答案评估提供了可扩展的解决方案，能够评估从简单事实性答案到复杂开放性论文的广泛回答类型（Fagbohun et al., 2024）。借助其对语言与语境的深层理解，大语言模型可识别关键概念、判断回答的准确性，并提供建设性反馈（Stamper et al., 2024）。在大规模教育场景中，学生回答数量庞大，人工评阅难以为继，该能力尤显珍贵（Broadbent et al., 2018）。\n\n大语言模型在自动化评估中的一大核心优势，是能够识别学生回答中的细微理解或误解（Kazi, 2023）。例如，在评估一篇关于历史事件的论文时，大语言模型可判断学生是否把握了事件的深层原因与影响，而非仅仅罗列事实（Kasneci et al., 2023）。然而，尽管大语言模型（LLM）在自动评估方面展现出巨大潜力，但仍需应对若干挑战（Fagbohun et al., 2024）。首要关切之一在于评估的准确性与一致性。LLM 与所有人工智能系统一样并非无懈可击，有时会生成错误或有偏见的评价（Owan et al., 2023）。确保评估公平、准确，并与学习目标保持一致，对于 LLM 在教育过程中的成功整合至关重要（Fagbohun et al., 2024）。\n\n# 4.2 成功评估案例与改进空间\n\n为说明 LLM 在自动答案评估中的能力，可参看以下示例：\n\n- **简答题评分**：某 LLM 被用于生物学考试中简答题的评分（Shin and Gierl, ）。该模型能够准确判断学生是否正确识别了细胞内某一细胞器的功能，并针对正确与错误答案均提供反馈。LLM 还能识别常见误解，例如将线粒体与细胞核的功能混淆，并给出纠正性反馈以引导学生学习。  \n- **作文评分**：在历史课上，学生需撰写关于第二次世界大战起因与影响的短文。LLM 依据理解关键事件、分析历史因素及论证连贯性等标准对作文进行评价。模型能够识别论证充分之处，并就学生可改进之处（如提供更多证据或考虑替代视角）给出反馈（Mansour et al., 2024; Henkel et al., 2024）。  \n- **选择题分析**：某 LLM 被用于分析数学考试中选择题的学生作答情况（Henkel et al., 2024）。除识别正确答案外，模型还分析错误选项的分布模式，识别常见错误与误解，并据此提供针对性反馈，指出需进一步学习的领域。\n\n尽管上述示例展示了 LLM 在自动评估中的潜力，但仍存在改进空间。一项挑战在于确保 LLM 提供的反馈具有建设性且可执行（Meyer et al., 2024a）。例如，模型在正确指出学生错误的同时，还需就如何纠正错误提供明确指导。此外，LLM 必须能够根据每位学生的先备知识与学习风格，调整其反馈内容，以满足个体化需求。另一个亟需改进的方向是提升大语言模型（LLM）对复杂且富有创造性的回答——例如涉及批判性思维、问题解决或艺术表达的回答——进行评估的能力。尽管 LLM 在理解与生成文本方面已取得显著进展，但对这些高阶技能的评估仍面临挑战（Hsiao et al., 2023）。未来的研究与开发需进一步增强 LLM 在此类任务上的能力，以确保其能够全面满足学习者多样化的需求。\n\n# 5. 生成题目的人工评估与质量指标\n\n# 5.1 生成题目的质量评估\n\nLLM 生成题目的质量是决定其作为教育工具有效性的关键因素。高质量题目应当清晰、相关，并与学习目标保持一致，能够促使学生进行批判性思考并应用所学知识。为确保 LLM 生成的题目达到上述标准，人工评估与质量指标发挥着至关重要的作用（Kurdi et al., 2020）。\n\n人工评估依据一套预先设定的标准对生成题目进行评判，这些标准包括语法正确性、相关性、清晰度、复杂度以及与课程的对齐程度（Kurdi et al., 2020；Maity et al., 2023）。评估通常由资深教师或学科专家执行，他们针对题目的优缺点提供反馈。此类反馈对于优化提示语并提升生成题目的质量具有不可替代的价值。\n\n除人工评估外，还可借助自动化质量指标对生成题目进行评价。这些指标可能包括基于 unigram、bigram 及 n-gram 的评估方法，能够从量化角度提供题目质量的洞见（Kurdi et al., 2020）。然而，用于评估 LLM 生成题目的自动化指标存在局限性：其往往侧重于语言表层相似度（如字符、unigram、bigram 或最长公共子序列的重合度），而非更深层的语境理解（Nema and Khapra, 2018）。\n\n评估生成题目质量的一大挑战在于部分标准具有主观性。例如，某位教师可能认为某题具有挑战性且发人深省，而另一位教师则可能视其为过于复杂或表述不清（Crogman and Trebeau Crogman, 2018）。为此，必须制定明确的评估指南与标准，以确保评估过程的一致性与客观性。\n\n# 5.2 不同方法间质量的差异由大语言模型（LLM）生成的问题质量会因所用方法与技术而显著差异。例如，采用零样本提示（zero-shot prompting）生成的问题往往较为宽泛，且与特定内容的契合度较低；而经过微调（fine-tuning）或提示微调（prompt-tuning）生成的问题则通常更为精准且相关（Maity et al., 2023）。理解这些差异对于在特定教育情境中选择恰当方法至关重要。\n\n质量差异的一个常见维度体现在生成问题的复杂度上。LLM 既能生成简单的事实性问题，也能生成更具分析性的高阶问题（Maity et al., 2024b）。然而，后者需要对内容与情境有更深层的理解，仅凭基础提示技术未必能够实现。为生成高阶问题，往往需借助更先进的技术，如思维链提示（chain-of-thought prompting）（Wei et al., 2022）或微调（Raffel et al., 2020）。\n\n另一质量差异则与生成问题所体现的文化与语言多样性有关。基于多样化数据集训练的 LLM 更擅长生成具有文化相关性、适用于不同学生群体的问题。然而，这种多样性亦可能带来挑战：模型可能生成某些学生群体不甚熟悉或关联度较低的问题。因此，在评估过程中，确保生成的问题具有包容性并能为所有学习者所理解，是一项重要考量（Maity et al., 2024a; Maity et al., 2024b）。\n\n# 6. 更广泛的影响与未来方向\n\n# 6.1 LLM 在个性化与自适应学习中的作用\n\n随着 LLM 的不断演进，其在个性化与自适应学习中的作用日益凸显。LLM 能够大规模生成情境相关的问题并评估学生回答，这为个性化教育开辟了新路径（Alier et al., 2023）。借助 LLM，教育者可打造量身定制的学习体验，使之适应每位学生的个体需求与学习进度（Goslen et al., 2024）。\n\n在个性化学习中应用 LLM 的一大优势在于其能够提供即时反馈与指导（Meyer et al., 2024b）。当学生与系统互动时，LLM 可生成挑战其理解的问题，识别其困难领域，并提供针对性反馈以支持学习。这种实时互动不仅有助于学生保持投入与动机，也为教育者提供了关于学生进展的宝贵洞察。然而，将大语言模型（LLMs）融入个性化学习也引发了关于“人—机”教育平衡的重要议题（Yekollu et al., 2024）。尽管 LLMs 能够提供可扩展且高效的解决方案，却无法取代人类教师对课堂情境的细腻理解与情感共鸣。关键在于寻求恰当平衡，使 LLMs 成为人类主导教育的补充与增强，而非取而代之。\n\n# 6.2 伦理考量与挑战\n\n在教育领域部署 LLMs 亦带来一系列伦理关切（Meyer et al., 2024b）。偏见、公平性与透明度等问题是负责任地使用教育 AI 的核心（Memarian and Doleck, 2023）。LLMs 同所有 AI 系统一样，依赖的训练数据可能蕴含偏见，这些偏见会体现在其生成的问题或评估结果中（Memarian and Doleck, 2023）。要确保 LLMs 的公平与无偏，需对训练数据保持审慎，并对系统输出进行持续监测与评估。\n\n另一项伦理考量是 AI 驱动教育过程的透明度（Badawi et al., 2018）。学生与教师需要理解 LLMs 如何生成问题、如何评判答案，并知晓系统潜在的局限与偏见（Memarian and Doleck, 2023）。透明度是建立对 AI 教育信任的关键，也能确保师生在使用这些技术时保持信心（Kim, 2024）。\n\n最后，LLMs 在教育中的应用还引发数据隐私与安全的问题（Rahman et al., 2024）。当 LLMs 与学生互动并评估其作答时，可能收集并存储有关学生表现与学习历程的敏感信息。保护这些数据并确保其被负责任地使用，对于维护教育过程的完整性与安全性至关重要。\n\n# 6.3 自动问题生成与评估的未来方向\n\n展望未来，LLMs 在自动问题生成与评估中的作用有望进一步扩展与演化（Fagbohun et al., 2024）。人工智能与自然语言处理技术的进步将催生更复杂的模型，使其能够胜任复杂且富有创造性的教育任务（Alqahtani et al., 2023）。随着这些模型更深地融入教育流程，它们将在支持个性化与自适应学习方面发挥关键作用，提供可扩展的解决方案，从而提升教育的质量与可及性。未来研究的一个颇具前景的方向是开发能够评估高阶思维技能（如批判性思维、问题解决与创造力）的模型。这些技能对 21 世纪的成功至关重要，而准确且高效地评估它们则是教育工作者面临的一项重大挑战。凭借先进的语言理解与生成能力，大语言模型（LLMs）有望应对这一挑战，为评估并支持这些关键技能的发展提供新的工具（Moore et al., 2023）。\n\n未来研究的另一重要方向是探索用于微调（fine-tuning）与提示调优（prompt-tuning）LLMs 的新方法，以适配特定的教育任务。随着 LLMs 被应用于日益广泛的教育情境，开发能够高效且有效地将这些模型适配到不同学科领域、学生群体及学习目标的技术显得尤为关键。\n\n# 7. 结论\n\n综上所述，大语言模型有望通过自动问题生成与答案评估革新教育。这些模型凭借理解与生成类人文本的能力，提供了可扩展的解决方案，能够增强个性化与自适应学习。借助先进的提示技术与微调方法，教育工作者可创建高质量、情境相关的问题，既能挑战学生，又能支持其学习。此外，LLMs 在自动评估方面的能力可提供及时且建设性的反馈，帮助学生识别改进领域并引导其学习旅程。\n\n然而，将 LLMs 融入教育亦带来需审慎应对的挑战与伦理考量。确保人工智能驱动的教育过程的公平性、准确性与透明度，对于建立对这些技术的信任与信心至关重要。展望未来，持续的研究与开发将是实现 LLMs 教育潜能的关键，从而为所有学生创造更加个性化、自适应且可及的学习体验。\n\n# 参考文献\n\nACHIAM, J., ADLER, S., AGARWAL, S., AHMAD, L., AKKAYA, I., ALEMAN, F. L., ALMEIDA, D., ALTENSCHMIDT, J., ALTMAN, S., ANADKAT, S., ET AL. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.  \nALIER, M., CASAN, M. J., AND FILVA, D. A. 2023. Smart learning applications: Leveraging llms for contextualized and ethical educational technology. In International conference on technological ecosystems for enhancing multiculturality. Springer, 190-199.ALQAHTANI, T., BADRELDIN, H. A., ALRASHED, M., ALSHAYA, A. I., ALGHAMDI, S. S., BIN SALEH, K., ALOWAIS, S. A., ALSHAYA, O. A., RAHMAN, I., AL YAMI, M. S., 等. 2023. 人工智能、自然语言处理与大型语言模型在高等教育与研究中的新兴角色. *Research in Social and Administrative Pharmacy* 19, 8, 1236-1242.  \nBADAWI, G., DE BEYROUTH, G., 与 BADAWI, H. 2018. AI 驱动的教育范式：教学与学习中的机遇、挑战与伦理考量.  \nBALFOUR, S. P. 2013. MOOCs 中的写作评估：自动作文评分与 Calibrated Peer Review™. *Research & Practice in Assessment* 8, 40-48.  \nBROADBENT, J., PANADERO, E., 与 BOUD, D. 2018. 以形成性取向实施总结性评估：大班教学案例研究. *Assessment & Evaluation in Higher Education* 43, 2, 307-322.  \nBROWN, T., MANN, B., RYDER, N., SUBBIAH, M., KAPLAN, J. D., DHARIWAL, P., NEELAKANTAN, A., SHYAM, P., SASTRY, G., ASKELL, A., AGARWAL, S., HERBERT-VOSS, A., KRUEGER, G., HENIGHAN, T., CHILD, R., RAMESH, A., ZIEGLER, D., WU, J., WINTER, C., HESSE, C., CHEN, M., SIGLER, E., LITWIN, M., GRAY, S., CHESS, B., CLARK, J., BERNER, C., MCCANDLISH, S., RADFORD, A., SUTSKEVER, I., 与 AMODEI, D. 2020. 语言模型是小样本学习者. 载于 *Advances in Neural Information Processing Systems*, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, 与 H. Lin 编. 第 33 卷. Curran Associates, Inc., 1877-1901.  \nCHAPPUIS, J. 等. 2015. 促进学习的七种评估策略. Pearson.  \nCROGMAN, H. 与 TREBEAU CROGMAN, M. 2018. 改进的生成问题学习及其课堂实施与评估. *Cogent Education* 5, 1, 1459340.  \nFAGBOHUN, O., IDUWE, N., ABDULLAHI, M., IFATUROTI, A., 与 NWANNA, O. 2024. 超越传统评估：探索大型语言模型对评分实践的影响. *Journal of Artificial Intelligence and Machine Learning & Data Science* 2, 1, 1-8.  \nFLORIDI, L. 与 CHRIATTI, M. 2020. GPT-3：其本质、范围、局限与后果. *Minds and Machines* 30, 681–694.  \nFLORIDI, L. 与 COWLS, J. 2022. 面向社会的 AI 五大原则统一框架. 载于 *Machine Learning and the City: Applications in Architecture and Urban Design*, 535-545.  \nGOSLEN, A., KIM, Y. J., ROWE, J., 与 LESTER, J. 2024. 基于 LIM 的学生计划生成用于游戏化学习环境中的自适应支架. *International Journal of Artificial Intelligence in Education*, 1-26.  \nHENKEL, O., HILLS, L., BOXER, A., ROBERTS, B., 与 LEVONIAN, Z. 2024. 大型语言模型能否给出合格分数？评估 LLM 在 K-12 教育中批改简答题能力的实证研究. 载于 *Proceedings of the Eleventh ACM Conference on Learning@ Scale*, 300-304.  \nHSIAO, Y.-P., KLIJN, N., 与 CHIU, M.-S. 2023. 构建面向大型语言模型时代的写作作业评估再设计框架. *Learning: Research and Practice* 9, 2, 148-158.  \nKASNECI, E., SESSLER, K., KÜCHEMANN, S., BANNERT, M., DEMENTIEVA, D., FISCHER, F., GASSER, U., GROH, G., GUNNEMANN, S., HÜLLERMEIER, E., 等. 2023. ChatGPT 能否向善？论大型语言模型在教育中的机遇与挑战. *Learning and Individual Differences* 103, 102274.  \nKAZI, N. H. 2023. 利用大型语言模型实现自动简答题评分与迷思检测. University of North Florida.  \nKIM, J. 2024. 教师视角下的教师—AI 协作教育. *Education and Information Technologies* 29, 7, 8693–8724.KURDI, G., LEO, J., PARSIA, B., SATTLER, U., 与 AL-EMARI, S. 2020. 面向教育目的的自动问题生成研究综述. International Journal of Artificial Intelligence in Education 30, 121-204.  \nLESTER, B., AL-RFOU, R., 与 CONSTANT, N. 2021. 规模之力：参数高效提示微调. arXiv 预印本 arXiv:2104.08691.  \nLI, Q., FU, L., ZHANG, W., CHEN, X., YU, J., XIA, W., ZHANG, W., TANG, R., 与 YU, Y. 2023. 面向教育的大型语言模型适配：基础能力、潜力与挑战. arXiv 预印本 arXiv:2401.08664.  \nLUCKIN, R. 与 HOLMES, W. 2016. 智能释放：教育人工智能之辩.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2023. 利用基于提示的技术借助大型语言模型生成中小学水平问题. 见：第 15 届信息检索评估论坛年会论文集. 30-39.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024a. 探索提示式大型语言模型在教育与测评应用中的能力. 见：第 17 届教育数据挖掘国际会议论文集，B. PaaÄyen 与 C. D. Epp 编. 国际教育数据挖掘学会，美国佐治亚州亚特兰大，961-968.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024b. GPT-4 Turbo 基于布鲁姆修订版分类法从教科书生成中小学水平问题的有效性如何？  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024c. 生成式预训练大型语言模型解释孟加拉语语法错误的就绪度研究. 见：第 17 届教育数据挖掘国际会议论文集，B. PaaÄyen 与 C. D. Epp 编. 国际教育数据挖掘学会，美国佐治亚州亚特兰大，664-671.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024d. 一种用于语言无关多项选择题生成的新型多阶段提示方法——基于 GPT. 见：欧洲信息检索会议. Springer, 268-277.  \nMANSOUR, W., ALBATARNI, S., ELTANBOULY, S., 与 ELSAYED, T. 2024. 大型语言模型能否自动评分书面作文的熟练度？ arXiv 预印本 arXiv:2403.06149.  \nMAZIDI, K. 与 NIELSEN, R. 2014. 自动问题生成中的语言学考量. 见：第 52 届计算语言学协会年会论文集（第 2 卷：短文）. 321-326.  \nMEMARIAN, B. 与 DOLECK, T. 2023. 人工智能（AI）在高等教育中的公平性、问责性、透明性与伦理（FATE）：一项系统综述. Computers and Education: Artificial Intelligence, 100152.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., 与 FLECKENSTEIN, J. 2024a. 利用 LLMs 将循证反馈带入课堂：AI 生成的反馈提升中学生文本修订、动机与积极情绪. Computers and Education: Artificial Intelligence 6, 100199.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., 与 FLECKENSTEIN, J. 2024b. 利用 LLMs 将循证反馈带入课堂：AI 生成的反馈提升中学生文本修订、动机与积极情绪. Computers and Education: Artificial Intelligence 6, 100199.  \nMOORE, S., TONG, R., SINGH, A., LIU, Z., HU, X., LU, Y., LIANG, J., CAO, C., KHOSRAVI, H., Denny, P. 等. 2023. 以 LLMs 赋能教育——下一代界面与内容生成. 见：人工智能教育国际会议. Springer, 32-37.MULLA, N. 与 GHARPURE, P. 2023. 自动问题生成：方法、数据集、评估指标与应用综述. *Progress in Artificial Intelligence* 12, 1, 1-32.  \nNEMA, P. 与 KHAPRA, M. M. 2018. 迈向更优的问题生成系统评估指标. arXiv 预印本 arXiv:1808.10192.  \nOWAN, V. J., ABANG, K. B., IDIKA, D. O., ETTA, E. O., 与 BASSEY, B. A. 2023. 探索人工智能工具在教育测量与评估中的潜力. *Eurasia Journal of Mathematics, Science and Technology Education* 19, 8, em2307.  \nRADFORD, A., WU, J., CHILD, R., LUAN, D., AMODEI, D., SUTSKEVER, I. 等. 2019. 语言模型是无监督多任务学习者. *OpenAI Blog* 1, 8, 9.  \nRAFFEL, C., SHAZEER, N., ROBERTS, A., LEE, K., NARANG, S., MATENA, M., ZHOU, Y., LI, W., 与 LIU, P. J. 2020. 探索迁移学习极限的统一文本到文本 Transformer. *Journal of Machine Learning Research* 21, 140, 1-67.  \nRAHMAN, M. A., ALQAHTANI, L., ALBOOQ, A., 与 AINOUSAH, A. 2024. 大型多模态深度学习模型的安全与隐私综述：教学视角. 载于 *2024 第 21 届学习与科技大会 (L&T)*. IEEE, 13-18.  \nRAIAAN, M. A. K., MUKTA, M. S. H., FATEMA, K., FAHAD, N. M., SAKIB, S., MIM, M. M. J., AHMAD, J., ALI, M. E., 与 AZAM, S. 2024. 大型语言模型综述：架构、应用、分类体系、开放问题与挑战. *IEEE Access*.  \nSHIN, J. 与 GIERL, M. J. 科学评估中自动项目生成的自动短答案评分. 载于 *Routledge 国际自动作文评分手册*. Routledge, 504-534.  \nSTAMPER, J., XIAO, R., 与 HOU, X. 2024. 增强基于大语言模型的反馈：来自智能导学系统与学习科学的洞见. 载于 *人工智能教育国际会议*. Springer, 32-43.  \nVASWANI, A., SHAZEER, N., PARMAR, N., USZKOREIT, J., JONES, L., GOMEZ, A. N., KAISER, L. U., 与 POLOSUKHIN, I. 2017. Attention is all you need. 载于 *神经信息处理系统进展*, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, 与 R. Garnett 编. 第 30 卷. Curran Associates, Inc.  \nWEI, J., WANG, X., SCHUURMANS, D., BOSMA, M., ICHTER, B., XIA, F., CHI, E., LE, Q. V., 与 ZHOU, D. 2022. 思维链提示激发大语言模型推理能力. 载于 *神经信息处理系统进展*, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, 与 A. Oh 编. 第 35 卷. Curran Associates, Inc., 24824-24837.  \nYEKOLLU, R. K., BHIMRAJ GHUGE, T., SUNIL BIRADAR, S., HALDIKAR, S. V., 与 FAROOK MOHIDEEN ABDUL KADER, O. 2024. AI 驱动的个性化学习路径：通过自适应系统提升教育. 载于 *智能数据国际会议*. Springer, 507-517.",
    "is_translated": true
  },
  "f073a540-29cb-4a8a-b4e8-980e96e8a325": {
    "id": "f073a540-29cb-4a8a-b4e8-980e96e8a325",
    "filename": "a-large-language-model-assisted-education-tool-to-provide-feedback-on-open-ended-responses.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/f073a540-29cb-4a8a-b4e8-980e96e8a325_a-large-language-model-assisted-education-tool-to-provide-feedback-on-open-ended-responses.pdf",
    "status": "completed",
    "created_at": "2025-12-17 09:34:10.139329",
    "updated_at": "2025-12-17 01:35:34.355330",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "A large language model-assisted education tool to provide feedback on open-ended responses",
    "markdown_content": "# A large language model-assisted education tool to provide feedback on open-ended responses\n\nJordan K. Matelsky  $^{1,2}$ , Felipe Parodi  $^{3}$ , Tony Liu  $^{4}$ , Richard D. Lange  $^{1,5}$ , and Konrad P. Kording  $^{1,3,4,6}$\n\n$^{1}$ Department of Bioengineering, University of Pennsylvania;  $^{2}$ Research & Exploratory Development Department, Johns Hopkins University Applied Physics Laboratory;  $^{3}$ Department of Neuroscience, University of Pennsylvania;  $^{4}$ Department of Computer Science, University of Pennsylvania;  $^{5}$ Department of Computer Science, Rochester Institute of Technology;  $^{6}$ CIFAR LMB Program\n\nOpen-ended questions are a favored tool among instructors for assessing student understanding and encouraging critical exploration of course material. Providing feedback for such responses is a time-consuming task that can lead to overwhelmed instructors and decreased feedback quality. Many instructors resort to simpler question formats, like multiple-choice questions, which provide immediate feedback but at the expense of personalized and insightful comments. Here, we present a tool that uses large language models (LLMs), guided by instructor-defined criteria, to automate responses to open-ended questions. Our tool delivers rapid personalized feedback, enabling students to quickly test their knowledge and identify areas for improvement. We provide open-source reference implementations both as a web application and as a Jupyter Notebook widget that can be used with instructional coding or math notebooks. With instructor guidance, LLMs hold promise to enhance student learning outcomes and elevate instructional methodologies.\n\nLarge language models | Automated learning assessment | Automated grading | Education Correspondence: matelsky@seas.upenn.edu\n\n# Introduction\n\nOpen-ended questions — questions that require students to produce multi-word, nontrivial responses — are a popular assessment tool in educational environments because they offer students the chance to explore their understanding of learning material. Such questions provide valuable insight into students' grasp of complex concepts and their problem-solving approaches. However, grading open-ended questions can be time-consuming, subjective, and — especially in the\n\ncase of large class sizes — prone to attentional errors. These factors create a critical bottleneck in precision education.\n\nLarge Language Models (LLMs) present an opportunity to automate and promote equity in learning assessments, providing rapid valuable feedback to students while reducing the burden on instructors. We developed a tool that automatically assesses students' responses to open-ended questions by evaluating their responses against a set of instructor-defined criteria. To use our tool, the instructor poses a question along with optional grading criteria. Students respond to these questions, and their answers are relayed to a server. The responses are paired with the grading criteria (which are not revealed to the student), forming a payload for a large language model (LLM). The LLM then generates automated feedback, suggesting areas for improvement to the student.\n\nHere, we describe the technical design of our tool, FreeText, and showcase its utility in educational environments spanning topics and complexity. We further outline the implications of our work for teaching complex subjects, and the potential role of large language models in education (Fig. 1). We share our source code and a public URL (see Supplemental Materials), allowing educators to experiment with FreeText firsthand.\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/6a9cf86fccb148a4b0f5a0c93b45755ea07d2180131b4cd518c60fe668d97ace.jpg)  \nFigure 1. Sketch comparing grading throughput and quality of feedback to students among various assessment methodologies The  $y$ -axis represents throughput (i.e., rapidity of feedback generation and number of assignments evaluated per real-world unit-time or cost), and the  $x$ -axis represents feedback quality (a qualitative measure of personalization and detail of feedback given to students). LLMs have the potential to fill a niche among educational tools by striking a balance between quantity and quality, delivering high throughput with feedback quality comparable to human graders. Improvements in technology (faster GPU cards, better LLM architectures) will continue to push throughput upward, and improvements in prompt design (or other domain-specific adaptations) will improve the quality of LLM-generated feedback.\n\n# Related Work\n\nAutomated grading is a longstanding pursuit in the field of education technology. Early automated grading tools focused on 'solvable' tasks like math or programming assignments, where grading generally relies on unit tests or direct output comparisons (Hollingsworth, 1960; Ureel II and Wallace, 2019; Orr and Russell, 2021; Messer et al., 2023). These approaches often overlook less easily-quantified but nonetheless critical indicators of learning and understanding, such as design quality, code maintainability, or potential areas of student confusion. Modern tools, like AutoGrader, which provides real-time grading for programming exercises, remain narrowly focused on output correctness and do not sufficiently account for documentation or maintainability (Liu et al., 2019).\n\nAssessing students' understanding from natural language responses, however, presents different challenges and has seen significant evolution. Early Automated Short Answer Grading (ASAG) models employed statistical or domain-specific neural network approaches (Heilman and Madnani, 2013; Riordan et al., 2017; Sung et al., 2019). In recent years, LLMs have been shown to outperform domain-specific language models (Radford et al., 2019; Mizumoto et al., 2019; Brown et al., 2020; Chung et al., 2022). LLMs facilitate grading of open-ended assignment responses, without the need for task-specific fine-tuning (Cao, 2023; Mizumoto and Eguchi, 2023; Yoon, 2023). However, Kortemeyer (2023) revealed that while LLMs like GPT-4 could be useful for preliminary grading of introductory physics assignments, they fell short for natural-language responses required in comprehensive exam grading. Further, while LLMs like GitHub Copilot streamline the process of code generation and review, they can fall short on more nuanced programming tasks and open-ended evaluation (Finnie-Ansley et al., 2022). Thus, in their current state, LLMs should be treated as a useful but fallible tool, with final assessments still in the hands of (human) instructors.\n\nIt is also important to consider how students perceive AI graders and how automated graders are deployed to educational settings (Burrows et al., 2015; Saha et al., 2019; Zhu et al., 2022). Many comment on the socio-technical dynamics of automated grading, including the potential for introduction of machine bias (e.g., Hsu et al. (2021)). The use of NLP for short answer grading is not a trivial task and has been set as an evaluation challenge in its own right (Dzikovska et al., 2013).\n\nTo address the evolving needs of grading open-ended responses, our framework proposes four key enhancements. First, it is specifically designed for open-ended questions, which are not typically well-served by the rubric-based grading of most ed-tech tools. Sec-\n\nond, our system leverages LLMs to deliver rapid, personalized feedback for student responses without explicitly attempting to produce a quantitative grade. Third, our framework introduces a feedback loop to continually improve instructor-provided prompts, question suggestions, and grading criteria. Lastly, our tool integrates with the Jupyter Notebook environment, extensively utilized in fields such as computer science, data science, and statistics.\n\n# Approach\n\nWe have designed our tool for use in a variety of educational contexts, ranging from primary school education to graduate courses. FreeText enables educators to integrate open-ended questions into their curriculum without incurring an instructor labor cost. This allows students to gain rapid, individualized, and sophisticated feedback, thereby creating a highly effective learning loop that can enhance the absorption of course materials. It guides students in refining their responses, enhancing their understanding and application of concepts in each iteration. This feedback is generated by a large language model (LLM), which circumvents the attentional errors often made by human graders, particularly when assessing a large volume of assignments. The LLM is capable of delivering intricate responses to students swiftly, as demonstrated by the examples provided in Table 1.\n\nOur software is packaged as a Python library. LLM interactions are handled by the Guidance Python package (Microsoft, 2023). User interfaces and a JSON HTTP API are supported by FastAPI (Lathkar, 2023). We support traditional (e.g., JSON files, SQLite) as well as cloud-based data storage drivers. Our server can be run at low financial and computational cost through the combination of serverless deployment (e.g., to AWS Lambda) and serverless databases (e.g., AWS DYNAMoDB). Student responses are not stored by Free-Text infrastructure by default.\n\nAny Guidance-compatible LLM may be swapped into the Freetext server. That is, by default we access LLMs through the OpenAI API, but it is easy to swap in locally hosted or fine-tuned models: thus, privileged or sensitive information may be kept to on-premise compute resources, or users may opt to change which API-based LLM is accessed. For example, a more powerful LLM may be selected in cases where course content is particularly complex, or a simpler model may be used for more elementary course content.\n\nOne front-end that students can access is a Jupyter Notebook widget, developed using IPyWidgets (Kluyver et al., 2016), making it easy to incorporate natural language short-answer questions as part of a notebook-based active-learning environment.\n\nThe widget communicates with the backend\n\nPython server described above. The widget is designed to be easily integrated into lecture and homework notebooks, enabling instructors to easily enrich existing teaching materials. A distinctive feature of our system is the intermediary server which equips the large language model with 'held-out' information, such as a rubric for correct responses, accessible only to the LLM and instructor, and not to the student. This establishes the useful informational asymmetry between the evaluator and the student.\n\nTo include the widget in a Python environment, the instructor can include the following code:\n\n!pip install freetext_jupyter  \nfrom freetext_jupyter import FreetextWidget\n\nFreetextWidget( # This ID is generated by the instructor. \"07b2c3ef-0f97-46bc-a11e--\"\n\nWhen executed in a Jupyter notebook cell, this code will access the HTTP API to replace the widget with the corresponding question text for the student. Upon encountering the widget in a notebook, the student is presented with an open-ended question accompanied by a text box for response input. When they submit their response, the system transmits it to the server for combination with the feedback criteria set by the instructor.\n\nIn the next stage, the student response and the pre-defined feedback criteria are bundled into a payload dispatched to a large language model. The LLM processes this payload and produces personalized feedback to the response. This feedback is relayed back to the student with seconds of latency through the web or notebook interface, offering them the immediate opportunity to reflect, amend, and improve their response as desired (Fig. 2).\n\nOur tool is designed to be easily deployable and scalable. The FreeText server can be run in resource-constrained or serverless platforms such as AWS Lambda. This allows for easy deployment and scaling, which is particularly important for large-scale projects and massive-scale courses (van Viegen et al., 2021). Our API can also be combined with other existing educational tools in order to capture and store student responses for instructor review.\n\n# Question Design\n\nInstructors can provide a question for students to answer — either programmatically, by accessing our HTTP API — or graphically in the browser using the simple web application UI. Instructors can also provide optional assessment criteria — text like \"make sure the student mentions DNA base pairs in their answer.\"\n\nFreeText can use question content to automatically establish grading criteria, or it can use the assessment criteria to improve the text of the question. The latter process works by asking the AI to serve as a student and answer a question while oblivious to the instructor's grading criteria. Then, the answer is automatically evaluated by a separate instantiation of the LLM — this time, against the instructor criteria. The assessment model determines if the student has been unfairly penalized due to omission of requirements (or a lack of clarity) in the original question text. If so, the question is updated to better encompass the requirements of the grading criteria.\n\nThis process of iteratively incorporating assessment criteria is subtly different from simply including the criteria in the question text: For example, if the question text is, \"What is the Rosetta Stone?\" and the criteria include, \"Mention why the Ptolemaic dynasty created the Rosetta Stone\", a bad question update would be to explicitly ask about the Egyptian political system, as this gives the student more information than the instructor originally intended. A better question update would be \"Explain what the Rosetta Stone is and the context of its creation,\" because this nudges the student to discuss the right material but does not give any new information.\n\n# Question Presentation\n\nThere are two built-in methods to present questions to students: the first is a simple web API, which can be used standalone, coupled with response-collection tools, or embedded within other web applications. The second is a Jupyter Notebook widget that can be embedded in tutorial coding notebooks.\n\nThe JSON web API endpoints may be accessed directly by application code, or students can access a simple web user interface. This interface comprises a question display and a textbox for student responses (see Supplemental Materials). Feedback to students is rendered beneath the response box upon answer submission, and students may reuse the same page to resubmit amended answers.\n\nThe Jupyter Notebook widget is designed to make it easy for instructors to include open-ended questions in their assignments and subject the grading of student responses to custom grading criteria. This flexibility makes it easy for instructors to tailor the tool to their specific needs and teaching style.\n\n# Feedback to Students\n\nOur tool provides two types of feedback to students. The first is a holistic text response that provides feedback on the entire answer as a whole. The second is span-bound feedback (referring to a specific substring of the response) that can be used to highlight specific parts of the text that are erroneous or otherwise need\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/5209fe91ef2047ed5842cbb413bc10aad9a1a2af8167dd3d98ee564bdaacb52d.jpg)\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/cd61c0ae15cf0320be444de8121a19d39c0baa1c3fe9526b165a6ec148060066.jpg)  \nFigure 2. A sequence diagram illustrating the flow of information within the FreeText system. A. First, an instructor formulates a question by supplying a student-facing question (\"Question\") along with grading criteria for the LLM to evaluate student responses. In return, the educator obtains a unique identifier from the database, instrumental in retrieving the question text in the following step. B. Equipped with a unique Question identifier, a student provides an answer to the educator's query (\"Response\"). The API receives this request, pairing the Response with a Prompt based upon the educator's question and criteria, and directs them towards a large language model for evaluation. C. A screenshot of the FreeText Jupyter widget integrated into an interactive code notebook.\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/bf7f9570f0e3176a21e9fe41333f8aad179f2fa417d93be67dc8da06718deaa9.jpg)\n\nstudent attention. For example, if a student's answer is correct but they misattribute a quote, the FreeText server could highlight the attribution specifically to give feedback. The type of feedback returned can be specified by the instructor during question creation.\n\n# Discussion\n\nHere we introduced FreeText, a framework capable of defining questions, collecting student responses, transmitting these responses alongside instructor expectations to a large language model (LLM), and generating rapid and personalized feedback for the students. Notably, the entirety of the student-facing workflow can be encapsulated within a Jupyter notebook, facilitating real-time enhancement of students' understanding of the course material. FreeText is not confined to a web application and Jupyter notebooks, or the academic subjects mentioned above. The FreeText Server can integrate with any application that consumes a JSON HTTP API, expanding its potential to a wider range of educational settings.\n\nOur system's broad applicability becomes evident when considering diverse learning models, such as the pod-based approach adopted by the online course Neuromatch Academy (van Viegen et al., 2021) in the field of computational neuroscience. In such settings, small student groups or 'pods' collaboratively tackle assignments and projects. Teaching Assistants, tasked with providing feedback, can benefit from our tool, as it can streamline grading processes, reducing potential for attentional errors and freeing up instructors to deliver more personalized guidance to students.\n\nFully automated student evaluation is challenging both from a technical perspective and from a human\n\nperspective, and thus FreeText is designed not to fully automate grading, but to serve as a useful tool benefiting both students and instructors. FreeText benefits students by providing rapid and personalized feedback on short-answer questions. FreeText benefits instructors by helping them to design better questions and grading criteria, by providing first-pass material for learning assessments, and by alleviating some of the burden of providing individualized instruction in large classes. LLMs in general, and FreeText specifically, are not a replacement human instructors, but they can nonetheless fill a niche among education technologies.\n\nLLMs undoubtedly hold immense power and potential. However, it is crucial to have an in-depth discussion about their ethical implications, especially in education. A key issue to consider is the potential biases that LLMs can introduce. These biases could unintentionally touch on sensitive subjects or unintentionally overlook marginalized groups. Instructors have a role to play by carefully designing their questions and assessment criteria. Further, students should be made aware of the nature of the system they are interacting with and its potential to make mistakes or act on internalized biases (Hsu et al., 2021). On the other hand, automated systems such as FreeText present an opportunity to reduce instructors' unconscious biases by evaluating all students' responses equally and without any explicit identification.\n\nFurthermore, we must consider the broader dynamics of the AI ecosystem. The realm of LLMs is not limited to the offerings of large AI conglomerates like OpenAI. A burgeoning industry of alternative LLMs, both from smaller commercial entities and open-source initiatives (Anthropic, 2023; Taori et al., 2023; Touvron et al., 2023; Wolf et al., 2020), is flourishing. Our\n\nframework is designed to be model-agnostic and can be readily adapted to integrate these alternative models.\n\nReliance solely on models from a single entity such as OpenAI raises two significant concerns. First, it centralizes the concentration of AI development resources and power, thereby exacerbating the already pronounced inequalities in the global AI landscape. Second, it can lead to a homogenization of the knowledge and perspectives propagated by AI models, potentially resulting in a limited and biased worldview. FreeText is therefore deliberately agnostic to the underlying LLM model and technologies.\n\nWe intend for our tool to enrich and expand students' educational experience, particularly in large-scale or resource-constrained course settings where detailed human intervention may be limited. Ongoing work includes the careful critique and evaluation of FreeText outputs by expert instructors, taking advantage of upcoming opportunities to apply this technology in a large class setting.\n\nEmbracing both technical as well as human diversity helps mitigate many of the concerns raised above and enriches the AI ecosystem. A broad range of perspectives stalls the monopolization of AI technology and fosters a more balanced, equitable, and robust AI landscape. This viewpoint aligns with our belief in the need for broad and diverse human inputs, both in the creation of AI models and in their applications in society.\n\n# Supplemental Materials\n\nFull-resolution versions of all images and tables from this publication are available at https://llm4edu.experiments.kordinglab.com/paper.\n\nThe FreeText server will be hosted temporarily for public use at https://llm4edu.experiments.kordinglab.com/app, with an interactive example assignment available at https://llm4edu.experiments.kordinglab.com/app/assignments/1393754a-d80f-474d-bff7-b1fec36cdbb7. Educators may contact us at the correspondence email of this preprint for a token, which is required to create new questions on our public instance.\n\nOur Jupyter Notebook Widget is available on GitHub at https://github.com/KordingLab/freetext-jupyter, and is powered by the FreeText Server, which can be found at https://github.com/KordingLab/llm4teach-freetext-server.\n\n# Acknowledgements\n\nResearch in this publication was supported by the National Institutes of Health under award number UC2-NS128361. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.\n\n# Bibliography\n\nAnthropic. Claude, 2023. URL https://www.anthropic.com. Accessed: 24 July 2023. T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901. Curran Associates, Inc., 2020.  \nS. Burrows, I. Gurevych, and B. Stein. The eras and trends of automatic short answer grading. International journal of artificial intelligence in education, 25:60-117, 2015.  \nC. Cao. Leveraging large language model and story-based gamification in intelligent tutoring system to scaffold introductory programming courses: A design-based research study, 2023.  \nH. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma, A. Webson, S. S. Gu, Z. Dai, M. Suzgun, X. Chen, A. Chowdhery, A. Castro-Ros, M. Pellat, K. Robinson, D. Valter, S. Narang, G. Mishra, A. Yu, V. Zhao, Y. Huang, A. Dai, H. Yu, S. Petrov, E. H. Chi, J. Dean, J. Devlin, A. Roberts, D. Zhou, Q. V. Le, and J. Wei. Scaling instruction-finetuned language models, 2022.  \nM. O. Dzikovska, R. Nielsen, C. Brew, C. Leacock, D. Giampicolo, L. Bentivogli, P. Clark, I. Dagan, and H. T. Dang. Semeval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge. In Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 263-274, 2013.  \nJ. Finnie-Ansley, P. Denny, B. A. Becker, A. Luxton-Reilly, and J. Prather. The robots are coming: Exploring the implications of openai codex on introductory programming. In Proceedings of the 24th Australasian Computing Education Conference, pages 10-19, 2022.  \nM. Heilman and N. Madnani. ETS: Domain adaptation and stacking for short answer scoring. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 275-279. Association for Computational Linguistics, 2013.  \nJ. Hollingsworth. Automatic graders for programming classes. Communications of the ACM, 3(10):528-529, 1960. ISSN 0001-0782. doi: 10.1145/367415.367422.  \nS. Hsu, T. W. Li, Z. Zhang, M. Fowler, C. Zilles, and K. Karahalios. Attitudes surrounding an imperfect ai autograder. In Proceedings of the 2021 CHI conference on human factors in computing systems, pages 1-15, 2021.  \nT. Kluyver, B. Ragan-Kelley, F. Perez, B. Granger, M. Bussonnier, J. Frederic, K. Kelley, J. Hamrick, J. Grout, S. Corlay, P. Ivanov, D. Avila, S. Abdalla, and C. Willing. Jupyter notebooks - a publishing format for reproducible computational workflows. In F. Loizides and B. Schmidt, editors, Positioning and Power in Academic Publishing: Players, Agents and Agendas, pages 87 - 90. IOS Press, 2016.  \nG. Kortemeyer. Can an Al-tool grade assignments in an introductory physics course?. 2023.  \nM. Lathkar. Getting started with fastapi. In High-Performance Web Apps with FastAPI: The Asynchronous Web Framework Based on Modern Python, pages 29-64. Springer, 2023.  \nX. Liu, S. Wang, P. Wang, and D. Wu. Automatic grading of programming assignments: An approach based on formal semantics. In 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET), pages 126-137, 2019. doi: 10.1109/ICSE-SEET.2019.00022.  \nM. Messer, N. C. C. Brown, M. Kölling, and M. Shi. Automated grading and feedback tools for programming education: A systematic review, 2023.  \nMicrosoft. Guidance. https://github.com/microsoft/guidance, 2023. Accessed: 24 July 2023.  \nA. Mizumoto and M. Eguchi. Exploring the potential of using an AI language model for automated essay scoring. Research Methods in Applied Linguistics, 2(2):100050, 2023. ISSN 2772-7661. doi: 10.1016/j.rmal.2023.100050.  \nT. Mizumoto, H. Ouchi, Y. Isobe, P. Reisert, R. Nagata, S. Sekine, and K. Inui. Analytic score prediction and justification identification in automated short answer scoring. In Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 316-325. Association for Computational Linguistics, 2019. doi: 10.18653/v1/W19-4433.  \nJ. W. Orr and N. Russell. Automatic assessment of the design quality of python programs with personalized feedback. arXiv preprint arXiv:2106.01399, 2021.  \nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised multitask learners. 2019.  \nB. Riordan, A. Horbach, A. Cahill, T. Zesch, and C. M. Lee. Investigating neural architectures for short answer scoring. In Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications, pages 159-168. Association for Computational Linguistics, 2017. doi: 10.18653/v1/W17-5017.  \nS. Saha, T. I. Dhamecha, S. Marvaniya, P. Foltz, R. Sindhgatta, and B. Sengupta. Joint multi-domain learning for automatic short answer grading. arXiv preprint arXiv:1902.09183, 2019.  \nC. Sung, T. Dhamecha, S. Saha, T. Ma, V. Reddy, and R. Arora. Pre-training BERT on domain resources for short answer grading. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-JCNLP), pages 6071-6075. Association for Computational Linguistics, 2019. doi: 10.18653/v1/D19-1628.  \nR. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and\n\nTable 1. Feedback examples.  \n\n<table><tr><td>Instructor-Generated Prompt</td><td>Student-Generated Answer</td><td>AI-Generated Feedback</td></tr><tr><td>Question\nExplain what a neuron is, detailing how they transmit information and what unique features they have.</td><td rowspan=\"2\">Neurons are cells that transmit information to other nerve, muscle, or gland cells. They use synapses.</td><td rowspan=\"2\">You correctly state that neurons are cells that transmit information to other nerve, muscle, or gland cells.\nYou also mention the use of synapses, which is correct as synapses are the connections between neurons where information is transmitted.\nHowever, your response is quite brief and lacks important details and explanations. Here are some points that you may have missed or misunderstood:\nYou did not provide any information about how neurons transmit information. It would be helpful to explain that neurons transmit information through electrical impulses called action potentials.\nYou did not mention the role of neurotransmitters in transmitting information between neurons. It is important to explain that neurotransmitters are chemical messengers released at the synapse to transmit the signal from one neuron to the next.\nYour response could benefit from more specific and detailed information about the unique features of neurons, such as the three main parts of a neuron (cell body, dendrites, and axon) and how the action potential is propagated along the axon. Overall, your response is a good start, but it would be more complete and accurate if you include the missing details mentioned above. Keep up the effort!</td></tr><tr><td>Criteria\nMust include the terms &quot;synapse&quot; and &quot;action potential.&quot;\nMust mention the role of neurotransmitters.</td></tr><tr><td>Question\nWhat are the components and structure of a molecule of DNA?</td><td rowspan=\"2\">DNA is a complex molecule and it is shaped like a double helix ladder, where the rungs are base pairs ATGC and the scaffold is sugars and phosphates.\nThe base pairs bind (A with G) and (C with T) using hydrogen bonds, which can be separated when the DNA is being read or duplicated.</td><td rowspan=\"2\">Correct points:\nYou correctly mentioned that DNA is shaped like a double helix ladder.\nYou accurately stated that the base pairs in DNA are ATGC.\nYou correctly noted that the base pairs bind using hydrogen bonds.\nPoints to improve:\nYou mentioned that the base pairs bind as A with G and C with T, but it&#x27;s important to clarify that adenine pairs with thymine (A-T) and guanine pairs with cytosine (G-C).\nOverall, you have a solid understanding of the components and structure of DNA. Just make sure to clarify the pairing of base pairs and the temporary breaking of hydrogen bonds during DNA processes. Good work!</td></tr><tr><td>Criteria\nMention base pairs, sugar, and phosphate.\nDescribe that DNA is a double helix.\nNote that base pairs pair up in a specific way using hydrogen bonds (AT and GC).</td></tr><tr><td>Question\nHow can large language models introduce biases into student evaluation?</td><td rowspan=\"2\">LLMs have bias because their training data can have toxic, biased, or inaccurate data in it. When evaluating students, LLMs could also penalize students that know information that is more recent or otherwise outside the LLM&#x27;s training set, which may appear to be inaccurate to the AI model.\nLLMs are also not designed to keep track of accurate information; they are autoregressive language models, and so they do not have a legitimate hold on fact and caution should be used when depending on an AI model for subtle communication.</td><td rowspan=\"2\">Great job in identifying some of the key factors that contribute to biases in large language models (LLMs) in student evaluation. It would be helpful to provide specific examples or evidence of how LLMs can have biased or inaccurate data in their training set. This would strengthen your argument and provide more clarity.\nYour statements align with the current understanding of LLMs and their limitations.\nOverall, your response demonstrates a good understanding of the topic. To further enhance your answer, consider providing more specific examples and expanding on the potential implications of relying on LLMs for student evaluation. Great job!</td></tr><tr><td>Criteria\n(None provided)</td></tr><tr><td>Question\nHow can large language models introduce biases into student evaluation?</td><td rowspan=\"2\">LLMs are biased because they&#x27;re made by large companies.</td><td rowspan=\"2\">Your response to the prompt raises an important point, but there are a few areas where your answer could be elaborated. Large language models (LLMs) are indeed created by large companies, but it&#x27;s important to note that the fact that LLMs are made by large companies does not directly imply bias. Bias can arise from various factors related to the training data and model design.\nConsider mentioning factors such as the source of training data, language patterns, prejudiced examples, feedback loops, lack of contextual understanding, and how evaluation metrics may steer LLM responses.\nOverall, your response is a good starting point, but it would benefit from further elaboration and a deeper understanding of the specific factors that contribute to biases in student evaluation by large language models. Keep up the effort!</td></tr><tr><td>Criteria\n(None provided)</td></tr></table>\n\nT. B. Hashimoto. Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models. https://crfm.stanford.edu/2023/03/13/alpaca.html, 3(6):7, 2023.  \nH. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.  \nL. C. Ureel II and C. Wallace. Automated critique of early programming antipatterns. In Proceedings of the 50th ACM Technical Symposium on Computer Science Education, SIGCSE '19, pages 738-744. Association for Computing Machinery, 2019. ISBN 978-1-4503-5890-3. doi: 10.1145/3287324.3287463.  \nT. van Viegen, A. Akrami, K. Bonnen, E. DeWitt, A. Hyafil, H. Ledmyr, G. W. Lindsay, P. Mineault, J. D. Murray, X. Pitkow, et al. Neuromatch academy: Teaching computational neuroscience with global accessibility. Trends in cognitive sciences, 25(7):535-538, 2021.  \nT. Wolf, L. Debut, V. Sanh, J. Chaumont, C. Delangue, A. Moi, P. Cistac, C. Ma, Y. Jernite, J. Plu, C. Xu, T. Le Scao, S. Gugger, M. Drame, Q. Lhoest, and A. M. Rush. Transformers: State-of-the-Art Natural Language Processing. pages 38-45. Association for Computational Linguistics, Oct. 2020. URL https://www.aclweb.org/anthology/2020.emnlp-demos.6.  \nS.-Y. Yoon. Short answer grading using one-shot prompting and text similarity scoring model, 2023.  \nX. Zhu, H. Wu, and L. Zhang. Automatic short-answer grading via bert-based deep neural networks. IEEE Transactions on Learning Technologies, 15(3):364-375, 2022.",
    "arxiv_id": "2106.01399",
    "error_message": "'JSONStore' object has no attribute 'keys'",
    "embedding": [
      0.302734375,
      2.453125,
      -0.95703125,
      0.8046875,
      0.439453125,
      1.7578125,
      -1.421875,
      -4.4375,
      2.0625,
      5.125,
      1.109375,
      2.859375,
      5.03125,
      2.015625,
      0.39453125,
      5.1875,
      -0.1884765625,
      2.375,
      -1.2734375,
      -8,
      1.265625,
      3.90625,
      1.609375,
      -6.09375,
      2.234375,
      -2.53125,
      1.1875,
      4.28125,
      2.171875,
      -1.125,
      6.34375,
      -4.96875,
      -1.21875,
      -0.357421875,
      0.6640625,
      -0.365234375,
      -1.4921875,
      -0.73046875,
      2.59375,
      2.3125,
      -5.46875,
      1.2734375,
      1.234375,
      0.703125,
      -1.0234375,
      6.03125,
      1.5390625,
      -0.78515625,
      -3.453125,
      -0.203125,
      -5.5625,
      -1.2421875,
      5.15625,
      1.3203125,
      0.54296875,
      -5.84375,
      -7.4375,
      6.96875,
      -3.953125,
      0.59375,
      2.78125,
      -0.6953125,
      5.75,
      -0.96875,
      2.5625,
      0.73046875,
      2.4375,
      1.4921875,
      -4.125,
      1.59375,
      0.671875,
      1.953125,
      7.3125,
      -2.1875,
      7.9375,
      5.71875,
      3.34375,
      4.09375,
      -2.765625,
      4.53125,
      -3.5625,
      4,
      4.25,
      -0.546875,
      5.28125,
      3.296875,
      1.3359375,
      1.1015625,
      -0.83203125,
      3.265625,
      -3.296875,
      1.015625,
      -2.578125,
      0.68359375,
      -2.03125,
      4.78125,
      -1.640625,
      -4,
      -6.125,
      1.375,
      0.19140625,
      -3.5625,
      1.8984375,
      -7,
      -0.5546875,
      -3.109375,
      -5.75,
      -5.28125,
      -3.625,
      -1.796875,
      -1.7890625,
      0.9140625,
      1.6875,
      -2.375,
      2.359375,
      -0.890625,
      5.4375,
      -3.96875,
      -4.96875,
      -1.828125,
      1.2265625,
      0.201171875,
      -1.5390625,
      1.15625,
      3.203125,
      2.890625,
      -4.5625,
      3.1875,
      3.28125,
      -1.9609375,
      4.59375,
      -0.7109375,
      6,
      -1.8125,
      -7.875,
      -2.640625,
      -6.3125,
      2.5,
      2.21875,
      5.28125,
      -7.3125,
      -0.30078125,
      0.68359375,
      -4.65625,
      4.6875,
      2.5625,
      -7.1875,
      -0.30859375,
      2.078125,
      -4.59375,
      -0.76953125,
      1.796875,
      2.96875,
      6.53125,
      -2.734375,
      -1.25,
      2.078125,
      3.984375,
      0.78125,
      -2.015625,
      -1.7421875,
      4.4375,
      -0.1396484375,
      0.279296875,
      -0.357421875,
      -1.3671875,
      -5.96875,
      3.3125,
      -2.078125,
      -2.4375,
      -0.478515625,
      13.5,
      2.046875,
      -0.421875,
      0.287109375,
      2.671875,
      -1.6875,
      6.0625,
      2.3125,
      -2.078125,
      0.298828125,
      3.546875,
      -1.3828125,
      6.03125,
      -1.859375,
      1.1171875,
      0.9140625,
      -3.90625,
      2.078125,
      -1.453125,
      3.0625,
      1.5390625,
      2.59375,
      1.7421875,
      -6.5625,
      -0.7578125,
      0.64453125,
      0.18359375,
      -1.5078125,
      2.65625,
      -0.1787109375,
      -9.5625,
      2.09375,
      0.2314453125,
      -4.0625,
      -1.734375,
      1.9453125,
      -2.140625,
      1.5625,
      -3.078125,
      1.25,
      3.40625,
      2.3125,
      -1.640625,
      5.8125,
      5.15625,
      5.90625,
      -2.265625,
      5.59375,
      0.408203125,
      2.65625,
      2.5625,
      6.28125,
      1.84375,
      -0.369140625,
      1.9765625,
      5.1875,
      3.984375,
      -0.75,
      5.84375,
      -0.240234375,
      0.734375,
      3.484375,
      -2.796875,
      -4.125,
      -4.90625,
      -5,
      -0.326171875,
      -0.9296875,
      1.7890625,
      -4.375,
      -6.09375,
      2.03125,
      1.8828125,
      3.421875,
      -3.546875,
      -1.15625,
      -2.921875,
      -2.765625,
      -6.21875,
      2.953125,
      5.8125,
      -5.40625,
      -2.890625,
      3.34375,
      8,
      -2.28125,
      -1.109375,
      -0.40625,
      -4.75,
      4.96875,
      -1.9296875,
      -7,
      3.5,
      1.296875,
      -4.96875,
      2.5,
      0.828125,
      3.25,
      3.09375,
      0.1201171875,
      0.69140625,
      -3.703125,
      0.53125,
      -2.4375,
      4.96875,
      1.34375,
      -7.96875,
      5.34375,
      -2.546875,
      -4.53125,
      -8.8125,
      7.40625,
      -5.15625,
      2.5,
      -2.453125,
      -0.185546875,
      5.65625,
      -2.765625,
      11.125,
      4.78125,
      2.265625,
      0.95703125,
      -3.234375,
      -5.5,
      1.3828125,
      -4.125,
      -1.1953125,
      -7.6875,
      0.203125,
      6.03125,
      0.71484375,
      0.46484375,
      -1.0859375,
      -0.96875,
      1.421875,
      -1.6015625,
      -1.203125,
      -0.05517578125,
      0.71484375,
      -0.486328125,
      -0.51953125,
      8.0625,
      -0.2578125,
      3.515625,
      -5.15625,
      -4.3125,
      2.078125,
      0.64453125,
      -0.8359375,
      -3.5625,
      -5.53125,
      -3.625,
      -3.265625,
      -4.09375,
      -0.90625,
      2.65625,
      1.5546875,
      5.84375,
      -1.1875,
      3.96875,
      -2.15625,
      -3.6875,
      -9.5,
      4.0625,
      -2.703125,
      0.90625,
      1.9765625,
      -2.734375,
      4.75,
      0.181640625,
      -3.328125,
      4.125,
      -2.09375,
      -4.0625,
      1.7734375,
      6.71875,
      -2.796875,
      0.5234375,
      -2.84375,
      3.875,
      1.6640625,
      -0.765625,
      4.21875,
      7.8125,
      -2.890625,
      0.51953125,
      -2.734375,
      -0.353515625,
      -1.2421875,
      5.03125,
      -2.78125,
      5.28125,
      -1.953125,
      0.345703125,
      -2.125,
      -2.9375,
      2.609375,
      -2.28125,
      -1.15625,
      -0.6875,
      -2.546875,
      0.546875,
      -0.16015625,
      -0.275390625,
      0.8359375,
      0.5390625,
      -2.59375,
      -2.5625,
      1.4375,
      -4.25,
      -0.4609375,
      -0.466796875,
      -0.490234375,
      5.375,
      1.1328125,
      -0.0033721923828125,
      1.828125,
      1.578125,
      -2.6875,
      -3.90625,
      0.78125,
      -2.484375,
      1.5390625,
      3.0625,
      0.05712890625,
      0.890625,
      2.234375,
      -0.44921875,
      -0.99609375,
      5.46875,
      -0.80078125,
      -1.0078125,
      0.59765625,
      -2.828125,
      -0.77734375,
      0.006866455078125,
      -5.71875,
      2.546875,
      -0.30859375,
      1.09375,
      0.42578125,
      -1.015625,
      -0.1015625,
      0.302734375,
      5.875,
      -2.328125,
      3.515625,
      -7.875,
      -1.34375,
      -3.71875,
      0.76953125,
      1.1953125,
      0.12158203125,
      0.044921875,
      1.234375,
      -0.072265625,
      4.75,
      1.28125,
      -0.55859375,
      3.28125,
      1.140625,
      -1.9921875,
      2.015625,
      -3.71875,
      -2.640625,
      4.65625,
      -4.4375,
      -2.5625,
      0.58203125,
      4.09375,
      -4.03125,
      5.875,
      6.71875,
      -5.9375,
      -1.3359375,
      1.4765625,
      4.28125,
      -2.9375,
      -0.2734375,
      -0.1865234375,
      -0.1533203125,
      -1.828125,
      0.7734375,
      -0.1884765625,
      1.1953125,
      -5.25,
      4.09375,
      2.546875,
      -1.5703125,
      0.359375,
      -0.470703125,
      -0.05517578125,
      -0.84765625,
      1.078125,
      -1.0234375,
      -0.2314453125,
      5.03125,
      7.4375,
      -8.25,
      -9.3125,
      3.953125,
      0.31640625,
      0.6640625,
      -1.8203125,
      4.375,
      0.2109375,
      0.8359375,
      -6.15625,
      -4.40625,
      1.5078125,
      0.404296875,
      2.078125,
      3.828125,
      -1.125,
      -2.625,
      -1.6640625,
      4.5625,
      1.703125,
      4.34375,
      -0.89453125,
      -1.6484375,
      0.330078125,
      -2.140625,
      3.078125,
      2.40625,
      7.96875,
      -4.59375,
      -1.5390625,
      1.484375,
      -8.125,
      2.03125,
      -2.390625,
      -0.44140625,
      -1.0625,
      2.484375,
      2.3125,
      -3.71875,
      -2.109375,
      -1.7265625,
      3.59375,
      -3.375,
      1.578125,
      2.125,
      -5.34375,
      -2.40625,
      1.609375,
      0.337890625,
      2.546875,
      -0.99609375,
      -4.1875,
      0.66015625,
      1.3046875,
      3.890625,
      -0.78515625,
      -4.53125,
      -1.875,
      -2.96875,
      3.6875,
      1.9453125,
      0.8984375,
      2.984375,
      -1.34375,
      -3.515625,
      1.359375,
      -1.1796875,
      3.03125,
      -0.22265625,
      0.515625,
      1.0234375,
      -1.7109375,
      2.96875,
      -2.40625,
      -2,
      -0.7578125,
      1.296875,
      -4.75,
      3.234375,
      3.96875,
      1.515625,
      2.34375,
      0.9921875,
      -4.96875,
      -3,
      1.734375,
      -4.8125,
      -3.03125,
      -3.390625,
      4.6875,
      -2.359375,
      0.10546875,
      -2.0625,
      -0.63671875,
      0.458984375,
      2,
      -0.494140625,
      2.234375,
      4.03125,
      -1.2734375,
      -2.65625,
      1.0703125,
      4.25,
      -2.984375,
      1.4296875,
      2.546875,
      1.28125,
      -5.625,
      -6.78125,
      -1.4140625,
      0.921875,
      6.6875,
      -2.125,
      1.1796875,
      -2.84375,
      4.5625,
      -0.26171875,
      0.83984375,
      -13.6875,
      1.5,
      -1.3359375,
      -1.765625,
      -1.1796875,
      -1.71875,
      1.640625,
      -1.0859375,
      5.5,
      3.546875,
      -1.078125,
      2.515625,
      4.65625,
      0.7109375,
      -1.5625,
      2.671875,
      -0.314453125,
      -0.86328125,
      1.5546875,
      -2.03125,
      -6.09375,
      -0.50390625,
      -0.9296875,
      0.59765625,
      1.0546875,
      2.140625,
      0.1884765625,
      0.2216796875,
      3.828125,
      -5.375,
      -1.0078125,
      3.265625,
      2.1875,
      -3.734375,
      -0.1318359375,
      -1.375,
      2.265625,
      -4.3125,
      2.03125,
      -0.032958984375,
      -2.0625,
      3.65625,
      3.046875,
      0.65234375,
      -0.349609375,
      -1.90625,
      0.466796875,
      5.09375,
      4.09375,
      -3.140625,
      0.80859375,
      -2.265625,
      -0.224609375,
      5.3125,
      1.1640625,
      -1.5234375,
      -3.09375,
      4.09375,
      0.138671875,
      -2.234375,
      4.65625,
      -1.2265625,
      -5.90625,
      0.033447265625,
      -0.828125,
      0.2333984375,
      -2.140625,
      2.71875,
      -0.4375,
      -1.1328125,
      0.31640625,
      0.263671875,
      0.57421875,
      -3.125,
      -0.29296875,
      -0.1064453125,
      -3.859375,
      1.9296875,
      -0.0186767578125,
      -0.8828125,
      1.3125,
      0.99609375,
      2.09375,
      0.0220947265625,
      3.875,
      2.015625,
      5.28125,
      3.421875,
      -2.53125,
      3.109375,
      -3.578125,
      -3.703125,
      -0.6015625,
      -3.296875,
      -2.015625,
      -0.099609375,
      -1.4921875,
      2.84375,
      -2.015625,
      -2.25,
      -4.0625,
      -5.875,
      -1.2109375,
      2.609375,
      -1.3515625,
      4.28125,
      -3.421875,
      5.5,
      -1.1796875,
      -3.84375,
      1.2421875,
      -0.26171875,
      0.9765625,
      -1.0390625,
      1.7421875,
      -6.75,
      1.625,
      5.03125,
      2.515625,
      -2.40625,
      6,
      0.06396484375,
      -3.921875,
      0.71875,
      2.90625,
      -2.015625,
      -2.671875,
      -1.2421875,
      -2.296875,
      -0.1220703125,
      -1.828125,
      0.95703125,
      -1.8671875,
      3.296875,
      -1.15625,
      -0.380859375,
      -2.21875,
      -5.03125,
      -0.30859375,
      -0.0142822265625,
      -0.9921875,
      3.1875,
      3.03125,
      0.8828125,
      -1.7109375,
      1.90625,
      3.171875,
      -1.1796875,
      1.453125,
      -1.703125,
      2.953125,
      3.109375,
      2.6875,
      0.279296875,
      -6.09375,
      -2.265625,
      0.43359375,
      -1.0625,
      4.28125,
      -1.625,
      3.359375,
      3.875,
      4.46875,
      -6.21875,
      -1.8359375,
      1.90625,
      -4.3125,
      0.41796875,
      2.109375,
      1.6796875,
      -0.6796875,
      -0.08154296875,
      1.1640625,
      -3.15625,
      -1.546875,
      2.90625,
      4.25,
      0.380859375,
      -1.3359375,
      3.359375,
      1.90625,
      6.90625,
      -2.75,
      -6.375,
      2.265625,
      2.328125,
      -2.671875,
      0.2099609375,
      5.40625,
      -3.265625,
      0.65234375,
      -1.8828125,
      2.1875,
      1.1328125,
      -0.345703125,
      1.96875,
      -0.6328125,
      2.0625,
      -0.408203125,
      -0.2001953125,
      3.15625,
      -1.15625,
      1.1640625,
      1.171875,
      -1.234375,
      -0.322265625,
      1.6953125,
      -1.171875,
      -1.5234375,
      -2.703125,
      -1.015625,
      -0.1767578125,
      4.1875,
      4.90625,
      -1.8046875,
      -2.3125,
      0.71875,
      5.25,
      -1.4140625,
      5.78125,
      0.59765625,
      8.875,
      -3.5,
      -3.109375,
      2.578125,
      -2.109375,
      1.5546875,
      -0.369140625,
      -6.9375,
      -2.921875,
      -0.474609375,
      0.470703125,
      -3.46875,
      2.875,
      -4.09375,
      2.28125,
      2.109375,
      2.078125,
      2.453125,
      0.90625,
      1.9921875,
      1.6171875,
      -1.296875,
      -2.828125,
      -3.234375,
      -1.234375,
      -2.34375,
      1.9453125,
      -4.28125,
      3.265625,
      1.0625,
      3.421875,
      -2.078125,
      -2.28125,
      -0.51953125,
      6.09375,
      2.28125,
      -1.140625,
      3.90625,
      2.3125,
      0.65625,
      3.453125,
      3.109375,
      -4.28125,
      -4.28125,
      6.0625,
      3.734375,
      -0.322265625,
      2.421875,
      -2.421875,
      0.98046875,
      -2.171875,
      -1.5078125,
      0.1435546875,
      3.75,
      -4.03125,
      -0.828125,
      -0.326171875,
      4.0625,
      -4.03125,
      2.96875,
      3,
      -6.71875,
      4.6875,
      -1.328125,
      -0.5703125,
      0.51171875,
      -0.06689453125,
      6.09375,
      -0.76953125,
      -0.640625,
      -4.75,
      -6.625,
      -2.9375,
      2.09375,
      1.171875,
      3.71875,
      2.8125,
      -3.046875,
      0.0556640625,
      -5,
      -3.140625,
      -4.96875,
      2.6875,
      0.045166015625,
      -2.4375,
      -2.0625,
      -3.15625,
      -8.5,
      -4.21875,
      -2.4375,
      -1.671875,
      -2.3125,
      -7,
      0.5703125,
      1.953125,
      -5.0625,
      -0.482421875,
      -3.578125,
      -1.6015625,
      1.5390625,
      0.1240234375,
      -0.6171875,
      -1.1953125,
      2.203125,
      3.203125,
      -1.4765625,
      5.59375,
      6.15625,
      2.0625,
      3.875,
      -0.93359375,
      -1.234375,
      -3.6875,
      6.71875,
      -1.796875,
      7.65625,
      4.34375,
      1.5,
      -5.84375,
      -0.255859375,
      -0.458984375,
      -0.75390625,
      -6.78125,
      0.478515625,
      -1.09375,
      -0.0034637451171875,
      2.046875,
      0.76171875,
      3.953125,
      -6.4375,
      -1.4609375,
      3.03125,
      -4.28125,
      0.283203125,
      3.9375,
      -2.5,
      3.015625,
      -2.109375,
      -2.15625,
      -0.333984375,
      1.84375,
      2.484375,
      -2.171875,
      2.0625,
      -3.96875,
      0.39453125,
      -0.91015625,
      -1.625,
      -1.0703125,
      -0.412109375,
      2.640625,
      0.259765625,
      0.4609375,
      2.78125,
      2.90625,
      3.140625,
      2.90625,
      3.125,
      -0.8671875,
      3.421875,
      -0.4609375,
      -6.5,
      4.125,
      0.48046875,
      -1.0390625,
      -0.1279296875,
      2.28125,
      -4.28125,
      1.46875,
      1.53125,
      -3.265625,
      -1.2734375,
      -2.859375,
      -2.78125,
      1.515625,
      -1.71875,
      0.96875,
      4.90625,
      1.7421875,
      1.6015625,
      1.4140625,
      1.75,
      1.5078125,
      0.68359375,
      -1.953125,
      5.78125,
      -4.40625,
      -2.578125,
      4.59375,
      3.046875,
      2.953125,
      -3.421875,
      -1.1015625,
      -4.1875,
      0.054443359375,
      2.265625,
      -1.46875,
      1.140625,
      5.625,
      -2.140625,
      -0.5234375,
      0.259765625,
      -0.1650390625,
      2.109375,
      -0.498046875,
      1.4453125,
      5.59375,
      3.453125,
      -2.59375,
      -0.94140625,
      -5.5,
      1.3828125,
      -2.046875,
      -1.328125,
      -0.1494140625,
      -0.5546875,
      -1.484375,
      1.296875,
      -2.1875,
      0.1181640625,
      1.296875,
      -5.90625,
      -0.154296875,
      4.65625,
      -2.921875,
      -0.004486083984375,
      1,
      2.5,
      -3.359375,
      1.7890625,
      0.828125,
      -2.546875,
      0.8671875,
      1.9375,
      -1.796875,
      4.71875,
      3.015625,
      -1.2421875,
      -0.373046875,
      -4.90625,
      0.267578125,
      1.46875,
      -0.048828125,
      2.25,
      -3,
      2.25,
      3.265625,
      2.84375,
      -1.2890625,
      3.53125,
      -0.16796875,
      -1.6171875,
      3.234375,
      -2.96875,
      -3.578125,
      -0.89453125,
      -1.453125,
      -2.3125,
      -0.1689453125,
      -1.484375,
      0.734375,
      2.546875,
      -7.03125,
      4.84375,
      -6.34375,
      5.65625,
      -0.59375,
      0.0137939453125,
      -2.125,
      -2.3125,
      2.125,
      -3.421875,
      -0.419921875,
      -0.91796875,
      -4.28125,
      3.09375,
      -1.359375,
      -2.015625,
      -0.75,
      -0.396484375,
      4.28125,
      -0.208984375,
      1.765625,
      -0.06787109375,
      1.890625,
      -5.9375,
      -2.25,
      1.6171875,
      -0.828125,
      0.68359375,
      0.115234375,
      -1.953125,
      -0.55859375,
      0.69140625,
      -2.390625,
      3.03125,
      -1.8046875,
      -1.796875,
      2.90625,
      1.4140625,
      4.53125,
      4.46875,
      -1.5078125,
      -0.80859375,
      -0.75,
      -4.5625,
      -5.15625,
      -0.6875,
      -0.31640625,
      -4.84375,
      0.703125,
      0.8671875,
      0.1875,
      0.484375,
      -0.8359375,
      1.5,
      2.234375,
      1.5,
      -0.2197265625,
      5.3125,
      -0.267578125,
      2.375,
      -4.53125,
      -5.5625,
      -6.46875,
      1.890625,
      -0.2890625,
      -4.75,
      -0.291015625,
      -4.71875,
      2.25,
      1.8984375,
      -1.8125,
      0.294921875,
      -0.2021484375,
      6.03125,
      -0.11328125,
      -2.859375,
      2.640625,
      3.515625,
      3.296875,
      -4.53125,
      -3.578125,
      -3.125,
      1.125,
      0.055419921875,
      0.01324462890625,
      -1.4140625,
      -0.671875,
      -2.609375,
      -0.1689453125,
      -6.03125,
      -2.65625,
      4.4375,
      2.234375,
      5.90625,
      0.6328125,
      -0.92578125,
      -2.078125,
      -1.125,
      -1.6171875,
      4.28125,
      3.15625,
      -0.33984375,
      1.203125,
      -3.609375,
      7.5,
      -5.375,
      -2.421875,
      -6.34375,
      -1.4921875,
      5.5,
      1.8359375,
      -3.796875,
      -1.1171875,
      -0.78125,
      1.515625,
      -0.265625,
      2.328125,
      -0.75,
      -2.953125,
      -1.1328125,
      5.03125,
      2.9375,
      -4.8125,
      1.296875,
      0.92578125,
      -3.25,
      -0.5390625,
      2.515625,
      2.984375,
      -1.4921875,
      4.0625,
      -0.94140625,
      -3.890625,
      -3.8125,
      4.28125,
      -0.00026702880859375,
      -0.90234375,
      1.3984375,
      -3.3125,
      1.734375,
      0.158203125,
      -0.1298828125,
      4.40625,
      -1.5390625,
      1.453125,
      -1.3125,
      3.578125,
      0.40234375,
      -1.671875,
      -3.21875,
      4.6875,
      2.71875,
      0.1376953125,
      1.5703125,
      -2.984375,
      -1.5234375,
      0.435546875,
      -7.0625,
      0.82421875,
      4.84375,
      0.0556640625,
      3.40625,
      -0.28515625,
      2.125,
      -3.109375,
      -0.953125,
      -1.0078125,
      -2.15625,
      2.59375,
      2.34375,
      2.390625,
      -2.0625,
      0.58203125,
      0.470703125,
      1.921875,
      0.57421875,
      5.25,
      -2.09375,
      3.296875,
      4.0625,
      3.859375,
      -4.09375,
      -2.734375,
      -0.01116943359375,
      0.74609375,
      -2.3125,
      0.0283203125,
      1.828125,
      -3.328125,
      1.859375,
      0.30078125,
      -1.265625,
      0.203125,
      -3.1875,
      -0.2177734375,
      1.296875,
      -2.921875,
      -5.8125,
      2.546875,
      -5.75,
      0.0869140625,
      4.0625,
      -0.83203125,
      -1.6171875,
      -1.171875,
      -1.2890625,
      2.640625,
      2.953125,
      -0.48828125,
      -2.984375,
      5.3125,
      -2.84375,
      -6.25,
      -4.71875,
      2.515625,
      -0.330078125,
      -2.921875,
      0.6328125,
      -2.8125,
      1.328125,
      -1.5546875,
      -6.0625,
      2.125,
      -1.171875,
      -0.357421875,
      2.703125,
      4.71875,
      -0.84375,
      -1.7265625,
      -2.234375,
      3.765625,
      1.546875,
      -0.0067138671875,
      -0.05078125,
      -0.2294921875,
      0.404296875,
      -3.25,
      3.796875,
      0.03271484375,
      -1.578125,
      4.875,
      3.671875,
      -6.15625,
      1.3984375,
      1.421875,
      4.6875,
      -3.125,
      -2.8125,
      -0.7265625,
      8.8125,
      -0.92578125,
      -0.98046875,
      -4.15625,
      -0.322265625,
      0.84375,
      -1.09375,
      -0.09814453125,
      -1.3671875,
      2.890625,
      -5.0625,
      0.6796875,
      2.0625,
      4.34375,
      3.8125,
      -3.359375,
      1.59375,
      4.625,
      1.2265625,
      4.21875,
      -2.296875,
      -2.859375,
      -2.390625,
      1.03125,
      -5.9375,
      -2.46875,
      -5.875,
      -2.1875,
      -1.65625,
      -2.421875,
      -1.8671875,
      0.84375,
      1.4765625,
      1.546875,
      -2.171875,
      -0.353515625,
      -1.2578125,
      -2.53125,
      1.5625,
      -0.408203125,
      -5.15625,
      2.078125,
      1.671875,
      -0.267578125,
      5.40625,
      2.390625,
      2.890625,
      -3.3125,
      0.61328125,
      -3.90625,
      -1.2890625,
      -2.40625,
      0.57421875,
      1.671875,
      -0.33984375,
      1.9296875,
      -0.1298828125,
      4.09375,
      -4.9375,
      -4.28125,
      -5.3125,
      -2.84375,
      -0.322265625,
      -0.48046875,
      -1.3125,
      0.84375,
      5.34375,
      -1.9453125,
      2.375,
      2.78125,
      0.921875,
      -4.28125,
      0.267578125,
      0.1357421875,
      3.5,
      3.375,
      4.4375,
      -5,
      4.78125,
      1.09375,
      -2.09375,
      4.0625,
      0.734375,
      1.1796875,
      -4.09375,
      2.875,
      -0.0556640625,
      3.8125,
      -4.0625,
      3.125,
      0.14453125,
      2.421875,
      4.6875,
      6.3125,
      1.796875,
      -2.515625,
      1.2734375,
      0.62109375,
      -2.421875,
      -3.0625,
      2.765625,
      -1.15625,
      -2.078125,
      3.328125,
      -0.5390625,
      2.1875,
      2.296875,
      2.375,
      2.015625,
      4.96875,
      -5.96875,
      2.421875,
      -6.1875,
      0.52734375,
      -5.6875,
      0.4921875,
      -6.78125,
      1.6875,
      3.734375,
      4.21875,
      -1.3515625,
      -4.375,
      2.25,
      2.609375,
      0.1787109375,
      -3.234375,
      2.546875,
      0.8359375,
      -0.1708984375,
      -2.796875,
      -3.140625,
      3.609375,
      0.28125,
      -1.3203125,
      -2.71875,
      2.78125,
      0.80859375,
      -0.244140625,
      -3.828125,
      0.10595703125,
      -2.09375,
      -6.71875,
      -3.65625,
      -3.859375,
      1.9296875,
      -3.640625,
      1.4296875,
      4.5,
      -2.21875,
      1.4921875,
      -0.7578125,
      1.8046875,
      2.140625,
      -0.74609375,
      0.1533203125,
      -0.83203125,
      -0.369140625,
      -0.06396484375,
      3.546875,
      -3.28125,
      0.96484375,
      -2.015625,
      3.421875,
      3.4375,
      -0.55859375,
      -1.484375,
      -7.34375,
      4.65625,
      2.1875,
      0.80859375,
      -0.8046875,
      -3.984375,
      2.265625,
      1.1171875,
      -1.8984375,
      -3.25,
      3.875,
      1.2265625,
      -1.046875,
      1.1484375,
      -0.90625,
      4.03125,
      1.5,
      3.171875,
      0.09423828125,
      0.345703125,
      -2.484375,
      -1.9375,
      -0.8359375,
      1.78125,
      -0.8203125,
      4.28125,
      -1.3125,
      -2.859375,
      -0.80078125,
      3.421875,
      0.9375,
      1.765625,
      -1.8046875,
      -2.234375,
      -1.1484375,
      3.140625,
      -1.2734375,
      -2.078125,
      -0.1826171875,
      0.1884765625,
      -1,
      -1.1953125,
      -0.609375,
      -1.671875,
      2.859375,
      -3.03125,
      -2.328125,
      -2.125,
      2.421875,
      0.443359375,
      -8.375,
      0.609375,
      1.0234375,
      0.78515625,
      0.75390625,
      0.2373046875,
      2.46875,
      3.265625,
      2.625,
      4.375,
      -0.2236328125,
      -3.859375,
      3.265625,
      18.125,
      -4.15625,
      -3.203125,
      1.0234375,
      -2.09375,
      1.2734375,
      9.875,
      0.87109375,
      0.81640625,
      1.4375,
      0.28515625,
      3.53125,
      2.890625,
      0.6171875,
      -1.0546875,
      -0.099609375,
      3.3125,
      2.140625,
      -1.5234375,
      -3.578125,
      0.36328125,
      -0.85546875,
      -0.263671875,
      4.25,
      -3.375,
      0.65625,
      1.859375,
      -3.6875,
      -2.40625,
      -1.890625,
      -1.1640625,
      -3.90625,
      -3.0625,
      -2.859375,
      0.84765625,
      -5.0625,
      -0.68359375,
      0.70703125,
      -2.125,
      -0.80078125,
      -2.390625,
      -4.15625,
      1.8515625,
      1.1953125,
      -2.375,
      -3.28125,
      -1.359375,
      0.271484375,
      -0.77734375,
      3.125,
      0.0118408203125,
      -1.9609375,
      -2.875,
      1.796875,
      1.5078125,
      -0.8359375,
      -2.125,
      -5.8125,
      -2.34375,
      -1.3671875,
      -2.21875,
      -2.6875,
      -3.765625,
      -0.2158203125,
      1,
      -3.125,
      -1.5546875,
      -0.169921875,
      0.416015625,
      0.96484375,
      -5.3125,
      -0.15234375,
      4.75,
      4.5,
      1.4453125,
      -1.703125,
      2.109375,
      4.15625,
      1.015625,
      3.015625,
      -1.2890625,
      1.7265625,
      -4.40625,
      0.2099609375,
      -2.859375,
      0.8828125,
      -4.75,
      1.3125,
      1.2109375,
      -0.494140625,
      4.65625,
      -6.125,
      2.609375,
      2.328125,
      -4.125,
      0.017333984375,
      2.484375,
      -1.6171875,
      -1.28125,
      -1.3984375,
      3.546875,
      1.328125,
      1.453125,
      1.1015625,
      0.36328125,
      -1.96875,
      0.16015625,
      -3.34375,
      1.8125,
      -2.359375,
      -2.828125,
      2.3125,
      1.015625,
      -1.5390625,
      0.0252685546875,
      1.2578125,
      -1.515625,
      -1.8046875,
      0.2265625,
      -1.8671875,
      1.2421875,
      -1.7734375,
      -2.859375,
      0.51953125,
      -8.625,
      -2.390625,
      -0.80078125,
      -5.4375,
      1.140625,
      -4.46875,
      -1.515625,
      -2.0625,
      -2.1875,
      -2.328125,
      2.3125,
      -3.796875,
      3.265625,
      4.71875,
      2.390625,
      -1.578125,
      -3.84375,
      2.109375,
      1.234375,
      -1.140625,
      -2.0625,
      2.234375,
      -2.125,
      0.2451171875,
      1.6328125,
      2.4375,
      -0.6171875,
      3.8125,
      2.40625,
      -4.875,
      -5.65625,
      4.6875,
      -2.4375,
      -1.09375,
      -1.15625,
      -1.0703125,
      -1.390625,
      -0.55078125,
      0.006683349609375,
      -2.9375,
      0.91796875,
      -0.0537109375,
      2.609375,
      -0.75,
      -5.75,
      4.8125,
      4.4375,
      -8.375,
      -0.66015625,
      -2.78125,
      1.3828125,
      -1.34375,
      1.59375,
      5.0625,
      1.265625,
      2.125,
      5.40625,
      2.25,
      -3.03125,
      -5.71875,
      0.029296875,
      3.890625,
      -3.171875,
      2.578125,
      2.671875,
      1.4296875,
      0.2294921875,
      -5.53125,
      -4.125,
      4.6875,
      3.09375,
      -3.3125,
      -1.6484375,
      -1.09375,
      -0.79296875,
      -3.75,
      -2.125,
      2.359375,
      1.4921875,
      2.640625,
      3.078125,
      1.4765625,
      -2.0625,
      2.0625,
      0.59765625,
      0.59765625,
      -2.703125,
      2.65625,
      2.25,
      2.1875,
      -7.75,
      4.8125,
      2.828125,
      2.390625,
      -0.5546875,
      0.296875,
      2.21875,
      0.053466796875,
      -4.75,
      -1.4765625,
      2.53125,
      4.125,
      -7.28125,
      2.4375,
      -3.203125,
      0.76953125,
      -2.1875,
      0.8359375,
      1.5859375,
      0.2001953125,
      -6.59375,
      -5,
      -3.609375,
      3.859375,
      2.5625,
      1.703125,
      2.078125,
      -2.140625,
      4.875,
      1.671875,
      -1.46875,
      0.48828125,
      -2.078125,
      -0.9296875,
      0.75,
      2.65625,
      0.359375,
      3.234375,
      3.984375,
      -2.1875,
      0.41015625,
      -5,
      -4.21875,
      -1.109375,
      -5.03125,
      -0.8828125,
      -0.236328125,
      -7.96875,
      4.9375,
      -1.8359375,
      -1.4140625,
      0.0625,
      0.55078125,
      -7.0625,
      5.625,
      3.953125,
      -4.3125,
      3.421875,
      -0.76171875,
      -2.984375,
      -0.62109375,
      -2.234375,
      -0.008544921875,
      -1.9609375,
      0.6640625,
      4.1875,
      -4.53125,
      1.59375,
      1.7421875,
      -2.546875,
      1.0546875,
      -3.109375,
      3.234375,
      -0.271484375,
      3,
      3.140625,
      0.8984375,
      1.4921875,
      -4.5,
      1.2421875,
      -0.890625,
      3.34375,
      -3.375,
      0.53125,
      0.90625,
      -3.171875,
      2.3125,
      2.109375,
      1.1875,
      -6.4375,
      -2.46875,
      1.3828125,
      -2.328125,
      2.6875,
      1.171875,
      2.703125,
      -3.1875,
      0.2080078125,
      2.5,
      2.21875,
      -1.140625,
      1.1953125,
      -5.25,
      2.390625,
      0.52734375,
      -6.6875,
      -3.890625,
      -0.1328125,
      -0.265625,
      -3.28125,
      -4.0625,
      -3.75,
      -0.1015625,
      2.890625,
      -3.609375,
      -0.0869140625,
      0.212890625,
      -1.8515625,
      2.1875,
      -1.0625,
      2.359375,
      0.203125,
      -1.7578125,
      -7.5625,
      -0.060791015625,
      -1.1640625,
      1.75,
      4.0625,
      -1.75,
      5.78125,
      0.08837890625,
      4.0625,
      -6.1875,
      3.390625,
      3.359375,
      -7.6875,
      3.609375,
      -4.1875,
      -0.4453125,
      -2.328125,
      -5.9375,
      -4.0625,
      3.90625,
      -2.453125,
      1.9765625,
      5.21875,
      -0.345703125,
      -0.1884765625,
      0.33203125,
      -2.359375,
      -3.1875,
      1.125,
      3.640625,
      -3.453125,
      4.03125,
      2.734375,
      -1.75,
      0.89453125,
      -1.3671875,
      1.5546875,
      -0.7578125,
      -5.28125,
      3.71875,
      0.85546875,
      -0.451171875,
      -1.328125,
      -4.4375,
      -1.7265625,
      -1.453125,
      -3.265625,
      1.078125,
      -0.71875,
      1.3046875,
      -1.4140625,
      1.6953125,
      -0.59375,
      -5.53125,
      0.8515625,
      -2.390625,
      -0.177734375,
      1.9765625,
      1.390625,
      1.53125,
      -1.8515625,
      0.419921875,
      3.6875,
      3.640625,
      0.7890625,
      -4.75,
      1.2890625,
      -1.015625,
      -1.578125,
      -2.1875,
      2.796875,
      -3.3125,
      -2.8125,
      3.015625,
      2.65625,
      2.5625,
      -4.71875,
      -2.546875,
      0.48046875,
      3.59375,
      0.0059814453125,
      1.1953125,
      0.4453125,
      2.296875,
      4.25,
      -6.15625,
      -4.3125,
      -1.34375,
      2.3125,
      -4.25,
      -4.78125,
      -0.455078125,
      -2.296875,
      1.0859375,
      5.3125,
      0.0224609375,
      2.15625,
      3.890625,
      -6.0625,
      -3,
      6.0625,
      3.3125,
      1.6171875,
      -0.8984375,
      -0.5078125,
      -2.109375,
      2.15625,
      7.65625,
      -3.796875,
      -2.5625,
      0.38671875,
      -3.953125,
      -2.265625,
      -3.046875,
      2.703125,
      -1.1796875,
      -6.90625,
      8.0625,
      -1.4140625,
      2.109375,
      2.0625,
      -0.80859375,
      3.4375,
      -0.21875,
      -0.296875,
      -1.421875,
      2.421875,
      4.03125,
      -3.859375,
      -3.609375,
      -2.09375,
      -1.65625,
      -0.64453125,
      -3.859375,
      0.006591796875,
      -0.57421875,
      4.03125,
      2.203125,
      0.71875,
      -0.0301513671875,
      -0.5859375,
      1.640625,
      -1.4296875,
      -0.78515625,
      -1.4765625,
      -2.5,
      1.0078125,
      -2.171875,
      2.296875,
      -4.0625,
      -2.953125,
      -0.578125,
      2.578125,
      2.015625,
      3.6875,
      -0.75390625,
      -3.203125,
      -4.21875,
      2.46875,
      0.92578125,
      7.125,
      3.734375,
      3.28125,
      1.2578125,
      -2.359375,
      1.0078125,
      4.1875,
      3.6875,
      -1.71875,
      -0.2080078125,
      2.640625,
      0.578125,
      -1.2890625,
      -0.9375,
      1.2890625,
      2.5625,
      3.9375,
      0.357421875,
      -0.86328125,
      -2.40625,
      -0.29296875,
      -4.5625,
      1.71875,
      3.921875,
      3.96875,
      0.400390625,
      -0.7421875,
      2.765625,
      4.6875,
      1.59375,
      1.578125,
      0.37890625,
      -0.76953125,
      -2.890625,
      1.2421875,
      0.58203125,
      -1.0390625,
      2.28125,
      -1.78125,
      -0.93359375,
      0.625,
      -3.125,
      3.421875,
      -1.0234375,
      -3.453125,
      1.1484375,
      -2.15625,
      3.640625,
      -0.0859375,
      0.1474609375,
      -0.28515625,
      1.9609375,
      1.4140625,
      4.65625,
      -1.9609375,
      -0.279296875,
      1.1484375,
      3,
      -0.86328125,
      -1.0234375,
      0.42578125,
      -0.70703125,
      0.8125,
      -1.3046875,
      0.60546875,
      -2.390625,
      2.5625,
      1.4765625,
      -2.25,
      2.375,
      -2.859375,
      -5.75,
      1.9609375,
      -2.625,
      0.1728515625,
      -1.3046875,
      1.578125,
      1.78125,
      0.031982421875,
      2.25,
      0.28125,
      -2.234375,
      -1.5546875,
      -1.921875,
      -0.75,
      -1.421875,
      -4.875,
      -1.640625,
      0.9296875,
      0.8203125,
      -1.5546875,
      1.75,
      1.40625,
      -0.318359375,
      -1.1796875,
      0.6796875,
      -0.5859375,
      1.2890625,
      0.96875,
      -0.0050048828125,
      1.59375,
      2.890625,
      0.9375,
      0.8828125,
      -0.388671875,
      1.6328125,
      -1.2578125,
      1.1015625,
      2.125,
      2.25,
      1.3046875,
      -0.51171875,
      2.171875,
      -0.84765625,
      2.640625,
      -2.375,
      0.50390625,
      -0.22265625,
      -1.78125,
      4.40625,
      -1.5390625,
      -0.640625,
      2.578125,
      2.5625,
      -3.390625,
      -1.5546875,
      -0.96484375,
      1.3515625,
      1.4609375,
      0.57421875,
      -2.40625,
      1.484375,
      0.94921875,
      2.109375,
      1.828125,
      2.671875,
      -4.1875,
      0.80078125,
      1.78125,
      -1.7421875,
      -0.03662109375,
      -0.259765625,
      -1,
      -0.361328125,
      -2.90625,
      -4.75,
      -0.0263671875,
      -0.0712890625,
      0.251953125,
      1.359375,
      -2.984375,
      1.0078125,
      0.07568359375,
      1.78125,
      3.359375,
      -3.484375,
      0.95703125,
      -0.41796875,
      1.109375,
      -1.3125,
      0.486328125,
      -0.85546875,
      1.6640625,
      -3.046875,
      -0.15234375,
      -1.3125,
      -0.875,
      0.00189208984375,
      0.984375,
      -1.421875,
      -4.21875,
      -1.1015625,
      -1.921875,
      -1.671875,
      -3.6875,
      1.96875,
      1.6171875,
      -2.703125,
      -1.03125,
      0.828125,
      -0.1806640625,
      0.447265625,
      -1.4921875,
      -0.703125,
      0.734375,
      2.484375,
      2.65625,
      3.171875,
      -1.90625,
      3,
      -1.6796875,
      -1.6640625,
      -3.59375,
      -0.21484375,
      1.7734375,
      -2.390625,
      2.875,
      -0.0037841796875,
      2.734375,
      3.296875,
      -0.96484375,
      0.80859375,
      1.5546875,
      -0.2275390625,
      4.375,
      3.703125,
      0.57421875,
      -0.08203125,
      0.130859375,
      0.69921875,
      0.482421875,
      0.59375,
      1.453125,
      -1.4921875,
      3.46875,
      -2.25,
      -0.69921875,
      -1.9140625,
      -1.7734375,
      0.51171875,
      -0.2177734375,
      0.90625,
      -3,
      3.1875,
      -0.84375,
      -1.734375,
      -0.578125,
      -0.333984375,
      -1.7421875,
      -0.061279296875,
      -3.65625,
      -2.140625,
      -1.078125,
      -1.3671875,
      1.0703125,
      0.408203125,
      -0.765625,
      -2.828125,
      -2.453125,
      -0.52734375,
      0.150390625,
      0.61328125,
      0.90625,
      1.984375,
      1.4375,
      0.333984375,
      0.92578125,
      -1.6796875,
      1.75,
      1.1171875,
      -0.94921875,
      1.1796875,
      -1.1640625,
      -0.341796875,
      -2.84375,
      -3.46875,
      -0.2060546875,
      -0.5546875,
      -1.640625,
      0.322265625,
      1.1875,
      -1.609375,
      -3.25,
      1.609375,
      -1.953125,
      4.78125,
      -0.275390625,
      -2.359375,
      2.875,
      0.291015625,
      0.412109375,
      -1.78125,
      -2.265625,
      1.1015625,
      -0.431640625,
      1.0546875,
      -1.0234375,
      1.59375,
      -1.1015625,
      0.55078125,
      -1.609375,
      -0.4375,
      -1.125,
      -2.09375,
      0.96484375,
      1.1328125,
      -0.69921875,
      5.4375,
      1.9140625,
      3.09375,
      0.52734375,
      0.22265625,
      0.75390625,
      4.0625,
      2.703125,
      -1.03125,
      -2.15625,
      -1.328125,
      2.796875,
      1.0859375,
      0.2275390625,
      -0.1787109375,
      3.125,
      7.53125,
      -0.51953125,
      -1.5859375,
      -2.90625,
      -0.79296875,
      0.1982421875,
      1.3515625,
      4.84375,
      -5.5,
      -0.27734375,
      0.90625,
      -0.138671875,
      -0.60546875,
      2.296875,
      3.28125,
      -0.357421875,
      2.921875,
      1.2421875,
      1.3359375,
      -1.0546875,
      1.8046875,
      -0.427734375,
      3.09375,
      -0.984375,
      -1.40625,
      -1.2109375,
      0.609375,
      -4.03125,
      2.328125,
      -1.453125,
      -0.1259765625,
      0.78125,
      -0.11474609375,
      3.28125,
      -2.59375,
      0.53515625,
      5.25,
      -0.6875,
      1.0703125,
      -1.421875,
      -0.298828125,
      4.59375,
      0.609375,
      0.74609375,
      -2.46875,
      2.28125,
      -0.373046875,
      -4.21875,
      -3.359375,
      -0.2470703125,
      -3.390625,
      -1.5390625,
      -5.03125,
      -0.0089111328125,
      -1.0703125,
      5.4375,
      -1.625,
      0.68359375,
      1.8515625,
      0.921875,
      1.1328125,
      4.53125,
      2.03125,
      1.84375,
      -0.474609375,
      -0.6171875,
      2.25,
      0.35546875,
      -2.671875,
      -0.8515625,
      2.4375,
      -3.953125,
      1.4765625,
      -1.796875,
      -1.3671875,
      0.578125,
      -2.765625,
      -1.78125,
      -1.6015625,
      1.328125,
      -3.046875,
      2.625,
      0.7421875,
      -0.96484375,
      -3.78125,
      2.75,
      1.5390625,
      1.1796875,
      1.921875,
      -1.3125,
      -2.4375,
      1.6171875,
      0.51171875,
      -0.2451171875,
      -1.3515625,
      3.078125,
      3.65625,
      -0.66015625,
      -2,
      0.5234375,
      3.640625,
      -0.53125,
      0.98828125,
      -2.515625,
      -1.890625,
      0.78515625,
      4.40625,
      2.09375,
      1.375,
      1.4609375,
      3.4375,
      -2.15625,
      1.2421875,
      -0.97265625,
      -3.15625,
      -1.46875,
      1.9375,
      1.1171875,
      1.609375,
      3.78125,
      0.97265625,
      2.203125,
      -3.859375,
      1.609375,
      -0.27734375,
      -2.53125,
      3.140625,
      0.69140625,
      -2.625,
      -2,
      -0.103515625,
      -4.875,
      1.578125,
      -1.1484375,
      -3.671875,
      1.40625,
      0.87109375,
      -0.11865234375,
      0.1826171875,
      -1.671875,
      2.921875,
      5.28125,
      0.8515625,
      1.359375,
      1.1640625,
      0.3671875,
      1.359375,
      -2.21875,
      3.359375,
      -1.640625,
      -3.96875,
      0.515625,
      0.61328125,
      1.7734375,
      -0.15234375,
      0.337890625,
      1.7890625,
      0.00836181640625,
      -1.4375,
      3.71875,
      0.94140625,
      0.25,
      4.40625,
      -0.91015625,
      0.07177734375,
      -3.953125,
      1.9609375,
      0.578125,
      -0.0751953125,
      0.181640625,
      1.578125,
      0.051513671875,
      -2.4375,
      0.2734375,
      -1.453125,
      1.7109375,
      -0.54296875,
      -0.71875,
      -2.21875,
      -2.453125,
      -2.46875,
      0.859375,
      -4.875,
      1.8046875,
      -0.34765625,
      -1.9296875,
      1.34375,
      -1.1875,
      -2.71875,
      -3.640625,
      1.9609375,
      2.203125,
      1.0390625,
      -3.515625,
      0.388671875,
      3.171875,
      -0.8046875,
      1.1875,
      3.53125,
      2.515625,
      -0.09130859375,
      -2.015625,
      1.453125,
      -6.9375,
      0.1982421875,
      -1.5390625,
      1.3203125,
      1.5,
      0.470703125,
      -1.7109375,
      4.03125,
      1.9609375
    ],
    "structure": {
      "sections": [
        {
          "title": "A large language model-assisted education tool to provide feedback on open-ended responses",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Introduction",
          "level": 1,
          "start_line": 11
        },
        {
          "title": "Related Work",
          "level": 1,
          "start_line": 24
        },
        {
          "title": "Approach",
          "level": 1,
          "start_line": 36
        },
        {
          "title": "Question Design",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "Question Presentation",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "Feedback to Students",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "Discussion",
          "level": 1,
          "start_line": 92
        },
        {
          "title": "Supplemental Materials",
          "level": 1,
          "start_line": 114
        },
        {
          "title": "Acknowledgements",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "Bibliography",
          "level": 1,
          "start_line": 126
        }
      ]
    },
    "tags": [
      "教育AI",
      "自动评分",
      "LLM应用"
    ],
    "suggested_tags": [
      "教育AI",
      "自动评分",
      "LLM应用",
      "开放题反馈"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.98,
        "reason": "论文核心目标是用大模型为开放式学生作答提供即时个性化反馈，直接服务于教学场景。"
      },
      {
        "name": "自动评分",
        "confidence": 0.95,
        "reason": "提出 FreeText 工具，依据教师设定的评分标准自动评估开放式答案，属于自动评分/自动学习评估研究。"
      },
      {
        "name": "LLM应用",
        "confidence": 0.92,
        "reason": "以大型语言模型为关键技术驱动，无需微调即可生成高质量反馈，是典型的LLM垂直应用。"
      },
      {
        "name": "开放题反馈",
        "confidence": 0.9,
        "reason": "聚焦开放式问题（free-text response）的即时反馈生成，解决传统主观题批改瓶颈。"
      }
    ],
    "tags_confirmed": true,
    "category": "教育AI",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:276483132",
          "title": "Enhancing Cybersecurity Education using Scoring Engines: A Practical Approach to Hands-On Learning and Feedback",
          "authors": [
            "Christopher Morales-Gonzalez",
            "Matthew Harper",
            "Pranathi Rayavaram",
            "Sashank Narain",
            "Xinwen Fu"
          ],
          "year": 2025,
          "venue": "Technical Symposium on Computer Science Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:275786515",
          "title": "A Rubric-Centric Approach for Automated Test Correction Utilizing RAG and Fine Tuning",
          "authors": [
            "G. Harshavardhan",
            "Kulvinder Singh"
          ],
          "year": 2024,
          "venue": "2024 4th International Conference on Technological Advancements in Computational Sciences (ICTACS)",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:271571948",
          "title": "Grading Programming Assignments by Summarization",
          "authors": [
            "Dong Dong",
            "Yue Liang"
          ],
          "year": 2024,
          "venue": "ACM Turing Celebration Conference",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:271462617",
          "title": "Automated Verification of Open/Closed Principle: A Code Analysis Approach",
          "authors": [
            "Gifty Roy",
            "Manohar M",
            "Benjamin A. Jacob"
          ],
          "year": 2024,
          "venue": "2024 5th International Conference for Emerging Technology (INCET)",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:265543562",
          "title": "Intelligent Deep-Learning Tutoring System to Assist Instructors in Programming Courses",
          "authors": [
            "David Roldán-álvarez",
            "Francisco J. Mesa"
          ],
          "year": 2024,
          "venue": "IEEE Transactions on Education",
          "citation_count": 10
        },
        {
          "external_id": "CorpusId:260611570",
          "title": "A large language model-assisted education tool to provide feedback on open-ended responses",
          "authors": [
            "Jordan K Matelsky",
            "Felipe Parodi",
            "Tony Liu",
            "Richard D. Lange",
            "K. Kording"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 30
        },
        {
          "external_id": "CorpusId:259203965",
          "title": "Automated Grading and Feedback Tools for Programming Education: A Systematic Review",
          "authors": [
            "Marcus Messer",
            "Neil C. C. Brown",
            "Michael Kölling",
            "Miaojing Shi"
          ],
          "year": 2023,
          "venue": "ACM Transactions on Computing Education",
          "citation_count": 125
        },
        {
          "external_id": "CorpusId:256194488",
          "title": "Smart tutor to provide feedback in programming courses",
          "authors": [
            "David Rold'an-'Alvarez"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:251881395",
          "title": "Automatic Assessment of the Design Quality of Student Python and Java Programs",
          "authors": [
            "J. Orr"
          ],
          "year": 2022,
          "venue": "Journal of Computing Sciences in Colleges (JCSC; Formerly: Journal of Computing in Small Colleges)",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:250315989",
          "title": "Automated Grading and Feedback of Programming Assignments",
          "authors": [
            "Marcus Messer"
          ],
          "year": 2022,
          "venue": "Annual Conference on Innovation and Technology in Computer Science Education",
          "citation_count": 3
        }
      ],
      "citations_fetched_at": "2025-12-17T09:45:02.640949",
      "references": [
        {
          "external_id": "CorpusId:6967078",
          "title": "The Continuous Hint Factory - Providing Hints in Vast and Sparsely Populated Edit Distance Spaces",
          "authors": [
            "Benjamin Paassen",
            "B. Hammer",
            "T. Price",
            "Tiffany Barnes",
            "S. Gross",
            "Niels Pinkwart"
          ],
          "year": 2017,
          "venue": "arXiv.org",
          "citation_count": 56
        },
        {
          "external_id": "CorpusId:3550454",
          "title": "Learning to Represent Student Knowledge on Programming Exercises Using Deep Learning",
          "authors": [
            "L. Wang",
            "Angela Sy",
            "Larry Liu",
            "C. Piech"
          ],
          "year": 2017,
          "venue": "Educational Data Mining",
          "citation_count": 87
        },
        {
          "external_id": "CorpusId:6515824",
          "title": "Learning Program Embeddings to Propagate Feedback on Student Code",
          "authors": [
            "C. Piech",
            "Jonathan Huang",
            "A. Nguyen",
            "Mike Phulsuksombati",
            "M. Sahami",
            "L. Guibas"
          ],
          "year": 2015,
          "venue": "International Conference on Machine Learning",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:6628106",
          "title": "Adam: A Method for Stochastic Optimization",
          "authors": [
            "Diederik P. Kingma",
            "Jimmy Ba"
          ],
          "year": 2014,
          "venue": "International Conference on Learning Representations",
          "citation_count": 160262
        },
        {
          "external_id": "CorpusId:14832074",
          "title": "Improving neural networks by preventing co-adaptation of feature detectors",
          "authors": [
            "Geoffrey E. Hinton",
            "Nitish Srivastava",
            "A. Krizhevsky",
            "I. Sutskever",
            "R. Salakhutdinov"
          ],
          "year": 2012,
          "venue": "arXiv.org",
          "citation_count": 7891
        },
        {
          "external_id": "CorpusId:26300103",
          "title": "Classification and regression trees",
          "authors": [
            "N. Speybroeck"
          ],
          "year": 2012,
          "venue": "International Journal of Public Health",
          "citation_count": 15842
        },
        {
          "external_id": "CorpusId:740063",
          "title": "A Survey on Transfer Learning",
          "authors": [
            "Sinno Jialin Pan",
            "Qiang Yang"
          ],
          "year": 2010,
          "venue": "IEEE Transactions on Knowledge and Data Engineering",
          "citation_count": 22286
        },
        {
          "external_id": "CorpusId:15539264",
          "title": "Rectified Linear Units Improve Restricted Boltzmann Machines",
          "authors": [
            "Vinod Nair",
            "Geoffrey E. Hinton"
          ],
          "year": 2010,
          "venue": "International Conference on Machine Learning",
          "citation_count": 18220
        },
        {
          "external_id": "CorpusId:7398727",
          "title": "Solving the Multiple Instance Problem with Axis-Parallel Rectangles",
          "authors": [
            "Thomas G. Dietterich",
            "R. Lathrop",
            "Tomas Lozano-Perez"
          ],
          "year": 1997,
          "venue": "Artificial Intelligence",
          "citation_count": 2935
        },
        {
          "external_id": "CorpusId:62710001",
          "title": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS",
          "authors": [
            "F. Rosenblatt"
          ],
          "year": 1963,
          "venue": "",
          "citation_count": 2560
        }
      ],
      "references_fetched_at": "2025-12-17T09:45:03.170339"
    }
  },
  "89ef51d5-6260-4fcd-9f65-1f75c9693e47": {
    "id": "89ef51d5-6260-4fcd-9f65-1f75c9693e47",
    "filename": "dynamic-fairness-aware-recommendation-through-multi-agent-social-choice.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/89ef51d5-6260-4fcd-9f65-1f75c9693e47_dynamic-fairness-aware-recommendation-through-multi-agent-social-choice.pdf",
    "status": "completed",
    "created_at": "2025-12-17 12:58:31.095101",
    "updated_at": "2025-12-17 05:00:02.895197",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Dynamic Fairness-aware Recommendation Through Multi-agent Social Choice",
    "markdown_content": "# Dynamic Fairness-aware Recommendation Through Multi-agent Social Choice\n\nAMANDA AIRD, Department of Information Science, University of Colorado, Boulder, USA\n\nPARESHA FARASTU, Department of Information Science, University of Colorado, Boulder, USA\n\nJOSHUA SUN, Department of Computer Science, University of Colorado, Boulder, USA\n\nELENA ŠTEFANCOVÁ, Comenius University Bratislava, Slovakia\n\nCASSIDY ALL, Department of Information Science, University of Colorado, Boulder, USA\n\nAMY VOIDA, Department of Information Science, University of Colorado, Boulder, USA\n\nNICHOLAS MATTEI, Department of Computer Science, Tulane University, USA\n\nROBIN BURKE, Department of Information Science, University of Colorado, Boulder, USA\n\nAlgorithmic fairness in the context of personalized recommendation presents significantly different challenges to those commonly encountered in classification tasks. Researchers studying classification have generally considered fairness to be a matter of achieving equality of outcomes between a protected and unprotected group, and built algorithmic interventions on this basis. We argue that fairness in real-world application settings is general, and especially in the context of personalized recommendation, is much more complex and multi-faceted, requiring a more general approach. We propose a model to formalize multistakeholder fairness in recommender systems as a two-stage social choice problem. In particular, we express recommendation fairness as a novel combination of an allocation and an aggregation problem, which integrate both fairness concerns and personalized recommendation provisions, and derive new recommendation techniques based on this formulation. We demonstrate the ability of our framework to dynamically incorporate multiple fairness concerns using both real-world and synthetic datasets.\n\nCCS Concepts:  $\\cdot$  Information systems  $\\rightarrow$  Recommender systems;  $\\cdot$  Computing methodologies  $\\rightarrow$  Multi-agent systems;  $\\cdot$  Social and professional topics  $\\rightarrow$  User characteristics.\n\nAdditional Key Words and Phrases: recommender systems, fairness, computational social choice\n\n# ACM Reference Format:\n\nAmanda Aird, Paresha Farastu, Joshua Sun, Elena Štefancová, Cassidy All, Amy Voida, Nicholas Mattei, and Robin Burke. 2023. Dynamic Fairness-aware Recommendation Through Multi-agent Social Choice. 1, 1 (February 2023), 32 pages. https://doi.org/xx.yyyyy/zzzzzz.zwwww\n\nAuthors' addresses: Amanda Aird, amanda.aird@colorado.edu, Department of Information Science, University of Colorado, Boulder, Boulder, Colorado, USA, 80309; Paresha Farastu, paresha.farastu@colorado.edu, Department of Information Science, University of Colorado, Boulder, Boulder, Colorado, USA, 80309; Joshua Sun, joshua.sun@colorado.edu, Department of Computer Science, University of Colorado, Boulder, Boulder, Colorado, USA, 80309; Elena.stefancova, elena.stefancova@fmph.uniba.sk, Comenius University Bratislava, Bratislava, Slovakia; Cassidy All, cassidy.all@colorado.edu, Department of Information Science, University of Colorado, Boulder, Boulder, Colorado, USA, 80309; Amy Voida, amyVoida@colorado.edu, Department of Information Science, University of Colorado, Boulder, Boulder, Colorado, USA, 80309; Nicholas Mattei, nsmattei@tulane.edu, Department of Computer Science, Tulane University, New Orleans, Louisiana, USA, 70118; Robin Burke, robin.burke@colorado.edu, Department of Information Science, University of Colorado, Boulder, Boulder, Colorado, USA, 80309.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\n© 2023 Association for Computing Machinery.\n\nManuscript submitted to ACM\n\n# 1 Introduction\n\nRecommender systems are personalized machine learning systems that support users' access to information in applications as disparate as rental housing, video streaming, job seeking, social media feeds and online dating. The challenges of ensuring fair outcomes in such systems, including the unique issues that come from recommendation ecosystems, have been addressed in a growing body of research literature surveyed in several works including Ekstrand et al. [20] and Patro et al. [44]. Despite these research efforts, some key limitations have remained unaddressed, including the dynamic and multi-stakeholder nature of recommendations systems, and these limitations render leave many solutions inadequate for the full range of applications for which recommender systems are deployed.\n\nThe first limitation we see in current work is that researchers have generally assumed that the problem of group fairness can be reduced to the problem of ensuring equality of outcomes between a protected and unprotected group, or in the case of individual fairness, that there is a single type of fairness to be addressed for all individuals. Fairness is a complex, multifaceted concept that can and does have different definitions, at different times, to different stakeholders, and these issues must be considered in the context in which the systems are deployed [27, 46].\n\nWe believe that this limitation is severe and not representative of realistic recommendation tasks in which fairness is sought. US anti-discrimination law, for example, identifies multiple protected categories relevant to settings such as housing, education and employment including gender, religion, race, age, and others [5]. But even in the absence of such external requirements, it seems likely that any setting in which fairness is a consideration will need to incorporate the viewpoints of multiple groups.\n\nWe also expect that fairness will mean different things for different groups. Consider, for example, a system recommending news articles. Fairness might require that, over time, readers see articles that are geographically representative of their region: rural and urban or uptown vs downtown, for example. But fairness in presenting viewpoints might also require that any given day's set of headlines represent a range of perspectives. These are two different views of what fairness means, entailing different measurements and potentially different types of algorithmic interventions. The diversity of fairness definitions in a single system is rarely addressed: where fairness for multiple groups has been considered (e.g., Kearns et al. [30], Sonboli et al. [50]), it is defined in the same way for all groups.\n\nThe second limitation that we see in current work is that fairness-aware interventions in recommender systems, as well as many other machine learning contexts, have a static quality. In many applications, a system is optimized for some criterion and when the optimization is complete, it produces decisions or recommendations based on that learned state [40]. We believe it is more realistic to think of fairness as a dynamic state, especially when what is of primary concern are fair outcomes. A recommender system's ability to produce outcomes that meet some fairness objective may be greatly influenced by context: what items are in inventory, what types of users arrive, how fair the most recent set of recommendations has been, among many others. A static policy runs the risk of failing to capitalize on opportunities to pursue fairness when they arise and/or trying to impose fairness when its cost is high, by not being sensitive to the context [14].\n\nOur contribution in this paper is the design of an architecture for implementing fairness in recommender systems that addresses both of these limitations. We start from the assumption that multiple fairness concerns should be active at any one time, and that these fairness concerns can be relatively unrestricted in form. Secondly, we build the framework to be dynamic, in that decisions are always made in the context of historical choices and results.\n\nOur research in fairness examines concepts inspired by the application context of Kiva Microloans, a non-profit organization which offers a platform (Kiva.org) for crowd-sourcing the funding of microloans, mostly in the developing world. Kiva's users (lenders) choose among the loan opportunities offered on the platform; microloans from multiple lenders that are aggregated and distributed through third party non-governmental organizations around the world. Kiva Microloans' mission specifically includes considerations of \"global financial inclusion\"; as such, incorporating fairness in its recommendation of loans to potential users (lenders) is a key goal. The authors have been working with Kiva on a multi-faceted project addressing this goal and the work described here is, in part, an outgrowth of that project [12, 47]. We will use Kiva's platform as an example throughout this paper. However, our findings and associated implementations are not specific to this setting.\n\n# 2 Related Work\n\nThere have been a number of efforts that explicitly consider the multisided nature of fairness in recommendation and matching platforms. Patro et al. [43] investigate fairness in two-sided matching platforms where there are both producers and consumers. They note, as we do, that optimizing fairness for only one side of the market can lead to very unfair outcomes for the other side of the market. Patro et al. [43] also appeal to the literature on the fair allocation of indivisible goods from the social choice literature [52]. They devise an algorithm that guarantees max-min share fairness of exposure to the producer side of the market and envy-free up to one item to the consumer side of the market [3]. Their work is closest to the allocation phase of the system detailed in the following sections. However, in contrast to our work, they only use exposure on the producer side and relevance on the consumer side as fairness metrics, whereas our work aims to capture additional definitions. Also, we note that envy-freeness is only applicable when valuations are shared: a condition not guaranteed in a personalized system. It is possible for a user with unique tastes to receive low utility recommendations and still not prefer another user's recommendation lists. Also, our fairness formulation extends beyond the users receiving recommendations to providers of recommended items and envy-freeness provides no way to compare users who are getting different types of benefits from a system. In addition, our fairness definitions are dynamic, a case not considered by Patro et al. [43]. Indeed, in a recent survey paper, Patro et al. [44] provide an overview of some of the current work and challenges in fair recommendation, highlighting the focus of our work, multi-sided, multi-stakeholder, dynamic, and contextual issues, as key challenges.\n\nLike Patro et al. [43], the work of Suhr et al. [51] investigates fairness in two-sided platforms, specifically those like Uber or Lyft where income opportunities are allocated to drivers. However, unlike our work and the work of Patro et al. [43], Suhr et al. [51] take proportionality as their definition of fairness, specifically proportionality with respect to time in a dynamic setting, and ensure that there is a fair distribution of income to the provider side of the platform. Buet-Golfouse and Utyagulov [9] also tackle the problem of multi-sided fair recommendation, arguing that recommender systems are built on sparse data and that the algorithms must take into account fairness. To this end they propose a regularization term that can be incorporated into the recommendation algorithm itself and account for various biases, e.g., exposure and/or selection bias, depending on the particular definition of the regularization term. The work of Buet-Golfouse and Utyagulov [9] is different from ours in that we make use of post-processing, as it allows for more flexibility w.r.t. the fairness definitions and allows us to treat the recommendation phase as a black-box, thus our system can be layered with any traditional recommendation algorithm. A post-processing approach also has the advantage that the set of fairness concerns and their relative importance can be adjusted on the fly without model retraining.\n\nWorking with large item sets and multiple definitions of fairness can be computationally challenging. For example, Zehlike et al. [59] propose a system that allows for multiple protected groups on the provider side and their system works online, i.e., not in an offline, batch mode. But it is designed more for a general ranking task and is very computationally inefficient for recommendation. Every new recommendation list to be reranked requires the generation of a binary tree of size  $|G|^{k}$ , where  $G$  is the number of protected groups and  $k$  is the size of the output list.\n\nFreeman et al. [23] investigate what they call dynamic social choice functions in settings where a fixed set of agents select a single item to share over a series of time steps. The work focuses on overall utility to the agents instead of considering the multiple sides of the recommendation interaction. Their problem is fundamentally a voting problem since all agents share the result, whereas we are focused on personalized recommendation. Their goal is to optimize the Nash Social Welfare of the set of agents (that remains fixed at each time step) and present four algorithms to find approximately optimal solutions. This work has a similar flavor to classical online learning / weighting experts problems [16] in the sense that the agent preferences remain fixed and the goal is to learn to satisfy them over a series of time steps. Similarly, Kaya et al. [29] focus on the problem of group recommendation, which is similar to classical social choice setting of multi-winner voting [63]; i.e., a group of  $k$  items are recommended as a shared resource to a set of users, and fairness is defined w.r.t. to this group of users preferences. Kaya et al. [29] propose methods that are similar to those found in the multi-winner voting literature that attempt to be fair w.r.t. the individual preferences of the group, and these algorithms are meant to aggregate user preferences, not deliver specific recommendations on a per user basis, a key difference with our work.\n\nGe et al. [25] investigate the problem of long term dynamic fairness in recommendation systems. This work, like ours, highlights the need to ensure that fairness is ensured as a temporal concept and not as a static, one off, decision. To this end they propose a framework to ensure fairness of exposure to the producers of items by casting the problem as a constrained Markov Decision Process where the actions are recommendations and the reward function takes into account both utility and exposure. Ge et al. [25] propose a novel actor-critic deep reinforcement learning framework to accomplish this task at the scale of large recommender systems with very large user and item sets. Again, this work fixes definitions of fairness a priori, although their learning methodology may serve as inspiration to our allocation stage problems in the future. The subject of the long term impacts of recommender systems is also considered by Akpinar et al. [1] who investigate the effects of various fairness interventions on the whole system, over time, finding similar effects to those of Ge et al. [25]. This reinforces the decisions in our model which take into account the long term, dynamics effects of any fairness intervention.\n\nReinforcement learning and other online learning methodologies have been proposed for various settings of fair recommendation. Zhang and Wang [60] provide a short position paper proposing using reinforcement learning and an underlying Markov Decision process in order to learn priorities and feedback online during user interaction. While this is similar to a learning to rank system there are some key differences in their proposal, including learning fairness metrics. While Zhang and Wang do not propose a system, we agree that it is an intriguing direction and methodology to incorporate reinforcement learning into fair recommendation frameworks. In the learning to rank space, wherein a recommendation system is attempting to learn the users preference function online, like in RL, Morik et al. [36] propose a new algorithm that is able to take into account notions of amortized group fairness while still learning user preferences. This is a fundamentally different setting than what we consider in that we are not performing learning to rank and we do not want to fix a set of fairness criteria a priroi into our recommendation algorithm, rather we treat the recommendation algorithm itself as an input.\n\nMorik et al. [36] investigate the problem of learning to rank over large item sets while ensuring fairness of merit based guarantees to groups of item producers. Specifically, they adapt existing methods to ensure that the exposure is unbiased, e.g., that it is not subject to rich-get-richer dynamics, and fairness defined as exposure being proportional to merit. Both of these goals are built into the regularization of the learner. In essence the goal is to learn user preferences while ensuring the above two desiderata. In contrast, our work factors out the recommendation methodology and we encapsulate the desired fairness definitions as separate agents rather than embedded in the learning algorithm.\n\nSimilar to the RL settings described above, other recommendation systems contexts include session base and streaming (sequential) recommendation. Wu et al. [56] investigate the setting of session based recommender systems which are short, memory-less recommendation experiences with, e.g., non-logged in users on a website. Like our work, they propose using the recommendation lists delivered over time in order to give the overall system some memory as to how fair it has been in the past, proposing a new time-decaying notion of exposure fairness. They also employ a post-processing concept for the overall recommendation: as they focus on session based recommender systems, there is no notion of long term user engagement. This is an important direction for potential future work, e.g., non-logged-in users are prevalent in many domains. Within the sequential recommender setting, Li et al. [32] propose a system for a (set of) users that incorporates feedback in learning both the preferences of the agent as well as a regularization term in the online learning algorithms to control for a type of interaction fairness per user. They use a deep learning framework work and a knowledge graph over the items to embed the user feedback and interaction and then use this to ensure that fairness of interaction is happening across protected item groups. Their model assumes fairness on a per-user (though dynamic) basis but more importantly that a large knowledge graph of item information is available, where we make no such assumptions and can define fairness both per-user and across use sets.\n\nThe architecture presented here advances and generalizes the approach found in Sonboli et al. [49]. Like that architecture, fairness concerns are represented as agents and interact through social choice. However, in Sonboli et al. [49], the allocation mechanism selects only a single agent at each time step and the choice mechanism has a fixed, additive, form. We allow for a wider variety of allocation and choice mechanisms, and therefore present a more general solution. In addition to extending the work in Sonboli et al. [49] by including the dynamic environment, we have worked with many different groups of stakeholders at Kiva.org in a qualitative research setting, allowing us to formalize a number of fairness concerns that operate at different levels of the recommendation ecosystem [47]. Similarly, Ferraro et al. [22] propose a novel set of re-rankers for a music recommendation platform after a set of interview studies with users and producers of music on the system. After these studies, they find that gender fairness is a key issue for many artists, with real world data they propose a re-ranking methodology that attempts to address this imbalance. The overall methods in this paper mirrors ours in that a close examination of a real world system, and interviews with stakeholders, give rise to a particular notion and measurement of fairness [47]. However, rather than a case study, we propose a more robust framework that treats the multi-stakeholder and contextual definitions of fairness as first order concerns.\n\nFinally, our recommendation allocation problem has some similarities with those found in computational advertising, where specific messages are matched with users in a personalized way [54, 57]. Because advertising is a paid service, these problems are typically addressed through mechanisms of monetary exchange, such as auctions. There is no counterpart to budgets or bids in our context, which means that solutions in this space do not readily translate to supporting fair recommendation [19, 58, 61].\n\n# 3 Example\n\nIn this section, we work through a detailed example demonstrating the function of the architecture through several iterations of user arrivals. The examples of fairness concerns articulated in our case study of Kiva.org arise from extensive interviews conducted with stakeholders at Kiva.org as a part of the larger scope of this project [47]. Indeed, in our research we found that there were many competing definitions of fairness, e.g., proportional parity or minimal levels of exposure, that act on different sides of the market, i.e., the producers, consumers, or both. In what follows we give a detailed overview of building up the system from these concerns. The reader only interested in the formal definition of the overall system will find this in Section 5.2.\n\nIn short, we view the entire recommendation ecosystem as a multi-agent system. Informally, each fairness concern can be represented by an agent, i.e., a collection of methods that is able to look at a (set of) recommendations and judge, for themselves, if these (potential) recommendations are fair according to the definition of that agent. Likewise, users of the system can be viewed as a disjoint set of agents that only care if the provided recommendations conform to their interests, as judged by the user/item recommendation algorithm, i.e., the user preference. Given this view, we envision a system where, as a user agent arrives, one or more fairness agents are allocated to that user according to a user agent/fairness agent compatibility function. The agent is able to articulate a list that would be more fair, i.e., provide a reranking methodology, and then in the aggregation stage we combine the lists from the fairness agent with the list generated by the user agent preferences alone.\n\nGiven this setup, we have a multi-agent system where we are solving both a classical social choice allocation problem, i.e., allocating fairness agents to arriving users, and an aggregation (voting) problem, where we combine (possibly competing) lists of recommended items. In the following sections we articulate, in case study form, how one may approach the problem of formalizing multiple fairness concerns as agents within our proposed system.\n\n# 3.1 Agents\n\nConsider the following set of fairness agents and their associated evaluations and preferences. We assume in this example that in all cases the agents' compatibility functions follow the pattern described in Sonboli et al. [50] where the entropy of the user profile relative to the sensitive feature is calculated and users with high entropy are determined to be good targets for fairness-enhancing interventions. Note that in these examples, the definition of a fair outcome is differnet for each agent, demonstrating the range of fairness definitions that can be incorporated in our system:\n\n$f_{H}$ : Health This agent is concerned with promoting loans to the health sector. Its evaluation function compares the proportion of loans in the database in the health sector against the proportion of health recommendations in the recommendation list history. Its preference function is binary: if the loan is in the health sector, the score is 1; otherwise, zero.  \n$f_{A}$ : Africa This agent is concerned with promoting loans to Africa. Its evaluation function, however, is list-wise. It counts lists in the recommendation if they have a least one loan recommendation to a country in Africa, and consider a fair outcome one in which every list has at least one such loan. Its preference function will be similarly binary as the  $f_{H}$  agent.  \n$f_{G}$ : Gender Parity This agent is concerned with promoting gender parity within the recommendation history. If, across the previously generated recommendation lists, the number of men and women presented is proportional to their prevalence in the database, its evaluation will return 1. However, it is preference function is more complex\n\nthan those above. If the women are underrepresented in the history, it will prefer loans to female borrowers, and conversely for men.[2]\n\n$f_{L}$ : Large This agent is concerned with promoting loans with larger total amounts: over $5,000. Internal Kiva research has shown that such loans are often very productive because they go to cooperatives and have a larger local impact. However, the same research has shown that Kiva users are less likely to support them because each contribution has a smaller relative impact. $^{3}$  This agent is similar to the  $f_{A}$  agent above in that it seeks to make sure each list has one larger loan.\n\n# 3.2 Loans\n\nConsider the contents of Table 1. For the sake of example, we will assume these loans, characterized by the Region, Gender, Section and Amount, constitute the set of loans available for recommendation.\n\n<table><tr><td></td><td>\\( {\\phi }_{1}^{s} \\) : Region</td><td>\\( {\\phi }_{2}^{s} \\) : Gender</td><td>\\( {\\phi }_{3}^{s} \\) : Sector</td><td>\\( {\\phi }_{4} \\) : Amount</td></tr><tr><td>\\( {v}_{1} \\)</td><td>Africa</td><td>Male</td><td>Agriculture</td><td>$5,000-$10,000</td></tr><tr><td>\\( {v}_{2} \\)</td><td>Africa</td><td>Female</td><td>Health</td><td>$500-$1,000</td></tr><tr><td>\\( {v}_{3} \\)</td><td>Middle-East</td><td>Female</td><td>Clothing</td><td>$0-$500</td></tr><tr><td>\\( {v}_{4} \\)</td><td>Central America</td><td>Female</td><td>Clothing</td><td>$5,000-$10,000</td></tr><tr><td>\\( {v}_{5} \\)</td><td>Central America</td><td>Female</td><td>Health</td><td>$0-$500</td></tr><tr><td>\\( {v}_{6} \\)</td><td>Middle-East</td><td>Female</td><td>Clothing</td><td>$0-$500</td></tr></table>\n\nTable 1. Set of Potential Loans.\n\n# 3.3 Mechanisms\n\nFor the sake of exposition, we posit two very simple mechanisms for allocation and choice. We will assume that our allocation mechanism is a single outcome lottery, e.g., a randomized allocation mechanism [8]. One agent will be chosen to participate in the choice mechanism, based on a random draw with probabilities based on the historic unfairness and user compatibility as measured by each agent.\n\nWe assume that the recommendation lists are of size 3 and the choice mechanism uses a weighted voting / score-based mechanism [7] using a weighted sum of 0.75 on the personalized results for the recommender system and 0.25 on the output of the allocated fairness agent.\n\n# 3.4 Users\n\nAt time  $t_1$ , User  $u_1$  arrives at the system and the recommendation process is triggered. The user has previously supported small loans only in Central America and Middle East, but has lent to a wide variety of sectors and genders.\n\nFor the sake of example, we will assume that the agents measure their prior history relative to their objectives as equally unfair at 0.5, except the Gender Parity agent, which starts out at parity and therefore returns a value of 1. However, the compatibility functions for  $f_{A}$  and  $f_{L}$  return lower scores because of the user's historical pattern of lending. This yields a lottery in which  $f_{G}$  has probability zero,  $f_{A}$  has a low probability, and  $f_{H}$  a higher one. The allocation mechanism chooses randomly, and we will assume that  $f_{H}$ , the health-focused agent, is picked.\n\nThe recommender returns the following list of items and predicted ratings  $\\left[\\{v_{6},0.6\\} ,\\{v_{4},0.5\\} ,\\{v_{5},0.3\\} ,\\{v_{3},0.3\\} ,\\right.$ $\\{v_{1},0.0\\} ,\\{v_{2},0.0\\} ]$  . The  $f_{H}$  agent gives a score of 1 to the health-related loans  $v_{2}$  and  $v_{5}$  and 0 to all others.\n\nThe choice mechanism combines these scores as described above and returns the final recommendation list  $\\left[\\{v_{5},0.475\\} ,\\{v_{6},0.45\\} ,\\{v_{4},0.375\\}\\right]$ . Note that the Health agent has successfully promoted its preferred item to the first position in the list.\n\nFor the sake of example, we assume that the agents' evaluation functions are very sensitive. Therefore, when User  $u_{2}$  arrives, the results of the previous recommendations have caused the evaluations to shift such that the Health  $f_{H}$  and Large  $f_{L}$  agents are now satisfied (note that  $v_{4}$  is included in  $u_{1}$ 's list and it was a large loan), the Gender parity agent  $f_{G}$  is now at 0.9 (note that there is only one male loan in the database) but the Africa agent  $f_{A}$ , which got nothing in  $u_{1}$ 's list, considers recent results to be unfair with a score of 0.25. We assume that  $u_{2}$  is similar to  $u_{1}$  in profile and therefore compatibility, but  $f_{A}$  has a much worse fairness score than  $f_{G}$ , and therefore a high allocation probability. We will assume  $f_{A}$  is chosen.\n\nBecause this user has similar preferences to  $u_{1}$ , they get the same recommendations:  $\\left[\\{v_{6}, 0.6\\}, \\{v_{4}, 0.5\\}, \\{v_{5}, 0.3\\}, \\{v_{3}, 0.3\\}\\right]$ ,  $\\{v_{1}, 0.0\\}, \\{v_{2}, 0.0\\}$ . The  $f_{A}$  agents scores the two loans from Africa ( $v_{1}$  and  $v_{2}$ ) at 1 and the others at 0.\n\nSo, after randomly breaking the tie between  $v_{1}$  and  $v_{2}$ , the final recommendation list is  $[\\{v_6, 0.45\\}, \\{v_4, 0.375\\}, \\{v_1, 0.25\\}]$ .\n\nWhen User  $u_{3}$  arrives, all four agents find themselves scoring fairness at 1 over the evaluation window and so no agents are allocated. The results from the recommendation algorithm pass through the choice mechanism unchanged and are delivered to the user.\n\nIn this example, we see the interplay between users' compatibility with agents and the computed fairness outcomes to allocate opportunities to pursue fairness among different agents over time.\n\n# 4 Formalizing Fairness Concerns\n\nA central tenet of our work is that fairness is a contested concept [38]. From an application point of view, this means that ideas about fairness will be grounded in specific contexts and specific stakeholders, and that these ideas will be multiple and possibly in tension with each other. From a technical point of view, this means that any fairness-aware recommender system should be capable of integrating multiple fairness concepts, arising as they may from this contested terrain.\n\nA central concept in this work is the idea of a fairness concern. We define a fairness concern as a specific type of fairness being sought, relative to a particular aspect of recommendation outcomes, evaluated in a particular way. As shown in the example above, a possible fairness concern in the microlending context might be group fairness relative to different geographical regions considered in light of the exposure of loans from these regions in recommendation lists. The concern identifies a particular aspect of the recommendation outcomes (in this case, their geographical distribution), the particular fairness logic and approach (more about this below), and the metric by which fair or unfair outcomes are determined.\n\nThe first consideration in building a fairness-aware recommender system is the question of what fairness concerns surround the use of the recommender system, itself. Many such concerns may arise and like any system-building enterprise, there are inevitably trade-offs involved in the formulation of fairness concerns. An organization may decide to incorporate only the highest-priority concerns into its systems. An initial step in fairness-aware recommendation is for an organization to consult its institutional mission and its internal and external stakeholders with the goal of eliciting and prioritizing fairness concerns. We report on our initial phases of stakeholder consultation with Kiva.org in Smith et al. [47]. Although not in the recommendation domain, another relevant project is the WeBuildAI project [31] and its participatory design framework for AI.\n\nIn addition to addressing different aspects of system outcomes, different fairness concerns may invoke different logics of fairness. Welfare economists have identified a number of such logics and we follow Moulin [37] who identifies four:\n\nExogenous Right: A fairness concern is motivated by exogenous right if it follows from some external constraint on the system. For example, the need to comply with fair lending regulations may mean that male and female borrowers should be presented proportionately to their numbers in the overall loan inventory.\n\nCompensation: A fairness concern that is a form of compensation arises in response to observed harm or extra costs incurred by one group versus others. For example, as noted above, loans with longer repayment periods are often not favored by Kiva users because their money is tied up for longer periods. To compensate for this tendency, these loans may need to be recommended more often.\n\n**Reward:** The logic of reward is operational when we consider that resources may be allocated as a reward for performance. For example, if we know that loans to large cooperative groups are highly effective in economic development, we may want to promote such loans as recommendations so that they are more likely to be funded and realize their promise.\n\nFitness: Fairness as fitness is based on the notion of efficiency. A resource should go to those best able to use it. In a recommendation context, it may mean matching items closely with user preferences. For example, when loans have different degrees of repayment risk, it may make sense to match the loan to the risk tolerance of the lender.\n\nIt is clear that fairness logics do not always pull in the same direction. The invocation of different logics are often at the root of political disagreements: for example, controversies over the criteria for college admissions sometimes pit ideas of reward for achievement against ideas of compensation for disadvantage.\n\nRecommender systems often operate as two-sided platforms, where one set of individuals are receiving recommendations and possibly acting on those recommendations (consumers), and another set of individuals is creating or providing items that may be recommended (providers) [10]. Consumers and providers are considered, along with the platform operator, to be the direct stakeholders in any discussion of recommender system objectives. Fairness concerns may derive from any stakeholder, and may need to be balanced against each other. The platform may be interested in enforcing fairness, even when other stakeholders are not. For example, the average recommendation consumer might only be interested in the best results for themselves, regardless of the impact on others. Fairness concerns can arise on behalf of other, indirect, stakeholders who are impacted by recommendations but not a party to them. An important example is representational fairness where concerns arise about the way the outputs of a recommender system operate to represent the world and classes of individuals within it: for example, the way the selection of news articles might end up representing groups of people unfairly [39] (see [20] for additional discussion). As a practical matter, representational fairness concerns can be handled in the same way as provider-side fairness for our purposes here.\n\nFinally, we have the consideration of group versus individual fairness. This dichotomy is well understood as a key difference across types of fairness concerns, defining both the target of measurement of fairness and the underlying principle being upheld. Group fairness requires that we seek fairness across the outcomes relative to predefined protected groups. Individual fairness asks whether each individual user has an appropriate outcome and assumes that users with similar profiles should be treated the same. Just as there are tensions between consumer and provider sides in fairness, there are fundamental incompatibilities between group and individual fairness. Treating all of the outcomes for a group in aggregate is inherently different than maintaining fair treatment across individuals considered separately. Friedler et al. offer a thorough discussion of this topic [24].\n\n<table><tr><td>Label</td><td>Fairness type</td><td>Logic</td><td>Side</td><td>Who is Impacted</td><td>Evaluation</td></tr><tr><td>LowCountry</td><td>Group</td><td>Comp.</td><td>Provider</td><td>Borrowers from countries with lower funding rates</td><td>Exposure of loans in recommendation lists</td></tr><tr><td>LargeAmt</td><td>Group</td><td>Reward</td><td>Provider</td><td>Borrowers in consortia seeking larger loans</td><td>Exposure of loans in recommendation lists</td></tr><tr><td>Repay</td><td>Individual</td><td>Reward</td><td>Provider</td><td>All borrowers</td><td>Loan exposure proportional to repayment probability</td></tr><tr><td>LowSector</td><td>Group</td><td>Exo. right</td><td>Provider</td><td>Borrowers in sectors with lower funding rates</td><td>Exposure of loans in recommendation lists</td></tr><tr><td>AllCountry</td><td>Individual</td><td>Exo. right</td><td>Provider</td><td>All borrowers</td><td>Catalog coverage by country</td></tr><tr><td>AccuracyLoss</td><td>Group</td><td>Exo. right</td><td>Consumer</td><td>All lenders</td><td>Accuracy loss due to fairness objective is fairly distributed across protected groups of users.</td></tr><tr><td>RiskTolerance</td><td>Individual</td><td>Fitness</td><td>Consumer</td><td>All lenders</td><td>Riskier loans are recommended to users with greater risk tolerance</td></tr></table>\n\nTable 2. Potential fairness concerns and their logics.\n\nPutting all of these dimensions together gives us a three-dimensional ontology of fairness concerns in recommendation: fairness logic, consumer- vs provider-side, and group vs individual target. Table 2 illustrates a range of different fairness concerns that derived from the microlending context and all of which have at least some support from the interview study by Smith et al. [47]. This list illustrates a number of the points relative to fairness concerns raised so far. We can see that all four of Moulin's fairness logics are represented. We also see that the fairness concerns can be group or individual: for example, we are attentive to individual qualities in the RiskTolerance concern, but group outcomes in LargeAmt. The AccuracyLoss concern is a consumer-side concern, relevant to lenders, but other concerns are on the provider side. We also see that it is possible for a single objective, here the geographic diversity of loan recommendation, to be represented by multiple fairness concerns: LowCountry and AllCountry. In spite of having the same target, these concerns are distinguished because they approach the objective from different logics and evaluate outcomes differently.\n\n# 4.1 Fairness Agents\n\nOur architecture SCRUF-D (Social Choice for Recommendation Under Fairness - Dynamic) [11] builds on the SCRUF architecture introduced in [14, 49]. It is designed to allow multiple fairness concerns to operate simultaneously in a recommendation context. Fairness concerns, derived from stakeholder consultation, are instantiated in the form of fairness agents, each having three capabilities:\n\nEvaluation: A fairness agent can evaluate whether the current historical state is fair, relative to its particular concern. Without loss of generality, we assume that this capability is represented by a function  $m_{i}$  for each agent  $i$  that takes as input a history of the system's actions and returns an number in the range [0, 1] where 1 is maximally fair and 0 is totally unfair, relative to the particular concern.\n\nCompatibility: A fairness agent can evaluate whether a given recommendation context represents a good opportunity for its associated items to be promoted. We assume that each agent  $i$  is equipped with a function  $c_{i}$  that can evaluate a user profile  $\\omega$  and associated information and return a value in the range [0, 1] where 1 indicates the most compatible user and context and 0, the least.\n\n**Preference:** An agent can compute a preference for a given item whose presence on a recommendation list would contribute (or not) to its particular fairness concern. Again, without loss of generality, we assume this preference can be realized by a function that accepts an item as input and returns a preference score in  $\\mathbb{R}_+$  where a larger value indicates that an item is more preferred.<sup>5</sup>\n\n# 4.2 Recommendation Process\n\nWe assume a recommendation generation process that happens over a number of time steps  $t$  as individual users arrive and recommendations are generated on demand. Users arrive at the system one at a time, receive recommendations, act on them (or not), and then depart. When a user arrives, a recommendation process produces a recommendation list  $\\ell_{s}$  that represents the system's best representation of the items of interest to that user, generated through whatever recommendation mechanism is available. We do not make any assumptions about this process, except that it is focused on the user and represents their preferences. A wide variety of recommendation techniques are well studied in the literature, including matrix factorization, neural embeddings, graph-based techniques, and others.\n\nThe first step to incorporating fairness into the recommendation process is to determine which fairness concerns / agents will be active in responding to a given recommendation opportunity. This is the allocation phase of the process, the output of which is a set of non-negative weights  $\\beta$ , summing to one, over the set of fairness agents, indicating to what extent each fairness agent is considered to be allocated to the current opportunity.\n\nOnce the set of fairness agents have been allocated, they have the opportunity to participate in the next phase of the process, which is the choice phase. In this phase, all of the active (non-zero weighted) agents and their weights participate in producing a final list of recommendations for the user. We view the recommender system itself as being an agent that is always allocated and therefore always participates in this phase.\n\n# 5 The SCRUF-D Architecture\n\nThe two phases of the SCRUF-D architecture are detailed in Figures 1 and 2. The original SCRUF framework [49] concentrated on the representation of user preferences, as computed by the recommender system, and fairness concerns, as derived from stakeholder consultation as discussed in Section 4.1, and their integration. SCRUF-D incorporates the history of system decisions and the fairness achieved over time to control the allocation of fairness concerns. We will first provide a high level overview of the system and describe each aspect in detail with formal notation: Table 3 provides a reference to this notation.\n\n# 5.1 Overview\n\nWe can think of a recommender system as a two-sided market in which the recommendation opportunities that arise from the arrival of a user  $u \\in \\mathcal{U}$  to the system, and each are allocated to a set of items  $v \\in \\mathcal{V}$  from the system's catalog. This market has some similarities to various forms of online matching markets including food banks [2], kidney allocation [4, 34], and ride sharing [18], in that users have preferences over the items; however, in our case this preference is known only indirectly through either the prior interaction history or a recommendation function.\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/9d73a2a2ee2993b66d2cc0e2d1a59d154be416ef91f7e9c0d34f7cb37269076c.jpg)  \nFig. 1. SCRUF-D Framework / Allocation Phase: Recommendation opportunities are allocated to fairness concerns based on the context.\n\nAdditionally, the items are not consumable or rivalous. For example, a loan can be recommended to any number of users - it is not \"used up\" in the recommendation interaction.<sup>6</sup> Also, users are not bound to the recommendations provided; in most online platforms including Kiva, there are multiple ways to find items, of which the recommender system is only one.\n\nOnce we have a collection of fairness agents we must solve two interrelated problems:\n\n(1) What agent(s) are allocated to a particular recommendation opportunity?  \n(2) How do we balance between the allocated agents and the user's individual preferences?\n\nFigure 1 shows the first phase of this process, allocation [7], in which the system decides which fairness concerns / agents should be allocated to a particular fairness opportunity. This is an online and dynamic allocation problem where we may consider many factors including the history of agent allocations so far, the generated lists from past interactions with users, and how fair the set of agents believes this history to be. As described in Section 4.1, agents take these histories and information about the current user profile and calculate two values:  $m$ , a measure of fairness relative to their agent-specific concern, and  $c$ , a measure of compatibility between the current context and the agent's fairness concern. The allocation mechanism takes these metrics into account producing a probability distribution over the fairness agents that we call the agent allocation, which can be interpreted as weights in the choice stage or be used to select a single agent via a lottery, e.g., a randomized allocation scheme [8].\n\nIn the second phase, shown in Figure 2, the recommender system generates a list of options, considered to represent the user's preferences. The fairness concerns generate their own preferences as well. These preferences may be global in character, i.e., preferences over all items, in which case they may be independent of what the recommender system produces; we call this a recommendation function below. Or, as indicated by the dashed line, these preferences may be scoped only over the items that the recommender system has generated; named a scoring function. In either case, the preference function of the fairness agent, like the one for the user, generates a list of items and scores. The choice mechanism combines these preferences of both the user and fairness agents, along with the allocation weights of the fairness agents, to arrive at a final recommendation list to be delivered to the user. The list itself, and possibly the\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/e71c3e552dac4980d79522265c0c0b3135a88652a4e8d5e94babbc5e7f459af9.jpg)  \nFig. 2. SCRUF-D Framework / Choice Phase: The preferences derived from the recommender system and the fairness concerns are integrated by the choice mechanism.\n\ninteractions the user has with it, becomes a new addition to the choice history and the process continues for the next user.\n\n# 5.2 Formal Description\n\nIn our formalization of a recommendation system setting we have a set of users  $\\mathcal{U} = \\{u_1, \\ldots, u_n\\}$  and a set of items  $\\mathcal{V} = \\{v_1, \\ldots, v_m\\}$ . For each item  $v_i \\in \\mathcal{V}$  we have a  $k$ -dimensional feature vector  $\\phi = \\langle \\phi_1, \\dots, \\phi_k \\rangle$  over a set of categorical features  $\\phi$ , each with finite domain. Some of these features may be sensitive, e.g., they are associated with one or more fairness agent concerns, we denote this set as  $\\phi^s$ . Without loss of generality, we assume that all elements in  $\\mathcal{V}$  share the same set of features  $\\phi$ . Finally, we assume that each user is associated with a profile of attributes  $\\omega = \\langle \\omega_1, \\dots, \\omega_j \\rangle$ , of which some also may be sensitive  $\\omega^s \\subseteq \\omega$ , e.g., they are associated with one or more fairness agents.\n\nAs in a standard recommendation system we assume that we have (one or more) recommendation mechanisms that take a user profile  $\\omega$  and a (set of) items  $v$  and produces a predicted rating  $\\hat{r} \\in \\mathbb{R}_+$ . We will often refer to a recommendation list,  $\\ell = \\langle \\{v_1, \\hat{r}_1\\}, \\ldots, \\{v_i, \\hat{r}_i\\} \\rangle$ , which is generated for user  $\\omega$  by sorting according to  $\\hat{r}$ , i.e.,  $\\text{sort}(\\mathcal{R}_i(\\omega, \\mathcal{V})) \\to \\ell$ . Note that this produces a permutation (ranking) over the set of items for that user, i.e. a recommendation. As a practical matter, the recommendation results will almost always contain a subset of the total set of items, typically the head (prefix) of the permutation up to some cutoff number of items or score value. For ease of exposition we assume we are able to score all items in the database.\n\nIn the SCRUF-D architecture, fairness concerns map directly onto agents  $\\mathcal{F} = \\{f_1,\\dots ,f_i\\}$ . In order for the agents to be able to evaluate their particular concerns, they take account of the current state of the system and voice their evaluation of how fairly the overall system is currently operating, their compatibility for the current recommendation opportunity, and their preference for how to make the outcomes more fair. Hence, each fairness agent  $i$  is described as a tuple,  $f_{i} = \\{m_{i},c_{i},\\mathcal{R}_{i}\\}$  consisting of a fairness metric,  $m_{i}(\\vec{L},\\vec{H})\\rightarrow [0,1]$ , that takes a choice history  $\\vec{L}$  and allocation history  $\\vec{H}$  and produces a value in  $[0,1]$  according to the agent's evaluation of how fair recommendations so far have\n\n<table><tr><td rowspan=\"9\">Rec. System</td><td>U(u)</td><td>Users (user).</td></tr><tr><td>V(v)</td><td>Items (item).</td></tr><tr><td>φ = ⟨φ1, . . . φk⟩</td><td>Item Features.</td></tr><tr><td>ω = ⟨ω1, . . . ωj⟩</td><td>User Profile.</td></tr><tr><td>φs ⊆ φ</td><td>Sensitive Item Features as a subset of all item features φ.</td></tr><tr><td>ωs ⊆ ω</td><td>Sensitive Aspects of User Profile as a subset of all user profile features ω.</td></tr><tr><td>Ri(ω, v) → {v, r}</td><td>Recommendation mechanism that takes a user profile ω and a (set of) items v and produces a predicted rating r ∈ R+.</td></tr><tr><td>l = ⟨{v1, r1}, . . . {vi, r1}⟩</td><td>Recommendation List as an ordered list of item, predicted rating pairs.</td></tr><tr><td>sort(Ri(ω, V)) → l</td><td>Recommendation List for user ω sorted by r.</td></tr><tr><td rowspan=\"7\">Fairness Agents</td><td>F = {f1, . . ., fi}</td><td>Set of Fairness Agents.</td></tr><tr><td>fi = {mi, ci, Ri}</td><td>Fairness agent i defined by a fairness metric mi, a compatibility metric ci, and a ranking function Ri.</td></tr><tr><td>mi(L, H) → [0, 1]</td><td>Fairness metric for agent i that takes a choice history L and allocation history H and produces a value in [0, 1] according to the agent&#x27;s evaluation of how fair recommendations so far have been.</td></tr><tr><td>ci(ω) → [0, 1]</td><td>Compatibility metric for agent i that takes a particular user profile ω and produces a value in [0, 1] for how compatible fairness agent i believes they are for user ω. Note: The compatibility metric combines preferences on the agent side and those on the user side (inferred from the profile). If these preferences are symmetrical, we have a one-sided matching problem, but two-sided cases are also possible.</td></tr><tr><td>Ri(ω, v) → {v, r}</td><td>Fairness Agent Recommendation function.</td></tr><tr><td>Ri(ℓ, ω, v) → {v, r}</td><td>Fairness Agent Scoring function.</td></tr><tr><td>ℓF = {R1(ω, V), . . ., Ri(ω, V)}</td><td>Set of Fairness Agent Recommendation Lists indexed by fairness agent label i.</td></tr><tr><td rowspan=\"2\">Allocation</td><td>A(F, mF(L, H), cF(ω)) → β ∈ R+|F|</td><td>Allocation mechanism A that takes a set of fairness agents F, the agents&#x27; fairness metric evaluations mF(L, H), and the agents&#x27; compatibility metric evaluations cF(ω) and maps to an agent allocation β.</td></tr><tr><td>H = {β1, . . ., βt}</td><td>Allocation History H that is an ordered list of agent allocations A at time t.</td></tr><tr><td rowspan=\"2\">Choice</td><td>C(ℓ, β, ℓF) → ℓC</td><td>Choice Function is a function from a recommendation list ℓ, agent allocation β, and fairness agent recommendation list(s) ℓF to a combined output list ℓC.</td></tr><tr><td>L = {ℓt, ℓF, ℓC}</td><td>Choice History that is an ordered list of user recommendation list ℓ, agent recommendation list(s) ℓF, and choice function output lists ℓC, indexed by time step t.</td></tr></table>\n\nTable 3. Notations for our formal description of the SCRUF-D architecture.\n\nbeen; a compatibility metric,  $c_{i}(\\omega) \\to [0,1]$ , that takes a particular user profile  $\\omega$  and produces a value in  $[0,1]$  for how compatible fairness agent  $i$  believes they are for user  $\\omega$ ; and a ranking function,  $\\mathcal{R}_i(\\omega, v) \\to \\{v, \\hat{r}\\}$ , that gives the fairness agent preferences.\n\nIn the allocation phase (Figure 1), we must allocate a set of fairness agents to a recommendation opportunity. Formally, this is an allocation function,  $\\mathcal{A}(\\mathcal{F},m_{\\mathcal{F}}(\\vec{L},\\vec{H}),c_{\\mathcal{F}}(\\omega))\\to \\beta \\in \\mathbb{R}_{+}^{|\\mathcal{F}|}$  that takes a set of fairness agents  $\\mathcal{F}$ , the agents'\n\nManuscript submitted to ACM\n\nfairness metric evaluations  $m_{\\mathcal{F}}(\\vec{L}, \\vec{H})$ , and the agents' compatibility metric evaluations  $c_{\\mathcal{F}}(\\omega)$  and maps to an agent allocation  $\\beta$ , where  $\\beta$  is a probability distribution over the agents  $\\mathcal{F}$ . The allocation function itself is allocating fairness agents to recommendation opportunities by considering both the fairness metric for each agent as well as each fairness agent's estimation of their compatibility.\n\nThe allocation function can take many forms, e.g., it could be a simple function of which every agent voices the most unfairness in the recent history [49], or it could be a more complex function from social choice theory such as the probabilistic serial mechanism [6] or other fair division or allocation mechanisms. Note here that the allocation mechanisms is directly comparing the agent valuations of both the current system fairness and compatibility. Hence, we are implicitly assuming that the agent fairness evaluations are comparable. While this is a somewhat strong assumption, it is less strong than assuming that fairness and other metrics, e.g., utility or revenue, are comparable as is common in the literature [62]. So, although we are assuming different normalized fairness values are comparable, we are only assuming that fairness is comparable with fairness, and not other aspects of the system. We explore options for the allocation function in our empirical experiments below. We track the outputs of this function as the allocation history,  $\\vec{H} = \\langle \\beta^1,\\dots ,\\beta^t\\rangle$ , an ordered list of agent allocations  $\\beta$  at time  $t$ .\n\nIn the second phase of the system (Figure 2), we take the set of allocated agents and combine their preferences (and weights) with those of the current user  $\\omega$ . To do this we define a choice function,  $C(\\ell, \\beta, \\ell_{\\mathcal{F}}) \\to \\ell_{\\mathcal{C}}$ , as a function from a recommendation list  $\\ell$ , agent allocation  $\\beta$ , and fairness agent recommendation list(s)  $\\ell_{\\mathcal{F}}$  to a combined list  $\\ell_{\\mathcal{C}}$ . Each of the fairness agents is able to express their preferences over the set of items for a particular user,  $\\mathcal{R}_i(\\omega, v) \\to \\{v, \\hat{r}\\}$ , and we take this set of lists,  $\\ell_{\\mathcal{F}} = \\{\\mathcal{R}_1(\\omega, \\mathcal{V}), \\dots, \\mathcal{R}_i(\\omega, \\mathcal{V})\\}$ , as input to the choice function that generates a final recommendation that is shown to the user,  $\\ell_{\\mathcal{C}}$ .\n\nWe again leave this choice function unspecified as this formulation provides a large design space: we could use a simple voting rule, a simple additive utility function or something much more complicated like rankings over the set of all rankings [7]. Note that the choice function can use the agent allocation  $\\beta$  as either a lottery to, e.g., select one agent to voice their fairness concerns, or as a weighting scheme. We investigate a range of choice functions in our experiments. In order for the fairness agents to be able to evaluate the status of the system we also track the choice history,  $\\vec{L} = \\langle \\ell^t,\\ell_{\\mathcal{F}}^t\\ell_{\\mathcal{C}}^t\\rangle$ , as an ordered list of user recommendation list  $\\ell$ , agent recommendation list(s)  $\\ell_{\\mathcal{F}}$ , and choice function output lists  $\\ell_{\\mathcal{C}}$ , indexed by time step  $t$ .\n\n# 6 Design Considerations\n\nWithin this framework there are a number of important design considerations to take into account for any particular instantiation of the SCRUF-D architecture. We have left many of the particular design choices open for future investigation. We allow for any type of recommendation algorithm; fairness agents may incorporate any type of compatibility function or fairness evaluation function. Similarly, we do not constrain the allocation or choice mechanisms. With SCRUF-D, we are able to explore many definitions of fairness and recommendation together in a principled and uniform way. In this section, we discuss a few of the design parameters that may be explored in future work.\n\n# 6.1 Agent Design\n\nWe can expect that an agent associated with a fairness concern will typically have preferences that order items relative to a particular feature or features associated with that concern. Items more closely related to the sphere of concern will be ranked more highly and those unrelated, lower. However, this property means that agents associated with different\n\nconcerns might have quite different rankings – the gender parity concern will rank women's loans highly regardless of their geography, for example. Thus, we cannot assume consistency or single-peakedness across the different agents.\n\nAs noted above, agents may have preferences over disjoint sets of items or they may be constrained only to have preferences over the items produced by the recommender system for the given user. This second option corresponds to a commonly-used re-ranking approach, where the personalization aspect of the system controls what items can be considered for recommendation and fairness considerations re-order the list [20]. If an agent can introduce any item into its preferences, then we may have the challenge in the choice phase of integrating items that are ranked by some agents but not others. Some practical work-arounds might include a constraint on the recommender system to always return a minimum number of items of interest to the allocated agents or a default score to assign to items not otherwise ranked.\n\nDespite our fairness-oriented motivation, it should be clear that our architecture is sufficiently general that an agent could be designed that pushes the system to act in harmful and unfair ways rather than beneficial and fairness-enhancing ones. The system has no inherent representation of fairness and would not be able to detect such usage. Thus, the importance of the initial step of stakeholder consultation and the careful crafting of fairness concerns. Because fairness concerns are developed within a single organization and with beneficence in mind, we assume that we do not need to protect against adversarial behavior, such as collusion among agents or strategic manipulation of preferences. The fact that the agents are all \"on the same team\" allows us to avoid constraints and complexities that otherwise arise in multi-agent decision contexts.\n\n# 6.2 Agent Efficacy\n\nThe ability of an agent to address its associated fairness concern in non-deterministic. It is possible that the agent may be allocated to a particular user interaction, but its associated fairness metric may still fail to improve. One likely reason for this is the primacy of the personalization objective. Generally, we expect that the user's interests will have the greatest weight in the final recommendations delivered. Otherwise, the system might have unacceptably low accuracy, and fail in its primary information access objective.\n\nOne design decision therefore is whether (and how) to track agent efficacy as part of the system history. If the agent's efficacy is generally low, then opportunities to which it is suited become particularly valuable; they are the rare situations in which this fairness goal can be addressed. Another aspect of efficacy is that relationships among item characteristics may mean that a given agent, while targeted to a specific fairness concern, might have the effect of enhancing multiple dimensions of fairness at once. Consider a situation in which geographic concerns and sectoral concerns intersect. Promoting an under-served region might also promote an under-served economic sector. Thus, the empirically-observed multidimensional impact of a fairness concern will need to be tracked to understand its efficacy.\n\nEfficacy may also be a function of internal parameters of the agent itself. A separate learning mechanism could then be deployed to optimize these parameters on the basis of allocation, choice and user interaction outcomes.\n\n# 6.3 Mechanism Inputs\n\nDifferent SCRUF implementations may differ in what aspects of the context are known to the allocation and/or choice mechanisms. Our hope is that we can leverage social choice functions in order to limit the complexity of the information that must be passed to the allocation and/or choice mechanisms. However, if a sophisticated and dynamic representation of agent efficacy is required, it may be necessary to implement a bandit-type mechanism to explore the space of allocation\n\nprobabilities and/or agent parameters as discussed above. Recent research on multidimensional bandit learning suggests possible approaches here [35].\n\n# 6.4 Agent Priority\n\nAs we have shown, agent priority in the allocation phase may be a function of user interests, considering different users as different opportunities to pursue fairness goals. It may also be a function of the history of prior allocations, or the state of the fairness concerns relative to some fairness metric we are trying to optimize. As the efficacy consideration would indicate, merely tracking allocation frequency is probably insufficient and it is necessary to tie agent priority to the state of fairness. Allocation priority is also tied to efficacy as noted above. It may be necessary to compute expected fairness impact across all dimensions in order to optimize the allocation.\n\nWe plan to leverage aspects of social choice theory to help ameliorate some of these issues. There is a significant body of research on allocation and fair division mechanisms that provide a range of desirable normative properties including envy-freeness [17], e.g., the guarantee that one agent will not desire another agent's allocation, Pareto optimally, e.g., that agents receive an allocation that is highly desirable according to their compatibility evaluations [6]. An important and exciting direction for research is understanding what allocation properties can be guaranteed for the SCRUF-D architecture overall depending on the allocation mechanism selected [7].\n\nWe note that in most practical settings the personalization goal of the system will be most important and therefore the preference of this agent will have topmost priority. It is always allocated and is not part of the allocation mechanism. Thus, we cannot assume that the preference lists of the agents that are input to the choice system are anonymous, a common assumption in the social choice literature on voting [7].\n\n# 6.5 Bossiness\n\nDepending on how the concept of agent / user compatibility is implemented, it may provide benefits to bossy users, those with very narrow majoritarian interests that do not allow for the support of the system's fairness concerns. Those users get results that are maximally personalized and do not share in any of the potential accuracy losses associated with satisfying the system's fairness objectives. Other, more tolerant users, bear these costs. A system may wish to ensure that all users contribute, at some minimal level, to the fairness goals. In social choice theory, a mechanism is said to be non-bossy if an agent cannot change the allocation without changing the allocation that they receive by modifying their preferences [42]. Some preliminary discussions of this problem specifically for fairness-aware recommendation appear in [21].\n\n# 6.6 Fairness Types\n\nWe concentrate in this paper and our work with Kiva generally on provider-side group fairness, that is characteristics of loans where protected groups can be distinguished. However, it is also possible to use the framework for other fairness requirements. On the provider side, an individual fairness concern is one that tracks individual item exposure as opposed to the group as a whole. It would have a more complex means of assessing preference over items and of assessing fairness state, but still fits within the framework.\n\nConsumer-side fairness can also be implemented through use of the compatibility function associated with each agent. For example, the example of assigning risk appropriately based on user risk tolerance becomes a matter of having a risk reduction agent that reports higher compatibility for users with lower risk tolerance.\n\n# 7 Experimental Methodology\n\nAs an initial examination of the properties of the SCRUF-D architecture, we conducted a series of experiments with real and simulated data, run on a Python implementation of the SCRUF-D architecture. See associated GitHub repository for the source code.<sup>7</sup>. Configuration files, data and Jupyter notebooks for producing the experiments and visualizations are found in a separate repository<sup>8</sup>.\n\n# 7.1 Data sets\n\n7.1.1 Microlending Data We used the Microlending 2017 dataset [48], which contains anonymized lending transactions from Kiva.org. The dataset has 2,673 pseudo-items, 4,005 lenders and 110,371 ratings / lending actions. See [50] and [48] for a complete description of the data set.\n\nWe considered two loan feature categories, loan size and country, as protected features. Prior work [50] identified loan size as a dimension along which fairness in lending may need to be sought. About  $4\\%$  of loans had this feature and were considered protected items. We set the fairness target to be  $20\\%$ . For the second protected feature, we followed Sonboli et al. [50] in identifying the 16 countries whose loans have the lowest rates of funding and labeled these as the protected group for the purposes of geographic fairness. We set the fairness target to be  $30\\%$ . Compatibility scores were defined using the entropy of a user's ratings versus the protected status of funded loans using the method in [50].\n\n7.1.2 MovieLens data We also used the MovieLens 1M dataset [26], which contains user ratings for movies. The dataset has 3,900 movies, 6,040 users, and approximately 1 million ratings. We selected movies with female writers and directors as one protected category and movies with non-English scripts as the other. We set the fairness targets for these to be  $12\\%$  and  $28\\%$ , respectively, which mirrors their prevalence in the item catalog.  \n7.1.3 Synthetic data The purpose of synthetic data in our simulations is to supply realistic recommender system output as input to the SCRUF-D reranker, allowing experimental control of the number of sensitive features, the prevalence of sensitive features among items, and the differing receptiveness of users towards those features.\n\nWe create synthetic data via latent factor generation. That is, we create matrices of latent factors similar to those that would be created through factorization and then generate sample ratings from these matrices. Let  $\\hat{U}$  and  $\\hat{V}$  be the user and item latent factor matrices with  $k$  latent factors. We designate the first  $k_{s}$  of the latent factors as corresponding to protected features of items, and the remaining  $k - k_{s}$  factors correspond to other aspects of the items.\n\nAs a first step, we generate a vector of real-valued propensities for each user  $\\Phi_{i} = \\langle \\phi_{1},\\dots,\\phi_{k_{s}}\\rangle$  corresponding to the sensitive features plus additional values for each of the non-sensitive features, drawn from an experimenter-specified normal distribution. Thus, it is possible to adjust the preferences of the user population regarding different sensitive features. The propensities associated with a sensitive feature also represent the user's compatibility with the respective fairness agent, a value which in a non-synthetic case is derived from the pre-existing user profile as in [50].\n\nFrom  $\\Phi_{i}$ , we perform an additional generation step to draw a latent factor vector  $U_{i}$  from a normal distribution centered on the propensities. This two-step process avoids having the latent factors tied exactly to the user propensities, which would otherwise make the compatibility of users with agents highly deterministic.\n\nThe profiles for items are generated in a similar way except that items have a binary association with their associated sensitive features and so the experimenter input consists of parameters for a multi-variate Bernoulli distribution. Each item's propensity is generated as a binary vector  $\\Phi_j$  using these probabilities. As with users, there is a second step of\n\nlatent factor generation, in which the elements of an item's latent feature vector  $V_{j}$  is drawn from a normal distribution centered on the item's (binary) propensity for that feature. This two-step procedure allows us to identify an item as possessing a particular feature (particularly protected ones) without the latent factor encoding this exactly.\n\nAfter  $\\hat{U}$  and  $\\hat{V}$  have been generated, we then select  $m$  items at random for each user  $i$  and compute the product of the  $\\hat{U}_i$  and  $\\hat{V}_j$  as the synthetic rating for each user  $i$ , item  $j$  pair. To simulate the bias for which a fairness solution is sought, we impose a rating penalty  $\\gamma$  on ratings generated for items with sensitive attributes. We sort these values and select the top  $m'$  as the recommender system output. The sorting / filtering process ensures that the output is biased towards more highly-rated items, which is what one would expect in recommender system output.\n\nFor the experiments in this paper, we generated 1,500 users (500 users with a high propensity towards the first factor, 500 users with a high propensity for the second protected factor and 500 users with an average propensity for both) and 1,000 items. For each user, we generated 200 sample ratings and used the top 50 as the recommendation lists. Item propensities were set to 0.1, 0.3 for the first two sensitive factors and the other values were randomly set. The standard deviation of the factors was 1.0. Corresponding user propensities for the features were  $\\mu = 0.5$ ,  $\\sigma = 0.05$  for the both protected factors in the case of the average propensity batch of users,  $\\mu = 0.1$ ,  $\\sigma = 0.1$  for the low propensity factor and  $\\mu = 0.9$ ,  $\\sigma = 0.1$  for the high propensity factor in the other two options. The generation parameters were based on proportions seen in real-world datasets including the Microlending dataset described above. The bias penalty  $\\gamma$  was set to 3.0.\n\nTo explore the dynamic response of the system, we created an artificial ordering of the synthetic users with three segments  $< A, B, C >$ , each arriving in sequence. We placed the synthetic users with high compatibility to Agent 2 and low compatibility with Agent 1 in segment  $A$ , then reversed this affinity in segment  $B$ . Segment  $C$  contained users without high compatibility with either agent. This data is referred to as the Synthetic dataset in the experiments.\n\n# 7.2 Fairness metrics\n\nThe agent-specific fairness metric allows each agent to calculate their current state of fairness given the user interactions that have occurred within the evaluation window. As we have noted above, SCRUF allows for a wide variety of metrics and makes no assumptions that agents have metrics with similar logic. For the experiments in this study, we have chosen to have uniform fairness metric across agents to more easily assess the impact of varying other platform parameters including the allocation and choice mechanisms.\n\nFor each agent defined on fairness concern relative to each dataset, we assign a target exposure value as noted above. That is, an agent with a  $20\\%$  target exposure will return a value of 1.0 (perfect fairness) if, across all of the recommendation lists in the evaluation window, there is at least an average of  $20\\%$  of items with its associated protected feature. More items do not result in a higher score, but fewer items would yield a value linearly-scaled towards zero, as the value when no protected items have been recommended. We have set the targets artificially high to investigate how the system responds to this pressure to include more protected items.\n\n# 7.3 Mechanisms\n\nAs noted above, there is a wide variety of different allocation mechanisms that can be studied. For our purposes in this paper, we are exploring mechanisms with widely differing logics to understand the implication of these choices for recommendation outcomes.\n\n- Least Fair: The fairness agent with the lowest fairness score  $m_i$  is chosen. This simple and commonly-used rule ensures that low fairness agents get attention, but it does not take into account the compatibility between a user and an item and so may cause more accuracy loss than others.  \n- Lottery: A lottery is constructed with probabilities proportional to the product of agent unfairness and compatibility:  $p(f_i) \\propto (1 - m_i) * c_i$ , normalized to sum to 1. A single agent is chosen by drawing from this lottery.  \n- Weighted: All agents are allocated to every recommendation opportunity but their weight is determined by the product of their unfairness and compatibility, similar to the lottery probabilities above:  $\\beta_{i} \\propto (1 - m_{i}) * c_{i}$ , normalized.\n\n# 7.4 Choice Mechanisms (Voting Rules)\n\nWe examine four different choice mechanisms. In computational social choice, choice mechanisms are classically understood as integrating the preferences of multiple agents together to form a single societal preference [7].<sup>9</sup>\n\nRescore: The simplest mechanism is one in which each agent contributes a weighted score for each item and these scores are summed to determine the rank of items. Each fairness agent has a fixed score increment  $\\delta$  that is added to all protected items, weighted by its allocation in the previous phase. This is combined with the scores computed by the recommendation algorithm.\n\nBorda: Under the Borda mechanism [63], ranks are associated with scores and the original scores used to compute those ranks are ignored. The ranks across agents are summed and the result determines the final ranking.\n\nCopeland: The Copeland mechanism calculates a win-loss record for each item considering all item-item pairs in a graph induced by the preferences. Item  $i$  scores one point over item  $j$  if the majority of allocated agents prefer  $i$  to  $j$ . We then sum these pairwise match-ups for each item  $i$  and order the list of items using these scores [41].\n\nRanked Pairs: The Ranked Pairs voting rule [53] computes the pairwise majority graph as described for Copeland but orders the resulting ranking by how much a particular item wins by, selecting these in order to create a complete ranking, skipping a pair if and only if it would induce a cycle in the aggregate ranking.\n\nEach of these choice mechanisms implements a fundamentally different logic for aggregating preferences: score-based, ordinal-based, consistency-based and pairwise-preference [63]. As we show in our results, choice mechanisms yield quite different accuracy / fairness tradeoffs.\n\nWhile the agent weights in these mechanisms fixed by the allocation mechanism (and normalized to 1), the recommender weight is a parameter, which determines how much the recommender systems results are emphasized relative to the fairness agents. Under different conditions and mechanisms, different recommender weights may be optimal. We refer to this weight throughout as  $\\lambda$ .\n\n# 7.5 Baseline algorithms\n\nAs noted above, there are very few recommendation algorithms that allow for dynamic reranking with multiple fairness concerns at once. The Multinomial FA*IR method described in [59] is not practical for recommendation because of its time complexity. For these experiments, we use OFair [50] and MultiFR [55].\n\nOFair is a multi-group fairness-aware recommendation reranking method based on the technique of maximum marginal relevance (MMR) [15] for diversity enhancement in reranking. OFair seeks to enhance fairness for multiple groups by treating each sensitive aspect as a dimension of diversity and greedily building a recommendation list by adding items that enhance its diversity in this respect. OFair adds an additional consideration of personalization by\n\nweighting different features according to user compatibility, building on the work of [33] using profile entropy relative to the sensitive features. OFair also has a  $\\lambda$  parameter, controlling how much the recommender systems scores are weighted in the reranking process.\n\nMulti-FR is described as a \"multi-objective optimization framework for fairness-aware recommendation\" [55]. Multi-FR models fairness constraints using a smoothed stochastic ranking policy and optimizes for fairness constraints using multiple gradient descent. The method finds multiple solutions along a theoretical Pareto frontier and chooses the best solution using a least misery strategy. Note that Multi-FR uses a batch-oriented strategy, attempting to address the fairness concerns over the entire set of recommendations at once. Still, Multi-FR is one of the few existing algorithms for fairness-aware recommendation that supports multiple fairness concerns, including provider-side and consumer-side constraints.\n\nOne key limitations of Multi-FR is that it represents provider-side fairness only in terms of mutually-exclusive provider groups. SCRUF-D has no such limitation and supports intersecting fairness concerns. Because of this difference, in our experiments, we had to create a cross-product of all possible combinations of protected features in order to capture the multiple features in our datasets. Also, Multi-FR only supports a single type of fairness objective on the provider side: minimizing the difference between actual and ideal exposure of item categories. For the experiments below, target exposures were set as follows: Microlending: loan size/0.20, country/0.30; both features/0.026; MovieLens: women writer or director/0.09, non-English/0.25, both features/0.02. Multi-FR has its own method of balancing accuracy and fairness and so does not have a parameter controlling the balance between fairness and accuracy.\n\nBatch-oriented processing as found in Multi-FR is a fairly common approach for fairness-aware recommendation [20] and it is true that recommendation results are often cached, so processing many users at once is a practical approach. However, it should be noted that a batch approach to fairness-aware recommendation does not guarantee fairness in the recommendations that are delivered. The system can guarantee that a good fairness/accuracy tradeoff is found across the recommendation lists that are processed in a given batch, but, these may not in fact be the recommendations that are delivered to users over any interval. The users compatible with a particular protected group (for example, those interested in foreign language movies) may not happen to show up very often. So, the careful balance between criteria achieved within the batch process may not be realized when the recommendations are delivered in practice: the recommendations which are fairness-enhancing may sit in the cache and never be output. One reason to prefer an on-demand approach to fairness enhancement is that it is responsive to fairness outcomes in the moment. Still, we have included Multi-FR as a comparator to indicate what batch-oriented algorithm can achieve by considering all the recommendations at once.\n\n# 7.6 Evaluation\n\nWe evaluate ranking accuracy using normalized discounted cumulative gain (nDCG) and fairness using our (normalized) fair exposure relative to the target proportion set for each protected group. Note that the fairness metric as computed by each agent is different from the overall fairness computed over the experiment, for the simple reason that agents only look back over a fixed window in computing their fairness at each time point. We will use the notation  $\\bar{m}_i$  to refer to the global fairness for agent  $i$ .\n\nTo derive a single score representing both the combined fairness of both agents and the disparity between them, we use the  $L_{1/2}$ -norm, which for our purposes is defined as\n\n$$\nL _ {1 / 2} = \\frac {1}{4} \\left(\\sum_ {\\forall i} \\sqrt {\\bar {m} _ {i}}\\right) ^ {2} \\tag {1}\n$$\n\nThe factor of  $1/4$  is used to give the resulting value the same scale as the original fairness scores. If we consider a fixed average  $\\bar{m}^*$  across all the agents, the  $L_{1/2}$  norm is maximized (and equal to  $\\bar{m}j$ ) if all of the fairness values are the same  $\\bar{m}_i = \\bar{m}^*$ . A mix of lower and higher values with the same average will give a lower result.\n\nA dynamic way to look at local fairness is to consider fairness regret over the course of the experiment. At each time step, we calculate  $1 - m_{i}$ , that is the difference from perfect fairness as the agent defines it, and then sum these values over the course of the simulation. This is similar to the notion of regret in reinforcement learning but using fairness instead of utility. Fairness regret  $G_{i}$  for agent  $i$  is defined as:\n\n$$\nG _ {i} (s) = \\sum_ {t = 0} ^ {s} 1 - m _ {i} (\\vec {L} _ {t}, \\vec {H} _ {t}) \\tag {2}\n$$\n\n# 8 Results\n\nFor the two datasets, we present results showing the results of adjusting  $\\lambda$ , the weight associated with the recommender agent. Lower  $\\lambda$  values put more weight on the reranking mechanisms. We then select a single  $\\lambda$  value for further analysis of each combination of mechanisms.\n\n# 8.1 MovieLens dataset\n\nFigure 3 shows the results for the MovieLens data organized by choice mechanism and showing the results of adjusting  $\\lambda$ , the weight associated with the recommender system. In general, as one might expect, as the weight decreases, accuracy drops and fairness increases. We note that the pair-wise Copeland and Ranked Pairs mechanisms prove difficult to tune when there is only a single agent being allocated. There is only a single value for all cases when  $\\lambda < 1.0$ . This is because these mechanisms depend only on rankings and so as long as the recommender outweighs the allocated agent, it wins all of the pair-wise comparisons and when it does not, it loses all of them.\n\nAs was also seen in [13], there exist some \"win-win\" regions with the Rescore mechanisms in conjunction with Weighted allocation. For small decreases in  $\\lambda$ , we see both fairness and accuracy increase at the same time, indicating that some reranking is actually beneficial to accuracy, even as measured in this off-line setting. In addition, the shallow slope of some of these curves suggests that implementers can increase fairness quite significantly over the baseline without too much loss of ranking accuracy. The other mechanisms have a steeper accuracy loss.\n\nFor the remainder of this discussion, we select the  $\\lambda$  values where accuracy loss is less than or equal to  $5\\%$  and consider what is the best fairness that can be achieved within this constraint. We do not have the ability to tune Multi-FR because of its design, which does Pareto optimization internally, so we report the results from this algorithm as designed.\n\nTable 4 includes all of the findings across the different mechanisms. We include both the  $L_{1/2}$  norm and the average in the table. Where these are close in value, the agents are getting similar fairness outcomes. We can see that the women writers and directors fairness target is quite a bit more difficult to hit than the non-English target. There is a large difference already in the unreranked baseline and this carries through to the rerankers. Many of them are able to achieve and exceed the fairness target for the non-English feature, but none do better than 0.4 for the other feature. One exception is Multi-FR, which overshoots the fairness targets and ends up with very low accuracy. Both Least Fair\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/4db86e77d4b3582897427e6e8f80db2818d76aac6c0e197c6851a8a49c6dae06.jpg)  \nFig. 3. Accuracy vs fairness for the MovieLens dataset at different values of  $\\lambda$ .\n\n<table><tr><td>Allocation</td><td>Choice</td><td>λ</td><td>nDCG</td><td>m1</td><td>m2</td><td>L1/2</td><td>Avg</td></tr><tr><td>-</td><td>-</td><td>1.0</td><td>0.0331</td><td>0.5116</td><td>0.1103</td><td>0.2742</td><td>0.3109</td></tr><tr><td>-</td><td>*OFair</td><td>1.0</td><td>0.0261</td><td>0.8035</td><td>0.2818</td><td>0.5092</td><td>0.5426</td></tr><tr><td>-</td><td>Multi-FR</td><td>N/A</td><td>0.0076</td><td>1.082</td><td>1.721</td><td>1.402</td><td>1.383</td></tr><tr><td rowspan=\"4\">Least Fair</td><td>Borda</td><td>0.41</td><td>0.0316</td><td>1.0950</td><td>0.3051</td><td>0.6390</td><td>0.7000</td></tr><tr><td>*Copeland</td><td>0.11</td><td>0.0298</td><td>1.2601</td><td>0.3594</td><td>0.7414</td><td>0.8097</td></tr><tr><td>Ranked Pairs</td><td>0.11</td><td>0.0314</td><td>1.2043</td><td>0.3963</td><td>0.7456</td><td>0.8003</td></tr><tr><td>Rescore</td><td>0.31</td><td>0.0321</td><td>1.1532</td><td>0.3164</td><td>0.6694</td><td>0.7348</td></tr><tr><td rowspan=\"4\">Lottery</td><td>Borda</td><td>0.41</td><td>0.0321</td><td>1.0528</td><td>0.2985</td><td>0.6181</td><td>0.6757</td></tr><tr><td>*Copeland</td><td>0.11</td><td>0.0297</td><td>1.2461</td><td>0.3596</td><td>0.7361</td><td>0.8028</td></tr><tr><td>*Ranked Pairs</td><td>0.11</td><td>0.0298</td><td>1.2439</td><td>0.3591</td><td>0.7350</td><td>0.8015</td></tr><tr><td>Rescore</td><td>0.31</td><td>0.0327</td><td>1.0991</td><td>0.3086</td><td>0.6431</td><td>0.7039</td></tr><tr><td rowspan=\"4\">Weighted</td><td>Borda</td><td>0.31</td><td>0.0318</td><td>1.0483</td><td>0.3617</td><td>0.6604</td><td>0.7050</td></tr><tr><td>Copeland</td><td>0.91</td><td>0.0315</td><td>1.0053</td><td>0.3940</td><td>0.6645</td><td>0.6997</td></tr><tr><td>Ranked Pairs</td><td>0.11</td><td>0.0316</td><td>1.1853</td><td>0.3947</td><td>0.7370</td><td>0.7900</td></tr><tr><td>Rescore</td><td>0.21</td><td>0.0318</td><td>1.2393</td><td>0.3542</td><td>0.7296</td><td>0.7967</td></tr></table>\n\nTable 4. Accuracy and fairness results for the MovieLens data. Results were chosen to be the greatest  ${L}_{1/2}$  fairness with nDCG loss no greater than 5% over baseline, except for the mechanisms indicated by * which were unable to hit this target at any setting.\n\nand Weighted in conjunction with the Ranked Pairs mechanism do well in this respect. However, these mechanisms are not the best with respect to maintaining accuracy.\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/a2bab743f850b2198c83bca2e39d547d74e636c31aeb306307b95a0b5d44baab.jpg)  \nFig. 4. Comparison of mechanisms on MovieLens data. OFair is omitted as it is far off the chart to the lower left. Multi-FR is far below in terms of accuracy.\n\nFigure 4 shows the accuracy vs. fairness results for all of the mechanisms and the baseline algorithms. We see some clustering by choice mechanism, except for the two pair-wise algorithms, Copeland and Ranked Pairs. For these algorithms, the Lottery mechanism yields very poor ranking accuracy. For Copeland, this is also true of the Least Fair mechanism. The reason is that the Weighted mechanism is so different here is that it is bringing multiple agents to the choice mechanism in these cases. (The others only promote a single agent to the choice phase.) With these multiple agents in the mix, the recommender is dominant and so the agents are less effective at increasing fairness.\n\nExcept for the Rescore mechanism, the Lottery allocation data points are all dominated by other points along the Pareto frontier, which would seem to indicate a disadvantage to allocating only a single agent in the allocation phase. Theoretically, Lottery and Weighted allocations are the same in expectation since the lottery is drawn from the same numerical distribution. However, that is not borne out in the results here. In the case of the Rescore mechanism, these two allocation mechanisms represent very different positions in the tradeoff space.\n\nOverall, the Rescore and Ranked Pairs mechanisms occupy the dominant positions: Rescore at higher accuracy levels and Ranked Pairs at higher fairness levels. Somewhat surprisingly, the Least Fair allocation stakes out two spots on the Pareto frontier, even though it ignores user compatibility. It is generally lower in accuracy than Lottery or Weighted mechanisms when the same choice mechanism is applied although there are exceptions in the experiments.\n\nBoth OFair and Multi-FR are dominated by the SCRUF mechanisms at different points. In the case of Multi-FR, it appears to have inherent limitations on how much accuracy loss it is willing to entertain in order to increase fairness. We also note that its reranking decisions are made off-line in a batch mechanism and so it is not able to respond\n\nManuscript submitted to ACM\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/5d13488472be0fc8d762547a256e13f4eb9e3ddc56d18369de1ec5443f0ff0fa.jpg)  \nFig. 5. Accuracy vs fairness for the Microlending dataset at different values of  $\\lambda$ . Value for Weighted + Borda had much lower fairness and were omitted.\n\ndynamically to fairness issues in the moment. OFair also has lower fairness and accuracy. Like the Weighted mechanism, it is trying to address all of the fairness concerns at once in each recommendation list.\n\n# 8.2 Microlending dataset\n\nFigure 5 shows the results for the Microlending dataset organized by choice mechanism adjusting  $\\lambda$ , the weight associated with the recommender system. The Microlending dataset turns out to be quite different from MovieLens for several reasons. One is that the fairness targets are much easier to achieve. As can be seen in Figure 5, almost all of the mechanisms are able to achieve fairness very close to 1.0. We also see fairly noisy behavior across the different  $\\lambda$  values, rather than the smoother accuracy / fairness tradeoff seen in the MovieLens data. We believe that this is a side-effect of the easier fairness target: there is not much trading-off that the system needs to perform.\n\nTable 5 shows the complete results and we note that the mechanisms are finding identical solutions in many cases, with the same fairness and accuracy values. This suggests that the original results contain only a limited number of protected items in each list and so there is only so much room for the reranker to alter the results. We believe that part of the reason for this effect is our choice of biased matrix factorization as our base recommendation algorithm. This algorithm is known to suffer from popularity bias and be limited in the range of items that it recommends [28]. In our future work, we will examine alternate base algorithms with better diversity.\n\nThe results for the Microlending data are summarized in the scatterplot in Figure 6. There only five points representing the 14 experimental conditions. OFair and Multi-FR are omitted because they are far from the optimal tradeoff region\n\n<table><tr><td>Allocation</td><td>Choice</td><td>λ</td><td>nDCG</td><td>m1</td><td>m2</td><td>L1/2</td><td>Avg</td></tr><tr><td>None</td><td>None</td><td>1.0</td><td>0.0074</td><td>0.6564</td><td>0.0397</td><td>0.3481</td><td>0.2547</td></tr><tr><td>None</td><td>OFair</td><td>1.0</td><td>0.0080</td><td>0.6616</td><td>0.4539</td><td>0.5529</td><td>0.5578</td></tr><tr><td>None</td><td>Multi-FR</td><td>N/A</td><td>0.0262</td><td>0.4472</td><td>0.6205</td><td>0.5338</td><td>0.5303</td></tr><tr><td rowspan=\"4\">Least Fair</td><td>Borda</td><td>0.61</td><td>0.0080</td><td>1.0077</td><td>0.9991</td><td>1.0034</td><td>1.0034</td></tr><tr><td>Copeland</td><td>0.71</td><td>0.0080</td><td>1.0077</td><td>0.9991</td><td>1.0034</td><td>1.0034</td></tr><tr><td>Ranked Pairs</td><td>0.71</td><td>0.0080</td><td>1.0077</td><td>0.9991</td><td>1.0034</td><td>1.0034</td></tr><tr><td>Rescore</td><td>0.41</td><td>0.0080</td><td>1.0077</td><td>0.9991</td><td>1.0034</td><td>1.0034</td></tr><tr><td rowspan=\"4\">Lottery</td><td>Borda</td><td>0.61</td><td>0.0088</td><td>1.0011</td><td>0.9940</td><td>0.9975</td><td>0.9975</td></tr><tr><td>Copeland</td><td>0.71</td><td>0.0088</td><td>1.0011</td><td>0.9940</td><td>0.9975</td><td>0.9975</td></tr><tr><td>Ranked Pairs</td><td>0.51</td><td>0.0088</td><td>1.0011</td><td>0.9940</td><td>0.9975</td><td>0.9975</td></tr><tr><td>Rescore</td><td>0.41</td><td>0.0089</td><td>1.0015</td><td>0.9940</td><td>0.9977</td><td>0.9978</td></tr><tr><td rowspan=\"4\">Weighted</td><td>Borda</td><td>0.61</td><td>0.0082</td><td>0.6548</td><td>0.5054</td><td>0.5777</td><td>0.5801</td></tr><tr><td>Copeland</td><td>0.31</td><td>0.0090</td><td>0.9995</td><td>0.9938</td><td>0.9966</td><td>0.9966</td></tr><tr><td>Ranked Pairs</td><td>0.31</td><td>0.0090</td><td>0.9995</td><td>0.9938</td><td>0.9966</td><td>0.9966</td></tr><tr><td>Rescore</td><td>0.41</td><td>0.0087</td><td>0.9995</td><td>0.9955</td><td>0.9975</td><td>0.9975</td></tr></table>\n\nTable 5. Accuracy and fairness results for the Microlending dataset. Results were chosen to be the best tradeoff for each respective mechanism\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/d0ad035d4f56ede9f0a316d29c83603e1a7f609c9c4f3e8c50edbb3614db3ba7.jpg)  \nFig. 6. Comparison of mechanisms on Microlending data. OFair is omitted as it is far off the chart to the lower left. Multi-FR has higher NDCG but is also omitted due to its far lower fairness.\n\n(although we know from the table that Multi-FR has quite good accuracy). All four of the Least Fair conditions have the same values at the lower right, as do many of the Lottery conditions, except for Rescore.\n\nManuscript submitted to ACM\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/b34874ec22715bfc1d730c667276248f4005a691d9453ea63cad3145dcfc1c75.jpg)  \n(a) Baseline\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/155ea81af13a2444f1d49a37ad2624acb19129cf97088791060687460d6ed5af.jpg)  \n(b) OFair\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/2c7d08f9a01fe68c964b1fd4ed4372bd9d274cebe4c5866e5d6ddf9ffaf852cf.jpg)  \n(c) Lottery\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/93a6a0d7f9c19d07423e88bf31c8b822eefa2da653561c8a6864449a755c0425.jpg)  \n(d) Weighted\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/e1825b68184140e5f29051220c7e0ca1ae19bc2b511d73d94c2aaf8f30beff1e.jpg)  \n(e) Least Fair  \nFig. 7. Cumulative fairness regret for fairness agents with different allocation mechanisms\n\nWith this limited data, it is hard to draw too many conclusions. Unlike in the MovieLens case, Least Fair occupies only the most extreme lower accuracy condition in this data. Rescore still seems to be a good strategy and Ranked Pairs with the Weighted allocation is still on the Pareto frontier as it was in the MovieLens case.\n\n# 8.3 Fairness dynamics\n\nThe compatibility of users with diverse sensitive features turns out to be highly correlated in our real-world datasets, which is perhaps not surprising, but it makes it difficult to explore dynamic scenarios simulating the arrival of disparate types of users at different times. For this reason, we used the Synthetic dataset described above in simulated experiments of user arrivals to examine how the balance between agents is achieved over time. With this synthetic data set, we do not have ground truth user preferences and so we evaluate recommendation accuracy only relative to the original rankings in the simulated data.\n\n![](/uploads/images/89ef51d5-6260-4fcd-9f65-1f75c9693e47/f6973803589cd3d93dfe69436a93010eaab58a569359db9ab93c674c39bb9825.jpg)  \nFig. 8. Ranking accuracy loss on the Synthetic data.\n\nIn Figure 7, we look closely at the cumulative fairness regret for the different allocation mechanisms. We keep the choice mechanism fixed (Borda) to isolate the impact of allocation on agent outcomes. Recall that the arrival of users is segmented so that users compatible with Agent 2 arrive as the first 500, followed by another 500 compatible with Agent 1, and then a third 500 user segment without strong compatibility to either agent. Note that the y-axis on these plots has a log scale.\n\nFor the Baseline algorithm, without reranking, the impact of the different segments can be see in the flattening of the Agent 1 curve for users 500-1000. These users are compatible with Agent 1 and already have some of these protected items in their recommendation lists. The regret ends up quite high for both agents.\n\nThe OFair algorithm does not fare much better. It is trying to satisfy all of the fairness constraints at once. While its fairness regret is lower, especially for Agent 2, it is still quite high. The other allocation mechanisms fare much better, maintaining  $10\\mathrm{x}$  or greater improvement in regret over the course of the experiment. The Lottery and Weighted mechanisms are quite similar to each other, with the Weighted mechanism doing slightly better for Agent 2. By not trying (as hard) to satisfy Agent 1 when its compatible users are rare, the system is able to achieve better fairness for both agents.\n\nThe Least Fair mechanism seems even better still for both agents. However, there is more to the story. By ignoring compatibility, this mechanism cannot achieve ranking accuracy as high as the others. This point is supported by Figure 8, which shows the loss of accuracy incurred by each algorithm. These are small differences, but the Least Fair mechanism is worst on this metric.\n\n# 9 Conclusion and Future Work\n\nWe have introduced the SCRUF-D architecture for integrating multiple fairness concerns into recommendation generation by leveraging social choice. The design is general and allows for many different types of fairness concerns: involving multiple fairness logics and encompassing both provider and consumer aspects of the recommendation platform. The architecture is also general in that it makes few assumptions about the nature of the allocation and choice mechanisms by which fairness is maintained, allowing for a large design space incorporating many types of functions.\n\nOur experiments represent a first step at exploring the interactions of different allocation and choice mechanisms at the heart of the SCRUF model. We have found that the interaction between mechanisms is quite data and application Manuscript submitted to ACM\n\nspecific although some general patterns emerge. A simple Rescoring technique is often just as good or better than more complex choice mechanisms. The Least Fair allocation mechanism, which ignores user preferences in allocating agents, is in some cases quite competitive with more sensitive allocations but some times incurs a substantial accuracy loss as we saw in the Microlending dataset.\n\nOur experiments with synthetic data show that the SCRUF-D architecture is capable of balancing among multiple fairness concerns dynamically and in the end, much better fairness results can be achieved by dynamic mechanisms able to respond to the current fairness needs of each agent, as opposed to the static approaches seen in OFair and Multi-FR.\n\nFuture work will proceed in multiple research arcs. One arc of future work is to apply the architecture in more realistic settings, particularly with Kiva. We are working with Kiva stakeholders and beginning the process of formalizing fairness concerns as documented in [47].\n\nWe have made the mechanisms and the agents fairly simple by design. Further experimentation will show how effective this structure is for maintaining fairness over time and allowing a wide variety of fairness concerns to be expressed. However, there are some areas of exploration that we can anticipate.\n\nOur experiments raise the question of the impact of the base recommender and data characteristics on potential outcomes. We will explore additional choices for recommendation algorithms and datasets to explore and confirm the findings here.\n\nFor reasons of space, some key variations on the experiments shown here were not explored. All of the experiments contain only two fairness agents, although this is not a limitation of the architecture. It will be important to see how the results found here extend to larger cohorts of agents. Similarly, we have limited our agent definitions so that all agents have the a similar fairness definition (targeted exposure). We will explore more diverse and heterogenous fairness definitions across agents in future work. We also note that our synthetic data experiments were limited only to examining user arrival sequencing but with a flexible data generation scheme, there are many additional variables to explore including studying how well niche users are served.\n\nWe note that in a recommendation context the decisions of the recommender system only influence the exposure of protected items. There is no guarantee that a given user will show any interest in an item just because it is presented. In some settings and for some fairness concerns, exposure might be enough. But in cases where utility derives from usage rather than exposure, there would be some value in having the system learn about the relationship between exposure and utility. This setting has the attributes of a multi-objective bandit learning problem [35], where the fairness concerns represent different classes of rewards and the allocation of agents represents different choices.\n\nEven when we consider exposure as our main outcome of interest, it is still the case that the allocation of different agents may result in differential improvements in fairness, the efficacy problem noted above. Perhaps the items associated with one agent are more common in recommendation lists and can be easily promoted through re-ranking while other agents' items are not. The weight associated with the allocation of agents may need to be adjusted to reflect the expected utility of allocation, and this expected utility would need to be learned.\n\nThe current architecture does not make any assumptions about the distribution of user characteristics and this can reduce its effectiveness. Suppose fairness concern  $f_{i}$  is \"difficult\" to achieve in that users with an interest in related items appear rarely. In that case, we should probably allocate  $f_{i}$  whenever a compatible user arrives, regardless of the state of the fairness metrics. This example suggests that the allocation mechanism could be adapted to look forward (to the distribution of future opportunities) as well as backwards (over fairness results achieved). This would require a model of opportunities similar to [45], and others studied in computational advertising settings.\n\nThe current architecture envisions fairness primarily in the context of group fairness expressed over recommendation outcomes. We believe that the architecture will support other types of fairness with additional enhancements. For example, a representational fairness concern would be incompatible with the assumption that fairness can be aggregated over multiple recommendation lists. Consider the examples in Noble's Algorithms of Oppression: it would not be acceptable for a recommender system to deliver results that reinforced racist or sexist stereotypes at times, even if those results were balanced out at other times in some overall average. Representational fairness imposes a stricter constraint than those considered here, effectively requiring that the associated concern be allocated for every recommendation opportunity.\n\nAs noted above, the model expressed here assumes that fairness agents have preferences only over items. But it is also possible to represent agents as having preferences over recommendation lists. This would allow agents to express preferences for combinations of items: for example, a preference that there be at least two Agriculture loans in the top 5 items of the list. This kind of preference cannot be expressed simply in terms of scores associated with items. Agents would naturally have to become more complex in their ability to reason about and generate such preferences, and the choice mechanism would become more like a combinatorial optimization problem. It is possible that we can characterize useful subclasses of the permutation space and avoid the full complexity of arbitrary preferences over subsets.\n\nAnother interesting direction for research is more theoretical in nature. Much of the research in social choice focuses on providing guaranteed normative properties of various mechanisms. However, the models used in traditional social choice theory do not take into consideration the dynamics of recommender systems as most mechanisms are designed to work in one-off scenarios without dynamic aspects. One direction would be to formulate the allocation phase of the architecture as an online matching problem, where fairness agents represent one side of the matching and users arrive online on the other side, revealing their compatibility metric. Similar to work in online ad allocation, each fairness agent might have some budget or capacity that limits the number of users they are matched with, in order to balance between various fairness concerns. It will be important to understand the properties of existing social choice mechanisms for allocation and choice when deployed in these dynamic contexts and to develop new methods with good properties.\n\n# Acknowledgments\n\nAuthors Burke, Voida and Aird were supported by the National Science Foundation under grant awards IIS-1911025 and IIS-2107577. Nicholas Mattei was supported by NSF Grant IIS-2107505. Many thanks to Pradeep Ragothaman and our other collaborators at Kiva for sharing their data and many insights into their important work supporting international development through microlending. Thanks also to Lalita Suwattee for her assistance in conducting experiments.\n\n# References\n\n[1] Nil-Jana Akpinar, Cyrus DiCiccio, Preetam Nandy, and Kinjal Basu. 2022. Long-term Dynamics of Fairness Intervention in Connection Recommender Systems. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society. 22-35.  \n[2] M. Aleksandrov, H. Aziz, S. Gaspers, and T. Walsh. 2015. Online Fair Division: Analysing a Food Bank problem. In Proc. 24th International Joint Conference on AI (IJCAI). IJCAI, 2540-2546.  \n[3] Georgios Amanatidis, Haris Aziz, Georgios Birmpas, Aris Filos-Ratsikas, Bo Li, Hervé Moulin, Alexandros A Voudouris, and Xiaowei Wu. 2023. Fair Division of Indivisible Goods: Recent Progress and Open Questions. Artificial Intelligence (2023), 103965.  \n[4] P. Awasthi and T. Sandholm. 2009. Online Stochastic Optimization in the Large: Application to Kidney Exchange.. In Proc. 21st International Joint Conference on AI (IJCAI). IJCAI, 405-411.  \n[5] Solon Barocas and Andrew D Selbst. 2016. Big Data's Disparate Impact. California law review 104, 3 (2016), 671. https://doi.org/10.15779/Z38BG31  \n[6] Anna Bogomolnaia and Hervé Moulin. 2001. A new solution to the random assignment problem. Journal of Economic theory 100, 2 (2001), 295-328.  \n[7] F. Brandt, V. Conitzer, U. Endriss, J. Lang, and A. D. Procaccia (Eds.). 2016. Handbook of Computational Social Choice. Cambridge University Press.\n\nManuscript submitted to ACM\n\n[8] Eric Budish, Yeon-Koo Che, Fuhito Kojima, and Paul Milgrom. 2013. Designing random allocation mechanisms: Theory and applications. American economic review 103, 2 (2013), 585-623.  \n[9] Francois Buet-Golfouse and Islam Utyagulov. 2022. Towards fair multi-stakeholder recommender systems. In Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization. 255-265.  \n[10] Robin Burke. 2017. Multisided Fairness for Recommendation. In Workshop on Fairness, Accountability and Transparency in Machine Learning (FATML). Halifax, Nova Scotia, 5 pages. https://arxiv.org/abs/1707.00093  \n[11] Robin Burke, Nicholas Mattei, Vladislav Grozin, Amy Voida, and Nasim Sonboli. 2022. Multi-agent Social Choice for Dynamic Fairness-aware Recommendation. In Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization. 234-244.  \n[12] Robin Burke, Pradeep Ragothaman, Nicholas Mattei, Brian Kimmig, Amy Voida, Nasim Sonboli, Anushka Kathait, and Melissa Fabros. 2022. A performance-preserving fairness intervention for adaptive microfinance recommendation. In Proceedings of the KDD Workshop on Online and Adapting Recommender Systems (OARS).  \n[13] Robin Burke, Nasim Sonboli, and Aldo Ordonez-Gauger. 2018. Balanced Neighborhoods for Multi-sided Fairness in Recommendation. In Proceedings of the 1st Conference on Fairness, Accountability and Transparency (Proceedings of Machine Learning Research, Vol. 81), Sorelle A. Friedler and Christo Wilson (Eds.). PMLR, New York, NY, USA, 202-214.  \n[14] Robin Burke, Amy Voida, Nicholas Mattei, and Nasim Sonboli. 2020. Algorithmic Fairness, Institutional Logics, and Social Choice. In Harvard CRCS Workshop on AI for Social Good at 29th International Joint Conference on Artificial Intelligence (IJCAI 2020). 5 pages.  \n[15] Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval. 335-336.  \n[16] Nicolo Cesa-Bianchi, Yoav Freund, David Haussler, David P Helmbold, Robert E Schapire, and Manfred K Warmuth. 1997. How to use expert advice. Journal of the ACM (JACM) 44, 3 (1997), 427-485.  \n[17] Yuga J Cohler, John K Lai, David C Parkes, and Ariel D Procaccia. 2011. Optimal envy-free cake cutting. In Twenty-Fifth AAAI Conference on Artificial Intelligence.  \n[18] John P Dickerson, Karthik A Sankararaman, Aravind Srinivasan, and Pan Xu. 2018. Allocation Problems in Ride Sharing Platforms: Online Matching with Offline Reusable Resources. In Proc. Thirty-Second AAAI Conference on Artificial Intelligence (AAAI). AAAI, 1007-1014.  \n[19] Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords. The American economic review 97, 1 (2007), 242-259.  \n[20] Michael D. Ekstrand, Anubrata Das, Robin Burke, and Fernando Diaz. 2022. Fairness in Information Access Systems. arXiv:2105.05779 [cs.IR]  \n[21] Paresha Farastu, Nicholas Mattei, and Robin Burke. 2022. Who Pays? Personalization, Bossiness and the Cost of Fairness. arXiv preprint arXiv:2209.04043 (2022).  \n[22] Andres Ferraro, Xavier Serra, and Christine Bauer. 2021. Break the loop: Gender imbalance in music recommenders. In Proceedings of the 2021 Conference on Human Information Interaction and Retrieval. 249-254.  \n[23] Rupert Freeman, Seyed Majid Zahedi, and Vincent Conitzer. 2017. Fair social choice in dynamic settings. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI). International Joint Conferences on Artificial Intelligence, Marina del Rey, CA, 4580-4587.  \n[24] Sorelle A Friedler, Carlos Scheidegger, and Suresh Venkatasubramanian. 2021. The (Im)possibility of fairness: different value systems require different mechanisms for fair decision making. Commun. ACM 64, 4 (April 2021), 136-143. https://doi.org/10.1145/3433949  \n[25] Yingqiang Ge, Shuchang Liu, Ruoyuan Gao, Yikun Xian, Yunqi Li, Xiangyu Zhao, Changhua Pei, Fei Sun, Junfeng Ge, Wenwu Ou, et al. 2021. Towards long-term fairness in recommendation. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining. ACM, New York, 445-453.  \n[26] F Maxwell Harper and Joseph A Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4 (2015), 19.  \n[27] Ben Hutchinson and Margaret Mitchell. 2019. 50 Years of Test (Un)fairness. Proceedings of the Conference on Fairness, Accountability, and Transparency - FAT* '19 (2019).  \n[28] Dietmar Jannach, Lukas Lerche, Iman Kamehkhosh, and Michael Jugovac. 2015. What recommenders recommend: an analysis of recommendation biases and possible countermeasures. User Modeling and User-Adapted Interaction 25 (2015), 427–491.  \n[29] Mesut Kaya, Derek Bridge, and Nava Tintarev. 2020. Ensuring fairness in group recommendations by rank-sensitive balancing of relevance. In Proceedings of the 14th ACM Conference on Recommender Systems. 101-110.  \n[30] Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. 2018. Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness. arXiv:1711.05144 [cs.LG]  \n[31] Min Kyung Lee, Daniel Kusbit, Anson Kahng, Ji Tae Kim, Xinran Yuan, Allissa Chan, Daniel See, Ritesh Noothigattu, Siheon Lee, and Alexandros Psomas. 2019. WeBuildAI: Participatory framework for algorithmic governance. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1–35.  \n[32] Cheng-Te Li, Cheng Hsu, and Yang Zhang. 2022. FairSR: Fairness-aware sequential recommendation through multi-task learning with preference graph embeddings. ACM Transactions on Intelligent Systems and Technology (TIST) 13, 1 (2022), 1-21.  \n[33] Weiwen Liu and Robin Burke. 2018. Personalizing Fairness-aware Re-ranking. arXiv preprint arXiv:1809.02921 (2018). Presented at the 2nd FATRec Workshop held at RecSys 2018, Vancouver, CA..\n\n[34] N. Mattei, A. Saffidine, and T. Walsh. 2018. An Axiomatic and Empirical Analysis of Mechanisms for Online Organ Matching. In Proceedings of the 7th International Workshop on Computational Social Choice (COMSOC). 24 pages.  \n[35] Rishabh Mehrotra, Niannan Xue, and Mounia Lalmas. 2020. Bandit based Optimization of Multiple Objectives on a Music Streaming Platform. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3224-3233.  \n[36] Marco Morik, Ashudeep Singh, Jessica Hong, and Thorsten Joachims. 2020. Controlling fairness and bias in dynamic learning-to-rank. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 429-438.  \n[37] Hervé Moulin. 2004. *Fair division and collective welfare*. MIT press.  \n[38] Deirdre K Mulligan, Joshua A Kroll, Nitin Kohli, and Richmond Y Wong. 2019. This thing called fairness: disciplinary confusion realizing a value in technology. Proceedings of the ACM on Human-Computer Interaction 3, CSCW (2019), 1-36.  \n[39] Safiya Umoja Noble. 2018. Algorithms of Oppression: How search engines reinforce racism. NYU Press.  \n[40] Cathy O'Neil. 2016. Weapons of math destruction: How big data increases inequality and threatens democracy. Broadway Books.  \n[41] Eric Pacuit. 2019. Voting Methods. In *The Stanford Encyclopedia of Philosophy* (Fall 2019 ed.), Edward N. Zalta (Ed.). Metaphysics Research Lab, Stanford University.  \n[42] Szilvia Pápaí. 2000. Strategyproof assignment by hierarchical exchange. *Econometrica* 68, 6 (2000), 1403-1433.  \n[43] Gourab K Patro, Arpita Biswas, Niloy Ganguly, Krishna P Gummadi, and Abhijnan Chakraborty. 2020. FairRec: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms. In Proceedings of The Web Conference 2020. 1194-1204.  \n[44] Gourab K Patro, Lorenzo Porcaro, Laura Mitchell, Qiuyue Zhang, Meike Zehlike, and Nikhil Garg. 2022. Fair ranking: a critical review, challenges, and future directions. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency. 1929-1942.  \n[45] Claudia Perlich, Brian Dalessandro, Rod Hook, Ori Stitelman, Troy Raeder, and Foster Provost. 2012. Bid optimizing and inventory scoring in targeted online advertising. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 804-812.  \n[46] Jessie J Smith, Lex Beattie, and Henriette Cramer. 2023. Scoping Fairness Objectives and Identifying Fairness Metrics for Recommender Systems: The Practitioners' Perspective. In Proceedings of the ACM Web Conference 2023. 3648-3659.  \n[47] Jessie J Smith, Anas Buhayh, Anushka Kathait, Pradeep Ragothaman, Nicholas Mattei, Robin Burke, and Amy Voida. 2023. The Many Faces of Fairness: Exploring the Institutional Logics of Multistakeholder Microlending Recommendation. In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency. 1652-1663.  \n[48] Nasim Sonboli, Amanda Aird, and Robin Burke. 2022. Microlending 2017 Data Set. https://doi.org/10.25810/PGJK-RR19  \n[49] Nasim Sonboli, Robin Burke, Nicholas Mattei, Farzad Eskandanian, and Tian Gao. 2020. \"And the Winner Is...\": Dynamic Lotteries for Multi-group Fairness-Aware Recommendation. arXiv:2009.02590 [cs.IR]  \n[50] Nasim Sonboli, Farzad Eskandanian, Robin Burke, Weiwen Liu, and Bamshad Mobasher. 2020. Opportunistic Multi-Aspect Fairness through Personalized Re-Ranking. In Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization (Genoa, Italy) (UMAP '20). Association for Computing Machinery, New York, NY, USA, 239-247. https://doi.org/10.1145/3340631.3394846  \n[51] Tom Suhr, Asia J Biega, Meike Zehlike, Krishna P Gummadi, and Abhijnan Chakraborty. 2019. Two-sided fairness for repeated matchings in two-sided markets: A case study of a ride-hailing platform. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3082-3092.  \n[52] William Thomson. 2011. Fair allocation rules. In Handbook of Social Choice and Welfare. Vol. 2. Elsevier, 393-506.  \n[53] T Nicolaus Tideman. 1987. Independence of clones as a criterion for voting rules. Social Choice and Welfare 4 (1987), 185-206.  \n[54] Jun Wang, Weinan Zhang, and Shuai Yuan. 2017. Display Advertising with Real-Time Bidding (RTB) and Behavioural Targeting. arXiv:1610.03013 [cs.GT]  \n[55] Haolun Wu, Chen Ma, Bhaskar Mitra, Fernando Diaz, and Xue Liu. 2022. A multi-objective optimization framework for multi-stakeholder fairness-aware recommendation. ACM Transactions on Information Systems 41, 2 (2022), 1-29.  \n[56] Yao Wu, Jian Cao, and Guandong Xu. 2023. FASTER: A Dynamic Fairness-assurance Strategy for Session-based Recommender Systems. ACM Transactions on Information Systems (2023).  \n[57] Shuai Yuan, Ahmad Zainal Abidin, Marc Sloan, and Jun Wang. 2012. Internet Advertising: An Interplay among Advertisers, Online Publishers, Ad Exchanges and Web Users. arXiv:1206.1754 [cs.IR]  \n[58] Shuai Yuan, Jun Wang, and Xiaoxue Zhao. 2013. Real-time bidding for online advertising: measurement and analysis. In Proceedings of the Seventh International Workshop on Data Mining for Online Advertising. ACM, 3.  \n[59] Meike Zehlike, Tom Suhr, Ricardo Baeza-Yates, Francesco Bonchi, Carlos Castillo, and Sara Hajian. 2022. Fair Top-k Ranking with multiple protected groups. Information Processing & Management 59, 1 (2022), 102707.  \n[60] Dell Zhang and Jun Wang. 2021. Recommendation fairness: From static to dynamic. arXiv preprint arXiv:2109.03150 (2021).  \n[61] Weinan Zhang, Shuai Yuan, and Jun Wang. 2014. Optimal real-time bidding for display advertising. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1077-1086.  \n[62] Ziwei Zhu, Xia Hu, and James Caverlee. 2018. Fairness-aware tensor-based recommendation. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 1153-1162.  \n[63] William S. Zwicker. 2016. Introduction to the Theory of Voting. In Handbook of Computational Social Choice, Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D. Procaccia (Eds.). Cambridge University Press, 23-56. https://doi.org/10.1017/CBO9781107446984.003",
    "arxiv_id": "2105.05779",
    "error_message": null,
    "embedding": [
      0.318359375,
      2.8125,
      0.74609375,
      -2.96875,
      -1.6640625,
      5.125,
      0.62890625,
      -4.3125,
      0.953125,
      3.3125,
      4.71875,
      2,
      4.65625,
      -0.08203125,
      1.140625,
      1.1953125,
      2.421875,
      0.828125,
      -1.5,
      -8.5625,
      -1.21875,
      5.0625,
      1.0859375,
      -7.75,
      2.40625,
      -2.234375,
      4.46875,
      3.515625,
      -2.078125,
      -0.330078125,
      3.53125,
      -6.28125,
      -0.68359375,
      -2.28125,
      -0.7265625,
      -1.4765625,
      -0.8203125,
      -0.287109375,
      3.171875,
      0.462890625,
      -6,
      4.5,
      -2.203125,
      0.341796875,
      -0.91015625,
      1.5,
      2.015625,
      0.99609375,
      -3.796875,
      -2.703125,
      -5.25,
      -3.765625,
      7.03125,
      -1.0234375,
      2.875,
      -6.21875,
      -7.8125,
      5.53125,
      -4.78125,
      -1.046875,
      0.80859375,
      -1.1171875,
      4.8125,
      -0.4375,
      2.6875,
      7,
      2.125,
      -1.0859375,
      -6.5,
      -1.34375,
      -0.030029296875,
      0.77734375,
      5.4375,
      -2.65625,
      6.9375,
      6.78125,
      -0.384765625,
      3.421875,
      -1.5546875,
      5.25,
      -4.65625,
      0.73828125,
      6.4375,
      1.0703125,
      4.1875,
      1.2734375,
      4.4375,
      2.03125,
      -2.46875,
      3,
      -0.71484375,
      2.15625,
      -3.921875,
      -3.359375,
      -1.2421875,
      4.625,
      1.359375,
      -6.90625,
      -8.3125,
      3.078125,
      -5.3125,
      0.3359375,
      1.6640625,
      -4.65625,
      -1.078125,
      -2.234375,
      -2.578125,
      -4.59375,
      -2.046875,
      -2.8125,
      -2.640625,
      2.046875,
      4.625,
      0.46875,
      3.1875,
      0.51171875,
      4.65625,
      -2.8125,
      -4,
      -2.546875,
      2.21875,
      -3,
      -0.1572265625,
      -2.140625,
      0.1630859375,
      -0.79296875,
      -5.75,
      0.66796875,
      6.53125,
      -1.84375,
      7.84375,
      1.234375,
      4.375,
      -0.55078125,
      -8.5,
      -2.53125,
      -4.78125,
      -0.19921875,
      4.21875,
      6.78125,
      -3,
      1.75,
      -3.90625,
      -4.6875,
      3.703125,
      1.0234375,
      -3.53125,
      -0.330078125,
      0.396484375,
      -0.93359375,
      -0.6796875,
      3.875,
      1.015625,
      6.5625,
      -1.9765625,
      -6.59375,
      0.6875,
      2.65625,
      0.91015625,
      -2.21875,
      3.890625,
      5.15625,
      1.1171875,
      4.46875,
      3.796875,
      -2.859375,
      -4.46875,
      2.09375,
      0.341796875,
      -1.703125,
      4.5,
      18,
      1.8359375,
      -2.15625,
      0.1953125,
      6.1875,
      -0.201171875,
      7.25,
      1.6796875,
      1.390625,
      -0.625,
      2.375,
      -4.3125,
      6.03125,
      -2,
      -1.1015625,
      0.388671875,
      -3.5625,
      3.234375,
      -1.5390625,
      5.71875,
      2.484375,
      4.125,
      -1.8671875,
      -1.5390625,
      0.8359375,
      3.90625,
      -0.1962890625,
      2.90625,
      2.71875,
      0.328125,
      -7.25,
      -0.94140625,
      0.419921875,
      -3.703125,
      -0.0693359375,
      3.9375,
      -0.050537109375,
      -2.21875,
      -4.0625,
      3.96875,
      2.5,
      2.953125,
      1.1796875,
      7.96875,
      2.78125,
      0.8828125,
      -1.3046875,
      1.953125,
      -1.5546875,
      4.03125,
      4.84375,
      -1.109375,
      -1.453125,
      -2.3125,
      1.0625,
      4.03125,
      4.71875,
      4.375,
      7,
      -0.408203125,
      1.5390625,
      3.8125,
      -2.140625,
      -1.453125,
      -2.5625,
      -9.75,
      -0.734375,
      -2.875,
      1.515625,
      -4.65625,
      -2.34375,
      0.138671875,
      0.92578125,
      1.2109375,
      -1.078125,
      -2.328125,
      -5.375,
      1.9375,
      -5.28125,
      -3.546875,
      4.03125,
      -4.6875,
      -3.40625,
      3.84375,
      5.3125,
      -3.765625,
      1.234375,
      -1.15625,
      -1.3203125,
      4.6875,
      -2.03125,
      -6.03125,
      2.71875,
      3.421875,
      -1.671875,
      3.34375,
      -2.515625,
      2.015625,
      4.75,
      3.1875,
      -0.703125,
      0.5390625,
      0.62109375,
      -0.515625,
      6.8125,
      0.1064453125,
      -5.3125,
      4,
      -3.484375,
      -2.3125,
      -3.9375,
      5.9375,
      -7.53125,
      6,
      -4.375,
      -0.66796875,
      4.5,
      -6.65625,
      12.4375,
      8.9375,
      1.046875,
      0.84375,
      -3.640625,
      -3.640625,
      -1.703125,
      -2.578125,
      -2.203125,
      -6.28125,
      2.40625,
      4.25,
      0.44921875,
      -2.171875,
      0.22265625,
      -3.03125,
      3.71875,
      -0.412109375,
      -2.828125,
      -0.83203125,
      2.53125,
      0.14453125,
      -1.109375,
      6.4375,
      -3.109375,
      -0.31640625,
      -2.578125,
      -1.5703125,
      2.15625,
      0.050537109375,
      -3.671875,
      -4.8125,
      -5,
      -4.96875,
      -3.8125,
      -0.357421875,
      -2.890625,
      0.54296875,
      1.640625,
      2.28125,
      -0.81640625,
      2.609375,
      2.296875,
      -3.984375,
      -8.9375,
      4.40625,
      -2.5,
      -1.8359375,
      2.875,
      0.67578125,
      5.25,
      -9.125,
      -0.55859375,
      0.72265625,
      -1.7578125,
      -3.984375,
      0.69921875,
      3.9375,
      -0.369140625,
      0.01220703125,
      -5.40625,
      4.1875,
      1.84375,
      1.8671875,
      2.421875,
      4.75,
      -1.921875,
      1.546875,
      -0.58203125,
      0.34765625,
      -2.640625,
      3.796875,
      -2.484375,
      4.90625,
      0.5703125,
      -4.6875,
      -3.28125,
      0.455078125,
      3.546875,
      -1.34375,
      -5.125,
      2.796875,
      -3.953125,
      3,
      -2.078125,
      4.125,
      -2.296875,
      0.78125,
      -2.640625,
      -5.28125,
      -3.1875,
      -2.359375,
      -3.453125,
      1.1484375,
      1.09375,
      2.4375,
      0.9453125,
      -4.875,
      3.328125,
      0.578125,
      -4.03125,
      -3.140625,
      -0.44921875,
      -2.5,
      1.4375,
      3.359375,
      0.53125,
      0.2470703125,
      3.140625,
      -0.95703125,
      -0.79296875,
      2.84375,
      0.2158203125,
      1.75,
      -1.1015625,
      -1.3671875,
      -0.38671875,
      -3.484375,
      -2.84375,
      0.33984375,
      0.1845703125,
      -1.3046875,
      2.34375,
      1.359375,
      -2.09375,
      -0.5078125,
      3.78125,
      2.375,
      0.23046875,
      -6.625,
      -3.90625,
      -0.259765625,
      2.9375,
      1.234375,
      -3.8125,
      0.1279296875,
      2.15625,
      1.3828125,
      3.078125,
      1.1328125,
      0.77734375,
      0.67578125,
      1.765625,
      -4.90625,
      -0.09716796875,
      -1.2734375,
      -2.3125,
      1.421875,
      -4.53125,
      -3.71875,
      3.34375,
      5.34375,
      -2.5625,
      2.78125,
      3.828125,
      -3.390625,
      -1.8515625,
      0.357421875,
      3.0625,
      -4.9375,
      -3.53125,
      -1.703125,
      0.63671875,
      -1.2890625,
      1.859375,
      3.875,
      -1.640625,
      -4.46875,
      2.296875,
      3.140625,
      -1.15625,
      -1.4453125,
      -2.578125,
      -1.96875,
      -1.90625,
      1.640625,
      -0.2890625,
      -0.236328125,
      3.484375,
      8.1875,
      -8.8125,
      -6.3125,
      5.8125,
      1.2890625,
      -0.8359375,
      -2.09375,
      1.0234375,
      0.99609375,
      1.6640625,
      -3.0625,
      -5.375,
      2.203125,
      -5.90625,
      2.390625,
      1.4921875,
      0.60546875,
      -1.8984375,
      -4,
      9,
      3.3125,
      5.09375,
      0.275390625,
      3.0625,
      3.109375,
      -5.71875,
      3.71875,
      3.421875,
      10.1875,
      -6.6875,
      -1.6796875,
      3.140625,
      -6.09375,
      1.03125,
      -3.921875,
      0.53125,
      -0.2216796875,
      -0.130859375,
      2.875,
      -4.0625,
      0.2021484375,
      -0.6015625,
      5.5625,
      -2.046875,
      0.90234375,
      1.0859375,
      -4.4375,
      -2.734375,
      0.345703125,
      1.265625,
      3.6875,
      -1.21875,
      -1.6875,
      0.9765625,
      -0.1044921875,
      -1.4453125,
      -1.078125,
      -3.171875,
      -1.1171875,
      -0.396484375,
      1.765625,
      3.359375,
      0.4453125,
      0.5859375,
      -1.265625,
      -5.71875,
      -2.53125,
      -1.5078125,
      0.43359375,
      -0.5234375,
      0.64453125,
      3.5,
      4.5,
      -1.1484375,
      -2.125,
      0.8125,
      0.10595703125,
      1.6796875,
      -0.7421875,
      -0.263671875,
      -1.1484375,
      2.78125,
      3.46875,
      -0.94921875,
      -3.15625,
      -1.6484375,
      0.447265625,
      -1,
      -3.5,
      -2.375,
      5.65625,
      0.63671875,
      -1.4296875,
      -0.85546875,
      -0.484375,
      3.859375,
      -0.09619140625,
      -1.71875,
      1.4296875,
      5.03125,
      -3.375,
      -2.28125,
      2.546875,
      2.265625,
      -0.392578125,
      -0.73046875,
      2.296875,
      -0.49609375,
      -4.375,
      -7.53125,
      -2.21875,
      1.3671875,
      6.21875,
      -0.703125,
      2.453125,
      -4.53125,
      3.53125,
      0.1142578125,
      0.95703125,
      -9.4375,
      1.7109375,
      -1.6796875,
      -1.265625,
      -0.84375,
      -6.28125,
      2.859375,
      -3.9375,
      3.109375,
      0.28515625,
      0.7109375,
      1.1015625,
      2.703125,
      -2.84375,
      -2.0625,
      4.25,
      0.87109375,
      2.4375,
      -0.388671875,
      -1.0546875,
      -2.5,
      -0.439453125,
      -0.376953125,
      3.296875,
      2.703125,
      4.65625,
      -1.3828125,
      -0.51171875,
      0.7890625,
      -3.96875,
      -2.359375,
      5.34375,
      0.83203125,
      -1.1953125,
      2.265625,
      -0.6171875,
      0.890625,
      -3.375,
      5.875,
      4.90625,
      -2.3125,
      2.859375,
      3.0625,
      0.2490234375,
      -3.765625,
      2.484375,
      -0.369140625,
      3.140625,
      3.21875,
      -4.84375,
      0.255859375,
      -0.158203125,
      1.28125,
      0.9375,
      3.28125,
      0.76953125,
      -6.71875,
      3.921875,
      -2.03125,
      -2.9375,
      3.359375,
      4.5625,
      -2.40625,
      -2.96875,
      3.65625,
      -3.703125,
      1.171875,
      0.96875,
      3.5625,
      -0.33203125,
      -0.162109375,
      0.69921875,
      -2.59375,
      -5.46875,
      -1.6796875,
      -1.6484375,
      -6.8125,
      5.03125,
      -0.035888671875,
      -3.5625,
      0.2578125,
      -2.15625,
      4.1875,
      -0.57421875,
      1.984375,
      2.1875,
      6.75,
      -0.2294921875,
      -3.5,
      1.71875,
      -3.859375,
      -7.34375,
      0.470703125,
      0.12158203125,
      -2.390625,
      -1.0859375,
      -1.671875,
      2.4375,
      0.75,
      -1.796875,
      -4.15625,
      -7.5,
      0.58984375,
      2.703125,
      -1.3359375,
      2.109375,
      -4.5,
      3.4375,
      0.484375,
      -5.1875,
      1.4453125,
      0.6875,
      -2.515625,
      -1.71875,
      -0.294921875,
      -7.9375,
      -0.314453125,
      9.625,
      5.03125,
      -3.765625,
      6.40625,
      4.15625,
      -1.6953125,
      0.6484375,
      -0.14453125,
      -2.28125,
      -0.84375,
      2.265625,
      -3.5,
      -0.345703125,
      -5.1875,
      -1.8671875,
      -2.40625,
      -0.484375,
      -0.953125,
      -3.234375,
      -4.53125,
      -2.59375,
      -2.25,
      0.498046875,
      -3.921875,
      1.96875,
      4.65625,
      -0.8828125,
      -2.5,
      4.125,
      6.71875,
      0.1435546875,
      1.4765625,
      -1.6640625,
      0.03076171875,
      5.9375,
      0.69140625,
      0.361328125,
      -5.03125,
      1.0859375,
      0.859375,
      -3.484375,
      2.875,
      -1.0703125,
      -0.32421875,
      1.296875,
      0.55078125,
      -3.984375,
      -1.109375,
      -1.5,
      -3.375,
      -1.875,
      -3.875,
      4.65625,
      1.9296875,
      1.6875,
      -0.046875,
      -1.7421875,
      -1.1953125,
      1.125,
      2.953125,
      0.36328125,
      -6.4375,
      2.4375,
      0.37109375,
      3.734375,
      -0.29296875,
      -5.09375,
      0.06787109375,
      0.11865234375,
      -1.15625,
      0.09228515625,
      6.53125,
      -3.515625,
      2.109375,
      -3.375,
      0.1513671875,
      0.70703125,
      3.078125,
      1.59375,
      -0.4375,
      0.4609375,
      0.3828125,
      2.125,
      0.98828125,
      -4.0625,
      -1.765625,
      -4,
      -1.7578125,
      0.53125,
      1.890625,
      -0.92578125,
      0.01708984375,
      -0.97265625,
      -0.921875,
      1.9296875,
      3.328125,
      3.65625,
      -2.765625,
      1.9921875,
      2.40625,
      3.796875,
      -5.5625,
      1.1640625,
      2.578125,
      9.875,
      -1.9375,
      -4.9375,
      6.3125,
      2.21875,
      1.5,
      4.3125,
      -8.625,
      -3,
      1.4609375,
      1.0390625,
      -3.875,
      -1.6015625,
      -3.890625,
      -2.078125,
      0.146484375,
      4.53125,
      3.46875,
      3.078125,
      5.65625,
      0.1376953125,
      -2.90625,
      0.486328125,
      -3.078125,
      -1.609375,
      -0.81640625,
      0.058837890625,
      -2.984375,
      -0.8359375,
      -1.15625,
      3.109375,
      0.77734375,
      -0.68359375,
      0.283203125,
      5.8125,
      2.375,
      -1.0625,
      1.921875,
      0.8203125,
      0.8203125,
      -0.578125,
      1.9921875,
      -1.390625,
      -0.87109375,
      6.21875,
      3.15625,
      -0.91015625,
      1.9921875,
      -1.515625,
      2.765625,
      -7,
      -1.484375,
      -0.796875,
      1.390625,
      -0.2099609375,
      -0.3203125,
      0.625,
      -0.50390625,
      -4.5625,
      1.125,
      -1.6328125,
      -4.15625,
      2.0625,
      0.96875,
      -0.796875,
      3.140625,
      1.453125,
      5.03125,
      2.734375,
      0.65625,
      -1.859375,
      -3.5,
      -2.421875,
      0.2080078125,
      -2.453125,
      -0.408203125,
      2.359375,
      -2.625,
      1.609375,
      -6.21875,
      -0.359375,
      -6.40625,
      3.21875,
      0.46484375,
      -3.96875,
      -1.09375,
      -2.546875,
      -5.375,
      -4.9375,
      0.84765625,
      -2.375,
      -2.078125,
      -5.9375,
      -3.65625,
      0.7890625,
      -6.75,
      2.5625,
      -4.34375,
      -2.109375,
      2.4375,
      1.0625,
      3.984375,
      -5.6875,
      2.265625,
      3.421875,
      1.328125,
      2.984375,
      1.703125,
      2.65625,
      4.375,
      -2,
      -2.140625,
      -3.171875,
      5.375,
      -2.21875,
      5.96875,
      4.90625,
      -0.71484375,
      -4.75,
      3.234375,
      -3.28125,
      1.5078125,
      -7.96875,
      -1.6484375,
      -0.6171875,
      -3.359375,
      2.078125,
      -2.9375,
      1.359375,
      -4.8125,
      -0.96875,
      1.9453125,
      -3.53125,
      -1.4453125,
      4.96875,
      0.80859375,
      5.375,
      2.046875,
      -1.28125,
      3.25,
      -0.349609375,
      2.875,
      0.232421875,
      1.375,
      -5.15625,
      2.890625,
      -1.6640625,
      0.3828125,
      2.53125,
      -0.33203125,
      2.671875,
      1.4609375,
      1.625,
      1.84375,
      3.421875,
      6.28125,
      -0.435546875,
      2.171875,
      2.09375,
      1.4609375,
      0.8125,
      -5.1875,
      0.8671875,
      0.87890625,
      3.421875,
      1.1171875,
      0.5859375,
      -0.0002803802490234375,
      0.62109375,
      -1.6015625,
      -5.28125,
      -3.375,
      -1.734375,
      -2.984375,
      3.15625,
      -0.69140625,
      0.609375,
      3.15625,
      -0.1845703125,
      0.5625,
      0.85546875,
      -0.054443359375,
      3.03125,
      -1.640625,
      -2,
      2.96875,
      -2.75,
      2.25,
      5,
      0.71484375,
      5,
      -0.1376953125,
      -0.447265625,
      -2.8125,
      -1.8828125,
      4.71875,
      -4.03125,
      -2.515625,
      3.96875,
      -1.4453125,
      -2.421875,
      0.70703125,
      -0.66015625,
      -0.3984375,
      -2.28125,
      1.2734375,
      5.09375,
      3.421875,
      -6.0625,
      0.26953125,
      -3.34375,
      -3.40625,
      -1.40625,
      0.1416015625,
      1.96875,
      4.25,
      3.671875,
      1.1953125,
      -0.53515625,
      -1.375,
      0.2470703125,
      -2.859375,
      0.81640625,
      0.9296875,
      -0.0142822265625,
      -0.66796875,
      -0.02392578125,
      2.84375,
      -0.71875,
      1.2265625,
      5.09375,
      -4.125,
      1.375,
      1.5078125,
      -0.26171875,
      -0.3203125,
      0.07568359375,
      0.439453125,
      0.29296875,
      -1.6171875,
      2.25,
      -3.59375,
      1.53125,
      0.44140625,
      -0.232421875,
      -0.2734375,
      5.71875,
      1.078125,
      -2.890625,
      0.6328125,
      -1.484375,
      -2.875,
      2.3125,
      -3.703125,
      -5.46875,
      0.349609375,
      -1.328125,
      -0.82421875,
      -0.333984375,
      -0.75,
      -1.3359375,
      6.15625,
      -8.375,
      4.125,
      -8.375,
      4.90625,
      -0.90625,
      -3.984375,
      0.1552734375,
      -4.0625,
      4.46875,
      -2.609375,
      -2.21875,
      3.96875,
      -2.609375,
      -0.94140625,
      -2.609375,
      3.953125,
      0.201171875,
      -0.392578125,
      3.578125,
      -4.71875,
      -2.75,
      -2.484375,
      2.59375,
      -8.3125,
      -3.703125,
      -1.90625,
      1.8203125,
      -1.5859375,
      -1.9296875,
      1.578125,
      -0.890625,
      3.859375,
      -4.71875,
      1.3984375,
      -3.796875,
      -2.09375,
      -0.2041015625,
      1.671875,
      4.46875,
      2.4375,
      -3.109375,
      -2.203125,
      -1.5,
      -3.34375,
      -0.31640625,
      0.462890625,
      3.546875,
      -3.671875,
      -1.4140625,
      0.025390625,
      -3.609375,
      -1.1640625,
      2.28125,
      -0.91015625,
      1.3828125,
      2.71875,
      -3.015625,
      2.609375,
      -0.953125,
      -2.59375,
      -5.9375,
      -3.640625,
      -4.21875,
      4.125,
      1.6640625,
      -2.375,
      5.34375,
      1.09375,
      0.1787109375,
      3.953125,
      -0.18359375,
      1.828125,
      -0.310546875,
      0.8359375,
      -3.671875,
      -5.21875,
      3.171875,
      0.70703125,
      2.421875,
      -3.125,
      -3.53125,
      -3.453125,
      0.34375,
      1.3046875,
      0.08251953125,
      1.828125,
      3.234375,
      -4.375,
      -1.015625,
      -4.34375,
      -2.390625,
      2.671875,
      4.84375,
      6.28125,
      5.46875,
      -1.609375,
      -2.859375,
      -3.390625,
      1.03125,
      3.28125,
      1.421875,
      -2.546875,
      0.38671875,
      1.5390625,
      4.59375,
      -3.46875,
      -1.0390625,
      -8.8125,
      3.34375,
      4.75,
      2.421875,
      -1.6171875,
      3.1875,
      0.99609375,
      2.5625,
      0.29296875,
      2.53125,
      -5.4375,
      -7.125,
      -2.84375,
      3.15625,
      2.421875,
      -2.984375,
      1.484375,
      2.6875,
      -0.3046875,
      0.89453125,
      4.15625,
      -1.2265625,
      -1.109375,
      5.15625,
      -0.38671875,
      -2.375,
      -2.203125,
      2.359375,
      -0.9609375,
      0.061279296875,
      -2.9375,
      -1.7421875,
      -2.53125,
      1.125,
      -1.4375,
      5.6875,
      0.0400390625,
      4.09375,
      -1.6796875,
      4.15625,
      -2,
      -0.0625,
      2.171875,
      6.46875,
      0.0810546875,
      -1.796875,
      3.421875,
      -3.8125,
      2.765625,
      2.59375,
      -8.125,
      -0.859375,
      1.296875,
      0.2021484375,
      5.90625,
      -1.8203125,
      -0.177734375,
      -3.28125,
      0.53515625,
      -8.630752563476562e-05,
      -4.875,
      -1.8828125,
      1.9765625,
      2.6875,
      -3.953125,
      2.546875,
      1.125,
      0.8984375,
      -3.609375,
      4.03125,
      -1.484375,
      3.546875,
      0.6015625,
      2.328125,
      -0.392578125,
      -3.578125,
      0.52734375,
      0.265625,
      -2.03125,
      -1.9375,
      0.244140625,
      1.5390625,
      3.8125,
      -0.65625,
      -4.5,
      -1.640625,
      -4.875,
      2.390625,
      -1.9921875,
      3.140625,
      -5.5625,
      4.25,
      -2.765625,
      2.421875,
      0.61328125,
      -5.1875,
      -2.421875,
      0.82421875,
      -1.453125,
      3.328125,
      5.46875,
      -2.359375,
      -2.921875,
      4.625,
      1.2734375,
      -2.953125,
      -2.59375,
      3.234375,
      -0.0269775390625,
      -2.65625,
      0.359375,
      2.453125,
      -0.86328125,
      -0.98828125,
      -0.2490234375,
      3.453125,
      1.5390625,
      -1.421875,
      1.3515625,
      4,
      0.36328125,
      0.76171875,
      2.109375,
      4.1875,
      -0.65234375,
      1.0703125,
      4.125,
      0.146484375,
      0.88671875,
      -2.46875,
      5.59375,
      -2.984375,
      -1.1484375,
      1.6328125,
      3.53125,
      -3.046875,
      0.451171875,
      5.25,
      5.34375,
      0.69921875,
      0.27734375,
      -1.3671875,
      2.546875,
      0.765625,
      -1.578125,
      -3.828125,
      -0.443359375,
      0.70703125,
      -2.5625,
      2.984375,
      -1.4921875,
      4.125,
      -1.21875,
      2.1875,
      1.953125,
      1.28125,
      2.546875,
      -1.625,
      -0.038330078125,
      2.859375,
      -2.625,
      2.046875,
      1.046875,
      -2.796875,
      1.84375,
      0.130859375,
      -2.375,
      -3.265625,
      -7.65625,
      -0.2080078125,
      -0.1259765625,
      1.3671875,
      0.75390625,
      2.046875,
      -0.154296875,
      3.3125,
      0.640625,
      1.6875,
      -4.8125,
      -5.21875,
      3.578125,
      -0.3828125,
      -3.78125,
      1.0703125,
      3.28125,
      2.578125,
      7.03125,
      3.890625,
      2.984375,
      -0.8125,
      2.609375,
      -1.421875,
      -0.68359375,
      1.0625,
      -3.453125,
      1.6484375,
      0.46484375,
      2.6875,
      0.203125,
      4.78125,
      -3.9375,
      -3.46875,
      -2.609375,
      -1.734375,
      0.11181640625,
      2.59375,
      -1.0546875,
      -0.87109375,
      4.5625,
      1.734375,
      2.484375,
      2.609375,
      -2.4375,
      -0.60546875,
      -0.396484375,
      -2.6875,
      2.296875,
      2.9375,
      2.609375,
      -2.15625,
      3.796875,
      2.265625,
      1.6328125,
      1.171875,
      3.25,
      -1.59375,
      -5.78125,
      3.53125,
      1.15625,
      2.953125,
      -2.078125,
      4.59375,
      3.625,
      1.7734375,
      4.59375,
      5.71875,
      0.98046875,
      -1.375,
      5.375,
      -1.421875,
      -2.609375,
      -2.53125,
      0.984375,
      -1.90625,
      -0.7109375,
      -0.0087890625,
      -2.421875,
      5.3125,
      -2.71875,
      -0.029052734375,
      1.4609375,
      7,
      -2.390625,
      3.296875,
      -5.5,
      1.140625,
      -3.734375,
      -1.3203125,
      -2.890625,
      -0.8984375,
      0.828125,
      3.359375,
      -0.265625,
      -2.875,
      2.84375,
      4.40625,
      -1.03125,
      -6.1875,
      3.90625,
      0.040283203125,
      0.515625,
      -1.8203125,
      -3.6875,
      3.5625,
      2.375,
      -0.95703125,
      -3.3125,
      4.65625,
      0.462890625,
      -5.59375,
      -5.78125,
      2.0625,
      -0.208984375,
      -6.21875,
      -4.1875,
      -3.09375,
      2.515625,
      -3.515625,
      3.75,
      0.94140625,
      1.6015625,
      3.6875,
      0.72265625,
      3.15625,
      1.1328125,
      -2.96875,
      -0.87109375,
      -0.6953125,
      -4.5625,
      1.9609375,
      3.75,
      -1.5546875,
      2.671875,
      -4.375,
      -0.359375,
      1.2578125,
      -0.87109375,
      -1.1484375,
      -4.59375,
      4.28125,
      -2.78125,
      3.703125,
      2.203125,
      -0.359375,
      1.0625,
      -1.890625,
      -4.5625,
      0.12890625,
      2.4375,
      1.6328125,
      -1.1953125,
      1.375,
      -0.9765625,
      6.40625,
      -1.78125,
      -1.1015625,
      2.359375,
      -1.9140625,
      -1,
      0.2158203125,
      -3.25,
      1.0390625,
      -2.0625,
      4.25,
      -2.453125,
      -5.3125,
      0.251953125,
      1.3984375,
      3.390625,
      1.703125,
      -5.65625,
      -1.8671875,
      2.0625,
      0.8828125,
      1.09375,
      -2.765625,
      -1.671875,
      -0.703125,
      -1.0546875,
      -3.359375,
      0.5625,
      1.28125,
      1.828125,
      -4.46875,
      -1.28125,
      -2.109375,
      2.234375,
      0.330078125,
      -7.9375,
      -0.1572265625,
      0.83203125,
      -2.234375,
      -1.3515625,
      0.4609375,
      3.796875,
      1.640625,
      -0.11181640625,
      6.5625,
      4.1875,
      -4.40625,
      2.546875,
      15.4375,
      0.435546875,
      -3.1875,
      1.7734375,
      -0.90234375,
      3.234375,
      4.59375,
      2.90625,
      0.140625,
      1.4375,
      -0.0556640625,
      1.828125,
      -0.8671875,
      1.828125,
      -0.70703125,
      -2.84375,
      4,
      -1.625,
      -4.875,
      -5.15625,
      -1.4296875,
      1.5078125,
      1.59375,
      1.7421875,
      1.4453125,
      3.859375,
      0.6328125,
      2.578125,
      -3.34375,
      -0.26171875,
      -1.390625,
      -0.97265625,
      3.203125,
      -0.494140625,
      3.171875,
      -4.5,
      2.078125,
      1.8203125,
      -0.5078125,
      -3.78125,
      -4.875,
      -2.21875,
      2.09375,
      2.890625,
      0.205078125,
      -1.234375,
      -1.171875,
      -1.625,
      2.375,
      1.3203125,
      -2.765625,
      -0.65625,
      -5.53125,
      0.490234375,
      -0.64453125,
      -0.2177734375,
      0.72265625,
      -5.75,
      -2.453125,
      0.83984375,
      -1.7109375,
      -0.146484375,
      -1.6953125,
      -0.1806640625,
      -0.392578125,
      -1.421875,
      -3.109375,
      1.2578125,
      4.53125,
      -2.859375,
      -3.78125,
      -4.59375,
      4.6875,
      2.25,
      2.21875,
      -1.0625,
      3.71875,
      4.78125,
      0.4140625,
      -1.3828125,
      -0.49609375,
      -2.96875,
      -0.0615234375,
      -1.234375,
      -0.73828125,
      2.140625,
      -4.15625,
      4.9375,
      -0.42578125,
      -2.390625,
      6.78125,
      -0.224609375,
      2.59375,
      2.90625,
      -0.9921875,
      -3.9375,
      3.5625,
      3.59375,
      -0.80859375,
      1.7421875,
      5.65625,
      1.6875,
      -2.375,
      0.37109375,
      2.84375,
      -1.796875,
      0.01708984375,
      -0.9453125,
      2.1875,
      0.77734375,
      2.234375,
      1.9453125,
      0.2158203125,
      -1.9609375,
      2.4375,
      4.125,
      -3.3125,
      -2.734375,
      -1.4609375,
      1.6171875,
      3.96875,
      2.40625,
      -3.015625,
      0.8828125,
      -7.65625,
      -4.40625,
      -2.171875,
      -2.65625,
      3.546875,
      -2.578125,
      1.46875,
      -0.08984375,
      -2.453125,
      -3.90625,
      -1.2578125,
      -3.171875,
      1.28125,
      4.96875,
      4.5,
      -1.4453125,
      -4.8125,
      -1.3125,
      1.8828125,
      -2.53125,
      -0.75,
      4.6875,
      -3.40625,
      2.90625,
      1.2890625,
      0.81640625,
      -5.28125,
      6.75,
      1.7109375,
      -2.546875,
      -5.25,
      1.71875,
      -1.421875,
      -4.15625,
      -1.5703125,
      0.435546875,
      -1.2109375,
      -2.078125,
      -3.21875,
      -3.578125,
      -1.1953125,
      -0.36328125,
      3.1875,
      4.15625,
      -5.4375,
      4.75,
      4.0625,
      -7.96875,
      -2.203125,
      -2.109375,
      1.9140625,
      -7.15625,
      3.515625,
      0.384765625,
      -3.03125,
      -1.375,
      5.4375,
      1.3671875,
      -1.2421875,
      -1.796875,
      0.72265625,
      3.59375,
      -2.65625,
      3.46875,
      3.578125,
      -0.2451171875,
      -1.3984375,
      -1.515625,
      -3.484375,
      2.34375,
      6.21875,
      -5.8125,
      -0.87109375,
      -3.4375,
      1.4609375,
      0.3046875,
      -3.90625,
      1.8984375,
      0.080078125,
      1.890625,
      4.46875,
      -1.5546875,
      -1.1484375,
      -1.28125,
      -2.03125,
      0.82421875,
      -2.640625,
      2.125,
      2.328125,
      -0.404296875,
      -0.8046875,
      3.71875,
      0.51953125,
      1.203125,
      -1.609375,
      0.3046875,
      2.25,
      4.78125,
      -5.75,
      0.400390625,
      3.578125,
      3.625,
      -2.015625,
      0.92578125,
      -4.78125,
      1.921875,
      -1.140625,
      1.5,
      -1.4921875,
      0.59375,
      -1.296875,
      -2.171875,
      -4.03125,
      2.65625,
      -0.71875,
      -0.306640625,
      3.953125,
      -1.2265625,
      0.54296875,
      2.265625,
      -1.3203125,
      -0.412109375,
      0.29296875,
      -1.8671875,
      1.125,
      0.6640625,
      4.03125,
      1.5859375,
      2.5,
      -2.359375,
      -2.078125,
      -1.9140625,
      -3.578125,
      1.4921875,
      -2.140625,
      -0.6640625,
      2.125,
      -3.09375,
      0.7421875,
      -2.265625,
      -0.1982421875,
      -2.125,
      1.0625,
      -3.78125,
      3.703125,
      2.515625,
      -4.34375,
      5,
      0.04638671875,
      -2.5,
      0.04052734375,
      1.1484375,
      0.455078125,
      -2.90625,
      1.9609375,
      1.3984375,
      -3.125,
      -3.328125,
      2.875,
      -1.7578125,
      -0.21484375,
      -2.625,
      3.4375,
      -1.28125,
      0.2314453125,
      2.65625,
      5.8125,
      0.1953125,
      -3.796875,
      1.921875,
      -4.8125,
      3.90625,
      0.396484375,
      -1.109375,
      1.3828125,
      -1.8125,
      1.5703125,
      0.5390625,
      1.796875,
      -8.4375,
      -2.296875,
      -0.024658203125,
      0.984375,
      2.703125,
      -0.1572265625,
      0.85546875,
      -0.9375,
      1.0390625,
      -3.296875,
      0.2578125,
      3.65625,
      -2.171875,
      -3.453125,
      -0.375,
      0.5625,
      -5.40625,
      2,
      2.5625,
      -0.1015625,
      3.421875,
      0.89453125,
      -1.46875,
      -1.0546875,
      -1.1171875,
      -2.671875,
      2.625,
      -0.59765625,
      -1.1015625,
      3.203125,
      -1.1640625,
      -1.6171875,
      3.453125,
      -0.091796875,
      -6.9375,
      0.8359375,
      0.384765625,
      -2.5625,
      1.5,
      -1.328125,
      2.484375,
      -0.97265625,
      1.5390625,
      -4.75,
      5.28125,
      3.28125,
      -7.46875,
      2.75,
      -2.890625,
      -0.8359375,
      -0.0228271484375,
      -5.5,
      -1.703125,
      6.3125,
      1.4921875,
      4.75,
      3.21875,
      -2.109375,
      0.061279296875,
      3.0625,
      -2.703125,
      -2.953125,
      2,
      0.71875,
      -1.3828125,
      1.28125,
      2.828125,
      3.265625,
      0.6953125,
      0.474609375,
      5.25,
      -3.15625,
      0.75390625,
      3.96875,
      3.859375,
      0.90625,
      -0.9453125,
      -2.390625,
      1.015625,
      -1.8515625,
      -3.0625,
      0.40234375,
      -0.578125,
      2.6875,
      -3.5625,
      0.46875,
      -0.9296875,
      -4.96875,
      -2.078125,
      -1.953125,
      -2.109375,
      0.25,
      0.56640625,
      1.9140625,
      -2.71875,
      -0.8671875,
      2.859375,
      2.34375,
      1.0078125,
      -5.1875,
      3.25,
      -1.4140625,
      -4,
      1.1328125,
      3.984375,
      -1.953125,
      -3.0625,
      1.234375,
      -1.96875,
      -0.004791259765625,
      -1.4609375,
      -1.265625,
      3.296875,
      -3.53125,
      1.828125,
      -3.5625,
      -5.125,
      1.546875,
      2.328125,
      -3.671875,
      -4.4375,
      -0.431640625,
      -2.046875,
      -2.09375,
      -5.21875,
      0.859375,
      0.431640625,
      0.20703125,
      3.796875,
      -1.3984375,
      2.125,
      0.77734375,
      -4.03125,
      -8.125,
      7.28125,
      4.8125,
      0.77734375,
      -4.0625,
      3.34375,
      -2.015625,
      5.84375,
      5.625,
      -3.4375,
      -0.82421875,
      -0.5625,
      -3.828125,
      -4.75,
      -2.65625,
      -0.96875,
      -0.66796875,
      -2.984375,
      5.625,
      -1.390625,
      5.875,
      0.76953125,
      -0.87109375,
      0.10888671875,
      0.94921875,
      4.6875,
      -0.67578125,
      0.75,
      1.1328125,
      -3.109375,
      -2,
      -1.3984375,
      0.349609375,
      -0.953125,
      4.46875,
      -3.375,
      0.2001953125,
      6.46875,
      1.4453125,
      1.546875,
      -2.4375,
      -2.296875,
      2.328125,
      -1.609375,
      -2.0625,
      0.004913330078125,
      -0.365234375,
      2.1875,
      -4.59375,
      -0.03564453125,
      -4.71875,
      3.40625,
      0.66796875,
      3.796875,
      0.93359375,
      -1.0546875,
      -1.125,
      -1.328125,
      -0.1240234375,
      1.5859375,
      -0.5078125,
      4.21875,
      2.34375,
      0.8515625,
      1.046875,
      -3.296875,
      -2.140625,
      1.8125,
      3.6875,
      -3.671875,
      -2.5,
      0.032470703125,
      -2.78125,
      -0.396484375,
      2.203125,
      1.3671875,
      -0.47265625,
      1.09375,
      0.08251953125,
      0.59765625,
      1.4609375,
      0.1240234375,
      -3.15625,
      -4.59375,
      1.6484375,
      3.15625,
      -5.65625,
      3.3125,
      -1.625,
      0.6640625,
      -0.51953125,
      4.59375,
      1.09375,
      -0.24609375,
      -0.8125,
      2.734375,
      -1.7265625,
      -1.015625,
      -0.1591796875,
      -0.10595703125,
      -0.5859375,
      -0.78515625,
      -0.94921875,
      -0.125,
      -0.7734375,
      0.671875,
      0.035888671875,
      -1.0546875,
      -1.1328125,
      -0.130859375,
      0.296875,
      -3,
      1.5625,
      2.4375,
      1.8359375,
      0.4921875,
      -2.96875,
      0.9453125,
      2.140625,
      0.75390625,
      0.07373046875,
      0.34765625,
      2.140625,
      -2.171875,
      -2.59375,
      8.9375,
      -0.86328125,
      -0.5390625,
      2.265625,
      -0.057861328125,
      1.1171875,
      -1.8515625,
      -3.859375,
      0.72265625,
      -3.015625,
      -0.380859375,
      -2.140625,
      0.33984375,
      -1.171875,
      -3.703125,
      -1.5,
      1.171875,
      -2.765625,
      -0.6640625,
      -1.640625,
      -3.421875,
      -1.4375,
      -0.484375,
      -0.76171875,
      3.625,
      -1.640625,
      -2.40625,
      0.5625,
      2.46875,
      1.828125,
      -0.51171875,
      -0.5625,
      0.70703125,
      -1.53125,
      1.8515625,
      0.15234375,
      -0.2412109375,
      4.59375,
      -2.21875,
      0.474609375,
      1.2890625,
      0.88671875,
      0.38671875,
      -1.28125,
      1.8046875,
      2.140625,
      -0.03076171875,
      2.15625,
      -2.15625,
      2.34375,
      5.46875,
      -0.6953125,
      -0.40234375,
      1.71875,
      -2.578125,
      2.515625,
      0.275390625,
      -1.3046875,
      3.3125,
      -0.76953125,
      -5.78125,
      -3.703125,
      -4.5625,
      -2.9375,
      1.1875,
      -0.462890625,
      1.921875,
      -2.078125,
      -2.859375,
      1.6328125,
      2.484375,
      -0.404296875,
      -1.25,
      -1.859375,
      0.5234375,
      2.0625,
      -0.5859375,
      0.5546875,
      0.75,
      4.3125,
      -0.408203125,
      -1.359375,
      1.1171875,
      1.234375,
      -2.09375,
      0.66796875,
      -0.56640625,
      -1.046875,
      -1.078125,
      -3.015625,
      -0.1103515625,
      -1.4453125,
      3.078125,
      0.2236328125,
      0.1787109375,
      -0.9921875,
      -0.9140625,
      -4.125,
      -0.67578125,
      -1.796875,
      0.0257568359375,
      -0.81640625,
      0.34765625,
      0.040771484375,
      -0.474609375,
      -2.1875,
      -1.1171875,
      0.361328125,
      0.034423828125,
      -1.625,
      -2.34375,
      -0.4296875,
      -0.85546875,
      -0.64453125,
      -0.0498046875,
      0.0712890625,
      -1.484375,
      1.625,
      0.022216796875,
      0.6328125,
      -1.0546875,
      2.421875,
      -1.5625,
      -0.0751953125,
      -0.26171875,
      -1.84375,
      0.6640625,
      2.6875,
      0.07421875,
      -1.2578125,
      -1.765625,
      1.7109375,
      -0.4453125,
      2.109375,
      -1.1640625,
      1.5390625,
      -0.55859375,
      -2.375,
      -0.70703125,
      -0.5859375,
      3.890625,
      -1.6953125,
      2.984375,
      -3.015625,
      3.265625,
      -1.0859375,
      -3.328125,
      -0.87890625,
      -0.232421875,
      -0.765625,
      1.1328125,
      1.2578125,
      2.40625,
      -0.462890625,
      -4.0625,
      -1.2421875,
      0.5703125,
      2.5625,
      -1.625,
      0.8828125,
      0.181640625,
      -3.125,
      3.5,
      0.69921875,
      -0.000682830810546875,
      -0.80859375,
      -2.421875,
      -0.6328125,
      -4.28125,
      -0.97265625,
      1.7578125,
      -0.7578125,
      -2.0625,
      0.416015625,
      1.3359375,
      1.9140625,
      -0.5859375,
      0.984375,
      0.72265625,
      1.1328125,
      -3.390625,
      -0.50390625,
      -0.392578125,
      0.47265625,
      -3.0625,
      -3.1875,
      -0.59765625,
      3.203125,
      -1.375,
      -3.59375,
      -2.015625,
      -3.859375,
      -1.53125,
      0.1259765625,
      -1.1875,
      -0.09326171875,
      1.0546875,
      -2.703125,
      0.2080078125,
      0.15625,
      1.46875,
      1.484375,
      -1.5546875,
      -1.5234375,
      1.6328125,
      1.8203125,
      1.21875,
      0.11962890625,
      -0.189453125,
      -1.3828125,
      0.640625,
      -0.6953125,
      0.376953125,
      -2.109375,
      2.0625,
      -0.058349609375,
      -4.34375,
      1.8828125,
      0.275390625,
      -0.82421875,
      -1.8203125,
      -2.90625,
      2.484375,
      1.8046875,
      3.734375,
      3.25,
      -0.87890625,
      1.7265625,
      4,
      0.6796875,
      0.7421875,
      -0.12890625,
      -6.875,
      1.6328125,
      0.7265625,
      2.75,
      -3.6875,
      1.578125,
      0.400390625,
      6.625,
      -1.4609375,
      -1.359375,
      2.765625,
      -1.0390625,
      2.578125,
      -0.09033203125,
      -0.435546875,
      -4.65625,
      1.359375,
      -2.8125,
      -0.828125,
      1.0078125,
      0.67578125,
      0.9375,
      1.0078125,
      0.08447265625,
      -1.125,
      2.765625,
      3.109375,
      1.5234375,
      -1.5859375,
      1.8046875,
      -0.380859375,
      0.9140625,
      0.54296875,
      -0.79296875,
      -0.408203125,
      -2.359375,
      -0.13671875,
      -0.41796875,
      0.80078125,
      -2.890625,
      -1.4609375,
      -0.2333984375,
      1.3828125,
      4.0625,
      5.09375,
      -3.4375,
      -3.421875,
      -0.2470703125,
      1.5390625,
      -0.021728515625,
      2.890625,
      -0.5234375,
      -1.2421875,
      -1.359375,
      -1.1015625,
      -3.8125,
      0.55078125,
      -2.875,
      -0.177734375,
      -0.8984375,
      -1.6171875,
      -1.3515625,
      5.28125,
      3.21875,
      1.4765625,
      7.15625,
      4.0625,
      4.0625,
      2.4375,
      0.6875,
      5.8125,
      2.46875,
      -2.8125,
      3.921875,
      -1.6875,
      -1.2734375,
      -2,
      -1.65625,
      -0.011474609375,
      0.255859375,
      -1.859375,
      0.29296875,
      0.609375,
      -1.6015625,
      -0.09765625,
      -0.97265625,
      2.546875,
      -4.03125,
      -0.52734375,
      -1.1015625,
      3.21875,
      -1.5078125,
      1.21875,
      0.83203125,
      0.41015625,
      0.0751953125,
      0.064453125,
      3.03125,
      -1.140625,
      -2.765625,
      -1.1875,
      -2.84375,
      -0.7265625,
      -0.70703125,
      0.40234375,
      -2.5,
      -1.0703125,
      3.65625,
      -0.62890625,
      1.9765625,
      -1.9921875,
      -0.9296875,
      0.6796875,
      2.234375,
      0.90234375,
      0.9765625,
      -1.0078125,
      1.796875,
      -3.09375,
      -0.466796875,
      0.1591796875,
      -1.171875,
      -2.359375,
      1.2109375,
      3.078125,
      0.94140625,
      -0.76171875,
      -1.296875,
      -0.87890625,
      -1.375,
      -1.1328125,
      -2.6875,
      -0.3359375,
      -1.0234375,
      -2.828125,
      -0.70703125,
      -0.1123046875,
      0.55859375,
      -2.125,
      -2.203125,
      -1.8046875,
      1.3046875,
      1.3203125,
      1.0546875,
      -1.8046875,
      4.75,
      3.40625,
      2.234375,
      2.328125,
      -2.234375,
      -0.78125,
      1.7421875,
      -1.3046875,
      -0.0634765625,
      1.5546875,
      -1.09375,
      1.171875,
      0.341796875,
      -0.921875,
      1.6875,
      2.546875,
      1.7890625,
      1.5,
      -1.890625,
      5.5625,
      0.96875,
      0.6953125,
      0.4609375,
      -2.078125,
      -0.8203125,
      0.283203125,
      1.75,
      -0.10107421875,
      -0.60546875,
      -1.78125,
      1.5546875,
      1.328125,
      -1.1796875,
      -0.87890625,
      -1.671875,
      -1.0078125,
      0.06396484375,
      -1.328125,
      2.265625,
      2.21875,
      0.1875,
      0.78125,
      -5.1875,
      1.15625,
      -1.0234375,
      1.296875,
      0.431640625,
      0.3984375,
      -1.203125,
      1.390625,
      1.4453125,
      -4.34375,
      -3.671875,
      1.484375,
      1.1796875,
      -1.5,
      -2.125,
      -0.9296875,
      -0.318359375,
      2.28125,
      5.21875,
      1.1015625,
      3.8125,
      -0.6796875,
      -1.984375,
      0.51171875,
      -0.97265625,
      -1.6015625,
      0.5078125,
      -0.68359375,
      1.078125,
      -0.0947265625,
      0.486328125,
      0.412109375
    ],
    "summary": "将推荐系统多利益相关者公平性建模为“先分配后聚合”的两阶段社会选择问题，通过多智能体博弈动态权衡不同公平准则与个性化需求。",
    "structure": {
      "sections": [
        {
          "title": "Dynamic Fairness-aware Recommendation Through Multi-agent Social Choice",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ACM Reference Format:",
          "level": 1,
          "start_line": 25
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 37
        },
        {
          "title": "2 Related Work",
          "level": 1,
          "start_line": 53
        },
        {
          "title": "3 Example",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "3.1 Agents",
          "level": 1,
          "start_line": 83
        },
        {
          "title": "3.2 Loans",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "3.3 Mechanisms",
          "level": 1,
          "start_line": 103
        },
        {
          "title": "3.4 Users",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "4 Formalizing Fairness Concerns",
          "level": 1,
          "start_line": 129
        },
        {
          "title": "4.1 Fairness Agents",
          "level": 1,
          "start_line": 159
        },
        {
          "title": "4.2 Recommendation Process",
          "level": 1,
          "start_line": 169
        },
        {
          "title": "5 The SCRUF-D Architecture",
          "level": 1,
          "start_line": 177
        },
        {
          "title": "5.1 Overview",
          "level": 1,
          "start_line": 181
        },
        {
          "title": "5.2 Formal Description",
          "level": 1,
          "start_line": 204
        },
        {
          "title": "6 Design Considerations",
          "level": 1,
          "start_line": 230
        },
        {
          "title": "6.1 Agent Design",
          "level": 1,
          "start_line": 234
        },
        {
          "title": "6.2 Agent Efficacy",
          "level": 1,
          "start_line": 244
        },
        {
          "title": "6.3 Mechanism Inputs",
          "level": 1,
          "start_line": 252
        },
        {
          "title": "6.4 Agent Priority",
          "level": 1,
          "start_line": 258
        },
        {
          "title": "6.5 Bossiness",
          "level": 1,
          "start_line": 266
        },
        {
          "title": "6.6 Fairness Types",
          "level": 1,
          "start_line": 270
        },
        {
          "title": "7 Experimental Methodology",
          "level": 1,
          "start_line": 276
        },
        {
          "title": "7.1 Data sets",
          "level": 1,
          "start_line": 280
        },
        {
          "title": "7.2 Fairness metrics",
          "level": 1,
          "start_line": 305
        },
        {
          "title": "7.3 Mechanisms",
          "level": 1,
          "start_line": 311
        },
        {
          "title": "7.4 Choice Mechanisms (Voting Rules)",
          "level": 1,
          "start_line": 319
        },
        {
          "title": "7.5 Baseline algorithms",
          "level": 1,
          "start_line": 335
        },
        {
          "title": "7.6 Evaluation",
          "level": 1,
          "start_line": 349
        },
        {
          "title": "8 Results",
          "level": 1,
          "start_line": 367
        },
        {
          "title": "8.1 MovieLens dataset",
          "level": 1,
          "start_line": 371
        },
        {
          "title": "8.2 Microlending dataset",
          "level": 1,
          "start_line": 408
        },
        {
          "title": "8.3 Fairness dynamics",
          "level": 1,
          "start_line": 445
        },
        {
          "title": "9 Conclusion and Future Work",
          "level": 1,
          "start_line": 460
        },
        {
          "title": "Acknowledgments",
          "level": 1,
          "start_line": 490
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 494
        }
      ]
    },
    "tags": [
      "推荐系统",
      "算法公平",
      "多智能体"
    ],
    "suggested_tags": [
      "推荐系统",
      "算法公平",
      "多智能体",
      "社会选择"
    ],
    "tag_suggestions": [
      {
        "name": "推荐系统",
        "confidence": 0.98,
        "reason": "全文围绕个性化推荐系统的公平性展开，是论文的核心研究对象"
      },
      {
        "name": "算法公平",
        "confidence": 0.97,
        "reason": "提出动态、多利益相关者的公平性框架，解决推荐场景下的公平定义与实现问题"
      },
      {
        "name": "多智能体",
        "confidence": 0.92,
        "reason": "将推荐公平形式化为多智能体社会选择的两阶段问题，采用多智能体系统视角"
      },
      {
        "name": "社会选择",
        "confidence": 0.9,
        "reason": "用分配+聚合的社会选择模型统一刻画多利益相关者公平，为方法核心"
      }
    ],
    "tags_confirmed": true,
    "category": "推荐系统",
    "s2_graph": {
      "citations": [],
      "citations_fetched_at": "2025-12-17T14:04:55.490732",
      "references": [],
      "references_fetched_at": "2025-12-17T14:04:56.164121"
    }
  },
  "a7a677b6-fa0d-4923-8e5f-2960eea6e02d": {
    "id": "a7a677b6-fa0d-4923-8e5f-2960eea6e02d",
    "filename": "agentscourt-building-judicial-decision-making-agents-with-court-debate-simulation-and-legal-knowledge-augmentation.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/a7a677b6-fa0d-4923-8e5f-2960eea6e02d_agentscourt-building-judicial-decision-making-agents-with-court-debate-simulation-and-legal-knowledge-augmentation.pdf",
    "status": "completed",
    "created_at": "2025-12-17 14:05:16.195302",
    "updated_at": "2025-12-17 06:06:50.156885",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
    "markdown_content": "# AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation\n\nZhitao He $^{1,2}$ , Pengfei Cao $^{1,2}$ , Chenhao Wang $^{1,2}$ , Zhuoran Jin $^{1,2}$ , Yubo Chen $^{1,2}$ , Jiexin Xu $^{3}$ , Huaijun Li $^{3}$ , Xiaojian Jiang $^{3}$ , Kang Liu $^{1,2}$ , Jun Zhao $^{1,2}$\n\n<sup>1</sup> The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China\n\n$^{2}$  School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China\n\n$^{3}$  AI Lab, China Merchant Bank, ShenZhen, China\n\n{zhitao.he, pengfei.cao, yubo.chen, kliu, jzhao}@nlpr.ia.ac.cn\n\n# Abstract\n\nWith the development of deep learning, natural language processing technology has effectively improved the efficiency of various aspects of the traditional judicial industry. However, most current efforts focus on tasks within individual judicial stages, making it difficult to handle complex tasks that span multiple stages. As the autonomous agents powered by large language models are becoming increasingly smart and able to make complex decisions in real-world settings, offering new insights for judicial intelligence. In this paper, (1) we propose a novel multi-agent framework, AgentsCourt, for judicial decision-making. Our framework follows the classic court trial process, consisting of court debate simulation, legal resources retrieval and decision-making refinement to simulate the decision-making of judge. (2) we introduce SimuCourt, a judicial benchmark that encompasses 420 Chinese judgment documents, spanning the three most common types of judicial cases. Furthermore, to support this task, we construct a large-scale legal knowledge base, Legal-KB, with multi-resource legal knowledge. (3) Extensive experiments show that our framework outperforms the existing advanced methods in various aspects, especially in generating legal articles, where our model achieves significant improvements of  $8.6\\%$  and  $9.1\\%$  F1 score in the first and second instance settings, respectively.\n\n# 1 Introduction\n\nRecent advances in deep learning have significantly impacted the legal domain, with notable achievements in legal question answering (Zhong et al., 2020b; Khazaeli et al., 2021; Cui et al., 2023), legal case retrieval (Sugathadasa et al., 2019; Shao et al., 2020; Li et al., 2023b; Shao et al., 2023) and legal judgment prediction (Xiao et al., 2018; Chalkidis et al., 2019; Wu et al., 2022, 2023b). These developments have effectively alleviated the long-\n\n# John Smith Case of Theft\n\nCase type: Criminal\n\nCause of Action: Theft\n\n# Case Details (Input)\n\nPlaintiff: Prosecutor's Office\n\nDefendant: John Smith\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/f13d531c22bea933dc2a11698513d45aa7b59106d6cd0bac7f0741af2bc54c07.jpg)\n\nBackground of the defendant: In 2017, John Smith was sentenced by a certain People's Court to seven months in prison for theft, and ...\n\nDetermine facts: During July and August of 2023, the defendant, John Smith, drove to the workshop yard of a certain company 11 times, stealing a total of over 4.28 tons of aluminum scrap ...\n\nIndictment: Upon appraisal, the involved aluminum scrap was valued at 74,700 RMB. The prosecutor's office charges the defendant with theft and suggests sentencing the defendant to three years of fixed-term imprisonment and imposing a fine of 20,000 RMB ...\n\nThe point of defense lawyer: Upon apprehension, the defendant, John Smith, fully confessed to the crimes as detailed above. Subsequent to the offense, the defendant's family has fully restituted the proceeds ...\n\nThe point of the defendant: John Smith does not dispute the facts and charges alleged in the indictment but claims to have actively cooperated with the investigation and requests leniency in sentencing ...\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/064dfeacb5d486a440bb5188adfd8e1a588cca9f78929a8dd0d0f44ec6ba374f.jpg)\n\n# Judicial Decision-Making (Output)\n\nThe court holds that the defendant, John Smith, has repeatedly stolen citizens' property, ..., and should be severely punished. The charges brought by the prosecutor's office are established. After being apprehended, the defendant truthfully confessed to his crimes ... The defense attorney's reasonable ... Case analysis\n\nIn conclusion, based on Article 64, Paragraph 3 of Article 67, Article 264 of the Criminal Law of the People's Republic of China, and Article 15 of the ... Legal Articles\n\nThe judgment is as follows: the defendant is found guilty of theft and is hereby sentenced to three years and eight months of fixed-term imprisonment, and fined 10,000 RMB.\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/6c655c23f08f568df7fc0141091e2db716b4bba94d3a5acb495b7c48e9860c80.jpg)\n\nFigure 1: We formulate the Judicial Decision-Making task using the real-world judgement documents: given the case details above, judge agent must 1) conduct a logically clear case analysis; 2) provide precise legal articles; 3) issue a definitive judgement.\n\nstanding issue in the judicial industry of \"too many cases, too few legal professionals\". However, case trial is a coherent process involving multiple stages such as court debates, case analysis, and legal judgment prediction. The complexity of this process demands close collaboration and interaction between stages. Although current research has made progress in individual stages, it often overlooks the inherent connections between these stages of the trial process. This results in the need to rely on the deep involvement of legal experts when dealing\n\n<table><tr><td>Framework</td><td>AgentsCourt (This work)</td><td>LaWGPT (Song et al., 2023)</td><td>PLJP (Wu et al., 2023b)</td><td>HRN (Lyu et al., 2023)</td><td>RLJP (Wu et al., 2022)</td></tr><tr><td>Case Analysis</td><td>✓</td><td>✓</td><td>✗</td><td>✗</td><td>✓</td></tr><tr><td>Precedent Retrieval</td><td>✓</td><td>✗</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>Web Research</td><td>✓</td><td>✗</td><td>✗</td><td>✗</td><td>✗</td></tr><tr><td>Court Simulation</td><td>✓</td><td>✗</td><td>✗</td><td>✗</td><td>✗</td></tr><tr><td>Judgement Prediction</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Legal Articles Generation</td><td>Multiple</td><td>Single</td><td>Single</td><td>Single</td><td>Single</td></tr><tr><td>Case Type</td><td>Various</td><td>Various</td><td>Crime</td><td>Crime</td><td>Crime</td></tr></table>\n\nTable 1: A comparison of our AgentsCourt to notable legal domain frameworks.\n\nwith complex judicial decisions. Meanwhile, autonomous agents based on large language models (LLMs) have shown considerable progress in various traditional natural language processing (NLP) tasks (Brown et al., 2020; Wei et al., 2022; Wang et al., 2023; Qian et al., 2023; Wu et al., 2023a) and making decisions in real-world environments (Yao et al., 2023; Richards, 2023; Chen et al., 2023), which offers new insights for judicial intelligence.\n\nHowever, simulating judicial decision-making is a non-trivial task because agents must navigate complex situations involving multiple stakeholders, understand the subtle nuances of legal provisions, and consider ethical and social justice factors. This presents three unique challenges to the agent system: (1) Intricate ethical relationships. In judicial decision, ethical and moral considerations, which are often subtle and multi-faceted, must be taken into account.(2) Expert knowledge of judicial domain. Judicial adjudication requires an in-depth understanding and accurate application of specialized knowledge such as laws, regulations and precedents. (3) Complex and hybrid reasoning. The agents must be capable of handling a complex amalgamation of logical, factual, and legal reasoning, often interwoven in cases.\n\nTo tackle the aforementioned challenges, we propose a novel multi-agent framework, AgentsCourt, for the Judicial Decision-Making task. As illustrated in Figure 1, given the case details, the task requires the agent to conduct a logically clear case analysis, provide precise legal articles and issue a definitive judgement. AgentsCourt follows the classic court trial process: opening remarks, court debate, precedent retrieval, and judgement, as depicted in Figure 2. Specifically, we first develop a Court Debate Simulation Module with three agents, which serves as a platform for all parties involved to present their points to clarify the intricate ethical relationships in the case. One agent serves as the judge to open a court session and announce the\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/ce948c8392963f330a8b47a0414056f1646a54b18da1ebb2a0d083d236848c9c.jpg)  \nFigure 2: Simplified court trial process.\n\nbasic facts of the case. The other two agents are designed as the plaintiff and the defendant respectively, and articulate their points of view during the court debate phase. Then, we devise the Legal Resources Retrieval Module to address the inadequacy of expert knowledge. This module employs a judge assistant agent to integrate the most relevant precedents, articles and other information retrieved from the knowledge base we constructed and the internet. Next, we propose the Decision-Making Refinement Module to facilitate complex and hybrid reasoning. This module firstly makes a preliminary judgement according to the inherent judicial expertise of the agent elicited by the established facts of current case and the transcripts of court debate, then subsequently refines the judgement using legal information retrieved.\n\nThe comparison between our framework and prior works is listed in Table 1. It is worth noting that our framework is not tailored to a specific legal system. AgentsCourt can achieve court simulation, precedent retrieval, judgment prediction, and supports the generation of multiple legal articles for practical judicial practice.\n\nWe also introduce SimuCourt, a judicial benchmark designed to evaluate Agent-as-Judge across a spectrum of different cases. SimuCourt encompasses 420 Chinese judgement documents, spanning the three most common types of judicial cases — criminal, civil, and administrative — in both first-instance and second-instance (appellate) courts, as well as covering three key societal roles: government agencies, the prosecutor's office, and individuals. Specifically, criminal cases involve acts\n\nthat are identified as violations of criminal law, such as theft. Civil cases typically involve disputes between individuals, such as contract disputes or torts. Administrative cases concern disputes between individuals and government agencies. All the cases come from the China Judgements Online<sup>1</sup>, which is an official platform established by the Supreme People's Court of China, aimed at publicly releasing the judgement documents of courts at all levels in China. Furthermore, we construct a large-scale legal knowledge base, Legal-KB, to support this domain task. It encompasses a variety of legal knowledge, including effective laws and regulations, highly cited judicial papers, and precedents from recent years. The use of real data allows the agents developed on it can be transferred into real applications without any gaps.\n\nWe summarize our contributions as follows:\n\n- We propose a novel multi-agent framework AgentsCourt. Given the basic information of a case, our framework can sequentially simulate court debate, retrieve precedents, analyze cases, provide legal articles, and deliver clear judgment. The new judicial paradigm simplifies the process of making judicial decisions, significantly enhancing judicial efficiency.  \n- We introduce SimuCourt, a judicial benchmark encompasses the three most common types of cases, enabling reliable assessment of the judicial analysis and decision-making power of agents for real judicial practice. Furthermore, we construct a legal knowledge base, Legal-KB, with multi-resource legal knowledge to support this task.  \n- We perform extensive experiments and ablation studies. The results indicate that our framework outperforms the existing advanced methods in various aspects, especially in generating legal articles, where our system achieves notable improvements of  $8.6\\%$  and  $9.1\\%$  F1 score in the first and second instance experimental settings, respectively.\n\n# 2 Related Work\n\nLegal Artificial Intelligence Legal Artificial Intelligence seeks to improve legal tasks by employing artificial intelligence techniques (Surden, 2019; Zhong et al., 2020a; Katz et al., 2023). With the\n\ncontinuous development of deep learning, the legal field has witnessed the emergence of more intelligent applications across various legal tasks. These tasks span across areas such as legal judgment prediction (LJP) (Xiao et al., 2018; Zhong et al., 2018; Xu et al., 2020; Yue et al., 2021; Wu et al., 2022, 2023b), legal question answering (Zhong et al., 2020b; Cui et al., 2023; Louis et al., 2024; Fei et al., 2023), legal language understanding (Chalkidis et al., 2022; Xiao et al., 2021; Niklaus et al., 2023; Yu et al., 2023), legal case retrieval (Sugathadasa et al., 2019; Shao et al., 2020; Li et al., 2023b; Shao et al., 2023), legal document summarization (Kanapala et al., 2019; Jain et al., 2023, 2024). While these existing efforts have made progress in individual legal tasks, they have overlooked the interconnection between different tasks, resulting in the necessity to heavily rely on the deep involvement of legal experts when dealing with complex judicial decisions. In this work, we focus on completing the entire process of judicial decision-making through multi-agent collaboration.\n\nMulti-agent framework Cooperation among agents like human group dynamics can enhance the efficiency and effectiveness of task accomplishment. Li et al. (2023a) enables two communicative agents to engage in a conversation and cooperate with each other to solve assigned tasks. Park et al. (2023) found social behaviors autonomously emerge within a group of agents. Qian et al. (2023); Hong et al. (2023) present innovative paradigms that leverages LLMs throughout the entire software development process by natural language communication. Du et al. (2023); Zhang et al. (2023); He et al. (2023); Chen et al. (2023); Wu et al. (2023a) further leverage multi-agent cooperation to achieve better performance on multiple tasks.\n\n# 2.1 Task Formulation\n\nWe propose a generative task to evaluate agent as judge. Specifically, as shown in Figure 1, we formulate the Judicial Decision-Making task as given the case details of a case, such as Determine facts, Complaint/Indictment, Statement of the plaintiff and the defendant, the agent system needs to make a complete judicial decision, which includes a clear and reasonable case analysis, rigorous legal articles, and definitive final judgement. SimuCourt encompasses two experimental settings:\n\nFirst Instance This setting refers to the trial court level, where the judge determines the guilt of the defendant, and assesses whether punitive\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/40932b1ae6c21d347be2fff1cb0532961a304206264961ee244a398f14ae8e64.jpg)  \nFigure 3: Overview of our multi-agent framework. The Court Debate Simulation Module recreates the court debate process through role-playing, mining different parties' points from limited real records. TheLegal Resources Retrieval Module employ an assistant agent to integrate information retrieved. The Decision-Making Refinement Module exploit the inherent judicial expertise of the judge agent and refines the judgment using information retrieved.\n\nmeasures are warranted. Within this setting, the primary focus is on evaluating the agent's understanding and analysis of case facts.\n\nSecond Instance This setting refers to the appellate court level. During this stage, the judge re-evaluates the case, considering new evidence. The objective at this stage is to ensure the legality and fairness of the initial judgement, identifying legal errors or inappropriate application of regulations from the first instance and demonstrating the capability to effectively handle new evidence.\n\n# 3 The AgentsCourt Framework\n\nWe propose a novel multi-agent framework, as shown in Figure 3. Our framework is based on real-world court trial process and aims to study the collaboration of multiple agents, as well as how they contribute to judicial decision-making.\n\n# 3.1 Court Debate Simulation\n\nThe court debate provides a platform for all parties involved to present their points and arguments comprehensively and fairly, which can significantly influence the judgement of the case.\n\nCourt Simulation Due to the majority of judgement documents only recording the key points of the plaintiff's and defendant's statements, obtaining complete court transcripts is challenging. Fortunately, as large language models have shown re\n\nmarkable ability in role-playing (Li et al., 2023a; Qian et al., 2023; Chen et al., 2023), in this module, we aim to reconstruct the court debate with multiple agents for each case. We set up three agents to play the roles of the judge, plaintiff, and defendant respectively. For each agent, we carefully design an role-playing prompt to build their character personality and use the actual statements from judgment documents as the their starting prompts. It is worth noting that due to the limited record of statements in judgment documents, we combine the plaintiff and their representative, as well as the defendant and their representative, into the plaintiff and defendant, respectively, without setting separate roles for representatives.\n\nCourt Debate In this stage, both the plaintiff and the defendant need to present their arguments in line with their interests. The plaintiff should vigorously argue their complaint, articulating their stance and reasoning. Meanwhile, the defendant must defend their actions, aiming to prove their innocence or seek a lighter penalty. During the court session, the judge agent first delivers opening remarks, which include basic information about the plaintiff and the defendant, determination of facts, and so on. Then, the trial moves into the court debate stage and the communication between the agents will be recorded as court transcripts. We present an example of court transcripts in Table 12.\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/86af19e735c01375b74f2751327d16753c556d8fe97f14945b39e0279f3c3a57.jpg)  \nFigure 4: Automatic retrieval of precedents.\n\n# 3.2 Legal Resources Retrieval\n\nCourt debate serves as a platform to thoroughly explore the facts and contentious issues within a case, making the judge better comprehend the complexity of the matter. Furthermore, to make accurate judicial decisions, judges must possess extensive legal knowledge and case information.\n\nJudge Assistant We assign an agent as judge assistant who is responsible for accessing the internet and the knowledge base. In terms of internet information acquisition, the assistant can use web research to seek open information, such as \"Does the case have any public opinion?\" This aids the judge in understanding the societal impact of the case and potential public perspectives. Ultimately, the agent organizes the retrieved news, comments to the judge, supporting the judge in making rational and well-founded judicial decisions.\n\nAutomatic Information Retrieval In terms of knowledge base retrieval, as presented in Figure 4, the assistant first predict the type of case based on the determine facts of the current case. Due to the vast number of documents in the knowledge base, and the fact that cases with the same cause often have more similar keywords, we employs the BM25 model (Lin et al., 2021) for efficient rough retrieval to obtain the top 100 documents from the knowledge base. Building on this, we further utilize the BGE-Large model (Xiao et al., 2023) to encode and re-rank these retrieved documents and choose the most relevant document to the current case as the optimal precedent. Additionally, to obtain more comprehensive laws and regulations relevant to the current case without introducing additional context, the judge assistant extracts the corresponding legal articles from the top 5 precedents as related legal provisions of current case.\n\n# 3.3 Judgement Refinement\n\nIn this module, we first exploit the inherent judicial expertise of the agent by utilizing determine facts of current case and transcripts of court debate to make a preliminary judgment. Then, the judge agent refines the judgment using information retrieved.\n\nPreliminary Judgement As shown in the bottom of Figure 3, after receiving the determine facts of current case and transcripts of simulated court debate, the judge agent takes the action of analysis, then provides its legal articles and subsequently reaching a preliminary judgement.\n\nJudgement Refinement After obtaining the preliminary judgement which involves analyzing the specific details of the case, the judge agent uses precedent and relevant legal information from the assistant to refine the its judgement and provide the final judgement. This includes but is not limited to analyzing the precedent, referring to legal regulations and considering opinions of public.\n\n# 4 The SimuCourt Benchmark\n\nThe task, Judicial Decision-Making, requires agents to conduct case analysis, generate legal articles and judgments. However, most existing legal datasets suffer from several limitations when it comes to assessing the Agent-as-Judge paradigm: 1) only contain the factual information of cases; 2) only focus on criminal cases; 3) only evaluate judgments. To this end, we propose SimuCourt, a judicial benchmark for a reliable assessment of the judicial analysis and decision-making power of agents. A comparison between our dataset and previous works is presented in Table 2.\n\n# 4.1 Data Collection\n\nWe collect 420 real-world cases from the China Judgements Online, which span across two fundamental trial stages: first instance and second instance. These cases encompass three types: criminal, civil, and administrative. For first-instance cases, each sample includes the indictment, the point of the defendant, determine facts, etc. For second-instance cases, each sample contains petition for appeal, the point of the appellant and appellation, etc. Detailed list and data examples can be found in the Appendix C. Most of cases were released after April 2023. This minimizes the risk of data leakage<sup>2</sup>. Detailed data statistics of SimuCourt are shown in Table 3. Furthermore, our dataset undergo rigorous scrutiny, ensuring the accuracy and completeness of the legal texts and information. Details of data collection and quality inspection can be found in Appendix D.\n\n<table><tr><td>Resource</td><td>SimuCourt</td><td>CAIL</td><td>SLJA-SYN</td></tr><tr><td>Background of Defendant?</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>Statement of Different Parties?</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>Multi-article Scenario?</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>Case Analysis Evaluation?</td><td>✓</td><td>✗</td><td>✓</td></tr><tr><td>Judgement Evaluation</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Laws Involved?</td><td>443</td><td>1</td><td>1</td></tr><tr><td>Case Retrival?</td><td>6.5M</td><td>2.6M</td><td>✗</td></tr><tr><td>Various Case Types?</td><td>Crime, Civial, Admini.</td><td>Crime</td><td>Crime</td></tr><tr><td>Different Instances Involved?</td><td>First/Second</td><td>First</td><td>First</td></tr></table>\n\nTable 2: A comparison of our SimuCourt to remarkable legal domain datasets. CAIL (Xiao et al., 2018) is a widely used legal judgment prediction dataset, where each case comes with a fact description; SLJA-SYN (Deng et al., 2023) is a comprehensive legal dataset designed to support multiple tasks such as article retrieval, article interpretation generation, criminal element generation and legal judgment prediction.  \n\n<table><tr><td>Feature</td><td>Criminal</td><td>Civil</td><td>Administrative</td></tr><tr><td># of Cases</td><td>140</td><td>140</td><td>140</td></tr><tr><td># of Causes of action</td><td>44</td><td>51</td><td>33</td></tr><tr><td>Avg # of Legal articles</td><td>6.3</td><td>3.3</td><td>1.6</td></tr><tr><td>Max # of Legal articles</td><td>11</td><td>10</td><td>8</td></tr><tr><td>Total # of Legal articles</td><td>198</td><td>153</td><td>92</td></tr><tr><td>Avg. Length of Facts</td><td>468.7</td><td>487.5</td><td>673.3</td></tr><tr><td>Avg. Length of Analysis</td><td>346.3</td><td>486.1</td><td>722.7</td></tr><tr><td>Avg. Length of Cases</td><td>2362.6</td><td>2473.8</td><td>3315.5</td></tr></table>\n\n# 4.2 Legal Knowledge Base Construction\n\nTo make accurate judicial decisions, judges must possess extensive legal knowledge. Furthermore, given the diversity and complexity of human society, each case may involve different facts, parties, and locations. To this end, we construct a large scale legal knowledge base consists of laws, regulations, judicial interpretation, journal articles, and precedents. Detailed data statistics of Legal-KB are shown in Table 4.\n\nLaws, Regulations and Judicial interpretations We download various legal documents from the National Laws and Regulations Database of China<sup>3</sup>, an authoritative resource for legal information that includes national laws, administrative regulations, local regulations, and judicial interpretations. We remove legal documents that are no longer in effect. Journal Articles Journal articles, typically authored by legal experts, can provide in-depth analysis and unique perspectives on specific legal issues. We collect highly-cited journal articles from 2010 to 2023 from the Chinese Legal Resources Knowledge Database<sup>4</sup>.\n\nTable 3: Statistics of SimuCourt. Length is measured via the number of words  \n\n<table><tr><td>Type</td><td>Num</td><td>Tokens</td><td>Avg. Tokens</td></tr><tr><td>Laws and Regulations</td><td>9K</td><td>66M</td><td>7390</td></tr><tr><td>Journal Articles</td><td>29K</td><td>15M</td><td>521</td></tr><tr><td>Precedents</td><td>6.5M</td><td>27.1B</td><td>4111</td></tr></table>\n\nTable 4: Statistics of our legal knowledge base.\n\nPrecedents We collect all judgement documents of criminal, civil and administrative cases from the China Judgements Online for the years 2017 to 2022. However, as illustrated in Figure 9 in the Appendix, the data exhibits a significant long-tail distribution. To balance the type of case, we limit the number of cases for each cause of action to no more than  $20\\mathrm{k}$ . For those causes of action with more cases, we retain only the top  $20\\mathrm{k}$  cases with the longest text as representatives of complex cases.\n\n# 5 Experiments\n\n# 5.1 Automatic Evaluation\n\nAs example data illustrated in Table 11, the legal articles and judgement are concise and structured. Therefore, we propose corresponding metrics for legal articles and judgement evaluation.\n\nLegal Articles Evaluation The correct legal articles is crucial for a fair judgment. Thus, we employ the strict matching method to assess the legal articles generated by the agent system. Specifically, we calculate the number of entries that match and do not match between the legal articles list of the agent system and the reference legal articles list. These counts are then micro-averaged to determine the overall precision, recall and F1 scores. Details can be found in Table 13.\n\nJudgement Evaluation for Civil and Administrative Cases The judgment of each civil or administrative case may encompass multiple results. While each result typically revolves around a single key point, it may involve specific monetary amounts and interest rate information. Consequently, traditional text matching methods based on similarity struggle to accurately capture these key points. Thus, we employ GPT-4 as an evaluator. Specifically, we separately count the number of matching and non-matching key points in the agent system's judgment results compared to the reference judgment results. The micro-averaged counts are used to calculate the overall precision, recall and F1 scores. Details is presented in Table 14.\n\nJudgement Evaluation for Criminal Cases Different from other cases, the sentence of criminal\n\n<table><tr><td rowspan=\"3\" colspan=\"2\">Model</td><td rowspan=\"2\" colspan=\"3\">Legal Articles</td><td colspan=\"5\">Judgement Results</td><td rowspan=\"2\" colspan=\"3\">Case Analysis</td><td></td></tr><tr><td colspan=\"3\">Civil and Admini.</td><td colspan=\"2\">Criminal</td><td></td></tr><tr><td>P</td><td>R</td><td>F</td><td>P</td><td>R</td><td>F</td><td>Charge</td><td>Prison term</td><td>Fine</td><td>Correctness</td><td>Logicality</td><td>Concision</td></tr><tr><td rowspan=\"6\">First</td><td>GPT-3.5</td><td>0.127</td><td>0.109</td><td>0.117</td><td>0.367</td><td>0.498</td><td>0.423</td><td>0.822</td><td>0.253</td><td>0.412</td><td>0.466</td><td>0.510</td><td>0.493</td></tr><tr><td>GPT-4</td><td>0.139</td><td>0.133</td><td>0.136</td><td>0.398</td><td>0.559</td><td>0.465</td><td>0.875</td><td>0.287</td><td>0.462</td><td>0.503</td><td>0.553</td><td>0.543</td></tr><tr><td>ReAct</td><td>0.161</td><td>0.109</td><td>0.131</td><td>0.387</td><td>0.532</td><td>0.448</td><td>0.866</td><td>0.262</td><td>0.437</td><td>0.516</td><td>0.567</td><td>0.533</td></tr><tr><td>AutoGPT</td><td>0.171</td><td>0.123</td><td>0.143</td><td>0.392</td><td>0.543</td><td>0.455</td><td>0.862</td><td>0.275</td><td>0.450</td><td>0.523</td><td>0.576</td><td>0.520</td></tr><tr><td>LaWGPT</td><td>0.183</td><td>0.105</td><td>0.133</td><td>0.414</td><td>0.548</td><td>0.471</td><td>0.875</td><td>0.237</td><td>0.425</td><td>0.506</td><td>0.546</td><td>0.533</td></tr><tr><td>AgentsCourt</td><td>0.219</td><td>0.189</td><td>0.203</td><td>0.437</td><td>0.603</td><td>0.507</td><td>0.887</td><td>0.337</td><td>0.500</td><td>0.550</td><td>0.596</td><td>0.526</td></tr><tr><td rowspan=\"6\">Second</td><td>GPT-3.5</td><td>0.206</td><td>0.169</td><td>0.186</td><td>0.317</td><td>0.429</td><td>0.365</td><td>0.716</td><td>0.166</td><td>0.516</td><td>0.496</td><td>0.540</td><td>0.526</td></tr><tr><td>GPT-4</td><td>0.200</td><td>0.267</td><td>0.228</td><td>0.356</td><td>0.482</td><td>0.409</td><td>0.800</td><td>0.183</td><td>0.533</td><td>0.530</td><td>0.583</td><td>0.576</td></tr><tr><td>ReAct</td><td>0.209</td><td>0.235</td><td>0.221</td><td>0.364</td><td>0.457</td><td>0.405</td><td>0.800</td><td>0.150</td><td>0.516</td><td>0.526</td><td>0.586</td><td>0.570</td></tr><tr><td>AutoGPT</td><td>0.217</td><td>0.248</td><td>0.231</td><td>0.371</td><td>0.478</td><td>0.417</td><td>0.816</td><td>0.166</td><td>0.550</td><td>0.540</td><td>0.590</td><td>0.583</td></tr><tr><td>LaWGPT</td><td>0.225</td><td>0.231</td><td>0.227</td><td>0.382</td><td>0.472</td><td>0.422</td><td>0.850</td><td>0.133</td><td>0.483</td><td>0.503</td><td>0.553</td><td>0.566</td></tr><tr><td>AgentsCourt</td><td>0.271</td><td>0.284</td><td>0.277</td><td>0.400</td><td>0.528</td><td>0.456</td><td>0.833</td><td>0.200</td><td>0.583</td><td>0.583</td><td>0.633</td><td>0.593</td></tr></table>\n\nTable 5: Overall performance of our framework and baselines in the first and second instance experimental settings.\n\ncase typically include three core elements: charge, prison term, and fine. The determination of the charge must match the facts of the case. The specific amounts of the prison term and fines are based not only on the facts but also take into account the defendant's performance in court, including their attitude towards the crime and the defense they present for their actions. We calculate the accuracy of the agent system separately for these three items.\n\n# 5.2 Human Evaluation\n\nThe case analysis entails intricate logical reasoning and ethical considerations that are challenging to evaluate through automatic metrics or GPT-4. For each setting, we present a panel of three graduate students majoring in law a random sample of 100 entries from each setting and the following binary True/False criteria guidelines: 1) Correctness: Mark true if and only if the analysis is satisfying and considers all parties involved. 2) Logicality: Mark false if the analysis contains any illogical or untrue reasoning. 3) Concision: Mark true if the analysis covers all necessary information without any extra information.\n\n# 5.3 Baselines\n\nVanilla We employ gpt-3.5-turbo-1106 and gpt-4-1106-preview with few-shot as vanilla models. Furthermore, due to limited budget, we only use the gpt-3.5-turbo-1106 as foundation models of all agent systems.\n\nReAct (Yao et al., 2023) This system enables the agent to improve its actions based on the outcomes of past activities like searches or tool usage.\n\nAutoGPT (Richards, 2023) This is the most advanced agents framework, incorporating a variety\n\nof tools and prompts designed to facilitate the automatic planning and execution of specified tasks.\n\nLaWGPT (Song et al., 2023) This is currently the most popular Chinese legal large language model, which has undergone extensive pretraining on Chinese legal corpora and fine-tuning on legal instructions, based on the general Chinese foundation model (Chinese-LLaMA-7B). It possesses strong capabilities in understanding and generating legal content.\n\n# 5.4 Main Results\n\nAs shown in Table 5, our framework outperforms other models in all aspects. For the evaluation on legal articles, our proposed framework achieved performance improvements of  $8.6\\%$  and  $9.1\\%$  in the two experimental settings, respectively. In contrast, GPT-4's performance in the first and second instance settings only reach  $13.6\\%$  and  $22.8\\%$ , respectively. This not only indicates significant shortcomings in the capabilities of LLMs in sourcing legal provisions, but also reflects the high challenge of our benchmark. In terms of judgment results evaluation, while all models performed well in the conviction of criminal cases, there is still a significant gap in determining prison term and fines compared to standard results. Furthermore, although the analysis of these systems has shown a certain degree of logicality, there is still room for improvement in terms of correctness and concision.\n\n# 5.5 Discussion and Analysis\n\nLegal Knowledge of LLMs As indicated in Figure 5, all three language models exhibit excellent performance on the simple task of predicting case\n\n<table><tr><td rowspan=\"2\">Model</td><td rowspan=\"2\">Legal Articles</td><td colspan=\"4\">Judgement Results</td></tr><tr><td>Civil and Admini.</td><td>Charge</td><td>Prison term</td><td>Fine</td></tr><tr><td>SimuCourt</td><td>0.203</td><td>0.507</td><td>0.887</td><td>0.337</td><td>0.500</td></tr><tr><td>w/o Court simulation</td><td>0.171</td><td>0.473</td><td>0.875</td><td>0.300</td><td>0.462</td></tr><tr><td>w/o Knowledge base</td><td>0.145</td><td>0.462</td><td>0.850</td><td>0.312</td><td>0.475</td></tr><tr><td>w/o Web search</td><td>0.196</td><td>0.488</td><td>0.865</td><td>0.325</td><td>0.487</td></tr></table>\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/a80620a24690083d6c6317472bf2ca9cf53baaa24dc1c664306adc5eda943a52.jpg)  \nFigure 5: Legal knowledge evaluation of LLMs.\n\ntypes. However, their performance is less impressive on the challenging task of predicting case reasons, the GPT-4 model achieves only  $35.4\\%$  accuracy, while LaWGPT, which has undergone extensive pre-training with professional knowledge, achieves only  $43.7\\%$ . For the task of article generation, the performance of all models is poor, with LaWGPT sometimes producing garbled output, resulting in even worse performance.\n\nMulti-agent Court Simulation The results of the ablation experiments, as shown in Table 6 in Appendix, demonstrate that our designed court debate simulation module effectively enhances the accuracy of judicial decisions. We further investigate the specific impact of this module on the prison term and fines in criminal case judgements. As depicted in Figure 6, it is evident that the absolute difference in prison term and fines significantly diminishes following the simulation of court debates.\n\nDifficulty of Distinct Types of Cases Table 7 presents the results of our framework in generating legal articles across different types of cases in the first instance setting. The agent system produces more reliable legal articles in criminal cases, while its use and understanding of relevant legal statutes in civil and administrative cases are no-\n\nTable 6: Ablation study of our framework in the first instance setting.  \n\n<table><tr><td>Case type</td><td>Precision</td><td>Recall</td><td>F1 Score</td></tr><tr><td>All</td><td>0.219</td><td>0.189</td><td>0.203</td></tr><tr><td>Criminal</td><td>0.489</td><td>0.264</td><td>0.343</td></tr><tr><td>Civil</td><td>0.073</td><td>0.063</td><td>0.067</td></tr><tr><td>Administrative</td><td>0.126</td><td>0.250</td><td>0.167</td></tr></table>\n\nTable 7: Legal articles evaluation of AgentsCourt.\n\ntably weaker. This observation may be attributed to the fact that the civil and administrative cases involve more complex issues, with multiple vested interests, such as contract disputes, family matters, or government decisions, requiring a deeper understanding of legal and social knowledge.\n\nLegal knowledge base With the support of an external knowledge base, the performance of agent system in judicial reasoning improved significantly, with an increase of up to  $6.2\\%$ . The achievements are also attributed to our designed automatic retrieval module. As shown in Table 8 in Appendix A, through the rough retrieval, the most similar cases only have a  $62\\%$  consistency in the cause of action with the current cases. However, after the documents re-ranking, the consistency of the cause of action between retrieved cases and the current cases increased to  $85\\%$ . This improvement proves the effectiveness of our retrieval module.\n\n# 6 Conclusion\n\nWe propose a novel multi-agent framework AgentsCourt, which can sequentially simulate court debate, retrieve precedents, analyze cases, provide legal articles, and deliver clear judgment. Furthermore, we introduce SimuCourt, a judicial benchmark to evaluate the judicial analysis and decision-making power of agents. Then, we perform experiments to analyze different modules. The new judicial paradigm we presented effectively simulates the judicial decision-making with multi-agent, which significantly enhances judicial efficiency.\n\n# 7 Limitation\n\nIn this paper, we introduce a novel judicial benchmark SimuCourt. After thorough analysis, our work still presents the following limitations:\n\n- Our data only includes Chinese documents from \"China Judgments Online.\" Despite our framework, AgentsCourt not being specifically designed for the civil law system, testing the agent system with real data from different legal systems is important.  \n- The judgement documents cover the three most common types of cases: criminal, civil, and administrative. Including a broader range of case types in the future would evaluate the judicial analysis and decision-making power of agents more comprehensively.  \n- Although our database contains a large number of precedents and legal resources, experimental results have shown that overall performance of agent systems is still unsatisfactory.\n\nWe look forward to further exploring the potential of the legal knowledge base in future studies.\n\n# References\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.  \nIlias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. 2019. Neural legal judgment prediction in english. arXiv preprint arXiv:1906.02059.  \nIlias Chalkidis, Abhik Jana, Dirk Hartung, Michael Bommarito, Ion Androutsopoulos, Daniel Katz, and Nikolaos Aletras. 2022. LexGLUE: A benchmark dataset for legal language understanding in English. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 4310-4330, Dublin, Ireland. Association for Computational Linguistics.  \nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, et al. 2023. Agent-verse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. arXiv preprint arXiv:2308.10848.  \nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li Yuan. 2023. Chatlaw: Open-source legal large language model with integrated external knowledge bases. arXiv preprint arXiv:2306.16092.\n\nWentao Deng, Jiahuan Pei, Keyi Kong, Zhe Chen, Furu Wei, Yujun Li, Zhaochun Ren, Zhumin Chen, and Pengjie Ren. 2023. Syllogistic reasoning for legal judgment analysis. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 13997-14009.  \nYilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. Improving factuality and reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325.  \nZhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Songyang Zhang, Kai Chen, Zongwen Shen, and Jidong Ge. 2023. Lawbench: Benchmarking legal knowledge of large language models. arXiv preprint arXiv:2309.16289.  \nZhitao He, Pengfei Cao, Yubo Chen, Kang Liu, Ruopeng Li, Mengshu Sun, and Jun Zhao. 2023. Lego: A multi-agent collaborative framework with role-playing and iterative feedback for causality explanation generation. In *Findings of the Association for Computational Linguistics: EMNLP* 2023, pages 9142-9163.  \nSirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. 2023. Metagpt: Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352.  \nDeepali Jain, Malaya Dutta Borah, and Anupam Biswas. 2023. Bayesian optimization based score fusion of linguistic approaches for improving legal document summarization. Knowledge-Based Systems, 264:110336.  \nDeepali Jain, Malaya Dutta Borah, and Anupam Biswas. 2024. A sentence is known by the company it keeps: Improving legal document summarization using deep clustering. Artificial Intelligence and Law, 32(1):165-200.  \nAmbedkar Kanapala, Sukomal Pal, and Rajendra Pamula. 2019. Text summarization from legal documents: a survey. Artificial Intelligence Review, 51:371-402.  \nDaniel Martin Katz, Dirk Hartung, Lauritz Gerlach, Abhik Jana, and Michael J Bommarito II. 2023. Natural language processing in the legal domain. arXiv preprint arXiv:2302.12039.  \nSoha Khazaeli, Janardhana Punuru, Chad Morris, Sanjay Sharma, Bert Staub, Michael Cole, Sunny Chiu-Webster, and Dhruv Sakalley. 2021. A free format legal question answering system. In Proceedings of the Natural Legal Language Processing Workshop 2021, pages 107-113.  \nGuohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023a. Camel: Communicative agents for\" mind\" exploration of large scale language model society. arXiv preprint arXiv:2303.17760.\n\nHaitao Li, Qingyao Ai, Jia Chen, Qian Dong, Yueyue Wu, Yiqun Liu, Chong Chen, and Qi Tian. 2023b. Sailer: structure-aware pre-trained language model for legal case retrieval. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1035-1044.  \nJimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Zheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira. 2021. Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations. In Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021), pages 2356-2362.  \nAntoine Louis, Gijs van Dijck, and Gerasimos Spanakis. 2024. Interpretable long-form legal question answering with retrieval-augmented large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 22266-22275.  \nYoungang Lyu, Jitai Hao, Zihan Wang, Kai Zhao, Shen Gao, Pengjie Ren, Zhumin Chen, Fang Wang, and Zhaochun Ren. 2023. Multi-defendant legal judgment prediction via hierarchical reasoning. arXiv preprint arXiv:2312.05762.  \nJoel Niklaus, Veton Matoshi, Pooja Rani, Andrea Galassi, Matthias Stürmer, and Ilias Chalkidis. 2023. Lextreme: A multi-lingual and multi-task benchmark for the legal domain. arXiv preprint arXiv:2301.13126.  \nJoon Sung Park, Joseph C O'Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442.  \nChen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software development. arXiv preprint arXiv:2307.07924.  \nToran Bruce Richards. 2023. Autogpt - the next evolution of data driven chat ai. https://auto-gpt.ai/.  \nYunqiu Shao, Jiaxin Mao, Yiqun Liu, Weizhi Ma, Ken Satoh, Min Zhang, and Shaoping Ma. 2020. Bert-pei: Modeling paragraph-level interactions for legal case retrieval. In *IJCAI*, pages 3501–3507.  \nYunqiu Shao, Yueyue Wu, Yiqun Liu, Jiaxin Mao, and Shaoping Ma. 2023. Understanding relevance judgments in legal case retrieval. ACM Transactions on Information Systems, 41(3):1-32.  \nPengxiao Song, Yixuan Jin, and Zhi Zhou. 2023. LaWGPT. https://github.com/pengxiao-song/LaWGPT.  \nKeet Sugathadasa, Buddhist Ayesha, Nisansa de Silva, Amal Shehan Perera, Vindula Jayawardana, Dimuthu Lakmal, and Madhavi Perera. 2019. Legal document\n\nretrieval using document vector embeddings and deep learning. In Intelligent Computing: Proceedings of the 2018 Computing Conference, Volume 2, pages 160-175. Springer.  \nHarry Surden. 2019. Artificial intelligence and law: An overview. Georgia State University Law Review, 35:19-22.  \nLei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. arXiv preprint arXiv:2305.04091.  \nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837.  \nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. 2023a. Autogen: Enabling next-gen llm applications via multiagent conversation framework. arXiv preprint arXiv:2308.08155.  \nYiquan Wu, Yifei Liu, Weiming Lu, Yating Zhang, Jun Feng, Changlong Sun, Fei Wu, and Kun Kuang. 2022. Towards interactivity and interpretability: A rationale-based legal judgment prediction framework. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 4787-4799.  \nYiquan Wu, Siying Zhou, Yifei Liu, Weiming Lu, Xiaozhong Liu, Yating Zhang, Changlong Sun, Fei Wu, and Kun Kuang. 2023b. Precedent-enhanced legal judgment prediction with llm and domain-model collaboration. arXiv preprint arXiv:2310.09241.  \nChaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun. 2021. Lawformer: A pre-trained language model for chinese legal long documents. AI Open, 2:79-84.  \nChaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng, Xianpei Han, Zhen Hu, Heng Wang, et al. 2018. Cait2018: A large-scale legal dataset for judgment prediction. arXiv preprint arXiv:1807.02478.  \nShitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff. 2023. C-pack: Packaged resources to advance general chinese embedding.  \nNuo Xu, Pinghui Wang, Long Chen, Li Pan, Xiaoyan Wang, and Junzhou Zhao. 2020. Distinguishing law articles for legal judgment prediction. arXiv preprint arXiv:2004.02557.  \nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2023. ReAct: Synergizing reasoning and acting in language models. In International Conference on Learning Representations (ICLR).\n\nFangyi Yu, Lee Quartey, and Frank Schilder. 2023. Exploring the effectiveness of prompt engineering for legal reasoning tasks. In *Findings of the Association for Computational Linguistics: ACL* 2023, pages 13582-13596, Toronto, Canada. Association for Computational Linguistics.\n\nLinan Yue, Qi Liu, Binbin Jin, Han Wu, Kai Zhang, Yanqing An, Mingyue Cheng, Biao Yin, and Dayong Wu. 2021. Neurjudge: A circumstance-aware neural framework for legal judgment prediction. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 973-982.\n\nHongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. 2023. Building cooperative embodied agents modularly with large language models. arXiv preprint arXiv:2307.02485.\n\nHaoxi Zhong, Zhipeng Guo, Cunchao Tu, Chaojun Xiao, Zhiyuan Liu, and Maosong Sun. 2018. Legal judgment prediction via topological learning. In Proceedings of the 2018 conference on empirical methods in natural language processing, pages 3540-3549.\n\nHaoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, and Maosong Sun. 2020a. How does NLP benefit legal system: A summary of legal artificial intelligence. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5218-5230, Online. Association for Computational Linguistics.\n\nHaoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, and Maosong Sun. 2020b. Jecqa: a legal-domain question answering dataset. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 9701-9708.\n\n# A Retrieval Module\n\nAs shown in Table 8, through the rough retrieval and documents re-ranking, the consistency of the cause of action between retrieved cases and the current cases increased to  $85\\%$ .\n\n# B Example of Court Transcript\n\nWe present an example of court transcript simulated by multi-agent debate in Table 12.\n\n# C Data Demonstration\n\nThe detailed list is presented in Table 10. Furthermore, we show examples of the first-instance stage in Figure 7 and second-instance stage in Figure 8, respectively.\n\n# D Data Analysis\n\n# D.1 Data Description\n\nOur choice of cases is driven by three reasons: (1) Diversity of causes of action. Based on our statistical analysis of data from the China Judgements Online over the past few years, we observed a significant long-tail distribution in various types of cases. For example, as shown in Figure 9, in the total civil cases of 2022, the top 15 causes of action accounted for  $66\\%$  of the total number of cases. To reflect a broader spectrum of legal practice, we focus on maintaining diversity in the types of causes of action; (2) Clarity of case analysis and facts. We have meticulously selected judgement documents that provide detailed case analysis and clear determine facts for annotation. This aim is to enhance the quality and accuracy of data annotation while aiding agents in better understanding the judicial reasoning and legal articles; (3) Uniqueness and accuracy of judgements. We prioritize cases that are not overturned in appellate review. This ensures the consistency of our evaluation, as these cases have already undergone a rigorous litigation process and the judgements are fair.\n\n# D.2 Data Quality Inspection\n\nWe first process the privacy information of all documents. Specifically, We have meticulously anonymized sensitive information in the judgement documents. Then, After completing data annotation and handling private information, we manually inspect the data quality from various aspects.\n\nPrivacy Information Processing: We have meticulously anonymized sensitive information in the judgement documents. In addition to replacing personal names, place names, and institution names with generic terms, we also anonymize other details that could potentially disclose personal privacy, such as ID numbers, phone numbers, and addresses, to ensure the safety of personal privacy.\n\nManual Inspection: After completing data annotation and handling private information, we manually inspect the quality of SimuCourt: (1) Case Meeting Standards. The selected samples need to include clear case analysis and facts and have not been overturned in the appellate stage. (2) Accurate Information Annotation. Annotation should ensure the accurate and error-free extraction of key information from the original legal documents, including case analysis, legal articles, and judgement. (3) Privacy Information Security. In order to safe\n\n<table><tr><td>Precedents</td><td>Rough retrieval</td><td>+ Re-ranking</td></tr><tr><td>Top1</td><td>62%</td><td>85%</td></tr><tr><td>Top2</td><td>60%</td><td>82%</td></tr><tr><td>Top3</td><td>61%</td><td>80%</td></tr></table>\n\nTable 8: Cause of action matching  \n\n<table><tr><td>Criteria</td><td>Pass Rate</td></tr><tr><td>Case Meeting Standards</td><td>98.6%</td></tr><tr><td>Accurate Information Extraction</td><td>95.8%</td></tr><tr><td>Privacy Information Security</td><td>100%</td></tr><tr><td>Average</td><td>98.1%</td></tr></table>\n\nTable 9: Data quality analysis.\n\nguard individual privacy and security, it is crucial to ensure that each data entry does not contain any content that could potentially disclose sensitive information about the parties involved. We employ three graduate students to manually review all 420 annotated cases. By carefully scrutinizing, our dataset exhibits a high level of quality. Specific quality metrics and analysis results are shown in Table 9.\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/b9c50203d76da36abff6c94b4f00142ade63cf573c470777106404ed4bc040a7.jpg)  \nFigure 6: The absolute difference change.\n\n# E Details of Automatic Evaluation\n\n# E.1 Legal Articles Evaluation\n\nWe start by using pattern matching to parse the free text, followed by a hard match against specific legal provisions. For example, as shown in Table 13. Then, with TP (True Positives) = 2, FP (False Positives) = 1, FN (False Negatives) = 2, the corresponding Precision = 2/3, and Recall = 2/4.\n\n# E.2 Judgement Evaluation for Civil and Administrative Cases\n\nWe utilize GPT-4 to assess the judgment results generated by the model in civil and administrative cases. As shown in Table x, we present an evaluation example, which is also a prompt demonstration for GPT-4.\n\n# John Smith Case of Theft\n\nCase type: Criminal\n\nCause of Action: Theft\n\n# Case Details (First Instance)\n\nPlaintiff: Prosecutor's Office\n\nDefendant: John Doe\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/495bde191deeb50326a990db5acd247bc71f200f72bbba6ed96490f236cfe075.jpg)\n\nBackground of the defendant: In January 2017, John Doe was sentenced by a certain People's Court to seven months in prison for theft; In October 2017, John Doe was sentenced to seven ...\n\nDetermine facts: During July and August of 2023, the defendant, John Doe, drove to the workshop yard of a certain company 11 times, stealing a total of over 4.28 tons of aluminum scrap, and later sold the stolen goods for over 53,000 yuan ...\n\nIndictment: Upon appraisal, the involved aluminum scrap was valued at 74,700 RMB. The prosecutor's office charges the defendant with theft and suggests sentencing the defendant to three years of fixed-term imprisonment and imposing a fine of 20,000 RMB ...\n\nThe point of defense lawyer: Upon apprehension, the defendant, John Doe, fully confessed to the crimes as detailed above. Subsequent to the offense, the defendant's family has fully restituted the proceeds ...\n\nStatement of the defendant: John Doe does not dispute the facts and charges alleged in the indictment but claims to have actively cooperated with the investigation and requests leniency in sentencing ...\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/e78d59ef84c804c3273780b86830cd5db469aab52f564aca48d84882e1dcd492.jpg)\n\n# Judicial Decision-Making (Output)\n\nThe court holds that the defendant, John Doe, has repeatedly stolen citizens' property, ..., and should be severely punished. The charges brought by the prosecutor's office are established. After being apprehended, the defendant truthfully confessed to his crimes ... The defense attorney's reasonable plea for leniency for the defendant is accepted ... Case analysis\n\nIn conclusion, based on Article 64, Paragraph 3 of Article 67, Article 264 of the Criminal Law of the People's Republic of China, and Article 15 of the ... Legal Articles\n\nThe judgment is as follows: the defendant is found guilty of theft and is hereby sentenced to three years and eight months of fixed-term imprisonment, and fined 10,000 RMB.\n\nCase analysis\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/d3892ce5471e6b891adec3ba6e87f84ddbe69b06dcb8fbb1e580078c65539261.jpg)\n\nLegal Articles\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/8a917379d5dcefec8def1811a7985f65fd265e53e0b445e5199d6a3c13d557ee.jpg)\n\nJudgement\n\nFigure 7: An example case of first-instance stage (translated from Chinese).\n\n# John Smith Case of Intentional Injury\n\nCase type: Criminal\n\nCause of Action: Intentional injury\n\n# Case Details (First Instance)\n\nAppellant: John Smith (original defendant)\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/591d7bf8ef66ab29ca9c56b97fed9f061c7ef60e919667dae8adb8fade851e85.jpg)\n\nAppellee: Prosecutor's Office\n\nBackground of the appellant: In July 2010, John Smith was sentenced to two years in prison for robbery and was released upon completing his sentence in December 2012.\n\nDetermine facts in the first instance: The defendant John Smith, in August 2022 had a verbal dispute with Emily Taylor (the victim, female, 52 years old) over debt issues. John Smith dragged Emily Taylor to the ground. According to judicial appraisal, Emily Taylor suffered ...\n\nJudicial analysis in the first instance: The first-instance court determined that the defendant John Smith intentionally caused bodily harm to another person, resulting in minor injuries ...\n\nLegal articles of the first instance: Article 234, paragraph 1, Article 67, paragraph 1, Article 45, and Article 47 of the Criminal Law of the People's Republic of China.\n\nJudgement of the first instance: The defendant John Smith was convicted of the crime of intentional injury and sentenced to six months of imprisonment.\n\nPetition for appeal: The original defendant John Smith appealed. The appellant John Smith's grounds for appeal are that during the debt collection process, the victim Emily Taylor tore and insulted the appellant, showing fault. According to the law, the appellant's criminal responsibility should be mitigated. Since the first instance did not recognize this, the appellant requests ...\n\nThe point of the appellant: 1. The appellant does not dispute the criminal facts and charges determined in the first instance, and voluntarily admits guilt; 2. The company operated by the appellant John Smith pays an annual tax of over 3 million yuan, which has stimulated local economic development ... ; 3. The incident in this case occurred suddenly and was not the intention of the appellant. The victim demanded wages, and the appellant has already compensated the victim with 80,000 yuan, obtaining the victim's forgiveness. Therefore, the appellant requests that the second instance change the judgment to probation for the appellant.\n\nThe point of the appellee: The first-instance court found that the facts of John Smith's intentional injury were clear, the evidence was solid and sufficient, the application of the law was correct, and the conviction and sentencing were accurate. The appellant's grounds for appeal lack factual and legal basis. It is recommended that the second-instance court uphold ...\n\nDetermine facts in the second instance: Upon review during the second instance, it was confirmed that the facts of John Smith's intentional injury, as determined in the original verdict, were clear. During the second instance, the appellant's defense counsel provided a \"petition\" from company employees, demonstrating John Smith's good behavior on normal occasions.\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/7b0fa1a0a753b77d075134cea84353b6735b1dc17b5334ce07be7b87fe4fda04.jpg)\n\n# Judicial Decision-Making (Output)\n\nThe court holds that John Smith intentionally caused bodily harm to another person, ... The facts as determined in the first instance were clear, ... After the incident, the appellant John Smith voluntarily surrendered and ... The materials submitted during the second instance demonstrated that the enterprise he operated encountered operational difficulties, resulting in workers' incomes being ... Case analysis\n\nIn conclusion, based on Article 236, paragraph 1, item (ii) of the Criminal Procedure Law of the People's Republic of China, Article 234, ... Legal Articles\n\nThe judgment is as follows: the appellant was convicted of the crime of intentional injury and sentenced to six months' imprisonment, suspended for one year.\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/8b64c3ca0564adccd619ef461b541ee33f8c2d5331049dab8acfc93c9e23f190.jpg)\n\nJudgement\n\nFigure 8: An example case of second-instance stage (translated from Chinese).\n\n<table><tr><td>First instance</td><td>Second instance</td></tr><tr><td>Case type</td><td>Case type</td></tr><tr><td>Cause of Action</td><td>Cause of Action</td></tr><tr><td>Plaintiff</td><td>Appellant</td></tr><tr><td>Defendant</td><td>Appellee</td></tr><tr><td>Background information of the defendant</td><td>Background information of the appellant</td></tr><tr><td>Indictment</td><td>Petition for appeal</td></tr><tr><td>The point of defense lawyer</td><td>The point of the appellant</td></tr><tr><td>The point of the defendant</td><td>The point of the appellant</td></tr><tr><td>Determine facts</td><td>Determine facts in the first instance</td></tr><tr><td>Case analysis</td><td>Judicial analysis in the first instance</td></tr><tr><td>Legal Articles</td><td>Legal articles of the first instance</td></tr><tr><td>Judgement</td><td>Judgement of the first instance</td></tr><tr><td></td><td>Determine facts in the second instance</td></tr><tr><td></td><td>Case analysis</td></tr><tr><td></td><td>Legal Articles</td></tr><tr><td></td><td>Judgement</td></tr></table>\n\nTable 10: Information list of different trial stages.\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/bfe8ab0398dd14f722cbccdad31faa1c77b19b89fe00520391c27d595316a0b0.jpg)  \nFigure 9: Cause of action of civil cases statistics in 2022\n\n<table><tr><td>Cause of action</td><td>Item</td><td>Content</td></tr><tr><td rowspan=\"3\">Theft</td><td>Case analysis</td><td>The court holds that the accused, John Doe, has repeatedly stolen citizens’ property, constituting theft, and should be severely punished. The charges brought by the prosecutor’s office are established. After being apprehended, the accused truthfully confessed to his crimes, voluntarily pleaded guilty, and returned part of the stolen goods, thus is eligible for a lighter punishment according to law. The defense attorney’s reasonable plea for leniency for the accused is accepted.</td></tr><tr><td>Legal articles</td><td>Article 64 of the Criminal Law of the People’s Republic of China; Paragraph 3 of Article 67 of the Criminal Law of the People’s Republic of China; Article 264 of the Criminal Law of the People’s Republic of China; Article 15 of the Criminal Procedure Law of the People’s Republic of China.</td></tr><tr><td>Judgement</td><td>Charge: The defendant is convicted of theft; Prison term: Sentenced to three years and eight months in prison; Fine: Fined ten thousand yuan.</td></tr></table>\n\nTable 11: An example output of criminal case.\n\n<table><tr><td>Role</td><td>Record</td></tr><tr><td>Judge</td><td>(1)Determine facts: On October 10, 2022, the defendant John Smith noticed the victim, David Lee, wearing a pair of gold earrings near a hotel. He then followed David Lee into an alley, and taking advantage of David Lee&#x27;s unawareness, he snatched the pair of gold earrings from behind. After successfully obtaining them, the defendant John Smith fled the scene... (2) Background of the defendant: John Smith was sentenced to six months&#x27; imprisonment by a certain People&#x27;s Court in June 2009 for the crime of theft; John Smith was sentenced to two years&#x27; imprisonment by a certain People&#x27;s Court in December 2010 for the crime of robbery... (3) Court Discipline...The plaintiff and the defendant may now make their statements.</td></tr><tr><td>Plaintiff</td><td>The defendant, John Smith, committed the crime of robbery with the purpose of unlawfully obtaining property from others, involving a considerable amount. His actions violate Article 267 of the Criminal Law of the People&#x27;s Republic of China. The criminal facts are clear, and the evidence is indeed substantial and sufficient. Therefore, he should be held criminally liable for the crime of robbery.</td></tr><tr><td>Defendant</td><td>I admit that the robbery occurred on October 10, 2022, which was an act of impulse. After the incident, I have truthfully confessed my crime. I hope the judge can give me a lenient punishment.</td></tr><tr><td>Plaintiff</td><td>The defendant has previously been sentenced to a term of imprisonment for intentionally committing a crime. If he commits another crime within five years of completing the sentence, he should be sentenced to a term of imprisonment exceeding the original sentence, which constitutes recidivism.</td></tr><tr><td>Defendant</td><td>I deeply acknowledge that my actions have caused adverse effects on society and irreversible losses to the victims. However, I assure the court that I will actively compensate the victims for their losses. I sincerely repent and am willing to accept the court&#x27;s judgment.</td></tr></table>\n\nTable 12: An example of court transcript simulated by multi-agent debate (translated from Chinese).  \n\n<table><tr><td>Reference legal articles</td><td>Generated legal articles</td></tr><tr><td>Article 67, Section 1 of the Criminal Law of the People&#x27;s Republic of China</td><td>Article 67 of the Criminal Law of the People&#x27;s Republic of China</td></tr><tr><td>Article 52 of Criminal Law of the People&#x27;s Republic of China</td><td>Article 53 of the Criminal Law of the People&#x27;s Republic of China</td></tr><tr><td>Article 53 of the Criminal Law of the People&#x27;s Republic of China</td><td>Article 52 of Criminal Law of the People&#x27;s Republic of China</td></tr><tr><td>Article 15 of the Criminal Procedure Law of the People&#x27;s Republic of China</td><td></td></tr></table>\n\nTable 13: A comparison between the reference legal articles and the legal articles generated by the model (translated from Chinese).\n\n<table><tr><td>Reference judgment</td><td>Generated judgment</td></tr><tr><td>Result1: The defendant, Company XYZ, shall return the plaintiff&#x27;s rental deposit of 6000 yuan and the remaining rent of 17025 yuan within five days from the effective date of this judgment.</td><td>Result1: The defendant shall return the deposit of 6000 yuan to the plaintiff.</td></tr><tr><td>Result2: The defendant, Company XYZ, shall pay the plaintiff a penalty of 5950 yuan within five days from the effective date of this judgment.</td><td>Result2: The defendant shall return the remaining rent of 17025 yuan to the plaintiff.</td></tr><tr><td>Result3: The plaintiff&#x27;s other claims are dismissed</td><td></td></tr><tr><td>The analysis by GPT-4:</td><td></td></tr><tr><td>Key Point Match Evaluation</td><td>The standard answer contains 4 key points: the return of the rental deposit of 6000 yuan, the return of the remaining rent of 17025 yuan, the payment of a penalty of 5950 yuan, and the dismissal of other claims. The generated answer&#x27;s &quot;Result 1&quot; matches the first key point (the return of the rental deposit of 6000 yuan), and &quot;Result 2&quot; matches the second key point (the return of the remaining rent of 17025 yuan). Therefore, the score for key point match is 2.</td></tr><tr><td>Answer Accuracy Evaluation</td><td>The generated answer consists of 2 results. The &quot;Result 1&quot; of the generated answer accurately matches one key point without including incorrect information, thus scoring 1 point. Similarly, the &quot;Result 2&quot; of the generated answer accurately matches another key point without including incorrect information, also scoring 1 point. Therefore, the score for accuracy is 2.</td></tr><tr><td>Output Result</td><td>Standard Key Points Count: 4, Key Point Match Score: 2, Generated Answer Results Count: 2, Answer Accuracy Score: 2</td></tr><tr><td>Precision</td><td>Answer Accuracy Score / Generated Answer Results Count = 2/2</td></tr><tr><td>Recall</td><td>Key Point Match Score / Standard Key Points Count = 2/4</td></tr></table>\n\nTable 14: A prompt demonstration for GPT-4 evaluator (translated from Chinese).",
    "arxiv_id": "1906.02059",
    "error_message": null,
    "embedding": [
      0.69921875,
      -0.2265625,
      -1.9453125,
      -3.828125,
      -1.375,
      2.828125,
      -0.75390625,
      -1.375,
      0.412109375,
      2.921875,
      1.328125,
      2.65625,
      2.859375,
      1.0703125,
      0.7109375,
      -1.6640625,
      2.40625,
      -0.50390625,
      0.54296875,
      -7.46875,
      0.77734375,
      3.25,
      0.455078125,
      -5.875,
      4.34375,
      -4.21875,
      2.109375,
      4.1875,
      4.25,
      -1.25,
      6.3125,
      -5.375,
      0.5703125,
      -1.8515625,
      -5.84375,
      -0.162109375,
      -4.40625,
      -1.9453125,
      4.875,
      4.84375,
      -7.625,
      0.396484375,
      1.7109375,
      0.6875,
      -3.578125,
      1.3046875,
      -0.376953125,
      -2.578125,
      -2.375,
      0.052734375,
      -4.75,
      -1.125,
      4.9375,
      0.2333984375,
      4.9375,
      -7.625,
      -7.9375,
      5.28125,
      -5.5625,
      1.65625,
      0.01806640625,
      -0.703125,
      0.9609375,
      1.8515625,
      2.140625,
      2.421875,
      2.578125,
      2.0625,
      0.466796875,
      1.125,
      -2.25,
      -0.57421875,
      5.28125,
      -4.625,
      7.6875,
      6.6875,
      0.27734375,
      1.625,
      -2.328125,
      5.6875,
      -7.09375,
      3.234375,
      2.8125,
      -0.32421875,
      7,
      1.3203125,
      1.7578125,
      -0.734375,
      -3.59375,
      0.9765625,
      -0.890625,
      1.1171875,
      -3.53125,
      -1.1953125,
      3.75,
      2.421875,
      0.859375,
      -1.8828125,
      -4.65625,
      -0.7734375,
      -0.69140625,
      0.240234375,
      0.8125,
      -2.734375,
      -3.390625,
      -2.359375,
      -2.25,
      -8.3125,
      -4.0625,
      -1.8984375,
      0.50390625,
      0.283203125,
      4.4375,
      -1.15625,
      2.890625,
      1.6328125,
      2.3125,
      -4.21875,
      -5.0625,
      -0.7265625,
      1.515625,
      0.82421875,
      0.26953125,
      0.291015625,
      1.828125,
      3.09375,
      -4.6875,
      4.34375,
      3.8125,
      -0.69140625,
      3.046875,
      -2.796875,
      4.28125,
      -2.171875,
      -9.625,
      -2.40625,
      -2.953125,
      1.984375,
      5.9375,
      5.96875,
      -4.4375,
      0.76953125,
      -2.34375,
      -5.625,
      3.34375,
      0.8203125,
      -7.875,
      1.828125,
      2.5625,
      -2.921875,
      -0.41796875,
      -1.265625,
      0.93359375,
      7.375,
      -3.484375,
      -4.90625,
      3.578125,
      2.34375,
      5.375,
      -0.67578125,
      -1.09375,
      2.890625,
      0.51953125,
      1.28125,
      -3.46875,
      -2.6875,
      -4.59375,
      0.68359375,
      3.484375,
      -2.71875,
      1.8046875,
      16.625,
      2.703125,
      -1.2265625,
      1.5390625,
      6.625,
      -3.859375,
      6.1875,
      1.046875,
      2.046875,
      1.125,
      0.0263671875,
      -2.296875,
      3.234375,
      -3.109375,
      1.828125,
      1.5703125,
      -5.25,
      3.78125,
      -2.625,
      -0.85546875,
      3.359375,
      3.046875,
      -0.87890625,
      -2.40625,
      -2.90625,
      3.515625,
      -0.02734375,
      -0.158203125,
      1.5234375,
      0.373046875,
      -9.0625,
      -0.32421875,
      0.353515625,
      -1.640625,
      2.453125,
      4.78125,
      -0.095703125,
      1.2890625,
      1.140625,
      3.109375,
      2.5,
      0.72265625,
      -3.484375,
      5.46875,
      2.078125,
      3.40625,
      -2.75,
      3.828125,
      0.81640625,
      4.84375,
      3.953125,
      2.515625,
      -0.4375,
      0.5390625,
      2.78125,
      3.109375,
      4.46875,
      1.5078125,
      6.0625,
      -0.1328125,
      0.51171875,
      3.734375,
      -3.03125,
      -3.75,
      -3.984375,
      -7.9375,
      -0.25390625,
      -1.046875,
      1.03125,
      -3.953125,
      -4.15625,
      -0.78515625,
      2.609375,
      1.8046875,
      -3.890625,
      -1.0078125,
      -4.84375,
      -2.625,
      -5.9375,
      0.68359375,
      1.828125,
      -7.3125,
      -3.734375,
      1.6015625,
      5.3125,
      0.8125,
      -1.5546875,
      -1.84375,
      -2.921875,
      4.25,
      -2.28125,
      -4.75,
      2.625,
      2.546875,
      -2.21875,
      3.09375,
      -1.171875,
      2.9375,
      1.7421875,
      1.8046875,
      -0.59375,
      -1.265625,
      3.015625,
      -1.015625,
      3.046875,
      0.11328125,
      -6.5,
      0.70703125,
      -4.03125,
      -5.15625,
      -9,
      6.84375,
      -1.9453125,
      2.03125,
      -3.140625,
      1.875,
      9.125,
      -1.8984375,
      11.625,
      5.5625,
      1.578125,
      1.109375,
      -3.03125,
      -5,
      1.8359375,
      -3.046875,
      1.4453125,
      -7.75,
      -2.484375,
      3.578125,
      0.244140625,
      -2.015625,
      1.5390625,
      -2.234375,
      3.984375,
      1.4375,
      -3.0625,
      -0.3515625,
      1.6640625,
      -0.361328125,
      -0.099609375,
      6.4375,
      -4.1875,
      0.6953125,
      -4.53125,
      -2.890625,
      2.546875,
      2.359375,
      -2.625,
      -2.34375,
      -7.78125,
      -2.25,
      -6.3125,
      -2.03125,
      -3.421875,
      2.875,
      -0.6796875,
      3.796875,
      -1.1015625,
      3.671875,
      0.96875,
      -7.5625,
      -7.25,
      10.1875,
      -2.859375,
      2.453125,
      2.46875,
      2.3125,
      5.84375,
      -6.03125,
      -5,
      3.140625,
      -2.015625,
      -4.71875,
      2.296875,
      3.953125,
      1.703125,
      1.1640625,
      -7.625,
      0.19921875,
      2.34375,
      0.5078125,
      1.9765625,
      7.1875,
      -2.671875,
      2.328125,
      0.130859375,
      -2.21875,
      -1.9296875,
      1.5390625,
      -1.9140625,
      8.6875,
      -0.35546875,
      0.51953125,
      -1.546875,
      -3.609375,
      1.84375,
      -1.7109375,
      -0.423828125,
      0.50390625,
      -2.734375,
      2.578125,
      1.2265625,
      1.640625,
      -2.65625,
      1.015625,
      -6.96875,
      -8.75,
      -0.486328125,
      -4.09375,
      -0.5,
      -1.03125,
      -0.69140625,
      1.1875,
      1.4375,
      -0.232421875,
      5.53125,
      6.90625,
      -0.38671875,
      -1.390625,
      3.390625,
      -2.390625,
      2.421875,
      4,
      1.0078125,
      -1.875,
      1.7890625,
      -2.296875,
      -2.265625,
      4.625,
      1.015625,
      0.369140625,
      -1.8046875,
      -2.875,
      0.421875,
      -0.2001953125,
      -7.125,
      -0.3125,
      0.55078125,
      -2.03125,
      2.8125,
      1.1171875,
      -0.91796875,
      0.75,
      4.28125,
      0.62109375,
      3.140625,
      -5.625,
      -4.1875,
      -4.1875,
      3.53125,
      -0.3515625,
      -4,
      1.546875,
      2.28125,
      1.0078125,
      6.21875,
      1.3046875,
      1.90625,
      2.734375,
      -0.59375,
      -4.0625,
      2.421875,
      -3.078125,
      -1.625,
      4.96875,
      -6.25,
      -4.96875,
      1.421875,
      3.015625,
      0.12158203125,
      2.25,
      0.734375,
      -5.5,
      -1.65625,
      1.734375,
      6.34375,
      -0.7265625,
      -2.65625,
      0.85546875,
      0.07568359375,
      -2.765625,
      2.5625,
      3.90625,
      -1.484375,
      -4.125,
      3.46875,
      3.875,
      -0.64453125,
      -2.5,
      -0.46875,
      0.2490234375,
      -0.96484375,
      -0.5,
      -1.9140625,
      -2.65625,
      4.8125,
      4.03125,
      -5.96875,
      -9.375,
      6.8125,
      0.1181640625,
      -0.390625,
      -2.296875,
      0.87890625,
      1.1875,
      0.10498046875,
      -2.953125,
      -6.375,
      -2.484375,
      -3.25,
      0.34375,
      0.1875,
      1.859375,
      0.78125,
      -0.263671875,
      5.46875,
      -0.59765625,
      4.3125,
      1.46875,
      -0.53515625,
      3.921875,
      -6.375,
      1.8125,
      2.671875,
      6.625,
      -2.5625,
      -1.421875,
      2.0625,
      -7.96875,
      -0.5390625,
      -2.125,
      -2.71875,
      -0.88671875,
      3.546875,
      2.875,
      -1.40625,
      -4,
      0.3359375,
      5.0625,
      -1.9375,
      0.61328125,
      4.4375,
      -3.546875,
      -3.859375,
      2.78125,
      3.1875,
      1.3203125,
      -1.875,
      -2.578125,
      0.359375,
      -1.8671875,
      0.2490234375,
      1.8359375,
      -0.1787109375,
      0.0233154296875,
      0.03173828125,
      4.78125,
      6.53125,
      0.1044921875,
      1.7265625,
      -2.5625,
      -3.359375,
      -2.78125,
      -2.046875,
      0.1787109375,
      -2.6875,
      -2.546875,
      0.80078125,
      0.19921875,
      3.453125,
      -3.1875,
      1.0546875,
      -0.50390625,
      0.412109375,
      -1.796875,
      0.91796875,
      1.1328125,
      3.5625,
      2.40625,
      -0.2353515625,
      -0.3671875,
      1.0546875,
      2.765625,
      -1.546875,
      -3.078125,
      -3.421875,
      3.265625,
      0.66015625,
      -2.234375,
      -2.625,
      -0.50390625,
      0.07373046875,
      0.8828125,
      -0.5078125,
      -0.072265625,
      1.9375,
      1.9296875,
      0.48828125,
      2.5,
      4.40625,
      -3.25,
      0.5078125,
      0.953125,
      0.62109375,
      -4.875,
      -6.625,
      -2.65625,
      1.6484375,
      4.53125,
      -1.734375,
      2.4375,
      -2.71875,
      3.75,
      0.6484375,
      0.419921875,
      -14.625,
      1.4375,
      1.1953125,
      -1.9140625,
      -2.203125,
      -3.78125,
      3.1875,
      -3.53125,
      4.21875,
      -0.71484375,
      -0.71875,
      -0.58984375,
      3.46875,
      1.0546875,
      -3.9375,
      5.09375,
      2.078125,
      -3.5,
      3.90625,
      0.5703125,
      -1.4453125,
      0.515625,
      -2.46875,
      1.046875,
      1.8515625,
      5.09375,
      -1.1796875,
      -1.2890625,
      1.96875,
      -4.21875,
      0.8984375,
      1.734375,
      2.25,
      -1.703125,
      2.3125,
      -1.40625,
      4.1875,
      -5.28125,
      4.25,
      0.53515625,
      -6.03125,
      4.125,
      3.984375,
      -2.9375,
      -0.26953125,
      1.4140625,
      -0.3359375,
      5.1875,
      4.375,
      -5.28125,
      -0.4765625,
      -0.6796875,
      1.6875,
      4.5625,
      -2.671875,
      0.2177734375,
      -2.953125,
      3.234375,
      2.609375,
      -2.890625,
      5.78125,
      -0.58984375,
      -3.875,
      -2.078125,
      1.1640625,
      -3.265625,
      0.275390625,
      -0.2431640625,
      1,
      0.2890625,
      -1.390625,
      1.0078125,
      -0.208984375,
      -3.359375,
      -1.671875,
      3.4375,
      -4.03125,
      4.40625,
      -1.1640625,
      -1.546875,
      -0.2392578125,
      -1.109375,
      3.765625,
      1.5078125,
      2.921875,
      2.53125,
      4.34375,
      3.453125,
      -1.8515625,
      6.28125,
      -3.46875,
      -4.09375,
      -1.0703125,
      -1.6328125,
      -3.75,
      0.8359375,
      0.306640625,
      2.203125,
      -1.15625,
      -3.984375,
      -6.53125,
      -6.4375,
      -1.171875,
      1.1796875,
      -0.78515625,
      1.6875,
      -1.8359375,
      3.09375,
      -2.125,
      -1.21875,
      1.09375,
      -2.296875,
      -1.2265625,
      -3.9375,
      0.044189453125,
      -5.96875,
      2.15625,
      5.84375,
      2.90625,
      -3.015625,
      4.65625,
      1.390625,
      -3.890625,
      -0.3984375,
      2.234375,
      -5.34375,
      -0.9453125,
      1.5078125,
      -1.453125,
      -2.328125,
      -5.09375,
      2.65625,
      -2.828125,
      3.84375,
      -0.265625,
      1.125,
      -3.59375,
      -1.6875,
      -2.765625,
      0.076171875,
      -3.484375,
      4.03125,
      2.5,
      -2.3125,
      -2.28125,
      4.21875,
      2,
      -1.0546875,
      1.296875,
      1.53125,
      3.53125,
      2.25,
      1.1953125,
      -0.75390625,
      -6.5625,
      -0.77734375,
      -0.455078125,
      -3.625,
      2.5625,
      -3.921875,
      2.8125,
      3.859375,
      3.671875,
      -3.859375,
      -4.46875,
      4.03125,
      -1.8515625,
      -1.1484375,
      1.0703125,
      2.6875,
      2.453125,
      2.453125,
      2.28125,
      -3.71875,
      -1.7109375,
      1.375,
      0.3046875,
      0.5078125,
      -3.4375,
      1.421875,
      0.28515625,
      7.03125,
      -7.75,
      -5.40625,
      0.11572265625,
      2.734375,
      0.8359375,
      1,
      9.875,
      -1.1796875,
      0.671875,
      -1.09375,
      0.68359375,
      2.5625,
      2.03125,
      -0.86328125,
      -2.0625,
      3.34375,
      2.765625,
      1.40625,
      1.859375,
      -2.40625,
      -0.8828125,
      -2.984375,
      -1.03125,
      -3.859375,
      3.90625,
      -0.796875,
      -2.671875,
      -4.34375,
      -0.1923828125,
      -2.40625,
      4.5,
      5.6875,
      0.455078125,
      1.8984375,
      2.203125,
      3.15625,
      -0.345703125,
      3.59375,
      0.30078125,
      11.4375,
      -1.4765625,
      -5.125,
      3.65625,
      2.3125,
      -2.28125,
      3.015625,
      -6.375,
      -3.828125,
      1.796875,
      3.546875,
      -0.5078125,
      -0.48828125,
      -3.40625,
      -0.98046875,
      3.703125,
      2.125,
      3.625,
      5.59375,
      5.5625,
      0.1845703125,
      0.7109375,
      -2.59375,
      -3.96875,
      -1.2421875,
      -2.484375,
      1.9921875,
      -3.546875,
      1.5703125,
      1.4140625,
      3.921875,
      0.0537109375,
      -2,
      -2.671875,
      5.40625,
      0.90625,
      0.21484375,
      2.28125,
      -0.7265625,
      -1.3984375,
      1.484375,
      4.34375,
      -5.5625,
      0.9921875,
      7.9375,
      4.5,
      -3.125,
      3.234375,
      -0.3515625,
      1.03125,
      -5.96875,
      -2.515625,
      1.3203125,
      -1.078125,
      -2.3125,
      -4.28125,
      -0.486328125,
      1.5703125,
      -4.125,
      2.46875,
      1.0390625,
      -5.75,
      0.384765625,
      1.5,
      -0.0654296875,
      2.375,
      0.6875,
      2.015625,
      1.4375,
      -5.3125,
      -3.171875,
      -3.484375,
      -0.08935546875,
      1.171875,
      -1.2578125,
      2.609375,
      3.40625,
      -0.451171875,
      1.859375,
      -6.375,
      2.640625,
      -2.171875,
      3.953125,
      2.859375,
      -5.28125,
      -0.375,
      -1.9375,
      -9.625,
      -8.0625,
      -1.8046875,
      -1.8828125,
      -0.056884765625,
      -4.0625,
      -1.59375,
      1.234375,
      -3.6875,
      -0.02392578125,
      -2.671875,
      0.119140625,
      4.625,
      -0.400390625,
      1.984375,
      -2.171875,
      2.34375,
      2.53125,
      -2.609375,
      0.130859375,
      -0.87109375,
      2.578125,
      7.875,
      -2.078125,
      -0.25390625,
      -3.09375,
      10.5,
      -0.07373046875,
      4.78125,
      2.671875,
      -0.10791015625,
      -3.796875,
      3.03125,
      1.7109375,
      1.0234375,
      -6,
      -1.1328125,
      -1.96875,
      0.71484375,
      1.2265625,
      -4.4375,
      0.66796875,
      -5.09375,
      -2.390625,
      -1.2109375,
      -2.65625,
      0.80859375,
      4.09375,
      1.8671875,
      5,
      1.6328125,
      2.15625,
      0.69921875,
      -0.0194091796875,
      1.2265625,
      -1.234375,
      2.78125,
      -4.78125,
      2.875,
      0.0791015625,
      -0.064453125,
      -0.462890625,
      0.8671875,
      0.80078125,
      0.08349609375,
      -1.8984375,
      4.6875,
      3.359375,
      1.578125,
      0.64453125,
      3.015625,
      -0.546875,
      -0.546875,
      -2.65625,
      -4.40625,
      2.6875,
      1.2109375,
      0.015380859375,
      -0.166015625,
      -0.8828125,
      -0.6875,
      -2.171875,
      -0.0380859375,
      -10.1875,
      -2.34375,
      -1.953125,
      -2.796875,
      3.546875,
      -2.453125,
      -1.296875,
      3.0625,
      4.4375,
      3.703125,
      4.75,
      0.55078125,
      2.390625,
      1.21875,
      -1.765625,
      5.0625,
      -3.265625,
      1.53125,
      4.6875,
      0.58203125,
      5.03125,
      -1.5703125,
      -2.8125,
      0.9453125,
      -0.2490234375,
      4.4375,
      -2.625,
      0.984375,
      7.875,
      -0.65625,
      0.30078125,
      -1.0234375,
      -2.078125,
      -0.90234375,
      -2.390625,
      -0.51171875,
      6.5625,
      4.90625,
      -3.109375,
      -2.578125,
      -4.0625,
      -0.53125,
      -0.91796875,
      -1.0234375,
      -0.1669921875,
      -1.3515625,
      -0.8515625,
      -0.12109375,
      0.62890625,
      -1.3203125,
      -3.3125,
      -7.09375,
      -1.40625,
      4.84375,
      1.515625,
      1.2265625,
      -1.4921875,
      2.359375,
      -4.15625,
      2.953125,
      0.060546875,
      -5.90625,
      1.3359375,
      3.84375,
      0.25,
      3.6875,
      1.609375,
      2.0625,
      2.578125,
      -2.84375,
      -1,
      -1.65625,
      1.75,
      2.96875,
      -1.328125,
      -1.5078125,
      5.1875,
      2.78125,
      -0.419921875,
      6.8125,
      1.0390625,
      -0.9609375,
      -1.2109375,
      -3.765625,
      -4.4375,
      -1.1953125,
      -1.4140625,
      -0.27734375,
      1.6953125,
      -0.67578125,
      -1.96875,
      3.34375,
      -5.40625,
      5.03125,
      -1.4921875,
      4.65625,
      -1.515625,
      -0.69921875,
      -0.33984375,
      -1.921875,
      1.546875,
      -4.5,
      0.0341796875,
      0.87890625,
      -1.1484375,
      -0.56640625,
      -5.84375,
      0.69140625,
      -1.6484375,
      2.734375,
      3.265625,
      -2.625,
      -0.134765625,
      -4.125,
      -0.3984375,
      -6.9375,
      -5.90625,
      -0.78125,
      0.5546875,
      -1.6640625,
      -0.66015625,
      -0.81640625,
      -3.109375,
      4.1875,
      -2.625,
      0.2451171875,
      -1.7578125,
      2.15625,
      1.671875,
      -1.2109375,
      6.75,
      4.5625,
      -5.34375,
      1.046875,
      -2.515625,
      -4.0625,
      -3.3125,
      -1.2265625,
      2.703125,
      -6.3125,
      -3.0625,
      0.5,
      0.859375,
      0.166015625,
      0.99609375,
      -0.64453125,
      2.5625,
      3.546875,
      -0.86328125,
      5.3125,
      0.138671875,
      0.310546875,
      -4.25,
      -4,
      -7.25,
      -0.396484375,
      -0.98828125,
      -2.109375,
      1.640625,
      -1.78125,
      -0.71484375,
      1.7734375,
      -3.078125,
      -0.23828125,
      -0.41015625,
      3.09375,
      0.018798828125,
      -2.125,
      0.6484375,
      -0.416015625,
      1.0546875,
      -1.359375,
      -1.8984375,
      -3.65625,
      -0.5234375,
      -0.4765625,
      -0.32421875,
      1.1328125,
      0.1376953125,
      1.015625,
      -2.953125,
      -2.734375,
      -2.640625,
      6.0625,
      3.421875,
      2.046875,
      2.15625,
      1.0390625,
      -0.1005859375,
      -1.96875,
      -1.34375,
      3.828125,
      -2.53125,
      -0.91796875,
      3.125,
      -2.90625,
      3.71875,
      -3.8125,
      -2.65625,
      -5.46875,
      2.453125,
      5.9375,
      1.2265625,
      -0.90625,
      -0.470703125,
      1.3828125,
      0.5078125,
      -1.171875,
      6.34375,
      -2.328125,
      -5.03125,
      -0.96484375,
      2.25,
      1.7890625,
      -6.21875,
      4.1875,
      -0.75,
      -2.078125,
      2.984375,
      2.6875,
      3.21875,
      -2.390625,
      3.234375,
      1.09375,
      -2.4375,
      -2.21875,
      5.5,
      0.92578125,
      1.3125,
      -1.0859375,
      -4.09375,
      -2.8125,
      1.2265625,
      1.3203125,
      2.5,
      0.10791015625,
      3.59375,
      0.71484375,
      4.9375,
      1.2109375,
      -0.04345703125,
      1.0703125,
      1.9609375,
      0.62109375,
      -4.25,
      0.9453125,
      -4.65625,
      3.109375,
      0.890625,
      -8.75,
      -0.06689453125,
      1.609375,
      0.90625,
      4.46875,
      2.140625,
      -0.8515625,
      -0.03271484375,
      -0.007598876953125,
      1.0546875,
      -2.15625,
      1.8828125,
      0.80859375,
      1.5234375,
      -5.1875,
      2.4375,
      -0.796875,
      1.1640625,
      -3.0625,
      4.53125,
      -0.2470703125,
      2.5,
      5.5625,
      3.78125,
      -3.8125,
      1.6953125,
      1.6953125,
      -1.828125,
      -3.09375,
      0.40625,
      0.3046875,
      2.28125,
      3.140625,
      -0.609375,
      -4.8125,
      -1.3125,
      -1.7578125,
      2.40625,
      0.6796875,
      1.2421875,
      -3,
      6.125,
      -5.125,
      -0.14453125,
      1.375,
      -2.546875,
      -2.90625,
      -0.3671875,
      0.0703125,
      3.734375,
      3.5,
      -0.19140625,
      -0.91796875,
      1.28125,
      -0.283203125,
      -1.78125,
      -2.03125,
      3.125,
      3.09375,
      -2.09375,
      -0.162109375,
      -2.828125,
      1.3515625,
      -3.15625,
      -1.765625,
      0.1982421875,
      -0.59375,
      -0.439453125,
      4,
      3.109375,
      0.578125,
      0.416015625,
      -3.921875,
      4.75,
      -0.1689453125,
      -0.08984375,
      4.53125,
      1.515625,
      1.671875,
      -4.5625,
      2.578125,
      -0.11474609375,
      -0.87109375,
      1.3515625,
      4.40625,
      -3.765625,
      -1.7734375,
      2.78125,
      3.953125,
      -0.5234375,
      -0.859375,
      -2.109375,
      5.125,
      -1.9140625,
      0.1279296875,
      -4.09375,
      -1.7265625,
      1.9375,
      -0.4375,
      1.2578125,
      -1.734375,
      1.3984375,
      -2.25,
      -1.8515625,
      2.546875,
      4.15625,
      1.0390625,
      -2.109375,
      2.515625,
      2.3125,
      -0.73828125,
      2.15625,
      -2.6875,
      -2.578125,
      -3.40625,
      1.625,
      -4.8125,
      -0.921875,
      -6.90625,
      1.140625,
      -4.25,
      0.25,
      2.09375,
      4.8125,
      -1.890625,
      4.6875,
      0.05712890625,
      -1.703125,
      -3.0625,
      -5.625,
      1.0625,
      -2.625,
      -5.75,
      -0.68359375,
      4.1875,
      2.734375,
      5.25,
      3.21875,
      1.515625,
      -4.6875,
      0.2578125,
      -4.03125,
      2.25,
      -1.5,
      -0.58203125,
      -2.140625,
      -0.6328125,
      1.8984375,
      0.373046875,
      3.859375,
      -4.4375,
      -3.140625,
      -4.6875,
      -0.2578125,
      -0.8046875,
      2.5,
      -1.6875,
      -3.5625,
      2.4375,
      -0.58203125,
      6.4375,
      3.359375,
      -1.71875,
      -1.6796875,
      4.375,
      0.76953125,
      1.609375,
      5.1875,
      1.8203125,
      -7.8125,
      3.15625,
      3.34375,
      -1.0859375,
      2.1875,
      2.265625,
      0.23828125,
      -6.34375,
      2.4375,
      1.5703125,
      1.75,
      -0.271484375,
      0.31640625,
      3.609375,
      1.9140625,
      5.3125,
      4.71875,
      3.390625,
      -1.71875,
      1.8046875,
      -1.0703125,
      -4.1875,
      0.74609375,
      1.390625,
      -3.859375,
      -1.046875,
      2.65625,
      -0.87890625,
      2.734375,
      -1.1484375,
      -0.92578125,
      4.25,
      7.1875,
      -3.640625,
      1.5859375,
      -3.59375,
      1.5390625,
      -4.25,
      -0.09326171875,
      -4.875,
      2.328125,
      3.34375,
      4.3125,
      0.0439453125,
      -3.546875,
      1.7265625,
      2.421875,
      -1.421875,
      -5.3125,
      2.875,
      0.12890625,
      1.0859375,
      -3.0625,
      -1.0546875,
      2.25,
      -0.75390625,
      0.0093994140625,
      -3.40625,
      3.4375,
      -1.15625,
      -2.984375,
      -4.5625,
      0.4609375,
      -0.36328125,
      -5.3125,
      -1.25,
      -5.4375,
      -0.0067138671875,
      -3.859375,
      3.609375,
      -0.171875,
      0.10546875,
      1.8984375,
      -3.296875,
      0.46484375,
      2.90625,
      -1.671875,
      3.828125,
      -1.7265625,
      -4.25,
      1.1640625,
      0.57421875,
      -4.28125,
      0.9765625,
      -1.125,
      2.265625,
      1.3359375,
      -1.6328125,
      -0.361328125,
      -3.5,
      3.75,
      0.90625,
      3.265625,
      -0.423828125,
      -3.34375,
      -0.2412109375,
      1.296875,
      -1.328125,
      -1.1328125,
      3.125,
      2.78125,
      1.53125,
      -1.1015625,
      0.455078125,
      4,
      -0.458984375,
      -1.2890625,
      1.4296875,
      -3.703125,
      -1.9296875,
      -3.328125,
      -2.890625,
      -0.0191650390625,
      -0.2197265625,
      3.921875,
      -4.53125,
      -4.5625,
      -0.5625,
      5.21875,
      0.1875,
      3.359375,
      2.046875,
      -0.40625,
      1.6796875,
      0.8359375,
      -2.796875,
      -5.21875,
      2.03125,
      1.7109375,
      0.61328125,
      -3.84375,
      1.703125,
      0.011474609375,
      2.890625,
      -3.859375,
      0.1640625,
      -3.671875,
      2.171875,
      -0.392578125,
      -10.125,
      -2.0625,
      2.21875,
      -0.0830078125,
      -1.171875,
      -0.3515625,
      1.515625,
      4.15625,
      4.21875,
      1.7421875,
      -0.322265625,
      -3.859375,
      2.609375,
      15.9375,
      -0.181640625,
      -4.53125,
      -0.15234375,
      -1.9140625,
      4.5,
      8.25,
      2.609375,
      2.625,
      2.5,
      -3.359375,
      1.625,
      -1.4375,
      1.7265625,
      -1.40625,
      1.1171875,
      2.75,
      2.03125,
      -2.59375,
      -6.03125,
      -2.4375,
      2,
      -1.203125,
      3.21875,
      -0.84375,
      2.484375,
      0.44140625,
      -1.796875,
      -0.02099609375,
      -5.21875,
      0.375,
      -2.4375,
      -2.515625,
      -1.4921875,
      -0.28125,
      -4.25,
      -1.515625,
      -0.1953125,
      -2.421875,
      0.494140625,
      -2.265625,
      -5.09375,
      0.640625,
      -0.2099609375,
      -2,
      1.53125,
      -2.203125,
      0.89453125,
      2.90625,
      2.0625,
      -2.828125,
      -0.039306640625,
      -3.484375,
      -0.0196533203125,
      2.59375,
      -3.671875,
      -1.1328125,
      -3.625,
      -3.765625,
      -3.53125,
      -0.6484375,
      -1.8828125,
      -2.59375,
      -0.232421875,
      0.05810546875,
      -2.203125,
      -2.921875,
      -0.58203125,
      0.62890625,
      -3.203125,
      -3.6875,
      -0.91796875,
      3.453125,
      6.3125,
      -0.275390625,
      -0.01904296875,
      1.890625,
      3.046875,
      0.37890625,
      2.859375,
      -2.34375,
      0.443359375,
      -4.21875,
      0.263671875,
      -0.98828125,
      -0.66796875,
      -3.0625,
      2.484375,
      1.25,
      -0.94140625,
      5.3125,
      -4.34375,
      4.75,
      1.796875,
      -4.15625,
      -2.65625,
      4.34375,
      0.1259765625,
      -1.390625,
      1.390625,
      6.1875,
      1.390625,
      -0.66796875,
      -1.3125,
      -0.03173828125,
      -2.96875,
      4.8125,
      -0.35546875,
      -0.53125,
      -0.06689453125,
      -5.09375,
      3.5,
      0.388671875,
      -0.52734375,
      -0.98828125,
      1.3984375,
      -4.59375,
      0.30859375,
      -0.6953125,
      -0.97265625,
      2.578125,
      3.6875,
      -4.40625,
      0.9375,
      -7.78125,
      -4.09375,
      -3.046875,
      -3.21875,
      -0.53125,
      -2.59375,
      2.28125,
      -2.21875,
      -0.90234375,
      -3.015625,
      0.8515625,
      -4.90625,
      3.3125,
      4.34375,
      1.640625,
      1.984375,
      -4.75,
      2.109375,
      2.859375,
      -2.671875,
      -0.1318359375,
      2.671875,
      -3.625,
      3.796875,
      2.515625,
      0.443359375,
      -0.474609375,
      4.375,
      0.953125,
      -2.65625,
      -0.3515625,
      0.6484375,
      -4.6875,
      -3.890625,
      -5.875,
      -0.5,
      -3.078125,
      -2.828125,
      0.08251953125,
      -5.34375,
      -2.5625,
      -1.953125,
      4,
      3.640625,
      -5.0625,
      4.875,
      4.9375,
      -4.125,
      -0.06982421875,
      0.0576171875,
      2.9375,
      -0.85546875,
      0.486328125,
      7.125,
      2.484375,
      -1.859375,
      2.078125,
      2.046875,
      -0.255859375,
      -5.5,
      2.4375,
      7.0625,
      -5.21875,
      1.0234375,
      3.328125,
      -0.130859375,
      1.203125,
      -3.828125,
      -4.71875,
      2.109375,
      3.65625,
      -6.40625,
      -0.1865234375,
      -0.451171875,
      0.484375,
      -2.734375,
      -2.4375,
      3.640625,
      -1.625,
      0.5859375,
      3.625,
      -0.7890625,
      -2.046875,
      -0.46484375,
      -2.390625,
      -0.55859375,
      -1.109375,
      4.46875,
      4.21875,
      2.96875,
      -6.09375,
      5.0625,
      3.484375,
      0.326171875,
      -1.609375,
      2.09375,
      3.71875,
      -0.2578125,
      -5.34375,
      0.396484375,
      -0.177734375,
      2.75,
      -5.15625,
      5.1875,
      -2.546875,
      1.3046875,
      -3.765625,
      0.6484375,
      2.46875,
      -0.0751953125,
      -2.15625,
      -3.625,
      -4.65625,
      1.1015625,
      -1.46875,
      2.578125,
      3.578125,
      -3,
      1.78125,
      3.0625,
      -1.9609375,
      1.015625,
      4.34375,
      0.048828125,
      1.7890625,
      0.0908203125,
      -1.6328125,
      -1.078125,
      2.890625,
      -1.5234375,
      -3.40625,
      -2.609375,
      -0.4375,
      1.5,
      -2.359375,
      1.2734375,
      -0.33984375,
      -6.21875,
      3.984375,
      0.56640625,
      1.640625,
      0.1923828125,
      0.21875,
      -2.734375,
      3.515625,
      3.6875,
      -5.5,
      4.65625,
      -0.83203125,
      -6.5,
      1.3671875,
      -2.40625,
      0.474609375,
      -6.34375,
      1.9375,
      3.078125,
      -2.640625,
      -1.7265625,
      4.28125,
      -2.125,
      0.412109375,
      -1.8046875,
      2.0625,
      -1.046875,
      2.015625,
      2.25,
      -0.111328125,
      3.90625,
      -5.21875,
      1.5,
      -2.390625,
      1.6640625,
      0.263671875,
      -0.7578125,
      0.93359375,
      -2.328125,
      0.92578125,
      3.40625,
      2.15625,
      -8.0625,
      -3.859375,
      -2.359375,
      0.6796875,
      3.59375,
      2.390625,
      0.83203125,
      -3.71875,
      1.109375,
      -1.171875,
      -0.82421875,
      -3.6875,
      -2.21875,
      -5.1875,
      2.390625,
      0.3515625,
      -2.140625,
      -2.96875,
      0.7421875,
      -0.90625,
      1.203125,
      -4.15625,
      -0.2236328125,
      0.189453125,
      0.25,
      -7.3125,
      0.08935546875,
      -0.177734375,
      -0.5546875,
      3.546875,
      1,
      1.7734375,
      3.921875,
      -0.67578125,
      -5.375,
      1.5859375,
      0.51953125,
      0.11328125,
      0.29296875,
      -1.0390625,
      3.953125,
      -1.28125,
      1.96875,
      -3.5625,
      4.0625,
      -0.1865234375,
      -10.8125,
      4.46875,
      -2.171875,
      0.01446533203125,
      -1.765625,
      -7.96875,
      -3.75,
      5.46875,
      -2.375,
      0.443359375,
      4.78125,
      3,
      -0.2265625,
      1.4921875,
      -1.1015625,
      -2.34375,
      2.78125,
      1.8984375,
      -3.953125,
      3.546875,
      4.875,
      -0.248046875,
      -2.015625,
      -1.0390625,
      1.875,
      0.55859375,
      0.01409912109375,
      4.5625,
      4.4375,
      -0.310546875,
      0.09716796875,
      -0.984375,
      1.96875,
      -0.26953125,
      -2.546875,
      0.443359375,
      -1.1875,
      0.98828125,
      -1.5546875,
      2.046875,
      1.0625,
      -4.25,
      -3.3125,
      -4.375,
      -1.75,
      -0.55859375,
      3.578125,
      0.99609375,
      -1.4375,
      0.302734375,
      4.1875,
      -0.2060546875,
      -0.6796875,
      -2.671875,
      1.375,
      -2.109375,
      -3.53125,
      -3.46875,
      5.5,
      -3.265625,
      -3.3125,
      1.9375,
      0.0140380859375,
      1.2890625,
      -0.7578125,
      -4.0625,
      2.578125,
      -1,
      -1.8359375,
      0.02294921875,
      -2.78125,
      1.2734375,
      3.984375,
      -4.1875,
      -5.46875,
      -1.5859375,
      -1.546875,
      -5.125,
      -4.15625,
      0.78515625,
      -3.171875,
      1.5703125,
      3.8125,
      1.6015625,
      -0.396484375,
      2.109375,
      -4.75,
      -6.125,
      5.96875,
      1.4765625,
      2,
      0.2109375,
      -0.59765625,
      -1.015625,
      3.859375,
      6.40625,
      -1.7265625,
      -1.7734375,
      -0.0576171875,
      -2.640625,
      -4.0625,
      -3.203125,
      -0.74609375,
      -1.28125,
      -5.59375,
      4.0625,
      0.984375,
      1.671875,
      0.0023193359375,
      -2.78125,
      1.78125,
      -0.72265625,
      2.015625,
      -0.46484375,
      0.20703125,
      3.046875,
      -1.953125,
      -0.87109375,
      -1.9140625,
      -3.296875,
      -2.15625,
      1.3984375,
      2.484375,
      -1.453125,
      5,
      0.337890625,
      -1.640625,
      -0.392578125,
      -1.4609375,
      2.75,
      -3.5625,
      -1.4453125,
      -2.96875,
      -1.59375,
      4.40625,
      -0.375,
      0.9140625,
      -4.625,
      0.005859375,
      0.1943359375,
      1.34375,
      2.703125,
      -1.1171875,
      1.0546875,
      0.173828125,
      0.359375,
      5.21875,
      1.0859375,
      3.59375,
      1.34375,
      3.4375,
      0.12890625,
      -3.78125,
      2.359375,
      3.046875,
      2.953125,
      0.0234375,
      -2.828125,
      -0.6015625,
      1.1328125,
      -2.28125,
      -1.578125,
      0.06201171875,
      -3.109375,
      2.6875,
      -0.06298828125,
      3.53125,
      0.74609375,
      0.7265625,
      0.255859375,
      -0.54296875,
      0.94921875,
      2.71875,
      -1.1328125,
      0.4140625,
      3.3125,
      3,
      3.59375,
      2.640625,
      0.90625,
      -1.390625,
      -2.359375,
      -1.2578125,
      0.8203125,
      -1.9453125,
      -0.890625,
      0.6484375,
      0.76171875,
      -0.2119140625,
      -0.5234375,
      2.0625,
      1.9921875,
      -2.15625,
      1.8515625,
      -2.140625,
      -0.77734375,
      1.625,
      2.515625,
      -1.53125,
      1.2578125,
      0.9921875,
      2.765625,
      -3.296875,
      1.859375,
      1.7265625,
      4.5,
      0.384765625,
      2.515625,
      2.171875,
      0.5078125,
      -1.3125,
      0.0240478515625,
      4.0625,
      -1.9609375,
      2.84375,
      1.2734375,
      2.046875,
      0.7421875,
      0.5234375,
      -0.98046875,
      2.828125,
      -0.984375,
      -0.07275390625,
      -1.9296875,
      1.265625,
      1.75,
      -0.076171875,
      -0.6953125,
      3.515625,
      1.9296875,
      -1.1171875,
      -0.390625,
      -4.90625,
      0.609375,
      -0.267578125,
      0.60546875,
      -0.77734375,
      0.3125,
      -2.875,
      2.0625,
      0.62109375,
      0.05029296875,
      -1.4921875,
      -3.546875,
      -1.3984375,
      1.3046875,
      0.3671875,
      -1.40625,
      2.25,
      0.216796875,
      -0.7578125,
      3.296875,
      -1.3359375,
      -0.47265625,
      1.4609375,
      -0.3515625,
      1.609375,
      1.203125,
      -2,
      -0.423828125,
      -0.0164794921875,
      -0.02978515625,
      1.78125,
      0.25,
      -1.5234375,
      0.1083984375,
      -0.400390625,
      0.58984375,
      1.859375,
      -1.2734375,
      3.125,
      3.15625,
      -1.28125,
      -0.94921875,
      -2.421875,
      3.8125,
      1.390625,
      -3.03125,
      -1.0078125,
      2.34375,
      -0.337890625,
      1.1015625,
      0.7578125,
      1.1640625,
      -0.77734375,
      -0.5703125,
      -0.326171875,
      -0.083984375,
      -3.078125,
      3.765625,
      -0.353515625,
      -0.030029296875,
      -2.390625,
      -2.671875,
      0.04296875,
      0.5546875,
      1.84375,
      -2.375,
      1.9296875,
      -0.7109375,
      0.1103515625,
      -1.609375,
      -0.76953125,
      -2.078125,
      4.46875,
      -1.421875,
      -1.4140625,
      -0.05712890625,
      3.734375,
      -3.3125,
      -2.171875,
      -0.6640625,
      -1.21875,
      -1.21875,
      3.109375,
      -4.03125,
      1.296875,
      -1.5,
      -1.8125,
      -0.54296875,
      -3.0625,
      -3.234375,
      -3.4375,
      2.4375,
      1.171875,
      0.462890625,
      2.765625,
      0.49609375,
      -0.5546875,
      5.25,
      0.91796875,
      1.96875,
      -0.50390625,
      1.6640625,
      2.234375,
      0.75,
      1.5234375,
      -3.03125,
      -0.3046875,
      -1.3125,
      -1.21875,
      -0.240234375,
      -4.59375,
      -2.21875,
      1.140625,
      2.8125,
      0.34765625,
      -0.036865234375,
      3.359375,
      0.48046875,
      0.69921875,
      0.56640625,
      4.96875,
      2.734375,
      1.7265625,
      -2.09375,
      1.296875,
      4.21875,
      -0.96484375,
      -1.453125,
      1.15625,
      0.84765625,
      2.9375,
      2.140625,
      0.208984375,
      0.65234375,
      -1.265625,
      2,
      0.384765625,
      1.953125,
      -1.4453125,
      1.5234375,
      -1.1171875,
      -1.125,
      4.5,
      -2.53125,
      -2.59375,
      0.61328125,
      -3.046875,
      -1.7421875,
      -1.0390625,
      -0.6953125,
      0.6171875,
      -0.58203125,
      0.236328125,
      -2.28125,
      -1.484375,
      -0.17578125,
      -1.7421875,
      2.4375,
      1.9609375,
      1.3984375,
      -0.3671875,
      -2.359375,
      0.1884765625,
      0.451171875,
      1.75,
      -0.69140625,
      -1.1796875,
      1.5546875,
      1.7890625,
      -4.9375,
      -1.7265625,
      -1.890625,
      -3.640625,
      3.390625,
      1.0234375,
      -0.59375,
      2.40625,
      -0.1337890625,
      -4.28125,
      2.25,
      0.333984375,
      3.46875,
      0.98046875,
      -1.4140625,
      -0.9140625,
      0.0283203125,
      1.1171875,
      -1.40625,
      -0.734375,
      1.4765625,
      -1.828125,
      -0.734375,
      0.328125,
      -1.515625,
      -0.59375,
      -2.234375,
      -3.359375,
      -2.3125,
      -3.34375,
      -1.3203125,
      -2.703125,
      0.80859375,
      2.0625,
      -0.55078125,
      2.328125,
      3.84375,
      -1.296875,
      -1.2890625,
      1.5859375,
      1.8515625,
      2.25,
      0.99609375,
      -5.90625,
      -2.71875,
      -2.359375,
      -0.60546875,
      -0.13671875,
      3.140625,
      1.125,
      5.78125,
      -0.921875,
      -1.484375,
      -4.25,
      -0.890625,
      0.18359375,
      1.3515625,
      4.21875,
      -4.125,
      1.4765625,
      0.55078125,
      0.375,
      -0.310546875,
      0.330078125,
      3.125,
      1.5,
      -0.05712890625,
      1.53125,
      2.09375,
      0.7890625,
      3.609375,
      0.1845703125,
      4.15625,
      0.5234375,
      -1.703125,
      -0.439453125,
      -1.1796875,
      -1.7578125,
      2.25,
      -2.859375,
      -0.1337890625,
      4.03125,
      -2.40625,
      1.796875,
      -2.046875,
      0.08642578125,
      3.1875,
      3.71875,
      0.06591796875,
      -0.81640625,
      0.45703125,
      2.8125,
      1.3515625,
      0.66796875,
      -2.953125,
      4.875,
      1.078125,
      -2.484375,
      1.1796875,
      -2.234375,
      -3.125,
      1.28125,
      0.640625,
      -2.9375,
      1.0078125,
      4.75,
      -2.734375,
      2.03125,
      3.078125,
      3.90625,
      1.65625,
      3.59375,
      -0.451171875,
      4.40625,
      -0.8515625,
      -0.78515625,
      3.8125,
      -0.7734375,
      -5.75,
      0.83984375,
      0.1728515625,
      -5.03125,
      1.328125,
      -1.2890625,
      -1.0390625,
      -0.314453125,
      -2.09375,
      1.7109375,
      -1.8046875,
      3.15625,
      1.765625,
      1.3359375,
      -2.421875,
      0.59765625,
      1.75,
      1.6640625,
      0.10205078125,
      -2.078125,
      1.0390625,
      1.828125,
      0.96484375,
      0.01239013671875,
      -2.515625,
      0.201171875,
      -2.6875,
      -1.453125,
      1.2734375,
      -0.009033203125,
      -1.4375,
      -1.796875,
      0.158203125,
      2.3125,
      -1.0390625,
      -4.3125,
      -1.15625,
      3.171875,
      5.40625,
      -0.2333984375,
      0.01312255859375,
      -1.140625,
      1.1953125,
      -0.8046875,
      0.421875,
      -1.59375,
      -1.3671875,
      3.609375,
      5.09375,
      -1.3046875,
      2.78125,
      0.51171875,
      0.2578125,
      0.5859375,
      -3.625,
      1.6171875,
      -2.21875,
      -1.2890625,
      1.5234375,
      -0.37890625,
      -1.3828125,
      0.17578125,
      1.5625,
      -3.046875,
      1.1796875,
      -3.203125,
      -0.330078125,
      -1.4140625,
      -0.92578125,
      -0.76953125,
      4.53125,
      1.1484375,
      -0.5625,
      4.09375,
      1.5703125,
      0.59375,
      0.76171875,
      -0.365234375,
      0.031982421875,
      -0.3828125,
      2.875,
      -1.640625,
      -1.4609375,
      -0.171875,
      0.328125,
      1.4140625,
      0.35546875,
      0.359375,
      3.4375,
      2.4375,
      -1.3203125,
      1.1796875,
      -0.83203125,
      -1.3671875,
      -3.34375,
      2.640625,
      4.03125,
      -2.5625,
      -2.046875,
      -1.84375,
      2.1875,
      -0.578125,
      -2.640625,
      0.2314453125,
      -0.02001953125,
      0.1591796875,
      -2.3125,
      0.5234375,
      -0.59765625,
      2.203125,
      -1.421875,
      1.1015625,
      -4.375,
      2.953125,
      -3.3125,
      0.75390625,
      0.51171875,
      -1.53125,
      0.91015625,
      1.5859375,
      -0.73828125,
      -2.65625,
      1.171875,
      1.390625,
      -0.515625,
      -1.4296875,
      -1.9765625,
      1.484375,
      -1.296875,
      -2.8125,
      -0.5390625,
      2.359375,
      1.4140625,
      0.26953125,
      -2.640625,
      -1.578125,
      2.984375,
      1.2265625,
      1.25,
      1.8828125,
      0.478515625,
      -1.0390625,
      1.8046875,
      0.482421875
    ],
    "structure": {
      "sections": [
        {
          "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 13
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 17
        },
        {
          "title": "John Smith Case of Theft",
          "level": 1,
          "start_line": 21
        },
        {
          "title": "Case Details (Input)",
          "level": 1,
          "start_line": 27
        },
        {
          "title": "Judicial Decision-Making (Output)",
          "level": 1,
          "start_line": 47
        },
        {
          "title": "2 Related Work",
          "level": 1,
          "start_line": 88
        },
        {
          "title": "2.1 Task Formulation",
          "level": 1,
          "start_line": 96
        },
        {
          "title": "3 The AgentsCourt Framework",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "3.1 Court Debate Simulation",
          "level": 1,
          "start_line": 113
        },
        {
          "title": "3.2 Legal Resources Retrieval",
          "level": 1,
          "start_line": 126
        },
        {
          "title": "3.3 Judgement Refinement",
          "level": 1,
          "start_line": 134
        },
        {
          "title": "4 The SimuCourt Benchmark",
          "level": 1,
          "start_line": 142
        },
        {
          "title": "4.1 Data Collection",
          "level": 1,
          "start_line": 146
        },
        {
          "title": "4.2 Legal Knowledge Base Construction",
          "level": 1,
          "start_line": 156
        },
        {
          "title": "5 Experiments",
          "level": 1,
          "start_line": 170
        },
        {
          "title": "5.1 Automatic Evaluation",
          "level": 1,
          "start_line": 172
        },
        {
          "title": "5.2 Human Evaluation",
          "level": 1,
          "start_line": 188
        },
        {
          "title": "5.3 Baselines",
          "level": 1,
          "start_line": 192
        },
        {
          "title": "5.4 Main Results",
          "level": 1,
          "start_line": 204
        },
        {
          "title": "5.5 Discussion and Analysis",
          "level": 1,
          "start_line": 208
        },
        {
          "title": "6 Conclusion",
          "level": 1,
          "start_line": 233
        },
        {
          "title": "7 Limitation",
          "level": 1,
          "start_line": 237
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 247
        },
        {
          "title": "A Retrieval Module",
          "level": 1,
          "start_line": 305
        },
        {
          "title": "B Example of Court Transcript",
          "level": 1,
          "start_line": 309
        },
        {
          "title": "C Data Demonstration",
          "level": 1,
          "start_line": 313
        },
        {
          "title": "D Data Analysis",
          "level": 1,
          "start_line": 317
        },
        {
          "title": "D.1 Data Description",
          "level": 1,
          "start_line": 319
        },
        {
          "title": "D.2 Data Quality Inspection",
          "level": 1,
          "start_line": 323
        },
        {
          "title": "E Details of Automatic Evaluation",
          "level": 1,
          "start_line": 344
        },
        {
          "title": "E.1 Legal Articles Evaluation",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "E.2 Judgement Evaluation for Civil and Administrative Cases",
          "level": 1,
          "start_line": 350
        },
        {
          "title": "John Smith Case of Theft",
          "level": 1,
          "start_line": 354
        },
        {
          "title": "Case Details (First Instance)",
          "level": 1,
          "start_line": 360
        },
        {
          "title": "Judicial Decision-Making (Output)",
          "level": 1,
          "start_line": 380
        },
        {
          "title": "John Smith Case of Intentional Injury",
          "level": 1,
          "start_line": 400
        },
        {
          "title": "Case Details (First Instance)",
          "level": 1,
          "start_line": 406
        },
        {
          "title": "Judicial Decision-Making (Output)",
          "level": 1,
          "start_line": 434
        }
      ]
    },
    "tags": [
      "法律AI",
      "多智能体",
      "司法判决预测"
    ],
    "suggested_tags": [
      "法律AI",
      "多智能体",
      "司法判决预测",
      "知识增强"
    ],
    "tag_suggestions": [
      {
        "name": "法律AI",
        "confidence": 0.98,
        "reason": "论文聚焦司法全流程，构建法官智能体，属于法律人工智能核心研究"
      },
      {
        "name": "多智能体",
        "confidence": 0.95,
        "reason": "提出AgentsCourt框架，通过多角色智能体模拟法庭辩论与判决，是多智能体协同的典型应用"
      },
      {
        "name": "司法判决预测",
        "confidence": 0.92,
        "reason": "任务目标为基于案情自动生成判决结果，直接对应司法判决预测任务"
      },
      {
        "name": "知识增强",
        "confidence": 0.9,
        "reason": "构建Legal-KB大规模法律知识库并用于决策 refinement，体现知识增强生成范式"
      }
    ],
    "tags_confirmed": true,
    "category": "法律AI",
    "translated_content": "# AgentsCourt：基于法庭辩论模拟与法律知识增强的司法裁决智能体构建\n\n何志涛$^{1,2}$，曹鹏飞$^{1,2}$，王晨浩$^{1,2}$，金卓然$^{1,2}$，陈玉博$^{1,2}$，徐杰欣$^{3}$，李怀军$^{3}$，蒋小俭$^{3}$，刘康$^{1,2}$，赵军$^{1,2}$\n\n<sup>1</sup> 中国科学院自动化研究所复杂系统认知与决策智能实验室，北京，中国  \n<sup>2</sup> 中国科学院大学人工智能学院，北京，中国  \n<sup>3</sup> 招商银行人工智能实验室，深圳，中国  \n\n{zhitao.he, pengfei.cao, yubo.chen, kliu, jzhao}@nlpr.ia.ac.cn\n\n# 摘要\n\n随着深度学习的发展，自然语言处理技术显著提升了传统司法行业各环节的效率。然而，现有研究多聚焦于单一司法阶段的任务，难以应对跨阶段的复杂任务。基于大语言模型的自主智能体在现实场景中展现出日益强大的复杂决策能力，为司法智能提供了新的思路。本文（1）提出一种面向司法裁决的多智能体框架 AgentsCourt，该框架遵循经典庭审流程，通过法庭辩论模拟、法律资源检索与裁决精化三个阶段模拟法官决策；（2）发布司法评测基准 SimuCourt，涵盖 420 份中文裁判文书，覆盖三类最常见司法案件；并构建大规模法律知识库 Legal-KB，整合多源法律知识以支撑任务；（3）大量实验表明，该框架在多方面优于现有先进方法，尤其在生成法律条文任务中，模型在一审与二审设置下分别取得 8.6% 与 9.1% 的 F1 分数显著提升。\n\n# 1 引言\n\n近年来，深度学习的进展对法律领域产生了深远影响，在法律问答（Zhong et al., 2020b；Khazaeli et al., 2021；Cui et al., 2023）、法律案例检索（Sugathadasa et al., 2019；Shao et al., 2020；Li et al., 2023b；Shao et al., 2023）以及法律判决预测（Xiao et al., 2018；Chalkidis et al., 2019；Wu et al., 2022, 2023b）等任务上均取得显著成果，有效缓解了长期存在的……\n\n# John Smith 盗窃案\n\n案件类型：刑事  \n案由：盗窃  \n\n# 案件详情（输入）\n\n原告：人民检察院  \n被告：John Smith  \n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/f13d531c22bea933dc2a11698513d45aa7b59106d6cd0bac7f0741af2bc54c07.jpg)\n\n被告背景：2017 年，John Smith 因盗窃被某人民法院判处有期徒刑七个月，……经查明：2023 年 7 月至 8 月期间，被告人 John Smith 先后 11 次驾车进入某公司车间堆场，累计窃得废铝 4.28 吨……\n\n起诉书：经鉴定，涉案废铝价值人民币 74,700 元。检察机关指控被告人犯盗窃罪，建议判处有期徒刑三年，并处罚金人民币 20,000 元……\n\n辩护人意见：被告人 John Smith 到案后如实供述上述犯罪事实；案发后，其家属已全额退赔违法所得……\n\n被告人意见：John Smith 对起诉书指控的事实与罪名均无异议，但辩称其积极配合侦查，请求法院从轻处罚……\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/064dfeacb5d486a440bb5188adfd8e1a588cca9f78929a8dd0d0f44ec6ba374f.jpg)\n\n# 司法判决（输出）\n\n本院认为，被告人 John Smith 多次窃取他人财物……依法应予严惩。检察机关指控罪名成立。被告人到案后如实供述犯罪事实……辩护人合理意见予以采纳……\n\n综上，依照《中华人民共和国刑法》第六十四条、第六十七条第三款、第二百六十四条及《……》第十五条之规定，判决如下：被告人犯盗窃罪，判处有期徒刑三年八个月，并处罚金人民币 10,000 元。\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/6c655c23f08f568df7fc0141091e2db716b4bba94d3a5acb495b7c48e9860c80.jpg)\n\n图 1：我们基于真实裁判文书构建司法判决任务：给定上述案件信息，裁判智能体须 1) 开展逻辑清晰的案件分析；2) 援引精确的法律条文；3) 作出终局性判决。\n\n司法行业长期面临“案多人少”之困境。然案件审理乃一连贯过程，涵盖法庭辩论、案件分析、法律适用预测等多个阶段，其复杂性要求各阶段紧密协同与互动。现有研究虽于单点环节取得进展，却常忽视审判流程各阶段间的内在关联，导致仍需法律专家深度介入方能应对……<table><tr><td>框架</td><td>AgentsCourt（本文）</td><td>LaWGPT（Song 等，2023）</td><td>PLJP（Wu 等，2023b）</td><td>HRN（Lyu 等，2023）</td><td>RLJP（Wu 等，2022）</td></tr><tr><td>案例分析</td><td>✓</td><td>✓</td><td>✗</td><td>✗</td><td>✓</td></tr><tr><td>先例检索</td><td>✓</td><td>✗</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>网络调研</td><td>✓</td><td>✗</td><td>✗</td><td>✗</td><td>✗</td></tr><tr><td>法庭模拟</td><td>✓</td><td>✗</td><td>✗</td><td>✗</td><td>✗</td></tr><tr><td>判决预测</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>法律条文生成</td><td>多类型</td><td>单类型</td><td>单类型</td><td>单类型</td><td>单类型</td></tr><tr><td>案件类型</td><td>多种</td><td>多种</td><td>刑事案件</td><td>刑事案件</td><td>刑事案件</td></tr></table>\n\n表 1：本文 AgentsCourt 与法律领域代表性框架的对比。\n\n面对复杂的司法裁决。与此同时，基于大语言模型（LLM）的自主智能体已在多项传统自然语言处理（NLP）任务（Brown 等，2020；Wei 等，2022；Wang 等，2023；Qian 等，2023；Wu 等，2023a）以及现实环境决策（Yao 等，2023；Richards，2023；Chen 等，2023）中取得显著进展，为司法智能提供了新的思路。\n\n然而，模拟司法决策并非易事，因为智能体必须在多方利益交织的复杂情境中权衡，理解法律条文的微妙差异，并兼顾伦理与社会正义因素。这对智能体系统提出了三项独特挑战：（1）伦理关系错综复杂。司法裁决必须考虑往往隐晦且多维的伦理与道德因素。（2）司法领域专业知识。裁判需深入理解并准确适用法律、法规与先例等专门知识。（3）复杂混合推理。智能体须具备处理逻辑、事实与法律推理交织的复杂混合推理能力。\n\n为应对上述挑战，本文提出一种面向司法决策任务的新型多智能体框架——AgentsCourt。如图 1 所示，给定案件详情，该任务要求智能体进行逻辑清晰的案例分析，提供精准的法律条文并作出明确判决。AgentsCourt 遵循经典庭审流程：开庭陈述、法庭辩论、先例检索与判决，如图 2 所示。具体而言，我们首先构建了一个由三名智能体组成的法庭辩论模拟模块，作为各方阐明立场的平台，以厘清案件中复杂的伦理关系。其中一名智能体担任法官，负责开启庭审并宣布……![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/ce948c8392963f330a8b47a0414056f1646a54b18da1ebb2a0d083d236848c9c.jpg)  \n图 2：简化的庭审流程。\n\n案件的基本事实。其余两个智能体分别被设定为原告与被告，在法庭辩论阶段阐述各自观点。随后，我们设计了法律资源检索模块（Legal Resources Retrieval Module），以弥补专家知识不足的问题。该模块引入一名“法官助理”智能体，将自建知识库与互联网检索到的最相关判例、法条及其他信息进行整合。接着，我们提出决策精化模块（Decision-Making Refinement Module），以支持复杂且混合的推理过程。该模块首先依据当前案件已确立的事实与法庭辩论笔录，激发智能体固有的司法专业知识，作出初步裁判；继而利用检索到的法律信息对初步裁判进行精化。\n\n本框架与既往工作的对比列于表 1。值得指出的是，本框架并非针对某一特定法系定制。AgentsCourt 能够实现庭审模拟、判例检索、判决预测，并支持生成多篇可供实务司法实践使用的法律文书。\n\n我们还引入了 SimuCourt，一个旨在跨多种案件类型评估“智能体即法官”（Agent-as-Judge）的司法基准。SimuCourt 涵盖 420 份中国裁判文书，覆盖刑事、民事、行政这三类最常见案件的一审与二审（上诉审）程序，并涉及政府机关、检察机关与个人三大社会主体。具体而言，刑事案件涉及被认定为违反刑法的犯罪行为，如盗窃；民事案件通常表现为个人之间的纠纷，如合同纠纷或侵权；行政案件则关乎个人与政府机关之间的争议。全部案件均来源于中国裁判文书网<sup>1</sup>——由中华人民共和国最高人民法院设立的官方平台，旨在公开发布全国各级法院的裁判文书。此外，我们构建了一个大规模法律知识库 Legal-KB，以支撑该领域任务。该知识库囊括有效法律法规、高被引司法论文及近年判例等多种法律知识。真实数据的使用使得基于其开发的智能体可无缝迁移至真实应用场景。\n\n我们的贡献总结如下：- 我们提出了一种新颖的多智能体框架 AgentsCourt。给定案件的基本信息，该框架可依次模拟法庭辩论、检索判例、分析案情、援引法律条文并作出清晰判决。这一全新的司法范式简化了司法决策流程，显著提升了司法效率。  \n- 我们构建了司法基准 SimuCourt，涵盖三类最常见案件，可可靠评估智能体在真实司法实践中的司法分析与决策能力。此外，我们构建了多源法律知识库 Legal-KB，为该任务提供知识支持。  \n- 我们开展了大量实验与消融研究。结果表明，本框架在多个维度上均优于现有先进方法，尤其在法律条文生成方面，系统在一审与二审实验设置中分别取得 $8.6\\%$ 与 $9.1\\%$ 的 F1 分数显著提升。\n\n# 2 相关工作\n\n法律人工智能 法律人工智能旨在利用人工智能技术改进法律任务（Surden, 2019；Zhong et al., 2020a；Katz et al., 2023）。随着深度学习的持续发展，法律领域涌现出愈发智能化的应用，覆盖法律判决预测（LJP）（Xiao et al., 2018；Zhong et al., 2018；Xu et al., 2020；Yue et al., 2021；Wu et al., 2022, 2023b）、法律问答（Zhong et al., 2020b；Cui et al., 2023；Louis et al., 2024；Fei et al., 2023）、法律语言理解（Chalkidis et al., 2022；Xiao et al., 2021；Niklaus et al., 2023；Yu et al., 2023）、案例检索（Sugathadasa et al., 2019；Shao et al., 2020；Li et al., 2023b；Shao et al., 2023）、法律文档摘要（Kanapala et al., 2019；Jain et al., 2023, 2024）等诸多任务。尽管现有研究在单一法律任务上取得进展，却忽视了任务间的相互关联，导致在处理复杂司法决策时仍需深度依赖法律专家。本文工作通过多智能体协作，致力于完成司法决策的全流程。多智能体框架  \n如同人类群体动力学中的协作，智能体之间的合作能够显著提升任务完成的效率与效果。Li 等（2023a）使两个可通信的智能体通过对话协作完成指定任务。Park 等（2023）发现，智能体群体中会自发涌现社会行为。Qian 等（2023）与 Hong 等（2023）提出了利用大语言模型（LLM）并通过自然语言交流贯穿整个软件开发流程的创新范式。Du 等（2023）、Zhang 等（2023）、He 等（2023）、Chen 等（2023）以及 Wu 等（2023a）进一步利用多智能体协作，在多项任务上取得更优性能。\n\n# 2.1 任务形式化\n\n我们提出一项生成式任务，以评估“智能体作为裁判”的能力。具体而言，如图 1 所示，我们将“司法决策制定”任务形式化为：给定案件的详细信息（如事实认定、起诉书/控告书、原被告陈述等），智能体系统需作出一份完整的司法判决，包括清晰合理的案件分析、严谨的法律条文引用以及明确的最终判决。SimuCourt 包含两种实验设置：\n\n一审（First Instance）  \n该设置对应审判法院层级，法官需判定被告是否有罪，并评估是否适用惩罚性措施。在此设置中，核心关注点在于评估智能体对案件事实的理解与分析能力。\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/40932b1ae6c21d347be2fff1cb0532961a304206264961ee244a398f14ae8e64.jpg)  \n图 3：多智能体框架概览。法庭辩论模拟模块通过角色扮演重现法庭辩论过程，从有限的实际记录中挖掘各方观点；法律资源检索模块利用助手智能体整合检索到的信息；决策精修模块则利用法官智能体的内在司法专业知识，并结合检索到的信息对判决进行精修。\n\n二审（Second Instance）  \n该设置对应上诉法院层级。在此阶段，法官需重新审理案件，并考虑新证据。此阶段的目标是确保一审判决的合法性与公正性，识别一审中的法律错误或法规适用不当之处，并展示有效处理新证据的能力。\n\n# 3 AgentsCourt 框架\n\n我们提出一种新颖的多智能体框架，如图 3 所示。该框架基于真实世界的庭审流程，旨在研究多智能体之间的协作及其对司法决策的贡献。\n\n# 3.1 法庭辩论模拟\n\n法庭辩论为各方提供全面、公平地陈述观点与论据的平台，可显著影响案件的判决结果。## 法庭模拟  \n由于大多数判决书仅记录原、被告陈述的要点，获取完整的庭审笔录极为困难。幸运的是，随着大语言模型在角色扮演方面表现出卓越能力（Li et al., 2023a；Qian et al., 2023；Chen et al., 2023），本模块旨在通过多智能体为每个案件重构法庭辩论。我们设置三名智能体，分别扮演法官、原告与被告。对每一智能体，我们精心设计角色扮演提示以构建其人格特征，并以判决书中的实际陈述作为其初始提示。值得注意的是，鉴于判决书对陈述的记录有限，我们将原告与其代理人、被告与其代理人分别合并为单一的原告与被告角色，不再单独设置代理人身份。\n\n### 法庭辩论  \n在此阶段，原告与被告均需围绕自身利益提出主张。原告应竭力论证其诉请，阐明立场与理由；被告则须为其行为辩护，力求证明无罪或寻求减轻责任。开庭时，法官智能体首先致开场词，内容包括原被告基本信息、事实认定等。随后进入法庭辩论环节，智能体间的交互将被记录为庭审笔录。我们在表 12 中展示了一份庭审笔录示例。\n\n![图4：先例的自动检索](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/86af19e735c01375b74f2751327d16753c556d8fe97f14945b39e0279f3c3a57.jpg)  \n\n# 3.2 法律资源检索  \n\n法庭辩论为深入挖掘案件事实与争议焦点提供了平台，使法官更全面地理解案件复杂性。此外，为作出准确的司法裁判，法官必须具备广泛的法律知识及案件信息。\n\n## 法官助理  \n我们指派一名智能体担任法官助理，负责访问互联网与知识库。在互联网信息获取方面，助理可通过网络检索搜集公开信息，例如“本案是否存在舆情？”以帮助法官了解案件的社会影响及潜在公众观点。最终，该智能体将检索到的新闻与评论整理后呈报法官，辅助其作出理性且有依据的司法决策。## 3.2 自动信息检索\n\n在知识库检索方面，如图 4 所示，助手首先根据当前案件的已认定事实预测案件类型。由于知识库中文档数量庞大，且相同案由的案件往往具有更为相似的关键词，我们采用 BM25 模型（Lin et al., 2021）进行高效的粗粒度检索，从知识库中获取排名前 100 的文档。在此基础上，我们进一步利用 BGE-Large 模型（Xiao et al., 2023）对这些检索到的文档进行编码与重排序，并选取与当前案件最相关的文档作为最优先例。此外，为了在不引入额外上下文的前提下获得与当前案件更为全面的法律法规，法官助手从前 5 个先例中提取相应的法律条文，作为当前案件的相关法律依据。\n\n# 3.3 判决精化\n\n在本模块中，我们首先利用智能体固有的司法专业知识，依据当前案件的已认定事实及法庭辩论笔录作出初步判决；随后，法官智能体借助检索到的信息对判决进行精化。\n\n**初步判决**  \n如图 3 底部所示，法官智能体在接收到当前案件的已认定事实与模拟法庭辩论笔录后，执行“分析”动作，继而给出所适用的法律条文，并据此形成初步判决。\n\n**判决精化**  \n在获得包含案件具体细节分析的初步判决后，法官智能体利用助手提供的有利先例与相关法律信息，对判决进行精化，并给出最终判决。该过程包括但不限于：分析先例、援引法律法规以及考量公众意见。\n\n# 4 SimuCourt 基准\n\n“司法决策”任务要求智能体开展案件分析、生成法律条文并作出判决。然而，现有法律数据集在评估“智能体即法官”范式时存在诸多局限：1）仅包含案件事实信息；2）仅聚焦刑事案件；3）仅对判决结果进行评估。为此，我们提出 SimuCourt，一个用于可靠评估智能体司法分析与决策能力的司法基准。表 2 展示了本数据集与既往工作的对比。\n\n# 4.1 数据收集我们从“中国裁判文书网”收集了 420 份真实案例，覆盖一审与二审两个基本审判阶段，涵盖刑事、民事与行政三类案由。一审样本包含起诉书、被告方观点、事实认定等内容；二审样本则涵盖上诉状、上诉人及被上诉人意见等。详细列表与数据示例见附录 C。绝大多数案例发布于 2023 年 4 月之后，从而最大限度降低数据泄露风险<sup>2</sup>。SimuCourt 的详细数据统计见表 3。此外，本数据集经过严格质检，确保法律文本与信息的准确性与完整性。数据收集与质量检验细节见附录 D。\n\n<table><tr><td>资源</td><td>SimuCourt</td><td>CAIL</td><td>SLJA-SYN</td></tr><tr><td>被告背景？</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>多方陈述？</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>多法条场景？</td><td>✓</td><td>✗</td><td>✗</td></tr><tr><td>案例分析评估？</td><td>✓</td><td>✗</td><td>✓</td></tr><tr><td>判决评估</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>涉及法条？</td><td>443</td><td>1</td><td>1</td></tr><tr><td>案例检索？</td><td>6.5M</td><td>2.6M</td><td>✗</td></tr><tr><td>多种案由？</td><td>刑事、民事、行政</td><td>刑事</td><td>刑事</td></tr><tr><td>不同审级？</td><td>一审/二审</td><td>一审</td><td>一审</td></tr></table>\n\n表 2：SimuCourt 与现有重要法律领域数据集的对比。CAIL（Xiao et al., 2018）为广泛使用的法律判决预测数据集，每案附事实描述；SLJA-SYN（Deng et al., 2023）为综合性法律数据集，支持法条检索、法条解释生成、犯罪构成要素生成及法律判决预测等多项任务。\n\n<table><tr><td>特征</td><td>刑事</td><td>民事</td><td>行政</td></tr><tr><td>案例数</td><td>140</td><td>140</td><td>140</td></tr><tr><td>案由数</td><td>44</td><td>51</td><td>33</td></tr><tr><td>平均法条数</td><td>6.3</td><td>3.3</td><td>1.6</td></tr><tr><td>最多法条数</td><td>11</td><td>10</td><td>8</td></tr><tr><td>法条总数</td><td>198</td><td>153</td><td>92</td></tr><tr><td>事实平均长度</td><td>468.7</td><td>487.5</td><td>673.3</td></tr><tr><td>分析平均长度</td><td>346.3</td><td>486.1</td><td>722.7</td></tr><tr><td>案例平均长度</td><td>2362.6</td><td>2473.8</td><td>3315.5</td></tr></table>\n\n# 4.2 法律知识库构建为了作出准确的司法裁判，法官必须具备广博的法律知识。此外，鉴于人类社会的多样性与复杂性，每个案件所涉及的事实、当事人及地域均可能不同。为此，我们构建了一个大规模法律知识库，涵盖法律、行政法规、司法解释、期刊论文与判例。Legal-KB 的详细数据统计见表 4。\n\n法律、行政法规与司法解释  \n我们从中国国家法律法规数据库<sup>3</sup>下载各类法律文本。该库为权威法律信息资源，包含国家法律、行政法规、地方性法规及司法解释。我们剔除了已失效的法律文本。  \n期刊论文  \n期刊论文通常由法学专家撰写，可对特定法律议题提供深入剖析与独到见解。我们从中国法律知识资源总库<sup>4</sup>收集了 2010–2023 年间的高被引期刊论文。\n\n表 3：SimuCourt 数据统计。长度以词数计量  \n\n<table><tr><td>类型</td><td>数量</td><td>词元数</td><td>平均词元数</td></tr><tr><td>法律与行政法规</td><td>9 K</td><td>66 M</td><td>7390</td></tr><tr><td>期刊论文</td><td>29 K</td><td>15 M</td><td>521</td></tr><tr><td>判例</td><td>6.5 M</td><td>27.1 B</td><td>4111</td></tr></table>\n\n表 4：我们的法律知识库数据统计。\n\n判例  \n我们收集了中国裁判文书网 2017–2022 年间的全部刑事、民事与行政裁判文书。然而，如附录图 9 所示，数据呈现显著的长尾分布。为平衡案由类型，我们将每一案由的文书数量上限设为 $20\\mathrm{k}$。对于超出此数量的案由，仅保留文本长度最长的前 $20\\mathrm{k}$ 份文书，以代表复杂案件。\n\n# 5 实验\n\n# 5.1 自动评估\n\n如表 11 中的示例数据所示，法律条文与裁判文书均简洁且结构化。因此，我们针对法律条文与裁判文书分别提出相应的评估指标。\n\n法律条文评估  \n正确的法律条文对于公正裁判至关重要。为此，我们采用严格匹配方法评估智能体系统生成的法律条文列表。具体而言，我们计算智能体系统输出的法律条文列表与参考法律条文列表之间完全匹配与不匹配的条目数，随后进行微平均，得到总体精确率、召回率与 F1 分数。详见表 13。民事与行政案件的判决评估  \n每一起民事或行政案件的判决可能包含多项结果。尽管每项结果通常围绕一个核心争点展开，但往往涉及具体的金额与利率信息。因此，基于相似度的传统文本匹配方法难以准确捕捉这些关键争点。为此，我们采用 GPT-4 作为评估器。具体而言，我们分别统计智能体系统判决结果与参考判决结果中相匹配与不相匹配的关键争点数量，并以微平均（micro-averaged）方式计算整体的精确率（precision）、召回率（recall）与 F1 分数。详细结果见表 14。\n\n刑事案件的判决评估  \n与其他类型案件不同，刑事案件的量刑……表 5：本文框架与基线方法在一审与二审实验场景下的整体性能对比。\n\n<table><tr><td rowspan=\"3\" colspan=\"2\">模型</td><td rowspan=\"2\" colspan=\"3\">法条援引</td><td colspan=\"5\">判决结果</td><td rowspan=\"2\" colspan=\"3\">案例分析</td><td></td></tr><tr><td colspan=\"3\">民事与行政</td><td colspan=\"2\">刑事</td><td></td></tr><tr><td>P</td><td>R</td><td>F</td><td>P</td><td>R</td><td>F</td><td>罪名</td><td>刑期</td><td>罚金</td><td>正确性</td><td>逻辑性</td><td>简洁性</td></tr><tr><td rowspan=\"6\">一审</td><td>GPT-3.5</td><td>0.127</td><td>0.109</td><td>0.117</td><td>0.367</td><td>0.498</td><td>0.423</td><td>0.822</td><td>0.253</td><td>0.412</td><td>0.466</td><td>0.510</td><td>0.493</td></tr><tr><td>GPT-4</td><td>0.139</td><td>0.133</td><td>0.136</td><td>0.398</td><td>0.559</td><td>0.465</td><td>0.875</td><td>0.287</td><td>0.462</td><td>0.503</td><td>0.553</td><td>0.543</td></tr><tr><td>ReAct</td><td>0.161</td><td>0.109</td><td>0.131</td><td>0.387</td><td>0.532</td><td>0.448</td><td>0.866</td><td>0.262</td><td>0.437</td><td>0.516</td><td>0.567</td><td>0.533</td></tr><tr><td>AutoGPT</td><td>0.171</td><td>0.123</td><td>0.143</td><td>0.392</td><td>0.543</td><td>0.455</td><td>0.862</td><td>0.275</td><td>0.450</td><td>0.523</td><td>0.576</td><td>0.520</td></tr><tr><td>LaWGPT</td><td>0.183</td><td>0.105</td><td>0.133</td><td>0.414</td><td>0.548</td><td>0.471</td><td>0.875</td><td>0.237</td><td>0.425</td><td>0.506</td><td>0.546</td><td>0.533</td></tr><tr><td>AgentsCourt</td><td>0.219</td><td>0.189</td><td>0.203</td><td>0.437</td><td>0.603</td><td>0.507</td><td>0.887</td><td>0.337</td><td>0.500</td><td>0.550</td><td>0.596</td><td>0.526</td></tr><tr><td rowspan=\"6\">二审</td><td>GPT-3.5</td><td>0.206</td><td>0.169</td><td>0.186</td><td>0.317</td><td>0.429</td><td>0.365</td><td>0.716</td><td>0.166</td><td>0.516</td><td>0.496</td><td>0.540</td><td>0.526</td></tr><tr><td>GPT-4</td><td>0.200</td><td>0.267</td><td>0.228</td><td>0.356</td><td>0.482</td><td>0.409</td><td>0.800</td><td>0.183</td><td>0.533</td><td>0.530</td><td>0.583</td><td>0.576</td></tr><tr><td>ReAct</td><td>0.209</td><td>0.235</td><td>0.221</td><td>0.364</td><td>0.457</td><td>0.405</td><td>0.800</td><td>0.150</td><td>0.516</td><td>0.526</td><td>0.586</td><td>0.570</td></tr><tr><td>AutoGPT</td><td>0.217</td><td>0.248</td><td>0.231</td><td>0.371</td><td>0.478</td><td>0.417</td><td>0.816</td><td>0.166</td><td>0.550</td><td>0.540</td><td>0.590</td><td>0.583</td></tr><tr><td>LaWGPT</td><td>0.225</td><td>0.231</td><td>0.227</td><td>0.382</td><td>0.472</td><td>0.422</td><td>0.850</td><td>0.133</td><td>0.483</td><td>0.503</td><td>0.553</td><td>0.566</td></tr><tr><td>AgentsCourt</td><td>0.271</td><td>0.284</td><td>0.277</td><td>0.400</td><td>0.528</td><td>0.456</td><td>0.833</td><td>0.200</td><td>0.583</td><td>0.583</td><td>0.633</td><td>0.593</td></tr></table>案件通常包含三项核心要素：罪名、刑期与罚金。罪名的确定必须与案件事实相符；刑期与罚金的具体数额不仅依据事实，还综合考量被告人在庭审中的表现，包括其对犯罪的态度及其为自身行为所作的辩护。我们分别计算智能体系统在这三项上的准确率。\n\n# 5.2 人工评估\n\n案例分析涉及复杂的逻辑推理与伦理考量，难以通过自动指标或 GPT-4 进行有效评估。针对每一种设置，我们从该设置中随机抽取 100 条样本，交由三位法学研究生组成的评审小组，依据以下二分类真/假标准进行评判：  \n1) 正确性：当且仅当分析令人满意且兼顾各方利益时标记为真。  \n2) 逻辑性：若分析中存在任何不合逻辑或与事实不符的推理，则标记为假。  \n3) 简洁性：若分析涵盖所有必要信息且无冗余内容，则标记为真。\n\n# 5.3 基线模型\n\nVanilla  我们采用 gpt-3.5-turbo-1106 与 gpt-4-1106-preview 作为 vanilla 模型，并以 few-shot 方式运行。受预算限制，所有智能体系统的基座模型仅使用 gpt-3.5-turbo-1106。\n\nReAct（Yao et al., 2023）  该系统使智能体能够基于过往活动（如搜索或工具调用）的结果改进后续行动。\n\nAutoGPT（Richards, 2023）  当前最先进的智能体框架之一，集成多种工具与提示，旨在实现指定任务的自动规划与执行。\n\nLaWGPT（Song et al., 2023）  目前最受欢迎的中文法律大模型，基于通用中文基座模型 Chinese-LLaMA-7B，在中文法律语料上进行了大规模预训练，并针对法律指令做了微调，具备较强的法律内容理解与生成能力。\n\n# 5.4 主要结果\n\n如表 5 所示，我们的框架在所有维度上均优于其他模型。在法律条文评估中，所提框架在两个实验设置下分别取得 $8.6\\%$ 与 $9.1\\%$ 的性能提升；相比之下，GPT-4 在一审与二审设置下的性能仅达 $13.6\\%$ 与 $22.8\\%$。这不仅暴露了大语言模型在援引法律条文能力上的显著不足，也体现了本基准的高度挑战性。在判决结果评估方面，各模型在刑事案件定罪上表现良好，但在刑期与罚金的具体裁量上与标准结果仍存在显著差距。此外，尽管这些系统的分析已表现出一定程度的逻辑性，但在正确性与简洁性方面仍有提升空间。\n\n# 5.5 讨论与分析## 大模型的法律知识\n\n如图 5 所示，在“预测案件类型”这一简单任务上，三种语言模型均表现出色。然而，在更具挑战性的“预测案件理由”任务中，性能显著下降：GPT-4 的准确率仅为 $35.4\\%$，而经过大量专业知识预训练的 LaWGPT 也仅达到 $43.7\\%$。在“法条生成”任务中，所有模型的表现均不理想，LaWGPT 有时甚至输出乱码，导致性能进一步恶化。\n\n<table><tr><td rowspan=\"2\">模型</td><td rowspan=\"2\">法条</td><td colspan=\"4\">判决结果</td></tr><tr><td>民事与行政</td><td>罪名</td><td>刑期</td><td>罚金</td></tr><tr><td>SimuCourt</td><td>0.203</td><td>0.507</td><td>0.887</td><td>0.337</td><td>0.500</td></tr><tr><td>w/o 法庭模拟</td><td>0.171</td><td>0.473</td><td>0.875</td><td>0.300</td><td>0.462</td></tr><tr><td>w/o 知识库</td><td>0.145</td><td>0.462</td><td>0.850</td><td>0.312</td><td>0.475</td></tr><tr><td>w/o 网络检索</td><td>0.196</td><td>0.488</td><td>0.865</td><td>0.325</td><td>0.487</td></tr></table>\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/a80620a24690083d6c6317472bf2ca9cf53baaa24dc1c664306adc5eda943a52.jpg)  \n图 5：大模型法律知识评估。\n\n### 多智能体法庭模拟\n\n附录表 6 中的消融实验结果表明，我们设计的法庭辩论模拟模块显著提升了司法判决的准确性。我们进一步探究该模块对刑事案件中“刑期”与“罚金”预测的具体影响。如图 6 所示，经过法庭辩论模拟后，刑期与罚金的绝对误差均显著降低。\n\n### 不同案件类型的难度\n\n表 7 给出了本框架在一审场景下针对不同类型案件生成法条的结果。智能体系统在刑事案件中能够产生更为可靠的法条，而在民事与行政案件中对相关法规的运用与理解明显较弱。这一现象可能源于民事与行政案件涉及更为复杂的多方利益纠葛（如合同纠纷、家事纠纷或政府决策），需要对法律及社会知识有更深入的理解。\n\nTable 6：一审场景下框架的消融实验结果。\n\n<table><tr><td>案件类型</td><td>精确率</td><td>召回率</td><td>F1 值</td></tr><tr><td>全部</td><td>0.219</td><td>0.189</td><td>0.203</td></tr><tr><td>刑事</td><td>0.489</td><td>0.264</td><td>0.343</td></tr><tr><td>民事</td><td>0.073</td><td>0.063</td><td>0.067</td></tr><tr><td>行政</td><td>0.126</td><td>0.250</td><td>0.167</td></tr></table>\n\nTable 7：AgentsCourt 法条生成评估。法律知识库  \n在外部知识库的支持下，代理系统在司法推理中的表现显著提升，提升幅度高达 $6.2\\%$。这些成果也归功于我们设计的自动检索模块。如附录 A 中的表 8 所示，经过粗检索后，最相似案例与当前案例在案由方面的一致性仅为 $62\\%$。然而，在文档重排序之后，检索案例与当前案例在案由上的一致性提升至 $85\\%$。这一改进证明了我们检索模块的有效性。\n\n# 6 结论  \n\n我们提出了一种新颖的多代理框架 AgentsCourt，该框架能够依次模拟法庭辩论、检索判例、分析案件、提供法律条文并作出清晰判决。此外，我们引入了 SimuCourt，一个用于评估代理司法分析与决策能力的司法基准。随后，我们开展实验，对不同模块进行分析。我们所提出的新司法范式通过多代理有效模拟了司法决策过程，显著提升了司法效率。\n\n# 7 局限  \n\n本文提出了一种新颖的司法基准 SimuCourt。经过深入分析，我们的工作仍存在以下局限：\n\n- 我们的数据仅包含来自“中国裁判文书网”的中文文书。尽管 AgentsCourt 框架并非专为大陆法系设计，但使用不同法系的实际数据对代理系统进行测试仍具有重要意义。  \n- 裁判文书涵盖了刑事、民事与行政这三类最常见案件。未来纳入更广泛的案件类型，将有助于更全面地评估代理的司法分析与决策能力。  \n- 尽管我们的数据库包含大量判例与法律资源，实验结果表明，代理系统的整体表现仍不尽如人意。\n\n我们期待在未来的研究中进一步探索法律知识库的潜力。\n\n# 参考文献Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, 等. 2020. Language models are few-shot learners. *Advances in Neural Information Processing Systems*, 33:1877-1901.  \nIlias Chalkidis, Ion Androutsopoulos, Nikolaos Aletras. 2019. Neural legal judgment prediction in English. arXiv 预印本 arXiv:1906.02059.  \nIlias Chalkidis, Abhik Jana, Dirk Hartung, Michael Bommarito, Ion Androutsopoulos, Daniel Katz, Nikolaos Aletras. 2022. LexGLUE: 面向英文法律语言理解的基准数据集. 载于《计算语言学协会第60届年会论文集（第一卷：长文）》，第4310-4330页，爱尔兰都柏林. 计算语言学协会.  \nWeize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, 等. 2023. Agent-verse: 促进多智能体协作并探索智能体中的涌现行为. arXiv 预印本 arXiv:2308.10848.  \nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, Li Yuan. 2023. ChatLaw: 集成外部知识库的开源法律大语言模型. arXiv 预印本 arXiv:2306.16092.Wentao Deng, Jiahuan Pei, Keyi Kong, Zhe Chen, Furu Wei, Yujun Li, Zhaochun Ren, Zhumin Chen, and Pengjie Ren. 2023. 法律判决分析中的三段论推理. In *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*, pages 13997-14009.  \nYilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. 通过多智能体辩论提升语言模型的事实性与推理能力. arXiv preprint arXiv:2305.14325.  \nZhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Songyang Zhang, Kai Chen, Zongwen Shen, and Jidong Ge. 2023. Lawbench：评测大语言模型法律知识的基准. arXiv preprint arXiv:2309.16289.  \nZhitao He, Pengfei Cao, Yubo Chen, Kang Liu, Ruopeng Li, Mengshu Sun, and Jun Zhao. 2023. Lego：一种多智能体协作框架，通过角色扮演与迭代反馈生成因果解释. In *Findings of the Association for Computational Linguistics: EMNLP* 2023, pages 9142-9163.  \nSirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. 2023. Metagpt：面向多智能体协作框架的元编程. arXiv preprint arXiv:2308.00352.  \nDeepali Jain, Malaya Dutta Borah, and Anupam Biswas. 2023. 基于贝叶斯优化的语言方法得分融合以改进法律文档摘要. *Knowledge-Based Systems*, 264:110336.  \nDeepali Jain, Malaya Dutta Borah, and Anupam Biswas. 2024. 句子由其上下文所定义：利用深度聚类改进法律文档摘要. *Artificial Intelligence and Law*, 32(1):165-200.  \nAmbedkar Kanapala, Sukomal Pal, and Rajendra Pamula. 2019. 法律文档文本摘要研究综述. *Artificial Intelligence Review*, 51:371-402.  \nDaniel Martin Katz, Dirk Hartung, Lauritz Gerlach, Abhik Jana, and Michael J Bommarito II. 2023. 法律领域中的自然语言处理. arXiv preprint arXiv:2302.12039.  \nSoha Khazaeli, Janardhana Punuru, Chad Morris, Sanjay Sharma, Bert Staub, Michael Cole, Sunny Chiu-Webster, and Dhruv Sakalley. 2021. 一种自由格式的法律问答系统. In *Proceedings of the Natural Legal Language Processing Workshop 2021*, pages 107-113.  \nGuohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023a. Camel：用于大规模语言模型社会“心智”探索的交互式智能体. arXiv preprint arXiv:2303.17760.Haitao Li, Qingyao Ai, Jia Chen, Qian Dong, Yueyue Wu, Yiqun Liu, Chong Chen, and Qi Tian. 2023b. Sailer: structure-aware pre-trained language model for legal case retrieval. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1035-1044.  \n李海涛、艾清尧、陈佳、董倩、吴月月、刘奕群、陈冲、田奇。2023b. Sailer：面向法律案例检索的结构感知预训练语言模型。载于第46届国际ACM SIGIR信息检索研究与发展会议论文集，第1035-1044页。\n\nJimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Zheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira. 2021. Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations. In Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021), pages 2356-2362.  \nJimmy Lin、马雪光、林圣杰、杨政宏、Ronak Pradeep、Rodrigo Nogueira。2021. Pyserini：基于稀疏与稠密表示的可复现信息检索研究Python工具包。载于第44届国际ACM SIGIR信息检索研究与发展会议论文集（SIGIR 2021），第2356-2362页。\n\nAntoine Louis, Gijs van Dijck, and Gerasimos Spanakis. 2024. Interpretable long-form legal question answering with retrieval-augmented large language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 22266-22275.  \nAntoine Louis、Gijs van Dijck、Gerasimos Spanakis。2024. 基于检索增强大语言模型的可解释长文本法律问答。载于AAAI人工智能大会论文集，第38卷，第22266-22275页。\n\nYoungang Lyu, Jitai Hao, Zihan Wang, Kai Zhao, Shen Gao, Pengjie Ren, Zhumin Chen, Fang Wang, and Zhaochun Ren. 2023. Multi-defendant legal judgment prediction via hierarchical reasoning. arXiv preprint arXiv:2312.05762.  \n吕永昂、郝继泰、王子涵、赵凯、高申、任鹏杰、陈竹敏、王芳、任朝春。2023. 基于层级推理的多被告法律判决预测。arXiv预印本 arXiv:2312.05762。\n\nJoel Niklaus, Veton Matoshi, Pooja Rani, Andrea Galassi, Matthias Stürmer, and Ilias Chalkidis. 2023. Lextreme: A multi-lingual and multi-task benchmark for the legal domain. arXiv preprint arXiv:2301.13126.  \nJoel Niklaus、Veton Matoshi、Pooja Rani、Andrea Galassi、Matthias Stürmer、Ilias Chalkidis。2023. Lextreme：法律领域的多语言多任务基准。arXiv预印本 arXiv:2301.13126。\n\nJoon Sung Park, Joseph C O'Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. 2023. Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442.  \nJoon Sung Park、Joseph C O'Brien、Carrie J Cai、Meredith Ringel Morris、Percy Liang、Michael S Bernstein。2023. 生成式智能体：人类行为的交互式拟像。arXiv预印本 arXiv:2304.03442。\n\nChen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents for software development. arXiv preprint arXiv:2307.07924.  \n钱辰、丛鑫、杨成、陈维泽、苏裕生、徐聚元、刘知远、孙茂松。2023. 面向软件开发的交互式智能体。arXiv预印本 arXiv:2307.07924。\n\nToran Bruce Richards. 2023. Autogpt - the next evolution of data driven chat ai. https://auto-gpt.ai/.  \nToran Bruce Richards。2023. AutoGPT——数据驱动对话AI的下一次演进。https://auto-gpt.ai/。\n\nYunqiu Shao, Jiaxin Mao, Yiqun Liu, Weizhi Ma, Ken Satoh, Min Zhang, and Shaoping Ma. 2020. Bert-pei: Modeling paragraph-level interactions for legal case retrieval. In *IJCAI*, pages 3501–3507.  \n邵云秋、毛佳昕、刘奕群、马为之、Ken Satoh、张敏、马少平。2020. Bert-pei：面向法律案例检索的段落级交互建模。载于*IJCAI*，第3501–3507页。\n\nYunqiu Shao, Yueyue Wu, Yiqun Liu, Jiaxin Mao, and Shaoping Ma. 2023. Understanding relevance judgments in legal case retrieval. ACM Transactions on Information Systems, 41(3):1-32.  \n邵云秋、吴月月、刘奕群、毛佳昕、马少平。2023. 理解法律案例检索中的相关性判断。ACM信息系统学报，41(3):1-32。\n\nPengxiao Song, Yixuan Jin, and Zhi Zhou. 2023. LaWGPT. https://github.com/pengxiao-song/LaWGPT.  \n宋鹏霄、金奕轩、周智。2023. LaWGPT。https://github.com/pengxiao-song/LaWGPT。\n\nKeet Sugathadasa, Buddhist Ayesha, Nisansa de Silva, Amal Shehan Perera, Vindula Jayawardana, Dimuthu Lakmal, and Madhavi Perera. 2019. Legal document使用文档向量嵌入与深度学习的检索方法。载于《智能计算：2018 计算会议论文集》第 2 卷，第 160–175 页。Springer。  \nHarry Surden。2019。人工智能与法律：综述。《佐治亚州立大学法律评论》，35:19–22。  \nLei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, 与 Ee-Peng Lim。2023。Plan-and-solve 提示：通过大语言模型改进零样本思维链推理。arXiv 预印本 arXiv:2305.04091。  \nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou 等。2022。思维链提示激发大语言模型推理能力。《神经信息处理系统进展》，35:24824–24837。  \nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, 与 Chi Wang。2023a。AutoGen：通过多智能体对话框架赋能下一代大语言模型应用。arXiv 预印本 arXiv:2308.08155。  \nYiquan Wu, Yifei Liu, Weiming Lu, Yating Zhang, Jun Feng, Changlong Sun, Fei Wu, 与 Kun Kuang。2022。迈向交互性与可解释性：一种基于理由的法律判决预测框架。载于《2022 实证方法自然语言处理会议论文集》，第 4787–4799 页。  \nYiquan Wu, Siying Zhou, Yifei Liu, Weiming Lu, Xiaozhong Liu, Yating Zhang, Changlong Sun, Fei Wu, 与 Kun Kuang。2023b。基于先例增强的法律判决预测：大语言模型与领域模型协同。arXiv 预印本 arXiv:2310.09241。  \nChaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, 与 Maosong Sun。2021。Lawformer：面向中文法律长文的预训练语言模型。《AI Open》，2:79–84。  \nChaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao Tu, Zhiyuan Liu, Maosong Sun, Yansong Feng, Xianpei Han, Zhen Hu, Heng Wang 等。2018。CAIL2018：用于判决预测的大规模法律数据集。arXiv 预印本 arXiv:1807.02478。  \nShitao Xiao, Zheng Liu, Peitian Zhang, 与 Niklas Muennighoff。2023。C-Pack：推进通用中文嵌入的打包资源。  \nNuo Xu, Pinghui Wang, Long Chen, Li Pan, Xiaoyan Wang, 与 Junzhou Zhao。2020。法律判决预测中的法条区分。arXiv 预印本 arXiv:2004.02557。  \nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, 与 Yuan Cao。2023。ReAct：在语言模型中协同推理与行动。载于《国际学习表征会议（ICLR）》。\n\nFangyi Yu, Lee Quartey, 与 Frank Schilder。2023。探索提示工程在法律推理任务中的有效性。载于《计算语言学协会 2023 年发现报告》，第 13582–13596 页，加拿大多伦多。计算语言学协会。林安岳、刘琪、金彬彬、吴涵、张凯、安彦卿、程明月、尹彪、吴大勇. 2021. Neurjudge：一种情境感知的法律判决预测神经框架. 见：第 44 届国际 ACM SIGIR 信息检索研究与发展会议论文集，页 973–982.\n\n张宏昕、杜伟华、单佳明、周沁宏、杜一伦、Joshua B. Tenenbaum、舒天民、甘创. 2023. 利用大语言模型模块化构建协作型具身智能体. arXiv 预印本 arXiv:2307.02485.\n\n钟皓曦、郭志鹏、涂存超、肖朝军、刘知远、孙茂松. 2018. 基于拓扑学习的法律判决预测. 见：2018 年经验方法自然语言处理会议论文集，页 3540–3549.\n\n钟皓曦、肖朝军、涂存超、张天扬、刘知远、孙茂松. 2020a. NLP 如何裨益法律系统：法律人工智能综述. 见：第 58 届计算语言学协会年会论文集，页 5218–5230，在线. 计算语言学协会.\n\n钟皓曦、肖朝军、涂存超、张天扬、刘知远、孙茂松. 2020b. JECQA：一个法律领域问答数据集. 见：AAAI 人工智能大会论文集，第 34 卷，页 9701–9708.\n\n# A 检索模块\n\n如表 8 所示，经过粗检索与文档重排序，检索案例与当前案例在案由方面的一致性提升至 $85\\%$。\n\n# B 庭审笔录示例\n\n我们在表 12 中展示了一段由多智能体辩论模拟生成的庭审笔录示例。\n\n# C 数据展示\n\n详细列表见表 10。此外，我们在图 7 与图 8 分别给出了一审阶段与二审阶段的示例。\n\n# D 数据分析\n\n# D.1 数据描述我们之所以如此遴选案例，出于以下三项考量：  \n（1）**案由多样性**。基于对近年中国裁判文书网数据的统计分析，我们发现各类案件呈显著长尾分布。例如，图 9 显示，2022 年全部民事案件中，前 15 类案由已占案件总量的 $66\\%$。为更全面地反映法律实践光谱，我们着重保持案由类型的多样性；  \n（2）**案情分析与事实的清晰度**。我们精心选取裁判文书，要求其对案件分析详尽、事实认定清晰，以提升数据标注的质量与准确性，并帮助智能体更好地理解司法推理与法律条文；  \n（3）**裁判的唯一性与准确性**。我们优先选择经二审维持原判、未被改判的案件，以确保评估的一致性，因其已历经严格诉讼程序，裁判结果具备公允性。\n\n# D.2 数据质量检验\n\n首先，我们对所有文书的隐私信息进行处理。具体而言，我们已细致地对裁判文书中的敏感信息进行了匿名化。随后，在完成数据标注与隐私处理之后，我们从多个维度人工检验数据质量。\n\n**隐私信息处理**：我们已细致地对裁判文书中的敏感信息进行了匿名化。除将人名、地名、机构名替换为通用称谓外，还对可能泄露个人隐私的其他细节（如身份证号、电话号码、住址等）予以匿名化，以确保个人信息安全。\n\n**人工检验**：在完成数据标注与隐私信息处理后，我们对 SimuCourt 的数据质量进行人工检验：  \n（1）**符合案例标准**。所选样本须包含清晰的案件分析与事实，且未被二审改判；  \n（2）**信息标注准确**。标注须确保从原始法律文书中准确无误地提取关键信息，包括案件分析、法律条文及裁判结果；  \n（3）**隐私信息安全**。为安全……\n\n<table><tr><td>先例</td><td>粗检索</td><td>+ 重排序</td></tr><tr><td>Top1</td><td>62%</td><td>85%</td></tr><tr><td>Top2</td><td>60%</td><td>82%</td></tr><tr><td>Top3</td><td>61%</td><td>80%</td></tr></table>\n\n表 8：案由匹配结果\n\n<table><tr><td>检验维度</td><td>通过率</td></tr><tr><td>符合案例标准</td><td>98.6%</td></tr><tr><td>信息提取准确</td><td>95.8%</td></tr><tr><td>隐私信息安全</td><td>100%</td></tr><tr><td>平均</td><td>98.1%</td></tr></table>\n\n表 9：数据质量分析为保护个人隐私与数据安全，必须确保每一条数据记录均不包含任何可能泄露当事方敏感信息的内容。我们聘请三名研究生对所有 420 条已标注案例进行人工复核。经细致审查，本数据集展现出较高的质量水平。具体的质量指标与分析结果见表 9。\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/b9c50203d76da36abff6c94b4f00142ade63cf573c470777106404ed4bc040a7.jpg)  \n图 6：绝对差值变化。\n\n# E 自动评估细节\n\n# E.1 法律条文评估\n\n我们首先采用模式匹配对自由文本进行解析，随后与具体法律条款进行硬匹配。例如，见表 13。此时，TP（真正例）= 2，FP（假正例）= 1，FN（假负例）= 2，对应的 Precision = 2/3，Recall = 2/4。\n\n# E.2 民事与行政案件判决评估\n\n我们利用 GPT-4 对模型在民事与行政案件中生成的判决结果进行评估。如表 x 所示，我们给出一条评估示例，该示例同时作为 GPT-4 的提示演示。\n\n# John Smith 盗窃案\n\n案件类型：刑事  \n案由：盗窃  \n\n# 案件详情（一审）\n\n原告：人民检察院  \n被告：John Doe  \n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/495bde191deeb50326a990db5acd247bc71f200f72bbba6ed96490f236cfe075.jpg)\n\n被告背景：2017 年 1 月，John Doe 因盗窃被某人民法院判处有期徒刑七个月；2017 年 10 月，John Doe 再次被判处有期徒刑七个月……\n\n事实认定：2023 年 7 月至 8 月期间，被告 John Doe 驾车前往某公司车间大院 11 次，累计盗窃铝屑 4.28 余吨，后销赃得款 5.万余元……\n\n起诉书：经鉴定，涉案铝屑价值人民币 74,700 元。人民检察院指控被告犯盗窃罪，建议判处有期徒刑三年，并处罚金人民币 20,000 元……\n\n辩护律师意见：被告 John Doe 到案后如实供述上述犯罪事实，案发后其家属已全额退赔违法所得……\n\n被告陈述：John Doe 对起诉书指控的事实与罪名无异议，但辩称积极配合调查，请求从轻处罚……\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/e78d59ef84c804c3273780b86830cd5db469aab52f564aca48d84882e1dcd492.jpg)\n\n# 司法决策（输出）法院认为，被告人 John Doe 多次窃取公民财物，……，依法应予严惩；公诉机关指控的罪名成立。被告人到案后如实供述自己的罪行，……；辩护人所提对被告人从宽处罚的合理辩护意见，本院予以采纳……\n\n案例分析\n\n综上，依照《中华人民共和国刑法》第六十四条、第六十七条第三款、第二百六十四条及《……法律条文》第十五条之规定，判决如下：被告人犯盗窃罪，判处有期徒刑三年八个月，并处罚金人民币一万元。\n\n案例分析\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/d3892ce5471e6b891adec3ba6e87f84ddbe69b06dcb8fbb1e580078c65539261.jpg)\n\n法律条文\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/8a917379d5dcefec8def1811a7985f65fd265e53e0b445e5199d6a3c13d557ee.jpg)\n\n判决结果\n\n图 7：一审阶段示例案件（由中文翻译而来）。\n\n# John Smith 故意伤害案\n\n案件类型：刑事  \n案由：故意伤害  \n\n# 案件详情（一审）\n\n上诉人：John Smith（原审被告人）\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/591d7bf8ef66ab29ca9c56b97fed9f061c7ef60e919667dae8adb8fade851e85.jpg)\n\n被上诉人：人民检察院\n\n上诉人背景：2010 年 7 月，John Smith 因抢劫罪被判处有期徒刑二年，2012 年 12 月刑满释放。\n\n一审认定事实：2022 年 8 月，被告人 John Smith 因债务纠纷与 Emily Taylor（被害人，女，52 岁）发生口角，遂将 Emily Taylor 拽倒在地。经司法鉴定，Emily Taylor 的损伤程度为……\n\n一审司法分析：一审法院认为，被告人 John Smith 故意非法损害他人身体健康，致一人轻伤，……\n\n一审适用法律：《中华人民共和国刑法》第二百三十四条第一款、第六十七条第一款、第四十五条、第四十七条。\n\n一审判决：被告人 John Smith 犯故意伤害罪，判处有期徒刑六个月。\n\n上诉请求：原审被告人 John Smith 不服一审判决，提出上诉。上诉理由为：在讨债过程中，被害人 Emily Taylor 撕扯并辱骂上诉人，存在过错，依法应对上诉人的刑事责任予以减轻；一审法院未予认定，故请求……上诉人观点：  \n1. 上诉人对一审认定的犯罪事实及罪名不持异议，并自愿认罪；  \n2. 上诉人 John Smith 所经营的公司每年纳税逾 300 万元，带动了地方经济发展……；  \n3. 本案系突发，非上诉人本意。被害人索要工资，上诉人已赔偿 8 万元并取得谅解。故请求二审改判缓刑。  \n\n被上诉人观点：  \n一审法院认定 John Smith 故意伤害事实清楚，证据确实、充分，适用法律正确，定罪量刑准确；上诉理由缺乏事实与法律依据，建议二审法院维持……  \n\n二审认定事实：  \n经二审审查，确认原判认定 John Smith 故意伤害的事实清楚。二审期间，上诉人辩护人提交公司员工“请愿书”，证明 John Smith 平时表现良好。  \n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/7b0fa1a0a753b77d075134cea84353b6735b1dc17b5334ce07be7b87fe4fda04.jpg)\n\n# 司法裁判（输出）\n\n法院认为，John Smith 故意非法损害他人身体……一审认定事实清楚……案发后，上诉人 John Smith 自动投案……二审提交的材料表明，其所经营企业遭遇经营困难，导致工人收入……案例分析  \n\n综上，依照《中华人民共和国刑事诉讼法》第二百三十六条第一款第（二）项、第二百三十四条……法条  \n\n判决如下：上诉人犯故意伤害罪，判处有期徒刑六个月，缓刑一年。  \n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/8b64c3ca0564adccd619ef461b541ee33f8c2d5331049dab8acfc93c9e23f190.jpg)\n\n裁判  \n\n图 8：二审阶段示例案件（由中文翻译而来）。<table><tr><td>一审</td><td>二审</td></tr><tr><td>案件类型</td><td>案件类型</td></tr><tr><td>案由</td><td>案由</td></tr><tr><td>原告</td><td>上诉人</td></tr><tr><td>被告</td><td>被上诉人</td></tr><tr><td>被告背景信息</td><td>上诉人背景信息</td></tr><tr><td>起诉书</td><td>上诉状</td></tr><tr><td>辩护律师观点</td><td>上诉人观点</td></tr><tr><td>被告观点</td><td>上诉人观点</td></tr><tr><td>事实认定</td><td>一审事实认定</td></tr><tr><td>案件分析</td><td>一审司法分析</td></tr><tr><td>法律条文</td><td>一审法律条文</td></tr><tr><td>判决</td><td>一审判决</td></tr><tr><td></td><td>二审事实认定</td></tr><tr><td></td><td>案件分析</td></tr><tr><td></td><td>法律条文</td></tr><tr><td></td><td>判决</td></tr></table>\n\n表10：不同审理阶段的信息清单。\n\n![](/uploads/images/a7a677b6-fa0d-4923-8e5f-2960eea6e02d/bfe8ab0398dd14f722cbccdad31faa1c77b19b89fe00520391c27d595316a0b0.jpg)  \n图9：2022年民事案件案由统计\n\n<table><tr><td>案由</td><td>项目</td><td>内容</td></tr><tr><td rowspan=\"3\">盗窃罪</td><td>案件分析</td><td>法院认为，被告人John Doe多次窃取公民财物，构成盗窃罪，依法应予严惩。检察机关指控的罪名成立。被告人被抓获后如实供述罪行，自愿认罪，并退还部分赃物，依法可予从轻处罚。辩护人对被告人从宽处罚的合理辩护意见予以采纳。</td></tr><tr><td>法律条文</td><td>《中华人民共和国刑法》第六十四条；《中华人民共和国刑法》第六十七条第三款；《中华人民共和国刑法》第二百六十四条；《中华人民共和国刑事诉讼法》第十五条。</td></tr><tr><td>判决</td><td>定罪：被告人犯盗窃罪；刑期：判处有期徒刑三年八个月；罚金：并处罚金人民币一万元。</td></tr></table>\n\n表11：刑事案件示例输出<table>\n<tr><td>角色</td><td>记录</td></tr>\n<tr><td>审判员</td><td>（1）认定事实：2022年10月10日，被告人John Smith在酒店附近发现被害人David Lee佩戴一副金耳环，遂尾随其进入小巷，趁其不备从身后夺取该金耳环，得手后逃离现场……（2）被告人背景：John Smith曾因盗窃罪于2009年6月被某人民法院判处有期徒刑六个月；又因抢劫罪于2010年12月被某人民法院判处有期徒刑二年……（3）法庭纪律……现由原被告双方发表意见。</td></tr>\n<tr><td>公诉人</td><td>被告人John Smith以非法占有为目的，公然夺取他人财物，数额较大，其行为已触犯《中华人民共和国刑法》第二百六十七条，犯罪事实清楚，证据确实、充分，依法应以抢劫罪追究其刑事责任。</td></tr>\n<tr><td>被告人</td><td>我承认2022年10月10日的抢劫行为系一时冲动所致，案发后已如实供述罪行，恳请法官从轻处罚。</td></tr>\n<tr><td>公诉人</td><td>被告人曾因故意犯罪被判处有期徒刑，刑罚执行完毕后五年内再犯应当判处有期徒刑以上刑罚之罪，构成累犯，依法应从重处罚。</td></tr>\n<tr><td>被告人</td><td>我深刻认识到自己的行为给社会造成不良影响，给被害人带来无法挽回的损失。但我保证将积极赔偿被害人损失，真诚悔罪，自愿接受法院裁判。</td></tr>\n</table>\n\n表12：多智能体辩论模拟的庭审笔录示例（由中文翻译而来）。\n\n<table>\n<tr><td>引用法条</td><td>生成法条</td></tr>\n<tr><td>《中华人民共和国刑法》第六十七条第一款</td><td>《中华人民共和国刑法》第六十七条</td></tr>\n<tr><td>《中华人民共和国刑法》第五十二条</td><td>《中华人民共和国刑法》第五十三条</td></tr>\n<tr><td>《中华人民共和国刑法》第五十三条</td><td>《中华人民共和国刑法》第五十二条</td></tr>\n<tr><td>《中华人民共和国刑事诉讼法》第十五条</td><td></td></tr>\n</table>表13：参考法律条文与模型生成法律条文的对比（由中文翻译而来）。\n\n| 参考判决 | 生成判决 |\n|---|---|\n| 结果1：被告XYZ公司应于本判决生效之日起五日内返还原告租赁押金6000元及剩余租金17025元。 | 结果1：被告应于本判决生效之日起五日内返还原告押金6000元。 |\n| 结果2：被告XYZ公司应于本判决生效之日起五日内支付原告违约金5950元。 | 结果2：被告应于本判决生效之日起五日内返还原告剩余租金17025元。 |\n| 结果3：驳回原告的其他诉讼请求 |  |\n| GPT-4分析： |  |\n| 关键点匹配评估 | 标准答案共包含4个关键点：返还租赁押金6000元、返还剩余租金17025元、支付违约金5950元、驳回其他诉讼请求。生成答案的“结果1”匹配第一个关键点（返还租赁押金6000元），“结果2”匹配第二个关键点（返还剩余租金17025元）。因此，关键点匹配得分为2。 |\n| 答案准确性评估 | 生成答案共包含2个结果。生成答案的“结果1”准确匹配一个关键点且未包含错误信息，得1分；同理，生成答案的“结果2”准确匹配另一关键点且未包含错误信息，亦得1分。因此，准确性得分为2。 |\n| 输出结果 | 标准关键点数：4，关键点匹配得分：2，生成答案结果数：2，答案准确性得分：2 |\n| 精确率 | 答案准确性得分 / 生成答案结果数 = 2/2 |\n| 召回率 | 关键点匹配得分 / 标准关键点数 = 2/4 |\n\n表14：GPT-4评估器的提示示例（由中文翻译而来）。",
    "is_translated": true,
    "summary": "利用多智能体模拟完整庭审流程（法庭辩论、法条检索、判决精修），让大模型扮演法官、原告、被告等角色，通过对抗式辩论与知识增强生成可解释的司法判决。"
  },
  "be719944-4291-4fae-bb3f-988e09fa236b": {
    "id": "be719944-4291-4fae-bb3f-988e09fa236b",
    "filename": "computer-science-education-in-chatgpt-era-experiences-from-an-experiment-in-a-programming-course-for-novice-programmers.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/be719944-4291-4fae-bb3f-988e09fa236b_computer-science-education-in-chatgpt-era-experiences-from-an-experiment-in-a-programming-course-for-novice-programmers.pdf",
    "status": "completed",
    "created_at": "2025-12-17 15:42:23.850430",
    "updated_at": "2025-12-17 07:45:09.104812",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "error_message": null,
    "title": "Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers",
    "markdown_content": "Article\n\n# Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers\n\nTomaž Kosar  $^{1}$ , Dragana Ostojić  $^{1}$ , Yu David Liu  $^{2}$  and Marjan Mernik  $^{1, *}$\n\n$^{1}$  Faculty of Electrical Engineering and Computer Science, University of Maribor, Koroška cesta 46, 2000 Maribor, Slovenia; tomaz.kosar@um.si (T.K.); dragana.ostojic@um.si (D.O.)  \n$^{2}$  Department of Computer Science, State University of New York at Binghamton (SUNY), 4400 Vestal Parkway East, Binghamton, NY 13902, USA; davidl@binghamton.edu  \n* Correspondence: marjan.mernik@um.si\n\nAbstract: The use of large language models with chatbots like ChatGPT has become increasingly popular among students, especially in Computer Science education. However, significant debates exist in the education community on the role of ChatGPT in learning. Therefore, it is critical to understand the potential impact of ChatGPT on the learning, engagement, and overall success of students in classrooms. In this empirical study, we report on a controlled experiment with 182 participants in a first-year undergraduate course on object-oriented programming. Our differential study divided students into two groups, one using ChatGPT and the other not using it for practical programming assignments. The study results showed that the students' performance is not influenced by ChatGPT usage (no statistical significance between groups with a  $p$ -value of 0.730), nor are the grading results of practical assignments ( $p$ -value 0.760) and midterm exams ( $p$ -value 0.856). Our findings from the controlled experiment suggest that it is safe for novice programmers to use ChatGPT if specific measures and adjustments are adopted in the education process.\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/eb49dc1f10ab87bde16826b9ca39fe1d0427ab99cab4d4193f53a032be36f5ad.jpg)\n\nCitation: Kosar, T.; Ostojic, D.; Liu,\n\nY.D.; Mernik, M. Computer Science\n\nEducation in ChatGPT Era:\n\nExperiences from an Experiment in a\n\nProgramming Course for Novice\n\nProgrammers.Mathematics2024,12\n\n629. https://doi.org/10.3390/\n\nmath12050629\n\nAcademic Editor: Chengjie Sun\n\nReceived: 19 January 2024\n\nRevised: 16 February 2024\n\nAccepted: 18 February 2024\n\nPublished: 21 February 2024\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/7f2eb8cdeb3723210720814e6fc60b069ddbd623510666cb30c38698636f621e.jpg)\n\nCopyright: © 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).\n\nKeywords: large language models; ChatGPT; artificial intelligence; controlled experiment; object-oriented programming; software engineering education\n\nMSC: 97P10\n\n# 1. Introduction\n\nIn recent years, integrating new technologies such as online learning platforms, mobile devices, and virtual learning environments has revolutionized how educators deliver content and engage with students. These innovations have made education more accessible, personalized, and interactive. As a result, students can explore subjects in more depth and at their own pace. While we remain in the process of understanding and applying these technologies, a new one is already on the horizon, in the form of generative artificial intelligence (AI) [1].\n\nThe usage of large language models (LLMs) [2] has grown exponentially in recent years. One such model, ChatGPT [3], has garnered significant attention in the public since its launch in November 2022. ChatGPT is a chatbot developed by OpenAI [4] and enables users to have human-like conversations. ChatGPT can answer questions and assist with tasks like composing emails, essays, and even programming code [5,6]. On one hand, the generated text is plausible, making it a powerful tool. On the other hand, ChatGPT can be misused, e.g., students may cheat on their essays.\n\nIn the Computer Science education community, there is significant debate over using ChatGPT-generated code in classrooms. On the positive side, the benefits of using ChatGPT in education are well argued for [7]. For example, ChatGPT may provide students with a more\n\ninteractive and engaging learning experience, and increase their interest and motivation [8,9]. Computer Science students can ask questions about programming code and receive immediate answers, making learning programming more efficient [10]. Additionally, ChatGPT can generate several different examples to explain complex programming concepts [7].\n\nOn the flip side, some believe it is risky [11,12]. The LLM is limited by the knowledge it was trained on [7], giving a possibility of answering complex questions inaccurately [13]. Furthermore, code debugging and interpretation require a deep understanding of the code under consideration. The educator can provide a step-by-step explanation of the code, while current LLMs are still limited in this respect as shown in [14]. Another serious drawback of using ChatGPT is that it could discourage students from developing skills, e.g., reasoning [15]. If students rely excessively on ChatGPT to provide programming code, they may not develop the required skills to solve problems on their own. Excessive use and cheating are some Computer Science educators' major concerns regarding ChatGPT usage, especially for novice programmers (first-year students). In a nutshell, students cannot develop important skills, such as critical thinking, creativity, decision-making [16], and one of the essential capabilities for software developers, problem solving [17]. Some universities even decided to take measures in blocking access to the ChatGPT website on school grounds [18].\n\nHowever, LLM technologies are probably here to stay. We believe that, rather than avoiding these technologies, we need to embrace LLMs and modernize education [19]. To understand how LLMs and ChatGPT influence the learning process [16], there is a need for experimental studies [10,20-23]. We have to test common beliefs empirically and rigorously, such as the belief that students will use LLMs without hesitation for plagiarism [24], or thinking that using LLMs will affect their critical thinking and problem-solving skills negatively [16]. In this paper, we report our experience in ChatGPT-assisted learning in Programming II, a course in the second semester of the first year of the Computer Science and Information Technologies undergraduate program at the University of Maribor, Slovenia. Our experiment was motivated by the following questions:\n\n- Does the use of ChatGPT affect performance on practical assignments and midterm exam results?  \n- Does the use of ChatGPT affect the overall student performance in the introductory programming course?  \nWhat impact does ChatGPT usage have on the course final grade?  \n- For what purpose did students use ChatGPT during the course on Programming II?  \n- Is ChatGPT useful for learning programming at all, according to students' opinions?\n\nIn this context, we performed a controlled experiment [25] using ChatGPT for practical assignments in the first-year undergraduate study of Computer Science. We formed two groups, one using ChatGPT and the other not using it for practical assignments. Several adjustments were made for the execution of this year's introductory course on object-oriented programming.\n\nOur results from the controlled experiment show that overall performance in the course was not influenced by ChatGPT usage or the results on practical assignments or midterm exams. We believe a main contributor leading to this conclusion is the adjustments we have made to the course during (1) constructing assignments, (2) defending assignments, and (3) midterm exams. Those actions encouraged participants not to rely solely on the use of ChatGPT. For example, all our assignments were designed carefully to minimize the chance of ChatGPT answering the questions directly. As another highlight, we introduced an evaluation process, where assignment grading was not based solely on the code submitted to the original assignment questions; instead, grades were given in the lab session based on an extended version of the assignment, through an interactive defense process involving the students and the teaching assistants. Overall, we believe ChatGPT should be incorporated into future education, and it must be embraced with adjustments in course evaluation to promote learning.\n\nThe paper is divided into sections, presenting a different part of this experiment. Section 2 discusses the background on ChatGPT, Section 3 describes related work, and Section 4 the\n\nexperiment design. Section 5 presents the results and data analysis. Section 6 discusses the threats to the validity of our controlled experiment, and, lastly, Section 7 summarizes our key findings from our empirical study.\n\n# 2. Background\n\nLLMs [2] represent a transformative technology in the field of natural language processing (NLP) [26], bringing a new linguistic capability and opportunities for diverse applications. These models are designed with vast neural architectures, and supported by extensive training data [27]. LLMs empower applications to understand, generate, and manipulate human languages in ways that were previously impossible. The main feature of LLMs is that they generate text similar to human speech. One of the most well-known LLMs is Generative Pre-trained Transformer (GPT-3) [28] based on the transformer architecture [29] that improved NLP significantly.\n\nChatbots [30] are computer programs designed to simulate conversations in text (or voice [31]) over the Internet. They are programmed to understand natural languages and respond to user questions in a way that imitates human-to-human conversations. Chatbots can be categorized into two main types: rule-based and machine learning (sometimes referred to as AI-powered) chatbots [30]. Rule-based chatbots operate on predefined rules. They follow instructions and can provide responses based on specific keywords or phrases. Rule-based chatbots are limited in their capabilities, and may struggle with complex questions. On the other hand, AI-powered chatbots use advanced technologies, such as LLMs. They are capable of understanding context and learning from interactions and responses. Both types are often used in applications such as customer support, healthcare, information retrieval assistance, virtual assistance, education, marketing, etc.\n\nChatbots, empowered by LLMs, represent a significant milestone in the evolution of human-computer interaction. These intelligent agents have gone beyond traditional chatbots to engage users in natural, context-aware conversations. LLM-powered chatbots have an understanding of linguistic variations, making interactions feel more human-like and personalized. One such system is ChatGPT [3]. ChatGPT is the most popular chatbot supported by the LLM GPT-3, developed by OpenAI [4] and available publicly. It is proficient in mimicking human-like communication with the users. GPT-3 models are trained on extensive text data (approximately 175 billion trainable parameters and 570 GB of text [32]). During our experiment (from February till June 2023), we used ChatGPT with GPT-3.5, although GPT-4 was already available (March 2023) but not for free usage.\n\nPrompts [33] refer to the input provided to the chatbot to generate responses. Prompts are the human instructions or questions users provide while interacting with the chatbot. There are different types of prompts: text-based, voice-based, task-driven, informational, conversational, and programming prompts. In the latter, programmers can send specific programming prompts, including code snippets, and chatbots can respond with a context using this input. Hence, programmers (and other users) can modify and fine-tune the prompt through a process called prompt engineering, which instructs the LMMs better to provide more accurate and complex solutions. In this process, programmers can use prompt patterns [34], which are similar to software patterns, reusable prompts to solve common problems in LLM interaction. One such prompt pattern is the domain-specific language (DSL) [35,36] creation pattern.\n\n# 3. Related Work\n\nThe recent popularity of ChatGPT has brought much attention to its benefits (e.g., AI pair programming) or drawbacks (e.g., cheating) in different fields, as well as what impact that chatbot has on higher education [12] in general. Studies on its capabilities and limitations emerged almost as soon as the ChatGPT public release [37]. Our study contributes to this field, and we summarize these studies in this section.\n\nOne of the most closely related empirical studies involving ChatGPT in learning programming is reported by [21]. Similar to our study, theirs involved undergraduate students\n\ntaking the object-oriented programming course, over a smaller number of participants (41) but more experienced programmers, second-year students. Their participants solved practical assignments in different programming languages (Python, Java, and  $\\mathrm{C + + }$ ), while, in our study, practical assignments were only in  $\\mathrm{C + + }$ . The fundamental difference lies in the design: ours is a between-subjects (i.e., differential) study, while Yilmaz and Yilmaz is a within-subjects study: all participants in their study used ChatGPT to solve tasks, and then expressed their opinions in a survey with open questions. In contrast, our study consisted of two groups (ChatGPT and no ChatGPT), and compared the results between these two groups of participants. The participants in their study stated that the most significant advantage of ChatGPT is its time-saving factor, as they obtained reasonably accurate answers quickly, and thus saved time searching for answers. They also stated that it helped debug and solve complex problems and can be available 24/7. Although some participants have expressed that ChatGPT has no disadvantages, some pointed out the problem that its use can lead to laziness, weakened thinking skills, and occupational anxiety. ChatGPT may also produce the wrong answer. Overall, the participants had a positive perception, viewing it as beneficial for solving complex problems and learning unfamiliar topics, and as a helpful tool. The feedback study from our controlled experiment confirms the last findings of their work. Ref. [10] reports another related study with undergraduate students. Similarly to our controlled experiment, this paper reports on a between-subjects study with two groups, one utilizing ChatGPT and the other having access only to textbooks and notes without internet usage. While in [10], experimenters gave participants programming challenges after finishing the course, our participants worked on their assignments with adjustments during the course, during the semester, partially at home, and in the classroom within lab sessions. They did not report on any adjustments in assignments. In regard to findings, Ref. [10] concluded that the ChatGPT group achieved higher scores in less time while attempting tasks with defined problems, inputs and outputs, and constraints. The assessment was based on the number of test cases successfully passed. The results from our controlled experiment did not confirm these findings. Study [10] also reported that participants faced challenges handling more complex tasks and could not solve some problems entirely. They were also more inaccurate and inconsistent with the submitted code.\n\nAnother new study [22] treated ChatGPT as a student, and tested whether it could complete an introductory functional language programming course. It turned out that ChatGPT achieved an overall grade of  $67\\%$  (B-), thus ranking 155 out of 314 students. The study was conducted in two ways, unassisted and assisted, as a student would be in a natural process. They assisted ChatGPT using four prompt engineering techniques: paraphrasing the problem, providing hints, teaching by example, and giving test cases. ChatGPT solved 16 out of 31 tasks with a  $100\\%$  success rate without additional help. However, when errors did occur, they were of one type—compilation or logical errors, with syntax errors being less common. With assistance, the results from the ChatGPT \"student\" improved from a rank of 220 to 155. We share a similar experience, where for our practical assignments, ChatGPT scored 24 points out of 44 without additional prompts; with proper prompt engineering, the result would be around 34 points. In their study, the authors reported ChatGPT mostly had problems understanding type specifications, inferring the type of expression, and working with larger programming tasks. Because of these results, students who might use just the code provided from ChatGPT must undergo a defense of practical assignments. We followed the practice of defense consistently during our controlled experiment.\n\nTo investigate the impact of ChatGPT on Computer Engineering students, Ref. [23] conducted a controlled experiment in the Embedded Systems course. Their main goal was to check how far ChatGPT could help students answer quiz questions without learning the related topics. Afterwards, these results were compared to those of the previous generation of students answering the same questions after learning those topics. In our experiment, tasks were exclusively programming tasks; Shoufan used theoretical questions as well—true/false questions—while our tasks were connected with writing complete code,\n\ncode completion (given code), and code analysis (given inputs/outputs, etc.). Their study also differed from ours in topics (embedded systems vs. object-oriented programming), participant experience (senior vs. novice), and experience duration (four quizzes vs. a whole course). The findings from [23] concluded that the ChatGPT group performed better answering code analysis and theoretical questions but faced problems with code completion and questions that involved images. In writing complete code, the results were inconsistent. The author concluded that the usage of ChatGPT is currently insufficient in Computer Engineering programs, and learning related topics is still essential.\n\nAn interesting empirical study from Mathematics [19] explored the potential impact of ChatGPT on their students. The study also focused on essential skills for Computer Science students—how the use of ChatGPT can affect critical thinking, problem-solving, and group work skills. The opinions of participants after assignments on these three skills included a five-point Likert scale (from one “no affect”) to five (“it will affect a lot”). The average results on critical thinking (2.38), problem-solving (2.39), and group work (2.97) indicate that participants perceive ChatGPT as having a small-to-moderate effect on the acquisition of the skills as mentioned earlier. Group work appears to be the most affected skill. It would be interesting to see the same results for Computer Science students. It might be an exciting set of feedback questions for the replication study [38]. Instead of conducting a feedback study, assessment instruments can validate students' problem-solving skills [39] in, for example, object-oriented programming (OOP). The research findings of this study conclude that the integration of ChatGPT into education introduces new challenges, necessitating the adjustment of teaching strategies and methodologies to develop critical skills among engineers [19]. We followed the advice and adjusted practical assignments in our course, Programming II.\n\n# 4. Experiment Design and Goals\n\nOur controlled experiment aimed to compare participants' results during the semester. Particularly, we wanted to verify if ChatGPT usage during the semester influenced final grades, midterm exams, and lab work results. The study design and goals are presented in detail in this section.\n\n# 4.1. Controlled Experiment and Participants\n\nWe prepared a controlled experiment that was part of the Programming II course at the University of Maribor, Faculty of Electrical Engineering and Computer Science (FERI), taught by the fourth author; the teaching assistants were the first and second authors, while the third author was a Fulbright researcher visiting the University of Maribor at that time. The topics covered in the course are listed in Table 1. In our undergraduate program, the course Programming II is the first on object-oriented programming. We teach students basic object-oriented topics: we start with class definition, instance variables, methods, associations, inheritance, etc. Since we use  $\\mathrm{C}++$ , we end our class with new  $\\mathrm{C}++$  features. The participants in our study were first-year undergraduate students in the Computer Science program, one (out of two) major undergraduate Computer Science program in Slovenia, attracting the best students from the country. We started with 198 participants in the study, but eliminated a small number of participants for several reasons. Beyond nontechnical reasons, we also excluded those who did not complete any practical assignments or did not take midterm exams. Finally, our study contains the results of 182 students.\n\nThe empirical study was a between-subjects study. We met with all the students at the beginning of the semester to discuss our concerns about ChatGPT and our proposed experiment. After the students accepted it unanimously, we proceeded by dividing them into two groups, with 99 participants each. The division was random and performed by technical staff, and participants were advised to keep this information private from the lecturer and teaching assistants. We did not want this information to affect practical assignments, defenses, and midterm exams. In the rest of the paper, we refer to a treatment group, Group I, which was encouraged to use ChatGPT, and a control group, Group II,\n\nwhich was asked not to use ChatGPT. An additional measure we agreed upon was to remove students from Group II who reported using ChatGPT for practical assignments in the feedback questionnaire, as this would compromise the results of this group.\n\nTable 1. Topics covered in Programming II together with lab work assignments.  \n\n<table><tr><td rowspan=\"2\">Week</td><td rowspan=\"2\">Topic</td><td colspan=\"2\">Practical Assignments</td></tr><tr><td>Mandatory</td><td>Optional</td></tr><tr><td>1</td><td>Programming I repetition</td><td>Fuel Consumption</td><td>Disarium number</td></tr><tr><td>2</td><td>Basic classes</td><td>Exercise</td><td>Fuel Log</td></tr><tr><td>3</td><td>Class variables and methods</td><td>Time</td><td>Text Utility</td></tr><tr><td>4</td><td>Aggregation and composition</td><td>Exercise Tracker</td><td>Mail Box</td></tr><tr><td>5</td><td>Inheritance</td><td>Strength Exercise</td><td>Bank</td></tr><tr><td>6</td><td></td><td>Midterm exam I</td><td></td></tr><tr><td>7</td><td>Abstract class</td><td>Graph</td><td>Graphic Layout</td></tr><tr><td>8</td><td>Template function</td><td>Vector Util</td><td>Vector Util</td></tr><tr><td>9</td><td>Template class</td><td>Linear Queue</td><td>Linked List</td></tr><tr><td>10</td><td></td><td>Additional help</td><td></td></tr><tr><td>11</td><td>Operator Overloading</td><td>Smart Pointer</td><td>Smart Pointer</td></tr><tr><td>12</td><td>C++11 and C++14</td><td>Exercise Tracker</td><td>Printer</td></tr><tr><td>13</td><td>Exceptions, File streams</td><td>Sensor Hub</td><td>Log</td></tr><tr><td>14</td><td></td><td colspan=\"2\">Final practical assignments&#x27; defense</td></tr><tr><td>15</td><td></td><td colspan=\"2\">Midterm exam II</td></tr></table>\n\n# 4.2. Practical Assignments\n\nWeekly assignments were connected with the topics presented in the lecture (see Table 1, column Topics). The participants received a description of an assignment (a few lines of text) after a lecture, and they had to work solely at home on code until the next lab session, which took place at the faculty.\n\nThe practical part of the course Programming II consisted of 22 assignments, 11 mandatory and 11 optional (column Practical Assignments in Table 1). Each week, participants received one mandatory and one optional assignment. Both were worth an equal (two) points. Note that the semester lasts for 15 weeks. However, participants did not receive practical assignments during midterm exams. The defense of practical assignments was on the next lab session (after the lecture). Note that we construct new mandatory and optional assignments every year to prevent assignment solutions from being transmitted from the older generation to the new generation of students.\n\nFrom Table 1, we can observe that the problems were different each week; also, problems were varied for mandatory and optional assignments. We believe providing students with different problems influences their understanding of object-oriented programming positively.\n\nFigure 1 shows a typical example of an assignment (the practical assignments can be found on the project homepage: https://github.com/tomazkosar/DifferentialStudyChatGPT, accessed on 12 January 2024). A short description was given of what code participants needed to provide, together with a UML diagram for further details. Note that both groups were given identical assignments (those in the Mandatory and Optional columns from Table 1).\n\nTake task 4.1.\n\n- Modify the ExerciseTracker class so that instance variable exercises is of type vector<Exercise*>(composition).\n\n- Add a StrengthExercise class that inherits from the Exercise class.\n\n- The main function should have an ExerciseTracker object and add to exercises:\n\n3 examples of Exercise and  \n2 examples of StrengthExercise.\n\nSome guidance on solving the problem:\n\n- Beware of using protected, virtual, and override.\n\nWhen solving the task, take into account all the knowledge acquired so far (use of the initialization list, constant methods, write down the get/set methods where you need them, etc.).\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/39569b0b1f949cd66f99b3522406a96d8f5c2ad3328d06f2c7b0be24172ef400.jpg)  \nFigure 1. Example of practical assignment (mandatory in week 5).\n\n# 4.3. ChatGPT-Oriented Adjustments\n\nTo prepare for our experiment, we made a number of important adjustments to the course evaluation. In retrospect, these measures likely played an important role in helping us understand the best practices in teaching in the ChatGPT era.\n\n# 4.3.1. Question Preparation\n\nBefore the start of the semester, we analyzed the usage of ChatGPT to answer questions that we had asked Programming II students in prior years. We discovered that ChatGPT excelled at providing solutions to practical assignments with detailed descriptions in the text, a phenomenon also confirmed by recent research [40]. As a result, we decided to provide a number of adjustments, detailed in Table 2. The columns of this table are:\n\nType\n\nFor instance, an \"extension\" assignment means participants had to extend one of the previous practical assignments.\n\nCode provided\n\nSome assignments were constructed in a way that participants had to incorporate the given code in their applications.\n\nDescription\n\nSome assignments were provided with minimal text. Supplemental information was given in the UML diagram.\n\nInput/output\n\nThis means the student receives the input of their program or the exact output of the program, and they need to follow these instructions.\n\nMain\n\nFor some assignments, participants receive the main program and the assignment description.\n\nTable 2. Mandatory assignments with explanation.  \n\n<table><tr><td>Problem</td><td>Type</td><td>Code Provided</td><td>Description</td><td>Input/Output</td><td>Main</td></tr><tr><td>Fuel Consumption</td><td>new</td><td>yes</td><td>text</td><td>no</td><td>yes</td></tr><tr><td>Exercise</td><td>new</td><td>no</td><td>text</td><td>no</td><td>no</td></tr><tr><td>Time</td><td>new</td><td>no</td><td>text</td><td>no</td><td>no</td></tr><tr><td>Exercise Tracker</td><td>extension</td><td>yes</td><td>text</td><td>no</td><td>no</td></tr><tr><td>Strength Exercise</td><td>extension</td><td>no</td><td>UML</td><td>no</td><td>no</td></tr><tr><td>Graph</td><td>new</td><td>yes</td><td>UML</td><td>yes</td><td>yes</td></tr><tr><td>Vector Util</td><td>new</td><td>yes</td><td>text</td><td>yes</td><td>yes</td></tr><tr><td>Linear Queue</td><td>new</td><td>no</td><td>text</td><td>no</td><td>no</td></tr><tr><td>Smart Pointer</td><td>new</td><td>yes</td><td>text</td><td>no</td><td>no</td></tr><tr><td>Exercise Tracker</td><td>extension</td><td>no</td><td>text</td><td>no</td><td>yes</td></tr><tr><td>Sensor Hub</td><td>new</td><td>no</td><td>text + UML</td><td>no</td><td>no</td></tr></table>\n\nIn individual practical assignments, we incorporated one or more adjustments as shown in Table 2. It served as our guideline before constructing practical assignments. Our intention was to prevent ChatGPT from providing direct answers, which would have encouraged Group I students into relying blindly on ChatGPT. We used figures where possible (UML, I/O program, main program, etc.). The deficiency of ChatGPT with non-text-based prompts was known previously [40]. However, we also found that almost all our assignments could be answered by ChatGPT after several rounds of follow-up prompts provided by experienced programmers. On the other hand, novice programmers often have problems constructing the most effective prompts because of a lack of knowledge, the context of the problem, etc.\n\n# 4.3.2. Extended Assignment\n\nThe practical assignment we initially gave at the end of each lecture was incomplete. At the beginning of the following lab session, participants would be asked to work on an extension problem connected to the original assignment. During this session, participants were not allowed to receive assistance from ChatGPT or similar means (such as social media). Nonetheless, resorting to lecture notes, Internet, and application library documentation with examples was permitted and encouraged. Ultimately, students were asked to defend their code developed for the extended assignment, which we detail next. Overall, we found that some participants struggled for the whole lab session (3 h), while the others finished in 15 min. Usually, extensions were small, and the best participants could defend their assignments early in lab sessions. Please refer to Figure 2 for more details on the extended assignments.\n\nTask 5.1 From the Exercise class derive the CyclingExercise class and add instance variables distance (double) and indoor (bool). Update the main function so that the ExerciseTracker instance contains at least three instances of the new class.\n\nFigure 2. Example of extended assignment.\n\n# 4.3.3. Assignment Defense\n\nThe lab session of Programming II comes with a rigorous and interactive defense procedure. To each student, teaching assistants ask several basic questions regarding topics connected with the last lecture and practical assignment. This year, we made an additional effort in the defense process of the practical assignments. Plagiarism between students was a problem before ChatGPT. With ChatGPT, the defense needs to be even more detailed. Our defense process consists of the following simple questions and tasks for students:\n\nConceptual questions\n\nTypically, we asked participants to explain part of their programming code with an emphasis on object-oriented concepts.\n\nCode analysis\n\nUsually, we asked participants to search in code for specific functionality.\n\nCode changes questions\n\nMinimal change in the object-oriented part of the programs that change the code's behavior or improve the structure of the code.\n\nCode completion questions\n\nDemonstration of using object-oriented code in the main program.\n\nDefense is a time-consuming process. In our opinion, however, it is also essential for developing different programming skills (e.g., code refactoring) and general skills (e.g., critical thinking), particularly in the ChatGPT era.\n\n# 4.3.4. Paper-Based Midterms\n\nBeyond ChatGPT, there are other options for LLMs, such as CoPilot [41-43]. To evaluate whether students have obtained the knowledge and skills related to Programming II fairly, we decided to use paper-based midterm exams for all participants. Neither group was using computers or IDEs. With that, we had a fair comparison of the results between those two groups.\n\n# 4.4. Procedure and Data Collection Instrument\n\nThe experiment consisted of a background questionnaire at the beginning of the semester, weekly assignments (lab work) with a weekly feedback questionnaire, two midterm exams, and a final feedback questionnaire at the end of the semester.\n\nThe background questionnaire aimed to obtain demographic data from participants (age, gender, etc.) and measure their prior experience with the programming language  $C++$ , ChatGPT, and their interests in programming, artificial intelligence, etc. The latter questions were constructed using a five-point Likert scale [44] with 1 representing the lowest value and 5 representing the highest value. Altogether, there were ten questions. In Section 5, we only show a subset of questions from the background questionnaires most relevant to our experiment.\n\nWeek assignments (discussed extensively in previous subsections) were associated with weekly feedback. The feedback questionnaires were given to participants, measuring the participants' perspectives on assignment complexity and usage of ChatGPT. In particular, the latter aimed to address our concern about participation, ensuring that they still followed our division of two groups, one with ChatGPT support and the other without ChatGPT support.\n\nInstead of theoretical questions, the questions in the midterm exams are closer to practical assignments, covering most of the topics taught in the first half of the semester (first midterm exam) and the second half of the semester (second midterm exam). Each midterm exam consisted of a programming question. Usually, the final result is an object-oriented structure of a given problem and a main program using that structure. Both exams were paper-based.\n\nThe feedback questionnaire measured the participants' perspectives on the experiment in the Programming II course. The thirteen questions can be divided into two categories: course and experiment feedback. First, the participants indicated how well they compre\n\nhended the assignments in Programming II. The second part of the questionnaire focused on ChatGPT (consistency of usage/non usage, purpose of use, etc.). In this paper, we report on a subset of statistics from the feedback questionnaire most relevant to understanding the main study's results. The complete set of questions and answers of our background and feedback questionnaires are available at https://github.com/tomazkosar/DifferentialStudyChatGPT (accessed on 12 January 2024).\n\n# 4.5. Hypotheses\n\nOur experiment was aimed at confirming/unconfirming three hypotheses: one on midterm exams, one on lab work, and one on overall results. This leads to six possibilities:\n\n-  $H1_{\\mathrm{null}}$  There is no significant difference in the score of the participants' lab work when using ChatGPT vs. those without ChatGPT.  \n-  $H1_{\\mathrm{alt}}$  There is a significant difference in the score of the participants' lab work when using ChatGPT vs. those without ChatGPT.  \n-  $H2_{\\mathrm{null}}$  There is no significant difference in the results of the participants' midterm exams when using ChatGPT vs. those without using ChatGPT for lab work.  \n-  $H2_{\\mathrm{alt}}$  There is a significant difference in the results of the participants' midterm exams when using ChatGPT vs. those without using ChatGPT for lab work.  \n-  $H3_{\\mathrm{null}}$  There is no significant difference in the final grade of the participants when using ChatGPT vs. those without ChatGPT for lab work.  \n-  $H3_{\\mathrm{alt}}$  There is a significant difference in the final grade of the participants when using ChatGPT vs. those without ChatGPT for lab work.\n\nThese hypotheses were tested statistically, and the results are presented in the next section.\n\n# 5. Results\n\nThis section compares the participants' performance in Programming II in a ChatGPT treatment group (Group I) vs. a control group without ChatGPT (Group II). To understand the outcome of our controlled experiment, this section also presents a study on the background and feedback questionnaires. Hence, the results of the feedback study affected a number of participants in the groups. As explained in the feedback subsection, we eliminated eight students from Group II due to the usage of ChatGPT. The inclusion would have affected the results and represented a threat to the validity of our study.\n\nAll the observations were tested statistically with  $\\alpha = 0.05$  as a threshold for judging significance [45]. The Shapiro-Wilk test of normal distribution was performed for all the data. If the data were not normally distributed, we performed a non-parametric Mann-Whitney test for two independent samples. We performed the parametric Independent Sample  $t$ -test to check if the data were normally distributed.\n\n# 5.1. Participant Background\n\nThe background questionnaire measured the participants' demographics, prior experiences, and interests. The students' average age was 19.5 years. Regarding gender,  $85.9\\%$  defined themselves as men,  $12.4\\%$  female, and  $1.7\\%$  preferred not to say.\n\nIn this paper, we only show a comparison of the participants' opinions about knowledge of ChatGPT. We used a five-point Likert scale in the question, with one representing \"very bad knowledge\" and five representing \"very good knowledge\". Table 3 confirms no statistically significant differences between Group I and Group II. However, we were surprised by the participants' confidence in their knowledge of ChatGPT (the median for both groups was 3). The background study was conducted in February 2023, confirming our assumption that students would use ChatGPT in our course. Therefore, this evidence showed us that adjustments were needed in the execution of the Programming II course.\n\nTable 3. ChatGPT knowledge comparison between groups (Mann-Whitney test).  \n\n<table><tr><td>Part</td><td>Mean</td><td>N</td><td>Std. Dev.</td><td>B</td><td>Mean Rank</td><td>Z</td><td>p-Value</td></tr><tr><td>Group I</td><td>2.97</td><td>89</td><td>1.08</td><td>3.00</td><td>84.79</td><td rowspan=\"2\">-1.145</td><td rowspan=\"2\">0.252</td></tr><tr><td>Group II</td><td>3.17</td><td>88</td><td>1.05</td><td>3.00</td><td>93.26</td></tr></table>\n\n# 5.2. Comparison\n\nTable 4 shows the results of both groups' performance in lab work. The average lab work success of Group I, which used ChatGPT, was  $65.27\\%$ , whilst the average score of Group II (no ChatGPT) was only slightly better,  $66.72\\%$ . Results around  $66\\%$  are due to participants' decisions to finish just mandatory assignments; only a small number of students decided to work on optional assignments. Note that the mandatory and optional weekly assignments are complementary—usually, optional assignments cover advanced topics. Table 4, surprisingly, shows that results from the lab work on Group I were worse, and, with that, not statistically significantly better compared to the lab work results from Group II. Hence, we can conclude that using LLM is not a decisive factor if the right actions are taken before the execution of the course. These results are discussed further in the section on threats to validity, where concerns are provided regarding our controlled experiment.\n\nTable 4. Comparison of practical course success between groups (Mann-Whitney Test).  \n\n<table><tr><td>Part</td><td>Mean</td><td>N</td><td>Std. Dev.</td><td>Median</td><td>Mean Rank</td><td>Z</td><td>p-Value</td></tr><tr><td>Group I</td><td>65.27</td><td>93</td><td>26.11</td><td>63.00</td><td>92.67</td><td rowspan=\"2\">-0.306</td><td rowspan=\"2\">0.760</td></tr><tr><td>Group II</td><td>66.72</td><td>89</td><td>19.71</td><td>63.00</td><td>90.28</td></tr></table>\n\nTable 5 compares the performance (by percentage) of the first, second, and overall (average) groups in the midterm exams. Group I (ChatGPT) and Group II (no ChatGPT) solved the same exams. From Table 5 it can be observed that Group I (ChatGPT) performed slightly better than Group II (no ChatGPT) in terms of average success (mean) on the first midterm. However, the difference was small, and not statistically significant. In both groups, the results of the second midterm exam were approximately  $10\\%$  worse compared to the first midterm exam. We believe these results are connected with the advanced topics in the second part of the semester in the course of Programming II; this is a common pattern observed every year. In the second midterm exam, the results were opposite to the first midterm exam—Group II (no ChatGPT) outperformed treatment Group I (ChatGPT) by around  $2\\%$ . Still, the results were not statistically significantly better. The latter observation is also accurate for the overall midterm results (average between the first and second midterms)—we could not confirm statistically significant differences between the midterm results between both groups. However, Group II (no ChatGPT) performed slightly better  $(65.96\\%$  vs.  $66.58\\%)$ . Before the experiment, we assumed that Group I (ChatGPT) would have significantly worse results than Group II, which was wrong. As described earlier, both groups were involved in paper-based midterm exams.\n\nTable 5. Comparison of midterm success between the groups (Mann-Whitney test).  \n\n<table><tr><td>Midterm</td><td>Part</td><td>Mean</td><td>N</td><td>Std. Dev.</td><td>Median</td><td>Mean Rank</td><td>Z</td><td>p-Value</td></tr><tr><td rowspan=\"2\">First</td><td>Group I</td><td>68.98</td><td>93</td><td>24.94</td><td>79.00</td><td>93.11</td><td rowspan=\"2\">-0.421</td><td rowspan=\"2\">0.674</td></tr><tr><td>Group II</td><td>67.89</td><td>89</td><td>23.66</td><td>74.00</td><td>89.82</td></tr><tr><td rowspan=\"2\">Second</td><td>Group I</td><td>55.72</td><td>81</td><td>21.45</td><td>60.00</td><td>75.23</td><td rowspan=\"2\">-0.666</td><td rowspan=\"2\">0.505</td></tr><tr><td>Group II</td><td>58.12</td><td>73</td><td>21.17</td><td>60.00</td><td>80.02</td></tr><tr><td rowspan=\"2\">Overall</td><td>Group I</td><td>65.96</td><td>81</td><td>18.29</td><td>71.00</td><td>76.88</td><td rowspan=\"2\">-0.181</td><td rowspan=\"2\">0.856</td></tr><tr><td>Group II</td><td>66.58</td><td>73</td><td>17.70</td><td>70.50</td><td>78.18</td></tr></table>\n\nThe results were similar for comparison of the overall results. Table 6 shows that Group I's average score of overall success was  $65.93\\%$ . In contrast, Group II achieved a slightly higher average score of  $66.61\\%$ . Note that the overall grade breakdown was constituted from  $50\\%$  of midterm exams and  $50\\%$  of practical assignments. The students received bonus points for extra tasks (usually, no more than  $5\\%$ ). Table 6 reveals no statistically significant difference between the overall success of Group I and Group II, as determined by the Mann-Whitney test.\n\nTable 6. Comparison of course final achievements between the groups (Mann-Whitney test).  \n\n<table><tr><td>Part</td><td>Mean</td><td>N</td><td>Std. Dev.</td><td>Median</td><td>Mean Rank</td><td>Z</td><td>p-Value</td></tr><tr><td>Group I</td><td>65.93</td><td>93</td><td>25.14</td><td>68.00</td><td>92.82</td><td rowspan=\"2\">-0.345</td><td rowspan=\"2\">0.730</td></tr><tr><td>Group II</td><td>66.61</td><td>89</td><td>21.34</td><td>66.00</td><td>90.12</td></tr></table>\n\nThese results (see Tables 4-6, again) allow us to accept all three null hypotheses, and confirm that, in our study, there was no influence of ChatGPT on midterm exams, practical assignments, and final results.\n\n# 5.3. Feedback Results\n\nAs described in Section 4.4, in the last week of the semester, we asked participants to complete a questionnaire about the course and specific actions devoted to ChatGPT. The feedback provided by the students at the end of the semester provided a further understanding of the previous subsection's results.\n\nThe participants could answer questions from home (the questionnaire was on our course web page). However, if they came to the last week's lab session, they were encouraged to fill in a questionnaire at the beginning. Note that the number of received answers deviates from the number of participants involved in the midterm exams (i.e., Group I submitted 69 answers while 81 participated in the second midterm exam). We submitted additional messages to participants, but some did not respond to our calls. The missing feedback corresponds to dropout students who did not finish this course and were not present in the classroom at the end of the semester. This is one of the threats to validity and is discussed further later.\n\n# 5.3.1. Course Complexity\n\nTable 7 shows the results from the feedback questionnaire, where the participants' perspectives were captured on the complexity of the whole course. We used a five-point Likert scale, with one representing \"low complexity\" and five representing \"high complexity\". Unsurprisingly, the results show that course complexity was higher for Group II (3.01 vs. 3.17), which did not use ChatGPT. However, the Mann-Whitney test did not exhibit statistically significant differences (Table 7). The statistical test results suggest that the course was equally complex for both groups. We speculate that the slightly different results in course complexity may result from the support of ChatGPT in helping participants understand the course topics better.\n\nTable 7. Participants' opinion on course complexity between the groups (Mann-Whitney test).  \n\n<table><tr><td>Part</td><td>Mean</td><td>N</td><td>Std. Dev.</td><td>Median</td><td>Mean Rank</td><td>Z</td><td>p-Value</td></tr><tr><td>Group I</td><td>3.01</td><td>69</td><td>0.80</td><td>3.00</td><td>63.45</td><td rowspan=\"2\">-1.205</td><td rowspan=\"2\">0.228</td></tr><tr><td>Group II</td><td>3.17</td><td>64</td><td>0.72</td><td>3.00</td><td>70.83</td></tr></table>\n\n# 5.3.2. The Usage of ChatGPT during the Semester—Group II\n\nAlthough we agreed with students to have two groups—one using ChatGPT and the other not, we were not sure if they would obey this decision. Therefore, we asked both\n\ngroups weekly if they were using ChatGPT and for what purpose. The results showed that both groups followed our suggestions.\n\nHowever, some students from Group II did not follow the instructions, as indicated in Figure 3, and used ChatGPT for almost every practical assignment. We decided to eliminate these eight students from the background, study, and feedback results since they corrupted the group, and inclusion would compromise the statistical results as explained earlier in this section. This is why the number of participants in Group II is slightly smaller than in Group I.\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/d9226962902af2c56ce210feb1a2f66c14874486e336e256f89415ed3e63cdac.jpg)  \nFigure 3. Number of participants in Group II that used ChatGPT regularly for practical assignments.\n\n# 5.3.3. The Usage of ChatGPT during the Semester—Group I\n\nWe warned Group I that excessive use of ChatGPT can lead to worse results on the paper-based midterm exams. Figure 4 confirms that most participants took our advice.\n\nOne of the motivating research questions from the Introduction section is whether students would use ChatGPT without hesitation if we allowed it. Figure 4 shows that, although 69 participants were allowed to use ChatGPT in Group I, only 21 reported using it for all assignments. These results indicate that the measures taken before and between semesters (e.g., hand-written exams and additional tasks in the classroom) probably affected the participants' decision not to use ChatGPT too frequently.\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/2e925604e72d641b40a7123a3d5d969b61ee9b7ed7693b6dbb66de20ee96134b.jpg)  \nFigure 4. Number of participants in Group I that used ChatGPT regularly for practical assignments.\n\n# 5.3.4. Influence of ChatGPT on Exam Grade\n\nOur concern before the semester was how ChatGPT usage would influence knowledge and students' grades. Despite our concerns, Figure 5 shows only 44 participants from Group I (ChatGPT), which is only half of all responses, answered with the benefits of its use with lab work assignments. From these results, we cannot state that we received unanimous results.\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/99a65cba6f4daefb773f92f5f19821823841c5c5f59e2370e828647946f2c573.jpg)  \nFigure 5. The positive impact of ChatGPT on course grade (Group I).\n\n# 5.3.5. Means of Use\n\nSoftware engineers may use ChatGPT for a wide variety of purposes, such as code generation, optimization, comparison, and explanation. In our classroom setting we wanted to minimize code generation as much as possible through adjustments for practical assignments.\n\nFigure 6 reveals that the adjustments served their intended goals. The participants of Group I were using it more for code optimization and comparison with their code than code generation. Again, we can assume that our actions and specific decisions before the semester did affect the use of code generation. Note that Figure 6 shows the results of a multiple-response question—participants chose one or more answers from various alternatives.\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/b7d445ac9b19849a5d35c11241fe63fc7a58350bd27c65a2b2a60d5bab845edb.jpg)  \nFigure 6. The purpose of ChatGPT use (Group I).\n\n# 5.3.6. Code Understandability\n\nWe were also interested in the satisfaction of the programming code received from ChatGPT. Therefore, Group I (ChatGPT) answered questions regarding the understandability of the code received from ChatGPT.\n\nAgain, we used a five-point Likert scale in this question, with one representing \"not understandable\" and five meaning \"very understandable\". From Figure 7, we can see that the code received from ChatGPT was very understandable to Group I. Most participants marked understandable or very understandable (four or five in Figure 7).\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/44b0fd14559cf672e2f8f53ad2a814ab50075e6e5b1077ff07fa0e5ac38281a9.jpg)  \nFigure 7. The understandability of code received from ChatGPT (Group I).\n\n# 5.3.7. Acceptance of ChatGPT among Students outside Programming\n\nWe wanted to know whether ChatGPT is accepted among students beyond programming assistance. Since its release in November 2022,  $70\\%$  of our students reported regular use in June 2023. The participants often reported explanations, instructions, understanding, examples, etc. Some exciting uses can also be seen from the word cloud in Figure 8 (life, generating, summaries), some study-specific (theory, algorithms, concepts, code, syntax, etc.), and some general ones as well (search, every day, everywhere, etc.).\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/0ee72b487b8c3432b16cd5243d16245b6902202508f0d6ad6a76d23d7692f9a9.jpg)  \nFigure 8. Uses of ChatGPT beyond programming.\n\n# 5.3.8. Future Use of ChatGPT in Programming\n\nAs a final question, the participants answered whether they would use ChatGPT for programming in the future. Most answers from Group I were positive as seen in Figure 9. To comprehend the high confidence in future technology adoption depicted in Figure 9, it is imperative to contextualize these findings within a broader context and correlate them with the insights gleaned from Figures 6 and 7. As illustrated in Figure 6, Computer Science students leverage ChatGPT for multifaceted self-assistance, extending beyond tasks such as code optimization and comparison to encompass various other applications as evidenced by the notable proportion of respondents selecting \"other\" in Figure 6. Additionally, Figure 7 underscores the exceptional clarity of the generated program code. We believe the combination of these factors has influenced the substantial percentage of students expressing their intent to continue utilizing ChatGPT in the future significantly.\n\nThe comparison between Figures 4 and 9 reveals that we introduced specific changes to lab work assignments successfully. Although they liked to use the ChatGPT as a programming assistance tool (Figure 9), they were not able to use it in our specific execution as much as they would want to (Figure 4).\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/9adf999d07e4cf9d9d9f73f91b9f1ac0e80e28a226ccf5487e274ac91b8ea999.jpg)  \nFigure 9. Future use of ChatGPT for programming.\n\n# 6. Threats to Validity\n\nThis section discusses the construct, internal, and external validity threats [46] of our controlled experiment.\n\n# 6.1. Construct Validity\n\nConstruct validity is how well we can measure the concept under consideration [47,48]. In our experiment, we wanted to measure the effect of ChatGPT on the Programming II course results.\n\nWe designed several assignments in which the participants were asked to understand the description of the problem and provide implementation in  $\\mathrm{C + + }$  code. With ChatGPT available, we adjusted the assignment definitions. These adjustments made assignments diverse in type (new or extensions), provided code, input/output, the given main program, etc. Figures were given where possible. The participants had to provide a complete implementation. Hence, additional functionalities were given to the participants in the lab session. It is possible that a specific assignment chosen or additional functionality given in the lab session or assessment could have affected the results. However, we have no evidence to suggest that this threat was present.\n\nThe complexity of assignments could cause another threat to validity. Altogether, there were 22 assignments, 11 of which were mandatory. We started with simple object-oriented problems: the first assignments had only one class, the following mandatory assignment used aggregation, the compulsory next assignment included inheritance, etc. These assignments started with straightforward problems and advanced during the semester. At the end of the semester, practical assignments contained ten or even more classes. It is unclear if our conclusions would remain the same if all the assignments were equally complex and how the complexity of programming tasks affected the assistance from ChatGPT (Group I). Indeed, the number of classes included in a single assignment is only one complexity metric; additional considerations include control flows and the programming constructs in the code. In general, however, our participants needed much more time to solve practical assignments at the end of the semester than at the beginning.\n\nOur midterm exams are designed to test theoretical knowledge through practical assignments. Therefore, midterm exams are close to the practical assignments given to participants just before the midterm exam. From the point of view of construct validity, we would not know the outcome if we had theoretical questions directly in the midterm exams.\n\nAnother construct validity concern is the choice of programming languages used for the course: how programming languages affect ChatGPT-generated results and the measured impact of ChatGPT. It would be interesting to have a replication study [49,50] with another programming language for first-year students (e.g., Python).\n\nWhile ChatGPT is a leading contender in LLMs, alternative models exist (e.g., Claude). Our weekly feedback questionnaires did not explore the usage of other LLMs, and our findings are restricted to ChatGPT. In addition, in spite of our recommendation of GPT-3.5, some participants may have acquired GPT-4, which was released during the execution of our experiment. We did not account for or inquire about this variable in the experiment or feedback questionnaire. Consequently, we cannot ensure that certain students in Group I did not leverage GPT-4, potentially influencing better results, particularly in practical assignments involving UML class diagrams.\n\nIn our experiment, we did not isolate the impact of ChatGPT on Group II participants. Alternative assistance sources were available to Group II participants throughout the semester. Considering the potential substitution effect of other online resources, any observed differences between the groups may not precisely capture the distinct influence of ChatGPT access. It is worth mentioning that these alternative resources were equally accessible to Group I participants, too. Consequently, the sole distinguishing factor between the two groups is the utilization of ChatGPT for Group I.\n\nThe infrequent ChatGPT usage by Group I participants (Figure 4) may in part result from the format of paper-based midterm exams. In addition, infrequent use may contribute to a lack of familiarity with employing ChatGPT effectively, potentially reducing the difference between the control and treatment groups. While these factors may be viewed as threats to the construct validity, they are aligned with our goal of collecting empirical evidence if we should encourage/discourage future students in Programming II from\n\nutilizing ChatGPT and similar LLMs. In our view, the autonomy granted to participants in Group I to decide whether to leverage LLMs when encountering challenges or learning new concepts—instead of forcing all participants in that group to use ChatGPT frequently—is a feature consistent with realistic classroom learning. Our results affirm the potential to permit and facilitate the use of LLMs in the subsequent executions of the Programming II course if the assessment stays the same or similar.\n\n# 6.2. Internal Validity\n\nInternal validity is the degree of confidence that other confounding or accidental factors do not influence the relationship under test.\n\nThere is a potential risk that the participants in Group II also used ChatGPT. To overcome this threat, participants were required to report their ChatGPT usage weekly. We asked them again in the final feedback questionnaire. We saw no considerable deviation from the final report compared to the weekly reports. Therefore, we only provide final feedback on ChatGPT usage in the paper (see Figure 3, again), and, as described in Section 5, eliminated eight participants (who reported using ChatGPT in Group II) from the statistical results.\n\nSome participants also expressed their disapproval of the midterm exams being performed on paper rather than on computers. The participants were missing the basic tools provided by IDEs, like code auto-complete, syntax highlighting, and code generation (constructors, set/get methods) that are usually provided by IDEs like CLion, a recommended IDE in the course Programming II development environment for lab work. We chose the offline approach for two different reasons. First, this controlled experiment was performed with first-year students. Some of them started with programming a few months ago. Therefore, we did not want them to use Copilot or similar AI tools that help students with code generation. The other reason is connected to their experience with IDEs. We wanted to measure the participants' understanding and ability to provide object-oriented code, and avoid the influence of their experience with IDEs.\n\nThe feedback study was an optional assignment at the end of the semester. Some participants did not complete the questionnaire in our e-learning platform (49 out of 182). The missing responses represent a selection threat because the effect on the feedback of the missing results is unknown. Nonetheless, since the missing feedback represents  $27\\%$  of all the participants, this is not a severe threat to the validity of our controlled experiment.\n\nAnother internal threat to validity arises due to the absence of training on the effective utilization of ChatGPT provided to students. Had the tool been employed in conjunction with training, the learning outcomes could have potentially differed for Group I, and, consequently, the outcomes could have varied from the one obtained in our study. It is worth mentioning that novice programmers frequently encounter challenges in formulating prompts, due to a deficit in understanding the notion of large language models. This limitation underscores the importance of incorporating comprehensive training to enhance students' proficiency in utilizing ChatGPT effectively and maximizing its potential. The same is true for conducting empirical studies on ChatGPT.\n\n# 6.3. External Validity\n\nExternal validity examines whether the findings of an experiment can be generalized to other contexts.\n\nSince only first-year students participated in our experiment, there is an external validity threat to whether the results can be generalized to students from other study years. Again, in this empirical research, we were interested in novice programmers.\n\nAnother external validity threat is the generalization of the study results to other courses—we do not know what the results would be if this experiment were part of other courses in the same school year.\n\nThis study shows no statistically significant difference in the usage of ChatGPT on midterm results and practical assignments. It would be interesting to see whether results\n\nmay differ for sub-categories of students taking Programming II, such as those with significant prior programming experiences, or those who have previously taken certain courses.\n\nThe findings of this study stem from an experiment conducted at a single university, prompting considerations regarding the generalizability of the results. Our outcomes may be subject to influence from factors such as demographic characteristics, cultural nuances, and the scale of the institution (specifically, the number of computer science students). To address this limitation, we reveal data from our experiment and encourage replications. Engaging in multi-institutional and multinational studies could provide a more comprehensive understanding of ChatGPT's impact on the learning experiences of novice programmers in computer science education, yielding more precise and robust results.\n\n# 7. Conclusions\n\nChatGPT has proven to be a valuable tool for many different purposes, like providing instant feedback and explanations. However, many skeptics emphasize that ChatGPT should not substitute learning and understanding in classrooms. We must exchange opinions and experiences when a transformative and disruptive technology occurs in the education process. Our study was motivated by this high-level goal.\n\nThis paper presents a controlled experiment that analyzes whether ChatGPT usage for practical assignments in a Computer Science course influences the outcome of learning. We formed two groups of first-year students, one that was encouraged to use ChatGPT and the other that was discouraged. The experiment evaluated a set of common hypotheses regarding the results from lab work, midterm exams, and overall performance.\n\nThe main findings suggest the following:\n\nComparing the participants' success in practical assignments between groups using ChatGPT and others not using it, we found that the results were not statistically different (see Table 4, again).\n\nWe prepared assignments and lab sessions in a way that minimized the likelihood that ChatGPT may help participants blindly without learning. Our results confirm that our efforts were successful.\n\nComparing the participants' success in midterm exams between groups using ChatGPT and others not using it, we found that the results were also not statistically different (see Table 5, again).\n\nAlthough Group I was using ChatGPT, our adjustments probably resulted in enough effort in learning by that treatment group. Therefore, their results were equal to the control group that was discouraged from using ChatGPT.\n\nComparing the participants' overall success in a course on Programming II between groups using ChatGPT and others not using it, we found that the results were also not statistically different (see Table 6, again).\n\nThis means that our specific execution of the course (with all the introduced adjustments) allows using ChatGPT as an additional learning aid.\n\nOur results also indicate that participants believe ChatGPT impacted the final grade positively (Figure 5), but the results do not confirm this on the lab work (Table 4), midterm exams (Table 5), nor the final achievements (Table 6). They also reported positive learning experiences (e.g., program understanding; see Figure 7). In addition, we found that ChatGPT was used for different purposes (code optimization, comparison, etc., as indicated in Figure 6). The participants confirmed strongly that they will most likely use ChatGPT (Figure 9).\n\n# Future Work\n\nOur study results and ChatGPT-oriented adjustments must be taken with caution in the future. Improvements in large language models will likely affect adjustments (specifically for practical assignments). ChatGPT's ever-evolving nature will probably drive our adjustments tailored to AI technology's current state. ChatGPT-oriented adjustments might erode relevance swiftly, necessitating periodic updates and reassessments to remain robust and practical. We wish to emphasize the importance of assignment defenses and the accompanying discussion with a student. For courses where interactive assignment\n\ndefenses are not used as a key form of evaluation, the adoption of ChatGPT may need to be considered carefully. For example, if teaching assistants were only to test the correctness of the code submitted by students without any interactive communication, the results of the evaluation may be different.\n\nThis study needs additional replications [38,49]. Different problems (applications) need to be applied to lab work with a different programming language, to name a few possibilities for strengthening the validity of our conclusions. In addition, we need to compare the results from midterm exams using IDE support. It would be interesting to see how the use of development tools affects the results of midterm exams. We are also interested in using our experiment design and specific adjustments in the introductory programming (CS1) course, an introductory course in the Computer Science program, as ChatGPT is successful with basic programming concepts and providing solutions. An empirical study to understand the obtained essential skills (critical thinking, problem-solving, and group work skills) [19] is also necessary, to understand its potential impact for future Computer Science engineers. As discussed in the section on threats to validity, broadening the perspective in replicated studies to involve more institutions and conducting a multi-institutional and multinational study has the potential to yield a deeper comprehension of the integration of large language models in education, leading to more precise and robust outcomes compared to the results presented in this study.\n\nOur future research endeavors in empirical studies with students and ChatGPT should address the limitations of traditional performance comparative metrics (also used in this empirical study). By enriching our research with qualitative assessments, we could uncover profound insights into cognitive engagement and pedagogical interactions driven by AI technology. These metrics could offer a more comprehensive understanding of its impact on teaching and learning processes.\n\nBesides the research directions highlighted above, there exist a multitude of directions associated with the integration of AI technology into pedagogical processes that warrant further investigation. It is essential to delve deeper into the identified risks associated with integrating ChatGPT into educational settings. These risks include the potential unreliability of generated data, students' reliance on technology, and the potential impact on students' cognitive abilities and interpersonal communication skills. Exploring these risks comprehensively is crucial for informing educators about the challenges and limitations of incorporating AI technology in pedagogy. Another intriguing direction for research would involve examining the positive impacts of ChatGPT. Future experiments aimed at investigating the potential educational benefits of large language models could yield crucial insights into their overall impact on learning. On the other hand, we must study the benefits not only for students but also for educators. These include educators' abilities to automate various tedious tasks, such as assessment preparation, monitoring academic performance, generating reports, etc. This technology can act as a digital assistant for educators, assisting with generating additional demonstration examples and visual aids for instructional materials. Understanding how educators utilize these positive features can provide insights into optimizing ChatGPT's role in educational environments. Furthermore, future research should address the limitations of ChatGPT in answering questions. Examining students' reactions when ChatGPT fails to answer questions correctly is essential for understanding their perceptions and experiences with AI technology in learning contexts. This insight can guide the development of interventions to support students' interaction with ChatGPT and mitigate potential frustrations or challenges they may encounter. These and many more topics hold great relevance for the education community and merit thorough exploration.\n\nAuthor Contributions: Conceptualization, T.K.; methodology, T.K.; software, T.K. and D.O.; validation, M.M. and Y.D.L.; investigation, T.K., D.O., M.M. and Y.D.L.; writing—original draft preparation, T.K., D.O., M.M. and Y.D.L.; writing—review and editing, T.K., D.O., M.M. and Y.D.L. All authors have read and agreed to the published version of the manuscript.\n\nFunding: The first, second and fourth authors acknowledge the financial support from the Slovenian Research Agency (Research Core Funding No. P2-0041). The third author acknowledges the financial support from the Fulbright Scholar Program.\n\nInstitutional Review Board Statement: Ethical review and approval were waived for this study because the tests had the form of a midterm exam.\n\nInformed Consent Statement: Informed consent was obtained from all subjects involved in the study.\n\nData Availability Statement: The data presented in this study are available in https://github.com/tomazkosar/DifferentialStudyChatGPT, accessed on 12 January 2024.\n\nAcknowledgments: The authors wish to thank the whole team of the Programming Methodologies Laboratory at the University of Maribor, Faculty of Electrical Engineering and Computer Science, for their help and fruitful discussions during the execution of the controlled experiment.\n\nConflicts of Interest: The authors declare no conflicts of interest.\n\n# References\n\n1. Stokel-Walker, C.; Van Noorden, R. What ChatGPT and generative AI mean for science. Nature 2023, 614, 214-216. [CrossRef]  \n2. MacNeil, S.; Tran, A.; Mogil, D.; Bernstein, S.; Ross, E.; Huang, Z. Generating diverse code explanations using the GPT-3 large language model. In Proceedings of the 2022 ACM Conference on International Computing Education Research, Virtual, 7-11 August 2022; Volume 2, pp. 37-39.  \n3. Radford, A.; Narasimhan, K.; Salimans, T.; Sutskever, I. Improving Language Understanding by Generative Pre-Training. 2018. Available online: https://www.mikecaptain.com/resources/pdf/GPT-1.pdf (accessed on 24 September 2023).  \n4. OpenAI. ChatGPT. 2023. Available online: https://chat.openai.com/ (accessed on 24 September 2023).  \n5. Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H.P.d.O.; Kaplan, J.; Edwards, H.; Burda, Y.; Joseph, N.; Brockman, G.; et al. Evaluating large language models trained on code. arXiv 2021, arXiv:2107.03374.  \n6. Tian, H.; Lu, W.; Li, T.O.; Tang, X.; Cheung, S.C.; Klein, J.; Bissyandé, T.F. Is ChatGPT the Ultimate Programming Assistant-How far is it? arXiv 2023, arXiv:2304.11938.  \n7. Rahman, M.M.; Watanobe, Y. ChatGPT for education and research: Opportunities, threats, and strategies. Appl. Sci. 2023, 13, 5783. [CrossRef]  \n8. Shoufan, A. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access 2023, 11, 38805-38818. [CrossRef]  \n9. Muñoz, S.A.S.; Gayoso, G.G.; Huambo, A.C.; Tapia, R.D.C.; Incaluque, J.L.; Aguila, O.E.P.; Cajamarca, J.C.R.; Acevedo, J.E.R.; Rivera, H.V.H.; Arias-González, J.L. Examining the Impacts of ChatGPT on Student Motivation and Engagement. Soc. Space 2023, 23, 1-27.  \n10. Qureshi, B. Exploring the use of ChatGPT as a tool for learning and assessment in undergraduate computer science curriculum: Opportunities and challenges. arXiv 2023, arXiv:2304.11214.  \n11. Milano, S.; McGrane, J.A.; Leonelli, S. Large language models challenge the future of higher education. Nat. Mach. Intell. 2023, 5, 333-334. [CrossRef]  \n12. Dempere, J.; Modugu, K.; Hesham, A.; Ramasamy, L.K. The Impact of ChatGPT on Higher Education. Front. Educ. 2023, 8, 1206936. [CrossRef]  \n13. DeFranco, J.F.; Kshetri, N.; Voas, J. Are We Writing for Bots or Humans? Computer 2023, 56, 13-14. [CrossRef]  \n14. Cao, J.; Li, M.; Wen, M.; Cheung, S.C. A study on prompt design, advantages and limitations of ChatGPT for deep learning program repair. arXiv 2023, arXiv:2304.08191.  \n15. Qin, C.; Zhang, A.; Zhang, Z.; Chen, J.; Yasunaga, M.; Yang, D. Is ChatGPT a general-purpose natural language processing task solver? arXiv 2023, arXiv:2302.06476.  \n16. Dwivedi, Y.K.; Kshetri, N.; Hughes, L.; Slade, E.L.; Jeyaraj, A.; Kar, A.K.; Baabdullah, A.M.; Koohang, A.; Raghavan, V.; Ahuja, M.; et al. \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. Int. J. Inf. Manag. 2023, 71, 102642. [CrossRef]  \n17. Winslow, L.E. Programming pedagogy—A psychological view. ACM SIGCSE Bull. 1996, 28, 17-22. [CrossRef]  \n18. Lukpat, A. ChatGPT Banned in New York City Public Schools over Concerns about Cheating, Learning Development. 2023. Available online: https://www.wsj.com/articles/chatgpt-banned-in-new-york-city-public-schools-over-concerns-about-cheating-learning-development-11673024059 (accessed on 24 September 2023).  \n19. Sánchez-Ruiz, L.M.; Moll-López, S.; Nuñez-Pérez, A.; Morán-Fernández, J.A.; Vega-Fleitas, E. ChatGPT Challenges Blended Learning Methodologies in Engineering Education: A Case Study in Mathematics. Appl. Sci. 2023, 13, 6039. [CrossRef]  \n20. Susnjak, T. ChatGPT: The end of online exam integrity? arXiv 2022, arXiv:2212.09292.  \n21. Yilmaz, R.; Yilmaz, F.G.K. Augmented intelligence in programming learning: Examining student views on the use of ChatGPT for programming learning. Comput. Hum. Behav. Artif. Hum. 2023, 1, 100005. [CrossRef]\n\n22. Geng, C.; Yihan, Z.; Pientka, B.; Si, X. Can ChatGPT Pass An Introductory Level Functional Language Programming Course? arXiv 2023, arXiv:2305.02230.  \n23. Shoufan, A. Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study. ACM Trans. Comput. Educ. 2023, 23, 45. [CrossRef]  \n24. King, M.R.; ChatGPT. A conversation on artificial intelligence, chatbots, and plagiarism in higher education. Cell. Mol. Bioeng. 2023, 16, 1-2. [CrossRef]  \n25. Wohlin, C.; Runeson, P.; Höst, M.; Ohlsson, M.C.; Regnell, B.; Wesslen, A. Experimentation in Software Engineering; Springer Science & Business Media: Berlin/Heidelberg, Germany, 2012.  \n26. Chowdhary, K.R. Natural language processing. In Fundamentals of Artificial Intelligence; Springer: New Delhi, India, 2020; pp. 603-649.  \n27. King, M.R. The future of AI in medicine: A perspective from a Chatbot. Ann. Biomed. Eng. 2023, 51, 291-295. [CrossRef]  \n28. Floridi, L.; Chiriatti, M. GPT-3: Its nature, scope, limits, and consequences. *Minds Mach.* 2020, 30, 681–694. [CrossRef]  \n29. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.N.; Kaiser, L.; Polosukhin, I. Attention is all you need. Adv. Neural Inf. Process. Syst. 2017, 30, 5998-6008.  \n30. Adamopoulou, E.; Moussiades, L. Chatbots: History, technology, and applications. Mach. Learn. Appl. 2020, 2, 100006. [CrossRef]  \n31. Jeon, J.; Lee, S.; Choe, H. Beyond ChatGPT: A conceptual framework and systematic review of speech-recognition chatbots for language learning. Comput. Educ. 2023, 206, 104898. [CrossRef]  \n32. Hughes, A. ChatGPT: Everything You Need to Know about OpenAI's GPT-4 Tool. 2023. Available online: https://www.sciencefocus.com/future-technology/gpt-3 (accessed on 26 September 2023).  \n33. White, J.; Fu, Q.; Hays, S.; Sandborn, M.; Olea, C.; Gilbert, H.; Elnashar, A.; Spencer-Smith, J.; Schmidt, D.C. A prompt pattern catalog to enhance prompt engineering with ChatGPT. arXiv 2023, arXiv:2302.11382.  \n34. White, J.; Hays, S.; Fu, Q.; Spencer-Smith, J.; Schmidt, D.C. ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design. arXiv 2023, arXiv:2303.07839.  \n35. Giner-Miguelez, J.; Gomez, A.; Cabot, J. A domain-specific language for describing machine learning datasets. J. Comput. Lang. 2023, 76, 101209. [CrossRef]  \n36. de la Vega, A.; García-Saiz, D.; Zorrilla, M.; Sánchez, P. Lavoisier: A DSL for increasing the level of abstraction of data selection and formatting in data mining. J. Comput. Lang. 2020, 60, 100987. [CrossRef]  \n37. Kasneci, E.; Sessler, K.; Kuchemann, S.; Bannert, M.; Dementieva, D.; Fischer, F.; Gasser, U.; Groh, G.; Gunnemann, S.; Hüllermeier, E.; et al. ChatGPT for good? On opportunities and challenges of large language models for education. Learn. Individ. Differ. 2023, 103, 102274. [CrossRef]  \n38. Kosar, T.; Gaberc, S.; Carver, J.C.; Mernik, M. Program comprehension of domain-specific and general-purpose languages: Replication of a family of experiments using integrated development environments. Empir. Softw. Eng. 2018, 23, 2734-2763. [CrossRef]  \n39. Sonnleitner, P.; Brunner, M.; Greiff, S.; Funke, J.; Keller, U.; Martin, R.; Hazotte, C.; Mayer, H.; Latour, T. The Genetics Lab. Acceptance and psychometric characteristics of a computer-based microworld to assess complex problem solving. Psychol. Test Assess. Model. 2012, 54, 54-72.  \n40. Ouh, E.L.; Gan, B.K.S.; Shim, K.J.; Wlodkowski, S. ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course. arXiv 2023, arXiv:2305.13680.  \n41. Moradi Dakhel, A.; Majdinasab, V.; Nikanjam, A.; Khomh, F.; Desmarais, M.C.; Jiang, Z.M.J. GitHub Copilot AI pair programmer: Asset or Liability? J. Syst. Softw. 2023, 203, 111734. [CrossRef]  \n42. Imai, S. Is GitHub Copilot a Substitute for Human Pair-Programming? An Empirical Study. In Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings (ICSE '22), Pittsburgh, PA, USA, 21–29 May 2022; pp. 319–321.  \n43. Asare, O.; Nagappan, M.; Asokan, N. Is GitHub's Copilot as bad as humans at introducing vulnerabilities in code? Empir. Softw. Eng. 2023, 28, 129. [CrossRef]  \n44. Likert, R. A technique for the measurement of attitudes. Arch. Psychol. 1932, 22, 55.  \n45. Sheskin, D.J. Handbook of Parametric and Nonparametric Statistical Procedures, 5th ed.; Chapman and Hall/CRC: New York, NY, USA, 2011.  \n46. Feldt, R.; Magazinius, A. Validity Threats in Empirical Software Engineering Research—An Initial Survey. In Proceedings of the 22nd International Conference on Software Engineering & Knowledge Engineering (SEKE'2010), Redwood City, CA, USA, 1-3 July 2010; Knowledge Systems Institute Graduate School: Skokie, IL, USA, 2010; pp. 374-379.  \n47. Ralph, P.; Tempero, E. Construct Validity in Software Engineering Research and Software Metrics. In Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018 (EASE'18), Christchurch, New Zealand, 28-29 June 2018; pp. 13-23.  \n48. Sjoberg, D.I.K.; Bergersen, G.R. Construct Validity in Software Engineering. IEEE Trans. Softw. Eng. 2023, 49, 1374-1396. [CrossRef]\n\n49. Shull, F.J.; Carver, J.C.; Vegas, S.; Juristo, N. The role of replications in empirical software engineering. Empir. Softw. Eng. 2008, 13, 211-218. [CrossRef]  \n50. Carver, J.C. Towards reporting guidelines for experimental replications: A proposal. In Proceedings of the 1st International Workshop on Replication in Empirical Software Engineering, Cape Town, South Africa, 2-8 May 2010; pp. 1-4.\n\nDisclaimer/Publisher's Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.",
    "arxiv_id": "2107.03374",
    "embedding": [
      -1.8125,
      2.71875,
      -0.81640625,
      -2.40625,
      -2.296875,
      -2,
      0.1396484375,
      -2.078125,
      1.65625,
      1.921875,
      0.6484375,
      2.515625,
      3.125,
      5.25,
      0.95703125,
      3.046875,
      0.98046875,
      0.8828125,
      1.5234375,
      -5.40625,
      -1.3828125,
      5.03125,
      0.8984375,
      -6.59375,
      1.8515625,
      -2.515625,
      0.06591796875,
      1.7734375,
      0.06640625,
      -1.875,
      4.4375,
      -5.375,
      -0.28515625,
      -1.7109375,
      -0.921875,
      0.267578125,
      -2.53125,
      -0.9609375,
      6,
      5.65625,
      -4.90625,
      0.26953125,
      0.89453125,
      -0.0169677734375,
      -1.28125,
      3.359375,
      1.9921875,
      -2.984375,
      -1.5859375,
      -2.84375,
      -4.125,
      -1.765625,
      6.65625,
      0.302734375,
      5.5,
      -3.9375,
      -9.1875,
      8.5,
      -2.421875,
      -1.3046875,
      1.515625,
      -4.375,
      4.46875,
      -0.5234375,
      3.21875,
      3.359375,
      3.65625,
      1.5390625,
      -2.984375,
      0.74609375,
      -1.9609375,
      0.375,
      3.71875,
      -2.453125,
      8.6875,
      6.375,
      3.390625,
      4.375,
      -2.046875,
      3.546875,
      -6.4375,
      4.21875,
      2.859375,
      2.109375,
      6.125,
      2.1875,
      1.75,
      -1.3984375,
      -2.390625,
      0.267578125,
      -0.83203125,
      -1.609375,
      -4.8125,
      -1.09375,
      0.68359375,
      4.0625,
      -2.40625,
      -4.96875,
      -5.78125,
      1.3203125,
      -2.015625,
      -1.0234375,
      -2.109375,
      -7.5,
      -0.88671875,
      -4.46875,
      -4.5625,
      -5.5625,
      -0.58203125,
      -0.375,
      0.1943359375,
      4.03125,
      3.484375,
      2.609375,
      3.0625,
      -0.0157470703125,
      1.1640625,
      -3.8125,
      -4.1875,
      -1.3828125,
      1.484375,
      -1.0546875,
      -1.203125,
      0.396484375,
      1.421875,
      -0.7734375,
      -4.125,
      2.34375,
      3.125,
      -0.267578125,
      0.71484375,
      2.375,
      5.8125,
      -0.6640625,
      -7.875,
      -2.9375,
      -3.09375,
      -0.296875,
      3.84375,
      7.09375,
      -4.3125,
      1.7890625,
      0.875,
      -5.25,
      4.46875,
      -0.267578125,
      -4,
      -0.4140625,
      2.796875,
      -2.515625,
      -0.279296875,
      0.515625,
      3.84375,
      6.0625,
      -2.546875,
      -4.40625,
      1.7421875,
      0.96875,
      -0.306640625,
      -1,
      -1.4140625,
      3.59375,
      -0.08251953125,
      -0.578125,
      -2.375,
      -0.62890625,
      -4.625,
      4.34375,
      0.1865234375,
      -2.75,
      1.046875,
      14.6875,
      -0.306640625,
      -3.21875,
      -0.671875,
      2.546875,
      -2.8125,
      9.625,
      1.2109375,
      0.9375,
      3.25,
      3.109375,
      -4.40625,
      5.09375,
      -2.453125,
      -1.3125,
      2.703125,
      -2.734375,
      -1.203125,
      -3.96875,
      1.609375,
      5.40625,
      1.859375,
      3.625,
      -2.71875,
      -2.890625,
      1.6015625,
      -0.22265625,
      -0.09375,
      4.15625,
      -1,
      -10.375,
      1.8046875,
      0.91796875,
      -2.65625,
      -1.28125,
      0.8515625,
      -2.609375,
      1.2421875,
      -1.046875,
      2.46875,
      2.046875,
      3.75,
      -0.96484375,
      5.625,
      1.71875,
      5.84375,
      -2.59375,
      5.15625,
      -0.6953125,
      4.03125,
      5.59375,
      2.4375,
      0.029052734375,
      -0.23046875,
      1.84375,
      4.4375,
      4.65625,
      2.796875,
      5.21875,
      -0.27734375,
      1.75,
      2.4375,
      -2.421875,
      -1.7109375,
      -5.75,
      -4.53125,
      1.65625,
      -3.40625,
      1.65625,
      -5.84375,
      -6.03125,
      0.51953125,
      1.9140625,
      2.1875,
      -2.140625,
      -2.234375,
      -2.96875,
      0.36328125,
      -10.75,
      1.921875,
      1.8203125,
      -7.1875,
      -3.078125,
      4.15625,
      8.5625,
      -0.1572265625,
      -0.71875,
      -0.2021484375,
      -4.34375,
      2.859375,
      -5.28125,
      -6.375,
      1.84375,
      3.71875,
      -5,
      3.890625,
      -3.34375,
      2.859375,
      1.6875,
      0.91796875,
      1.8984375,
      -3.265625,
      1.125,
      -1.25,
      4.46875,
      0.2060546875,
      -5.9375,
      2.859375,
      -2.296875,
      -5.5,
      -6.875,
      8.625,
      -5.34375,
      4.75,
      -3.015625,
      1.0390625,
      4.125,
      -1.703125,
      9.625,
      3.5,
      1.75,
      4.8125,
      -0.050537109375,
      -2.9375,
      1.8984375,
      -3.40625,
      0.48828125,
      -6.9375,
      -3.390625,
      6.3125,
      1.296875,
      -1.7421875,
      -0.8828125,
      -2.515625,
      5.53125,
      -0.1611328125,
      -0.73046875,
      1.09375,
      0.90625,
      -0.51953125,
      0.004791259765625,
      8.125,
      -1.0703125,
      1.0703125,
      -4.53125,
      -2.953125,
      2.109375,
      2.375,
      1.8046875,
      -3.890625,
      -3.859375,
      -3.46875,
      -4.25,
      -3.640625,
      -1.078125,
      2.296875,
      -0.9140625,
      5.96875,
      -1.7578125,
      4.75,
      0.447265625,
      -5.9375,
      -10.5,
      6.84375,
      -2.65625,
      1.75,
      1.109375,
      1.484375,
      5.75,
      -1.625,
      -1.9296875,
      2.40625,
      -2.34375,
      -3.25,
      1.3046875,
      6.9375,
      -1.4296875,
      0.6640625,
      -4.3125,
      2.625,
      0.451171875,
      -2.28125,
      4.8125,
      4.96875,
      -2.078125,
      0.447265625,
      -2.375,
      3.5625,
      1.484375,
      2.796875,
      -3,
      6.28125,
      1.5625,
      -2.15625,
      -3.140625,
      -4.34375,
      0.78515625,
      -0.5390625,
      -1.8125,
      -0.1552734375,
      -5.96875,
      5.03125,
      0.765625,
      0.6953125,
      -0.58984375,
      0.60546875,
      -2.921875,
      -2.6875,
      2.6875,
      -5.09375,
      0.2080078125,
      0.484375,
      1.5078125,
      2.78125,
      0.236328125,
      0.734375,
      3.421875,
      2.625,
      -2.515625,
      -3.328125,
      1.8203125,
      -1.6328125,
      -1.6875,
      2.28125,
      -0.59375,
      0.04931640625,
      2.828125,
      -1.7734375,
      -1.3359375,
      5.09375,
      -3.34375,
      0.458984375,
      -2.25,
      -3,
      1.21875,
      0.26171875,
      -6.34375,
      2,
      1.46875,
      -1.59375,
      1.3515625,
      0.88671875,
      1.21875,
      1.3828125,
      1.234375,
      0.205078125,
      3.1875,
      -1.3828125,
      -2.71875,
      -5.15625,
      1.59375,
      1.8046875,
      -0.337890625,
      0.462890625,
      -1.59375,
      1.9375,
      7.28125,
      0.91015625,
      5.09375,
      0.94140625,
      -0.59375,
      -1.6484375,
      0.359375,
      -3.359375,
      -4.625,
      2.28125,
      -2.484375,
      -3.796875,
      -1.609375,
      2.09375,
      -2.140625,
      4.78125,
      4.46875,
      -2.28125,
      0.30078125,
      1.5078125,
      3.59375,
      -2.59375,
      -1.140625,
      -0.57421875,
      0.06787109375,
      -1.0859375,
      1.9375,
      2.953125,
      2.140625,
      -2.296875,
      3.53125,
      1.3125,
      -0.1796875,
      2.734375,
      -0.94921875,
      0.5390625,
      2.140625,
      -3.703125,
      -0.83984375,
      -1.5546875,
      3.109375,
      3.65625,
      -7.90625,
      -7,
      2.65625,
      1.90625,
      -1.5390625,
      -2.9375,
      2.1875,
      3.53125,
      2.5,
      -3.40625,
      -4.9375,
      0.0045166015625,
      -0.7421875,
      5.15625,
      1.96875,
      -0.490234375,
      -6.03125,
      -2.828125,
      7.21875,
      0.953125,
      3.484375,
      1,
      -2.578125,
      1.8984375,
      -5.09375,
      2.765625,
      2.453125,
      7.3125,
      -5.875,
      -2.3125,
      1.4296875,
      -9.1875,
      0.8828125,
      -3.453125,
      -2.34375,
      -1.5078125,
      1.0546875,
      2.921875,
      -2.234375,
      -2.21875,
      -3.53125,
      4.875,
      -5.0625,
      -0.10546875,
      2.78125,
      -7.125,
      -2.890625,
      0.2314453125,
      2.46875,
      4.65625,
      -2.453125,
      -2.9375,
      -0.91796875,
      -1.3203125,
      3.796875,
      -0.0380859375,
      -3.515625,
      -2.234375,
      -1.8671875,
      0.8125,
      0.404296875,
      1.9765625,
      1.0390625,
      0.09228515625,
      -5.15625,
      -2.421875,
      0.251953125,
      1.0078125,
      -3.78125,
      1.0703125,
      1.7421875,
      1.6640625,
      0.91796875,
      -3.453125,
      0.171875,
      -0.94921875,
      0.373046875,
      -2.421875,
      2.296875,
      1.765625,
      6.21875,
      1.4453125,
      2.859375,
      -2.484375,
      -1.9140625,
      2.140625,
      -3.6875,
      -5.0625,
      -1.5078125,
      0.51953125,
      -1.609375,
      -2.921875,
      -2.484375,
      -0.86328125,
      1.5078125,
      0.796875,
      0.455078125,
      1.375,
      4.96875,
      0.875,
      0.77734375,
      3.09375,
      2.375,
      -2.078125,
      -1.15625,
      2.03125,
      3.234375,
      -5.3125,
      -5.46875,
      -5.09375,
      1.5625,
      6.03125,
      -2.875,
      1.5234375,
      -0.83984375,
      7.9375,
      -0.54296875,
      1.453125,
      -14.625,
      2.515625,
      -1.171875,
      -4.9375,
      0.69140625,
      0.265625,
      4.1875,
      -2.328125,
      3.40625,
      1.2421875,
      -0.255859375,
      1.4296875,
      1.515625,
      -1.3828125,
      -2.71875,
      6.375,
      0.84765625,
      -2.3125,
      -0.365234375,
      -0.2197265625,
      -1.9296875,
      -1.3671875,
      -0.173828125,
      -0.55078125,
      1.5703125,
      2.875,
      0.416015625,
      1.375,
      -0.5703125,
      -6.125,
      -1.75,
      3.125,
      2.21875,
      -1.4765625,
      1.9765625,
      -2.1875,
      2.453125,
      -1.203125,
      4.03125,
      4.25,
      -3.125,
      1.3515625,
      1.875,
      -0.98046875,
      -0.6015625,
      -2.375,
      -3.078125,
      3.859375,
      4.59375,
      -2.609375,
      1.4140625,
      -0.470703125,
      -3.296875,
      4.1875,
      -0.9609375,
      -2.671875,
      -2.109375,
      4,
      0.2451171875,
      -0.390625,
      5.125,
      0.74609375,
      -6.84375,
      -0.515625,
      -2.390625,
      -0.169921875,
      -2.78125,
      -0.80859375,
      2.4375,
      -1.2421875,
      -0.828125,
      0.58203125,
      -0.21484375,
      -4.15625,
      -3.78125,
      -1.3984375,
      -4.40625,
      6.28125,
      -2.578125,
      -0.17578125,
      -2.9375,
      -0.6953125,
      1.15625,
      -1.15625,
      -0.2890625,
      2.578125,
      4.46875,
      3.171875,
      -4.53125,
      3.703125,
      -2.21875,
      -5.15625,
      0.44921875,
      -4.34375,
      -2.296875,
      1.453125,
      0.033203125,
      1.5546875,
      -0.0267333984375,
      -2.609375,
      -2.546875,
      -6.21875,
      -0.71875,
      3.96875,
      -0.8984375,
      4.90625,
      -0.416015625,
      4.15625,
      2.28125,
      -2.265625,
      0.220703125,
      0.2353515625,
      -0.41015625,
      -0.94140625,
      2.140625,
      -8.375,
      -0.263671875,
      3.34375,
      0.92578125,
      -2.484375,
      6.5,
      1.0859375,
      -0.859375,
      0.54296875,
      3.625,
      -3.28125,
      -1.6015625,
      1.8125,
      -2.015625,
      -1.421875,
      -1.65625,
      -0.43359375,
      -0.98828125,
      3.140625,
      -1.6015625,
      -0.294921875,
      -2.640625,
      -2.6875,
      -3.0625,
      -0.216796875,
      -1.890625,
      0.9609375,
      2.453125,
      1.09375,
      -1.28125,
      2.328125,
      1.4453125,
      2.359375,
      -0.0830078125,
      -1.359375,
      5.5625,
      2.140625,
      5.96875,
      -0.365234375,
      -8.125,
      2.03125,
      -1.171875,
      -3.390625,
      3.171875,
      -3.796875,
      0.66796875,
      3.203125,
      3.9375,
      -6.34375,
      -1.1875,
      4.6875,
      -2.765625,
      -2.046875,
      1.265625,
      5.34375,
      0.97265625,
      4.75,
      0.3125,
      -1.15625,
      -2.5,
      3.9375,
      3.34375,
      -2.15625,
      -1.3515625,
      3.640625,
      1.328125,
      3.671875,
      -5.125,
      -7.46875,
      0.404296875,
      0.9921875,
      -1.75,
      -0.98828125,
      3.609375,
      -3.859375,
      2.15625,
      -1.515625,
      2.34375,
      0.2197265625,
      1.09375,
      4.875,
      0.77734375,
      0.1279296875,
      0.03955078125,
      1.078125,
      2.9375,
      0.28515625,
      -2.578125,
      -0.5078125,
      -0.99609375,
      -0.58984375,
      2.890625,
      -1.9921875,
      -0.69140625,
      -0.87890625,
      -0.255859375,
      -1.0625,
      5.75,
      6.625,
      -1.078125,
      -1.0859375,
      0.10107421875,
      6.90625,
      -0.98046875,
      6.375,
      2.703125,
      11.125,
      -0.89453125,
      -0.83203125,
      2.5,
      -2.578125,
      1.8984375,
      -2.0625,
      -7.375,
      -0.8359375,
      0.68359375,
      1.515625,
      -1.625,
      0.462890625,
      -4.40625,
      -1.2109375,
      4.6875,
      1.4765625,
      5.96875,
      2.59375,
      2.28125,
      0.97265625,
      -1.15625,
      -4.875,
      -0.80859375,
      -1.1015625,
      -0.04638671875,
      0.9296875,
      1.109375,
      2.578125,
      2.40625,
      2.65625,
      -0.52734375,
      -1.2265625,
      -1.171875,
      6.03125,
      3.21875,
      -2.125,
      2.734375,
      -0.0026702880859375,
      -0.98046875,
      3.671875,
      2.9375,
      -5.1875,
      -4.40625,
      6.40625,
      3.9375,
      -0.271484375,
      1.7734375,
      -2.59375,
      1.3125,
      -3.953125,
      -1.0234375,
      -1.3125,
      3.1875,
      -3.953125,
      -0.76171875,
      2.78125,
      2.390625,
      -4.25,
      1.921875,
      0.9609375,
      -6.71875,
      2.46875,
      0.31640625,
      -1.328125,
      3.75,
      0.4453125,
      3.640625,
      1.6875,
      -1.2734375,
      -5.09375,
      -3.921875,
      -2.71875,
      1.953125,
      1.4921875,
      3.078125,
      2.203125,
      -3.265625,
      -0.86328125,
      -5.9375,
      0.765625,
      -2.40625,
      4.34375,
      3.28125,
      -5.78125,
      2.109375,
      -3.03125,
      -8.25,
      -2.84375,
      -0.74609375,
      -2.140625,
      -1.6953125,
      -4.53125,
      -1.0859375,
      1.1640625,
      -5.4375,
      1.671875,
      -3.078125,
      -1.8359375,
      5.75,
      0.69140625,
      0.8515625,
      -3.625,
      3.96875,
      2.203125,
      2.34375,
      4.375,
      1.703125,
      3.765625,
      3.1875,
      0.88671875,
      -0.1845703125,
      -3.796875,
      7.21875,
      -1.953125,
      8.5,
      5.40625,
      1.1796875,
      -6.25,
      2.84375,
      -1.3984375,
      -1.046875,
      -5.28125,
      0.82421875,
      1.015625,
      -0.36328125,
      0.67578125,
      2.34375,
      5.03125,
      -2.859375,
      -3.3125,
      -0.376953125,
      -4.53125,
      0.44140625,
      4.21875,
      -1.5859375,
      3.109375,
      -3,
      1.7734375,
      1.1953125,
      1.5859375,
      2.15625,
      -1.609375,
      0.8359375,
      -4.3125,
      0.671875,
      -1.96875,
      -0.68359375,
      -1,
      -2.078125,
      2.15625,
      0.1416015625,
      0.11181640625,
      2.078125,
      1.65625,
      4.75,
      3.09375,
      4.53125,
      -1.015625,
      -0.0419921875,
      1.0546875,
      1.9453125,
      2.03125,
      1.421875,
      -2.890625,
      -1.953125,
      0.30859375,
      -4.53125,
      1.828125,
      2.59375,
      -8.1875,
      -2.109375,
      -1.9296875,
      -6.09375,
      5.0625,
      0.63671875,
      1.1796875,
      4.53125,
      1.0078125,
      2.34375,
      3.796875,
      0.87109375,
      1.1875,
      0.203125,
      -2.796875,
      6.25,
      -3.5625,
      -0.62890625,
      4.09375,
      2.640625,
      3.765625,
      -3.265625,
      -1.3671875,
      -4.15625,
      0.9765625,
      2.65625,
      -0.51953125,
      -0.1708984375,
      6.3125,
      -1.4140625,
      -1.9609375,
      -2.09375,
      -1.34375,
      2.625,
      -5.4375,
      3.421875,
      5.21875,
      5.78125,
      -0.85546875,
      -3.890625,
      -4.8125,
      0.267578125,
      -2.359375,
      -0.96484375,
      -1.3671875,
      0.515625,
      0.1982421875,
      2.0625,
      -0.94140625,
      0.65625,
      -1.515625,
      -4.5,
      -1.203125,
      5.125,
      -2.5,
      -1.28125,
      -1.0859375,
      3.734375,
      -3.140625,
      1.8671875,
      1.4609375,
      -3.25,
      1.5546875,
      5.3125,
      -2.421875,
      2.625,
      3.53125,
      -0.037109375,
      0.044921875,
      -3.3125,
      -0.044921875,
      0.2578125,
      -1.5546875,
      0.53515625,
      -4.875,
      3.234375,
      2.234375,
      4.71875,
      -3.375,
      5.53125,
      1.921875,
      1.3515625,
      2.59375,
      -3.453125,
      -3.453125,
      -1.453125,
      -2.15625,
      -0.01348876953125,
      -0.8515625,
      -0.333984375,
      0.2158203125,
      5,
      -6.15625,
      3.8125,
      -5.46875,
      5.375,
      0.9765625,
      2.390625,
      0.318359375,
      -1.03125,
      -0.330078125,
      -1.71875,
      3.90625,
      -0.64453125,
      -0.9140625,
      0.6875,
      -3.796875,
      0.6640625,
      -1.4140625,
      1.0859375,
      3.25,
      -1.7109375,
      2.703125,
      -2.015625,
      1.4296875,
      -7.25,
      -2.328125,
      -2.21875,
      0.9375,
      -0.59375,
      0.66796875,
      -3.859375,
      -0.2080078125,
      1.09375,
      -3.5625,
      1.7890625,
      -3.96875,
      -1.578125,
      3.640625,
      3.265625,
      5.6875,
      3.875,
      -0.0712890625,
      -0.134765625,
      -3.109375,
      -3.46875,
      -1.03125,
      -3.171875,
      -0.5625,
      -4.15625,
      -0.54296875,
      0.99609375,
      -0.75390625,
      2.125,
      -1.6015625,
      0.921875,
      2.65625,
      3.171875,
      -1.0625,
      1.5625,
      -1.53125,
      -1.6640625,
      -3.328125,
      -2.9375,
      -5.59375,
      2.5625,
      -0.4765625,
      -2.984375,
      -0.3359375,
      -1.25,
      2.09375,
      0.62890625,
      0.71484375,
      0.90625,
      -1.1953125,
      2.140625,
      -1.1875,
      -2.296875,
      2.65625,
      1.2421875,
      2.6875,
      -1.53125,
      -1.59375,
      -6.65625,
      0.69921875,
      1.359375,
      0.9765625,
      -2.078125,
      -1.7890625,
      -2.734375,
      -1.125,
      -4.84375,
      -4.59375,
      6.3125,
      3.09375,
      3.75,
      3.8125,
      0.55078125,
      -0.267578125,
      1.625,
      -1.8828125,
      3.5,
      -0.0012664794921875,
      -0.86328125,
      1.4453125,
      -0.173828125,
      4.40625,
      -3.640625,
      -3.640625,
      -5.53125,
      -1.0546875,
      7.0625,
      -1.7421875,
      -3.34375,
      0.83203125,
      -2.515625,
      3.09375,
      1.2890625,
      1.8046875,
      -4.59375,
      -1.4296875,
      -2.125,
      3.65625,
      -0.51953125,
      -3.453125,
      -1.3359375,
      1.4296875,
      -2.75,
      0.99609375,
      4.9375,
      5.28125,
      -2.09375,
      1.734375,
      -2.875,
      -4.5625,
      -2.859375,
      6.5,
      -0.49609375,
      -1.015625,
      -2.4375,
      -2.875,
      -0.1591796875,
      0.97265625,
      -1.859375,
      4.53125,
      -2.34375,
      1.828125,
      1.6015625,
      5.71875,
      1.6640625,
      -2.59375,
      0.96484375,
      1.828125,
      1.328125,
      -1.359375,
      2.21875,
      -6.25,
      -0.3046875,
      0.062255859375,
      -8.125,
      1.34375,
      2.4375,
      0.6875,
      3.0625,
      -1.578125,
      3.90625,
      0.423828125,
      -2.953125,
      -4.15625,
      -2.40625,
      4.96875,
      3.234375,
      2.28125,
      -6.625,
      -0.5703125,
      -0.09814453125,
      0.181640625,
      -1.90625,
      3.734375,
      -2.328125,
      2.265625,
      4.15625,
      2.375,
      -4.125,
      -0.98046875,
      -0.322265625,
      -1.3671875,
      -3.734375,
      0.71875,
      0.05322265625,
      0.02880859375,
      5.96875,
      0.7890625,
      -3.75,
      -2.140625,
      -1.1640625,
      2.5625,
      1.6328125,
      1.4609375,
      -3.53125,
      -0.0888671875,
      -3.359375,
      -1.15625,
      6.78125,
      -0.65625,
      -2.90625,
      1.78125,
      -0.388671875,
      4.46875,
      2.9375,
      0.375,
      -1.7734375,
      5.0625,
      -2,
      -4.84375,
      -4.375,
      -0.359375,
      -1.765625,
      -2.9375,
      2.71875,
      -3.859375,
      1.09375,
      -3.5625,
      -3.890625,
      0.353515625,
      -1.2421875,
      0.51171875,
      4.5625,
      3.765625,
      0.306640625,
      1.0546875,
      -2.859375,
      3.59375,
      3.25,
      -3.640625,
      0.50390625,
      -0.578125,
      1.6171875,
      -4.34375,
      3.25,
      -0.77734375,
      -0.91796875,
      4.28125,
      3.4375,
      -5.78125,
      0.052490234375,
      0.80078125,
      2.53125,
      -2.5,
      0.90234375,
      -0.75390625,
      6.1875,
      -1.3359375,
      -0.341796875,
      -3.21875,
      -2.25,
      -1.5390625,
      -2.734375,
      0.240234375,
      -0.263671875,
      0.703125,
      -4.125,
      0.6484375,
      4.84375,
      6.6875,
      2.796875,
      -1.6328125,
      1.046875,
      1.703125,
      0.625,
      5.71875,
      -2.96875,
      -3.78125,
      -1.375,
      -0.0751953125,
      -6.25,
      -1.8125,
      -8.1875,
      -0.054931640625,
      -2.140625,
      0.73046875,
      -0.73046875,
      -0.0023193359375,
      0.50390625,
      -1.8359375,
      -1.5390625,
      -1.09375,
      -2.859375,
      -4.25,
      0.5078125,
      -1.375,
      -6,
      1.484375,
      -0.91015625,
      -1.9609375,
      5,
      4.65625,
      2.515625,
      -1.109375,
      1.78125,
      -1.75,
      -1.8359375,
      -1.53125,
      -0.07275390625,
      -0.90625,
      -2.78125,
      0.8984375,
      -0.2734375,
      4.34375,
      -3.1875,
      -4.71875,
      -6.21875,
      -0.9453125,
      0.376953125,
      2.21875,
      0.58984375,
      -1.109375,
      1.8828125,
      -0.224609375,
      4.71875,
      0.703125,
      -0.90234375,
      -4.4375,
      2.359375,
      3.203125,
      2.671875,
      2.234375,
      0.2138671875,
      -3.375,
      3.109375,
      1.4375,
      -0.99609375,
      4.25,
      -0.17578125,
      0.455078125,
      -5.0625,
      0.201171875,
      -3.078125,
      1.0078125,
      -2.09375,
      2.4375,
      2.703125,
      0.05419921875,
      5.875,
      5.15625,
      1.2734375,
      -0.95703125,
      2.109375,
      2.6875,
      -1.8046875,
      -0.765625,
      1.9375,
      -0.6171875,
      -1.984375,
      1.828125,
      -0.25390625,
      3.5625,
      -2.140625,
      2.203125,
      0.1728515625,
      4.5,
      -4.53125,
      1.5078125,
      -4.8125,
      -0.263671875,
      -5.5625,
      0.11572265625,
      -3.8125,
      -1.828125,
      4.65625,
      6.125,
      -1.40625,
      -4.78125,
      1.59375,
      4.4375,
      -0.98046875,
      -5.59375,
      4.0625,
      0.5625,
      0.07861328125,
      -2.953125,
      -3.578125,
      5.84375,
      0.00592041015625,
      3.90625,
      -4.3125,
      0.89453125,
      0.8671875,
      -2.296875,
      -5.875,
      3.390625,
      1.546875,
      -4.1875,
      -3.859375,
      -4.5,
      3.046875,
      -4.3125,
      -0.431640625,
      3,
      -1.609375,
      2.5625,
      -0.890625,
      4.46875,
      3.984375,
      -2.078125,
      1.4140625,
      0.28515625,
      -1.34375,
      0.9296875,
      3.125,
      -2.15625,
      1.171875,
      -1.3828125,
      0.703125,
      2.421875,
      -1.203125,
      -0.97265625,
      -6.6875,
      0.78125,
      3.75,
      3.703125,
      -3.484375,
      -4.875,
      0.76171875,
      -0.08740234375,
      -3.421875,
      1.5078125,
      2.234375,
      0.80859375,
      -2.65625,
      -0.04443359375,
      2.59375,
      3.046875,
      -1.5078125,
      0.796875,
      -0.16015625,
      0.057373046875,
      -4.03125,
      -2.75,
      -4.875,
      1.4609375,
      -2.21875,
      5.71875,
      -2.453125,
      -3.125,
      0.55078125,
      3.296875,
      -1.7578125,
      2.875,
      0.16015625,
      -1.5,
      1.171875,
      3.734375,
      -0.60546875,
      -4.75,
      0.51953125,
      1.015625,
      0.8515625,
      -2.03125,
      -2.1875,
      -0.390625,
      2.84375,
      -6.5,
      -2.6875,
      0.80859375,
      2.375,
      -3.3125,
      -8.4375,
      0.6015625,
      1.5234375,
      -1.3828125,
      -0.1875,
      -1.0234375,
      0.80859375,
      3.5625,
      2.578125,
      3.296875,
      -1.625,
      -2.140625,
      3.53125,
      19.25,
      -2.65625,
      -4.40625,
      1.140625,
      -3.390625,
      5.375,
      6.4375,
      1.875,
      2.921875,
      4.03125,
      -1.8984375,
      0.173828125,
      1.9765625,
      0.859375,
      -0.65625,
      0.83203125,
      2.953125,
      0.01409912109375,
      -0.640625,
      -4.375,
      -0.7421875,
      2.15625,
      1.828125,
      1.4921875,
      -1.1875,
      -0.1064453125,
      1.1015625,
      -3.796875,
      -0.64453125,
      -2.953125,
      -1.6953125,
      -2.78125,
      -1.1015625,
      -2.015625,
      1.7578125,
      -3.5625,
      0.76171875,
      -0.06689453125,
      0.64453125,
      -1.703125,
      -5.15625,
      -4,
      3.6875,
      1.15625,
      -2.734375,
      0.04296875,
      -1.3671875,
      -1.859375,
      0.05078125,
      1.3828125,
      -0.2236328125,
      -0.73046875,
      -2.84375,
      2.09375,
      2.015625,
      -2.625,
      -4.40625,
      -5.59375,
      -4.75,
      -3.125,
      -1.7109375,
      -0.6171875,
      -4.34375,
      -1.21875,
      -0.65234375,
      -2.515625,
      0.345703125,
      0.8828125,
      -2.015625,
      0.99609375,
      -9.125,
      -2.140625,
      2.890625,
      4.375,
      0.08544921875,
      -2.078125,
      0.9765625,
      3.796875,
      2.046875,
      2.71875,
      -0.90625,
      2.09375,
      -2.140625,
      -0.244140625,
      1.8984375,
      -0.98828125,
      -2.921875,
      0.96484375,
      0.205078125,
      1.390625,
      2.9375,
      -6.3125,
      0.44921875,
      0.458984375,
      -2.4375,
      -1.1484375,
      2.046875,
      1.5546875,
      -1.234375,
      -3.75,
      3.671875,
      -1.7734375,
      -0.1787109375,
      -0.7421875,
      1.0625,
      -1.0078125,
      1.140625,
      -2.109375,
      0.84765625,
      0.98046875,
      -4.9375,
      2.625,
      0.859375,
      -0.734375,
      -0.458984375,
      2.671875,
      -4.375,
      -2.9375,
      2.40625,
      -3.40625,
      3.5625,
      0.232421875,
      -0.0029144287109375,
      -1.375,
      -7.59375,
      -3.921875,
      -2,
      -5.6875,
      1.0078125,
      -2.859375,
      -1.3515625,
      -2.015625,
      -0.8515625,
      -0.9453125,
      2.03125,
      -2.484375,
      3.5625,
      4.65625,
      0.19921875,
      -0.515625,
      -0.8984375,
      2.625,
      1.6953125,
      -2.46875,
      -3.6875,
      1.75,
      -1.65625,
      -0.373046875,
      3.375,
      3.25,
      -2.5,
      3.984375,
      0.1484375,
      -2.578125,
      -4.25,
      4.15625,
      -2.75,
      -1.546875,
      -1.546875,
      0.40625,
      -0.859375,
      -3.328125,
      -1.28125,
      -7.53125,
      2.765625,
      -1.8203125,
      2.625,
      -0.66015625,
      -4.03125,
      4.0625,
      7.5,
      -5.90625,
      0.625,
      0.515625,
      3.5625,
      -3.78125,
      4.09375,
      1.96875,
      -2.65625,
      0.96875,
      0.98828125,
      1.0546875,
      -0.72265625,
      -2.28125,
      3.453125,
      3.75,
      -6.375,
      4.125,
      0.1171875,
      0.69140625,
      -1.3359375,
      -4.96875,
      -3.296875,
      5.6875,
      4.03125,
      -2.078125,
      -0.63671875,
      -2.546875,
      -0.36328125,
      -3.921875,
      -3.953125,
      3.734375,
      -0.045166015625,
      0.2294921875,
      3.984375,
      -0.43359375,
      -4.34375,
      -1.796875,
      -1.4609375,
      -0.00115203857421875,
      -2.125,
      2.203125,
      1.625,
      1.703125,
      -5.53125,
      9.1875,
      4.40625,
      1.1640625,
      -0.2734375,
      2.359375,
      4.96875,
      -1.9375,
      -6.96875,
      0.9296875,
      -1.0859375,
      3.234375,
      -2.46875,
      3.859375,
      -4.125,
      0.640625,
      -3.046875,
      3.140625,
      0.2314453125,
      0.65625,
      -4.78125,
      -3.046875,
      -0.376953125,
      1.90625,
      -1.1875,
      3.46875,
      4.46875,
      -1.203125,
      2.78125,
      3.921875,
      -3.875,
      2.890625,
      -1.453125,
      -3.578125,
      0.50390625,
      -0.58203125,
      0.6328125,
      0.0028839111328125,
      3.3125,
      0.27734375,
      0.50390625,
      -1.1171875,
      -3.828125,
      -0.8515625,
      -4.65625,
      1.4609375,
      -3.078125,
      -6.0625,
      4.96875,
      1.6875,
      -0.3671875,
      2.0625,
      -0.435546875,
      -5.8125,
      6.09375,
      5.34375,
      -0.56640625,
      4.5,
      0.1884765625,
      -3.25,
      -2.34375,
      -1.234375,
      -1.546875,
      -4.15625,
      0.6953125,
      3.53125,
      -1.3828125,
      1.8359375,
      2.75,
      -0.94140625,
      2.328125,
      -0.6484375,
      7.65625,
      -0.3515625,
      2.3125,
      0.8125,
      1.28125,
      3.28125,
      -5.3125,
      -0.96484375,
      -5.40625,
      -0.046142578125,
      -2.015625,
      0.64453125,
      -1.7421875,
      -1.3984375,
      3.046875,
      1.8046875,
      0.0079345703125,
      -9.1875,
      -4.125,
      -0.07666015625,
      -1.53125,
      4.53125,
      1.7109375,
      -2.078125,
      -2.125,
      -0.1455078125,
      1.953125,
      0.294921875,
      0.9921875,
      -2.34375,
      -4.09375,
      1.4140625,
      3.171875,
      -6.96875,
      -0.890625,
      -2.125,
      -0.37109375,
      -2.234375,
      -2.25,
      -4.03125,
      2.171875,
      1.484375,
      -3.4375,
      2.25,
      0.322265625,
      0.095703125,
      2.890625,
      1.5625,
      0.71875,
      2.96875,
      -3.015625,
      -7.59375,
      -1.140625,
      1.8125,
      0.212890625,
      3.703125,
      -1.5703125,
      4.1875,
      0.06640625,
      2.328125,
      -5.09375,
      7.125,
      0.7578125,
      -9.25,
      4.03125,
      -0.875,
      2.890625,
      0.47265625,
      -4.71875,
      -1.4375,
      4.75,
      -0.123046875,
      -1.5,
      4.5625,
      0.61328125,
      1.125,
      2.453125,
      -2.6875,
      -4.0625,
      3.125,
      1.78125,
      -3.0625,
      1.296875,
      2.828125,
      -1.3515625,
      0.43359375,
      0.66796875,
      2.6875,
      -1.890625,
      -1.546875,
      4.28125,
      2.5,
      0.462890625,
      -2.453125,
      -3.34375,
      0.12353515625,
      -1.921875,
      -1.7578125,
      2.46875,
      -1.125,
      -0.95703125,
      -2.0625,
      1.6796875,
      2.015625,
      -3.5625,
      -3.015625,
      -2.75,
      -1.5859375,
      0.421875,
      1.328125,
      -1.7109375,
      -0.4921875,
      -0.70703125,
      3.359375,
      2.890625,
      2.28125,
      -2.28125,
      -0.0306396484375,
      -1.078125,
      -3,
      -2.71875,
      2.921875,
      -3.28125,
      -2.15625,
      1.3046875,
      -2.140625,
      -0.6953125,
      -2.8125,
      -2.265625,
      1.6171875,
      1.953125,
      -1.1953125,
      -2.171875,
      -2.109375,
      -0.022705078125,
      3.9375,
      -3.453125,
      -0.8671875,
      -1.40625,
      -0.17578125,
      -4.71875,
      -2.203125,
      -1.15625,
      -3.21875,
      3.53125,
      4.25,
      -1.828125,
      1.3203125,
      2.234375,
      -4.15625,
      -3.53125,
      7.0625,
      1.6875,
      -0.9765625,
      0.83203125,
      2.109375,
      -4.9375,
      4.25,
      5.75,
      0.62890625,
      -3.25,
      -2.109375,
      -2.171875,
      -2.484375,
      -2.84375,
      2.078125,
      -0.02294921875,
      -8.3125,
      10.4375,
      -2.140625,
      3.09375,
      2.953125,
      -0.57421875,
      3.15625,
      -0.59375,
      1.3046875,
      1.796875,
      -1.03125,
      4.78125,
      -5.46875,
      -0.154296875,
      -1.4609375,
      -1.125,
      0.20703125,
      -2.0625,
      0.65625,
      0.259765625,
      5.09375,
      0.65234375,
      0.123046875,
      -3.390625,
      -2.21875,
      2.734375,
      -1,
      -3.25,
      -2.765625,
      -3.125,
      -0.6484375,
      -4.78125,
      -0.046875,
      -3.71875,
      1.0390625,
      -2.765625,
      1.4609375,
      2.6875,
      2.375,
      -1.09375,
      -2.828125,
      -0.91015625,
      1.3984375,
      3.6875,
      4.1875,
      -0.5078125,
      4.3125,
      -0.828125,
      2.78125,
      3.21875,
      4.5,
      2.765625,
      -2.796875,
      -1.0078125,
      -0.5859375,
      -2.21875,
      -2.53125,
      -1.8515625,
      0.90234375,
      3.109375,
      4.3125,
      -0.890625,
      0.197265625,
      -4.28125,
      -1.3828125,
      -2.703125,
      -0.365234375,
      3.109375,
      1.1796875,
      -2.140625,
      -0.470703125,
      4,
      4.4375,
      2.109375,
      3.921875,
      -1.2578125,
      -0.484375,
      -1.515625,
      -0.59765625,
      2.515625,
      -2,
      1.328125,
      2.296875,
      -0.59375,
      -0.41796875,
      -3.140625,
      1.5078125,
      0.2255859375,
      -4.59375,
      0.953125,
      0.89453125,
      1.171875,
      1.2265625,
      0.33203125,
      -1.6171875,
      1.5625,
      -0.66015625,
      3.640625,
      -2.6875,
      1.7734375,
      0.07958984375,
      2.65625,
      -4.0625,
      -0.65625,
      -0.9140625,
      -0.1279296875,
      1.6171875,
      -1.3515625,
      -1.03125,
      -1.9765625,
      5.03125,
      -0.25390625,
      0.298828125,
      2.390625,
      1.3828125,
      -0.58984375,
      3.78125,
      -2.3125,
      0.146484375,
      0.09765625,
      2.34375,
      2.15625,
      2.234375,
      2.53125,
      2.125,
      -1.4609375,
      -0.43359375,
      -2.796875,
      -2.28125,
      -2.453125,
      -1.0390625,
      0.4453125,
      -0.045166015625,
      3.40625,
      -0.87890625,
      0.58203125,
      0.5703125,
      0.028564453125,
      -1.4140625,
      -0.25,
      -1.203125,
      1.15625,
      -2.546875,
      -4.46875,
      2.90625,
      -0.91015625,
      1.3359375,
      1.4453125,
      1.9609375,
      0.150390625,
      -1.0390625,
      -4.71875,
      4.21875,
      1.7265625,
      2.125,
      -0.1904296875,
      2.859375,
      -0.796875,
      1.4453125,
      -1.265625,
      -0.58203125,
      1.859375,
      -3.453125,
      4.53125,
      0.625,
      1.9453125,
      3.84375,
      5.25,
      -1.7109375,
      -0.04443359375,
      -1.7578125,
      1.640625,
      -0.5703125,
      0.53515625,
      -2.671875,
      1.828125,
      -1.25,
      -1.2890625,
      -0.1513671875,
      4.4375,
      -3.984375,
      -1.8046875,
      -1.7421875,
      -1.6328125,
      -1.140625,
      2.328125,
      1.4609375,
      -0.578125,
      -2.65625,
      -4.0625,
      1.0703125,
      -0.828125,
      0.91015625,
      1.640625,
      -2.734375,
      -1.046875,
      0.30078125,
      -1.5625,
      -1.5390625,
      -3.828125,
      -0.0361328125,
      0.212890625,
      0.91015625,
      0.212890625,
      -0.72265625,
      -0.458984375,
      2.59375,
      -0.51171875,
      -0.21484375,
      0.173828125,
      -1.484375,
      -2.859375,
      -0.039306640625,
      -1.5625,
      -2.765625,
      -1.484375,
      0.275390625,
      -1.640625,
      -1.4453125,
      1.7109375,
      -0.306640625,
      -1.859375,
      0.765625,
      0.2001953125,
      0.349609375,
      1.078125,
      -0.546875,
      -1.109375,
      2.390625,
      0.67578125,
      2.21875,
      2.328125,
      0.28125,
      -1.1953125,
      -1.1953125,
      2.609375,
      -1.2109375,
      2.078125,
      -1.5,
      -0.8203125,
      1.9296875,
      1.1875,
      2.953125,
      1.984375,
      0.8046875,
      0.77734375,
      1.3046875,
      -3.390625,
      3.546875,
      3.578125,
      2.25,
      1.625,
      0.060791015625,
      -1.171875,
      0.08740234375,
      -0.3828125,
      1.6640625,
      -1.5,
      2.15625,
      1.03125,
      -0.8046875,
      -0.99609375,
      -0.07861328125,
      0.375,
      -0.01239013671875,
      2.046875,
      -4.4375,
      -0.27734375,
      1.5390625,
      -1.109375,
      0.44140625,
      0.421875,
      -2.15625,
      2.734375,
      -3.890625,
      -0.115234375,
      -2.671875,
      2.6875,
      3,
      0.44140625,
      -2.03125,
      -3.171875,
      -0.462890625,
      0.55859375,
      -2.359375,
      3.265625,
      1.171875,
      2.546875,
      -0.267578125,
      -0.033935546875,
      -1.890625,
      -1.1328125,
      1.203125,
      -1.0625,
      2.359375,
      4.4375,
      0.1044921875,
      0.484375,
      -1.9375,
      -2.953125,
      -0.95703125,
      -1.8515625,
      -0.26953125,
      1.53125,
      2.59375,
      -0.58984375,
      0.26171875,
      2.921875,
      -0.443359375,
      5.53125,
      0.53515625,
      -0.5703125,
      3.03125,
      -2.25,
      0.84765625,
      -3.75,
      0.66015625,
      0.94921875,
      1.4453125,
      1.734375,
      -2.4375,
      -0.177734375,
      1.0390625,
      0.1328125,
      1.734375,
      -0.2890625,
      -3.53125,
      -1.2109375,
      1.2578125,
      -0.36328125,
      -0.8203125,
      1.3828125,
      0.1416015625,
      4.4375,
      -0.045654296875,
      -0.640625,
      1.609375,
      1.0390625,
      2.46875,
      1.09375,
      -2.859375,
      -1.8984375,
      0.6640625,
      1.671875,
      1.3984375,
      -0.69140625,
      4.65625,
      4.84375,
      -2.359375,
      -2.484375,
      -1.90625,
      0.98828125,
      0.86328125,
      0.26171875,
      4.71875,
      -6.53125,
      -0.52734375,
      3.53125,
      -1.7421875,
      -1.640625,
      0.51953125,
      2.34375,
      -3.0625,
      2.109375,
      0.2431640625,
      -0.71875,
      -1.71875,
      2.6875,
      -2.15625,
      2.125,
      0.11767578125,
      -0.06591796875,
      -1.7421875,
      2.328125,
      -0.59375,
      2.328125,
      -2.09375,
      -0.41796875,
      3.640625,
      -0.1767578125,
      2.171875,
      -2.171875,
      -1.109375,
      3.5,
      -0.3515625,
      -1.4375,
      -0.859375,
      -1.265625,
      -0.2490234375,
      1.796875,
      0.330078125,
      0.50390625,
      2.9375,
      0.2373046875,
      -4.59375,
      -1.3125,
      -1.578125,
      -3,
      -1.3046875,
      -2.75,
      0.84765625,
      -1.9609375,
      4.1875,
      -3.3125,
      0.76953125,
      6.6875,
      3.6875,
      3.28125,
      1.3515625,
      0.2158203125,
      3.1875,
      -0.73828125,
      -3.25,
      2.046875,
      -0.28125,
      -0.69921875,
      1.984375,
      1.640625,
      -1.890625,
      -1.8046875,
      -0.90234375,
      -0.091796875,
      0.7265625,
      0.2021484375,
      -0.248046875,
      -2.203125,
      1.734375,
      0.09130859375,
      1.953125,
      -3.328125,
      0.5859375,
      -3.359375,
      0.1875,
      -1.015625,
      -1.8515625,
      -1.515625,
      -0.2109375,
      1.984375,
      0.796875,
      0.006011962890625,
      4.3125,
      -2.53125,
      -1.1015625,
      1.5546875,
      -0.59375,
      0.7578125,
      -1.03125,
      3.203125,
      -1.7265625,
      0.50390625,
      -2.578125,
      -0.68359375,
      1.75,
      5.03125,
      2.71875,
      3.078125,
      -2.53125,
      0.443359375,
      1.2734375,
      -0.8515625,
      -1.8359375,
      -2.71875,
      0.62890625,
      1.6171875,
      -0.408203125,
      0.400390625,
      0.71484375,
      -1.1484375,
      -0.34765625,
      -2.234375,
      0.263671875,
      -0.9296875,
      1.28125,
      2.890625,
      0.87890625,
      -2.015625,
      -2.0625,
      -0.2060546875,
      -4.3125,
      -0.05126953125,
      2.078125,
      -1.3828125,
      3.171875,
      2.296875,
      -2.734375,
      4.0625,
      1.6328125,
      -0.62890625,
      4.09375,
      -0.11328125,
      0.9296875,
      -0.9140625,
      2.109375,
      0.68359375,
      -0.84765625,
      4.46875,
      -0.1865234375,
      -4.03125,
      0.80078125,
      -0.90234375,
      -0.15234375,
      0.33203125,
      -2.1875,
      2.40625,
      -0.87890625,
      1.6328125,
      3.453125,
      -0.146484375,
      2.1875,
      3.859375,
      -1.40625,
      -2.8125,
      -4.4375,
      -0.9140625,
      -0.8515625,
      1.078125,
      0.88671875,
      3.75,
      0.8359375,
      -1.7578125,
      0.20703125,
      0.08984375,
      0.796875,
      -0.8125,
      -1.7578125,
      -3.109375,
      -2.5,
      -3.890625,
      0.1337890625,
      0.357421875,
      2.546875,
      0.90234375,
      -0.341796875,
      0.40234375,
      2.109375,
      -3.671875,
      -0.4921875,
      -0.53125,
      1.3828125,
      -1.0078125,
      -1.359375,
      0.8984375,
      1.9765625,
      -1.859375,
      1.484375,
      2.953125,
      3.578125,
      -1.234375,
      -2.640625,
      0.232421875,
      -4.59375,
      -2.59375,
      0.5859375,
      0.0517578125,
      1.8515625,
      -1.890625,
      -0.6484375,
      0.2890625,
      0.455078125
    ],
    "summary": "通过将学生随机分为实验组（使用ChatGPT）和对照组（不使用ChatGPT），在真实编程课程环境中进行对比实验，以量化评估ChatGPT对初学者学习效果的影响。",
    "structure": {
      "sections": [
        {
          "title": "Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers",
          "level": 1,
          "start_line": 3
        },
        {
          "title": "1. Introduction",
          "level": 1,
          "start_line": 49
        },
        {
          "title": "2. Background",
          "level": 1,
          "start_line": 77
        },
        {
          "title": "3. Related Work",
          "level": 1,
          "start_line": 87
        },
        {
          "title": "4. Experiment Design and Goals",
          "level": 1,
          "start_line": 103
        },
        {
          "title": "4.1. Controlled Experiment and Participants",
          "level": 1,
          "start_line": 107
        },
        {
          "title": "4.2. Practical Assignments",
          "level": 1,
          "start_line": 119
        },
        {
          "title": "4.3. ChatGPT-Oriented Adjustments",
          "level": 1,
          "start_line": 149
        },
        {
          "title": "4.3.1. Question Preparation",
          "level": 1,
          "start_line": 153
        },
        {
          "title": "4.3.2. Extended Assignment",
          "level": 1,
          "start_line": 183
        },
        {
          "title": "4.3.3. Assignment Defense",
          "level": 1,
          "start_line": 191
        },
        {
          "title": "4.3.4. Paper-Based Midterms",
          "level": 1,
          "start_line": 213
        },
        {
          "title": "4.4. Procedure and Data Collection Instrument",
          "level": 1,
          "start_line": 217
        },
        {
          "title": "4.5. Hypotheses",
          "level": 1,
          "start_line": 231
        },
        {
          "title": "5. Results",
          "level": 1,
          "start_line": 244
        },
        {
          "title": "5.1. Participant Background",
          "level": 1,
          "start_line": 250
        },
        {
          "title": "5.2. Comparison",
          "level": 1,
          "start_line": 260
        },
        {
          "title": "5.3. Feedback Results",
          "level": 1,
          "start_line": 282
        },
        {
          "title": "5.3.1. Course Complexity",
          "level": 1,
          "start_line": 288
        },
        {
          "title": "5.3.2. The Usage of ChatGPT during the Semester—Group II",
          "level": 1,
          "start_line": 296
        },
        {
          "title": "5.3.3. The Usage of ChatGPT during the Semester—Group I",
          "level": 1,
          "start_line": 307
        },
        {
          "title": "5.3.4. Influence of ChatGPT on Exam Grade",
          "level": 1,
          "start_line": 316
        },
        {
          "title": "5.3.5. Means of Use",
          "level": 1,
          "start_line": 323
        },
        {
          "title": "5.3.6. Code Understandability",
          "level": 1,
          "start_line": 332
        },
        {
          "title": "5.3.7. Acceptance of ChatGPT among Students outside Programming",
          "level": 1,
          "start_line": 341
        },
        {
          "title": "5.3.8. Future Use of ChatGPT in Programming",
          "level": 1,
          "start_line": 348
        },
        {
          "title": "6. Threats to Validity",
          "level": 1,
          "start_line": 357
        },
        {
          "title": "6.1. Construct Validity",
          "level": 1,
          "start_line": 361
        },
        {
          "title": "6.2. Internal Validity",
          "level": 1,
          "start_line": 381
        },
        {
          "title": "6.3. External Validity",
          "level": 1,
          "start_line": 393
        },
        {
          "title": "7. Conclusions",
          "level": 1,
          "start_line": 407
        },
        {
          "title": "Future Work",
          "level": 1,
          "start_line": 429
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 455
        }
      ]
    },
    "tags": [
      "计算机教育",
      "编程教育",
      "教育实证研究"
    ],
    "suggested_tags": [
      "计算机教育",
      "编程教育",
      "教育实证研究",
      "生成式AI教育应用"
    ],
    "tag_suggestions": [
      {
        "name": "计算机教育",
        "confidence": 0.95,
        "reason": "论文核心研究领域是计算机科学教育，特别是针对编程初学者的教学实践与评估。"
      },
      {
        "name": "编程教育",
        "confidence": 0.9,
        "reason": "研究聚焦于面向对象编程课程，探讨ChatGPT在编程学习任务中的影响。"
      },
      {
        "name": "教育实证研究",
        "confidence": 0.85,
        "reason": "采用控制实验方法，通过分组对比、统计分析（p值）来实证评估ChatGPT对学习效果的影响。"
      },
      {
        "name": "生成式AI教育应用",
        "confidence": 0.8,
        "reason": "研究主题是大型语言模型（如ChatGPT）在教育场景中的具体应用、潜在风险与应对策略。"
      }
    ],
    "tags_confirmed": true,
    "category": "CS教育",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283635611",
          "title": "DeepSeek-R1-assisted design and maintenance of concrete-filled steel tubular structures through automated modeling code generation",
          "authors": [
            "Xiao-Guang Zhou",
            "Chao Hou"
          ],
          "year": 2026,
          "venue": "Engineering applications of artificial intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283897212",
          "title": "SIGMA: An AI-Empowered Training Stack on Early-Life Hardware",
          "authors": [
            "L. Qu",
            "Lianhai Ren",
            "Peng Cheng",
            "Rui Gao",
            "Ruizhe Wang",
            "Tianyu Chen",
            "Xiao Liu",
            "Xingjian Zhang",
            "Yeyun Gong",
            "Yifan Xiong",
            "Yucheng Ding",
            "Yuting Jiang",
            "Zheng-Wen Lin",
            "Zhongxin Guo",
            "Ziyue Yang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280860499",
          "title": "Fast and Controllable Bias-Guided Jailbreak Attack on Large Language Models",
          "authors": [
            "Zizi Kang",
            "H. Xia",
            "Rui Zhang",
            "Xiaoxue Song",
            "Le Li",
            "Chunqiang Hu"
          ],
          "year": 2025,
          "venue": "IEEE Internet of Things Journal",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283896079",
          "title": "ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding",
          "authors": [
            "Jia-Nan Li",
            "Jian Guan",
            "Wei Wu",
            "Chongxuan Li"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283895778",
          "title": "Socratic Students: Teaching Language Models to Learn by Asking Questions",
          "authors": [
            "Rajeev Bhatt Ambati",
            "Tianyi Niu",
            "Aashu Singh",
            "Shlok Mishra",
            "Shashank Srivastava",
            "Snigdha Chaturvedi"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283897144",
          "title": "AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning",
          "authors": [
            "Jiaru Zou",
            "Ling Yang",
            "Yunzhe Qi",
            "Sirui Chen",
            "Mengting Ai",
            "Ke Shen",
            "Jingrui He",
            "Mengdi Wang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283895994",
          "title": "Scaling Laws for Code: Every Programming Language Matters",
          "authors": [
            "Jian Yang",
            "Shawn Guo",
            "Lin Jing",
            "Wei Zhang",
            "Aishan Liu",
            "Chuan Hao",
            "Zhoujun Li",
            "Wayne Xin Zhao",
            "Xianglong Liu",
            "Weifeng Lv",
            "Bryan Dai"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283896626",
          "title": "neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings",
          "authors": [
            "Ojas Pungalia",
            "Rashi Upadhyay",
            "Abhishek Mishra",
            "H. Abhiram",
            "Tejasvi Alladi",
            "Sujan Yenuganti",
            "Dhruv Kumar"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283896665",
          "title": "NL2Repo-Bench: Towards Long-Horizon Repository Generation Evaluation of Coding Agents",
          "authors": [
            "Jingzhe Ding",
            "Shengda Long",
            "Changxin Pu",
            "Huan Zhou",
            "Hongwan Gao",
            "Xiang Gao",
            "Chao He",
            "Yue Hou",
            "Fei Hu",
            "Zhaojian Li",
            "Weiran Shi",
            "Zaiyuan Wang",
            "Daoguang Zan",
            "Chenchen Zhang",
            "Xiaoxu Zhang",
            "Qizhi Chen",
            "Xianfu Cheng",
            "Bo Deng",
            "Qingshui Gu",
            "Kaihui Hua",
            "Juntao Lin",
            "Pai Liu",
            "Mingchen Li",
            "Xuanguang Pan",
            "Zifan Peng",
            "Yujia Qin",
            "Yong Shan",
            "Zhewen Tan",
            "Weihao Xie",
            "Zihan Wang",
            "Yishuo Yuan",
            "Jiayu Zhang",
            "Enduo Zhao",
            "Yunfei Zhao",
            "He Zhu",
            "Chenyang Zou",
            "Ming Ding",
            "Jianpeng Jiao",
            "Jiaheng Liu",
            "Minghao Liu",
            "Qiangcai Liu",
            "Chongyao Tao",
            "Jian Yang",
            "Tong Yang",
            "Zhaoxiang Zhang",
            "Xinjie Chen",
            "Wenhao Huang",
            "Ge Zhang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283897135",
          "title": "Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context",
          "authors": [
            "Jahidul Arafat"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283896851",
          "title": "Market-Bench: Evaluating Large Language Models on Introductory Quantitative Trading and Market Dynamics",
          "authors": [
            "Abhay Srivastava",
            "Sam Jung",
            "Spencer Mateega"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283897177",
          "title": "Training Versatile Coding Agents in Synthetic Environments",
          "authors": [
            "Yiqi Zhu",
            "Apurva Gandhi",
            "Graham Neubig"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283738094",
          "title": "Language models for the analysis of and interaction with climate change documents",
          "authors": [
            "Elena Volkanovska"
          ],
          "year": 2025,
          "venue": "Environmental Data Science",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883329",
          "title": "AutoFSM: A Multi-agent Framework for FSM Code Generation with IR and SystemC-Based Testing",
          "authors": [
            "Qiuming Luo",
            "Yanming Lei",
            "Kunzhong Wu",
            "Yixuan Cao",
            "Chengjian Liu"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883635",
          "title": "AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference",
          "authors": [
            "Kuan-Wei Lu",
            "Ding-Yong Hong",
            "Pangfeng Liu"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883443",
          "title": "Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models",
          "authors": [
            "Melih Catal",
            "Pooja Rani",
            "Harald C. Gall"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883336",
          "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation",
          "authors": [
            "Hong Je-Gal",
            "Chan-Bin Yi",
            "Hyun-Suk Lee"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883832",
          "title": "Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration",
          "authors": [
            "Adilet Metinov",
            "Gulida M. Kudakeeva",
            "G. Kabaeva"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883503",
          "title": "Progress over Points: Reframing LM Benchmarks Around Scientific Objectives",
          "authors": [
            "Alwin Jin",
            "Sean M. Hendryx",
            "Vaskar Nath"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283883414",
          "title": "REMODEL-LLM: Transforming C code to Java using LLMs",
          "authors": [
            "Aryan Gupta",
            "Y. R. Reddy"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737023",
          "title": "PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code",
          "authors": [
            "Itay Dreyfuss",
            "Antonio Abu Nassar",
            "Samuel Ackerman",
            "Axel Ben David",
            "Rami Katan",
            "Orna Raz",
            "Marcel Zalmanovici"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737082",
          "title": "ESS: An Offload-Centric Latent-Cache Management Architecture for DeepSeek-V3.2-Exp",
          "authors": [
            "Xinhang Chen",
            "Chao Zhang",
            "Jiahuan He",
            "Wei Liu",
            "Jianming Zhang",
            "Wenlong Zhou",
            "Xiao Li",
            "Pai Zeng",
            "Shiyong Li",
            "Yuanpan Qian",
            "Dong Li",
            "Zhaogeng Li"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737329",
          "title": "Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap",
          "authors": [
            "Shagnik Pal",
            "Shaizeen Aga",
            "Suchita Pati",
            "Mahzabeen Islam",
            "L. John"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737095",
          "title": "Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving",
          "authors": [
            "Songyang Gao",
            "Yuzhe Gu",
            "Zijian Wu",
            "Lingkai Kong",
            "Wenwei Zhang",
            "Zhongrui Cai",
            "Fan Zheng",
            "Tianyou Ma",
            "Junhao Shen",
            "Haiteng Zhao",
            "Duanyang Zhang",
            "Huilun Zhang",
            "Kuikun Liu",
            "Chengqi Lyu",
            "Yanhui Duan",
            "Chiyu Chen",
            "Ningsheng Ma",
            "Jianfei Gao",
            "Han Lyu",
            "Dahua Lin",
            "Kai Chen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737655",
          "title": "ATLAS: Automated Toolkit for Large-Scale Verified Code Synthesis",
          "authors": [
            "Mantas Baksys",
            "Stefan Zetzsche",
            "Olivier Bouissou",
            "Remi Delmas",
            "Soonho Kong"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737679",
          "title": "Scaling Behavior of Discrete Diffusion Language Models",
          "authors": [
            "Dimitri von Rutte",
            "J. Fluri",
            "Omead Brandon Pooladzandi",
            "Bernhard Scholkopf",
            "Thomas Hofmann",
            "Antonio Orvieto"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737640",
          "title": "Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale",
          "authors": [
            "Zhaodong Wang",
            "Zhenting Qi",
            "Sherman Wong",
            "Nathan Hu",
            "Samuel Lin",
            "Jun Ge",
            "Erwin Gao",
            "Yining Yang",
            "Ben Maurer",
            "Wenlin Chen",
            "David Recordon",
            "Yilun Du",
            "Minlan Yu",
            "Ying Zhang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737582",
          "title": "Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation",
          "authors": [
            "Lim Chien Her",
            "Ming Yan",
            "Yunshu Bai",
            "Ruihao Li",
            "Hao Zhang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283851547",
          "title": "The extended hollowed mind: why foundational knowledge is indispensable in the age of AI",
          "authors": [
            "Christian R. Klein",
            "Reinhard Klein"
          ],
          "year": 2025,
          "venue": "Frontiers in Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283806020",
          "title": "Retail QA Automation Framework for LLM-Generated UX: Testing Conversational Commerce Interfaces for Compliance, Clarity, and Consistency",
          "authors": [
            "Mohnish Neelapu"
          ],
          "year": 2025,
          "venue": "International Journal of Innovative Research in Engineering &amp; Multidisciplinary Physical Sciences",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283721921",
          "title": "Understanding Chain-of-Thought Effectiveness in Code Generation: An Empirical and Information-Theoretic Analysis",
          "authors": [
            "Naizhu Jin",
            "Zhong Li",
            "Guang Yang",
            "Tian Zhang",
            "Qingkai Zeng"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283721915",
          "title": "Efficient MoE Serving in the Memory-Bound Regime: Balance Activated Experts, Not Tokens",
          "authors": [
            "Yanpeng Yu",
            "Haiyue Ma",
            "Krish Agarwal",
            "Nicolai Oswald",
            "Qijing Huang",
            "Hugo Linsenmaier",
            "Chunhui Mei",
            "Ritchie Zhao",
            "Ritika Borkar",
            "B. Rouhani",
            "David Nellans",
            "Ronny Krashinsky",
            "Anurag Khandelwal"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283722209",
          "title": "Training-free Context-adaptive Attention for Efficient Long Context Modeling",
          "authors": [
            "Zeng You",
            "Yaofo Chen",
            "Shuhai Zhang",
            "Zhijie Qiu",
            "Tingyu Wu",
            "Yingjian Li",
            "Yaowei Wang",
            "Mingkui Tan"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283721922",
          "title": "Chasing Shadows: Pitfalls in LLM Security Research",
          "authors": [
            "Jonathan Evertz",
            "Niklas Risse",
            "Nicolai Neuer",
            "Andreas Muller",
            "Philipp Normann",
            "Gaetano Sapia",
            "Srishti Gupta",
            "David Pape",
            "Soumya Shaw",
            "Devansh Srivastav",
            "Christian Wressnegger",
            "Erwin Quiring",
            "Thorsten Eisenhofer",
            "Daniel Arp",
            "Lea Schonherr"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283712193",
          "title": "Towards a Science of Scaling Agent Systems",
          "authors": [
            "Y. Kim",
            "Ken Gu",
            "Chanwoo Park",
            "Chunjong Park",
            "Samuel Schmidgall",
            "A. Heydari",
            "Yao Yan",
            "Zhihan Zhang",
            "Yuchen Zhuang",
            "Mark Malhotra",
            "Paul Pu Liang",
            "Hae Won Park",
            "Yuzhe Yang",
            "Xuhai Xu",
            "Yi-qing Du",
            "Shwetak Patel",
            "Tim Althoff",
            "D. McDuff",
            "Xin Liu"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283711379",
          "title": "Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training",
          "authors": [
            "Jakub Krajewski",
            "Amitis Shidani",
            "Dan Busbridge",
            "Sam Wiseman",
            "Jason Ramapuram"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283711310",
          "title": "Multicalibration for LLM-based Code Generation",
          "authors": [
            "Viola Campos",
            "Robin Kuschnereit",
            "A. Ulges"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283711612",
          "title": "Token Sugar: Making Source Code Sweeter for LLMs through Token-Efficient Shorthand",
          "authors": [
            "Zhensu Sun",
            "Chengran Yang",
            "Xiaoning Du",
            "Zhou Yang",
            "Li Li",
            "David Lo"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283712228",
          "title": "Secure or Suspect? Investigating Package Hallucinations of Shell Command in Original and Quantized LLMs",
          "authors": [
            "Md Nazmul Haque",
            "Elizabeth Lin",
            "Lawrence Arkoh",
            "Biruk Tadesse",
            "Bowen Xu"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283711727",
          "title": "Autonomous Issue Resolver: Towards Zero-Touch Code Maintenance",
          "authors": [
            "Aliaksei Kaliutau"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283712208",
          "title": "From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change",
          "authors": [
            "Yong-Woon Kim"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283711605",
          "title": "Towards Foundation Models with Native Multi-Agent Intelligence",
          "authors": [
            "Shuyue Hu",
            "Haoyang Yan",
            "Yiqun Zhang",
            "Yang Chen",
            "Dongzhan Zhou",
            "Lei Bai"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283711639",
          "title": "SimpleDevQA: Benchmarking Large Language Models on Development Knowledge QA",
          "authors": [
            "Jing Zhang",
            "Lianghong Guo",
            "Yanlin Wang",
            "Mingwei Liu",
            "Jiachi Chen",
            "Yuchi Ma",
            "Ensheng Shi",
            "T. Zhuo",
            "Hongyu Zhang",
            "Zibin Zheng"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283692990",
          "title": "Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning",
          "authors": [
            "Amir Mohammad Akhlaghi",
            "Amirhossein Shabani",
            "Mostafa Abdolmaleki",
            "S. R. Kheradpisheh"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283694336",
          "title": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning",
          "authors": [
            "Nearchos Potamitis",
            "L. Klein",
            "Akhil Arora"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283693749",
          "title": "Do LLMs Trust the Code They Write?",
          "authors": [
            "Francisco Ribeiro",
            "Claudio Spiess",
            "P. Devanbu",
            "Sarah Nadi"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283693513",
          "title": "VulnLLM-R: Specialized Reasoning LLM with Agent Scaffold for Vulnerability Detection",
          "authors": [
            "Yuzhou Nie",
            "Hongwei Li",
            "Chengquan Guo",
            "Ruizhe Jiang",
            "Zhun Wang",
            "Bo Li",
            "D. Song",
            "Wenbo Guo"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283694461",
          "title": "PCMind-2.1-Kaiyuan-2B Technical Report",
          "authors": [
            "Kairong Luo",
            "Zhenbo Sun",
            "Xinyu Shi",
            "Shengqi Chen",
            "Bowen Yu",
            "Yunyi Chen",
            "Chenyi Dang",
            "Hengtao Tao",
            "Hui Wang",
            "Fangming Liu",
            "Kaifeng Lyu",
            "Wenguang Chen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283693420",
          "title": "AutoICE: Automatically Synthesizing Verifiable C Code via LLM-driven Evolution",
          "authors": [
            "Weilin Luo",
            "Xueyi Liang",
            "Haotian Deng",
            "Yanan Liu",
            "Hai Wan"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283693399",
          "title": "Bridging Code Graphs and Large Language Models for Better Code Understanding",
          "authors": [
            "Zeqi Chen",
            "Zhaoyang Chu",
            "Yi Gui",
            "Feng Guo",
            "Yao Wan",
            "Chuan Shi"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-17T15:45:57.342966",
      "references": [
        {
          "external_id": "CorpusId:247309683",
          "title": "Atlas of AI: power, politics, and the planetary costs of artificial intelligence.",
          "authors": [
            "Muhammed Can"
          ],
          "year": 2022,
          "venue": "International Affairs",
          "citation_count": 649
        },
        {
          "external_id": "CorpusId:235436185",
          "title": "BEiT: BERT Pre-Training of Image Transformers",
          "authors": [
            "Hangbo Bao",
            "Li Dong",
            "Furu Wei"
          ],
          "year": 2021,
          "venue": "International Conference on Learning Representations",
          "citation_count": 3326
        },
        {
          "external_id": "CorpusId:235352775",
          "title": "MERLOT: Multimodal Neural Script Knowledge Models",
          "authors": [
            "Rowan Zellers",
            "Ximing Lu",
            "Jack Hessel",
            "Youngjae Yu",
            "J. S. Park",
            "Jize Cao",
            "Ali Farhadi",
            "Yejin Choi"
          ],
          "year": 2021,
          "venue": "Neural Information Processing Systems",
          "citation_count": 423
        },
        {
          "external_id": "CorpusId:234790100",
          "title": "Measuring Coding Challenge Competence With APPS",
          "authors": [
            "Dan Hendrycks",
            "Steven Basart",
            "Saurav Kadavath",
            "Mantas Mazeika",
            "Akul Arora",
            "Ethan Guo",
            "Collin Burns",
            "Samir Puranik",
            "Horace He",
            "D. Song",
            "J. Steinhardt"
          ],
          "year": 2021,
          "venue": "NeurIPS Datasets and Benchmarks",
          "citation_count": 872
        },
        {
          "external_id": "CorpusId:234778104",
          "title": "Women’s Participation in Open Source Software: A Survey of the Literature",
          "authors": [
            "Bianca Trinkenreich",
            "I. Wiese",
            "A. Sarma",
            "M. Gerosa",
            "Igor Steinmacher"
          ],
          "year": 2021,
          "venue": "ACM Transactions on Software Engineering and Methodology",
          "citation_count": 82
        },
        {
          "external_id": "CorpusId:233324338",
          "title": "Carbon Emissions and Large Neural Network Training",
          "authors": [
            "David A. Patterson",
            "Joseph Gonzalez",
            "Quoc V. Le",
            "Chen Liang",
            "Lluís-Miquel Munguía",
            "D. Rothchild",
            "David R. So",
            "Maud Texier",
            "J. Dean"
          ],
          "year": 2021,
          "venue": "arXiv.org",
          "citation_count": 866
        },
        {
          "external_id": "CorpusId:233289653",
          "title": "Generating bug-fixes using pretrained transformers",
          "authors": [
            "Dawn Drain",
            "Chen Wu",
            "Alexey Svyatkovskiy",
            "Neel Sundaresan"
          ],
          "year": 2021,
          "venue": "MAPS@PLDI",
          "citation_count": 55
        },
        {
          "external_id": "CorpusId:232404883",
          "title": "Alignment of Language Agents",
          "authors": [
            "Zachary Kenton",
            "Tom Everitt",
            "Laura Weidinger",
            "Iason Gabriel",
            "Vladimir Mikulik",
            "G. Irving"
          ],
          "year": 2021,
          "venue": "arXiv.org",
          "citation_count": 200
        },
        {
          "external_id": "CorpusId:245758737",
          "title": "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow",
          "authors": [
            "Sid Black",
            "Leo Gao",
            "Phil Wang",
            "Connor Leahy",
            "Stella Biderman"
          ],
          "year": 2021,
          "venue": "",
          "citation_count": 879
        },
        {
          "external_id": "CorpusId:262580630",
          "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜",
          "authors": [
            "Emily M. Bender",
            "Timnit Gebru",
            "Angelina McMillan-Major",
            "Shmargaret Shmitchell"
          ],
          "year": 2021,
          "venue": "Conference on Fairness, Accountability and Transparency",
          "citation_count": 5857
        },
        {
          "external_id": "CorpusId:231591445",
          "title": "Learning Transferable Visual Models From Natural Language Supervision",
          "authors": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "A. Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark",
            "Gretchen Krueger",
            "I. Sutskever"
          ],
          "year": 2021,
          "venue": "International Conference on Machine Learning",
          "citation_count": 39878
        },
        {
          "external_id": "CorpusId:232035663",
          "title": "Zero-Shot Text-to-Image Generation",
          "authors": [
            "A. Ramesh",
            "Mikhail Pavlov",
            "Gabriel Goh",
            "Scott Gray",
            "Chelsea Voss",
            "Alec Radford",
            "Mark Chen",
            "I. Sutskever"
          ],
          "year": 2021,
          "venue": "International Conference on Machine Learning",
          "citation_count": 5870
        },
        {
          "external_id": "CorpusId:231979430",
          "title": "Calibrate Before Use: Improving Few-Shot Performance of Language Models",
          "authors": [
            "Tony Zhao",
            "Eric Wallace",
            "Shi Feng",
            "D. Klein",
            "Sameer Singh"
          ],
          "year": 2021,
          "venue": "International Conference on Machine Learning",
          "citation_count": 1646
        },
        {
          "external_id": "CorpusId:231855531",
          "title": "CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation",
          "authors": [
            "Shuai Lu",
            "Daya Guo",
            "Shuo Ren",
            "Junjie Huang",
            "Alexey Svyatkovskiy",
            "Ambrosio Blanco",
            "Colin B. Clement",
            "Dawn Drain",
            "Daxin Jiang",
            "Duyu Tang",
            "Ge Li",
            "Lidong Zhou",
            "Linjun Shou",
            "Long Zhou",
            "Michele Tufano",
            "Ming Gong",
            "Ming Zhou",
            "Nan Duan",
            "Neel Sundaresan",
            "Shao Kun Deng",
            "Shengyu Fu",
            "Shujie Liu"
          ],
          "year": 2021,
          "venue": "NeurIPS Datasets and Benchmarks",
          "citation_count": 1335
        },
        {
          "external_id": "CorpusId:231718679",
          "title": "In-IDE Code Generation from Natural Language: Promise and Challenges",
          "authors": [
            "Frank F. Xu",
            "Bogdan Vasilescu",
            "Graham Neubig"
          ],
          "year": 2021,
          "venue": "ACM Transactions on Software Engineering and Methodology",
          "citation_count": 164
        },
        {
          "external_id": "CorpusId:231603388",
          "title": "Persistent Anti-Muslim Bias in Large Language Models",
          "authors": [
            "Abubakar Abid",
            "Maheen Farooqi",
            "James Y. Zou"
          ],
          "year": 2021,
          "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
          "citation_count": 635
        },
        {
          "external_id": "CorpusId:230435736",
          "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling",
          "authors": [
            "Leo Gao",
            "Stella Biderman",
            "Sid Black",
            "Laurence Golding",
            "Travis Hoppe",
            "Charles Foster",
            "Jason Phang",
            "Horace He",
            "Anish Thite",
            "Noa Nabeshima",
            "Shawn Presser",
            "Connor Leahy"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 2499
        },
        {
          "external_id": "CorpusId:229934464",
          "title": "Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses",
          "authors": [
            "Micah Goldblum",
            "Dimitris Tsipras",
            "Chulin Xie",
            "Xinyun Chen",
            "Avi Schwarzschild",
            "D. Song",
            "A. Ma̧dry",
            "Bo Li",
            "T. Goldstein"
          ],
          "year": 2020,
          "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
          "citation_count": 340
        },
        {
          "external_id": "CorpusId:229156229",
          "title": "Extracting Training Data from Large Language Models",
          "authors": [
            "Nicholas Carlini",
            "Florian Tramèr",
            "Eric Wallace",
            "Matthew Jagielski",
            "Ariel Herbert-Voss",
            "Katherine Lee",
            "Adam Roberts",
            "Tom B. Brown",
            "D. Song",
            "Ú. Erlingsson",
            "Alina Oprea",
            "Colin Raffel"
          ],
          "year": 2020,
          "venue": "USENIX Security Symposium",
          "citation_count": 2410
        },
        {
          "external_id": "CorpusId:226282019",
          "title": "Learning Autocompletion from Real-World Datasets",
          "authors": [
            "Gareth Ari Aye",
            "Seohyun Kim",
            "Hongyu Li"
          ],
          "year": 2020,
          "venue": "2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)",
          "citation_count": 36
        },
        {
          "external_id": "CorpusId:222178041",
          "title": "PyMT5: Multi-mode Translation of Natural Language and Python Code with Transformers",
          "authors": [
            "Colin B. Clement",
            "Dawn Drain",
            "Jonathan Timcheck",
            "Alexey Svyatkovskiy",
            "Neel Sundaresan"
          ],
          "year": 2020,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 161
        },
        {
          "external_id": "CorpusId:221836101",
          "title": "CodeBLEU: a Method for Automatic Evaluation of Code Synthesis",
          "authors": [
            "Shuo Ren",
            "Daya Guo",
            "Shuai Lu",
            "Long Zhou",
            "Shujie Liu",
            "Duyu Tang",
            "M. Zhou",
            "Ambrosio Blanco",
            "Shuai Ma"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 705
        },
        {
          "external_id": "CorpusId:235165921",
          "title": "Unit Test Case Generation with Transformers",
          "authors": [
            "Michele Tufano",
            "Dawn Drain",
            "Alexey Svyatkovskiy",
            "Shao Kun Deng",
            "Neel Sundaresan"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 234
        },
        {
          "external_id": "CorpusId:221665105",
          "title": "Learning to summarize from human feedback",
          "authors": [
            "Nisan Stiennon",
            "Long Ouyang",
            "Jeff Wu",
            "Daniel M. Ziegler",
            "Ryan J. Lowe",
            "Chelsea Voss",
            "Alec Radford",
            "Dario Amodei",
            "Paul Christiano"
          ],
          "year": 2020,
          "venue": "Neural Information Processing Systems",
          "citation_count": 2669
        },
        {
          "external_id": "CorpusId:219781060",
          "title": "Generative Pretraining From Pixels",
          "authors": [
            "Mark Chen",
            "Alec Radford",
            "Jeff Wu",
            "Heewoo Jun",
            "Prafulla Dhariwal",
            "D. Luan",
            "I. Sutskever"
          ],
          "year": 2020,
          "venue": "International Conference on Machine Learning",
          "citation_count": 1689
        },
        {
          "external_id": "CorpusId:220425360",
          "title": "Contrastive Code Representation Learning",
          "authors": [
            "Paras Jain",
            "Ajay Jain",
            "Tianjun Zhang",
            "P. Abbeel",
            "Joseph E. Gonzalez",
            "Ion Stoica"
          ],
          "year": 2020,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 167
        },
        {
          "external_id": "CorpusId:220363858",
          "title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion",
          "authors": [
            "R. Schuster",
            "Congzheng Song",
            "Eran Tromer",
            "Vitaly Shmatikov"
          ],
          "year": 2020,
          "venue": "USENIX Security Symposium",
          "citation_count": 180
        },
        {
          "external_id": "CorpusId:219966759",
          "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations",
          "authors": [
            "Alexei Baevski",
            "Henry Zhou",
            "Abdel-rahman Mohamed",
            "Michael Auli"
          ],
          "year": 2020,
          "venue": "Neural Information Processing Systems",
          "citation_count": 7213
        },
        {
          "external_id": "CorpusId:219531210",
          "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention",
          "authors": [
            "Pengcheng He",
            "Xiaodong Liu",
            "Jianfeng Gao",
            "Weizhu Chen"
          ],
          "year": 2020,
          "venue": "International Conference on Learning Representations",
          "citation_count": 3308
        },
        {
          "external_id": "CorpusId:219401607",
          "title": "Unsupervised Translation of Programming Languages",
          "authors": [
            "M. Lachaux",
            "Baptiste Rozière",
            "Lowik Chanussot",
            "Guillaume Lample"
          ],
          "year": 2020,
          "venue": "Neural Information Processing Systems",
          "citation_count": 492
        },
        {
          "external_id": "CorpusId:218971783",
          "title": "Language Models are Few-Shot Learners",
          "authors": [
            "Tom B. Brown",
            "Benjamin Mann",
            "Nick Ryder",
            "Melanie Subbiah",
            "J. Kaplan",
            "Prafulla Dhariwal",
            "Arvind Neelakantan",
            "Pranav Shyam",
            "Girish Sastry",
            "Amanda Askell",
            "Sandhini Agarwal",
            "Ariel Herbert-Voss",
            "Gretchen Krueger",
            "T. Henighan",
            "R. Child",
            "A. Ramesh",
            "Daniel M. Ziegler",
            "Jeff Wu",
            "Clemens Winter",
            "Christopher Hesse",
            "Mark Chen",
            "Eric Sigler",
            "Ma-teusz Litwin",
            "Scott Gray",
            "Benjamin Chess",
            "Jack Clark",
            "Christopher Berner",
            "Sam McCandlish",
            "Alec Radford",
            "I. Sutskever",
            "Dario Amodei"
          ],
          "year": 2020,
          "venue": "Neural Information Processing Systems",
          "citation_count": 51131
        },
        {
          "external_id": "CorpusId:218971825",
          "title": "Language (Technology) is Power: A Critical Survey of “Bias” in NLP",
          "authors": [
            "Su Lin Blodgett",
            "Solon Barocas",
            "Hal Daum'e",
            "Hanna M. Wallach"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1463
        },
        {
          "external_id": "CorpusId:219124374",
          "title": "SourceFinder: Finding Malware Source-Code from Publicly Available Repositories",
          "authors": [
            "Md Omar Faruk Rokon",
            "Risul Islam",
            "Ahmad Darki",
            "E. Papalexakis",
            "M. Faloutsos"
          ],
          "year": 2020,
          "venue": "International Symposium on Recent Advances in Intrusion Detection",
          "citation_count": 67
        },
        {
          "external_id": "CorpusId:218684574",
          "title": "Backstabber’s Knife Collection: A Review of Open Source Software Supply Chain Attacks",
          "authors": [
            "Marc Ohm",
            "H. Plate",
            "Arnold Sykosch",
            "M. Meier"
          ],
          "year": 2020,
          "venue": "International Conference on Detection of intrusions and malware, and vulnerability assessment",
          "citation_count": 241
        },
        {
          "external_id": "CorpusId:218470180",
          "title": "Jukebox: A Generative Model for Music",
          "authors": [
            "Prafulla Dhariwal",
            "Heewoo Jun",
            "Christine Payne",
            "Jong Wook Kim",
            "Alec Radford",
            "I. Sutskever"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 889
        },
        {
          "external_id": "CorpusId:211554280",
          "title": "Recalibrating global data center energy-use estimates",
          "authors": [
            "E. Masanet",
            "Arman Shehabi",
            "Nuoa Lei",
            "S. Smith",
            "J. Koomey"
          ],
          "year": 2020,
          "venue": "Science",
          "citation_count": 920
        },
        {
          "external_id": "CorpusId:211171605",
          "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages",
          "authors": [
            "Zhangyin Feng",
            "Daya Guo",
            "Duyu Tang",
            "Nan Duan",
            "Xiaocheng Feng",
            "Ming Gong",
            "Linjun Shou",
            "Bing Qin",
            "Ting Liu",
            "Daxin Jiang",
            "Ming Zhou"
          ],
          "year": 2020,
          "venue": "Findings",
          "citation_count": 3285
        },
        {
          "external_id": "CorpusId:226096901",
          "title": "5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding",
          "authors": [
            "知秀 柴田"
          ],
          "year": 2020,
          "venue": "",
          "citation_count": 12704
        },
        {
          "external_id": "CorpusId:210861095",
          "title": "Scaling Laws for Neural Language Models",
          "authors": [
            "J. Kaplan",
            "Sam McCandlish",
            "T. Henighan",
            "Tom B. Brown",
            "Benjamin Chess",
            "R. Child",
            "Scott Gray",
            "Alec Radford",
            "Jeff Wu",
            "Dario Amodei"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 6430
        },
        {
          "external_id": "CorpusId:208613572",
          "title": "What distinguishes great software engineers?",
          "authors": [
            "P. Li",
            "Amy J. Ko",
            "Andrew Begel"
          ],
          "year": 2019,
          "venue": "Empirical Software Engineering",
          "citation_count": 41
        },
        {
          "external_id": "CorpusId:204838007",
          "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
          "authors": [
            "Colin Raffel",
            "Noam Shazeer",
            "Adam Roberts",
            "Katherine Lee",
            "Sharan Narang",
            "Michael Matena",
            "Yanqi Zhou",
            "Wei Li",
            "Peter J. Liu"
          ],
          "year": 2019,
          "venue": "Journal of machine learning research",
          "citation_count": 23386
        },
        {
          "external_id": "CorpusId:108777959",
          "title": "Unified rational protein engineering with sequence-based deep representation learning",
          "authors": [
            "E. C. Alley",
            "Grigory Khimulya",
            "Surojit Biswas",
            "Mohammed Alquraishi",
            "G. Church"
          ],
          "year": 2019,
          "venue": "Nature Methods",
          "citation_count": 982
        },
        {
          "external_id": "CorpusId:202712680",
          "title": "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search",
          "authors": [
            "Hamel Husain",
            "Hongqiu Wu",
            "Tiferet Gazit",
            "Miltiadis Allamanis",
            "Marc Brockschmidt"
          ],
          "year": 2019,
          "venue": "arXiv.org",
          "citation_count": 1244
        },
        {
          "external_id": "CorpusId:202573071",
          "title": "CTRL: A Conditional Transformer Language Model for Controllable Generation",
          "authors": [
            "N. Keskar",
            "Bryan McCann",
            "L. Varshney",
            "Caiming Xiong",
            "R. Socher"
          ],
          "year": 2019,
          "venue": "arXiv.org",
          "citation_count": 1350
        },
        {
          "external_id": "CorpusId:203171710",
          "title": "Automatic programming: The open issue?",
          "authors": [
            "M. O’Neill",
            "L. Spector"
          ],
          "year": 2019,
          "venue": "Genetic Programming and Evolvable Machines",
          "citation_count": 26
        },
        {
          "external_id": "CorpusId:199453025",
          "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks",
          "authors": [
            "Jiasen Lu",
            "Dhruv Batra",
            "Devi Parikh",
            "Stefan Lee"
          ],
          "year": 2019,
          "venue": "Neural Information Processing Systems",
          "citation_count": 4148
        },
        {
          "external_id": "CorpusId:198953378",
          "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
          "authors": [
            "Yinhan Liu",
            "Myle Ott",
            "Naman Goyal",
            "Jingfei Du",
            "Mandar Joshi",
            "Danqi Chen",
            "Omer Levy",
            "M. Lewis",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
          ],
          "year": 2019,
          "venue": "arXiv.org",
          "citation_count": 27461
        },
        {
          "external_id": "CorpusId:186206968",
          "title": "SPoC: Search-based Pseudocode to Code",
          "authors": [
            "Sumith Kulal",
            "Panupong Pasupat",
            "Kartik Chandra",
            "Mina Lee",
            "Oded Padon",
            "A. Aiken",
            "Percy Liang"
          ],
          "year": 2019,
          "venue": "Neural Information Processing Systems",
          "citation_count": 276
        },
        {
          "external_id": "CorpusId:239549249",
          "title": "Protecting Visual Information in Augmented Reality from Malicious Application Developers",
          "authors": [
            "Jk Jensen",
            "Jinhan Hu",
            "Amir Rahmati",
            "R. Likamwa"
          ],
          "year": 2019,
          "venue": "WearSys@MobiSys",
          "citation_count": 166
        },
        {
          "external_id": "CorpusId:170079302",
          "title": "Learning Compositional Neural Programs with Recursive Tree Search and Planning",
          "authors": [
            "Thomas Pierrot",
            "Guillaume Ligner",
            "Scott E. Reed",
            "Olivier Sigaud",
            "Nicolas Perrin",
            "Alexandre Laterre",
            "David Kas",
            "Karim Beguir",
            "Nando de Freitas"
          ],
          "year": 2019,
          "venue": "Neural Information Processing Systems",
          "citation_count": 42
        }
      ],
      "references_fetched_at": "2025-12-17T15:45:58.191443"
    },
    "translated_content": "文章\n\n# ChatGPT 时代的计算机科学教育：面向初学者的编程课程实验经验\n\nTomaž Kosar $^{1}$，Dragana Ostojić $^{1}$，Yu David Liu $^{2}$，Marjan Mernik $^{1, *}$\n\n$^{1}$ 斯洛文尼亚马里博尔大学电气工程与计算机科学学院，Koroška cesta 46，2000 Maribor，Slovenia；tomaz.kosar@um.si（T.K.）；dragana.ostojic@um.si（D.O.）  \n$^{2}$ 美国纽约州立大学宾汉姆顿分校（SUNY）计算机科学系，4400 Vestal Parkway East，Binghamton，NY 13902，USA；davidl@binghamton.edu  \n* 通讯作者：marjan.mernik@um.si\n\n摘要：随着 ChatGPT 等大型语言模型聊天机器人的普及，学生群体——尤其是计算机科学教育领域——对其使用日益频繁。然而，教育界对 ChatGPT 在学习过程中的作用存在显著争议。因此，厘清 ChatGPT 对课堂学习、学生参与度及整体学业成就的可能影响至关重要。本实证研究在一门面向大一学生的面向对象编程课程中开展对照实验，共 182 名参与者。通过差异研究设计，将学生分为使用 ChatGPT 组与未使用 ChatGPT 组，完成实践编程作业。研究结果显示，ChatGPT 的使用并未显著影响学生成绩（组间 $p$ 值为 0.730），亦未对实践作业评分（$p$ 值为 0.760）及期中考试成绩（$p$ 值为 0.856）产生显著差异。对照实验结果表明，若在教学过程中采取特定措施与调整，初学者使用 ChatGPT 是安全的。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/eb49dc1f10ab87bde16826b9ca39fe1d0427ab99cab4d4193f53a032be36f5ad.jpg)\n\n引用格式：Kosar, T.; Ostojic, D.; Liu, Y.D.; Mernik, M. Computer Science Education in ChatGPT Era: Experiences from an Experiment in a Programming Course for Novice Programmers. *Mathematics* **2024**, *12*, 629. https://doi.org/10.3390/math12050629\n\n学术编辑：Chengjie Sun  \n收稿日期：2024 年 1 月 19 日  \n修订日期：2024 年 2 月 16 日  \n接受日期：2024 年 2 月 18 日  \n发表日期：2024 年 2 月 21 日\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/7f2eb8cdeb3723210720814e6fc60b069ddbd623510666cb30c38698636f621e.jpg)\n\n版权：© 2024 作者。许可方 MDPI，瑞士巴塞尔。本文是一篇开放获取文章，遵循知识共享署名（CC BY）许可协议（https://creativecommons.org/licenses/by/4.0/）发布。\n\n关键词：大型语言模型；ChatGPT；人工智能；对照实验；面向对象编程；软件工程教育\n\nMSC：97P10\n\n# 1. 引言近年来，在线学习平台、移动设备以及虚拟学习环境等新技术的融合，彻底革新了教育工作者传递内容并与学生互动的方式。这些创新使教育更具可及性、个性化与交互性，学生因而能够以自身节奏更深入地探索学科内容。在我们仍在理解并应用这些技术之际，另一项新技术——生成式人工智能（generative artificial intelligence, AI）[1]——已悄然浮现。\n\n大型语言模型（large language models, LLMs）[2] 的使用近年来呈指数级增长。其中，ChatGPT [3] 自 2022 年 11 月发布以来便备受公众瞩目。ChatGPT 由 OpenAI [4] 开发，是一款聊天机器人，可与用户进行类人对话。该模型能够回答问题，并协助完成撰写电子邮件、论文乃至编程代码等任务 [5,6]。一方面，其生成的文本颇具可信度，使其成为强大工具；另一方面，ChatGPT 亦可能被滥用，例如学生利用其代写论文。\n\n在计算机科学教育领域，关于课堂中使用 ChatGPT 生成代码的争议尤为激烈。支持方充分论证了其在教育中的益处 [7]。例如，ChatGPT 可为学生提供更富交互性与吸引力的学习体验，提升其兴趣与动机 [8,9]。计算机科学学生可就编程代码提问并获得即时反馈，从而提高编程学习效率 [10]。此外，ChatGPT 能够生成多种示例，用以阐释复杂的编程概念 [7]。\n\n然而，反对方则认为此举存在风险 [11,12]。LLM 受限于其训练知识 [7]，可能在回答复杂问题时出现不准确的情况 [13]。此外，代码调试与解读需对代码本身有深入理解。教师可提供逐步讲解，而现有 LLM 在此方面仍显不足，如文献 [14] 所示。另一严重弊端在于，ChatGPT 可能阻碍学生能力的培养，例如推理能力 [15]。若学生过度依赖 ChatGPT 获取编程代码，便难以独立发展解决问题所需的技能。过度使用与作弊行为，成为计算机科学教育工作者对 ChatGPT 使用的主要担忧，尤其针对初学者（大一新生）。简言之，学生将无法培养批判性思维、创造力、决策能力 [16] 以及软件开发者必备的问题解决能力 [17]。部分高校甚至已采取措施，在校园网络中屏蔽 ChatGPT 网站 [18]。然而，LLM 技术大概率将长期存在。我们认为，与其回避这些技术，不如拥抱 LLM 并推动教育现代化 [19]。为了理解 LLM 与 ChatGPT 如何影响学习过程 [16]，亟需开展实验研究 [10,20–23]。我们必须以实证且严谨的方式检验一些普遍观念，例如“学生将毫不犹豫地利用 LLM 进行剽窃”[24]，或“使用 LLM 会负面削弱其批判性思维与问题解决能力”[16]。本文报告了我们在斯洛文尼亚马里博尔大学（University of Maribor）计算机科学与信息技术本科一年级第二学期“Programming II”课程中，借助 ChatGPT 开展学习的实践经验。我们的实验围绕以下研究问题展开：\n\n- ChatGPT 的使用是否会影响实践作业成绩与期中考试成绩？  \n- ChatGPT 的使用是否会影响该入门编程课程的整体学业表现？  \nChatGPT 的使用对课程最终成绩有何影响？  \n- 在 Programming II 课程中，学生出于何种目的使用 ChatGPT？  \n- 据学生反馈，ChatGPT 究竟是否有助于编程学习？\n\n在此框架下，我们开展了一项对照实验 [25]，让计算机科学本科一年级学生在完成实践作业时使用 ChatGPT。我们设置了两组：一组允许使用 ChatGPT，另一组禁止使用。针对本年度面向对象编程入门课程，我们在实施过程中进行了若干调整。\n\n对照实验结果表明，课程总体成绩、实践作业成绩以及期中考试成绩均未受到 ChatGPT 使用的显著影响。我们认为，这一结论主要归因于我们在以下三方面对课程所做的调整：（1）作业设计；（2）作业答辩；（3）期中考试。这些举措促使参与者不会单纯依赖 ChatGPT。例如，我们精心设计的所有作业均最大限度地降低了 ChatGPT 直接给出答案的可能性。另一亮点是，我们引入了新的评价流程：作业评分不再仅依据学生提交给原始题目的代码，而是在实验课中通过“交互式答辩”环节，由学生与助教共同完成一个扩展版任务，并据此给出成绩。总体而言，我们认为应将 ChatGPT 纳入未来教育体系，但必须在课程评价方式上做出相应调整，以促进真正的学习。\n\n本文结构如下：第 2 节介绍 ChatGPT 的研究背景，第 3 节综述相关文献，第 4 节……实验设计。第5节汇报结果与数据分析；第6节讨论本受控实验对效度的威胁；最后，第7节总结本实证研究的关键发现。\n\n# 2 背景\n\nLLMs [2] 是自然语言处理（NLP）[26] 领域的一项变革性技术，带来了全新的语言能力与多样化的应用机遇。这些模型拥有庞大的神经架构，并依托海量训练数据 [27]。LLMs 使应用能够以此前无法实现的方式理解、生成并操控人类语言。其核心特征在于生成近似人类言语的文本。最具代表性的 LLM 之一是基于 Transformer 架构 [29] 的生成式预训练变换模型 GPT-3 [28]，该模型显著推进了 NLP 的发展。\n\n聊天机器人（Chatbots）[30] 是一种旨在通过互联网以文本（或语音 [31]）形式模拟对话的计算机程序。它们被设计为理解自然语言，并以模仿人际交流的方式回应用户提问。聊天机器人可分为两大类：基于规则的与基于机器学习（有时称为 AI 驱动）的聊天机器人 [30]。基于规则的聊天机器人依赖预设规则运行，根据特定关键词或短语给出回应，其能力有限，难以应对复杂问题。相比之下，AI 驱动的聊天机器人采用 LLM 等先进技术，能够理解上下文并从交互与回应中学习。两类机器人均广泛应用于客户支持、医疗、信息检索辅助、虚拟助理、教育、营销等场景。\n\n由 LLMs 赋能的聊天机器人标志着人机交互演进的重要里程碑。这些智能代理已超越传统聊天机器人，能够与用户进行自然且具备上下文感知的对话。LLM 驱动的聊天机器人理解语言变体，使交互更具人类特征与个性化。ChatGPT [3] 便是其中一例。ChatGPT 是由 OpenAI [4] 开发并公开提供、基于 LLM GPT-3 的最受欢迎聊天机器人，擅长模仿与用户的类人交流。GPT-3 模型在约 1750 亿可训练参数与 570 GB 文本数据上训练 [32]。在本实验期间（2023 年 2 月至 6 月），我们使用的是搭载 GPT-3.5 的 ChatGPT；尽管 GPT-4 已于 2023 年 3 月发布，但当时尚未免费开放。提示（Prompts）[33] 是指提供给聊天机器人以生成回复的输入。提示是用户在与聊天机器人交互时所给出的人工指令或问题。提示可分为多种类型：基于文本的、基于语音的、任务驱动的、信息性的、对话式的以及编程提示。在最后一类中，程序员可以发送包含代码片段的特定编程提示，聊天机器人则能够利用该输入生成具有上下文的回应。因此，程序员（及其他用户）可通过一种称为提示工程（prompt engineering）的过程对提示进行修改与微调，从而更好地指导大模型（LMMs）提供更准确且更复杂的解决方案。在此过程中，程序员可采用提示模式（prompt patterns）[34]——类似于软件模式，是可复用的提示，用于解决与 LLM 交互中的常见问题。其中一种提示模式即为领域特定语言（DSL）[35,36] 创建模式。\n\n# 3 相关工作\n\nChatGPT 近期的流行引发了人们对其在不同领域所带来的益处（如 AI 结对编程）或弊端（如作弊）的广泛关注，也促使学界探讨该聊天机器人对高等教育 [12] 的总体影响。自 ChatGPT 公开发布以来，关于其能力与局限性的研究便迅速涌现 [37]。本研究亦对该领域作出贡献，本节将对上述研究进行综述。\n\n与 ChatGPT 在编程学习中应用最为密切相关的一项实证研究由 [21] 报告。与我们的研究类似，该研究以本科生为对象在参加面向对象编程课程的更具经验的大二学生中，Yilmaz 与 Yilmaz 的研究样本量较小（41 人）。其受试者需以多种编程语言（Python、Java 与 $\\mathrm{C + + }$）完成实践作业，而本研究的实践作业仅限于 $\\mathrm{C + + }$。二者在设计层面存在根本差异：本研究为**组间设计**（between-subjects，即差异比较研究），而 Yilmaz 与 Yilmaz 采用**组内设计**（within-subjects）——所有受试者均先使用 ChatGPT 完成任务，随后通过开放式问卷表达意见。相反，本研究设置两组（ChatGPT 组与无 ChatGPT 组），并比较两组间的结果差异。Yilmaz 等的研究对象指出，ChatGPT 最显著的优势在于**节省时间**：他们可迅速获得较为准确的答案，从而减少检索时间。此外，ChatGPT 有助于调试与解决复杂问题，且可 24 小时随时可用。尽管部分受试者认为 ChatGPT 并无明显缺陷，另一些则提出其使用可能导致**惰性、思维弱化**及**职业焦虑**，且 ChatGPT 亦可能生成错误答案。总体而言，受试者对 ChatGPT 持积极态度，视其为解决复杂问题、学习陌生主题的有益工具。本研究对照实验的反馈结果印证了上述发现。\n\n文献 [10] 报告了另一项针对本科生的相关研究。与本对照实验类似，该文亦采用组间设计，设置两组：一组可使用 ChatGPT，另一组仅能查阅教材与笔记且禁用网络。不同于 [10] 在课程结束后统一布置编程挑战，本研究的受试者在学期过程中**随课程进度**完成布置的作业，部分在家完成，部分在实验课课堂完成；[10] 并未提及对作业的任何调整。在结果方面，文献 [10] 指出，ChatGPT 组在**限定输入、输出与约束**的任务中，于更短时间内获得更高分数，评估依据为通过的测试用例数量。然而，本对照实验的结果**未能复现**上述结论。研究 [10] 亦报告，受试者在处理更复杂任务时面临挑战，部分问题未能完全解决，且提交的代码存在**准确性不足**与**一致性差**的问题。另一项最新研究 [22] 将 ChatGPT 视为一名学生，测试其是否能够完成一门入门级函数式语言编程课程。结果表明，ChatGPT 获得了 67%（B−）的总评成绩，在 314 名学生中排名第 155。该研究采用“无辅助”与“有辅助”两种方式进行，模拟学生自然学习过程。作者通过四种提示工程（prompt engineering）技术对 ChatGPT 进行辅助：问题复述、提供提示、示例教学以及给出测试用例。在无额外帮助的情况下，ChatGPT 在 31 项任务中成功解决 16 项，成功率达 100%。然而，一旦出错，错误类型集中于编译或逻辑错误，语法错误相对较少。在获得辅助后，ChatGPT“学生”的排名从第 220 位提升至第 155 位。我们在实践作业中也获得类似经验：在未追加提示的情况下，ChatGPT 得分为 24/44；若采用恰当的提示工程，得分可提升至约 34 分。该研究作者指出，ChatGPT 主要难以理解类型规范、推断表达式类型以及处理较大规模的编程任务。基于上述结果，仅依赖 ChatGPT 所生成代码的学生必须对实践作业进行答辩。我们在受控实验中也始终遵循了这一答辩机制。\n\n为探究 ChatGPT 对计算机工程专业学生的影响，文献 [23] 在嵌入式系统课程中开展了一项受控实验。其主要目标是检验 ChatGPT 能在多大程度上帮助学生在未学习相关主题的情况下回答测验题，随后将这些结果与上一代学生在学习相关主题后回答同一套题目的成绩进行比较。我们的实验任务全部为编程任务；而 Shoufan 的研究还包含理论题（判断题），我们的任务则聚焦于编写完整代码、代码补全（给定部分代码）以及代码分析（给定输入/输出等）。此外，两项研究在主题（嵌入式系统 vs. 面向对象编程）、受试者经验（高年级 vs. 初学者）及实验周期（四次测验 vs. 整门课程）等方面亦存在差异。文献 [23] 的研究发现，ChatGPT 组在代码分析与理论题上表现更佳，但在代码补全及涉及图像的题目上遇到困难。在编写完整代码方面，结果并不一致。作者最终得出结论：目前 ChatGPT 在计算机工程教育中的应用仍显不足，学习相关主题依然不可或缺。一项来自数学领域的有趣实证研究 [19] 探讨了 ChatGPT 对其学生可能产生的影响。该研究同时聚焦于计算机科学学生所需的核心技能——使用 ChatGPT 如何影响批判性思维、问题解决以及团队协作能力。参与者在完成相关作业后，就上述三项技能给出了评价，采用五点李克特量表（1 分表示“无影响”，5 分表示“影响很大”）。平均得分分别为：批判性思维 2.38、问题解决 2.39、团队协作 2.97，表明参与者认为 ChatGPT 对前述技能的习得具有轻微至中等程度的影响，其中团队协作技能受到的影响最大。若能在计算机科学学生群体中重复该研究，结果将颇具参考价值；这亦可作为复制性研究 [38] 的一组引人关注的反馈问题。除开展反馈研究外，还可借助评估工具验证学生的问题解决能力 [39]，例如在面向对象编程（OOP）情境中。该研究的结论指出，将 ChatGPT 融入教育会引入新的挑战，亟需调整教学策略与方法，以培养工程师的关键技能 [19]。我们遵循该建议，并在本课程“Programming II”中对实践作业进行了相应调整。\n\n# 4 实验设计与目标\n\n本对照实验旨在比较参与者在整个学期内的学习成果。具体而言，我们拟验证学期中使用 ChatGPT 是否会对期末成绩、期中考试成绩以及实验课成绩产生影响。本节将详细阐述研究设计与目标。\n\n# 4.1 对照实验与参与者我们在斯洛文尼亚马里博尔大学电气工程与计算机科学学院（FERI）开设的“程序设计 II”课程中进行了一项受控实验；该课程由第四位作者主讲，第一、二位作者担任助教，第三位作者当时为富布赖特访问学者。课程所涵盖的主题列于表 1。在我校本科培养方案中，“程序设计 II”是首门面向对象程序设计课程，教学内容包括类定义、实例变量、方法、关联、继承等基础概念。由于课程采用 $\\mathrm{C}++$，我们最后还会介绍 $\\mathrm{C}++$ 的新特性。研究对象为计算机科学专业的一年级本科生，该专业是斯洛文尼亚两个主要计算机科学本科项目之一，吸引了全国最优秀的学生。实验初始共有 198 名参与者，后因多种原因剔除了少量样本。除非技术性原因外，未完成任何实践作业或未参加期中考试的学生亦被排除。最终，本研究纳入 182 名学生的数据。\n\n本实证研究采用组间设计。学期初，我们与全体学生就 ChatGPT 的潜在影响及拟开展的实验进行了说明，学生一致同意后，将其随机分为两组，每组 99 人。分组由技术人员随机完成，参与者被提醒勿向授课教师及助教透露分组信息，以避免影响实践作业、答辩及期中考试评分。后文中，我们将被鼓励使用 ChatGPT 的实验组称为 Group I，被要求不使用 ChatGPT 的对照组称为 Group II。为进一步保证对照组纯净，我们约定：若 Group II 的学生在反馈问卷中报告曾在实践作业中使用 ChatGPT，则将其数据剔除，以免污染该组结果。\n\n表 1　“程序设计 II”课程主题及配套实验作业<table><tr><td rowspan=\"2\">周次</td><td rowspan=\"2\">主题</td><td colspan=\"2\">实践作业</td></tr><tr><td>必修</td><td>选修</td></tr><tr><td>1</td><td>Programming I 复习</td><td>Fuel Consumption</td><td>Disarium number</td></tr><tr><td>2</td><td>基础类</td><td>Exercise</td><td>Fuel Log</td></tr><tr><td>3</td><td>类变量与方法</td><td>Time</td><td>Text Utility</td></tr><tr><td>4</td><td>聚合与组合</td><td>Exercise Tracker</td><td>Mail Box</td></tr><tr><td>5</td><td>继承</td><td>Strength Exercise</td><td>Bank</td></tr><tr><td>6</td><td></td><td>期中考试 I</td><td></td></tr><tr><td>7</td><td>抽象类</td><td>Graph</td><td>Graphic Layout</td></tr><tr><td>8</td><td>模板函数</td><td>Vector Util</td><td>Vector Util</td></tr><tr><td>9</td><td>模板类</td><td>Linear Queue</td><td>Linked List</td></tr><tr><td>10</td><td></td><td>补充辅导</td><td></td></tr><tr><td>11</td><td>运算符重载</td><td>Smart Pointer</td><td>Smart Pointer</td></tr><tr><td>12</td><td>C++11 与 C++14</td><td>Exercise Tracker</td><td>Printer</td></tr><tr><td>13</td><td>异常与文件流</td><td>Sensor Hub</td><td>Log</td></tr><tr><td>14</td><td></td><td colspan=\"2\">期末实践作业答辩</td></tr><tr><td>15</td><td></td><td colspan=\"2\">期中考试 II</td></tr></table>\n\n# 4.2 实践作业\n\n每周布置的作业均与当次讲座所授主题紧密相关（见表 1“主题”列）。参与者在讲座结束后会收到一段简短的作业描述，随后需在家中独立完成代码，直至下一次在学院进行的实验课。\n\n《Programming II》课程的实践部分共包含 22 项作业，其中 11 项为必修，11 项为选修（见表 1“实践作业”列）。每周发布 1 项必修作业与 1 项选修作业，二者分值相同（均为 2 分）。需注意的是，学期总时长为 15 周，但在期中考试周不布置实践作业。实践作业的答辩安排在下一节实验课（即讲座之后）进行。为防止往届学生将作业解答传递给新生，我们每年均重新设计必修与选修作业。\n\n由表 1 可见，每周所涉问题均不相同，且必修与选修作业的题目亦有所区分。我们认为，向学生提供多样化的问题有助于其更积极地理解面向对象编程。图 1 展示了一个典型的作业示例（实践作业可在项目主页获取：https://github.com/tomazkosar/DifferentialStudyChatGPT，访问日期：2024 年 1 月 12 日）。作业提供了简短的文字说明，指出参与者需要提交何种代码，并附有一张 UML 图以供进一步参考。请注意，两组学生收到的作业完全相同（即表 1 中“必修”与“选修”列所列内容）。\n\n以任务 4.1 为例：\n\n- 修改 `ExerciseTracker` 类，使其成员变量 `exercises` 的类型为 `vector<Exercise*>`（采用组合关系）。  \n- 新增 `StrengthExercise` 类，并使其继承自 `Exercise` 类。  \n- 在 `main` 函数中创建 `ExerciseTracker` 对象，并向 `exercises` 添加：  \n  3 个 `Exercise` 实例，以及  \n  2 个 `StrengthExercise` 实例。  \n\n解题提示：\n\n- 注意正确使用 `protected`、`virtual` 与 `override`。  \n- 解题时需综合运用迄今所学全部知识（使用初始化列表、常量成员函数、按需编写 get/set 方法等）。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/39569b0b1f949cd66f99b3522406a96d8f5c2ad3328d06f2c7b0be24172ef400.jpg)  \n图 1. 实践作业示例（第 5 周必修）。\n\n# 4.3. 面向 ChatGPT 的调整\n\n为开展本实验，我们对课程评价方式进行了若干重要调整。事后看来，这些措施对于厘清 ChatGPT 时代的教学最佳实践起到了关键作用。\n\n# 4.3.1. 题目设计\n\n学期开始前，我们分析了 ChatGPT 对往年 Programming II 学生所布置问题的解答情况。结果发现，ChatGPT 在提供含详细文字描述的实践作业解决方案方面表现优异，这一现象亦被近期研究所证实 [40]。因此，我们决定实施表 2 所列的一系列调整。该表各列含义如下：\n\n类型  \n例如，“扩展”作业要求参与者在先前某一实践作业的基础上进行功能扩展。\n\n提供代码  \n部分作业预先给出若干代码片段，要求参与者将其整合进自己的程序中。\n\n描述  \n部分作业仅提供极简文字说明，补充信息通过 UML 图呈现。\n\n输入/输出  \n即学生获得程序的预期输入或精确输出，需据此完成实现。\n\nMain  \n部分作业直接提供主程序及作业描述，参与者在此基础上完成任务。\n\n表 2. 必修作业说明。<table><tr><td>问题</td><td>类型</td><td>是否提供代码</td><td>描述形式</td><td>输入/输出</td><td>主程序</td></tr><tr><td>Fuel Consumption</td><td>新增</td><td>是</td><td>文本</td><td>否</td><td>是</td></tr><tr><td>Exercise</td><td>新增</td><td>否</td><td>文本</td><td>否</td><td>否</td></tr><tr><td>Time</td><td>新增</td><td>否</td><td>文本</td><td>否</td><td>否</td></tr><tr><td>Exercise Tracker</td><td>扩展</td><td>是</td><td>文本</td><td>否</td><td>否</td></tr><tr><td>Strength Exercise</td><td>扩展</td><td>否</td><td>UML</td><td>否</td><td>否</td></tr><tr><td>Graph</td><td>新增</td><td>是</td><td>UML</td><td>是</td><td>是</td></tr><tr><td>Vector Util</td><td>新增</td><td>是</td><td>文本</td><td>是</td><td>是</td></tr><tr><td>Linear Queue</td><td>新增</td><td>否</td><td>文本</td><td>否</td><td>否</td></tr><tr><td>Smart Pointer</td><td>新增</td><td>是</td><td>文本</td><td>否</td><td>否</td></tr><tr><td>Exercise Tracker</td><td>扩展</td><td>否</td><td>文本</td><td>否</td><td>是</td></tr><tr><td>Sensor Hub</td><td>新增</td><td>否</td><td>文本 + UML</td><td>否</td><td>否</td></tr></table>\n\n在个体实践作业中，我们引入了表2所示的一项或多项调整，该表在构建实践作业前充当我们的设计指南。其目的在于阻止ChatGPT直接给出完整答案，从而避免第一组学生对ChatGPT产生盲目依赖。我们尽可能采用图示（UML、I/O程序、主程序等）。ChatGPT对非文本提示的不足此前已有报道[40]。然而，我们也发现，在经验丰富的程序员多轮追问下，几乎所有作业ChatGPT都能给出解答；相反，新手程序员因缺乏知识与问题背景，往往难以构造最有效的提示。\n\n# 4.3.2 扩展作业\n\n我们在每节课末尾布置的初始实践作业并不完整。在随后的实验课开始时，参与者需完成与原作业相关的扩展问题。此过程中，禁止使用ChatGPT或类似工具（如社交媒体）。不过，查阅讲义、互联网及带示例的应用库文档不仅被允许，而且受到鼓励。最终，学生需为其扩展作业所编写的代码进行答辩，具体细节如下。总体而言，部分参与者在整个实验课（3小时）内仍感吃力，而另一些人在15分钟内即告完成。通常，扩展任务规模较小，表现最佳的学生可在实验课早期完成并顺利通过答辩。扩展作业的更多细节见图2。任务 5.1 从 Exercise 类派生 CyclingExercise 类，并新增实例变量 distance（double 型）与 indoor（bool 型）。更新 main 函数，使 ExerciseTracker 实例至少包含三个新类的实例。\n\n图 2. 扩展作业示例。\n\n# 4.3.3. 作业答辩\n\n编程 II 的实验课采用严格且互动性强的答辩流程。助教将就最近一讲及其实践作业的相关主题，向每位学生提出若干基础问题。今年，我们在实践作业的答辩环节投入了额外精力。早在 ChatGPT 出现之前，学生间的抄袭已是问题；随着 ChatGPT 的普及，答辩必须更加细致。我们的答辩流程包括以下简明的提问与任务：\n\n概念性问题  \n通常要求参与者解释其程序代码的某些部分，重点考察面向对象概念。\n\n代码分析  \n通常要求参与者在代码中查找特定功能。\n\n代码修改问题  \n在程序的面向对象部分进行最小改动，以改变代码行为或改善代码结构。\n\n代码补全问题  \n演示如何在主程序中使用面向对象代码。\n\n答辩过程耗时颇多，但我们认为，这对于培养多种编程技能（如代码重构）及通用技能（如批判性思维）至关重要，尤其在 ChatGPT 时代。\n\n# 4.3.4. 纸质期中考试\n\n除 ChatGPT 外，还存在其他 LLM 工具，如 CoPilot [41–43]。为公平评估学生是否掌握编程 II 相关知识与技能，我们决定对所有参与者采用纸质期中考试。两组学生均不使用计算机或 IDE，从而确保两组成绩的可比性。\n\n# 4.4. 实验流程与数据收集工具\n\n实验于学期初进行背景问卷，随后每周布置实验作业并附带每周反馈问卷，期中举行两次纸质考试，学期末再进行最终反馈问卷。\n\n背景问卷旨在收集参与者的人口统计学信息（年龄、性别等），并衡量其先前对 $C++$ 语言、ChatGPT 的使用经验，以及对编程、人工智能等的兴趣。后一部分问题采用五点李克特量表 [44]，1 表示最低值，5 表示最高值。问卷共十题。第 5 节仅展示背景问卷中与实验最相关的部分问题。周次作业（在前几小节中已详细讨论）均配有每周反馈。反馈问卷发放给参与者，用于测量其对作业复杂度及 ChatGPT 使用情况的看法；其中后者尤其旨在回应我们对“分组依从性”的担忧，确保参与者仍严格遵循“有 ChatGPT 支持”与“无 ChatGPT 支持”的两组划分。\n\n期中考试题目并非理论性问答，而更接近实践作业，覆盖学期前半段（第一次期中考试）与后半段（第二次期中考试）所授的大部分主题。每场期中考试均包含一道编程题，通常要求给出某问题的面向对象结构，并撰写使用该结构的主程序。两次考试均为纸质笔试。\n\n反馈问卷测量了参与者对“编程 II”课程实验的总体看法。13 个问题可分为两类：课程反馈与实验反馈。首先，参与者需指出其对编程 II 作业的理解程度；问卷第二部分聚焦 ChatGPT（使用/未使用的一致性、使用目的等）。本文仅报告与主要研究结果最相关的部分统计量。背景问卷与反馈问卷的完整题项及答案见 https://github.com/tomazkosar/DifferentialStudyChatGPT（访问日期：2024 年 1 月 12 日）。\n\n# 4.5 研究假设\n\n本实验旨在验证/证伪三项假设：一项针对期中考试，一项针对实验作业，一项针对总评成绩。由此产生六种情形：\n\n- $H1_{\\mathrm{null}}$ 使用 ChatGPT 与不使用 ChatGPT 的参与者在实验作业得分上无显著差异。  \n- $H1_{\\mathrm{alt}}$ 使用 ChatGPT 与不使用 ChatGPT 的参与者在实验作业得分上存在显著差异。  \n- $H2_{\\mathrm{null}}$ 在实验作业阶段使用 ChatGPT 与否，对参与者期中考试成绩无显著影响。  \n- $H2_{\\mathrm{alt}}$ 在实验作业阶段使用 ChatGPT 与否，对参与者期中考试成绩存在显著影响。  \n- $H3_{\\mathrm{null}}$ 在实验作业阶段使用 ChatGPT 与否，对参与者最终总评成绩无显著影响。  \n- $H3_{\\mathrm{alt}}$ 在实验作业阶段使用 ChatGPT 与否，对参与者最终总评成绩存在显著影响。\n\n上述假设均经统计检验，结果见下一节。\n\n# 5 研究结果本节比较了在“编程 II”课程中使用 ChatGPT 的实验组（Group I）与未使用 ChatGPT 的对照组（Group II）的学习表现。为了阐明本次对照实验的结果，本节还报告了针对参与者背景及反馈问卷的调研结果；反馈研究的结论对两组样本量产生了影响。如反馈小节所述，我们从 Group II 中剔除了 8 名曾使用 ChatGPT 的学生，若将其纳入分析，将干扰实验结果并对研究效度构成威胁。\n\n所有观测值均以 $\\alpha = 0.05$ 作为显著性判定阈值进行统计检验 [45]。首先对所有数据实施 Shapiro-Wilk 正态性检验；若数据不服从正态分布，则采用非参数 Mann-Whitney 双独立样本检验；若数据服从正态分布，则采用参数独立样本 $t$ 检验。\n\n# 5.1 参与者背景\n\n背景问卷测量了参与者的人口统计学特征、先前经验及兴趣。学生平均年龄为 19.5 岁；性别分布方面，$85.9\\%$ 自认为是男性，$12.4\\%$ 为女性，$1.7\\%$ 不愿透露。\n\n本文仅展示参与者对 ChatGPT 知识掌握程度的组间比较。该题采用五点李克特量表，1 表示“知识很差”，5 表示“知识很好”。表 3 显示 Group I 与 Group II 之间无统计学显著差异；然而，参与者对自身 ChatGPT 知识的自信程度令我们惊讶（两组中位数均为 3）。背景调研于 2023 年 2 月实施，进一步印证了我们关于学生将在课程中使用 ChatGPT 的假设，因此该证据提示我们需对“编程 II”课程的实施作出相应调整。\n\n表 3 两组 ChatGPT 知识比较（Mann-Whitney 检验）\n\n<table><tr><td>组别</td><td>均值</td><td>N</td><td>标准差</td><td>中位数</td><td>平均秩</td><td>Z</td><td>p 值</td></tr><tr><td>Group I</td><td>2.97</td><td>89</td><td>1.08</td><td>3.00</td><td>84.79</td><td rowspan=\"2\">-1.145</td><td rowspan=\"2\">0.252</td></tr><tr><td>Group II</td><td>3.17</td><td>88</td><td>1.05</td><td>3.00</td><td>93.26</td></tr></table>\n\n# 5.2 结果比较表4 展示了两组在实验课中的表现结果。使用 ChatGPT 的 Group I 平均实验课成绩为 $65.27\\%$，而未使用 ChatGPT 的 Group II 平均成绩仅略高，为 $66.72\\%$。约 $66\\%$ 的成绩源于参与者仅完成必修任务；仅有少数学生选择完成选做任务。值得注意的是，必修与选做每周任务互为补充——通常选做任务涵盖进阶主题。表4 出人意料地显示，Group I 的实验课成绩反而更低，且与 Group II 相比并无统计学意义上的显著提升。因此，我们可得出结论：若在课程实施前采取适当措施，使用 LLM 并非决定性因素。这些结果将在“效度威胁”一节中进一步讨论，其中将阐述本对照实验的相关顾虑。\n\n表4. 两组实践课程成绩比较（Mann-Whitney 检验）\n\n| 组别   | 均值   | N   | 标准差 | 中位数 | 平均秩   | Z       | p 值   |\n|--------|--------|-----|--------|--------|----------|---------|--------|\n| Group I   | 65.27  | 93  | 26.11  | 63.00  | 92.67    | -0.306  | 0.760  |\n| Group II  | 66.72  | 89  | 19.71  | 63.00  | 90.28    |         |        |\n\n表5 比较了两组在期中考试中的成绩（百分比）。Group I（ChatGPT）与 Group II（无 ChatGPT）参加的是同一份试卷。由表5 可见，Group I 在第一次期中考试中的平均成绩（均值）略优于 Group II，但差异微小，且无统计学显著性。两组在第二次期中考试中的成绩均较第一次下降约 $10\\%$。我们认为，这与《程序设计 II》课程后半学期涉及的进阶主题有关；该现象每年均会出现。第二次期中考试中，结果与第一次相反——Group II（无 ChatGPT）以约 $2\\%$ 的优势优于实验组 Group I（ChatGPT）。然而，该差异同样未达到统计学显著水平。该结论亦适用于总体期中成绩（两次期中平均）——我们未能证实两组间存在统计学显著差异。不过，Group II（无 ChatGPT）的总体成绩仍略优于 Group I（$65.96\\%$ vs. $66.58\\%$）。实验前，我们曾假设 Group I 的成绩将显著低于 Group II，但该假设并未得到验证。如前所述，两组均参加了纸质期中考试。\n\n表5. 两组期中考试成绩比较（Mann-Whitney 检验）<table><tr><td>期中</td><td>部分</td><td>均值</td><td>N</td><td>标准差</td><td>中位数</td><td>平均秩</td><td>Z</td><td>p 值</td></tr><tr><td rowspan=\"2\">第一次</td><td>组 I</td><td>68.98</td><td>93</td><td>24.94</td><td>79.00</td><td>93.11</td><td rowspan=\"2\">-0.421</td><td rowspan=\"2\">0.674</td></tr><tr><td>组 II</td><td>67.89</td><td>89</td><td>23.66</td><td>74.00</td><td>89.82</td></tr><tr><td rowspan=\"2\">第二次</td><td>组 I</td><td>55.72</td><td>81</td><td>21.45</td><td>60.00</td><td>75.23</td><td rowspan=\"2\">-0.666</td><td rowspan=\"2\">0.505</td></tr><tr><td>组 II</td><td>58.12</td><td>73</td><td>21.17</td><td>60.00</td><td>80.02</td></tr><tr><td rowspan=\"2\">总体</td><td>组 I</td><td>65.96</td><td>81</td><td>18.29</td><td>71.00</td><td>76.88</td><td rowspan=\"2\">-0.181</td><td rowspan=\"2\">0.856</td></tr><tr><td>组 II</td><td>66.58</td><td>73</td><td>17.70</td><td>70.50</td><td>78.18</td></tr></table>\n\n对总体成绩的比较亦呈现类似结果。表 6 显示，组 I 的总体平均成绩为 $65.93\\%$，而组 II 略高，为 $66.61\\%$。需指出，总评成绩由 $50\\%$ 的期中考试与 $50\\%$ 的实践作业构成；学生完成额外任务可获得不超过 $5\\%$ 的附加分。Mann-Whitney 检验表明，两组在总体成绩上差异无统计学意义（见表 6）。\n\n表 6　两组课程最终成绩比较（Mann-Whitney 检验）\n\n<table><tr><td>部分</td><td>均值</td><td>N</td><td>标准差</td><td>中位数</td><td>平均秩</td><td>Z</td><td>p 值</td></tr><tr><td>组 I</td><td>65.93</td><td>93</td><td>25.14</td><td>68.00</td><td>92.82</td><td rowspan=\"2\">-0.345</td><td rowspan=\"2\">0.730</td></tr><tr><td>组 II</td><td>66.61</td><td>89</td><td>21.34</td><td>66.00</td><td>90.12</td></tr></table>\n\n上述结果（再次参见表 4–6）允许我们接受全部三项零假设，并确认在本研究中，ChatGPT 对期中考试、实践作业及最终成绩均无显著影响。\n\n# 5.3　反馈结果\n\n如第 4.4 节所述，学期最后一周，我们邀请参与者填写了一份关于课程及 ChatGPT 相关活动的问卷。期末学生反馈为理解前述结果提供了进一步依据。受试者可在家中作答（问卷发布于课程网页）；若其出席最后一周的实验课，则被鼓励在课前填写。值得注意的是，回收答卷数与参加期中考试的人数存在偏差（例如，I 组回收 69 份答卷，而参加第二次期中考试者共 81 人）。我们向受试者追加提醒，但部分仍未回应。缺失的反馈对应于退课且期末未出现在教室的学生。此为效度威胁之一，后文将进一步讨论。\n\n# 5.3.1 课程复杂度\n\n表 7 汇总了反馈问卷结果，反映了受试者对整门课程复杂度的看法。我们采用五点李克特量表，1 表示“复杂度低”，5 表示“复杂度高”。不出所料，结果显示 II 组（未使用 ChatGPT）的课程复杂度评分更高（3.01 vs. 3.17）。然而，Mann-Whitney 检验未呈现统计学显著差异（见表 7）。统计结果表明，两组受试者感知的课程复杂度相当。我们推测，课程复杂度评分的微小差异可能源于 ChatGPT 在帮助受试者理解课程内容方面所提供的支持。\n\n表 7 两组对课程复杂度的看法比较（Mann-Whitney 检验）\n\n<table><tr><td>组别</td><td>均值</td><td>样本量</td><td>标准差</td><td>中位数</td><td>平均秩</td><td>Z</td><td>p 值</td></tr><tr><td>I 组</td><td>3.01</td><td>69</td><td>0.80</td><td>3.00</td><td>63.45</td><td rowspan=\"2\">-1.205</td><td rowspan=\"2\">0.228</td></tr><tr><td>II 组</td><td>3.17</td><td>64</td><td>0.72</td><td>3.00</td><td>70.83</td></tr></table>\n\n# 5.3.2 学期内 ChatGPT 的使用情况——II 组\n\n尽管我们与学生约定分为两组——一组使用 ChatGPT，另一组不使用——但我们无法确定其是否遵守该约定。因此，我们每周询问两组学生是否使用 ChatGPT 及其使用目的。结果显示，两组大体遵循了我们的安排。\n\n然而，如图 3 所示，II 组部分学生未遵守指令，在几乎所有实践作业中均使用了 ChatGPT。我们决定将这 8 名学生从背景、研究与反馈结果中剔除，因其破坏了组间纯净性，纳入后将损害本节前述的统计结果。正因如此，II 组的有效样本量略小于 I 组。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/d9226962902af2c56ce210feb1a2f66c14874486e336e256f89415ed3e63cdac.jpg)  \n图 3 II 组中定期在实践作业中使用 ChatGPT 的受试者人数# 5.3.3 学期内 ChatGPT 的使用情况——Group I\n\n我们事先提醒 Group I，过度依赖 ChatGPT 可能导致纸质期中考试成绩下降。图 4 证实，大多数参与者采纳了我们的建议。\n\n引言部分提出的一个研究动机是：若明确允许使用 ChatGPT，学生是否会毫无顾虑地使用？图 4 显示，尽管 Group I 中有 69 名参与者被允许使用 ChatGPT，仅有 21 人报告在所有作业中均使用了该工具。该结果表明，学期前后采取的措施（如手写考试及课堂附加任务）可能影响了参与者不频繁使用 ChatGPT 的决定。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/2e925604e72d641b40a7123a3d5d969b61ee9b7ed7693b6dbb66de20ee96134b.jpg)  \n图 4. Group I 中定期在实践作业中使用 ChatGPT 的参与者人数。\n\n# 5.3.4 ChatGPT 对考试成绩的影响\n\n学期前我们担忧 ChatGPT 的使用会如何影响知识掌握与学生成绩。尽管存在顾虑，图 5 显示，Group I（ChatGPT 组）中仅 44 名参与者（占全部反馈的一半）认为其在实验作业中的使用带来了益处。据此，我们无法得出一致结论。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/99a65cba6f4daefb773f92f5f19821823841c5c5f59e2370e828647946f2c573.jpg)  \n图 5. ChatGPT 对课程成绩的积极影响（Group I）。\n\n# 5.3.5 使用方式\n\n软件工程师可将 ChatGPT 用于多种目的，如代码生成、优化、比较与解释。在课堂环境中，我们通过对实践作业的调整，尽可能减少代码生成行为。\n\n图 6 表明，上述调整达成了预期目标。Group I 的参与者更多地将 ChatGPT 用于代码优化及与自身代码的比较，而非直接生成代码。再次可见，学期前采取的具体措施确实影响了代码生成行为。值得注意的是，图 6 基于多选题结果——参与者可从多个选项中选择一个或多个答案。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/b7d445ac9b19849a5d35c11241fe63fc7a58350bd27c65a2b2a60d5bab845edb.jpg)  \n图 6. ChatGPT 的使用目的（Group I）。\n\n# 5.3.6 代码可读性\n\n我们亦关注参与者对 ChatGPT 所提供编程代码的满意度。因此，Group I（ChatGPT 组）就所获代码的可读性回答了相关问题。同样，本问题仍采用五点李克特量表，1 表示“完全无法理解”，5 表示“非常易于理解”。由图 7 可见，Group I 的参与者普遍认为来自 ChatGPT 的代码易于理解，大多数受访者选择了“易于理解”或“非常易于理解”（图 7 中的 4 分或 5 分）。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/44b0fd14559cf672e2f8f53ad2a814ab50075e6e5b1077ff07fa0e5ac38281a9.jpg)  \n图 7. Group I 对 ChatGPT 所生成代码的可理解性评价。\n\n# 5.3.7 非编程场景下学生对 ChatGPT 的接受度\n\n我们进一步探究 ChatGPT 在编程辅助之外是否被学生广泛接受。自 2022 年 11 月发布至 2023 年 6 月，已有 $70\\%$ 的学生表示会定期使用。参与者频繁提及的功能包括解释、指导、理解、示例等。图 8 的词云还展示了一些颇具新意的用途（如生活、生成、摘要），既有学习相关（theory、algorithms、concepts、code、syntax 等），也有通用场景（search、every day、everywhere 等）。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/0ee72b487b8c3432b16cd5243d16245b6902202508f0d6ad6a76d23d7692f9a9.jpg)  \n图 8. ChatGPT 在编程之外的使用场景。\n\n# 5.3.8 ChatGPT 在未来编程中的使用意向\n\n最后一题询问参与者未来是否愿意继续使用 ChatGPT 进行编程。如图 9 所示，Group I 的大多数回答呈积极态度。为理解图 9 所呈现的高采纳信心，有必要将其置于更广泛的背景中，并与图 6 和图 7 的洞见关联。图 6 表明，计算机科学学生将 ChatGPT 用于多元自助场景，不仅限于代码优化与对比，还涵盖其他用途（图 6 中显著比例的“other”选项可佐证）。此外，图 7 进一步凸显了生成代码的极高可读性。我们认为，上述因素共同促成了显著比例的学生表达未来持续使用 ChatGPT 的强烈意愿。\n\n对比图 4 与图 9 可见，我们对实验作业所做的针对性调整取得了成效：尽管学生乐于将 ChatGPT 作为编程辅助工具（图 9），但在我们设定的具体实验环境中，其实际使用频率低于预期（图 4）。\n\n![](/uploads/images/be719944-4291-4fae-bb3f-988e09fa236b/9adf999d07e4cf9d9d9f73f91b9f1ac0e80e28a226ccf5487e274ac91b8ea999.jpg)  \n图 9. 未来编程中使用 ChatGPT 的意愿。\n\n# 6 效度威胁\n\n本节讨论本对照实验在构念效度、内部效度与外部效度方面存在的威胁 [46]。\n\n# 6.1 构念效度构念效度（construct validity）衡量的是我们对所关注概念的测量程度 [47,48]。在本实验中，我们旨在测量 ChatGPT 对“编程 II”课程成绩的影响。\n\n我们设计了若干作业，要求参与者理解问题描述并提供 $\\mathrm{C + + }$ 代码实现。鉴于 ChatGPT 可用，我们对作业定义进行了调整。这些调整使作业类型多样化（新增或扩展），并提供代码、输入/输出、给定的主程序等。在可能的情况下，还提供了图示。参与者需提交完整实现。因此，在实验课环节中向参与者提供了额外功能。特定作业的选择、实验课中提供的附加功能或评估方式可能对结果产生影响。然而，我们尚无证据表明该威胁存在。\n\n作业的复杂性可能构成另一项效度威胁。共有 22 个作业，其中 11 个为必修。我们从简单的面向对象问题开始：前几个作业仅包含一个类；随后的必修作业引入了聚合；再下一个必修作业涉及继承等。这些作业从简单问题起步，并在学期内逐步加深。学期末的实践作业甚至包含十个或更多类。尚不明确若所有作业复杂度相同，我们的结论是否仍然成立，也不清楚编程任务的复杂度如何影响 ChatGPT 对第一组参与者的辅助效果。诚然，单个作业所包含的类数量仅是复杂度的一个指标；控制流以及代码中的编程构造等因素亦需考虑。然而，总体而言，参与者在学期末完成实践作业所需时间远多于学期初。\n\n我们的期中考试旨在通过实践作业检验理论知识。因此，期中考试与考试前刚刚布置给参与者的实践作业相近。从构念效度角度看，若期中考试直接采用理论题，我们将无法得知结果。\n\n另一项构念效度关注点在于课程所选编程语言：编程语言如何影响 ChatGPT 生成结果以及所测得的 ChatGPT 影响。若能以另一种编程语言（如 Python）对一年级学生进行重复研究 [49,50]，将颇具意义。尽管 ChatGPT 是当前大语言模型（LLM）中的佼佼者，但替代模型亦已出现（例如 Claude）。我们每周的反馈问卷并未涉及其他 LLM 的使用情况，因此本研究的结论仅限于 ChatGPT。此外，尽管我们推荐参与者使用 GPT-3.5，但部分学生可能在实验期间自行获取了实验过程中发布的 GPT-4；我们既未在实验设计中，也未在反馈问卷中对该变量加以控制或询问。因此，我们无法确保 Group I 中的某些学生未借助 GPT-4，从而可能对实验结果——尤其是在涉及 UML 类图的实践作业中——产生有利影响。\n\n在本实验中，我们并未将 ChatGPT 对 Group II 参与者的影响进行隔离。整个学期期间，Group II 的参与者均可使用其他辅助资源。鉴于其他在线资源可能产生的替代效应，两组之间观察到的差异未必能精确反映 ChatGPT 访问权限的独特影响。需要指出的是，这些替代资源对 Group I 的参与者同样开放；因此，两组之间唯一的区分因素在于 Group I 明确允许使用 ChatGPT。\n\nGroup I 参与者对 ChatGPT 的使用频率较低（见图 4），部分原因可能在于期中考试采用纸质形式。此外，使用频率低可能导致学生未能充分熟悉如何高效利用 ChatGPT，从而削弱了实验组与对照组之间的差异。尽管这些因素可能被视为对构念效度（construct validity）的威胁，但它们与我们的研究目标一致：即在“是否应鼓励/劝阻未来 Programming II 课程学生使用 ChatGPT 及类似 LLM”这一问题上收集实证证据。在我们看来，允许 Group I 的参与者在遇到挑战或学习新概念时自主决定是否借助 LLM——而非强制该组所有学生频繁使用 ChatGPT——更符合真实课堂情境。我们的结果支持在后续 Programming II 课程中，若评估形式保持不变或相似，可允许并促进 LLM 的使用。\n\n# 6.2 内部效度\n\n内部效度指我们对“所检验的关系未受到其他混淆或偶然因素干扰”的信心程度。\n\n存在 Group II 参与者亦使用 ChatGPT 的潜在风险。为应对此威胁，我们要求参与者每周报告其 ChatGPT 使用情况，并在期末反馈问卷中再次确认。对比期末报告与每周报告，未发现显著差异。因此，本文仅呈现期末反馈中关于 ChatGPT 使用的数据（再次参见图 3），并如第 5 节所述，将报告使用过 ChatGPT 的 8 名 Group II 参与者从统计结果中剔除。部分参与者也对期中考试采用纸质形式而非计算机完成表示不满。他们缺失 IDE 所提供的基本工具，例如代码自动补全、语法高亮以及代码生成（构造函数、set/get 方法）等功能，而这些功能通常在 CLion 等 IDE 中可用；CLion 是本课程 Programming II 实验环境所推荐的 IDE。我们之所以选择离线方式，主要基于两点考虑：第一，本次对照实验的对象为一年级学生，其中部分学生仅在前几个月才开始接触编程，因此我们不希望其使用 Copilot 或其他类似的 AI 代码生成工具；第二，与他们对 IDE 的熟悉程度有关。我们旨在衡量参与者对面向对象代码的理解与编写能力，并尽可能避免其 IDE 使用经验对结果产生干扰。\n\n反馈研究为期末的可选作业。部分参与者未在本课程的在线学习平台填写问卷（182 人中缺 49 人）。缺失的反馈构成选择偏差威胁，因其对整体反馈的影响未知。然而，由于缺失比例仅占全部参与者的 $27\\%$，该缺失对本对照实验效度的威胁并不严重。\n\n另一项内部效度威胁源于未向学生提供关于高效使用 ChatGPT 的培训。倘若学生在接受培训的前提下使用该工具，Group I 的学习成效可能有所不同，进而导致研究结果出现差异。值得指出的是，新手程序员常因对大型语言模型概念缺乏理解而在撰写提示（prompt）时遇到困难。这一局限凸显了系统培训的重要性，以提升学生有效使用 ChatGPT 的能力并发挥其最大潜能；对于开展 ChatGPT 的实证研究亦是如此。\n\n# 6.3 外部效度\n\n外部效度考察实验结果能否推广至其他情境。\n\n由于本实验仅招募一年级学生，因此存在外部效度威胁：结果能否推广至其他年级的学生尚不可知。需要再次强调，本实证研究关注的是新手程序员。\n\n另一项外部效度威胁在于研究结果能否推广至其他课程——若将该实验置于同学年内的其他课程，其结果是否一致尚不明确。\n\n本研究表明，ChatGPT 的使用在期中考试成绩与实践作业成绩上均未产生统计学显著差异。未来可进一步探究……对于修读“编程 II”的不同学生子群体（例如已具备丰富编程经验者，或曾修过特定课程者），结论可能存在差异。\n\n本研究的结果源于在单一高校开展的实验，因而其可推广性需谨慎考量。我们的结论可能受到人口统计特征、文化差异以及院校规模（尤其是计算机科学专业学生数量）等因素的影响。为缓解此局限，我们公开实验数据并鼓励后续复现。开展多院校、跨国研究可更全面地理解 ChatGPT 对计算机科学教育中新手程序员学习体验的影响，从而获得更精确且稳健的结果。\n\n# 7 结论\n\nChatGPT 已被证明在诸多场景中颇具价值，例如提供即时反馈与解释。然而，不少质疑者强调，ChatGPT 不应在课堂中取代学习与理解。当教育过程出现变革性、颠覆性技术时，我们必须交流观点与经验。本研究正是受此高层次目标驱动。\n\n本文报告了一项对照实验，分析在计算机科学课程的实践作业中使用 ChatGPT 是否会影响学习成效。我们将一年级学生分为两组：一组被鼓励使用 ChatGPT，另一组则被劝阻。实验针对实验课成绩、期中考试成绩及总体表现等常见假设进行了评估。\n\n主要发现如下：\n\n- 比较使用与未使用 ChatGPT 的两组在实践作业中的表现，结果显示差异无统计学意义（再次参见表 4）。\n- 我们在设计作业与实验课时，已尽量降低 ChatGPT 使学生“盲目复制、缺乏学习”的可能性。结果证实，我们的设计达到了预期效果。\n- 比较两组在期中考试中的表现，结果同样无统计学差异（再次参见表 5）。\n- 尽管实验组（Group I）使用了 ChatGPT，我们的调整可能使该组在学习上投入了足够努力，因此其成绩与劝阻使用 ChatGPT 的对照组相当。\n- 比较两组在“编程 II”课程中的总体表现，结果亦无统计学差异（再次参见表 6）。\n\n这意味着，在我们特定的课程实施方案（含所有调整措施）下，可将 ChatGPT 作为额外的学习辅助工具使用。我们的研究结果还表明，参与者认为 ChatGPT 对最终成绩产生了积极影响（图 5），然而实验数据并未在实验作业（表 4）、期中考试（表 5）以及最终学业表现（表 6）中验证这一观点。与此同时，参与者报告了积极的学习体验（例如程序理解；见图 7）。此外，我们发现 ChatGPT 被用于多种目的（代码优化、对比等，详见图 6）。参与者强烈表示，他们极有可能继续使用 ChatGPT（图 9）。\n\n# 未来工作\n\n本研究所提出的结果以及面向 ChatGPT 的教学调整在未来应用时需谨慎对待。随着大语言模型的持续改进，相关调整（尤其是针对实践作业的部分）可能会受到影响。ChatGPT 不断演进的特性将促使我们根据当前人工智能技术的发展状态对教学策略进行动态调整。面向 ChatGPT 的调整可能迅速失去适用性，因此需要定期更新与重新评估，以保持其稳健性与实用性。我们特别强调作业答辩及与学生伴随讨论的重要性。在那些未将互动式作业答辩作为核心评价方式的课程中，引入 ChatGPT 需经过审慎考量。例如，若助教仅检验学生提交代码的正确性而缺乏任何互动沟通，则评估结果可能产生偏差。\n\n本研究尚需进一步复制验证 [38,49]。可通过更换不同问题（应用场景）及编程语言等方式强化实验作业，以提升结论的外部效度。此外，我们还需比较在集成开发环境（IDE）支持下期中考试的结果，探讨开发工具的使用如何影响期中考试成绩。我们亦计划将本实验设计与具体调整应用于计算机科学专业导论编程课程（CS1），鉴于 ChatGPT 在基础编程概念讲解与解决方案提供方面表现良好。为理解学生所获得的关键能力（批判性思维、问题解决与团队协作能力）[19]，尚需开展实证研究，以评估其对未来计算机科学工程师的潜在影响。如“效度威胁”一节所述，通过在复制研究中拓展视角、纳入更多院校并开展多机构、跨国研究，有望更深入地理解大语言模型在教育中的整合方式，从而获得比本研究更为精确且稳健的结论。我们未来面向学生与 ChatGPT 的实证研究，应着力弥补传统绩效比较指标（本研究亦采用）之局限。若能引入质性评估，或可深入揭示由人工智能技术驱动的认知投入与教学互动之机理，从而更全面地理解其对教与学过程之影响。\n\n除上述研究方向外，人工智能融入教学流程尚有多重议题亟待探究。首要者，需深入剖析将 ChatGPT 引入教育情境所潜藏之风险：生成数据之潜在不可靠性、学生对技术之依赖，以及其对学生认知能力与人际沟通技能之可能影响。系统梳理上述风险，可为教育工作者提供关于人工智能教学应用之挑战与限度的重要参考。另一方面，ChatGPT 之积极效应亦值得深究。未来若设计实验以检验大型语言模型之教育潜能，或可获取关乎其整体学习效应之关键洞见。然其益处不仅惠及学生，亦应关注教师群体：借助该技术，教师可自动化诸多繁琐事务，如命题、学业表现监测、报告生成等；ChatGPT 亦可充当数字助教，协助生成补充示例与可视化教具。厘清教师如何运用此类正向功能，可为优化 ChatGPT 于教育场景之角色提供依据。此外，未来研究尚须正视 ChatGPT 在答疑环节之局限。考察学生面对 ChatGPT 答非所问时之反应，有助于理解其在学习情境中对人工智能之感知与体验，进而指导干预措施之设计，以支持学生与 ChatGPT 之互动，并缓解其可能遭遇之挫败或困境。上述议题及其他相关主题，对教育界极具现实意义，值得深入探析。\n\n作者贡献：概念构思，T.K.；方法设计，T.K.；软件开发，T.K. 与 D.O.；验证工作，M.M. 与 Y.D.L.；调查研究，T.K.、D.O.、M.M. 与 Y.D.L.；初稿撰写，T.K.、D.O.、M.M. 与 Y.D.L.；审阅与润色，T.K.、D.O.、M.M. 与 Y.D.L.。所有作者均已阅读并同意稿件之最终发表版本。资助：第一、第二与第四位作者感谢斯洛文尼亚研究机构（研究核心资助编号 P2-0041）的经费支持。第三位作者感谢富布赖特学者计划（Fulbright Scholar Program）的经费支持。\n\n机构伦理审查声明：本研究无需伦理审查与批准，因为测试以期中考试的形式进行。\n\n知情同意声明：已获得所有参与研究对象的知情同意。\n\n数据可用性声明：本研究中所呈现的数据可在 https://github.com/tomazkosar/DifferentialStudyChatGPT 获取，访问日期为 2024 年 1 月 12 日。\n\n致谢：作者感谢马里博尔大学电气工程与计算机科学学院编程方法学实验室全体同仁，在受控实验执行过程中提供的帮助与富有成效的讨论。\n\n利益冲突：作者声明不存在任何利益冲突。\n\n# 参考文献1. Stokel-Walker, C.; Van Noorden, R. ChatGPT 与生成式人工智能对科学的启示. Nature 2023, 614, 214-216. [CrossRef]  \n2. MacNeil, S.; Tran, A.; Mogil, D.; Bernstein, S.; Ross, E.; Huang, Z. 利用 GPT-3 大语言模型生成多样化代码解释. 见《2022 ACM 国际计算教育研究会议论文集》, 线上, 2022年8月7–11日; 第2卷, 第37–39页.  \n3. Radford, A.; Narasimhan, K.; Salimans, T.; Sutskever, I. 通过生成式预训练提升语言理解. 2018. 在线获取: https://www.mikecaptain.com/resources/pdf/GPT-1.pdf (2023年9月24日访问).  \n4. OpenAI. ChatGPT. 2023. 在线获取: https://chat.openai.com/ (2023年9月24日访问).  \n5. Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pinto, H.P.d.O.; Kaplan, J.; Edwards, H.; Burda, Y.; Joseph, N.; Brockman, G.; 等. 评估基于代码训练的大语言模型. arXiv 2021, arXiv:2107.03374.  \n6. Tian, H.; Lu, W.; Li, T.O.; Tang, X.; Cheung, S.C.; Klein, J.; Bissyandé, T.F. ChatGPT 是终极编程助手吗——差距几何？arXiv 2023, arXiv:2304.11938.  \n7. Rahman, M.M.; Watanobe, Y. ChatGPT 在教育与研究中的机遇、威胁与策略. Appl. Sci. 2023, 13, 5783. [CrossRef]  \n8. Shoufan, A. 探索学生对 ChatGPT 的认知：主题分析与后续调查. IEEE Access 2023, 11, 38805-38818. [CrossRef]  \n9. Muñoz, S.A.S.; Gayoso, G.G.; Huambo, A.C.; Tapia, R.D.C.; Incaluque, J.L.; Aguila, O.E.P.; Cajamarca, J.C.R.; Acevedo, J.E.R.; Rivera, H.V.H.; Arias-González, J.L. 审视 ChatGPT 对学生动机与参与度的影响. Soc. Space 2023, 23, 1-27.  \n10. Qureshi, B. 探索 ChatGPT 作为本科计算机科学课程学习与评估工具的机遇与挑战. arXiv 2023, arXiv:2304.11214.  \n11. Milano, S.; McGrane, J.A.; Leonelli, S. 大语言模型对高等教育未来的挑战. Nat. Mach. Intell. 2023, 5, 333-334. [CrossRef]  \n12. Dempere, J.; Modugu, K.; Hesham, A.; Ramasamy, L.K. ChatGPT 对高等教育的影响. Front. Educ. 2023, 8, 1206936. [CrossRef]  \n13. DeFranco, J.F.; Kshetri, N.; Voas, J. 我们究竟在为机器人还是人类写作？Computer 2023, 56, 13-14. [CrossRef]  \n14. Cao, J.; Li, M.; Wen, M.; Cheung, S.C. 关于 ChatGPT 在深度学习程序修复中的提示设计、优势与局限性的研究. arXiv 2023, arXiv:2304.08191.  \n15. Qin, C.; Zhang, A.; Zhang, Z.; Chen, J.; Yasunaga, M.; Yang, D. ChatGPT 是通用自然语言处理任务求解器吗？arXiv 2023, arXiv:2302.06476.  \n16. Dwivedi, Y.K.; Kshetri, N.; Hughes, L.; Slade, E.L.; Jeyaraj, A.; Kar, A.K.; Baabdullah, A.M.; Koohang, A.; Raghavan, V.; Ahuja, M.; 等. “就算 ChatGPT 写的又怎样？” 生成式对话 AI 在研究、实践与政策中的机遇、挑战与影响的多学科视角. Int. J. Inf. Manag. 2023, 71, 102642. [CrossRef]  \n17. Winslow, L.E. 编程教学法——心理学视角. ACM SIGCSE Bull. 1996, 28, 17-22. [CrossRef]  \n18. Lukpat, A. 因作弊与学习发展担忧，纽约市公立学校禁用 ChatGPT. 2023. 在线获取: https://www.wsj.com/articles/chatgpt-banned-in-new-york-city-public-schools-over-concerns-about-cheating-learning-development-11673024059 (2023年9月24日访问).  \n19. Sánchez-Ruiz, L.M.; Moll-López, S.; Nuñez-Pérez, A.; Morán-Fernández, J.A.; Vega-Fleitas, E. ChatGPT 对工程教育混合式学习方法的挑战：数学案例研究. Appl. Sci. 2023, 13, 6039. [CrossRef]  \n20. Susnjak, T. ChatGPT：在线考试诚信的终结？arXiv 2022, arXiv:2212.09292.  \n21. Yilmaz, R.; Yilmaz, F.G.K. 编程学习中的增强智能：考察学生对使用 ChatGPT 学习编程的观点. Comput. Hum. Behav. Artif. Hum. 2023, 1, 100005. [CrossRef]22. Geng, C.; Yihan, Z.; Pientka, B.; Si, X. ChatGPT 能否通过初级函数式语言编程课程？arXiv 2023, arXiv:2305.02230.  \n23. Shoufan, A. 无先验知识的学生能否利用 ChatGPT 回答测试题？一项实证研究。ACM Trans. Comput. Educ. 2023, 23, 45. [CrossRef]  \n24. King, M.R.; ChatGPT. 关于人工智能、聊天机器人与高等教育中剽窃问题的对话。Cell. Mol. Bioeng. 2023, 16, 1-2. [CrossRef]  \n25. Wohlin, C.; Runeson, P.; Höst, M.; Ohlsson, M.C.; Regnell, B.; Wesslen, A. 软件工程实验方法；Springer Science & Business Media: Berlin/Heidelberg, Germany, 2012.  \n26. Chowdhary, K.R. 自然语言处理。载于《人工智能基础》；Springer: New Delhi, India, 2020；pp. 603-649.  \n27. King, M.R. 医学中人工智能的未来：来自聊天机器人的视角。Ann. Biomed. Eng. 2023, 51, 291-295. [CrossRef]  \n28. Floridi, L.; Chiriatti, M. GPT-3：其本质、范围、局限与影响。Minds Mach. 2020, 30, 681–694. [CrossRef]  \n29. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.N.; Kaiser, L.; Polosukhin, I. Attention is all you need. Adv. Neural Inf. Process. Syst. 2017, 30, 5998-6008.  \n30. Adamopoulou, E.; Moussiades, L. 聊天机器人：历史、技术与应用。Mach. Learn. Appl. 2020, 2, 100006. [CrossRef]  \n31. Jeon, J.; Lee, S.; Choe, H. 超越 ChatGPT：面向语言学习的语音识别聊天机器人概念框架与系统综述。Comput. Educ. 2023, 206, 104898. [CrossRef]  \n32. Hughes, A. ChatGPT：关于 OpenAI 的 GPT-4 工具您需要了解的一切。2023。在线获取：https://www.sciencefocus.com/future-technology/gpt-3（访问日期：2023 年 9 月 26 日）。  \n33. White, J.; Fu, Q.; Hays, S.; Sandborn, M.; Olea, C.; Gilbert, H.; Elnashar, A.; Spencer-Smith, J.; Schmidt, D.C. 用于提升 ChatGPT 提示工程的提示模式目录。arXiv 2023, arXiv:2302.11382.  \n34. White, J.; Hays, S.; Fu, Q.; Spencer-Smith, J.; Schmidt, D.C. 用于改进代码质量、重构、需求获取与软件设计的 ChatGPT 提示模式。arXiv 2023, arXiv:2303.07839.  \n35. Giner-Miguelez, J.; Gomez, A.; Cabot, J. 一种用于描述机器学习数据集的领域特定语言。J. Comput. Lang. 2023, 76, 101209. [CrossRef]  \n36. de la Vega, A.; García-Saiz, D.; Zorrilla, M.; Sánchez, P. Lavoisier：一种用于提升数据挖掘中数据选择与格式化抽象水平的 DSL。J. Comput. Lang. 2020, 60, 100987. [CrossRef]  \n37. Kasneci, E.; Sessler, K.; Kuchemann, S.; Bannert, M.; Dementieva, D.; Fischer, F.; Gasser, U.; Groh, G.; Gunnemann, S.; Hüllermeier, E.; 等。ChatGPT 能否向善？大型语言模型在教育中的机遇与挑战。Learn. Individ. Differ. 2023, 103, 102274. [CrossRef]  \n38. Kosar, T.; Gaberc, S.; Carver, J.C.; Mernik, M. 领域特定语言与通用语言的程序理解：在集成开发环境中复制一组实验。Empir. Softw. Eng. 2018, 23, 2734-2763. [CrossRef]  \n39. Sonnleitner, P.; Brunner, M.; Greiff, S.; Funke, J.; Keller, U.; Martin, R.; Hazotte, C.; Mayer, H.; Latour, T. The Genetics Lab：用于评估复杂问题解决能力的计算机化微世界的接受度与心理测量特征。Psychol. Test Assess. Model. 2012, 54, 54-72.  \n40. Ouh, E.L.; Gan, B.K.S.; Shim, K.J.; Wlodkowski, S. ChatGPT，你能为我的编程练习生成解答吗？在本科 Java 编程课程中对其有效性的评估。arXiv 2023, arXiv:2305.13680.  \n41. Moradi Dakhel, A.; Majdinasab, V.; Nikanjam, A.; Khomh, F.; Desmarais, M.C.; Jiang, Z49. Shull, F.J.; Carver, J.C.; Vegas, S.; Juristo, N. 复现在实证软件工程中的作用. Empir. Softw. Eng. 2008, 13, 211-218. [CrossRef]  \n50. Carver, J.C. 面向实验复现的报告指南：一项提案. 见：第一届实证软件工程复现国际研讨会论文集，南非开普敦，2010年5月2–8日；第1–4页。\n\n免责声明/出版方声明：所有出版物中的陈述、观点与数据均完全由相应作者与贡献者个人负责，不代表MDPI及/或编辑部的立场。MDPI及/或编辑部对因文中提及的任何观点、方法、说明或产品而导致的人身或财产损害不承担任何责任。",
    "is_translated": true
  },
  "4b50e85d-a04b-4275-9800-d5ab160e071a": {
    "id": "4b50e85d-a04b-4275-9800-d5ab160e071a",
    "filename": "2512.02038v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/4b50e85d-a04b-4275-9800-d5ab160e071a_2512.02038v1.pdf",
    "status": "completed",
    "created_at": "2025-12-18 17:11:22.145573",
    "updated_at": "2025-12-18 09:14:03.916175",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Deep Research: A Systematic Survey",
    "markdown_content": "# Deep Research: A Systematic Survey\n\nZhengliang Shi $^{1}$  Yiqun Chen $^{2}$  Haitao Li $^{3}$  Weiwei Sun $^{4}$  Shiyu Ni $^{5}$  Yougang Lyu $^{6}$  Run-Ze Fan $^{7}$  Bowen Jin $^{8}$  Yixuan Weng $^{9}$  Minjun Zhu $^{9}$  Qiujie Xie $^{9}$  Xinyu Guo $^{10}$  Qu Yang $^{11}$  Jiayi Wu $^{11}$  Jujia Zhao $^{12}$  Xiaqiang Tang $^{11}$  Xinbei Ma $^{11}$  Cunxiang Wang $^{3}$  Jiaxin Mao $^{2}$  Qingyao Ai $^{3}$  Jen-Tse Huang $^{13}$  Wenxuan Wang $^{2}$  Yue Zhang $^{9}$  Yiming Yang $^{4}$  Zhaopeng Tu $^{11, \\text{双}}$  Zhaochun Ren $^{12, \\text{双}}$\n\n$^{1}$ Shandong University  $^{2}$ Renmin University of China  $^{3}$ Tsinghua University  $^{4}$ Carnegie Mellon University  $^{5}$ UCAS  $^{6}$ University of Amsterdam\n\n<sup>7</sup>University of Massachusetts Amherst <sup>8</sup>University of Illinois Urbana-Champaign <sup>9</sup>Westlake University <sup>10</sup>University of Arizona <sup>11</sup>Tencent <sup>12</sup>Leiden University <sup>13</sup>Johns Hopkins University\n\nAbstract: Large language models (LLMs) have rapidly evolved from text generators into powerful problem solvers. Yet, many open tasks demand critical thinking, multi-source, and verifiable outputs, which are beyond single-shot prompting or standard retrieval-augmented generation. Recently, numerous studies have explored Deep Research (DR), which aims to combine the reasoning capabilities of LLMs with external tools, such as search engines, thereby empowering LLMs to act as research agents capable of completing complex, open-ended tasks. This survey presents a comprehensive and systematic overview of deep research systems, including a clear roadmap, foundational components, practical implementation techniques, important challenges, and future directions. Specifically, our main contributions are as follows: (i) we formalize a three-stage roadmap and distinguish deep research from related paradigms; (ii) we introduce four key components: query planning, information acquisition, memory management, and answer generation, each paired with fine-grained sub-taxonomies; (iii) we summarize optimization techniques, including prompting, supervised fine-tuning, and agentic reinforcement learning; and (iv) we consolidate evaluation criteria and open challenges, aiming to guide and facilitate future development. As the field of deep research continues to evolve rapidly, we are committed to continuously updating this survey to reflect the latest progress in this area.\n\n$\\mathbf{\\bar{X}}$  Corresponding Author\n\nKeywords: Deep Research, Large Language Models, Information Retrieval\n\nDate: November 13, 2025\n\nCode Repository: https://github.com/mangopy/Deep-Research-Survey\n\n$\\mathbb{E}$  Contact: zhengliang.shii@gmail.com chenyiqun990321@ruc.edu.cn z. ren@liacs.leidenuniv.nl\n\n# Contents\n\n1 Introduction 5  \n2 Preliminary Concept of Deep Research 6\n\n2.1 What is Deep Research 6  \n2.2 Understanding Deep Research from Three Phases 6  \n2.3 Comparing Deep Research with RAG 9\n\n3 Key Components in Deep Research System 9\n\n3.1 Query Planning 9\n\n3.1.1 Parallel Planning 10  \n3.1.2 Sequential Planning 11  \n3.1.3 Tree-based Planning 12\n\n3.2 Information Acquisition 13\n\n3.2.1 Retrieval Tools 13  \n3.2.2 Retrieval Timing 14  \n3.2.3 Information Filtering 17\n\n3.3 Memory Management 19\n\n3.3.1 Memory Consolidation 20  \n3.3.2 Memory Indexing 21  \n3.3.3 Memory Updating 21  \n3.3.4 Memory Forgetting 23\n\n3.4 Answer Generation 24\n\n3.4.1 Integrating Upstream Information 24  \n3.4.2 Synthesizing Evidence and Maintaining Coherence 25  \n3.4.3 Structuring Reasoning and Narrative 26  \n3.4.4 Presentation Generation 27\n\n4 Practical Techniques for Optimizing Deep Research Systems 27\n\n4.1 Workflow Prompt Engineering 28  \n4.1.1 Deep Research System of Anthropic 28  \n4.2 Supervised Fine-Tuning 29\n\n4.2.1 Strong-to-weak Distillation 29  \n4.2.2 Iterative Self-Evolving 30\n\n# 4.3 End-to-End Agentic Reinforcement Learning 31\n\n4.3.1 Preliminary 31  \n4.3.2 End-to-end Optimization of a Specific Module 33  \n4.3.3 End-to-end Optimization of an Entire Pipeline 34\n\n# 5 Evaluation of Deep Research System 36\n\n# 5.1 Agentic Information Seeking 36\n\n5.1.1 Complex Queries 36  \n5.1.2 Interaction Environment 38\n\n# 5.2 Comprehensive Report Generation 39\n\n5.2.1 Survey Generation 39  \n5.2.2 Long-Form Report Generation 39  \n5.2.3 Poster Generation 40  \n5.2.4 Slides Generation 40\n\n# 5.3 AI for Research 41\n\n5.3.1 Idea Generation 41  \n5.3.2 Experimental Execution 41  \n5.3.3 Academic Writing 42  \n5.3.4 Peer Review 42\n\n# 5.4 Software Engineering 43\n\n# 6 Challenges and Outlook 43\n\n# 6.1 Retrieval Timing 43\n\n# 6.2 Memory Evolution 43\n\n6.2.1 Proactive Personalization Memory Evolution 44  \n6.2.2 Cognitive-Inspired Structured Memory Evolution 44  \n6.2.3 Goal-Driven Reinforced Memory Evolution 45\n\n# 6.3 Instability in Training Algorithms 45\n\n6.3.1 Existing Solutions 46  \n6.3.2 Future Directions 46\n\n# 6.4 Evaluation of Deep Research System 46\n\n6.4.1 Logical Evaluation 47  \n6.4.2 Boundary between Novelty and Hallucination 47  \n6.4.3 Bias and Efficiency of LLM-as-Judge 48\n\n# 7 Open Discussion: Deep Research to General Intelligence 48\n\n7.1 Creativity 48  \n7.2 Fairness 49  \n7.3 Safety and Reliability 49\n\n# 8 Conclusion and Future Outlook 49\n\n# 1. Introduction\n\nLarge language models (LLMs), trained on web-scale corpora, have rapidly evolved from fluent text generators into autonomous agents capable of long-horizon reasoning in practical complex applications [224, 83, 465, 288]. They have exhibited strong generalization across diverse domains, including mathematical reasoning [112, 466], creative writing [95], and practical software engineering [118, 140, 166]. Many real-world tasks are inherently open-ended, involving critical thinking, factually grounded information, and the production of self-contained responses. This is far beyond what single-shot prompting or static parametric knowledge can provide [122, 183, 289]. To address this gap, the Deep Research (DR) paradigm [237, 97, 66, 481, 125, 202] has emerged. DR frames LLMs within an end-to-end research workflow that iteratively decomposes complex problems, acquire evidence via tool use, and synthesizes validated insights into coherent long-form answers.\n\nDespite rapid progress, there remains no comprehensive survey that systematically analyzes the key components, technical details, and open challenges of DR. Most existing work [458, 31] mainly summarizes developments in related areas such as Retrieval-Augmented Generation (RAG) and web-based agents [401, 200, 285, 456, 316]. However, in contrast to RAG [89, 72], DR adopts a more flexible, autonomous workflow that eschews handcrafted pipelines and aims to produce coherent, evidence-grounded reports. Therefore, a clear overview of its technical landscape is urgent but remains a challenge. This survey fills this gap by providing a comprehensive synthesis of DR: mapping its core components to representative system implementations, consolidating key techniques and evaluation methodologies, and establishing a foundation for consistent benchmarking and sustained progress in AI-driven research.\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/00a79b85f8e1862e58c4784de6c963180a67493b21e2fa4916b4cc8e54a699c1.jpg)  \nFigure 1: An overview of four key components in a general deep research system, including: Task Planning (Section 3.1). Information Acquisition (Section 3.2). Memory Management (Section 3.3) and Answer Generation (Section 3.4).\n\nIn this survey, we propose a three-stage roadmap for DR systems, illustrating their broad applications ranging from agentic information seeking to autonomous scientific discovery. Based on the roadmap, we summarize the key components of the task-solving workflow for the most commonly used DR systems. Specifically, we present four foundational components in DR: (i) query planning, which decomposes the initially input query into a series of simpler, sub-queries [250, 426]; (ii) information acquisition, which invokes external retrieval, web browsing, or various tools on demand [167, 221]; (iii) memory management, which ensures relevant task-solving context through controlled updating or folding [243]; (iv) answer generation, which produces comprehensive outputs with explicit source attribution, e.g., a scientific report. This scope is distinct from standard RAG [89, 72] techniques, which typically treat retrieval as a heuristic augmentation step, without a flexible research workflow or a broader action space. We also introduce how to optimize DR systems in effectively coordinating these components, categorizing existing approaches into three types: (i) workflow prompting; (ii) supervised fine-tuning (SFT), and (iii) end-to-end reinforcement learning (RL).\n\nThe remainder of this paper is organized as follows: Section 2 clearly defines DR and its boundaries; Section 3 introduces four key components in DR; Section 4 introduces technique details about optimizing a DR system; Section 5 summarizes well-known evaluation datasets and resources, and Section 6 discusses challenges for future directions.\n\nTo sum up, our survey makes the following contributions: (i) We formalize a three-stage roadmap of DR and clearly distinguish it from related techniques such as standard retrieval-augmented generation; (ii) We introduce four key components of DR systems, together with fine-grained subtaxonomies for each, to provide a comprehensive view of the research loop; (iii) We summarize detailed optimization approaches for building DR systems, offering practical insights into workflow prompting, supervised fine-tuning, and reinforcement learning; and (iv) We consolidate evaluation criteria and open challenges to enable comparable reporting and to guide future research.\n\n# 2. Preliminary Concept of Deep Research\n\n# 2.1. What is Deep Research\n\nDR aims to endow LLMs with an end-to-end research workflow, enabling them to function as agents that generate coherent, source-grounded reports with minimal human supervision. Such systems automate the entire research loop, spanning planning, evidence acquisition, analysis, and reporting. In a DR setting, the LLM agent plans queries, acquires and filters evidence from heterogeneous sources (e.g., the web, tools, and local files), maintains and revises a working memory, and synthesizes verifiable answers with explicit attribution. Below, we formally introduce a three-phase roadmap that structures the rapidly evolving, capability-oriented landscape of DR, and we compare it systematically with conventional RAG paradigms.\n\n# 2.2. Understanding Deep Research from Three Phases\n\nWe view DR as a capability trajectory rather than a value hierarchy. The three phases below capture a progressive expansion of what systems can reliably do, from acquiring precise evidence, to synthesizing it into readable analyses, and finally to forming defensible insights.\n\nPhase I: Agentic Search. Phase I systems specialize in finding the correct sources and extracting answers with minimal synthesis. They typically reformulate the user query (via rewriting or decomposition) to improve recall, retrieve and re-rank candidate documents, apply lightweight\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/9e18e14bed5afbe77d92971f47bc2bec1d415d6461aecf4829cde478f991a242.jpg)  \nFigure 2: Taxonomy of the main content of this survey.\n\nfiltering or compression, and produce concise answers supported by explicit citations. The emphasis is on faithfulness to retrieved content and predictable runtime. Representative applications include\n\n<table><tr><td>Capability\n(Key Feature)</td><td>Standard RAG</td><td>Agentic Search</td><td>Integrated Research</td><td>Full-stack AI Scientist</td></tr><tr><td>Search Engine Access</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Use of Various Tools (e.g., Web APIs)</td><td>✗</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Code Execution for Experiment</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td></tr><tr><td>Reflection for Action Correction</td><td>✗</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Task-solving Memory Management</td><td>✗</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Innovation and Hypothesis Proposal</td><td>✗</td><td>✗</td><td>✗</td><td>✓</td></tr><tr><td>Long-form Answer Generation &amp; Validation</td><td>✓</td><td>✗</td><td>✓</td><td>✓</td></tr><tr><td>Action Space</td><td>Narrow</td><td>Broad</td><td>Broad</td><td>Broad</td></tr><tr><td>Reasoning Horizon</td><td>Single</td><td>Long-horizon</td><td>Long-horizon</td><td>Long-horizon</td></tr><tr><td>Workflow Organization</td><td>Fixed</td><td>Flexible</td><td>Flexible</td><td>Flexible</td></tr><tr><td>Output Form and Application</td><td>Short Span</td><td>Short Span</td><td>Report</td><td>Academic Paper</td></tr></table>\n\nTable 1: Comparison between conventional RAG (leftmost column) and the three envisioned stages of Deep Research (right columns). The capabilities evolve from static retrieval and generation to adaptive, autonomous, and scientifically creative workflows.\n\nopen-domain question answering [227, 165], multi-hop question answering [425, 344, 265], and other information-seeking tasks [271, 444, 333, 70, 215] where truth is localized to a small set of sources. Evaluation prioritizes retrieval recall@k and answer exact matching, complemented by citation correctness and end-to-end latency, reflecting the phase's focus on accuracy-per-token and operational efficiency.\n\nPhase II: Integrated Research. Phase II systems move beyond isolated facts to produce coherent, structured reports that integrate heterogeneous evidence while managing conflicts and uncertainty. The research loop becomes explicitly iterative: systems plan sub-questions, retrieve and extract key evidence from various raw content (e.g., HTML [323], tables [44, 226], and charts [208, 208]), and ultimately synthesize comprehensive, narrative reports. The most commonly-used applications include market and competitive analysis [469, 347], policy briefs [356], itinerary design under constraints [331], and other long-horizon question answering [66, 434, 378, 49]. Accordingly, evaluation shifts from superficial short-form lexical matching to long-form quality, including: fine-grained factuality [43, 216], verified citations [310, 86], structural coherence [21], key points coverage [379]. Phase II thus trades a modest increase in compute and complexity for substantial gains in clarity, coverage, and decision support.\n\nPhase III: Full-stack AI Scientist. Phase III aims at advancing scientific understanding and creation beyond mere information aggregation, representing a broader and more ambitious stage of DR In this phase, DR agents are expected not only to aggregate evidence but also to generate hypotheses [490], conduct experimental validation or ablation studies [223], critique existing claims [498], and propose novel perspectives [386]. Common applications include paper reviewing [506, 248, 498], scientific discovery [460, 292, 291], and experiment automation [362, 472]. Evaluation at this stage emphasizes the novelty and insightfulness of the findings, the argumentative coherence, the reproducibility of claims (including the ability to re-derive results from cited sources or code), and calibrated uncertainty disclosure.\n\n# 2.3. Comparing Deep Research with RAG\n\nMany real-world tasks are inherently open-ended, involving critical thinking, factually grounded information, and self-contained responses. These present several fundamental limitations of existing approaches. Below, we summarize three key challenges that cannot be solved by conventional RAG or scaling LLM parameters alone:\n\n- Flexible Interaction with the Digital World. Conventional RAG systems operate in a static retrieval loop, relying solely on pre-indexed corpora [232, 225]. However, real-world tasks often require active interaction with dynamic environments such as search engines, web APIs, or even Code executors [487, 223, 362]. DR systems extend this paradigm by enabling LLMs to perform multi-step, tool-augmented interactions, allowing agents to access up-to-date information, execute operations, and verify hypotheses within a digital ecosystem.  \n- Long-horizon Planning with Autonomous Workflows. Complex research-like problems often require agents to coordinate multiple subtasks [378], manage task-solving context [411], and iteratively refine intermediate outcomes [290]. DR addresses this limitation through closed-loop control and multi-turn reasoning, allowing agents to autonomously plan, revise, and optimize their workflows toward long-horizon objectives.  \n- Reliable Language Interfaces for Open-ended Tasks. LLMs are prone to hallucination and inconsistency [109, 471, 123, 13, 52], particularly in open-ended settings. DR systems introduce verifiable mechanisms that align natural language outputs with grounded evidence, establishing a more reliable interface between human users and autonomous research agents.\n\n# 3. Key Components in Deep Research System\n\nA DR system can be viewed as a closed-loop workflow that takes a complex research question as input and produces a structured answer, typically in the form of long-form text with citations or synthesized reports. As illustrated in Figure 1, the DR system iteratively cycles through a set of interconnected components: (i) query planning, which decomposes the original question into subqueries and tool calls that guide the workflow; (ii) knowledge acquisition, which retrieves and filters relevant information from external corpora, tools, or APIs; (iii) memory management, which stores, updates, and prunes intermediate findings to maintain context over long horizons; and (iv) answer generation, which synthesizes the accumulated evidence into a coherent, verifiable response with citations and checks for consistency. In this work, we provide detailed definitions and functionality for each component, along with representative works.\n\n# 3.1. Query Planning\n\nQuery Planning refers to the process of transforming a complex and logically intricate question into a structured sequence of executable sub-queries (aka., sub-tasks), each of which can be addressed incrementally. This decomposition allows stepwise reasoning and knowledge acquisition, thereby enhancing the reliability and accuracy of the final output generated by deep research system.\n\nFigure 3 shows three widely-used strategies for query planning: (i) parallel planning, which decomposes the input into independent sub-queries that may be resolved in parallel [36, 59]; (ii) sequential planning, which arranges sub-queries into a linear order where each step depends on intermediate outcomes [286, 145]; and (iii) tree-based planning, which explores branching decision spaces and selects among candidate paths through pruning, backtracking, or heuristic\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/32f52c56a027f95d31d9b1a8ff4c504bfcb9079502a68369aade6388bd249415.jpg)  \nFigure 3: Three commonly-used types of query planning: (i) parallel planning; (ii) sequential planning; and (iii) tree-based planning.\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/72346dfb2923e13e26d46cd9087eee88668a171a596d2b7e825b5e97db304b38.jpg)\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/008dccf3e20d999af78a497ab58615e0397ec23962b7a2208c908fe9d2ae785b.jpg)\n\nguided search [427].\n\n# 3.1.1. Parallel Planning\n\nDefinition. As illustrated in Figure 3(a), parallel planning operates by rewriting or decomposing the original query into multiple sub-questions in a single pass, typically without iterative interaction with downstream components. The primary advantage of this strategy lies in its efficiency: simultaneous generation enables parallel processing of sub-queries.\n\nRepresentative Work. Early research typically instantiates parallel planning modules through heuristic approaches, most notably via prompt engineering [484, 59] or training on manually annotated datasets. For example, Least-to-Most Prompting [484] guides GPT-3 [19] to decompose a complex task into an ordered sequence of simpler, self-contained sub-queries in a few-shot setting. Similarly, CoVE [59] prompts LLMs to first generate multiple independent sub-questions and then ground each one with well-established evidence in parallel, a strategy widely adopted in knowledge-intensive applications.\n\nDespite these advancements, query planning based on general heuristics or task-agnostic supervision often suffers from misalignment with end-to-end objectives in downstream applications, particularly in complex QA scenarios [425, 115, 344, 250]. To mitigate this issue, recent work has turned to end-to-end planning optimization via RL. For example, the Rewrite-Retrieve-Read framework [203] trains a query planner to maximize final answer accuracy using the Proximal Policy Optimization algorithm [276]. Crucially, the planner is reinforced only when documents retrieved by its sub-queries enable an LLM to generate a correct answer, which replaces reliance on heuristic decomposition rules. Building on this approach, subsequent efforts such as DeepRetrieval [133] and CardRewriter [96] have extended reward modeling for query planners to incorporate diverse downstream metrics (e.g., evidence recall, retrieval NDCG@k). More recently, studies have also explored jointly optimizing query planning with other components in modular dense retrieval pipelines through multi-agent RL methods [36].\n\nAdvantages & Disadvantages. Despite their efficiency, parallel planning has two primary limitations. First, they typically operate in a one-shot fashion, interacting with other modules (e.g., retriever, reasoner, aggregator) non-iteratively. As a result, they lack mechanisms to incorporate intermediate evidence, correct earlier decisions, or adaptively allocate computational resources. Second, they often ignore data and logical dependencies across sub-queries. Parallel execution assumes conditional independence, yet many real-world queries involve sequential reasoning in which later subtasks depend on the resolution of earlier ones. This can result in ill-posed or unanswerable sub-queries\n\ndue to missing contextual information.\n\n# 3.1.2. Sequential Planning\n\nDefinition. As illustrated in Figure 3(b), the sequential planning decomposes the original query through multiple iterative steps, where each round of decomposition builds upon the outputs of previous rounds. At each stage, the sequential planning may invoke different modules or external tools to process intermediate results, enabling a dynamic, feedback-driven reasoning process. This multi-turn interaction allows the sequential planning to perform logically dependent query decompositions that are often intractable for pre-processing planning, which typically assumes conditional independence among sub-queries. By incorporating intermediate evidence and adapting the query trajectory accordingly, sequential planning is particularly well-suited for complex tasks that require stepwise inference, disambiguation, or progressive information gathering.\n\nRepresentative Work. The sequential planning is often used to provide a series of sub-queries for the external knowledge needed in a step-by-step manner, which has been widely used in iterative QA systems [181, 308, 139]. For example, LLatrieval [181] introduces an iterative query planner that, whenever the current documents fail verification, leverages the LLM to pinpoint missing knowledge and generate a new query, either a question or a pseudo-passage, to retrieve supplementary evidence, repeating the cycle until the accumulated context fully supports a verifiable answer. DRAGIN [308] introduces a query planner that can utilize the self-attention scores to select the most context-relevant tokens from the entire generation history and reformulate them into a concise and focused query. This dynamic, attention-driven approach produces more accurate queries compared to the static last sentence or last  $n$  tokens strategies in previous methods, resulting in higher-quality retrieved knowledge and improved downstream generation. In ReSP [139], the query planner dynamically guides each retrieval iteration by formulating novel sub-questions explicitly targeted at identified information gaps whenever the currently accumulated evidence is deemed insufficient. By conditioning this reformulation process on both global and local memory states and by disallowing previously issued sub-questions, the approach mitigates the risks of over-planning and redundant retrieval. This design ensures that each newly generated query substantially contributes to advancing the multi-hop reasoning trajectory toward the final answer. RAISE [233] sequentially decomposes a scientific question into sub-problems, generates logic-aware queries for each, and retrieves step-specific knowledge to drive planning and reasoning. Additionally, S3 [134] and AI-SearchPlanner [213] both adopt sequential decision-making to control when and how to propose retrieval queries during multi-turn search. At each turn, the sequential planner evaluates the evolving evidence state and decides whether to retrieve additional context or to stop. Besides, more recent studies, including Search-R1 [145], R1-Searcher [300, 301] integrate a sequential planning strategy into an end-to-end, multi-turn search framework, thereby leveraging LLMs' internal reasoning for query planning.\n\nAdvantages & Disadvantages. Sequential planning enables dynamic, context-aware reasoning and fine-grained query reformulation, thereby facilitating more accurate acquisition of external knowledge. However, excessive reasoning turns or overly long reasoning chains can incur substantial computational costs and latency. In addition, an increased number of turns may introduce cumulative noise and error propagation, potentially causing instability during reinforcement learning training.\n\n# 3.1.3. Tree-based Planning\n\nDefinition. As illustrated in Figure 3(c), the tree-based planning integrates features of both parallel and sequential planning by recursively treating each sub-query as a node within a structured search space, typically represented as a tree or a directed acyclic graph (DAG) [51]. This structure enables the use of advanced search algorithms, such as Monte Carlo Tree Search (MCTS) [20], to explore and refine potential reasoning paths. Compared to linear or flat decompositions, this approach supports more flexible and fine-grained decomposition of the original query, facilitating comprehensive knowledge acquisition.\n\nRepresentative Work. A representative example is RAG-Star [132], which leverages MCTS in conjunction with the Upper Confidence Bound for Trees (UCT) [161] to guide a query planner in the iterative decomposition of complex questions. At each iteration, the planning model selects the most promising node using the UCT criterion, expands it by generating a sub-query and corresponding answer using a language model, evaluates the quality of the expansion via a retrieval-based reward model, and back-propagates the resulting score. This iterative process grows a reasoning tree of sub-queries until a satisfactory final answer is obtained. Other examples include DTA [494] and DeepSieve [106], which use a tree-based planner to restructure sequential reasoning traces into a DAG. This design enables the planning to aggregate intermediate answers along multiple branches and improves the model's ability to capture both hierarchical and non-linear dependencies across sub-tasks. DeepRAG [103] introduces tree-based planning via binary-tree exploration to iteratively decompose queries and decide parametric vs. retrieved reasoning, yielding large accuracy gains with fewer retrievals. More recently, MAO-ARAG [37] trains a planning agent that can dynamically orchestrate multiple, diverse query reformulation modules through a DAG structure. This adaptive workflow enables comprehensive query decomposition to enhance performance.\n\nAdvantages & Disadvantages. Tree-based planning integrates the strengths of parallel and sequential planning. It facilitates the decomposition of interdependent sub-queries and supports local parallel execution, striking an effective balance between efficiency and effectiveness. Nevertheless, training a robust Tree-based Planning module is challenging, requiring precise dependency modeling, careful trade-offs between speed and quality, addressing data scarcity, and tackling credit assignment issues in reinforcement learning.\n\n# Takeaway\n\nThis section on query planning provides a detailed overview of strategies for enhancing DR systems by decomposing complex queries into simpler, manageable subtasks. Each type of planning strategy offers unique benefits and faces specific challenges.\n\n- Pre-processing planning is efficient in executing sub-queries simultaneously, though they may overlook dependencies between them.  \n- Sequential planning excels in managing dependencies through iterative processes but can incur higher computational costs.  \n- Tree-based planning strikes a balance by combining the strengths of both sequential and pre-processing approaches, allowing for adaptive and flexible query decomposition.\n\n# 3.2. Information Acquisition\n\nDR systems often acquire external information to augment LLMs' internal knowledge. However, due to the cost of retrieval and the uncertainty of document quality, it is necessary to determine when retrieval is needed [449, 396, 455]. Moreover, how to perform retrieval and manage retrieved information is key to the DR system's interaction with external knowledge. In the following, we discuss retrieval tools, retrieval timing, and information filtering in turn.\n\n# 3.2.1. Retrieval Tools\n\nDefinition. In the context of DR, retrieval tools [299, 503, 419] are used to identify relevant information from large-scale corpora in response to a query, typically containing indexing and search techniques. Within typical DR workflows, retrieval serves as a core mechanism for bridging knowledge gaps by surfacing candidate evidence that can then be checked for accuracy, filtered for relevance, or combined into a coherent answer. Below, we systematically review widely adopted retrieval techniques, organized by modality: (i) text-only retrieval, and (ii) multimodal retrieval.\n\nText Retrieval. Conceptually, modern text retrieval can be organized into three families: (i) lexical retrieval, (ii) semantic retrieval, and (iii) commercial web search. Lexical and semantic retrieval are typically implemented on local resources, while commercial web search is typically accessed only via paid APIs. Specifically, lexical retrieval refers to methods that match documents based on exact term overlaps and statistical term weighting, including traditional approaches like TF-IDF and BM25 [269], as well as neural sparse models that learn to expand queries and documents with relevant terms while maintaining interpretable inverted-index structures [80, 79, 157, 156, 259, 354, 80, 273].\n\nDifferent from the lexical retrieval, semantic retrieval refers to dense neural methods that encode queries and documents into continuous vector spaces to capture semantic similarity beyond exact term matching [283, 111, 284, 144], which has been widely adopted in recent works [145, 289].\n\nMore recently, commercial web search (like Google or Bing) has also been widely used in DR systems and web agents [334, 75, 240, 34]. It diverges from lexical and semantic retrieval models by providing access to real-time information, leveraging massive-scale web crawling and indexing, incorporating sophisticated ranking algorithms that consider authority and freshness signals, and offering built-in fact verification through cross-source validation. Previous work, such as WebGPT [221] and SearchGPT [412], demonstrates that commercial search APIs enable research agents to access current events and dynamic content that would be missing from static corpora.\n\nRecent studies [182, 183, 329, 253] exemplify a shift towards more autonomous and capable research agents. These models feature deep web exploration capabilities, allowing them to interactively navigate beyond static search results to gather information. Overall, the evolution from lexical and semantic retrieval to commercial web search marks a shift from static, closed-corpus search toward dynamic, real-world information access, enabling DR systems to retrieve not only relevant but also timely and verifiable knowledge.\n\nMultimodal Retrieval. Multimodal retrieval aims to mine multimodal information, including text, layout, and visuals (figures, tables, charts), and to preserve grounded pointers (spans, cells, coordinates) for verifiable citation, while maximizing recall under tight latency to support iterative DR. Multimodal information retrieval can be organized into three classes based on the primary type of information modality being indexed and retrieved: (i)text-aware retrieval with layout, which\n\nindexes titles, captions, callouts, and surrounding prose and leverages document understanding models (LayoutLM [415], Donut [159], DocVQA [210]) plus layout/metadata filters; (ii) visual retrieval via text-image similarity, which encodes figures and chart thumbnails with CLIP [261], SigLIP [446], or BLIP [171] and performs ANN search for text-to-image matching or composed image retrieval [420]; and (iii) structure-aware retrieval over parsed tables and charts, which indexes axes, legends, data marks, and table schemas to support grounded lookup of numeric facts and relations (e.g., ChartReader [42] or Chartformer [477]). These three approaches are typically combined: queries are searched across all indices simultaneously, with results fused using reciprocal-rank fusion [50] or cross-modal reranking to preserve grounded pointers for citations. Recent chart-focused VLMs [214, 25, 452, 209] further enhance the quality of visual-textual features.\n\nComparing Text Retrieval and Multimodal Retrieval. Compared to text-only retrieval, multimodal retrieval provides several key advantages. First, it captures visually encoded information and numeric trends that text-based methods often overlook, and facilitates cross-modal verification through hybrid fusion [50]. Second, it enables grounded citations using techniques such as layout parsing (e.g., LayoutLM [415], Donut [159]) and chart understanding (e.g., ChartReader [42] or Chartformer [477]). However, multimodal retrieval also presents several challenges, including increased computational costs for visual processing [261, 446], sensitivity to OCR errors and variations in chart formats [327, 404], and the complexity of aligning information across different modalities.\n\n# Takeaway\n\nKnowledge retrieval for DR has evolved from traditional lexical and dense-text search to the use of real-time commercial web search engines for up-to-date information. However, text-only methods fail to capture information embedded in visual elements like charts, tables, and layouts. Multimodal retrieval addresses this gap by modeling visual and structural data. Its primary contribution is enabling grounded, verifiable citations by linking retrieved evidence back to specific data points (e.g., table cells or chart coordinates), though this introduces higher computational costs and challenges in cross-modal alignment and format processing.\n\n# 3.2.2. Retrieval Timing\n\nDefinition. Retrieval timing refers to determining when a model should trigger retrieval tools during information seeking, which is also known as adaptive retrieval [131, 429, 60]. Because the quality of retrieved documents is not guaranteed, blindly performing retrieval at every step is often suboptimal [206, 470, 289]. Retrieval introduces additional computational overhead, and low-quality or irrelevant documents may even mislead the model or degrade its reasoning performance [286]. Consequently, adaptive retrieval aims to invoke retrieval only when the model lacks sufficient knowledge, which requires the model to recognize its own knowledge boundaries [176, 453, 405, 266], i.e., knowing what it knows and what it does not.\n\nPrior work on adaptive retrieval follows two main directions: (i) estimating and enhancing a model's ability to recognize its own knowledge boundaries for a given query, and (ii) optimizing the retrieval-trigger model in multi-step settings to maximize downstream task performance.\n\nConfidence Estimation as a Proxy for Boundary Perception. There are extensive works that investigate LLMs' perception of their knowledge boundaries. The degree to which a model perceives its boundaries is typically measured by the alignment between its confidence and factual correctness. Since factual correctness is typically evaluated by comparing the model's generated answer with the\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/e88e50b146556ee278460289bc5b9707974121f49570b3c45c3669d5ebe82ee7.jpg)  \nFigure 4: Existing information filtering approaches can be broadly categorized into the following types: (i) Document Selection; (ii) Context Compression; and (iii) Rule-based Cleaning.\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/2bb32cedf603ee1741fc305236394e252e54dde960167c2d6480ac1e8f9e2a2c.jpg)\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/7eac7a1a0df7a03794809ea6b77635e368cde94a40ad1d09039011f859307726.jpg)\n\nground-truth answer, existing studies focus on how to measure the model's confidence, which can be broadly divided into four categories.\n\n- Probabilistic Confidence. This line of work treats a model's token-level generation probabilities as its confidence in the answer [104, 58, 137, 153, 295, 164, 69]. Prior to the emergence of LLMs, a line of work had already shown that neural networks tend to be poorly calibrated, often producing overconfident predictions even when incorrect [104, 58, 137]. More recently, some research[153, 295] reported that LLMs can be well calibrated on structured tasks such as multi-choice question answering or appropriate prompts, but for open-ended generation tasks, predicted probabilities still diverge from actual correctness. To address this gap, Duan et al. [69] proposed SAR, which computes confidence by focusing on important tokens, while Kuhn et al. [164] introduced semantic uncertainty, which estimates confidence from the consistency of outputs across multiple generations.  \n- Consistency-based Confidence. Since probabilistic confidence often fails to capture a model's semantic certainty and is inapplicable to black-box models without accessible generation probabilities, recent works represent confidence via semantic consistency across multiple responses [78, 207, 164, 451, 60]. The key idea is that a confident model should generate highly consistent answers across runs. Fomicheva et al. [78] first measured consistency through lexical similarity, while later studies used NLI (i.e., natural language inference) models or LLMs to assess semantic consistency [207, 164]. To address the issue of consistent but incorrect answers, Zhang et al. [451] measure consistency across different models, as incorrect answers tend to vary between models, whereas correct ones align. Ding et al. [60] further extended this idea to multilingual settings.\n\n- Confidence Estimation Based on Internal States. LLMs' internal states have been shown to capture the factuality of their generated content [10, 309, 28, 364, 230, 229]. Azaria and Mitchell [10] first discovered that internal states can signal models' judgment of textual factuality. Subsequent studies [309, 28] found that internal states after response generation reflect the factuality of self-produced answers. More recently, Wang et al. [364] and Ni et al. [230] demonstrated that factuality-related signals already exist in the pre-generation states, enabling the prediction of whether the output will be correct.  \n- Verbalized Confidence. Several studies explore enabling LLMs to express confidence in natural language, akin to humans, viewing such verbalization as a sign of intelligence [185, 431, 340, 409, 450, 424, 228]. Yin et al. [431] and Ni et al. [228] examined whether LLMs can identify unanswerable questions, finding partial ability but persistent overconfidence. Other works [340, 409] investigated fine-grained confidence expression. Xiong et al. [409] offered the first comprehensive study for black-box models, while Tian et al. [340] proposed generating multiple answers per pass for more accurate estimation. Beyond prompting, some methods explicitly train models to verbalize confidence [185, 424, 450], with Lin et al. [185] introducing this idea and using correctness-based supervision.\n\nRepresentative Adaptive Retrieval Approaches. Deep research systems typically involve iterative interactions between model inference and external document retrieval, differing mainly in how they determine when to retrieve. Early works such as IR-CoT [343] enforce retrieval after every reasoning step, ensuring continual grounding in external knowledge but at the cost of efficiency. Building on insights from studies of models' perceptions of their own knowledge boundaries, recent approaches treat retrieval as a model-issued action, enabling the model to perform it dynamically only when needed. Similar to techniques in confidence estimation, these methods assess whether the model can answer a question correctly given the current context and perform retrieval when knowledge is deemed insufficient. They can be broadly categorized into four paradigms.\n\n- Probabilistic Strategy. It triggers retrieval based on token-generation probabilities: when the model produces a token with low confidence, retrieval is initiated [138, 308].  \n- Consistency-based Strategy. Recognizing that both token-level probabilities and single-model self-consistency may fail to capture true semantic uncertainty, Rowen [60] evaluates consistency across responses generated by multiple models and languages, triggering retrieval when cross-model or cross-lingual agreement is low.  \n- Internal States Probing. CtrlA [126], UAR [40], and SEAKR [429] further propose that compared to generated responses, a model's internal states provide a more faithful reflection of its confidence, using them to guide adaptive retrieval decisions.  \n- Verbalized Strategy. It enables the model to directly express its confidence via natural language. These methods typically generate special tokens directly in the response to indicate the need for retrieval. ReAct [428] directly prompts the model to generate corresponding action text when retrieval is needed. Self-RAG [9] trains the model to explicitly express uncertainty through the special token (i.e., <retrieve>), signaling the need for retrieval. With LLMs' growing reasoning capacity, recent research has shifted toward determining retrieval timing through reasoning and reflection. Search-o1 [182] introduces a Reason-in-Documents module, which prompts the model to selectively invoke search during reasoning. Search-R1 [145] further frames retrieval as part of the environment and employs reinforcement learning to jointly optimize both when and what to retrieve.\n\nCollectively, these methods trace an evolution from fixed or per-step retrieval (e.g., IR-CoT [343]) to\n\ndynamically triggered retrieval (e.g., ReAct [428], Self-RAG [9], Search-o1 [182]), and finally to RL-based systems that explicitly train retrieval policies (e.g., Search-R1 [145]).\n\n# 3.2.3. Information Filtering\n\nDefinition. Information filtering refers to the process of selecting, refining, or transforming retrieved documents so that only the most relevant and reliable evidence is passed to subsequent steps. Since retrieval tools are not perfect, the retrieved information often contains considerable noise [433, 393, 73]. This includes the content that is entirely irrelevant to the query or plausible-looking statements that nevertheless provide incorrect or misleading context. As shown in prior work [433, 143], LLMs are highly sensitive to such noise; without additional filtering or optimization, they can be easily misled into generating incorrect or hallucinated responses. Figure 4 summarizes three information filtering approaches: (i) Document Selection, (ii) Context Compression, and (iii) Rule-based Cleaning.\n\nDocument Selection. Document selection aims to rank a set of candidate documents based on their relevance and usefulness to the query, selecting the top-k helpful documents for question answering [410, 439, 381]. This selection operation reduces the impact of noisy documents on LLMs, improving the question-answering accuracy in downstream tasks. Below, we review three document selection strategies: point-wise selection, pair-wise selection, and list-wise selection.\n\n- Point-wise Selection. Given an initially retrieved document list, point-wise methods independently score each candidate document. The most common approach involves fine-tuning an embedding model (e.g., BGE [406]) that encodes the query and each document separately, after which their relevance is estimated via inner-product similarity [410, 128]. Another widely adopted strategy employs a cross encoder, which takes the concatenation of the query and a document as input and directly predicts a binary relevance score [65, 371]. More recently, several studies have leveraged LLMs' natural language understanding capabilities for relevance assessment. These methods train LLMs to output special tokens, such as <ISREL> [9] or the identifier True [439], to indicate whether an input document is relevant to the query.  \n- Pair-wise Selection. Unlike the point-wise approach, which assigns an absolute relevance score, the pair-wise method compares the relevance of two input candidate information snippets (typically two documents) and predicts which one is more relevant to the query. Pair-wise selection is less common than point-wise selection. A representative work is PRP [255], which adopts a pairwise-ranking-prompting approach. In PRP, the LLM receives a query and two candidate documents to decide which is more relevant, and the final ranking list is then obtained using a heapsort algorithm. To mitigate positional bias, PRP performs the comparison twice, swapping the document order each time, and aggregates the results to yield a more stable judgment.  \n- List-wise methods. Given a document list, a list-wise selection strategy directly selects the final set of relevant documents from the candidate list. A representative work is RankGPT [317], which feeds the entire candidate sequence into an LLM and leverages prompt engineering to produce a global ranking. In addition to RankGPT, other work, such as TourRank [35], uses a tournament-inspired strategy to generate a robust ranking list [35, 432]. ListT5 [432] proposes a list re-ranking method based on the Fusion-in-Decoder (FiD) [127] architecture, which independently encodes multiple documents in parallel and orders them by relevance, mitigating positional sensitivity while preserving efficiency. For large document sets, it builds m-ary tournament trees to group, rank, and merge results in parallel. Recently, more and more work has employed the reasoning model for list-wise document selection, advancing document selection by explicitly modeling a chain of thought. For example, InstructRAG [381] trains an LLM to generate detailed rationales\n\nvia instruction tuning [281], directly judging the usefulness of each document in the raw retrieved document list. Rank-R1 [505] employs the reinforcement learning algorithm GRPO [279] to train the LLM, enabling it to learn how to select the documents most relevant to a query from a list of candidates. ReasonRank [188] empowers a list-wise selection model through a proposed multiview ranking-based GRPO [279], training an LLM on automatically synthesized multi-domain training data.\n\nContent Compression. Content Compression aims to remove redundant or irrelevant information from retrieved knowledge, thereby increasing the density of useful content within the model's context. Existing approaches primarily fall into two categories: lexical-based and embedding-based methods.\n\n- Lexical-based methods condense retrieved text into concise natural language, aiming to only include the key point related to the given query [410, 355]. Representative works such as RECOMP [410] fine-tune a smaller, open-source LLM to summarize the input retrieved documents, where the ground truth is synthesized by prompting powerful commercial LLMs like GPT-4 [1]. Chain-of-Note [438] introduces a reading-notes mechanism that compels the model to assess the relevance of retrieved documents to the query and extract the most critical information before generating an answer, with training data annotated by GPT-4 and further validated through human evaluation. Other work, like BIDER [146], eliminates reliance on external model distillation by synthesizing Key Supporting Evidence (KSE) for each document, using it for compressor SFT, and further optimizing with PPO based on gains in answer correctness. Zhu et al. [496] argue that previous compressors optimized with log-likelihood objectives failed to precisely define the scope of useful information, resulting in residual noise. They proposed a noise-filtering approach grounded in the information bottleneck principle, aiming to maximize the mutual information between the compressed content and the target output while minimizing it between the compressed content and retrieved passages. RankCoT [395] implicitly learns document reranking during information refinement. It first employs self-reflection to generate summary candidates for each document. In subsequent DPO [276] training, the compression model is encouraged to assign higher probabilities to correct summaries when all documents are fed in, thereby inducing implicit reranking in the final summarization.\n\n- **Embedding-based methods** compress context into dense embedding sequences [219, 107, 45]. Because embedding sequences can store information flexibly, embedding-based methods can be more efficient and effective than lexical-based methods. ICAE [92] uses an encoder to compress context into fixed-length embedding sequences and designs training tasks to align the embedding space with the answer generation model. COCOM [263] jointly fine-tunes the encoder and answer generation model, enhancing the latter's ability to capture the semantics of embeddings. xRAG [41] focuses on achieving extreme compression rates. It introduces a lightweight bridging module, initialized with a two-layer MLP and trained through paraphrase pretraining and context-aware instruction tuning. This module projects the document embedding vectors originally used for initial retrieval into a single token in the answer generation model's representation space, achieving contextual compression with only a single additional token. ACC-RAG [107] adapts compression rates for different documents by employing a hierarchical compressor to produce multi-granularity embedding sequences and dynamically selecting compression rates based on query complexity. Similarly, QGC [24] adjusts compression rates based on query characteristics, dynamically selecting different rates for different documents based on their relevance to the query.\n\nRule-based Cleaning. Rule-based methods are effective for cleaning externally sourced information with specific structures. For example,HtmlRAG [323] applies rule-based compression to remove\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/a1dadec4ef8080583f6246d7ca4840e6a3906bc01dfaceedcc170d4c741d30e0.jpg)  \nFigure 5: Memory management contains four key stages: (1) Memory Consolidation, (2) Memory Indexing, (3) Memory Updating, and (4) Memory Forgetting.\n\nstructurally present but semantically empty elements, such as CSS styling and JavaScript code, from retrieved web pages. This is combined with a two-stage block-tree pruning strategy that first uses embeddings for coarse pruning, followed by a generative model for fine-grained pruning. Separately, TableRAG [32] accurately extracts core table information through schema retrieval, which identifies key column names and data types, and cell retrieval, which locates high-frequency cell value pairs. This method addresses the challenges of context length limitations and information loss in large table understanding.\n\nAdvantages & Disadvantages. Filtering the retrieved knowledge is a simple yet effective strategy to enhance the performance of DR systems, as widely demonstrated in previous work [410, 323, 65]. However, incorporating an additional filtering module typically incurs additional computational costs and increased latency [393]. Moreover, overly filtering may remove useful or even correct information, thereby degrading model performance. Therefore, balancing filtering precision and information retention is crucial for building efficient and reliable DR systems.\n\n# Takeaway\n\nKnowledge filtering can further process the metadata retrieved by DR systems, providing them with more concise and useful external knowledge while reducing noise interference and attention dilution caused by long context lengths. Filtering methods can be categorized into post-ranking selection, context compression, and rule-based cleaning. However, these knowledge filtering techniques often introduce additional time and computational costs. Therefore, different DR systems should choose the most suitable filtering method based on task characteristics to balance performance and resource consumption.\n\n# 3.3. Memory Management\n\nDefinition. Memory management is a foundational component of advanced DR architectures, which governs the dynamic lifecycle of context used by DR agents in complex, long-horizon tasks [398, 67,\n\n136], aiming to maintain coherent and relevant task-solving context [113, 462, 319].\n\nCore Operation. As illustrated in Figure 5, memory management typically involves four core operations: consolidation, indexing, updating, and forgetting. Consolidation converts short-term experiences into durable representations that form the basis for later indexing. Indexing organizes these representations into retrieval structures that support efficient recall during problem solving. Updating refines or corrects stored knowledge, whereas forgetting selectively removes outdated or irrelevant content to reduce interference. In the following sections, we discuss consolidation, indexing, updating, and forgetting in detail.\n\n# 3.3.1. Memory Consolidation\n\nDefinition. Memory consolidation is the process of transforming transient, short-term information, such as user dialogues or tool execution outputs, into stable, long-term representations [303, 67, 398]. Drawing an analogy to cognitive neuroscience, this process encodes and abstracts raw inputs to create durable memory engrams, laying the groundwork for efficient long-term storage and retrieval [398].\n\nMemory consolidation involves transforming interaction histories into durable formats, including but not limited to model parameters [370], structured graphs [474], or knowledge bases [197, 67]. Distinct from memory indexing, which creates navigable access pathways over existing memories, consolidation is fundamentally concerned with the initial transformation and structural organization of raw experience. Two primary paradigms for this process have emerged: (i) unstructured memory consolidation and (ii) structured memory consolidation.\n\nUnstructured Memory Consolidation. This paradigm distills lengthy interaction histories or raw texts into high-level, concise summaries or key event logs. For example, MemoryBank [482] processes and distills conversations into a high-level summary of daily events, which helps in constructing a long-term user profile. Similarly, MemoChat [197] summarizes conversation segments by abstracting the main topics discussed, while ChatGPT-RSum [358] adopts a recursive summarization strategy to manage extended conversations. Other approaches focus on abstracting experiences; Generative Agents [245] utilize a reflection mechanism triggered by sufficient event accumulation to generate more abstract thoughts as new, consolidated memories. To create generalizable plans, GITM [501] summarizes key actions from multiple successful plans into a common reference memory.\n\nStructured Memory Consolidation. This paradigm transforms unstructured information into highly organized formats such as databases, graphs, or trees. This structural encoding is the primary act of consolidation, designed to capture complex inter-entity relationships and create an organized memory corpus. For instance, TiM [187] extracts entity relationships from raw information and stores them as tuples in a structured database. ChatDB [119] leverages a database as a form of symbolic memory, transforming raw inputs into a queryable, relational format. AriGraph [6] implements a memory graph where knowledge is represented as vertices and their interconnections as edges. Similarly, HippoRAG [142] constructs knowledge graphs over entities, phrases, and summaries to form an interconnected web of fragmented knowledge units. MemTree [268] builds and updates a tree structure by traversing from the root and deciding whether to deepen the tree with new information or create new leaf nodes based on semantic similarity. This hierarchical organization is the core of its consolidation strategy, enabling structured storage of memories.\n\n# 3.3.2. Memory Indexing\n\nDefinition. Memory indexing involves constructing a navigational map over a DR agent's consolidated memories, analogous to a library's catalog or a book's index for efficient information retrieval [204]. Unlike memory consolidation, which focuses on the initial transformation of raw data into a durable format, indexing operates on already consolidated memories to create efficient, semantically rich retrieval pathways. This process builds auxiliary access structures that enhance retrieval not only in efficiency but also in relevance.\n\nEffective indexing goes beyond simple keyword matching by encoding temporal [211] and relational [142] dependencies among memories. This is typically achieved by generating auxiliary codes, such as vector embeddings, summaries, or entity tags, which serve as retrieval entry points into the memory store. Given the vast, high-dimensional spaces these codes inhabit, specialized search techniques are required, such as Locality-Sensitive Hashing (LSH) [54], Hierarchical Navigable Small World (HNSW) graphs [205], or libraries like FAISS [150] for high-speed similarity search. These access mechanisms are commonly organized through three established paradigms:\n\n- Signal-enhanced Indexing. This paradigm augments consolidated memory entries with auxiliary metadata, including emotional context, topics, and keywords, which function as granular pivots for context-aware retrieval [312, 448]. For instance, LongMemEval [390] enhances memory keys by integrating temporal and semantic signals to improve retrieval precision. Similarly, the Multiple Memory System (MMS) [448] decomposes experiences into discrete components, such as cognitive perspectives and semantic facts, thereby facilitating multifaceted retrieval strategies.  \n- Graph-based Indexing. This paradigm leverages a graph structure, where memories are nodes and their relationships are edges, as a sophisticated index. By representing memory networks in this way, agents can perform complex multi-hop reasoning by traversing chains of connections to locate information that is not explicitly linked to the initial query [46, 194]. For instance, HippoRAG [142] uses lightweight knowledge graphs to explicitly model inter-memory relations, enabling structured, interpretable access. A-Mem [414] adopts a dynamic strategy where the agent autonomously links related memory notes, progressively growing a flexible access network.  \n- Timeline-based Indexing. This paradigm creates a temporal index by organizing memory entries along chronological or causal sequences. Such structuring provides a historical access pathway, which is essential for understanding progression, maintaining conversational coherence, and supporting lifelong learning [353]. For example, the Theanine system [235] arranges memories along evolving timelines to facilitate retrieval based on both relevance and temporal dynamics. Zep [262] introduces a bi-temporal model for its knowledge graph, indexing each fact with  $t_{valid}$  and  $t_{invalid}$  timestamps, which allows the agent to navigate the memory based on temporal validity.\n\n# 3.3.3. Memory Updating\n\nDefinition. Memory updating is a core capability of DR agents, involving the reactivation and modification of existing knowledge in response to new information or environmental feedback [361, 321, 369]. This process is essential for maintaining the consistency, accuracy, and relevance of the agent's internal world model, thereby enabling continual learning and adaptive behavior in dynamic environments [349, 357].\n\nMemory updating governs how an agent corrects factual inaccuracies, incorporates new information, and gradually improves its knowledge base [290, 55, 218]. Although related to memory forgetting, which focuses on removing outdated or incorrect content, memory updating centers on\n\nmodifying and refining existing knowledge to increase its fidelity. In the following, we introduce two updating strategies, depending on whether the memory is external (non-parametric) or internal (parametric) to the model [357].\n\nNon-Parametric Memory Updating. Non-parametric memory, stored in external formats such as vector databases or structured files, is updated via explicit, discrete operations on the data itself. This approach offers flexibility and transparency. Key operations include:\n\n- Integration and Conflict Updating. This operation focuses on incorporating new information and refining existing entries to maintain logical consistency. For example, the Mem0 framework employs an LLM to manage its knowledge base through explicit operations, such as adding new facts (ADD) or modifying existing entries with new details (UPDATE) to resolve inconsistencies [46]. To handle temporal conflicts, Zep updates its knowledge graph by modifying an existing fact's effective time range, setting an invalidation timestamp ( $t_{invalid}$ ) to reflect that a newer fact has superseded it [262]. Similarly, the TiM framework curates its memory by using Merge operations to combine related facts into a more coherent representation [187]  \n- Self-Reflection Updating. Inspired by human memory reconsolidation, this paradigm enables agents to iteratively refine their knowledge by reflecting on past experiences [290, 486]. Early systems like Reflexion [290] and Voyager [349] implement this through verbal self-correction and updates to a skill library. More dynamically, A-Mem [414] triggers a Memory Evolution process that re-evaluates and autonomously refines previously linked memories based on new contextual information.\n\nParametric Memory Updating. Parametric memory, encoded directly in a model's weights, is updated by modifying internal representations. This is typically more complex and computationally intensive. Three main approaches have emerged:\n\n- Global Updating. This approach integrates new knowledge by continuing model training on additional datasets [278]. While effective for large-scale adaptation, it is computationally expensive and prone to catastrophic forgetting [361]. To address this, instead of simply injecting factual knowledge, Memory-R1 trains a dedicated Memory Manager agent to learn an optimal policy for modification operations such as ADD and UPDATE, moving beyond heuristic rules [417]. Additionally, a recent framework refines this process by employing methods such as Direct Preference Optimization to fine-tune the model's memory utilization strategy [463].  \n- Localized Updating. This technique modifies specific facts in the model's parameters without requiring full retraining [55, 218]. It is especially suited for online settings where rapid adaptation is needed, such as updating a user's preference [321]. Methods typically follow a locate-and-edit strategy or use meta-learning to predict weight adjustments while preserving unrelated knowledge [218, 321].  \n- Modular Updating. This emerging paradigm avoids the risks of continual weight modification by distilling knowledge into a dedicated, plug-and-play parametric module. Frameworks such as MLP Memory [380] and Memory Decoder [22] train a lightweight external module to imitate the output distribution of a non-parametric kNN retriever. This process effectively compiles a large corpus of external knowledge into the compact weights of the module. The resulting module can then be attached to any compatible LLM to provide specialized knowledge without modifying the base model's parameters, thereby avoiding catastrophic forgetting and reducing the latency of real-time retrieval [380, 22].\n\n# 3.3.4. Memory Forgetting\n\nDefinition. Forgetting constitutes a fundamental mechanism in advanced agent architectures, enabling the selective removal or suppression of outdated, irrelevant, or potentially erroneous memory content. Rather than a system defect, forgetting is a functional process critical for filtering noise, reclaiming finite storage resources, and mitigating interference between conflicting information. In contrast to memory updating, which modifies existing knowledge to improve its accuracy, forgetting is a subtractive process that streamlines the memory store by eliminating specific content. This process can be broadly categorized into passive and active mechanisms.\n\nPassive Forgetting. This simulates the natural decay of human memory, in which infrequently accessed or temporally irrelevant memories gradually lose prominence. This mechanism is particularly critical for managing the agent's immediate working memory or context window. Implementations are typically governed by automated, time-based rules rather than explicit content analysis. For instance, MemGPT [243] employs a First-In-First-Out (FIFO) queue for recent interactions, automatically moving the oldest messages from the main context into long-term storage. MemoryBank [482] draws inspiration from the Ebbinghaus forgetting curve, in which memory traces decay over time unless reinforced, allowing the agent to naturally prioritize recent content. A more aggressive approach, MEM1 [491], employs a use-and-discard policy: after each interaction, the agent synthesizes essential information into a compact state and immediately discards all prior contextual data to maintain constant memory consumption.\n\nActive Forgetting. Active forgetting involves the intentional and targeted removal or invalidation of specific memory content. This process is a deliberate action, often triggered by the detection of contradictions or the need to correct inaccurate information, and its implementation varies depending on the memory type.\n\n- Non-Parametric Memory. Active forgetting in external memory stores involves direct data manipulation. For example, Mem0 [46] implements an explicit DELETE command to remove outdated or contradictory facts. Similarly, TiM [187] introduces a dedicated FORGET operation to actively purge irrelevant or incorrect thoughts from its memory cache. Reinforcement learning can also be used to train a specialized Memory Manager agent to autonomously decide when to execute a DELETE command, as seen in the Memory-R1 framework [417]. AriGraph [6] maintains a structured memory graph by removing outdated vertices and edges. Some systems employ nondestructive forgetting; the Zep architecture [262], for example, uses edge invalidation to assign an invalid timestamp to an outdated entry, effectively retiring it without permanent deletion.  \n- Parametric Memory. In this context, active forgetting is typically achieved through machine unlearning techniques that modify a model's internal parameters to erase specific knowledge without full retraining. Approaches include locating and deactivating specific neurons or adjusting training objectives to promote the removal of targeted information. For example, MEOW [101] facilitates efficient forgetting by fine-tuning an LLM on generated contradictory facts, effectively overwriting undesirable memories stored in its weights.\n\n# Takeaway\n\nMemory management is a cornerstone of the DR paradigm, enabling agents to transcend single-turn interactions and conduct complex, long-horizon investigations by governing the information lifecycle. Through the interdependent operations of consolidation, indexing, updating, and forgetting, the DR system maintains the context and coherence essential for an iterative research loop. Consequently, a sophisticated memory framework is what fundamentally distinguishes a DR agent from a simple RAG system, equipping it with the consistency, adaptability, and self-evolution necessary to autonomously synthesize comprehensive, trustworthy, and verifiable reports from a vast and dynamic information landscape.\n\n# 3.4. Answer Generation\n\nDefinition. Answer generation typically represents the culminating stage of a DR system. It synthesizes information from upstream components, such as query planning (Section 3.1), information acquisition (Section 3.3.1), and memory systems (Section 3.3.1), and generates a coherent, comprehensive, and well-supported response that accurately reflects the user's original intent.\n\nUnlike traditional text generation, the answer generation within an advanced DR workflow addresses complex challenges such as reconciling conflicting evidence, maintaining long-range coherence, and structuring outputs with transparent reasoning and proper citations. It has evolved from template-based generation [160] to sophisticated synthesis shown in Figure 6, which reflects the growing demand for trustworthy, explainable, and multimodal research outputs [167, 16]. To deconstruct this process, we will explore it across four progressive stages: beginning with the integration of diverse information sources, moving to the synthesis of evidence and maintenance of coherence, then structuring the reasoning and narrative, and finally, advancing to the frontier of cross-modal generation.\n\n# 3.4.1. Integrating Upstream Information\n\nDefinition. The main principle of trustworthy answer generation is to ensure that every statement is grounded in verifiable external evidence. Thus, the first stage of answer generation is integrating information from its upstream components, including: the sub-queries from the query planning, the ranked and potentially conflicting evidence, and the evolving contextual state stored in memory.\n\nRecent developments in this area demonstrate sophisticated strategies for integrating upstream information, moving from simple evidence-feeding to dynamic, state-aware synthesis. The most common approach involves integrating ranked evidence from the retrieval module. Frameworks like Self-RAG [9], for example, employ a more dynamic integration by adaptively retrieving passages on demand. It then generates reflection tokens to assess the relevance of the retrieved information and its own generation, effectively integrating an internal self-correction mechanism to steer the synthesis. Moving beyond static evidence, more advanced systems integrate the query plan with an evolving memory state to ensure long-range coherence, a paradigm known as Stateful Query Planning. For instance, graph-centric frameworks like Plan-on-Graph (PoG) [30] explicitly integrate the plan with a dynamic memory (storing sub-goal status, explored paths, and retrieved entities). This memory is then actively used during a reflection step to guide and self-correct subsequent planning, tightly coupling the reasoning state with the generation process. Similarly, search-based frameworks like MCTS-OPS [435] formalize this by treating the MCTS tree itself as the state of the evolving query\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/ca14f5e5740622790f5c5db025669990dd38cb1b3038681b63f85cd75315c2b0.jpg)  \nFigure 6: Illustrating the schematic of the answer generation process in DR. The workflow begins by integrating upstream information, moves to synthesizing evidence and ensuring coherence, then constructs a structured narrative via reasoning, and culminates in a multimodal presentation output.\n\nplan. Here, the system integrates its experiential memory (node values from past rollouts) to guide the SELECTION and EXPANSION of the next planning step, ensuring the final answer synthesizes the full context of the problem-solving process.\n\nWhile these architectures provide a robust foundation, the core challenges of synthesizing contradictory evidence and maintaining long-form coherence remain the next frontier.\n\n# 3.4.2. Synthesizing Evidence and Maintaining Coherence\n\nProducing answers to research-level questions requires resolving informational conflicts and sustaining coherent, information-dense narration across extended outputs.\n\n**Resolving Conflicting Evidence.** Research queries frequently surface contradictory sources, requiring the model to discriminate among varying levels of reliability. Building on fact-verification paradigms [339], recent systems adopt three major strategies.\n\n- Credibility-Aware Attention: Instead of treating all retrieved information equally, this approach intelligently weighs evidence based on its source. The system assigns a higher score to information coming from more credible sources (e.g., a top-tier scientific journal) compared to less reliable ones (e.g., an unverified blog) [56]. This allows the model to prioritize trustworthy information while still considering relevant insights from a wider range of sources [94].  \n- Multi-Agent Deliberation: This strategy simulates an expert committee meeting to debate the evidence. Frameworks like MADAM-RAG [350] employ multiple independent AI agents, each tasked with analyzing the retrieved documents from a different perspective. Each agent forms its own assessment and conclusion. Afterwards, a final meta-reasoning step synthesizes these\n\ndiverse viewpoints to forge a more robust and nuanced final answer, much like a panel of experts reaching a consensus [351].\n\n- Reinforcement Learning for Factuality: This method trains the generator through a trial-and-error process that rewards factual accuracy [313]. A representative approach is RioRAG [372], in which an LLM receives a positive reward when it generates statements that are strongly and consistently supported by the provided evidence. Conversely, it is penalized for making unsubstantiated claims or statements that contradict the source material, shaping the model to inherently prefer generating factually grounded and reliable answers.\n\nLong-form Coherence and Information Density. Another key challenge is ensuring Sustained Informational Accuracy. Research answers are often lengthy, and maintaining a logical thread while avoiding repetition or morbidity is non-trivial. Let  $L_{\\mathrm{model}}$  denote the maximum coherent length of a model's output, and  $L_{\\mathrm{SFT}}$  represent the average length of examples in its supervised fine-tuning dataset. SFT offers an intuitive approach to enhancing the long-form generation capabilities of large language models. However, LongWriter [12] empirically demonstrates that the maximum coherent length of a model's output often scales with the average length of its fine-tuning samples, which can be formally expressed as  $L_{\\mathrm{model}} \\propto L_{\\mathrm{SFT}}$  [12]. To address this, LongWriter focuses on systematic training for extended generation, while others use reflection-driven processes to iteratively improve consistency [399]. Additionally, RioRAG [372] introduces a length-adaptive reward function to promote information density, which penalizes morbidity that fails to add informational value, preventing reward hacking through morbidity. Together, these techniques shift the focus of generation from mere content aggregation toward credible, concise, and coherent synthesis, laying the groundwork for structured reasoning.\n\n# 3.4.3. Structuring Reasoning and Narrative\n\nThe research community's focus is shifting from the mere factual accuracy of DR systems to the crucial need for explainability and logical rigor in their answers. An opaque answer, which prevents users from tracing the underlying reasoning process, has significantly diminished utility in critical domains like scientific research [116, 201, 283]. Consequently, a significant line of work has emerged to enable models to generate structured reasoning processes rather than just monolithic final answers [376, 484, 99]. This trend is reflected in the design of most modern DeepResearch systems, which increasingly favor the explicit presentation of this structural information [418, 486].\n\nPrompt-based Chain-of-Thought. This foundational approach focuses on eliciting intermediate reasoning steps before producing a final answer. The most prominent technique is Chain-of-Thought (CoT) prompting [376], which can be formally expressed as  $\\mathcal{R} = \\mathrm{LLM}(\\mathrm{CoT - Prompt} + \\mathcal{Q} + \\mathrm{Evidence})$ . This method enhances both interpretability and multi-step reasoning performance. Its applicability has been broadened by extensions such as zero-shot CoT [162] and Least-to-Most prompting [484].\n\nExplicit Structural Planning. More advanced systems move beyond simple linear chains to formalize the structure of the entire answer. For instance, RAPID [99] formalizes this process into three stages: (i) outline generation; (ii) outline refinement through evidence discovery; and (iii) plan-guided writing, where the outline forms a directed acyclic graph to support complex, non-linear argumentation. Similarly, SuperWriter [399] extends this idea by decoupling the reasoning and text-production phases and optimizing the entire process via hierarchical Direct Preference Optimization.\n\nTool-Augmented Reasoning. This line of work enhances reasoning by dynamically interfacing with\n\nexternal resources. Representative work allows models to invoke external computational or retrieval tools dynamically, ensuring both analytic rigor and factual grounding [274, 254, 120, 385, 287].\n\n# 3.4.4. Presentation Generation\n\nThe frontier of answer generation extends beyond text, encompassing the integration of multimodal and structured information. Research questions increasingly demand answers that combine textual reasoning with visual, tabular, or auditory data, maintaining semantic and presentational coherence. Early breakthroughs such as BLIP-2 [172] and InstructBLIP [53] enable multimodal instruction-following by aligning vision-language embeddings. MiniGPT-4 [493] advances this by leveraging cross-modal attention to seamlessly integrate visual and textual evidence.\n\nRecently, a series of works have demonstrated higher presentation capabilities, signaling an evolution from content generation to presentation generation [430, 407, 504]. Existing work like MedConQA [403], LIDA [346], ChartGPT [441], and Urania [430] can synthesize data analyses into dynamic, interactive visualizations. Others work, including PresentAgent [149], Qwen2.5-Omni [147], and AnyToAny [507], generates synchronized audio narrations alongside text. More recently, PPTAgent [479] and Paper2Video [504] even extend to editable presentation generation, where full analytical reports are automatically transformed into slide decks with coordinated text, figures, and layout elements. At the leading edge, video-grounded agents [178, 383] retrieve or generate relevant visual footage, delivering answers through multimodal storytelling. As summarized in Table 2, while most DR systems still focus on textual synthesis with citations, only a handful, such as OpenAI DeepResearch [238] and H2O.ai DeepResearch [108], currently support comprehensive multimodal output. The emerging consensus suggests that rich, multi-format answer generation will soon become a standard expectation [408], bridging the gap between knowledge synthesis and human-centered presentation.\n\n# Takeaway\n\nAnswer generation represents the synthesis core of DR systems, integrating upstream information, reconciling conflicting evidence, and structuring coherent, evidence-grounded narratives. Recent advances, from credibility-aware attention and multi-agent deliberation to reinforcement learning for factuality, have enhanced both factual reliability and interpretability. Systems now move beyond content aggregation toward concise, logically structured synthesis supported by transparent reasoning frameworks such as Chain-of-Thought and plan-guided writing. Moreover, the frontier of answer generation extends into multimodal generation, where text, visuals, tables, and audio coalesce into rich, human-centered outputs. These developments mark a paradigm shift from generating text to generating explainable, trustworthy, and presentation-ready knowledge.\n\n# 4. Practical Techniques for Optimizing Deep Research Systems\n\nSo far, we have introduced the core components that constitute a typical DR system. Building on these foundation, we now delve into practical techniques for improving such DR systems in real-world settings. These techniques focus on how to flexibly coordinate and enhance the key components, with the goal of achieving more reliable and effective task completion. Below, we discuss three commonly used paradigms: workflow prompting, supervised fine-tuning, and agentic reinforcement learning. Workflow prompting typically relies on a carefully designed pipeline (aka., prompting engineering)\n\nTable 2: Comparing output capabilities of contemporary representative DR systems, where the indicates supported capability  \n\n<table><tr><td rowspan=\"2\">System</td><td colspan=\"5\">Content Generation</td><td colspan=\"3\">Structured Output</td><td colspan=\"3\">Advanced</td></tr><tr><td>Text</td><td>Image</td><td>Audio</td><td>Video</td><td>Pres.</td><td>Table</td><td>JSON</td><td>Code</td><td>Chart</td><td>GUI</td><td>Cite</td></tr><tr><td>Gemini DeepResearch [193]</td><td>■</td><td>■</td><td></td><td></td><td></td><td>■</td><td></td><td></td><td>■</td><td></td><td>■</td></tr><tr><td>Grok DeepSearch [400]</td><td>■</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>■</td></tr><tr><td>OpenAI DeepResearch [238]</td><td>■</td><td>■</td><td></td><td></td><td></td><td>■</td><td></td><td>■</td><td>■</td><td>■</td><td>■</td></tr><tr><td>AutoGLM [190]</td><td>■</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>■</td></tr><tr><td>H2O.ai DeepResearch [108]</td><td>■</td><td>■</td><td>■</td><td></td><td>■</td><td>■</td><td>■</td><td>■</td><td>■</td><td></td><td>■</td></tr><tr><td>Skywork DeepResearch [4]</td><td>■</td><td></td><td></td><td>■</td><td>■</td><td></td><td></td><td></td><td></td><td></td><td>■</td></tr><tr><td>Perplexity DeepResearch [3]</td><td>■</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>■</td></tr><tr><td>Manus [195]</td><td>■</td><td></td><td></td><td></td><td>■</td><td>■</td><td></td><td></td><td>■</td><td></td><td>■</td></tr><tr><td>OpenManus [239]</td><td>■</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>■</td><td></td><td>■</td></tr><tr><td>OWL (CAMEL-AI) [120]</td><td>■</td><td></td><td></td><td></td><td>■</td><td>■</td><td></td><td></td><td>■</td><td></td><td>■</td></tr><tr><td>SunaAI [2]</td><td>■</td><td></td><td></td><td></td><td>■</td><td>■</td><td></td><td></td><td>■</td><td></td><td></td></tr><tr><td>Alita [257]</td><td>■</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>■</td><td></td><td></td></tr></table>\n\nthat guides the agents. The latter two paradigms aim to train a specific DR agent capable of reasoning, retrieving information, and generating high-quality answers.\n\n# 4.1. Workflow Prompt Engineering\n\nDefinition. A simple yet effective way to build a DR system is to construct a complex workflow that enables collaboration among multiple agents. In the most common setting, an orchestration agent coordinates a team of specialized worker agents, allowing them to operate in parallel on different aspects of a complex research task. To illustrate the key principles and design considerations behind such a DR workflow, we introduce Anthropic Deep Research [337] as a representative example.\n\n# 4.1.1. Deep Research System of Anthropic\n\nAnthropic proposes a multi-agent Deep Research (DR) framework where a lead orchestrator coordinates multiple worker agents through structured, auditable interactions. The system transforms an open-ended research query into a complete workflow, from planning and delegation to synthesis and citation, under an explicit research budget controlling agent count, tool usage, and reasoning depth. We highlight several core points that enable the system's efficiency and reliability:\n\n- Query Stratification and Planning. The orchestrator first analyzes the semantic type and difficulty of the input query (e.g., depth-first vs. breadth-first) to determine research strategy and allocate a corresponding budget of agents, tool calls, and synthesis passes.  \n- Delegation and Scaling. Effort scales with complexity: from 1–2 agents for factual lookups to up to 10 or more for multi-perspective analyses, each assigned with clear quotas and stopping criteria to enable dynamic budget reallocation.  \n- Task Decomposition and Prompt Specification. The main query is decomposed into modular subtasks, each encoded as a structured prompt specifying objectives, output schema, citation policy, and fallback actions to ensure autonomy with accountability.  \n- Tool Selection and Evidence Logging. A central tool registry (e.g., web fetch, PDF parsing, calculators) is used following freshness, verifiability, and latency rules. Agents record all tool provenance in an evidence ledger for traceable attribution.  \n- Parallel Gathering and Interim Synthesis. Worker agents operate concurrently while the orchestrator monitors coverage, resolves conflicts, and launches micro-delegations to close residual gaps or\n\n![](/uploads/images/4b50e85d-a04b-4275-9800-d5ab160e071a/0175879da2b9b76cb2f6737a5096967d2f3c04ef215507c64596b957e5cf5073.jpg)  \nFigure 7: Comparisons among three types of data synthesis approaches, including: (i) Strong-to-Weak Distillation, (ii) Multi-Agent Distillation, and (iii) Iterative Self-Evolving. Each type is illustrated through the process of how agents perform tasks, learn, and refine their abilities.\n\ntrigger deeper reasoning where needed.\n\n- Final Report and Attribution. The orchestrator integrates verified findings into a coherent report, programmatically linking claims to sources and ensuring schema compliance, factual grounding, and transparent citation.\n\nOverall, Anthropic's system exemplifies a scalable, interpretable multi-agent research paradigm that achieves high-quality synthesis through modular delegation, explicit budgeting, and verifiable reasoning.\n\n# 4.2. Supervised Fine-Tuning\n\nDefinition. Supervised fine-tuning (SFT) is a widely adopted approach that trains models to imitate desired behaviors using input-output pairs under a supervised learning objective. Within DR, SFT is commonly employed as the cold start, e.g., a warm-up process, before online reinforcement learning [145, 182, 397, 300, 173]. It aims to endow agents with basic task-solving skills [252, 382].\n\nSince manual collection of expert trajectories is labor-intensive, costly, and difficult to scale, a key challenge lies in automatically constructing high-quality SFT datasets. This has been widely explored by prior work [367, 483, 336, 48]. Below, we categorize representative work into two main paradigms: (i) strong-to-weak distillation, distilling correct task-solving trajectories from powerful LLMs (e.g., GPT-5 and DeepSeek-V3.1) into smaller, weak models; and (ii) iterative self-evolution, iteratively fine-tuning the model on the dataset produced by itself, leading to a progressive improvement.\n\n# 4.2.1. Strong-to-weak Distillation\n\nDefinition. Strong-to-weak distillation transfers high-quality decision trajectories from a powerful teacher system to smaller, weaker student models. Early work predominantly uses a single LLM-based agent to synthesize trajectories; more recent research employs multi-agent teacher systems to elicit more diverse, higher-complexity trajectories. We detail these two lines of work below.\n\nSingle-agent distillation. Representative systems instantiate this pipeline in various ways. WebDancer [391] provides the agent with search and click tools. A strong non-reasoning model generates short CoT, while a large reasoning model (LRM) generates long CoT. The agent learns from both, using rejection sampling for quality control. WebSailor [174] uses an expert LRM to generate action-observation trajectories, then reconstructs short CoT with a non-reasoning model, ensuring the final reasoning chain is compact enough for long-horizon tasks. WebShaper [335] uses search and visit tools in a ReAct-style trajectory. It performs 5 rollouts per task and filters out repeated or speculative answers using a reviewing LLM. WebThinker [183] augments SFT with policy-gradient refinement and WebSynthesis [88] leverages a learned world model to simulate virtual web environments and employs MCTS to synthesize diverse, controllable web interaction trajectories entirely offline.\n\nMulti-agent distillation. Multi-agent distillation synthesizes training data using an agentic teacher system composed of specialized, collaborating agents (e.g., a planner, a tool caller, and a verifier), with the goal of transferring emergent problem-solving behaviors into a single end-to-end student model [93, 328]. This paradigm tends to produce diverse trajectories, richer tool-use patterns, and explicit self-correction signals.\n\nA representative work is MaskSearch [397], which constructs a multi-agent pipeline that includes a planner, a query rewriter, and an observer, generating 58k verified chain-of-thought trajectories. Similarly, Chain-of-Agents [180] builds on the expert multi-agent system OAgents [495] to synthesize task-solving trajectories, and after a four-stage filtering pipeline that removes trivial or incorrect cases, it yields 16,433 high-quality trajectories for agent training. More recently, AgentFounder [307] propose the agentic continual pre-training, which scales up the data generation process by constructing large-scale planning traces, tool-invocation sequences, and step-by-step reasoning data.\n\nComparing Two Types of Distillation. Single-agent distillation provides a simple and easy-to-deploy pipeline, but it is limited by the bias of a single teacher model and the relatively shallow nature of its synthesized trajectories [234, 199, 502, 220]. Such trajectories often emphasize token-level action sequences rather than higher-level reasoning, which can restrict the student model's generalization ability in complex tasks. In contrast, multi-agent distillation generates longer and more diverse trajectories that expand the action space to include strategic planning, task decomposition, iterative error correction, and self-reflection [489, 29]. This broader behavioral coverage equips student models with stronger capabilities for multi-step and knowledge-intensive reasoning [180].\n\nDespite these advantages, multi-agent distillation introduces notable trade-offs. The pipelines require careful system design, substantial inference cost, and dedicated infrastructure for logging and verification. Data quality can also be brittle as the system's sensitivity to prompting [256, 264, 280].\n\n# 4.2.2. Iterative Self-Evolving\n\nDefinition. Iterative self-evolving data generation is an autonomous, cyclic process in which a model continuously generates new training data to fine-tune itself, progressively enhancing its capabilities [367, 349, 447, 467].\n\nRepresentative Work. Early evidence that large language models can improve themselves comes from self-training methods [367, 443, 39], where a model bootstraps from a small set of seed tasks to synthesize instruction-input-output triples, filters the synthetic data, and then fine-tunes itself on the resulting corpus. These approaches deliver substantial gains in instruction following with minimal human supervision. Yuan et al. [443] further introduces self-rewarding language models,\n\nin which the model generates its own rewards through LLM-as-a-Judge prompting. More recently, Zhao et al. [467] extends this idea to the zero-data regime by framing self-play as an autonomous curriculum. The model creates code-style reasoning tasks, solves them, and relies on an external code executor as a verifiable environment to validate both tasks and solutions. In the context of DR, EvolveSearch [447] iteratively selects high-performing rollouts (i.e., task-solving trajectories) and re-optimizes the model on these data via supervised fine-tuning.\n\nAdvantages & Disadvantages. A key advantage of iterative self-evolving frameworks is their closed-loop design, where the model progressively improves its capabilities by tightly interleaving data generation with training. This autonomy enables scalable training without heavy reliance on external models or human annotations, and it allows exploration of data distributions that extend beyond handcrafted knowledge [367, 445, 443, 298, 76].\n\nHowever, self-improvement also introduces significant risks. Previous studies have shown that, as iterations progress, distributional drift, reward hacking, and self-reinforcing errors may accumulate and degrade data quality, potentially leading to training collapse [293, 294, 114]. In addition, without robust validation mechanisms, the process may converge prematurely to narrow modes with limited performance ceilings [5, 15, 61, 18].\n\n# 4.3. End-to-End Agentic Reinforcement Learning\n\nDefinition. In this section, we dive into the application of end-to-end agentic reinforcement learning (RL) in DR, i.e., using RL algorithms to incentivize DR agents that can flexibly plan, act, and generate a final answer. We start with a brief overview, including commonly used RL algorithms and reward design for optimizing DR systems. For a clear explanation, we provide a glossary table in Table 3 to formally introduce the key variable in this section 4.3. Then we discuss two training practices: (i) specific module optimization and (ii) entire pipeline optimization.\n\n# 4.3.1. Preliminary\n\nRL algorithms in Deep Research. In DR, LLMs are trained to act as autonomous agents that generate comprehensive reports through complex query decomposition, multi-step reasoning, and extensive tool use. The primary RL algorithms used to train these agents include Proximal Policy Optimization (PPO) from OpenAI [276, 236], Group Relative Policy Optimization (GRPO) from DeepSeek [279, 105], and their variants [437].\n\nProximal Policy Optimization. PPO [276] is a clipped policy-gradient method that constrains updates within a trust region [242]. Given a current policy  $\\pi_{\\theta}$  and a old policy  $\\pi_{\\theta_{\\mathrm{old}}}$ , the objective is to maximize the clipped surrogate:\n\n$$\nL ^ {\\mathrm {P P O}} (\\theta) = \\mathbb {E} _ {t} \\left[ \\min  \\left(r _ {t} (\\theta) \\hat {A} _ {t}, \\operatorname {c l i p} \\left(r _ {t} (\\theta), 1 - \\epsilon , 1 + \\epsilon\\right) \\hat {A} _ {t}\\right) \\right], \\tag {1}\n$$\n\n$$\nr _ {t} (\\theta) = \\frac {\\pi_ {\\theta} \\left(o ^ {t} \\mid s _ {t}\\right)}{\\pi_ {\\theta_ {\\mathrm {o l d}}} \\left(o ^ {t} \\mid s _ {t}\\right)}. \\tag {2}\n$$\n\nwhere  $\\epsilon$  bounds the policy update and  $\\hat{A}_t$  is the estimated advantage. The advantage is computed using discounted returns or generalized advantage estimation (GAE) [275] as:\n\n$$\n\\hat {A} _ {t} = \\sum_ {l = 0} ^ {T - t} \\gamma^ {l} \\cdot r _ {t + l} + \\gamma^ {T - t + 1} \\cdot V _ {\\phi} (s _ {T + 1}) - V _ {\\phi} (s _ {t}). \\tag {3}\n$$\n\nTable 3: Summary of key notations used in proximal policy optimization and group-relative policy optimization algorithms.  \n\n<table><tr><td>Symbol</td><td>Definition</td><td>Description</td></tr><tr><td>πθ</td><td>Current policy</td><td>Parameterized LLM policy that generates actions (tokens or sequences) conditioned on a given state.</td></tr><tr><td>πθold</td><td>Reference (old) policy</td><td>A frozen snapshot of the policy before the current update, used for computing probability ratios and ensuring stable optimization.</td></tr><tr><td>q</td><td>Input query</td><td>Input question or prompt to the agent.</td></tr><tr><td>o</td><td>Model output</td><td>Final answer produced by the policy model.</td></tr><tr><td>o^t</td><td>Action at step t</td><td>The token generated by the policy model conditioned on state st.</td></tr><tr><td>st</td><td>State at step t</td><td>Context of the policy model at time step t.</td></tr><tr><td>R(o|·)</td><td>Reward function</td><td>Scalar score assigned to output o for the input query q.</td></tr><tr><td>rt(θ)</td><td>Probability ratio</td><td>Ratio between current and reference policy probabilities, computed as πθ(ot|st)/πθold(ot|st).</td></tr><tr><td>ε</td><td>Clipping threshold</td><td>Stability constant that limits update magnitude in PPO or adds numerical robustness in GRPO.</td></tr><tr><td>G</td><td>Response group</td><td>A collection of multiple sampled responses corresponding to the same query st in GRPO.</td></tr><tr><td>m</td><td>Group size</td><td>The number of candidate responses in a response group G.</td></tr><tr><td>oj</td><td>j-th response in group</td><td>The j-th sampled output candidate among the m responses in group G.</td></tr></table>\n\nHere  $r_{t + l}$  denotes the immediate reward at time step  $t + l$ ,  $\\gamma \\in [0,1)$  is the discount factor balancing the importance of long-term and short-term returns;  $T$  is the terminal time step of the current trajectory (episode);  $s_{T + 1}$  is the next state used for bootstrapping after termination,  $V_{\\phi}(s_t)$  is the value function predicted by the value network parameterized by  $\\phi$ . We define the empirical return  $\\hat{R}_t$  purely from rewards as:\n\n$$\n\\hat {R} _ {t} = \\sum_ {l = 0} ^ {T - t} \\gamma^ {l} r _ {t + l}, \\tag {4}\n$$\n\nwhich represents the cumulative discounted rewards from time step  $t$  until the end of the episode. In PPO, the value function parameters  $\\phi$  are updated by minimizing the squared error between the predicted value and the empirical return:\n\n$$\n\\mathcal {L} ^ {\\text {v a l u e}} (\\phi) = \\frac {1}{2} \\mathbb {E} _ {t} \\left[ \\left(V _ {\\phi} \\left(s _ {t}\\right) - \\hat {R} _ {t}\\right) ^ {2} \\right]. \\tag {5}\n$$\n\nGroup Relative Policy Optimization. Group Relative Policy Optimization (GRPO) [279] extends PPO by normalizing rewards within groups of responses to the same query. Formally, given a group  $\\mathcal{G}$  of  $m$  responses  $\\{o_1,o_2,\\ldots ,o_m\\}$  sampled for the same query  $s_t$ , each response is assigned a scalar reward  $R_{j}$ . The group-relative advantage for the  $j$ -th response is:\n\n$$\n\\hat {A} _ {j} ^ {\\mathcal {G}} = \\frac {\\mathcal {R} _ {j} - \\operatorname {m e a n} \\left(\\left\\{\\mathcal {R} _ {i} \\mid i \\in [ m ] \\right\\}\\right)}{\\operatorname {s t d} \\left(\\left\\{\\mathcal {R} _ {i} \\mid i \\in [ m ] \\right\\}\\right) + \\epsilon}, \\tag {6}\n$$\n\nwhere  $\\mathrm{mean}_{\\mathcal{G}}$  and  $\\mathrm{std}_{\\mathcal{G}}$  denote the mean and standard deviation of rewards within group  $\\mathcal{G}$ , and  $\\epsilon$  prevents numerical instability when the variance is small. The GRPO objective mirrors PPO's clipping mechanism but replaces  $\\hat{A}_t^{\\mathcal{G}}$  with the group-relative advantage  $\\hat{A}_j^{\\mathcal{G}}$ :\n\n$$\n\\mathcal {L} ^ {\\mathrm {G R P O}} (\\theta) = \\mathbb {E} \\left[ \\frac {1}{| \\mathcal {G} |} \\sum_ {j = 1} ^ {| \\mathcal {G} |} \\min  \\left\\{\\frac {\\pi_ {\\theta} (o _ {j} \\mid q)}{\\pi_ {\\theta_ {\\mathrm {o l d}}} (o _ {j} \\mid q)} \\hat {A} _ {j} ^ {\\mathcal {G}}, \\operatorname {c l i p} \\left(\\frac {\\pi_ {\\theta} (o _ {j} \\mid q)}{\\pi_ {\\theta_ {\\mathrm {o l d}}} (o _ {j} \\mid q)}, 1 - \\epsilon , 1 + \\epsilon\\right) \\hat {A} _ {j} ^ {\\mathcal {G}} \\right\\} \\right]. \\tag {7}\n$$\n\nComparison between PPO and GRPO in Deep Research. In PPO, each sampled output is optimized using an advantage signal derived from a value model. While this approach is effective, its performance is highly reliant on accurate value estimation and requires additional resources for training the value model. In contrast, GRPO optimizes by contrasting each response against others within the same group. This shifts the focus to a relative-quality comparison among competing hypotheses, simplifying implementation while maintaining strong performance.\n\nReward Design in Deep Research Agents. During the RL training of DR agents, the reward model, denoted as  $\\mathcal{R}(\\cdot)$ , assesses the quality (e.g., correctness) of the agents' outputs and produces scalar signals to enable policy optimization algorithms such as PPO and GRPO. Reward design takes a critical role in training LLM. There are two common reward design paradigms in DR systems, i.e., rule-based rewards and LLM-as-judge rewards.\n\n- Rule-based Rewards  $\\mathcal{R}_{\\text {rule }}(\\cdot)$ . Rule-based rewards are derived from deterministic, task-specific metrics such as Exact Match (EM) and F1 score [277]. In the context of research agents, EM is a commonly used binary score that indicates whether a generated answer perfectly matches a ground-truth string [156, 145, 144]. Alternatively, the F1 score (i.e., the harmonic mean of precision and recall calculated over token overlap) is also used to reward outputs [36, 37]. However, a key limitation of rule-based rewards is that they are primarily suited for tasks with well-defined, short-span ground truths (e.g., a specific entity name) and struggle to evaluate multi-answer or open-ended questions effectively.  \n- LLM-as-judge Rewards  $\\mathcal{R}_{LLMs}(\\cdot)$ . The LLM-as-judge approach uses an external LLM to evaluate the quality of an agent's output and assign a scalar score based on a predefined rubric [7]. Formally, for an output  $o$  to an input query  $q$ , the reward assigned by an LLM judge  $\\phi$  can be formulated as:\n\n$$\n\\mathcal {R} _ {\\mathrm {L L M s}} (o \\mid q) = \\mathbb {E} _ {\\text {c r i t e r i a} \\in \\mathcal {C}} [ \\phi (o, q, \\text {c r i t e r i a}) ]\n$$\n\nwhere  $\\mathcal{C}$  is the set of evaluation criteria (e.g., accuracy, completeness, citation quality, clarity, etc) and  $\\phi(\\cdot)$  returns a scalar score for each criterion.\n\n# 4.3.2. End-to-end Optimization of a Specific Module\n\nDefinition. End-to-end optimization of a specific module focuses on applying RL techniques to improve individual components within a DR system, such as the query planning, document ranking, or planning modules.\n\nRepresentative work. Within DR, most existing work trains the query planner [134, 499, 492, 192] while freezing the parameters, leaving components such as retrieval. MAO-ARAG [37] treats DR as a multi-turn process where a planning agent orchestrates sub-agents for information seeking. PPO propagates a holistic reward (e.g., final F1 minus token and latency penalties) across all steps,\n\nenabling end-to-end learning of the trade-offs between answer quality and computational cost. AI-SearchPlanner [213] decouples a lightweight search planner from a frozen QA generator. PPO optimizes the planner with dual rewards: an outcome reward for improving answer quality and a process reward for reasoning rationality. A Pareto-regularized objective balances utility with real-world cost, guiding the planner on when to query or stop.\n\nAdvantages & Disadvantages. Single-module optimization usually focuses on training a single core component (e.g., the planning module) while keeping the others fixed. Optimizing this critical module can improve the performance of a DR system by enabling more accurate credit assignment, more sophisticated algorithm design for the target module, and reduced training data and computational costs. However, this approach restricts the optimization space and may be inadequate when other frozen modules contain significant design or performance flaws.\n\n# 4.3.3. End-to-end Optimization of an Entire Pipeline\n\nDefinition. End-to-end pipeline optimization involves jointly optimizing all components and processes from input to output (e.g., query decomposition, search, reading, and report generation) to achieve the best overall performance across the DR workflow.\n\nRepresentative work on Multi-Hop Search. Some work focuses on enhancing the capability of multi-hop search by training the entire DR systems end-to-end [247, 300, 301, 481, 394]. For example, Jin et al. [145, 144] present Search-R1, the first work to formulate search-augmented reasoning as a fully observable Markov Decision Process and to optimize the entire pipeline via RL, containing query planning, retrieval, and extracting the final answer. By masking retrieved tokens in the policy-gradient loss, the model learns to autonomously decide when and what to search while keeping the training signal on its own generated tokens. Meanwhile, Song et al. [300] introduces R1-Searcher, a two-stage RL method in which the DR agent learns when to invoke external searches and how to use retrieved knowledge via outcome rewards. However, it has been observed that pure RL training often leads to over-reliance on external retrieval, resulting in over-searching [301]. To mitigate this issue, R1-Searcher++ [301] first cold-starts the DR agent via an SFT, then applies a knowledge-assimilation RL process to encourage the agent to internalize previously retrieved documents and avoid redundant retrievals.\n\nBesides the above early effort, recent work extends the naive Search-R1 by integrating multi-reward signals or improving the training environment. For the reward design, R-Search [468] trains models to decide when to retrieve and how to integrate external knowledge in both single-hop and multi-hop question answering. The framework improves answer quality and evidence reliability by optimizing reasoning-search trajectories under a multi-objective reward design. For the training environment, ZeroSearch [311] and  $O^2$ -Searcher [212] simulate a search engine to develop retrieval capabilities without accessing the actual web, providing a more controllable setting for RL training. In contrast, DeepResearcher [481] operates directly in real-world web environments, learning to plan, search, verify, and autonomously answer open-domain questions.\n\nBesides a basic document retrieval tool, some work also integrates additional information-seeking tools, teaching the DR agent to flexibly combine them. MMSearch-R1 [394] stands out as the first RL-trained multimodal model that learns when and how to search the text or image from the web on demand. HierSearch [324] introduces a hierarchical DR framework for enterprise scenarios that involve both local and web knowledge sources. Other work [200, 247, 110] integrates knowledge\n\ngraphs into DR agents to achieve efficient multi-hop reasoning.\n\nRepresentative work on Long-Chain Web Search. Besides the relatively simple multi-hop QA tasks, more recent work also applies end-to-end pipeline optimization to address longer-chain web search problems. Prior works, such as WebDancer [391], WebSailor [174], and Kimi-K2 [338], have focused on advancing more intricate multi-hop tasks, including GAIA [215] and BrowseComp [378]. These approaches combine data synthesis with end-to-end reinforcement learning training, thereby enabling more extensive iterations in the DR process.\n\nFurthermore, Gao et al. [85] presents ASearcher, which scales end-to-end RL to extreme long-horizon search. A fully asynchronous RL engine removes the 10-turn ceiling that plagued earlier systems, allowing trajectories of  $40+$  turns and  $150\\mathrm{k}$  tokens to be optimized without blocking GPU updates. Coupled with an autonomous QA-synthesis agent that injects noise and fuzzes questions for difficulty, the whole pipeline is operated end-to-end, from synthetic data creation to multi-turn policy optimization. SimpleDeepSearcher [314] leverages real-web simulation and distilled SFT to deliver agentic search capability without heavy RL, yet stays fully compatible with lightweight RL refinement. WebAgent-R1 [382] and DeepDiver [282] are training web agents through end-to-end multi-turn RL algorithms.\n\nIn addition, some works [180, 63, 64, 62] have studied Deep Research systems across multiple tool-calling scenarios. For example, Li et al. [180] introduces Chain-of-Agents (CoA), a novel paradigm that distills the capabilities of multi-agent systems into a single LLM. CoA enables native, end-to-end complex problem-solving by dynamically orchestrating multiple role-playing and tool agents within one model. Through multi-agent distillation and agentic RL, the authors train Agent Foundation Models (AFMs) in an end-to-end approach that achieves excellent performance on diverse web search benchmarks, while significantly reducing computational overhead compared to traditional multi-agent systems. Tool-Star [63] and ARPO [64] investigate how to effectively leverage tools in long-horizon tasks such as Deep Research, and use the GRPO algorithm to optimize the entire pipeline end-to-end. Additionally, AEPO [62] further improves rollout efficiency and, based on ARPO, optimizes both performance and efficiency for the end-to-end tool-use pipeline.\n\nAdvantages & Disadvantages. These end-to-end methods model the entire DR system as a multi-turn search process, achieving comprehensive optimization across reasoning, query rewriting, knowledge retrieval, tool invocation, and answer generation. This modeling and optimization approach is not only flexible but also allows for different objectives to be emphasized through the design of reward functions. However, these methods also have drawbacks, including sparse rewards, excessively long responses, and unstable training. Continuous optimization is needed to further enhance the effectiveness, stability, and efficiency of DR systems.\n\n# Takeaway\n\n- RL Algorithms: PPO provides stable updates based on absolute rewards, while GRPO leverages group-relative advantages to reduce resource requirements.  \n- Specific Module End-to-End Optimization: Targets a critical component (e.g., planner or searcher) for RL training, improving overall performance at lower cost, though limitations in other frozen modules cannot be addressed.  \n- Entire Pipeline End-to-End Optimization: Optimizes the full DR workflow, including retrieval, reasoning, tool use, and answer generation, yielding holistic gains but facing sparse rewards, long outputs, and training instability.\n\n# 5. Evaluation of Deep Research System\n\nDR techniques have been applied to a wide range of downstream tasks, including healthcare [7], financial report generation [342], and survey generation [366]. In this section, we systematically review common benchmarks and evaluation protocols for DR systems across three representative scenarios: (i) information seeking, (ii) report generation, and (iii) AI for research. These scenarios reflect the most prevalent applications of DR agents. Each category poses distinct challenges, illuminating the limitations of current systems while offering practical insights to guide future advances.\n\n# 5.1. Agentic Information Seeking\n\nEvaluating the effectiveness of agentic information-seeking is a critical component of assessing DR systems. In DR scenarios, information seeking is not a single QA task but a multi-stage, iterative, and cross-domain process in which agents must continuously explore, reformulate, and synthesize information from diverse sources. To capture this complexity, benchmark design has evolved from early static single-hop retrieval tasks such as Natural Questions (NQ) [165] to dynamic web environments requiring multi-hop reasoning and complex interactions, e.g., BrowseComp [378] and HotpotQA [425]. In this section, we review representative benchmarks and evaluation frameworks along two dimensions: query complexity and interaction environment complexity.\n\nTable 4: Comprehensive overview of existing and emerging benchmarks for Deep Research Systems that focus on question answering scenarios.  \n\n<table><tr><td>Benchmark (with link)</td><td>Date</td><td>Aspect</td><td>Data size (train/dev/test)</td><td>Evaluation metrics</td></tr><tr><td>NQ</td><td>2019</td><td>QA</td><td>307373/7830/7842</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>SimpleQA</td><td>2024</td><td>QA</td><td>4,326</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>HotpotQA</td><td>2019</td><td>QA</td><td>90124 / 5617 / 5813</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>2WikiMultihopQA</td><td>2020</td><td>QA</td><td>167454/12576/12576</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>Bamboogle</td><td>2023</td><td>QA</td><td>8600</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>MultiHop-RAG</td><td>2024</td><td>QA</td><td>2556</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>MuSiQue</td><td>2022</td><td>QA</td><td>25K</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>GPQA</td><td>2023</td><td>QA</td><td>448</td><td>Accuracy</td></tr><tr><td>GAIA</td><td>2023</td><td>QA</td><td>450</td><td>Exact Match</td></tr><tr><td>BrowseComp</td><td>2025</td><td>QA</td><td>1266</td><td>Exact Match</td></tr><tr><td>BrowseComp-Plus</td><td>2025</td><td>QA</td><td>830</td><td>Accuracy / Recall / Search Call / Calibration Error</td></tr><tr><td>HLE</td><td>2025</td><td>QA</td><td>2500</td><td>Exact Match / Accuracy</td></tr></table>\n\n# 5.1.1. Complex Queries\n\nThe evolution of benchmarks for agentic information seeking has closely followed the increasing complexity of query demands. Early benchmarks such as NQ [165], TriviaQA [151], and SimpleQA [377] established the foundation for question answering research. These datasets focused on single-hop queries, where answers could be retrieved with a single lookup or were already contained within the LLM's parameters. While such tasks provided a controlled starting point, they could not capture the reasoning and synthesis required in DR.\n\nTable 5: Comprehensive overview of existing and emerging benchmarks for Deep Research Systems that focus on more boarder scenarios.  \n\n<table><tr><td>Benchmark (with link)</td><td>Date</td><td>Aspect</td><td>Data size (train/dev/test)</td><td>Evaluation metrics</td></tr><tr><td>FRAMES</td><td>2024</td><td>QA</td><td>824</td><td>Exact Match / F1 / Accuracy</td></tr><tr><td>InfoDeepSeek</td><td>2025</td><td>QA</td><td>245</td><td>Accuracy / Utilization / Compactness</td></tr><tr><td>AssistantBench</td><td>2025</td><td>QA</td><td>214</td><td>F1 / Similarity</td></tr><tr><td>Mind2Web</td><td>2025</td><td>QA</td><td>2350</td><td>Accuracy / F1 / Step Success Rate</td></tr><tr><td>Mind2Web 2</td><td>2025</td><td>QA</td><td>130</td><td>Agent-as-a-Judge</td></tr><tr><td>Deep Research Bench</td><td>2025</td><td>QA</td><td>89</td><td>Precision / Recall / F1</td></tr><tr><td>DeepResearchGym</td><td>2025</td><td>QA</td><td>96,000</td><td>Report Relevance / Retrieval Faithfulness / Report Quality</td></tr><tr><td>WebArena</td><td>2024</td><td>Complex Task</td><td>812</td><td>Correctness</td></tr><tr><td>WebWalkerQA</td><td>2025</td><td>QA</td><td>680</td><td>Accuracy / Action Count</td></tr><tr><td>WideSearch</td><td>2025</td><td>QA</td><td>200</td><td>LLM Judge</td></tr><tr><td>MMInA</td><td>2025</td><td>Complex Task</td><td>1050</td><td>Success Rate</td></tr><tr><td>AutoSurvey</td><td>2024</td><td>Survey Generation</td><td>530,000</td><td>Citation Quality / Content Quality</td></tr><tr><td>ReportBench</td><td>2025</td><td>Survey Generation</td><td>600</td><td>Content Quality / Cited Statement / Non-Cited Statements</td></tr><tr><td>SurveyGen</td><td>2025</td><td>Survey Generation</td><td>4200</td><td>Topical Relevance / Academic Impact / Content Diversity</td></tr><tr><td>Deep Research Comparator</td><td>2025</td><td>Report Generation</td><td>176</td><td>BradleyTerry Score</td></tr><tr><td>DeepResearch Bench</td><td>2025</td><td>Report Generation</td><td>100</td><td>LLM Judge</td></tr><tr><td>ResearcherBench</td><td>2025</td><td>Report Generation</td><td>65</td><td>Rubric Assessment / Factual Assessment</td></tr><tr><td>LiveDRBench</td><td>2025</td><td>Report Generation</td><td>100</td><td>Precision / Recall / F1</td></tr><tr><td>PROXYQA</td><td>2025</td><td>Report Generation</td><td>100</td><td>LLM Judge</td></tr><tr><td>SCHOLARQABENCH</td><td>2025</td><td>Report Generation</td><td>2967</td><td>Accuracy / Citations / Rubrics</td></tr><tr><td>Paper2Poster</td><td>2025</td><td>Poster Generation</td><td>100</td><td>Visual Quality / Textual Coherence / VLM Judge</td></tr><tr><td>PosterGen</td><td>2025</td><td>Poster Generation</td><td>10</td><td>Poster Content / Poster Design</td></tr><tr><td>P2PInstruct</td><td>2025</td><td>Poster Generation</td><td>121</td><td>LLM Judge</td></tr><tr><td>Doc2PPT</td><td>2022</td><td>Slides Generation</td><td>6000</td><td>ROUGE / Figure Subsequence / Text-Figure Relevance</td></tr><tr><td>SLIDESBENCH</td><td>2025</td><td>Slides Generation</td><td>7000/0/585</td><td>Text / Image / Layout / Color / LLM Judge</td></tr><tr><td>Zenodo10K</td><td>2025</td><td>Slides Generation</td><td>10,448</td><td>Content / Design / Coherence</td></tr><tr><td>TSBench</td><td>2025</td><td>Slides Generation</td><td>379</td><td>Editing Success / Efficiency</td></tr><tr><td>AI Idea Bench</td><td>2025</td><td>Idea Generation</td><td>0/0/3495</td><td>LLM Judge</td></tr><tr><td>Scientist-Bench</td><td>2025</td><td>Idea Generation, Experimental Execution</td><td>0/0/52</td><td>LLM Judge, Human Judge</td></tr><tr><td>PaperBench</td><td>2025</td><td>Experimental Execution</td><td>0/0/20</td><td>LLM Judge</td></tr><tr><td>ASAP-Review</td><td>2021</td><td>Peer Review</td><td>0/0/8877</td><td>Human / ROUGE / BERTScore</td></tr><tr><td>DeepReview</td><td>2025</td><td>Peer Review</td><td>13378/0/1286</td><td>LLM Judge</td></tr><tr><td>SWE-Bench</td><td>2023</td><td>Software Engineering</td><td>0/0/500</td><td>Environment</td></tr><tr><td>ScienceWorld</td><td>2022</td><td>Scientific Discovery</td><td>3600/1800/1800</td><td>Environment</td></tr><tr><td>GPT-Simulator</td><td>2024</td><td>Scientific Discovery</td><td>0/0/76369</td><td>LLM Judge</td></tr><tr><td>DiscoveryWorld</td><td>2024</td><td>Scientific Discovery</td><td>0/0/120</td><td>LLM Judge</td></tr><tr><td>CORE-Bench</td><td>2024</td><td>Scientific Discovery</td><td>0/0/270</td><td>Environment</td></tr><tr><td>MLE</td><td>2024</td><td>Machine Learning Engineering</td><td>0/0/75</td><td>Environment</td></tr><tr><td>RE-Bench</td><td>2024</td><td>Machine Learning Engineering</td><td>0/0/7</td><td>Environment</td></tr><tr><td>DSBench</td><td>2024</td><td>Data Science</td><td>0/0/540</td><td>Environment</td></tr><tr><td>Spider2-V</td><td>2024</td><td>Data Science</td><td>0/0/494</td><td>Environment</td></tr><tr><td>DSEval</td><td>2024</td><td>Data Science</td><td>0/0/513</td><td>LLM Judge</td></tr><tr><td>UnivEARTH</td><td>2025</td><td>Earth Observation</td><td>0/0/140</td><td>Exact Match</td></tr><tr><td>Commit0</td><td>2024</td><td>Software Engineering</td><td>0/0/54</td><td>Unit test</td></tr></table>\n\nAs research questions grew more complex, benchmarks evolved from simple fact retrieval to multi-step reasoning challenges. Multi-hop QA datasets assess an agent's ability to reformulate queries and build reasoning chains across documents. HotpotQA [425], one of the earliest and most widely used multi-hop datasets, requires reasoning across multiple Wikipedia articles using supporting facts to derive the answer. 2WikiMultihopQA [115] extends this by integrating information from two\n\nseparate Wikipedia pages per question, emphasizing cross-document reasoning. Bamboogle [251] consists of 125 two-hop questions generated from random Wikipedia articles, testing the ability to decompose and reason over complex queries. MultiHop-RAG [332] is the RAG dataset designed specifically for multi-hop queries, categorizing questions into four types: inference, comparison, temporal, and null queries. MuSiQue [344] adopts a bottom-up approach, systematically pairing composable single-hop questions where one reasoning step depends on another. FRAMES [163] simulates realistic multi-document queries to evaluate an LLM's ability to retrieve relevant facts, reason accurately, and synthesize information into coherent responses. However, most of these benchmarks rely on structured, linear reasoning paths, which fall short of reflecting the inherent ambiguity and branching, non-linear exploration required in real-world research scenarios.\n\nRecent benchmarks have begun to capture this growing complexity, placing greater emphasis on the in-depth and progressive exploration of complex topics. For instance, GPQA [265] is a graduate-level dataset in physics, chemistry, and biology that tests both domain experts and skilled non-experts, requiring extensive reasoning and problem-solving. Similarly, GAIA [215] provides 466 carefully designed questions that require multi-step reasoning, real-world knowledge retrieval, and complex generation. HLE [249] aims to be a comprehensive, fully closed academic benchmark across dozens of disciplines, including mathematics, humanities, and natural sciences, designed to advance reasoning skills. Its questions cannot be quickly answered through an online search. These recent datasets challenge agents to operate in environments that better reflect the ambiguity, branching evidence paths, and iterative synthesis characteristic of real-world DR systems.\n\n# 5.1.2. Interaction Environment\n\nAs agent capabilities have advanced, evaluation based solely on static environments and fixed corpora is no longer sufficient. Consequently, a series of benchmarks has been developed to reflect the scale and dynamics of real-world web environments, requiring agents to interact with, navigate, and creatively explore web pages to obtain complex or hard-to-find information.\n\nSome studies have incorporated browsing tools such as Google and Bing into benchmarks, enabling agents to directly retrieve and extract information from the live web. For example, InfoDeepSeek [402] and AssistantBench [434] present challenging tasks that require agents to integrate multiple search and browsing tools in real-time web environments, testing their ability to operate dynamically. Mind2Web [57] replaces the overly simplified, simulated environments common in other datasets with authentic, dynamic, and unpredictable real-world websites, providing complete records of user interactions, webpage snapshots, and network traffic. Its successor, Mind2Web 2 [98], was subsequently introduced to more rigorously evaluate agent-based search systems on realistic, long-horizon tasks that involve live web search and browsing. BrowseComp [378] and BrowseCompPlus [38] demand persistent navigation to locate hard-to-find, entangled information across multiple sites. Moreover, DeepResearchBench [17] offers a large-scale RetroSearch environment that reduces task degradation and network randomness while evaluating LLM agents on complex real-world web research tasks. DeepResearchGym [49] complements this by providing an open-source sandbox with a reproducible search API and a rigorous evaluation protocol, promoting transparency and reproducibility in DR area.\n\nBuilding on this trend, subsequent datasets have increasingly emphasized the authenticity and complexity of interactive environments. WebArena [488] provides a highly realistic and reproducible environment for language-guided agents, built from fully functional websites across four domains. WebWalkerQA [392] assesses LLMs' ability to systematically traverse website subpages and extract\n\nhigh-quality data through interactive actions such as clicking, specifically testing complex, multi-step web interactions. WideSearch [388] focuses on a critical yet under-evaluated task: requiring agents to thoroughly and accurately acquire all large-scale atomic information that meets a set of criteria and organize it into a structured output. MMInA [341] extends these challenges by providing a multi-hop, multi-modal benchmark for embodied agents performing integrated internet tasks on realistic, evolving websites, ensuring high realism and applicability to natural user tasks. Together, these benchmarks illustrate a clear trend: web-oriented evaluation environments are becoming increasingly human-like, visually grounded, diverse, complex, and realistic, pushing the limits of agentic information seeking and DR in dynamic, real-world settings.\n\n# 5.2. Comprehensive Report Generation\n\nAnother critical dimension in evaluating DR systems is their capacity to generate comprehensive reports. Unlike single-point answers or brief summaries, comprehensive reports require systems to integrate information from multiple sources and modalities into structured, logically coherent, and broadly informative outputs. This process involves information aggregation, content organization, factual consistency verification, and clarity of expression, and is therefore regarded as a core indicator of a DR system's overall capability. Below, we introduce the relevant benchmarks by task type.\n\n# 5.2.1. Survey Generation\n\nA closely related task is survey generation, which involves producing structured overviews or syntheses of a specific scientific topic by aggregating information from diverse sources. Thanks to the clear citation structure provided by gold-standard references, survey generation has been widely used to evaluate the capabilities of DR systems. AutoSurvey [366] gathers arXiv articles of varying lengths and uses a multi-LLM-as-judge framework to evaluate survey generation in terms of speed, citation quality, and content quality. Moreover, ReportBench [175] is a systematic benchmark for evaluating research reports generated by large language models. It focuses on two key aspects: the relevance of citations and the reliability and accuracy of the report's statements. The evaluation corpus is constructed using high-quality survey papers published on arXiv as the gold standard. SurveyGen [14] is another survey-generation dataset, containing over 4,200 human-written surveys with chapter-level structure, cited references, and rich metadata. It enables comprehensive evaluation of content quality, citation accuracy, and structural consistency.\n\n# 5.2.2. Long-Form Report Generation\n\nOther benchmarks focus on different types of report generation tasks and introduce alternative evaluation frameworks. For example, Deep Research Comparator [27] provides a unified evaluation platform for DR agents, enabling systematic assessment of long-form reports and their intermediate reasoning processes through side-by-side comparison, fine-grained human feedback, and ranking mechanisms. DeepResearch Bench [66] is a benchmark of 100 PhD-level research tasks, introducing two evaluation methods for generated reports: a reference-based assessment of overall quality and a citation-based evaluation of retrieval accuracy. ResearcherBench [413] comprises 65 research questions focused on evaluating the capabilities of advanced agent systems on cutting-edge AI science problems, using an evaluation framework that combines rubric assessment and factual evaluation. LiveDRBench [130] is a benchmark for DR tasks, offering challenging science and world-event queries and evaluating systems via intermediate reasoning steps and factual sub-propositions. PROXYQA [322] uses human-designed meta-questions and corresponding proxy questions to indirectly\n\nassess knowledge coverage and information richness, providing an objective measure of long-form text generation quality. SCHOLARQABENCH [8] is a benchmark for scientific literature synthesis tasks in multiple formats, comprising 2,967 expert-written queries and 208 long-form answers across the field of computer science. Evaluating research reports is particularly challenging because there is no single gold-standard answer, and multiple valid perspectives exist for assessing quality. The diversity of acceptable content, reasoning approaches, and presentation styles makes it difficult to define objective metrics. As a result, most benchmarks rely on LLM-as-judge methods [169], leveraging large language models' reasoning and knowledge to provide scalable, consistent, and nuanced evaluations of content quality, factual accuracy, citation relevance, and structural coherence.\n\n# 5.2.3. Poster Generation\n\nPoster generation can be viewed as a highly condensed and visually structured variant of the comprehensive report generation task. Unlike multi-page reports, a scientific poster is typically a single-page, high-density summary that concisely presents the research motivation, methodology, results, and conclusions in a format that is both navigable and visually engaging. For DR systems, this task imposes unique challenges: not only must the system aggregate and synthesize information from multiple heterogeneous sources, such as research papers, notes, and presentation slides, but it must also transform that content into an effective visual layout. Evaluation of poster generation typically focuses on three main aspects: factual completeness, visual communication effectiveness, and readability. For example, Paper2Poster [244] focuses exclusively on AI research papers. The dataset comprises 100 paper-poster pairs, covering 280 distinct topics across subfields. A comprehensive evaluation framework is introduced, comprising four key dimensions: visual quality, text coherence, VLM-based quality judgment, and PaperQuiz, which is a novel metric designed to assess how effectively a poster communicates the core knowledge of the original paper. PosterGen [464] adopts a two-dimensional evaluation protocol, dividing the assessment into poster content and poster design. It introduces a VLM-based metric to evaluate key design aspects, including layout balance, readability, and aesthetic consistency. P2PInstruct [315] is a large-scale instruction dataset for paper-to-poster generation, containing over 30,000 high-quality instruction-response pairs. It covers the full pipeline from image element processing and text generation to final layout formatting.\n\n# 5.2.4. Slides Generation\n\nSlide generation represents another critical pathway for evaluating the comprehensive capabilities of DR systems. This task challenges a system not only to comprehend and summarize large volumes of heterogeneous information sources, but also to transform the distilled content into a structured, slide-based presentation format. The objectives of slide generation encompass information distillation, logical structuring, and presentation-oriented expression, making it a strong indicator of a system's ability to coordinate across multiple dimensions. Common benchmark tasks and datasets for this evaluation often involve generating slides from meeting transcripts, research papers, long-form reports, or collections of web documents. These benchmarks typically assess whether a model can maintain content integrity and factual accuracy while performing high-quality information selection and organization. Doc2PPT [82] collects paired documents and their corresponding slide decks from academic proceedings. It conducts detailed post-processing for evaluation, using metrics such as Slide-Level ROUGE, Longest Common Figure Subsequence, Text-Figure Relevance, and Mean Intersection over Union. For Example, SLIDESBENCH [91] is a benchmark comprising 7,000 training examples and 585 test examples, derived from 310 slide decks across 10 distinct domains. It supports two types of evaluation: reference-based evaluation, which measures similarity to target (gold) slides,\n\nand reference-free evaluation, which assesses the design quality of the generated slides independently. Zhang et al. introduced Zenodo10K [478], a new dataset collected from Zenodo, a platform hosting diverse, openly licensed artifacts across various domains. They also proposed PPTEval [478], an evaluation framework leveraging GPT-4.0 as the judge to assess presentation quality along three dimensions: content, design, and coherence. TSBench [152] is a benchmark dataset specifically designed to evaluate the slide editing capabilities of models and frameworks. It includes 379 distinct editing instructions along with the corresponding slide modifications.\n\n# 5.3. AI for Research\n\nAI for Research seeks to harness artificial intelligence to advance scientific discovery, either by automating processes or by assisting researchers in accelerating their work [31]. Its applications and corresponding benchmarks include (i) idea generation, (ii) experimental execution, (iii) academic writing, and (iv) peer review. Unlike report generation, research goes beyond producing extended outputs; it requires the creation of new perspectives, conclusions, and knowledge, thereby necessitating mechanisms for evaluating novelty.\n\n# 5.3.1. Idea Generation\n\nA key challenge in research lies in generating genuinely novel ideas and, more importantly, in reliably assessing their novelty. Such evaluation is typically conducted by human experts, but it remains difficult and resource-intensive. Existing approaches generally fall into two categories. The first is human- or LLM-based evaluation. Si et al. [296] recruited over 100 NLP researchers to evaluate the novelty of ideas generated by humans, LLMs, and human-LLM collaboration. However, this process is not easily scalable and proves difficult even for domain experts. Moreover, they investigated LLMs' ability to assess novelty, finding that LLM judgments show lower agreement with expert reviewers than human evaluations. Li et al. [177] and Gao et al. [87] leverage LLMs through direct prompting to evaluate novelty. To enhance the reliability of LLMs' judgments, Lu et al. [196] and Su et al. [306] integrate LLMs with the Semantic Scholar API and web access, enabling them to evaluate ideas against related literature. AI Idea Bench 2025 [258] provides a benchmark for quantifying and comparing ideas generated by LLMs. It incorporates 3,495 representative papers published in AI-related conferences after October 10, 2023, together with their corresponding inspiration papers. Furthermore, it introduces an evaluation framework to assess whether the ideas derived from inspiration papers are consistent with the ground-truth papers. The second category is density-based evaluation, which relies on the absolute local density in the semantic embedding space to measure novelty. Wang et al. [365] introduces the Relative Neighbor Density (RND) algorithm, which evaluates novelty by examining the distributional patterns of semantic neighbors rather than relying solely on absolute local density. Moreover, they construct large-scale semantic embedding databases for novelty assessment, encompassing more than 30 million publications across two distinct domains.\n\n# 5.3.2. Experimental Execution\n\nEvaluation of experimental execution typically involves both objective and subjective assessments. Objective evaluation generally emphasizes the outcomes produced in specific environments, such as benchmark performance or compiler outputs. For example, Lu et al. [196] and Weng et al. [386] directly adopt the results of downstream tasks as evaluation metrics, while Tang et al. [326] leverages compiler outputs to assist LLMs in refining experiments and correcting code errors. Subjective evaluation involves leveraging either humans or LLMs to assess the quality of experimental designs.\n\nFor example, Tang et al. [326] employs LLMs to compare code implementations with atomic research ideas, thereby verifying whether the code satisfies the intended requirements of the ideas. Starace et al. [304] employs LLMs to evaluate source code, documentation, and configuration files against human-designed rubrics to derive a final grade.\n\n# 5.3.3. Academic Writing\n\nThe evaluation of academic writing differs substantially from general report generation. It requires not only factual accuracy, logical coherence, and clarity, but also alignment with underlying ideas and experimental results, proper integration of citations from related work, and effective visualization of findings. To capture these multifaceted criteria, Lu et al. [196] employ LLMs to assess writing along dimensions such as originality, quality, clarity, and significance. Similarly, Hopner et al. [117] train a domain-specific LLM to predict citation counts and review scores as proxies for paper quality, addressing the limitations of generic LLMs in academic evaluation. Building on this direction, Starace et al. [304] introduce PaperBench, a benchmark designed to assess AI agents' ability to replicate AI papers. The benchmark includes 20 ICML 2024 Spotlight and Oral papers, and evaluates replication quality using LLMs guided by manually constructed rubrics that hierarchically decompose each task into graded subtasks. Tang et al. [326] propose Scientist-Bench, a comprehensive benchmark built from top-cited papers published between 2022 and 2024 across 16 research areas and multiple expertise levels. It evaluates dimensions such as technical novelty, methodological rigor, empirical validation, and potential impact, closely reflecting the criteria used in the ICLR review process. To further push the boundaries of scientific evaluation, Xu et al. [413] present ResearcherBench, a more challenging benchmark for evaluating DR systems, which consists of 65 research questions carefully curated from real-world scientific contexts across 35 AI subfields. They also propose a dual evaluation framework that combines rubric-based assessment to evaluate the quality of insights with factual evaluation that measures citation faithfulness and evidence coverage.\n\n# 5.3.4. Peer Review\n\nAI for peer review seeks to leverage an AI agent to generate feedback on scientific papers. However, evaluating such feedback is challenging, as reviews are typically lengthy and inherently subjective. Yuan et al. [442] introduced ASAP-Review, a large-scale benchmark that collects 8,877 AI papers from ICLR (2017–2022) via OpenReview and NeurIPS papers (2016–2019) via the official proceedings, along with their corresponding reviews. The dataset is annotated across multiple dimensions, including Motivation, Originality, Soundness, Substance, Replicability, Clarity, and Comparison. To evaluate generated reviews, they employ automatic metrics such as ROUGE and BERTScore [454], as well as human judgments. Lu et al. [196] collect 500 ICLR 2022 papers from OpenReview to establish a benchmark for the peer review task, subsequently employing self-reflection, few-shot examples, and response ensembling with LLMs to assess the quality of the generated reviews. Weng et al. [384] introduces the REVIEW-5k dataset, which contains 782 test samples collected from ICLR 2024. Each sample includes the paper title, abstract, LaTeX or Markdown source, and the corresponding review comments. The dataset also provides structured review information, including summaries, strengths and weaknesses, clarification questions, and review scores. For evaluation, they employ Proxy Mean Squared Error (Proxy MSE) and Proxy Mean Absolute Error (Proxy MAE), which leverage multiple independent reviews of the same submission as unbiased estimators of its true rating [305]. Similarly, Gao et al. [90] constructed REVIEWER2, a dataset comprising 27,805 papers and reviews collected from CONLL-16, ACL-17, COLING-20, ARR-22, ICLR-17–23, and NeurIPS-16–22. Zhu et al. [498] introduces DeepReview-Bench, a dataset of 1.2K ICLR 2024–2025 submissions collected\n\nfrom OpenReview. The dataset includes textual reviewer assessments, interactive rebuttal-stage discussions, and standardized scoring information. For quantitative evaluation, they employ MAE, MSE, accuracy, F1, and Spearman correlation, while qualitative evaluation is conducted under the LLM-as-a-judge paradigm [169, 100, 170] across five dimensions: constructive value, analytical depth, plausibility, technical accuracy, and overall quality.\n\n# 5.4. Software Engineering\n\nIn addition to the above scenarios, DR agents can also be applied to software engineering, representing a shift from assisting with isolated code snippets to autonomously executing complex software development tasks [186]. A pioneering work is SWE-Bench [141], a benchmark designed to evaluate whether AI agents can resolve real-world GitHub issues. Although SWE-Bench does not yet cover full end-to-end software development, it marks an important step toward bridging idealized benchmarks with practical scenarios. Meanwhile, DR agents have been deployed in a wide range of complex software engineering domains, including scientific discovery [359, 360, 129, 71, 297, 270, 318], machine learning experimentation [124, 26, 387, 179], data science [148, 23, 461], earth observation [154], and software library completion [472, 241].\n\n# 6. Challenges and Outlook\n\n# 6.1. Retrieval Timing\n\nAlthough determining when to retrieve has become a standard feature of various DR systems, several fundamental challenges remain. Existing DR systems, such as Search-R1 Jin et al. [145], rely too heavily on answer correctness to guide the entire search pipeline and lack fine-grained guidance on when to retrieve, leading to both over-retrieval and under-retrieval Wu et al. [396]. Moreover, even with continued retrieval, the model may still produce an incorrect answer, and when no relevant evidence can be retrieved, generating an answer regardless risks misleading users, particularly in safety-critical domains such as healthcare and finance.\n\nFuture research could explore fine-grained reward designs that assess, at each step, whether the model lacks the knowledge needed to answer the question [396] and whether relevant documents can be retrieved [374]. Such signals would help determine when retrieval is necessary. Beyond deciding when to retrieve, the system should also evaluate whether the model's post-retrieval answer is correct and, after completing the entire process, estimate the uncertainty of the final output to avoid misleading users.\n\n# 6.2. Memory Evolution\n\nDR systems aim to mimic the research process of human experts by integrating autonomous planning, multi-source information acquisition, dynamic memory management, and deep knowledge synthesis. However, existing memory modules face significant challenges in fulfilling this vision. To develop more capable and DR systems, it is essential to re-examine the role of memory and identify future directions in personalization, structurization, adaptivity, and goal-driven optimization [84, 136, 74].\n\n# 6.2.1. Proactive Personalization Memory Evolution\n\nRecap of previous work. Personalized memory in current systems often serves as a passive knowledge buffer, primarily designed to record user interaction histories and preferences for enhancing retrieval-based responses [457, 231]. While effective for maintaining conversational consistency, this potentially limits the agent to a reactive stance [231]. The memory's primary function is to serve as a repository of past events, such as the fine-grained, timestamped interactions stored in episodic memory or the consolidated user traits in semantic memory [368, 457]. Even advanced management techniques, such as the reflective mechanisms proposed by RMM [325], are chiefly focused on optimizing the organization and retrieval of this historical data to improve the relevance of future responses, rather than enabling forward-looking planning.\n\nA necessary paradigm shift is emerging, moving from memory as a historical archive to memory as a dynamic, predictive user model [231]. To transition from mere assistants to true collaborators, future agents must leverage memory to engage in proactive reasoning. The foundation for such a model is a comprehensive, multi-dimensional user profile, as conceptualized in benchmarks like PersonalLens, which integrates demographics, detailed cross-domain preferences, and summaries of past interactions to form a holistic view of the user [473]. Early steps in this direction can be seen in goal-oriented systems like MemGuide, which employs proactive reasoning by using the user's task intent and analyzing missing information slots to strategically filter memories [68]. The ultimate vision is for future memory modules to empower agents as proactive partners by capturing not only explicit preferences but also implicit signals, such as communication styles and latent intents. The PaRT framework exemplifies this future, using its dynamic user profile to actively guide conversations by generating personalized new topics and retrieving real-time external information [231]. A blueprint for the underlying architecture can be found in systems like MIRIX, whose multi-component design could support diverse proactive functions; for instance, its Procedural Memory could store workflows to anticipate a user's next steps in a complex task [368]. By integrating these capabilities, the system can anticipate user needs, proactively acquire and present relevant information, and adapt its interaction style in real time, thus shifting from reactive responses to proactive planning for more effective, intuitive, personalized support [231].\n\n# 6.2.2. Cognitive-Inspired Structured Memory Evolution\n\nThe predominant memory architecture in current systems (e.g., vector stores of text chunks) follows a flat storage paradigm, which lacks the capacity to capture deep logical or relational structures between knowledge elements. This architectural deficiency fundamentally hinders complex multihop reasoning, as the system cannot traverse explicit relationships between concepts. Recent work has begun to address this by moving towards structured representations like knowledge graphs, where entities are explicitly linked by semantic relationships, thereby providing a scaffold for more sophisticated inference [46, 411, 262]. Moreover, memory is often treated as a static snapshot, making it incapable of addressing the temporal dynamics of knowledge. This is a critical failure point in real-world scenarios where information evolves. Pioneering work has introduced bi-temporal models into knowledge graphs [262], allowing memory to track not only when a fact was recorded but also the period during which it was valid in the real world, using non-destructive updates that preserve historical context [46, 262].\n\nA key future direction is to integrate these structured memory representations with dynamic, autonomous update mechanisms, drawing inspiration from cognitive science. Agents should be capable of autonomously transforming unstructured inputs into structured representations (e.g.,\n\nknowledge graphs [46, 262], operator trees [47], or multi-faceted memory fragments [448]) in real time during interaction. Importantly, this is not a one-time conversion, but a continuous stream-processing procedure. As new information arrives, the memory structure must dynamically expand, prune, and reorganize itself [46, 414, 187]. This vision is partially realized in systems that employ agentic, cognitive-inspired operations such as INSERT, FORGET, and MERGE to refine memory content [187], or processes like memory evolution, in which new memories trigger updates and recontextualization of existing, linked memories [414]. The ultimate goal is to create a unified cognitive framework that addresses the dual challenges of representational depth and timeliness of knowledge. This framework would likely emulate the distinction between human episodic and semantic memory, a principle already explored in several advanced architectures [222, 262, 448, 423], allowing an agent to both ground its knowledge in specific experiences and evolve a generalized, abstract understanding of the world.\n\n# 6.2.3. Goal-Driven Reinforced Memory Evolution\n\nExisting strategies for memory retention are primarily heuristic-based, relying on static signals such as recency or semantic relevance [417, 463]. However, these heuristics fail to guarantee that preserved memories are truly useful for achieving the final task goal, as they often ignore the interconnected memory cycle effect of storage, retrieval, and utilization [463]. A more powerful paradigm is to formulate memory management as a decision-making problem within a RL framework [436, 491, 194, 485, 417]. In this approach, the agent learns an optimal policy for memory operations, such as updating a fixed-length internal state [436, 491] or executing structured commands like ADD, UPDATE, and DELETE on a memory store [417]. The learning process is guided solely by the reward from the final task outcome, forcing memory management to emerge as a goal-aligned, adaptive capability [436, 491, 417].\n\nA key direction lies in extending this RL paradigm to jointly optimize the entire memory cycle, where agents learn not just to store information but to dynamically retrieve and utilize it through sophisticated strategies, such as multi-round reasoning [194] and experience reuse [485, 463]. This goal is becoming increasingly practical due to two key advances. First, emerging frameworks enable policy learning for memory management at low cost and in real time, without requiring expensive LLM fine-tuning [485]. Second, the data efficiency of RL training makes this approach viable even in data-scarce domains [417]. However, despite these promising developments, a fundamental obstacle remains: the long-term credit assignment problem, which involves developing reliable algorithms to attribute a final outcome to a long sequence of intermediate memory decisions [436].\n\n# 6.3. Instability in Training Algorithms\n\nIn DR systems, multiple rounds of interaction with the environment are required. Although RL algorithms such as PPO [276] and GRPO [279] exhibit stable behavior in single-turn scenarios, they often become unstable when extended to multi-turn settings. This instability typically appears as a gradual or abrupt drop in reward, the generation of invalid responses, and symptoms such as entropy collapse and gradient explosion [145, 416, 373, 320]. These issues remain persistent challenges for training agentic RL systems. Below, we examine two newly emerging solutions and outline future directions for further study.\n\n# 6.3.1. Existing Solutions\n\nFiltering void turns. The first representative solution is proposed by Xue et al. [416], who identify void turns as a major cause of collapse in multi-turn RL. Void turns refer to responses that do not advance the task, such as fragmented text, repetitive content, or premature termination; and once produced, they propagate through later turns, creating a harmful feedback loop. These errors largely stem from the distribution shift between pre-training and multi-turn inference, where the model must process external tool outputs or intermediate signals that were not present during pretraining, increasing the chance of malformed generations. To address this, SimpleTIR [416] filters out trajectories containing void turns, effectively removing corrupted supervision and stabilizing multi-turn RL training.\n\nMitigating the Echo Trap. Wang et al. [373] identify the Echo Trap as a central cause of collapse in multi-turn RL. The Echo Trap refers to rapid policy homogenization, where the model abandons exploration and repeatedly produces conservative outputs that yield short-term rewards. Once this happens, reward variance and policy entropy drop sharply, forming a self-reinforcing degenerative loop. The root cause is a misalignment between reward-driven optimization and reasoning quality. In multi-turn settings, sparse binary rewards cannot distinguish coincidental success from genuine high-quality reasoning, encouraging reward hacking behaviors such as hallucinated reasoning or skipping essential steps. To address this, the proposed StarPO-S [373] uses uncertainty-based trajectory filtering to retain trajectories exhibiting meaningful exploration. This breaks the Echo Trap cycle and stabilizes multi-turn RL training.\n\n# 6.3.2. Future Directions\n\nBeyond the solutions discussed above, we highlight two additional directions for achieving more stable agentic RL training.\n\nCold-start methods that preserve exploration. SFT is a practical cold-start strategy for multi-turn RL, yet it introduces a significant drawback: it rapidly reduces output entropy, constraining the model's ability to explore and develop new reasoning strategies [500]. A promising research direction is to design cold-start methods that improve initial task performance while maintaining exploratory behavior. Such techniques should aim to avoid early entropy collapse and preserve the model's capacity for innovation in multi-turn reasoning.\n\nDenser and smoother reward design. Although StarPO-S [373] effectively mitigates training collapse in PPO-based multi-turn RL, its benefit is more limited for GRPO. The critic module inherent to PPO algorithm [276] naturally smooths reward signals, while GRPO relies on group-wise normalization, which makes it more sensitive to reward variance and extreme values. Developing denser, smoother, and more informative reward functions for multi-turn scenarios, especially for GRPO-style algorithms, remains an important direction for future research.\n\n# 6.4. Evaluation of Deep Research System\n\nEvaluation of DR generally falls into two complementary aspects: (i) the evaluation of agentic information-seeking capabilities and (ii) the evaluation of long-form generation [175, 425]. Considerable progress has been made in the former, with benchmarks such as HotpotQA [425], GAIA [215]. The more recent Deep Research Bench [66, 352] further provides increasingly complex and in-\n\nteractive settings for evaluating agents' abilities to retrieve, navigate, and synthesize information across dynamic web environments. However, reliably evaluating model-generated long-form outputs, especially research-style reports in response to open-ended and high-level queries, remains an open and pressing challenge [379]. Most existing approaches rely on LLM-as-a-Judge to directly evaluate general dimensions such as content factuality, structural coherence, and readability [413]. While effective for scalable comparisons, these evaluation strategies ignore crucial dimensions and are subject to several limitations.\n\n# 6.4.1. Logical Evaluation\n\nSince DR typically requires long-form context generation, maintaining logical coherence throughout the text is essential [476]. Existing studies suggest that while LLMs demonstrate strong capabilities for recognizing logical patterns, such as in summarization tasks or the detection of inconsistencies in short passages, their ability to create rigorous logical chains during DR remains uncertain [168]. In particular, when required to synthesize insights from multiple retrieved supporting documents, models often fail to consistently transform fragmented evidence into a logically connected narrative. The generated reasoning may contain gaps, abrupt leaps, or even circular justifications, compromising the argument's fidelity [260]. This limitation underscores a key challenge for DR: the task is not merely to produce fluent and factually plausible text, but to articulate insights that are logically well-founded and epistemically defensible [189].\n\nAccordingly, robust logical evaluation emerges as a central challenge. However, most existing research on logical assessment remains narrowly scoped. Current benchmarks typically address limited logical tasks, such as solving symbolic logic puzzles, identifying entailment in short sentences, or handling deductive reasoning in synthetic settings [375, 246]. While these tasks provide valuable insights into basic reasoning abilities, they fall short of capturing the complexities of long-form logical consistency. Specifically, they do not address whether models can sustain coherent argumentative structures across extended contexts, reconcile conflicting sources, or systematically avoid introducing unsupported claims. One potential approach is to design evaluation frameworks that assess coherence across multiple granularities (e.g., sentence-level, paragraph-level, and document-level), capturing both local and global logical dependencies [102].\n\n# 6.4.2. Boundary between Novelty and Hallucination\n\nIn DR, progressing beyond faithful summarization toward the generation of genuinely novel hypotheses or perspectives is a central goal [81]. However, in practice, outputs that appear original may embed unverifiable claims, fabricated connections between sources, or spurious inferences lacking epistemic grounding [184]. This challenge is exacerbated in open-ended settings, where no single ground truth exists and retrieval broadens the hypothesis space, increasing the likelihood that superficially plausible but unsupported statements evade detection, especially by surface-level or style-sensitive evaluation methods [135]. Current practices often depend on density-based novelty scores or LLM-as-judge assessments of originality [365, 459], yet these alone do not ensure verifiability or differentiate between creative recombination and unfounded speculation.\n\nA potential solution is to differentiate between two types of novelty. Generative novelty refers to new combinations or perspectives, while deductive novelty refers to conclusions logically derived from known facts. To achieve this, novelty scoring can be combined with validity-checking mechanisms [11, 440, 267]. For example, researchers can pre-register testable claims along with verification plans, ensure that each claim is linked to clear sources, and systematically ablate sources to determine\n\nwhich are necessary or sufficient [480, 345]. Additionally, inserting control examples or testing the system with false information can reveal how often it generates incorrect but seemingly original results [217]. Another useful method is to restrict the system to documents published before a certain cutoff date and then examine whether its outputs are later validated by subsequently published sources—providing insight into the independence and robustness of novel ideas [191, 155].\n\n# 6.4.3. Bias and Efficiency of LLM-as-Judge\n\nLLM-as-Judge has become a mainstream approach for evaluating long-form model outputs. However, this practice introduces two major challenges. The first challenge is bias. LLM judges may prefer longer responses, be affected by answer ordering, reward particular writing styles, or favor systems that resemble themselves [100, 169]. Such biases may reduce the robustness and fairness of existing evaluation protocols. The second challenge is efficiency. Large-scale pairwise evaluation is resource-intensive, especially when relying on paid APIs and applying costly comparison methods to long outputs [497]. These limitations motivate two directions for improvement: mitigating bias and improving efficiency.\n\nMitigating bias. Bias can be reduced by incorporating human evaluators for critical or ambiguous cases, providing a grounded reference for calibration [169]. Another direction is to fine-tune judge models using datasets that highlight diverse reasoning styles and explicit debiasing signals [497]. Such training may lessen systematic preferences for particular formats or linguistic patterns.\n\nImproving efficiency. Efficiency can be improved by adopting open-source, general-purpose judge models, which reduce evaluation cost while offering greater transparency and reproducibility [272]. Further improvements may come from smarter candidate selection algorithms that focus on the most informative comparisons [475]. By lowering the number of required pairwise evaluations without sacrificing quality, such methods enable LLM-based evaluation in more resource-constrained settings.\n\n# 7. Open Discussion: Deep Research to General Intelligence\n\nAs DR systems advance, they must navigate key challenges that bridge specialized task-solving with broader cognitive capabilities. This subsection examines three pivotal areas (i.e., creativity, fairness, safety, and reliability) that may shape the development from current DR paradigms to AGI-level autonomy, ensuring these systems not only augment human inquiry but also foster equitable, innovative, and trustworthy ecosystems.\n\n# 7.1. Creativity\n\nDespite the considerable attention and rapid development in both academia and industry, Previous studies highlight fundamental limitations in LLM creativity based on next-token prediction [198]. While they excel at recombination [411, 417], emotion [422, 421], imitation [169, 363], and logical reasoning [348, 302], the question remains whether AI can evolve from these capabilities to achieve genuine innovation and novel concept generation. This transition may require mechanisms beyond statistical learning, drawing on psychological theories of human creativity, such as insight or eureka moments, which involve sudden restructuring of mental representations and are not easily explained by probabilistic models [389]. Some argue that hallucinations in AI could be interpreted as a form of creativity [198], potentially bridging this gap, but this perspective needs careful examination to distinguish between productive divergence and erroneous output.\n\n# 7.2. Fairness\n\nAs noted in prior work [77], DR powered by autonomous agents may inadvertently inherit and amplify existing biases in academia. For example, they could favor mainstream fields, methodologies, or prominent researchers, thereby overlooking emerging interdisciplinary work or contributions from non-mainstream regions. r To mitigate this, such systems should incorporate built-in fairness frameworks that ensure comprehensive and impartial evaluation of all data, prevent the reinforcement of academic hierarchies, and provide equitable support to researchers from diverse backgrounds. A critical consideration is the impact of each agent's decision step on the overall fairness of outcomes: how much does bias in early steps shape subsequent decision spaces during interactions with the environment? Recent work [158] indicates that this cascading effect could limit exploration and perpetuate inequities if not addressed through debiasing techniques at every stage.\n\n# 7.3. Safety and Reliability\n\nAlthough some studies suggest that AI hallucinations can spark diversity [198, 330], they also pose risks of disseminating serious academic errors. To enhance safety and reliability, Deep research system should ensure conclusions are supported by clear, traceable evidence chains; offer highly transparent reasoning processes to avoid \"black-box\" decisions; and implement robust validation mechanisms to curb the spread of hallucinated science [33, 296]. These measures are essential for maintaining trust in AI-assisted research and preventing misinformation in scholarly pursuits.\n\n# 8. Conclusion and Future Outlook\n\nDeep research (DR) stands at the frontier of transforming large language models from passive responders into autonomous investigators capable of iterative reasoning, evidence synthesis, and verifiable knowledge creation. This survey consolidates recent advances in architectures, optimization methods, and evaluation frameworks, providing a unified roadmap for understanding and building future DR systems. By investigating relevant works, this survey facilitates future research and accelerates the advancement of DR systems toward more general, reliable, and interpretable intelligence. Given the rapid evolution of this field, we will continuously update this survey to encompass emerging paradigms such as multimodal reasoning, self-evolving memory, and agentic reinforcement learning. This effort aims to provide a comprehensive and up-to-date understanding of deep research systems.\n\n# References\n\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[2] Kortix AI. Suna: Open-source generalist ai agent, 2025. URL https://github.com/kortix-ai/suna.  \n[3] Perplexity AI. Perplexity deep research, 2025. URL https://perplexity.ai/hub/blog/introducing-perplexity-deep-research.  \n[4] Skywork AI. Skywork-deepresearch. https://github.com/SkyworkAI/Skywork-DeepResearch, 2025.  \n[5] Sina Alemohammad, Josue Casco-Rodriguez, Lorenzo Luzi, Ahmed Imtiaz Humayun, Hossein Babaei, Daniel LeJeune, Ali Siahkoohi, and Richard G Baraniuk. Self-consuming generative models go mad. In International Conference on Learning Representations, 2024.  \n[6] Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Andrey Kravchenko, Mikhail Burtsev, and Evgeny Burnaev. Arigraph: Learning knowledge graph world models with episodic memory for llm agents. arXiv preprint arXiv:2407.04363, 2024.  \n[7] Rahul K. Arora, Jason Wei, Rebecca Soskin Hicks, Preston Bowman, Joaquin Quiñonero Candela, Foivos Tsimpourlas, Michael Sharman, Meghan Shah, Andrea Vallone, Alex Beutel, Johannes Heidecke, and Karan Singhal. Healthbench: Evaluating large language models towards improved human health. ArXiv, abs/2505.08775, 2025.  \n[8] Akari Asai, Jacqueline He, Rulin Shao, Weijia Shi, Amanpreet Singh, Joseph Chee Chang, Kyle Lo, Luca Soldaini, Sergey Feldman, Mike D'arcy, et al. Openscholar: Synthesizing scientific literature with retrieval-augmented lms. arXiv preprint arXiv:2411.14199, 2024.  \n[9] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-RAG: Learning to retrieve, generate, and critique through self-reflection. In The Twelfth International Conference on Learning Representations, 2024.  \n[10] Amos Azaria and Tom Mitchell. The internal state of an llm knows when it's lying. arXiv preprint arXiv:2304.13734, 2023.  \n[11] Zhangir Azerbayev, Bartosz Piotrowski, Hailey Schoelkopf, Edward W Ayers, Dragomir Radev, and Jeremy Avigad. Proofnet: Autoformalizing and formally proving undergraduate-level mathematics. arXiv preprint arXiv:2302.12433, 2023.  \n[12] Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. Longwriter: Unleashing 10,000+ word generation from long context LLMs. In The Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=kQ5s9Yh0WI.  \n[13] Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, and Pascale Fung. HalluLens: LLM hallucination benchmark. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2025.\n\n[14] Tong Bao, Mir Tafseer Nayeem, Davood Rafiei, and Chengzhi Zhang. Surveygen: Quality-aware scientific survey generation with large language models. arXiv preprint arXiv:2508.17647, 2025.  \n[15] Quentin Bertrand, Avishek Joey Bose, Alexandre Duplessis, Marco Jiralerspong, and Gauthier Gidel. On the stability of iterative retraining of generative models on their own data. arXiv preprint arXiv:2310.00429, 2023.  \n[16] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. Improving language models by retrieving from trillions of tokens, 2022.  \n[17] Nikos I Bosse, Jon Evans, Robert G Gambee, Daniel Hnyk, Peter Mühlbacher, Lawrence Phillips, Dan Schwarz, Jack Wildman, et al. Deep research bench: Evaluating ai web research agents. arXiv preprint arXiv:2506.06287, 2025.  \n[18] Martin Briesch, Dominik Sobania, and Franz Rothlauf. Large language models suffer from their own output: An analysis of the self-consuming training loop. arXiv preprint arXiv:2311.16822, 2023.  \n[19] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33, 2020.  \n[20] Cameron B Browne, Edward Powley, Daniel Whitehouse, Simon M Lucas, Peter I Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis, and Simon Colton. A survey of monte carlo tree search methods. IEEE Transactions on Computational Intelligence and AI in games, 2012.  \n[21] Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, and Le Sun. Structeval: Deepen and broaden large language model assessment via structured evaluation. arXiv preprint arXiv:2408.03281, 2024.  \n[22] Jiaqi Cao, Jiarui Wang, Rubin Wei, Qipeng Guo, Kai Chen, Bowen Zhou, and Zhouhan Lin. Memory decoder: A pretrained, plug-and-play memory for large language models. arXiv preprint arXiv:2508.09874, 2025.  \n[23] Ruisheng Cao, Fangyu Lei, Haoyuan Wu, Jixuan Chen, Yeqiao Fu, Hongcheng Gao, Xinzhuang Xiong, Hanchong Zhang, Wenjing Hu, Yuchen Mao, et al. Spider2-v: How far are multimodal agents from automating data science and engineering workflows? Advances in Neural Information Processing Systems, 2024.  \n[24] Zhiwei Cao, Qian Cao, Yu Lu, Ningxin Peng, Luyang Huang, Shanbo Cheng, and Jinsong Su. Retaining key information under high compression ratios: Query-guided compressor for llms. arXiv preprint arXiv:2406.02376, 2024.  \n[25] Victor Carbune, Hassan Mansoor, Fangyu Liu, Rahul Aralikatte, Gilles Baechler, Jindong Chen, and Abhanshu Sharma. Chart-based reasoning: Transferring capabilities from llms to vlms (chartpali-5b). arXiv preprint arXiv:2403.12596, 2024.\n\n[26] Jun Shern Chan, Neil Chowdhury, Oliver Jaffe, James Aung, Dane Sherburn, Evan Mays, Giulio Starace, Kevin Liu, Leon Maksin, Tejal Patwardhan, et al. Mle-bench: Evaluating machine learning agents on machine learning engineering. arXiv preprint arXiv:2410.07095, 2024.  \n[27] Prahaladh Chandrahasan, Jiahe Jin, Zhihan Zhang, Tevin Wang, Andy Tang, Lucy Mo, Morteza Ziyadi, Leonardo FR Ribeiro, Zimeng Qiu, Markus Dreyer, et al. Deep research comparator: A platform for fine-grained human annotations of deep research agents. arXiv preprint arXiv:2507.05495, 2025.  \n[28] Chao Chen, Kai Liu, Ze Chen, Yi Gu, Yue Wu, Mingyuan Tao, Zhihang Fu, and Jieping Ye. Inside: Llms' internal states retain the power of hallucination detection. arXiv preprint arXiv:2402.03744, 2024.  \n[29] Justin Chih-Yao Chen, Swarnadeep Saha, Elias Stengel-Eskin, and Mohit Bansal. Magdi: Structured distillation of multi-agent interaction graphs improves reasoning in smaller language models. arXiv preprint arXiv:2402.01620, 2024.  \n[30] Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, and Hui Xiong. Plan-on-graph: Self-correcting adaptive planning of large language model on knowledge graphs. Advances in Neural Information Processing Systems, 37:37665-37691, 2024.  \n[31] Qiguang Chen, Mingda Yang, Libo Qin, Jinhao Liu, Zheng Yan, Jiannan Guan, Dengyun Peng, Yiyan Ji, Hanjing Li, Mengkang Hu, et al. Ai4research: A survey of artificial intelligence for scientific research. arXiv preprint arXiv:2507.01903, 2025.  \n[32] Si-An Chen, Lesly Miculicich, Julian Eisenschlos, Zifeng Wang, Zilong Wang, Yanfei Chen, Yasuhisa Fujii, Hsuan-Tien Lin, Chen-Yu Lee, and Tomas Pfister. Tablerag: Million-token table understanding with language models. Advances in Neural Information Processing Systems, 2024.  \n[33] Xiaoyang Chen, Ben He, Hongyu Lin, Xianpei Han, Tianshu Wang, Boxi Cao, Le Sun, and Yingfei Sun. Spiral of silence: How is large language model killing information retrieval? – a case study on open domain question answering, 2024.  \n[34] Xuanzhong Chen, Zile Qiao, Guoxin Chen, Liangcai Su, Zhen Zhang, Xinyu Wang, Pengjun Xie, Fei Huang, Jingren Zhou, and Yong Jiang. Agentfrontier: Expanding the capability frontier of llm agents with zpd-guided data synthesis. arXiv preprint arXiv:2510.24695, 2025.  \n[35] Yiqun Chen, Qi Liu, Yi Zhang, Weiwei Sun, Xinyu Ma, Wei Yang, Daiting Shi, Jiaxin Mao, and Dawei Yin. Tourrank: Utilizing large language models for documents ranking with a tournament-inspired strategy. In Proceedings of the ACM on Web Conference 2025, 2025.  \n[36] Yiqun Chen, Lingyong Yan, Weiwei Sun, Xinyu Ma, Yi Zhang, Shuaiqiang Wang, Dawei Yin, Yiming Yang, and Jiaxin Mao. Improving retrieval-augmented generation through multi-agent reinforcement learning. arXiv preprint arXiv:2501.15228, 2025.  \n[37] Yiqun Chen, Erhan Zhang, Lingyong Yan, Shuaiqiang Wang, Jizhou Huang, Dawei Yin, and Jiaxin Mao. Mao-arag: Multi-agent orchestration for adaptive retrieval-augmented generation. arXiv preprint arXiv:2508.01005, 2025.  \n[38] Zijian Chen, Xueguang Ma, Shengyao Zhuang, Ping Nie, Kai Zou, Andrew Liu, Joshua Green, Kshama Patel, Ruoxi Meng, Mingyi Su, et al. Browsecomp-plus: A more fair and transparent evaluation benchmark of deep-research agent. arXiv preprint arXiv:2508.06600, 2025.\n\n[39] Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu. Self-play fine-tuning converts weak language models to strong language models. arXiv preprint arXiv:2401.01335, 2024.  \n[40] Qinyuan Cheng, Xiaonan Li, Shimin Li, Qin Zhu, Zhangyue Yin, Yunfan Shao, Linyang Li, Tianxiang Sun, Hang Yan, and Xipeng Qiu. Unified active retrieval for retrieval augmented generation. arXiv preprint arXiv:2406.12534, 2024.  \n[41] Xin Cheng, Xun Wang, Xingxing Zhang, Tao Ge, Si-Qing Chen, Furu Wei, Huishuai Zhang, and Dongyan Zhao. xrag: Extreme context compression for retrieval-augmented generation with one token. Advances in Neural Information Processing Systems, 2024.  \n[42] Zhi-Qi Cheng, Qi Dai, Siyao Li, Jingdong Sun, Teruko Mitamura, and Alexander G Hauptmann. Chartreader: A unified framework for chart derendering and comprehension without heuristic rules. arXiv preprint arXiv:2304.02173, 2023.  \n[43] I Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu, et al. Factool: Factuality detection in generative ai-a tool augmented framework for multi-task and multi-domain scenarios. arXiv preprint arXiv:2307.13528, 2023.  \n[44] Maryna Chernyshevich. Core intelligence at semeval-2025 task 8: Multi-hop llm agent for tabular question answering. In Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025), 2025.  \n[45] Alexis Chevalier, Alexander Wettig, Anirudh Ajith, and Danqi Chen. Adapting language models to compress contexts. arXiv preprint arXiv:2305.14788, 2023.  \n[46] Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, and Deshraj Yadav. Mem0: Building production-ready ai agents with scalable long-term memory. arXiv preprint arXiv:2504.19413, 2025.  \n[47] Philipp Christmann and Gerhard Weikum. Recursive question understanding for complex question answering over heterogeneous personal data. arXiv preprint arXiv:2505.11900, 2025.  \n[48] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. Journal of Machine Learning Research, 25(70):1-53, 2024.  \n[49] João Coelho, Jingjie Ning, Jingyuan He, Kangrui Mao, Abhijay Paladugu, Pranav Setlur, Jiahe Jin, Jamie Callan, João Magalhaes, Bruno Martins, et al. Deepresearchgym: A free, transparent, and reproducible evaluation sandbox for deep research. arXiv preprint arXiv:2505.19253, 2025.  \n[50] Gordon V. Cormack, Charles L. A. Clarke, and Stefan Buettcher. Reciprocal rank fusion outperforms condorcet and individual rank learning methods. In SIGIR, 2009.  \n[51] Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Clifford Stein. Introduction to algorithms. MIT press, 2022.  \n[52] Manuel Cossio. A comprehensive taxonomy of hallucinations in large language models. arXiv preprint arXiv:2508.01781, 2025.\n\n[53] Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. Instructclip: Towards general-purpose vision-language models with instruction tuning. In Proceedings of the 37th International Conference on Neural Information Processing Systems, 2023.  \n[54] Mayur Datar, Nicole Immorlica, Piotr Indyk, and Vahab S Mirrokni. Locality-sensitive hashing scheme based on p-stable distributions. In Proceedings of the twentieth annual symposium on Computational geometry, 2004.  \n[55] Nicola De Cao, Wilker Aziz, and Ivan Titov. Editing factual knowledge in language models. arXiv preprint arXiv:2104.08164, 2021.  \n[56] Boyi Deng, Wenjie Wang, Fengbin Zhu, Qifan Wang, and Fuli Feng. Cram: Credibility-aware attention modification in llms for combating misinformation in rag. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 23760-23768, 2025.  \n[57] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang, Huan Sun, and Yu Su. Mind2web: Towards a generalist agent for the web. Advances in Neural Information Processing Systems, 2023.  \n[58] Shrey Desai and Greg Durrett. Calibration of pre-trained transformers. arXiv preprint arXiv:2003.07892, 2020.  \n[59] Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. Chain-of-verification reduces hallucination in large language models. arXiv preprint arXiv:2309.11495, 2023.  \n[60] Hanxing Ding, Liang Pang, Zihao Wei, Huawei Shen, and Xueqi Cheng. Retrieve only when it needs: Adaptive retrieval augmentation for hallucination mitigation in large language models. arXiv preprint arXiv:2402.10612, 2024.  \n[61] Elvis Dohmatob, Yunzhen Feng, Pu Yang, Francois Charton, and Julia Kempe. A tale of tails: Model collapse as a change of scaling laws. arXiv preprint arXiv:2402.07043, 2024.  \n[62] Guanting Dong, Licheng Bao, Zhongyuan Wang, Kangzhi Zhao, Xiaoxi Li, Jiajie Jin, Jinghan Yang, Hangyu Mao, Fuzheng Zhang, Kun Gai, et al. Agentic entropy-balanced policy optimization. arXiv preprint arXiv:2510.14545, 2025.  \n[63] Guanting Dong, Yifei Chen, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Yutao Zhu, Hangyu Mao, Guorui Zhou, Zhicheng Dou, and Ji-Rong Wen. Tool-star: Empowering llm-brained multi-tool reasoner via reinforcement learning. arXiv preprint arXiv:2505.16410, 2025.  \n[64] Guanting Dong, Hangyu Mao, Kai Ma, Licheng Bao, Yifei Chen, Zhongyuan Wang, Zhongxia Chen, Jiazhen Du, Huiyang Wang, Fuzheng Zhang, et al. Agentic reinforced policy optimization. arXiv preprint arXiv:2507.19849, 2025.  \n[65] Guanting Dong, Yutao Zhu, Chenghao Zhang, Zechen Wang, Ji-Rong Wen, and Zhicheng Dou. Understand what llm needs: Dual preference alignment for retrieval-augmented generation. In Proceedings of the ACM on Web Conference 2025, pages 4206-4225, 2025.  \n[66] Mingxuan Du, Benfeng Xu, Chiwei Zhu, Xiaorui Wang, and Zhendong Mao. Deepresearch bench: A comprehensive benchmark for deep research agents. arXiv preprint arXiv:2506.11763, 2025.\n\n[67] Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, and Jeff Z Pan. Rethinking memory in ai: Taxonomy, operations, topics, and future directions. arXiv preprint arXiv:2505.00675, 2025.  \n[68] Yiming Du, Bingbing Wang, Yang He, Bin Liang, Baojun Wang, Zhongyang Li, Lin Gui, Jeff Z Pan, Ruifeng Xu, and Kam-Fai Wong. Bridging the long-term gap: A memory-active policy for multi-session task-oriented dialogue. arXiv preprint arXiv:2505.20231, 2025.  \n[69] Jinhao Duan, Hao Cheng, Shiqi Wang, Alex Zavalny, Chenan Wang, Renjing Xu, Bhavya Kailkhura, and Kaidi Xu. Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models. arXiv preprint arXiv:2307.01379, 2023.  \n[70] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. Eli5: Long form question answering. arXiv preprint arXiv:1907.09190, 2019.  \n[71] Run-Ze Fan, Zengzhi Wang, and Pengfei Liu. Megascience: Pushing the frontiers of posttraining datasets for science reasoning. arXiv preprint arXiv:2507.16812, 2025.  \n[72] Wenqi Fan, Yujuan Ding, Liang bo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. A survey on rag meeting llms: Towards retrieval-augmented large language models. Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2024.  \n[73] Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, and Ruifeng Xu. Enhancing noise robustness of retrieval-augmented language models with adaptive adversarial training. arXiv preprint arXiv:2405.20978, 2024.  \n[74] Jinyuan Fang, Yanwen Peng, Xi Zhang, Yingxu Wang, Xinhao Yi, Guibin Zhang, Yi Xu, Bin Wu, Siwei Liu, Zihao Li, et al. A comprehensive survey of self-evolving ai agents: A new paradigm bridging foundation models and lifelong agentic systems. arXiv preprint arXiv:2508.07407, 2025.  \n[75] Runnan Fang, Shihao Cai, Baixuan Li, Jialong Wu, Guangyu Li, Wenbiao Yin, Xinyu Wang, Xiaobin Wang, Liangcai Su, Zhen Zhang, et al. Towards general agentic intelligence via environment scaling. arXiv preprint arXiv:2509.13311, 2025.  \n[76] Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Francisco J R. Ruiz, Julian Schrittwieser, Grzegorz Swirszcz, et al. Discovering faster matrix multiplication algorithms with reinforcement learning. Nature, 610(7930):47-53, 2022.  \n[77] Emilio Ferrara. Fairness and bias in artificial intelligence: A brief survey of sources, impacts, and mitigation strategies. Sci, 2024.  \n[78] Marina Fomicheva, Shuo Sun, Lisa Yankovskaya, Frédéric Blain, Francisco Guzmán, Mark Fishel, Nikolaos Aletras, Vishrav Chaudhary, and Lucia Specia. Unsupervised quality estimation for neural machine translation. Transactions of the Association for Computational Linguistics, 8: 539-555, 2020.  \n[79] Thibault Formal, Carlos Lassance, Benjamin Piwowarski, and Stéphane Clinchant. Splade v2: Sparse lexical and expansion model for information retrieval. arXiv preprint arXiv:2109.10086, 2021.\n\n[80] Thibault Formal, Benjamin Piwowarski, and Stéphane Clinchant. Splade: Sparse lexical and expansion model for first stage ranking. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2288-2292, 2021.  \n[81] Giorgio Franceschelli and Mirco Musolesi. On the creativity of large language models. AI & society, 40(5), 2025.  \n[82] Tsu-Jui Fu, William Yang Wang, Daniel McDuff, and Yale Song. Doc2ppt: Automatic presentation slides generation from scientific documents. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 634-642, 2022.  \n[83] Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, Fengli Xu, and Yong Li. Large language models empowered agent-based modeling and simulation: A survey and perspectives. *Humanities and Social Sciences Communications*, 2024.  \n[84] Huan-ang Gao, Jiayi Geng, Wenyue Hua, Mengkang Hu, Xinzhe Juan, Hongzhang Liu, Shilong Liu, Jiahao Qiu, Xuan Qi, Yiran Wu, et al. A survey of self-evolving agents: On path to artificial super intelligence. arXiv preprint arXiv:2507.21046, 2025.  \n[85] Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei, Banghua Zhu, and Yi Wu. Beyond ten turns: Unlocking long-horizon agentic search with large-scale asynchronous rl. arXiv preprint arXiv:2508.07976, 2025.  \n[86] Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen. Enabling large language models to generate text with citations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023.  \n[87] Xian Gao, Zongyun Zhang, Mingye Xie, Ting Liu, and Yuzhuo Fu. Graph of ai ideas: Leveraging knowledge graphs and llms for ai research idea generation. arXiv preprint arXiv:2503.08549, 2025.  \n[88] Yifei Gao, Junhong Ye, Jiaqi Wang, and Jitao Sang. Websynthesis: World-model-guided mcts for efficient webui-trajectory synthesis. arXiv preprint arXiv:2507.04370, 2025.  \n[89] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023.  \n[90] Zhaolin Gao, Kante Brantley, and Thorsten Joachims. Reviewer2: Optimizing review generation through prompt generation. arXiv preprint arXiv:2402.10886, 2024.  \n[91] Jiaxin Ge, Zora Zhiruo Wang, Xuhui Zhou, Yi-Hao Peng, Sanjay Subramanian, Qinyue Tan, Maarten Sap, Alane Suhr, Daniel Fried, Graham Neubig, et al. Autopresent: Designing structured visuals from scratch. In Proceedings of the Computer Vision and Pattern Recognition Conference, 2025.  \n[92] Tao Ge, Jing Hu, Lei Wang, Xun Wang, Si-Qing Chen, and Furu Wei. In-context autoencoder for context compression in a large language model. arXiv preprint arXiv:2307.06945, 2023.  \n[93] Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu. Scaling synthetic data creation with 1,000,000,000 personas. arXiv preprint arXiv:2406.20094, 2024.\n\n[94] Ziyu Ge, Yuhao Wu, Daniel Wai Kit Chin, Roy Ka-Wei Lee, and Rui Cao. Resolving conflicting evidence in automated fact-checking: A study on retrieval-augmented llms, 2025.  \n[95] Carlos Gómez-Rodriguez and Paul Williams. A confederacy of models: a comprehensive evaluation of llms on creative writing. arXiv preprint arXiv:2310.08433, 2023.  \n[96] Peiyuan Gong, Feiran Zhu, Yaqi Yin, Chenglei Dai, Chao Zhang, Kai Zheng, Wentian Bao, Jiaxin Mao, and Yi Zhang. Cardrewriter: Leveraging knowledge cards for long-tail query rewriting on short-video platforms. arXiv preprint arXiv:2510.10095, 2025.  \n[97] Google. Deep research is now available on gemini 2.5 pro experimental. https://blog.google/products/gemini/deep-research-gemini-2-5-pro-experimental/, February 2025.  \n[98] Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, et al. Mind2web 2: Evaluating agentic search with agent-as-a-judge. arXiv preprint arXiv:2506.21506, 2025.  \n[99] Hongchao Gu, Dexun Li, Kuicai Dong, Hao Zhang, Hang Lv, Hao Wang, Defu Lian, Yong Liu, and Enhong Chen. RAPID: Efficient retrieval-augmented long text generation with writing planning and information discovery. In Findings of the Association for Computational Linguistics: ACL 2025, 2025.  \n[100] Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, et al. A survey on llm-as-a-judge. arXiv preprint arXiv:2411.15594, 2024.  \n[101] Tianle Gu, Kexin Huang, Ruilin Luo, Yuanqi Yao, Yujiu Yang, Yan Teng, and Yingchun Wang. Meow: Memory supervised llm unlearning via inverted facts. arXiv preprint arXiv:2409.11844, 2024.  \n[102] Jian Guan, Xiaoxi Mao, Changjie Fan, Zitao Liu, Wenbiao Ding, and Minlie Huang. Long text generation by modeling sentence-level and discourse-level coherence. arXiv preprint arXiv:2105.08963, 2021.  \n[103] Xinyan Guan, Jiali Zeng, Fandong Meng, Chunlei Xin, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, and Jie Zhou. Deep Learning: Thinking to retrieve step by step for large language models. arXiv preprint arXiv:2502.01142, 2025.  \n[104] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International conference on machine learning, pages 1321-1330. PMLR, 2017.  \n[105] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.  \n[106] Minghao Guo, Qingcheng Zeng, Xujiang Zhao, Yanchi Liu, Wenchao Yu, Mengnan Du, Haifeng Chen, and Wei Cheng. Deepsieve: Information sieving via llm-as-a-knowledge-router. arXiv preprint arXiv:2507.22050, 2025.  \n[107] Shuyu Guo and Zhaochun Ren. Dynamic context compression for efficient rag. arXiv preprint arXiv:2507.22931, 2025.\n\n[108] H2O.ai. H2o.ai deep research, 2025. URL https://h2o.ai/.  \n[109] Muhammad Usman Hadi, Rizwan Qureshi, Abbas Shah, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili, et al. A survey on large language models: Applications, challenges, limitations, and practical usage. Authorea Preprints, 2023.  \n[110] Chuzhan Hao, Wenfeng Feng, Yuewei Zhang, and Hao Wang. Dynasearcher: Dynamic knowledge graph augmented search agent via multi-reward reinforcement learning. arXiv preprint arXiv:2507.17365, 2025.  \n[111] Jiashu He, Jinxuan Fan, Bowen Jiang, Ignacio Houine, Dan Roth, and Alejandro Ribeiro. Selfgive: Associative thinking from limited structured knowledge for enhanced large language model reasoning. arXiv preprint arXiv:2505.15062, 2025.  \n[112] Zhiwei He, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xingyu Chen, Yue Wang, Linfeng Song, Dian Yu, Zhenwen Liang, Wenxuan Wang, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, and Dong Yu. Deepmath-103k: A large-scale, challenging, decontaminated, and verifiable mathematical dataset for advancing reasoning. arXiv preprint arXiv:2504.11456, 2025.  \n[113] Zihong He, Weizhe Lin, Hao Zheng, Fan Zhang, Matt W Jones, Laurence Aitchison, Xuhai Xu, Miao Liu, Per Ola Kristensson, and Junxiao Shen. Human-inspired perspectives: A survey on ai long-term memory. arXiv preprint arXiv:2411.00489, 2024.  \n[114] David Herel and Tomas Mikolov. Collapse of self-trained language models. arXiv preprint arXiv:2404.02305, 2024.  \n[115] Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. Constructing a multi-hop qa dataset for comprehensive evaluation of reasoning steps. In Proceedings of the 28th International Conference on Computational Linguistics, 2020.  \n[116] Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, et al. Metagpt: Meta programming for a multi-agent collaborative framework. In The Twelfth International Conference on Learning Representations, 2023.  \n[117] Niklas Hübner, Leon Eshuijs, Dimitrios Alivanistos, Giacomo Zamprogno, and Ilaria Tiddi. Automatic evaluation metrics for artificially generated scientific research. arXiv preprint arXiv:2503.05712, 2025.  \n[118] Xinying Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John C. Grundy, and Haoyu Wang. Large language models for software engineering: A systematic literature review. ACM Transactions on Software Engineering and Methodology, 2023.  \n[119] Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. Chatdb: Augmenting llms with databases as their symbolic memory. arXiv preprint arXiv:2306.03901, 2023.  \n[120] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru Li, Qiguang Chen, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Bernard Ghanem, Ping Luo, and Guohao Li. Owl: Optimized workforce learning for general multi-agent assistance in real-world task automation, 2025. Accessed: 2025-11-13.\n\n[121] Minda Hu, Tianqing Fang, Jianshu Zhang, Junyu Ma, Zhisong Zhang, Jingyan Zhou, Hongming Zhang, Haitao Mi, Dong Yu, and Irwin King. Webcot: Enhancing web agent reasoning by reconstructing chain-of-thought in reflection, branching, and rollback. arXiv preprint arXiv:2505.20013, 2025.  \n[122] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems, 2023.  \n[123] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems, 43(2):1-55, 2025.  \n[124] Qian Huang, Jian Vora, Percy Liang, and Jure Leskovec. Mlagentbench: Evaluating language agents on machine learning experimentation. arXiv preprint arXiv:2310.03302, 2023.  \n[125] Yuxuan Huang, Yihang Chen, Haozheng Zhang, Kang Li, Huichi Zhou, Meng Fang, Linyi Yang, Xiaoguang Li, Lifeng Shang, Songcen Xu, et al. Deep research agents: A systematic examination and roadmap. arXiv preprint arXiv:2506.18096, 2025.  \n[126] Liu Huanshuo, Hao Zhang, Zhijiang Guo, Jing Wang, Kuicai Dong, Xiangyang Li, Yi Quan Lee, Cong Zhang, and Yong Liu. CtrlA: Adaptive retrieval-augmented generation via inherent control. In Findings of the Association for Computational Linguistics: ACL 2025, 2025.  \n[127] Gautier Izacard and Edouard Grave. Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282, 2020.  \n[128] Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. Unsupervised dense information retrieval with contrastive learning. arXiv preprint arXiv:2112.09118, 2021.  \n[129] Peter Jansen, Marc-Alexandre Côté, Tushar Khot, Erin Bransom, Bhavana Dalvi Mishra, Bodhisattwa Prasad Majumder, Oyvind Tafjord, and Peter Clark. Discoveryworld: A virtual environment for developing and evaluating automated scientific discovery agents. Advances in Neural Information Processing Systems, 2024.  \n[130] Abhinav Java, Ashmit Khandelwal, Sukruta Midigeshi, Aaron Halfaker, Amit Deshpande, Navin Goyal, Ankur Gupta, Nagarajan Natarajan, and Amit Sharma. Characterizing deep research: A benchmark and formal definition. arXiv preprint arXiv:2508.04183, 2025.  \n[131] Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, and Jong C Park. Adaptive-rag: Learning to adapt retrieval-augmented large language models through question complexity. arXiv preprint arXiv:2403.14403, 2024.  \n[132] Jinhao Jiang, Jiayi Chen, Junyi Li, Ruiyang Ren, Shijie Wang, Wayne Xin Zhao, Yang Song, and Tao Zhang. Rag-star: Enhancing deliberative reasoning with retrieval augmented verification and refinement. arXiv preprint arXiv:2412.12881, 2024.  \n[133] Pengcheng Jiang, Jiacheng Lin, Lang Cao, Runchu Tian, SeongKu Kang, Zifeng Wang, Jimeng Sun, and Jiawei Han. Deepretrieval: Hacking real search engines and retrievers with large language models via reinforcement learning. arXiv preprint arXiv:2503.00223, 2025.\n\n[134] Pengcheng Jiang, Xueqiang Xu, Jiacheng Lin, Jinfeng Xiao, Zifeng Wang, Jimeng Sun, and Jiawei Han. s3: You don't need that much data to train a search agent via rl. arXiv preprint arXiv:2505.14146, 2025.  \n[135] Xuhui Jiang, Yuxing Tian, Fengrui Hua, Chengjin Xu, Yuanzhuo Wang, and Jian Guo. A survey on large language model hallucination via a creativity perspective. arXiv preprint arXiv:2402.06647, 2024.  \n[136] Xun Jiang, Feng Li, Han Zhao, Jiahao Qiu, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, et al. Long term memory: The foundation of ai self-evolution. arXiv preprint arXiv:2410.15665, 2024.  \n[137] Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. How can we know when language models know? on the calibration of language models for question answering. Transactions of the Association for Computational Linguistics, 2021.  \n[138] Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. Active retrieval augmented generation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7969-7992, 2023.  \n[139] Zhouyu Jiang, Mengshu Sun, Lei Liang, and Zhiqiang Zhang. Retrieve, summarize, plan: Advancing multi-hop question answering with an iterative approach. In Companion Proceedings of the ACM on Web Conference 2025, 2025.  \n[140] Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models resolve real-world github issues? arXiv preprint arXiv:2310.06770, 2023.  \n[141] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models resolve real-world github issues? arXiv preprint arXiv:2310.06770, 2023.  \n[142] Bernal Jimenez Gutierrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, and Yu Su. Hipporag: Neurobiologically inspired long-term memory for large language models. Advances in Neural Information Processing Systems, 2024.  \n[143] Bowen Jin, Jinsung Yoon, Jiawei Han, and Sercan O Arik. Long-context llms meet rag: Overcoming challenges for long inputs in rag. In The Thirteenth International Conference on Learning Representations, 2024.  \n[144] Bowen Jin, Jinsung Yoon, Priyanka Kargupta, Sercan O Arik, and Jiawei Han. An empirical study on reinforcement learning for reasoning-search interleaved llm agents. arXiv preprint arXiv:2505.15117, 2025.  \n[145] Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed Za mani, and Jiawei Han. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516, 2025.  \n[146] Jiajie Jin, Yutao Zhu, Yujia Zhou, and Zhicheng Dou. Bider: Bridging knowledge inconsistency for efficient retrieval-augmented llms via key supporting evidence. arXiv preprint arXiv:2402.12174, 2024.\n\n[147] Xu Jin, Guo Zhifang, He Jinzheng, Hu Hangrui, He Ting, Bai Shuai, Chen Keqin, Wang Jialin, Fan Yang, Dang Kai, Zhang Bin, Wang Xiong, Chu Yunfei, and Lin Junyang. Qwen2.5-omni technical report. arXiv preprint arXiv:2503.20215v1, 2025.  \n[148] Liqiang Jing, Zhehui Huang, Xiaoyang Wang, Wenlin Yao, Wenhao Yu, Kaixin Ma, Hongming Zhang, Xinya Du, and Dong Yu. Dsbench: How far are data science agents from becoming data science experts? arXiv preprint arXiv:2409.07703, 2024.  \n[149] Shi Jingwei, Zhang Zeyu, Wu Biao, Liang Yanjie, Fang Meng, Chen Ling, and Zhao Yang. Presentagent: Multimodal agent for presentation video generation. arXiv preprint arXiv:2507.04036, 2025.  \n[150] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus. IEEE Transactions on Big Data, 7(3), 2019.  \n[151] Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, 2017.  \n[152] Kyudan Jung, Hojun Cho, Jooyeol Yun, Sooyung Yang, Jaehyeok Jang, and Jaegul Choo. Talk to your slides: Language-driven agents for efficient slide editing. arXiv preprint arXiv:2505.11604, 2025.  \n[153] Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221, 2022.  \n[154] Chia Hsiang Kao, Wenting Zhao, Shreelekha Revankar, Samuel Speas, Snehal Bhagat, Rajeev Datta, Cheng Perng Phoo, Utkarsh Mall, Carl Vondrick, Kavita Bala, et al. Towards llm agents for earth observation. arXiv preprint arXiv:2504.12110, 2025.  \n[155] Ezra Karger, Houtan Bastani, Chen Yueh-Han, Zachary Jacobs, Danny Halawi, Fred Zhang, and Philip E Tetlock. Forecastbench: A dynamic benchmark of ai forecasting capabilities. arXiv preprint arXiv:2409.19839, 2024.  \n[156] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, 2020.  \n[157] Omar Khattab and Matei Zaharia. Colbert: Efficient and effective passage search via late interaction over BERT. In SIGIR, 2020.  \n[158] Tahsin Alamgir Kheya. The pursuit of fairness in artificial intelligence models. arXiv preprint arXiv:2403.17333, 2024.  \n[159] Geewook Kim and et al. Donut: Document understanding transformer withoutOCR. In ECCV, 2022.  \n[160] Yanghoon Kim, Hwanhee Lee, Joongbo Shin, and Kyomin Jung. Improving neural question generation using answer separation. In Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 6602-6609, 2019.\n\n[161] Levente Kocsis and Csaba Szepesvári. Bandit based monte-carlo planning. In European conference on machine learning. Springer, 2006.  \n[162] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 2022.  \n[163] Satyapriya Krishna, Kalpesh Krishna, Anhad Mohananey, Steven Schwarcz, Adam Stambler, Shyam Upadhyay, and Manaal Faruqui. Fact, fetch, and reason: A unified evaluation of retrieval-augmented generation. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies, 2025.  \n[164] Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation. arXiv preprint arXiv:2302.09664, 2023.  \n[165] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics, 2019.  \n[166] Cheryl Lee, Chunqiu Steven Xia, Longji Yang, Jen-tse Huang, Zhouruixin Zhu, Lingming Zhang, and Michael R Lyu. Unidebugger: Hierarchical multi-agent framework for unified software debugging. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, 2025.  \n[167] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Roktäschel, Sebastian Riedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive nlp tasks. In Proceedings of the 34th International Conference on Neural Information Processing Systems, 2020.  \n[168] Anguo Li and Lei Yu. Summary factual inconsistency detection based on llms enhanced by universal information extraction. In Findings of the Association for Computational Linguistics: ACL 2025, 2025.  \n[169] Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou, Qingyao Ai, Ziyi Ye, and Yiqun Liu. Llms-as-judges: a comprehensive survey on llm-based evaluation methods. arXiv preprint arXiv:2412.05579, 2024.  \n[170] Junlong Li, Shichao Sun, Weizhe Yuan, Run-Ze Fan, Hai Zhao, and Pengfei Liu. Generative judge for evaluating alignment. arXiv preprint arXiv:2310.05470, 2023.  \n[171] Junnan Li and et al. Blip: Bootstrapping language-image pre-training. In International Conference on Machine Learning, 2022.  \n[172] Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: bootstrapping language-image pre-training with frozen image encoders and large language models. In International Conference on Machine Learning, 2023.  \n[173] Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, et al. Websailor-v2: Bridging the chasm to proprietary agents via synthetic data and scalable reinforcement learning. arXiv preprint arXiv:2509.13305, 2025.\n\n[174] Kuan Li, Zhongwang Zhang, Huifeng Yin, Liwen Zhang, Litu Ou, Jialong Wu, Wenbiao Yin, Baixuan Li, Zhengwei Tao, Xinyu Wang, et al. Websailor: Navigating super-human reasoning for web agent. arXiv preprint arXiv:2507.02592, 2025.  \n[175] Minghao Li, Ying Zeng, Zhihao Cheng, Cong Ma, and Kai Jia. Reportbench: Evaluating deep research agents via academic survey tasks, 2025.  \n[176] Moxin Li, Yong Zhao, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See Kiong Ng, Tat-Seng Chua, and Yang Deng. Knowledge boundary of large language models: A survey. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5131-5157, 2025.  \n[177] Ruochen Li, Liqiang Jing, Chi Han, Jiawei Zhou, and Xinya Du. Learning to generate research idea with dynamic control. arXiv preprint arXiv:2412.14626, 2024.  \n[178] Shutao Li, Bin Li, Bin Sun, and Yixuan Weng. Towards visual-prompt temporal answer grounding in instructional video. IEEE Trans. Pattern Anal. Mach. Intell., 2024.  \n[179] Sijie Li, Weiwei Sun, Shanda Li, Ameet Talwalkar, and Yiming Yang. Towards community-driven agents for machine learning engineering. arXiv preprint arXiv: 2506.20640, 2025.  \n[180] Weizhen Li, Jianbo Lin, Zhuosong Jiang, Jingyi Cao, Xinpeng Liu, Jiayu Zhang, Zhenqiang Huang, Qianben Chen, Weichen Sun, Qiexiang Wang, et al. Chain-of-agents: End-to-end agent foundation models via multi-agent distillation and agentic rl. arXiv preprint arXiv:2508.13167, 2025.  \n[181] Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, and Xipeng Qiu. Llatrieval: Llm-verified retrieval for verifiable generation. arXiv preprint arXiv:2311.07838, 2023.  \n[182] Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and Zhicheng Dou. Search-o1: Agentic search-enhanced large reasoning models. arXiv preprint arXiv:2501.05366, 2025.  \n[183] Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, and Zhicheng Dou. Webthinker: Empowering large reasoning models with deep research capability. arXiv preprint arXiv:2504.21776, 2025.  \n[184] Ethan Lin, Zhiyuan Peng, and Yi Fang. Evaluating and enhancing large language models for novelty assessment in scholarly publications. In Proceedings of the 1st Workshop on AI and Scientific Discovery: Directions and Opportunities, 2025.  \n[185] Stephanie Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in words. Transactions on Machine Learning Research, 2022.  \n[186] Junwei Liu, Kaixin Wang, Yixuan Chen, Xin Peng, Zhenpeng Chen, Lingming Zhang, and Yiling Lou. Large language model-based agents for software engineering: A survey. arXiv preprint arXiv:2409.02977, 2024.  \n[187] Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, and Guannan Zhang. Think-in-memory: Recalling and post-thinking enable llms with long-term memory. arXiv preprint arXiv:2311.08719, 2023.\n\n[188] Wenhan Liu, Xinyu Ma, Weiwei Sun, Yutao Zhu, Yuchen Li, Dawei Yin, and Zhicheng Dou. Reasonrank: Empowering passage ranking with strong reasoning ability. arXiv preprint arXiv:2508.07050, 2025.  \n[189] Xiang Liu, Peijie Dong, Xuming Hu, and Xiaowen Chu. Longgenbench: Long-context generation benchmark. arXiv preprint arXiv:2410.04199, 2024.  \n[190] Xiao Liu, Bo Qin, Dongzhu Liang, Guang Dong, Hanyu Lai, Hanchen Zhang, Hanlin Zhao, Iat Long Iong, Jiadai Sun, Jiaqi Wang, et al. Autoglm: Autonomous foundation agents for guis. arXiv preprint arXiv:2411.00820, 2024.  \n[191] Yachuan Liu, Xiaochun Wei, Lin Shi, Xinnuo Li, Bohan Zhang, Paramveer Dhillon, and Qiaozhu Mei. Exante: A benchmark for ex-ante inference in large language models. arXiv preprint arXiv:2505.19533, 2025.  \n[192] Yu Liu, Yanbing Liu, Fangfang Yuan, Cong Cao, Youbang Sun, Kun Peng, WeiZhuo Chen, Jianjun Li, and Zhiyuan Ma. Opera: A reinforcement learning-enhanced orchestrated planner-executor architecture for reasoning-oriented multi-hop retrieval. arXiv preprint arXiv:2508.16438, 2025.  \n[193] Google LLC. Gemini deep research, 2024. URL https://gemini.google/overview/deep-research/.  \n[194] Lin Long, Yichen He, Wentao Ye, Yiyuan Pan, Yuan Lin, Hang Li, Junbo Zhao, and Wei Li. Seeing, listening, remembering, and reasoning: A multimodal agent with long-term memory. arXiv preprint arXiv:2508.09736, 2025.  \n[195] Manus AI (Butterfly Effect Pte. Ltd.). Manus ai, 2025. URL https://manus.im/.  \n[196] Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, and David Ha. The ai scientist: Towards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292, 2024.  \n[197] Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, and Yunsheng Wu. Memochat: Tuning llms to use memos for consistent long-range open-domain conversation. arXiv preprint arXiv:2308.08239, 2023.  \n[198] Li-Chun Lu. A critical analysis of existing creativity evaluations, 2025.  \n[199] Michal Lukasik, Srinadh Bhojanapalli, Aditya Krishna Menon, and Sanjiv Kumar. Teacher's pet: understanding and mitigating biases in distillation. arXiv preprint arXiv:2106.10494, 2021.  \n[200] Haoran Luo, Haihong E, Guanting Chen, Qika Lin, Yikai Guo, Fangzhi Xu, Zemin Kuang, Meina Song, Xiaobao Wu, Yifan Zhu, and Luu Anh Tuan. Graph-r1: Towards agentic graphrag framework via end-to-end reinforcement learning. arXiv preprint arXiv:2507.21892, 2025.  \n[201] Yi Luo, Linghang Shi, Yihao Li, Aobo Zhuang, Yeyun Gong, Ling Liu, and Chen Lin. From intention to implementation: automating biomedical research via llms. Science China Information Sciences, 2025.  \n[202] Yougang Lyu, Xiaoyu Zhang, Lingyong Yan, Maarten de Rijke, Zhaochun Ren, and Xiuying Chen. Deepshop: A benchmark for deep research shopping agents. arXiv preprint arXiv:2506.02839, 2025.\n\n[203] Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, and Nan Duan. Query rewriting in retrieval-augmented large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023.  \n[204] Aru Maekawa, Hidetakaka Kamigaito, Kotaro Funakoshi, and Manabu Okumura. Generative replay inspired by hippocampal memory indexing for continual language learning. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, 2023.  \n[205] Yu A Malkov and Dmitry A Yashunin. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence, 42(4), 2018.  \n[206] Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Toronto, Canada, July 2023.  \n[207] Potsawee Manakul, Adrian Liusie, and Mark JF Gales. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. arXiv preprint arXiv:2303.08896, 2023.  \n[208] Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty, and Enamul Hoque. ChartQA: A benchmark for question answering about charts with visual and logical reasoning. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, Findings of the Association for Computational Linguistics: ACL 2022, May 2022.  \n[209] Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, and Shafiq Joty. Unichart: A universal vision-language pretrained model for chart comprehension and reasoning. arXiv preprint arXiv:2305.14761, 2023.  \n[210] Minesh Mathew, Umapada Pal, and CV Jawahar. Docvqa: A dataset for document visual question answering. In WACV Workshops, 2021.  \n[211] Sanket Vaibhav Mehta, Jai Gupta, Yi Tay, Mostafa Dehghani, Vinh Q Tran, Jinfeng Rao, Marc Najork, Emma Strubell, and Donald Metzler. Dsi++: Updating transformer memory with new documents. arXiv preprint arXiv:2212.09744, 2022.  \n[212] Jianbiao Mei, Tao Hu, Daocheng Fu, Licheng Wen, Xuemeng Yang, Rong Wu, Pinlong Cai, Xinyu Cai, Xing Gao, Yu Yang, et al. O2-searcher: A searching-based agent model for open-domain open-ended question answering. arXiv preprint arXiv:2505.16582, 2025.  \n[213] Lang Mei, Zhihan Yang, and Chong Chen. Ai-searchplanner: Modular agentic search via pareto-optimal multi-objective reinforcement learning. arXiv preprint arXiv:2508.20368, 2025.  \n[214] Fanqing Meng, Wenqi Shao, Quanfeng Lu, Peng Gao, Kaipeng Zhang, Yu Qiao, and Ping Luo. Chartassistant: A universal chart multimodal language model via chart-to-table pre-training and multitask instruction tuning. arXiv preprint arXiv:2401.02384, 2024.  \n[215] Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for general ai assistants. In The Twelfth International Conference on Learning Representations, 2023.\n\n[216] Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. FActScore: Fine-grained atomic evaluation of factual precision in long form text generation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, 2023.  \n[217] Yifei Ming, Senthil Purushwalkam, Shrey Pandit, Zixuan Ke, Xuan-Phi Nguyen, Caiming Xiong, and Shafiq Joty. Faitheval: Can your language model stay faithful to context, even if \" the moon is made of marshmallows\". arXiv preprint arXiv:2410.03727, 2024.  \n[218] Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. Fast model editing at scale. arXiv preprint arXiv:2110.11309, 2021.  \n[219] Jesse Mu, Xiang Li, and Noah Goodman. Learning to compress prompts with gist tokens. Advances in Neural Information Processing Systems, 2023.  \n[220] Vaishnavh Nagarajan, Aditya K Menon, Srinadh Bhojanapalli, Hossein Mobahi, and Sanjiv Kumar. On student-teacher deviations in distillation: does it pay to disobey? Advances in Neural Information Processing Systems, 36:5961–6000, 2023.  \n[221] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.  \n[222] Jiayan Nan, Wenquan Ma, Wenlong Wu, and Yize Chen. Nemori: Self-organizing agent memory inspired by cognitive science. arXiv preprint arXiv:2508.03341, 2025.  \n[223] Deepak Nathani, Lovish Madaan, Nicholas Roberts, Nikolay Bashlykov, Ajay Menon, Vincent Moens, Amar Budhiraja, Despoina Magka, Vladislav Vorotilov, Gaurav Chaurasia, et al. Mlgym: A new framework and benchmark for advancing ai research agents. arXiv preprint arXiv:2502.14499, 2025.  \n[224] Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad Usman, Naveed Akhtar, Nick Barnes, and Ajmal Mian. A comprehensive overview of large language models. ACM Transactions on Intelligent Systems and Technology, 2025.  \n[225] Fnu Neha and Deepshikha Bhati. Traditional rag vs. agentic rag: A comparative study of retrieval-augmented systems. Authorea Preprints, 2025.  \n[226] Giang Nguyen, Ivan Brugere, Shubham Sharma, Sanjay Kariyappa, Anh Totti Nguyen, and Freddy Lecue. Interpretable llm-based table question answering. arXiv preprint arXiv:2412.12386, 2024.  \n[227] Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. Ms marco: A human-generated machine reading comprehension dataset. In International Conference on Learning Representations, 2016.  \n[228] Shiyu Ni, Keping Bi, Jiafeng Guo, and Xueqi Cheng. When do llms need retrieval augmentation? mitigating llms' overconfidence helps retrieval augmentation. arXiv preprint arXiv:2402.11457, 2024.  \n[229] Shiyu Ni, Keping Bi, Jiafeng Guo, Minghao Tang, Jingtong Wu, Zengxin Han, and Xueqi Cheng. Annotation-efficient universal honesty alignment. arXiv preprint arXiv:2510.17509, 2025.\n\n[230] Shiyu Ni, Keping Bi, Jiafeng Guo, Lulu Yu, Baolong Bi, and Xueqi Cheng. Towards fully exploiting llm internal states to enhance knowledge boundary perception. arXiv preprint arXiv:2502.11677, 2025.  \n[231] Zihan Niu, Zheyong Xie, Shaosheng Cao, Chonggang Lu, Zheyu Ye, Tong Xu, Zuozhu Liu, Yan Gao, Jia Chen, Zhe Xu, et al. Part: Enhancing proactive social chatbots with personalized real-time retrieval. In Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval, 2025.  \n[232] Agada Joseph Oche, Ademola Glory Folarshade, Tirthankar Ghosal, and Arpan Biswas. A systematic review of key retrieval-augmented generation (rag) systems: Progress, gaps, and future directions. arXiv preprint arXiv:2507.18910, 2025.  \n[233] Minhae Oh, Jeonghye Kim, Nakyung Lee, Donggeon Seo, Taeuk Kim, and Jungwoo Lee. Raise: Enhancing scientific reasoning in llms via step-by-step retrieval. arXiv preprint arXiv:2506.08625, 2025.  \n[234] Utkarsh Ojha, Yuheng Li, Anirudh Sundara Rajan, Yingyu Liang, and Yong Jae Lee. What knowledge gets distilled in knowledge distillation? Advances in Neural Information Processing Systems, 36:11037-11048, 2023.  \n[235] Kai Tzu-iunn Ong, Namyoung Kim, Minju Gwak, Hyungjoo Chae, Taeyoon Kwon, Yohan Jo, Seung-won Hwang, Dongha Lee, and Jinyoung Yeo. Towards lifelong dialogue agents via timeline-based memory management. arXiv preprint arXiv:2406.10996, 2024.  \n[236] OpenAI. Chatgpt: Language model. https://openai.com/, 2023.  \n[237] OpenAI. Deep research system card. Technical report, OpenAI, February 2025.  \n[238] OpenAI. Deep research, 2025. URL https://openai.com/index/introducing-deep-research/.  \n[239] OpenManus. Openmanus: An open multi-agent research framework. https://openmanus.github.io/, 2025. Accessed: 2025-11-13.  \n[240] Litu Ou, Kuan Li, Huifeng Yin, Liwen Zhang, Zhongwang Zhang, Xixi Wu, Rui Ye, Zile Qiao, Pengjun Xie, Jingren Zhou, et al. Browsc: Confidence-guided test-time scaling for web agents. arXiv preprint arXiv:2510.23458, 2025.  \n[241] Anne Ouyang, Simon Guo, Simran Arora, Alex L. Zhang, William Hu, Christopher R'e, and Azalia Mirhoseini. Kernelbench: Can llms write efficientgpu kernels? arXiv preprint arXiv: 2502.10517, 2025.  \n[242] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 2022.  \n[243] Charles Packer, Vivian Fang, Shishir_G Patil, Kevin Lin, Sarah Wooders, and Joseph_E Gonzalez. Memgpt: Towards llms as operating systems. arXiv preprint arXiv:2310.08560, 2023.  \n[244] Wei Pang, Kevin Qinghong Lin, Xiangru Jian, Xi He, and Philip Torr. Paper2poster: Towards multimodal poster automation from scientific papers. arXiv preprint arXiv:2505.21497, 2025.\n\n[245] Joon Sung Park, Joseph O'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on user interface software and technology, 2023.  \n[246] Mihir Parmar, Nisarg Patel, Neeraj Varshney, Mutsumi Nakamura, Man Luo, Santosh Mashetty, Arindam Mitra, and Chitta Baral. Towards systematic evaluation of logical reasoning ability of large language models. CoRR, 2024.  \n[247] Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, and Siliang Tang. Graph retrieval-augmented generation: A survey. arXiv preprint arXiv:2408.08921, 2024.  \n[248] Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, and Wenjun Wang. Review: Harnessing large language models for personalized review generation. arXiv preprint arXiv:2407.07487, 2024.  \n[249] Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanity's last exam. arXiv preprint arXiv:2501.14249, 2025.  \n[250] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring and narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350, 2022.  \n[251] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring and narrowing the compositionality gap in language models. In *The 2023 Conference on Empirical Methods in Natural Language Processing*, 2023.  \n[252] Zehan Qi, Xiao Liu, Iat Long Iong, Hanyu Lai, Xueqiao Sun, Wenyi Zhao, Yu Yang, Xinyue Yang, Jiadai Sun, Shuntian Yao, et al. Webrl: Training llm web agents via self-evolving online curriculum reinforcement learning. arXiv preprint arXiv:2411.02337, 2024.  \n[253] Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, et al. Webresearcher: Unleashing unbounded reasoning capability in long-horizon agents. arXiv preprint arXiv:2509.13309, 2025.  \n[254] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toollm: Facilitating large language models to master 16000+ real-world apis. In International Conference on Learning Representations, 2023.  \n[255] Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Le Yan, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, et al. Large language models are effective text rankers with pairwise ranking prompting. arXiv preprint arXiv:2306.17563, 2023.  \n[256] Jiahao Qiu, Xinzhe Juan, Yimin Wang, Ling Yang, Xuan Qi, Tongcheng Zhang, Jiacheng Guo, Yifu Lu, Zixin Yao, Hongru Wang, et al. Agentdistill: Training-free agent distillation with generalizable mcp boxes. arXiv preprint arXiv:2506.14728, 2025.  \n[257] Jiahao Qiu, Xuan Qi, Tongcheng Zhang, Xinzhe Juan, Jiacheng Guo, Yifu Lu, Yimin Wang, Zixin Yao, Qihan Ren, Xun Jiang, et al. Alita: Generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal self-evolution. arXiv preprint arXiv:2505.20286, 2025.\n\n[258] Yansheng Qiu, Haoquan Zhang, Zhaopan Xu, Ming Li, Diping Song, Zheng Wang, and Kaipeng Zhang. Ai idea bench 2025: Ai research idea generation benchmark. arXiv preprint arXiv:2504.14191, 2025.  \n[259] Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang. Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2010.08191, 2020.  \n[260] Haoran Que, Feiyu Duan, Liqu He, Yutao Mou, Wangchunshu Zhou, Jiaheng Liu, Wenge Rong, Zekun Moore Wang, Jian Yang, Ge Zhang, et al. Hellobench: Evaluating long text generation capabilities of large language models. arXiv preprint arXiv:2409.16191, 2024.  \n[261] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, 2021.  \n[262] Preston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, and Daniel Chalef. Zep: a temporal knowledge graph architecture for agent memory. arXiv preprint arXiv:2501.13956, 2025.  \n[263] David Lau, Shuai Wang, Hervé Déjean, and Stéphane Clinchant. Context embeddings for efficient answer generation in rag. arXiv preprint arXiv:2407.09252, 2024.  \n[264] Alistair Reid, Simon O'Callaghan, Liam Carroll, and Tiberio Caetano. Risk analysis techniques for governed llm-based multi-agent systems. arXiv preprint arXiv:2508.05687, 2025.  \n[265] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R Bowman. Gpqa: A graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024.  \n[266] Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hua Wu, Ji-Rong Wen, and Haifeng Wang. Investigating the factual knowledge boundary of large language models with retrieval augmentation. In Proceedings of the 31st International Conference on Computational Linguistics, 2025.  \n[267] ZZ Ren, Zhihong Shao, Junxiao Song, Huajian Xin, Haocheng Wang, Wanjia Zhao, Liyue Zhang, Zhe Fu, Qihao Zhu, Dejian Yang, et al. Deepseek-prover-v2: Advancing formal mathematical reasoning via reinforcement learning for subgoal decomposition. arXiv preprint arXiv:2504.21801, 2025.  \n[268] Alireza Rezazadeh, Zichao Li, Wei Wei, and Yujia Bao. From isolated conversations to hierarchical schemas: Dynamic tree memory representation for llms. arXiv preprint arXiv:2410.14052, 2024.  \n[269] Stephen Robertson and Hugo Zaragoza. The Probabilistic Relevance Framework: BM25 and Beyond. Now Publishers Inc., 2009.  \n[270] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, Jordan S. Ellenberg, Pengming Wang, Omar Fawzi, Pushmeet Kohli, Alhussein Fawzi, Josh Grochow, Andrea Lodi, Jean-Baptiste Mouret, Talia Ringer, and Tao Yu. Mathematical discoveries from program search with large language models. Nature, 2023.\n\n[271] Nirmal Roy, Leonardo F. R. Ribeiro, Rexhina Blloshmi, and Kevin Small. Learning when to retrieve, what to rewrite, and how to respond in conversational QA. In Findings of the Association for Computational Linguistics: EMNLP 2024, 2024.  \n[272] Aishwarya Sahoo, Jeevana Kruthi Karnuthala, Tushar Parmanand Budhwani, Pranchal Agarwal, Sankaran Vaidyanathan, Alexa Siu, Franck Dernoncourt, Jennifer Healey, Nedim Lipka, Ryan Rossi, et al. Quantitative llm judges. arXiv preprint arXiv:2506.02945, 2025.  \n[273] Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. Colbertv2: Effective and efficient retrieval via lightweight late interaction. arXiv preprint arXiv:2112.01488, 2021.  \n[274] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools, 2023. URL https://arxiv.org/abs/2302.04761.  \n[275] John Schulman, Philipp Moritz, Sergey Levine, Michael I. Jordan, and P. Abbeel. High-dimensional continuous control using generalized advantage estimation. CoRR, 2015.  \n[276] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.  \n[277] Hinrich Schütze, Christopher D Manning, and Prabhakar Raghavan. Introduction to information retrieval, volume 39. Cambridge University Press Cambridge, 2008.  \n[278] Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. Character-llm: A trainable agent for role-playing. arXiv preprint arXiv:2310.10158, 2023.  \n[279] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[280] Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, and Xin Wang. Understanding the information propagation effects of communication topologies in llm-based multi-agent systems. arXiv preprint arXiv:2505.23352, 2025.  \n[281] Zhang Shengyu, Dong Linfeng, Li Xiaoya, Zhang Sen, Sun Xiaofei, Wang Shuhe, Li Jiwei, Runyi Hu, Zhang Tianwei, Fei Wu, et al. Instruction tuning for large language models: A survey. arXiv preprint arXiv:2308.10792, 2023.  \n[282] Wenxuan Shi, Haochen Tan, Chuqiao Kuang, Xiaoguang Li, Xiaozhe Ren, Chen Zhang, Hanting Chen, Yasheng Wang, Lifeng Shang, Fisher Yu, et al. Pangu deepdiver: Adaptive search intensity scaling via open-web reinforcement learning. arXiv preprint arXiv:2505.24332, 2025.  \n[283] Yaorui Shi, Shihan Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, and Xiang Wang. Search and refine during think: Autonomous retrieval-augmented reasoning of llms. arXiv e-prints, pages arXiv-2505, 2025.  \n[284] Zhengliang Shi, Shen Gao, Zhen Zhang, Xiuying Chen, Zhumin Chen, Pengjie Ren, and Zhaochun Ren. Towards a unified framework for reference retrieval and related work generation. In Findings of the Association for Computational Linguistics, 2023.\n\n[285] Zhengliang Shi, Shen Gao, Xiuyi Chen, Yue Feng, Lingyong Yan, Haibo Shi, Dawei Yin, Pengjie Ren, Suzan Verberne, and Zhaochun Ren. Learning to use tools via cooperative and interactive agents. In Findings of the Association for Computational Linguistics: EMNLP 2024, 2024.  \n[286] Zhengliang Shi, Shuo Zhang, Weiwei Sun, Shen Gao, Pengjie Ren, Zhumin Chen, and Zhaochun Ren. Generate-then-ground in retrieval-augmented generation for multi-hop question answering. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2024.  \n[287] Zhengliang Shi, Shen Gao, Lingyong Yan, Yue Feng, Xiuyi Chen, Zhumin Chen, Dawei Yin, Suzan Verberne, and Zhaochun Ren. Tool learning in the wild: Empowering language models as automatic tool agents. In Proceedings of the ACM on Web Conference 2025, pages 2222-2237, 2025.  \n[288] Zhengliang Shi, Ruotian Ma, Jen-tse Huang, Xinbei Ma, Xingyu Chen, Mengru Wang, Qu Yang, Yue Wang, Fanghua Ye, Ziyang Chen, et al. Social welfare function leaderboard: When llm agents allocate social welfare. arXiv preprint arXiv:2510.01164, 2025.  \n[289] Zhengliang Shi, Lingyong Yan, Dawei Yin, Suzan Verberne, Maarten de Rijke, and Zhaochun Ren. Iterative self-incentivization empowers large language models as agentic searchers. arXiv preprint arXiv:2505.20128, 2025.  \n[290] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflection: Language agents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36, 2023.  \n[291] Parshin Shojaee, Kazem Meidani, Shashank Gupta, Amir Barati Farimani, and Chandan K Reddy. Llm-sr: Scientific equation discovery via programming with large language models. arXiv preprint arXiv:2404.18400, 2024.  \n[292] Parshin Shojaee, Ngoc-Hieu Nguyen, Kazem Meidani, Amir Barati Farimani, Khoa D Doan, and Chandan K Reddy. Llm-srbench: A new benchmark for scientific equation discovery with large language models. arXiv preprint arXiv:2504.10415, 2025.  \n[293] Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson. The curse of recursion: Training on generated data makes models forget. arXiv preprint arXiv:2305.17493, 2023.  \n[294] Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson, and Yarin Gal. Ai models collapse when trained on recursively generated data. Nature, 2024.  \n[295] Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Boyd-Graber, and Lijuan Wang. Prompting gpt-3 to be reliable. arXiv preprint arXiv:2210.09150, 2022.  \n[296] Chenglei Si, Diyi Yang, and Tatsunori Hashimoto. Can llms generate novel research ideas? a large-scale human study with  $100+$  nlp researchers. arXiv preprint arXiv:2409.04109, 2024.  \n[297] Zachary S Siegel, Sayash Kapoor, Nitya Nagdir, Benedikt Stroebl, and Arvind Narayanan. Corebench: Fostering the credibility of published research through a computational reproducibility agent benchmark. arXiv preprint arXiv:2409.11363, 2024.\n\n[298] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. Mastering the game of go without human knowledge. nature, 2017.  \n[299] Amit Singhal et al. Modern information retrieval: A brief overview. IEEE Data Eng. Bull., 2001.  \n[300] Huatong Song, Jinhao Jiang, Yingqian Min, Jie Chen, Zhipeng Chen, Wayne Xin Zhao, Lei Fang, and Ji-Rong Wen. R1-searcher: Incentivizing the search capability in llms via reinforcement learning. arXiv preprint arXiv:2503.05592, 2025.  \n[301] Huatong Song, Jinhao Jiang, Wenqing Tian, Zhipeng Chen, Yuhuan Wu, Jiahao Zhao, Yingqian Min, Wayne Xin Zhao, Lei Fang, and Ji-Rong Wen. R1-searcher++: Incentivizing the dynamic knowledge acquisition of llms via reinforcement learning. arXiv preprint arXiv:2505.17005, 2025.  \n[302] Zayne Sprague, Fangcong Yin, Juan Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi Ye, Kyle Mahowald, and Greg Durrett. To cot or not to cot? chain-of-thought helps mainly on math and symbolic reasoning. arXiv preprint arXiv:2409.12183, 2024.  \n[303] Larry R Squire, Lisa Genzel, John T Wixted, and Richard G Morris. Memory consolidation. Cold Spring Harbor perspectives in biology, 7(8):a021766, 2015.  \n[304] Giulio Starace, Oliver Jaffe, Dane Sherburn, James Aung, Jun Shern Chan, Leon Maksin, Rachel Dias, Evan Mays, Benjamin Kinsella, Wyatt Thompson, et al. Paperbench: Evaluating ai's ability to replicate ai research. arXiv preprint arXiv:2504.01848, 2025.  \n[305] Buxin Su, Jiayao Zhang, Natalie Collina, Yuling Yan, Didong Li, Kyunghyun Cho, Jianqing Fan, Aaron Roth, and Weijie Su. The icml 2023 ranking experiment: Examining author self-assessment in ml/ai peer review. Journal of the American Statistical Association, pages 1-16, 2025.  \n[306] Haoyang Su, Renqi Chen, Shixiang Tang, Xinzhe Zheng, Jingzhe Li, Zhenfei Yin, Wanli Ouyang, and Nanqing Dong. Two heads are better than one: A multi-agent system has the potential to improve scientific idea generation. CoRR, 2024.  \n[307] Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang, Kuan Li, Jialong Wu, Xuanzhong Chen, et al. Scaling agents via continual pre-training. arXiv preprint arXiv:2509.13310, 2025.  \n[308] Weihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, and Yiqun Liu. Dragin: dynamic retrieval augmented generation based on the information needs of large language models. arXiv preprint arXiv:2403.10081, 2024.  \n[309] Weihang Su, Changyue Wang, Qingyao Ai, Yiran Hu, Zhijing Wu, Yujia Zhou, and Yiqun Liu. Unsupervised real-time hallucination detection based on the internal states of large language models. arXiv preprint arXiv:2403.06448, 2024.  \n[310] Hao Sun, Hengyi Cai, Bo Wang, Yingyan Hou, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, and Dawei Yin. Towards verifiable text generation with evolving memory and self-reflection. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 2024.\n\n[311] Hao Sun, Zile Qiao, Jiayan Guo, Xuanbo Fan, Yingyan Hou, Yong Jiang, Pengjun Xie, Yan Zhang, Fei Huang, and Jingren Zhou. Zerosearch: Incentivize the search capability of llms without searching. arXiv preprint arXiv:2505.04588, 2025.  \n[312] Haoran Sun and Shaoning Zeng. Hierarchical memory for high-efficiency long-term reasoning in llm agents. arXiv preprint arXiv:2507.22925, 2025.  \n[313] Jiashuo Sun, Xianrui Zhong, Sizhe Zhou, and Jiawei Han. Dynamiccrag: Leveraging outputs of large language model as feedback for dynamic reranking in retrieval-augmented generation, 2025.  \n[314] Shuang Sun, Huatong Song, Yuhao Wang, Ruiyang Ren, Jinhao Jiang, Junjie Zhang, Fei Bai, Jia Deng, Wayne Xin Zhao, Zheng Liu, et al. Simpledeepsearcher: Deep information seeking via web-powered reasoning trajectory synthesis. arXiv preprint arXiv:2505.16834, 2025.  \n[315] Tao Sun, Enhao Pan, Zhengkai Yang, Kaixin Sui, Jiajun Shi, Xianfu Cheng, Tongliang Li, Wenhao Huang, Ge Zhang, Jian Yang, et al. P2p: Automated paper-to-poster generation and fine-grained benchmark. arXiv preprint arXiv:2505.17104, 2025.  \n[316] Weiwei Sun, Zhengliang Shi, Shen Gao, Pengjie Ren, Maarten de Rijke, and Zhaochun Ren. Contrastive learning reduces hallucination in conversations. In Proceedings of the AAAI Conference on Artificial Intelligence, 2023.  \n[317] Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and Zhaochun Ren. Is chatgpt good at search? investigating large language models as re-ranking agents. arXiv preprint arXiv:2304.09542, 2023.  \n[318] Weiwei Sun, Shengyu Feng, Shanda Li, and Yiming Yang. Co-bench: Benchmarking language model agents in algorithm search for combinatorial optimization. arXiv preprint arXiv: 2504.04310, 2025.  \n[319] Weiwei Sun, Miao Lu, Zhan Ling, Kang Liu, Xuesong Yao, Yiming Yang, and Jiecao Chen. Scaling long-horizon llm agent via context-folding. arXiv preprint arXiv:2510.11967, 2025.  \n[320] supermancmk. when running the official gsm8k with tool, multi turn async rollout sglang example without any modifications, the model crashes and appears nan. https://github.com/volcengine/verl/issues/1581, 2025.  \n[321] Jihoon Tack, Jaehyung Kim, Eric Mitchell, Jinwoo Shin, Yee Whye Teh, and Jonathan Richard Schwarz. Online adaptation of language models with a memory of amortized contexts. Advances in Neural Information Processing Systems, 2024.  \n[322] Haochen Tan, Zhijiang Guo, Zhan Shi, Lu Xu, Zhili Liu, Yunlong Feng, Xiaoguang Li, Yasheng Wang, Lifeng Shang, Qun Liu, et al. Proxyqa: An alternative framework for evaluating long-form text generation with large language models. arXiv preprint arXiv:2401.15042, 2024.  \n[323] Jiejun Tan, Zhicheng Dou, Wen Wang, Mang Wang, Weipeng Chen, and Ji-Rong Wen. HtmIrag:Html is better than plain text for modeling retrieved knowledge in rag systems. In Proceedings of the ACM on Web Conference 2025, 2025.\n\n[324] Jiejun Tan, Zhicheng Dou, Yan Yu, Jiehan Cheng, Qiang Ju, Jian Xie, and Ji-Rong Wen. Hiersearch: A hierarchical enterprise deep search framework integrating local and web searches. arXiv preprint arXiv:2508.08088, 2025.  \n[325] Zhen Tan, Jun Yan, I Hsu, Rujun Han, Zifeng Wang, Long T Le, Yiwen Song, Yanfei Chen, Hamid Palangi, George Lee, et al. In prospect and retrospect: Reflective memory management for long-term personalized dialogue agents. arXiv preprint arXiv:2503.08026, 2025.  \n[326] Jiabin Tang, Lianghao Xia, Zhonghang Li, and Chao Huang. AI-researcher: Autonomous scientific innovation. arXiv preprint arXiv:2505.18705, 2025.  \n[327] Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, Prasann Singhal, Manya Wadhwa, Zeyu Leo Liu, Zayne Sprague, Ramya Namuduri, Bodun Hu, Juan Diego Rodriguez, Puyuan Peng, and Greg Durrett. Chartmuseum: Testing visual reasoning capabilities of large vision-language models. arXiv preprint arXiv:2505.13444, 2025.  \n[328] Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Tian Jin, Xiaowen Dong, Yanfeng Wang, and Siheng Chen. Synthesizing post-training data for llms through multi-agent simulation. arXiv preprint arXiv:2410.14251, 2024.  \n[329] Xiangru Tang, Tianrui Qin, Tianhao Peng, Ziyang Zhou, Daniel Shao, Tingting Du, Xinming Wei, Peng Xia, Fang Wu, He Zhu, et al. Agent kb: Leveraging cross-domain experience for agentic problem solving. arXiv preprint arXiv:2507.06229, 2025.  \n[330] Xiaqiang Tang, Jian Li, Keyu Hu, Du Nan, Xiaolong Li, Xi Zhang, Weigao Sun, and Sihong Xie. Cognibench: A legal-inspired framework and dataset for assessing cognitive faithfulness of large language models. arXiv preprint arXiv:2505.20767, 2025.  \n[331] Yihong Tang, Zhaokai Wang, Ao Qu, Yihao Yan, Zhaofeng Wu, Dingyi Zhuang, Jushi Kai, Kebing Hou, Xiaotong Guo, Han Zheng, et al. Itinera: Integrating spatial optimization with large language models for open-domain urban itinerary planning. arXiv preprint arXiv:2402.07204, 2024.  \n[332] Yixuan Tang and Yi Yang. Multihop-rag: Benchmarking retrieval-augmented generation for multi-hop queries. arXiv preprint arXiv:2401.15391, 2024.  \n[333] Md Mehrab Tanjim, Yeonjun In, Xiang Chen, Victor S Bursztyn, Ryan A Rossi, Sungchul Kim, Guang-Jie Ren, Vaishnavi Muppala, Shun Jiang, Yongsung Kim, et al. Disambiguation in conversational question answering in the era of llm: A survey. arXiv preprint arXiv:2505.12543, 2025.  \n[334] Zhengwei Tao, Haiyang Shen, Baixuan Li, Wenbiao Yin, Jialong Wu, Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Liwen Zhang, et al. Webleaper: Empowering efficiency and efficacy in webagent via enabling info-rich seeking. arXiv preprint arXiv:2510.24697, 2025.  \n[335] Zhengwei Tao, Jialong Wu, Wenbiao Yin, Junkai Zhang, Baixuan Li, Haiyang Shen, Kuan Li, Liwen Zhang, Xinyu Wang, Yong Jiang, et al. Webshaper: Agentically data synthesizing via information-seeking formalization. arXiv preprint arXiv:2507.15061, 2025.  \n[336] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Stanford alpaca: An instruction-following llama model, 2023.\n\n[337] Anthropic Engineering Team. How we built our multi-agent research system, June 2025. URL https://www.anthropic.com/engineering/built-multi-agent-research-system. Accessed 2025-08-27.  \n[338] Kimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, et al. Kimi k2: Open agentic intelligence. arXiv preprint arXiv:2507.20534, 2025.  \n[339] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERIFICATION. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2018.  \n[340] Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher D Manning. Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback. arXiv preprint arXiv:2305.14975, 2023.  \n[341] Shulin Tian, Ziniu Zhang, Liangyu Chen, and Ziwei Liu. Mmina: Benchmarking multihop multimodal internet agents. arXiv preprint arXiv:2404.09992, 2024.  \n[342] Yong-En Tian, Yu-Chien Tang, Kuang-Da Wang, An-Zi Yen, and Wen-Chih Peng. Template-based financial report generation in agentic and decomposed information retrieval. arXiv preprint arXiv:2504.14233, 2025.  \n[343] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv preprint arXiv:2212.10509, 2022.  \n[344] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Musique: Multihop questions via single-hop question composition. Transactions of the Association for Computational Linguistics, 10, 2022.  \n[345] George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, and Swarat Chaudhuri. Putnambench: Evaluating neural theorem-provers on the putnam mathematical competition. Advances in Neural Information Processing Systems, 2024.  \n[346] Dibia Victor. Lida: A tool for automatic generation of grammar-agnostic visualizations and infographics using large language models. arXiv preprint arXiv:2303.02927, 2023.  \n[347] Alisa Vinogradova, Vlad Vinogradov, Dmitrii Radkevich, Ilya Yasny, Dmitry Kobyzev, Ivan Izmailov, Katsiaryna Yanchanka, Roman Doronin, and Andrey Doronichev. Llm-based agents for competitive landscape mapping in drug asset due diligence. arXiv preprint arXiv:2508.16571, 2025.  \n[348] Yuxuan Wan, Wenxuan Wang, Yiliu Yang, Youliang Yuan, Jen-tse Huang, Pinjia He, Wenxiang Jiao, and Michael Lyu. Logicaker: Evaluating and improving the logical reasoning ability of large language models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, 2024.\n\n[349] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023.  \n[350] Han Wang, Archiki Prasad, Elias Stengel-Eskin, and Mohit Bansal. Retrieval-augmented generation with conflicting evidence. In Second Conference on Language Modeling, 2025.  \n[351] Han Wang, Archiki Prasad, Elias Stengel-Eskin, and Mohit Bansal. Retrieval-augmented generation with conflicting evidence. arXiv preprint arXiv:2504.13079, 2025.  \n[352] Jiayu Wang, Yifei Ming, Riya Dulepet, Qinglin Chen, Austin Xu, Zixuan Ke, Frederic Sala, Aws Albarghouthi, Caiming Xiong, and Shafiq Joty. Liversearchbench: A live benchmark for user-centric deep research in the wild. arXiv preprint arXiv:2510.14240, 2025.  \n[353] Juyuan Wang, Rongchen Zhao, Wei Wei, Yufeng Wang, Mo Yu, Jie Zhou, Jin Xu, and Liyan Xu. Comorag: A cognitive-inspired memory-organized rag for stateful long narrative reasoning. arXiv preprint arXiv:2508.10419, 2025.  \n[354] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533, 2022.  \n[355] Liang Wang, Nan Yang, and Furu Wei. Learning to retrieve in-context examples for large language models. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics, March 2024.  \n[356] Maggie Wang, Ella Colby, Jennifer Okwara, Varun Nagaraj Rao, Yuhan Liu, and Andrés Monroy-Hernández. Policypulse: Llm-synthesis tool for policy researchers. In Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, 2025.  \n[357] Peng Wang, Zexi Li, Ningyu Zhang, Ziwen Xu, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, and Huajun Chen. Wise: Rethinking the knowledge memory for lifelong model editing of large language models. Advances in Neural Information Processing Systems, 2024.  \n[358] Qingyue Wang, Yanhe Fu, Yanan Cao, Shuai Wang, Zhiliang Tian, and Liang Ding. Recursively summarizing enables long-term dialogue memory in large language models. Neurocomputing, 639:130193, 2025.  \n[359] Ruoyao Wang, Peter Jansen, Marc-Alexandre Côté, and Prithviraj Ammanabrolu. Scicnceworld: Is your agent smarter than a 5th grader? arXiv preprint arXiv:2203.07540, 2022.  \n[360] Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, Marc-Alexandre Côté, Peter Clark, and Peter Jansen. Can language models serve as text-based world simulators? arXiv preprint arXiv:2406.06485, 2024.  \n[361] Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, and Jundong Li. Knowledge editing for large language models: A survey. ACM Computing Surveys, 2024.  \n[362] Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, et al. Openhands: An open platform for ai software developers as generalist agents. arXiv preprint arXiv:2407.16741, 2024.\n\n[363] Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Shuchang Zhou, et al. Coser: Coordinating llm-based persona simulation of established roles. In The Forty-second International Conference on Machine Learning, 2025.  \n[364] Yanling Wang, Haoyang Li, Hao Zou, Jing Zhang, Xinlei He, Qi Li, and Ke Xu. Hidden question representations tell non-factuality within and across large language models. arXiv preprint arXiv:2406.05328, 2024.  \n[365] Yao Wang, Mingxuan Cui, and Arthur Jiang. Enabling ai scientists to recognize innovation: A domain-agnostic algorithm for assessing novelty. arXiv preprint arXiv:2503.01508, 2025.  \n[366] Yidong Wang, Qi Guo, Wenjin Yao, Hongbo Zhang, Xin Zhang, Zhen Wu, Meishan Zhang, Xinyu Dai, Qingsong Wen, Wei Ye, et al. Autosurvey: Large language models can automatically write surveys. Advances in neural information processing systems, 2024.  \n[367] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated instructions. arXiv preprint arXiv:2212.10560, 2022.  \n[368] Yu Wang and Xi Chen. Mirix: Multi-agent memory system for llm-based agents. arXiv preprint arXiv:2507.07957, 2025.  \n[369] Yu Wang, Yifan Gao, Xiusi Chen, Haoming Jiang, Shiyang Li, Jingfeng Yang, Qingyu Yin, Zheng Li, Xian Li, Bing Yin, et al. Memoryllm: Towards self-updatable large language models. arXiv preprint arXiv:2402.04624, 2024.  \n[370] Yu Wang, Chi Han, Tongtong Wu, Xiaoxin He, Wangchunshu Zhou, Nafis Sadeq, Xiusi Chen, Zexue He, Wei Wang, Gholamreza Haffari, et al. Towards lifespan cognitive systems. arXiv preprint arXiv:2409.13265, 2024.  \n[371] Yuhao Wang, Ruiyang Ren, Junyi Li, Wayne Xin Zhao, Jing Liu, and Ji-Rong Wen. Rear: A relevance-aware retrieval-augmented framework for open-domain question answering. arXiv preprint arXiv:2402.17497, 2024.  \n[372] Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, and Haifeng Wang. Reinforced informativeness optimization for long-form retrieval-augmented generation, 2025.  \n[373] Zihan Wang, Kangrui Wang, Qineng Wang, Pingyue Zhang, Linjie Li, Zhengyuan Yang, Xing Jin, Kefan Yu, Minh Nhat Nguyen, Licheng Liu, et al. Ragen: Understanding self-evolution in llm agents via multi-turn reinforcement learning. arXiv preprint arXiv:2504.20073, 2025.  \n[374] Ziliang Wang, Xuhui Zheng, Kang An, Cijun Ouyang, Jialu Cai, Yuhang Wang, and Yichao Wu. Stepsearch: Igniting llms search ability via step-wise proximal policy optimization. arXiv preprint arXiv:2505.15107, 2025.  \n[375] Anjiang Wei, Yuheng Wu, Yingjia Wan, Tarun Suresh, Huanmi Tan, Zhanke Zhou, Sanmi Koyejo, Ke Wang, and Alex Aiken. Satbench: Benchmarking llms' logical reasoning via automated puzzle generation from sat formulas. arXiv preprint arXiv:2505.14615, 2025.\n\n[376] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 2022.  \n[377] Jason Wei, Nguyen Karina, Hyung Won Chung, Yunxin Joy Jiao, Spencer Papay, Amelia Glaese, John Schulman, and William Fedus. Measuring short-form factuality in large language models. arXiv preprint arXiv:2411.04368, 2024.  \n[378] Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia Glaese. Browsecomp: A simple yet challenging benchmark for browsing agents. arXiv preprint arXiv:2504.12516, 2025.  \n[379] Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Jie Huang, Dustin Tran, Daiyi Peng, Ruibo Liu, Da Huang, et al. Long-form factuality in large language models. Advances in Neural Information Processing Systems, 2024.  \n[380] Rubin Wei, Jiaqi Cao, Jiarui Wang, Jushi Kai, Qipeng Guo, Bowen Zhou, and Zhouhan Lin. Mlp memory: Language modeling with retriever-pretrained external memory. arXiv preprint arXiv:2508.01832, 2025.  \n[381] Zhepei Wei, Wei-Lin Chen, and Yu Meng. Instructrag: Instructing retrieval-augmented generation via self-synthesized rationales. arXiv preprint arXiv:2406.13629, 2024.  \n[382] Zhepei Wei, Wenlin Yao, Yao Liu, Weizhi Zhang, Qin Lu, Liang Qiu, Changlong Yu, Puyang Xu, Chao Zhang, Bing Yin, et al. Webagent-r1: Training web agents via end-to-end multi-turn reinforcement learning. arXiv preprint arXiv:2505.16421, 2025.  \n[383] Yixuan Weng and Bin Li. Visual answer localization with cross-modal mutual knowledge transfer. In ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023.  \n[384] Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, and Linyi Yang. Cycleresearcher: Improving automated research via automated review. arXiv preprint arXiv:2411.00816, 2024.  \n[385] Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang, and Linyi Yang. Cycleresearcher: Improving automated research via automated review. In The Thirteenth International Conference on Learning Representations, 2025.  \n[386] Yixuan Weng, Minjun Zhu, Qiujie Xie, Qiyao Sun, Zhen Lin, Sifan Liu, and Yue Zhang. Deepscientist: Advancing frontier-pushing scientific findings progressively. arXiv preprint arXiv:2509.26603, 2025.  \n[387] Hjalmar Wijk, Tao Lin, Joel Becker, Sami Jawhar, Neev Parikh, Thomas Broadley, Lawrence Chan, Michael Chen, Josh Clymer, Jai Dhyani, et al. Re-bench: Evaluating frontier ai r&d capabilities of language model agents against human experts. arXiv preprint arXiv:2411.15114, 2024.  \n[388] Ryan Wong, Jiawei Wang, Junjie Zhao, Li Chen, Yan Gao, Long Zhang, Xuan Zhou, Zuo Wang, Kai Xiang, Ge Zhang, et al. Widesearch: Benchmarking agentic broad info-seeking. arXiv preprint arXiv:2508.07999, 2025.\n\n[389] Chen Henry Wu. Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction. In International Conference on Machine Learning, 2025.  \n[390] Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, and Dong Yu. Longmemeval: Benchmarking chat assistants on long-term interactive memory. arXiv preprint arXiv:2410.10813, 2024.  \n[391] Jialong Wu, Baixuan Li, Runnan Fang, Wenbiao Yin, Liwen Zhang, Zhengwei Tao, Dingchu Zhang, Zekun Xi, Gang Fu, Yong Jiang, et al. Webdancer: Towards autonomous information seeking agency. arXiv preprint arXiv:2505.22648, 2025.  \n[392] Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Linhai Zhang, Yulan He, Deyu Zhou, Pengjun Xie, et al. Webwalker: Benchmarking llms in web traversal. arXiv preprint arXiv:2501.07572, 2025.  \n[393] Jiayi Wu, Hengyi Cai, Lingyong Yan, Hao Sun, Xiang Li, Shuaiqiang Wang, Dawei Yin, and Ming Gao. Pa-rag: Rag alignment via multi-perspective preference optimization. arXiv preprint arXiv:2412.14510, 2024.  \n[394] Jinming Wu, Zihao Deng, Wei Li, Yiding Liu, Bo You, Bo Li, Zejun Ma, and Ziwei Liu. Mmsearchr1: Incentivizing lmms to search. arXiv preprint arXiv:2506.20670, 2025.  \n[395] Mingyan Wu, Zhenghao Liu, Yukun Yan, Xinze Li, Shi Yu, Zheni Zeng, Yu Gu, and Ge Yu. Rankcot: Refining knowledge for retrieval-augmented generation through ranking chain-of-thoughts. arXiv preprint arXiv:2502.17888, 2025.  \n[396] Peilin Wu, Mian Zhang, Xinlu Zhang, Xinya Du, and Zhiyu Chen. Search wisely: Mitigating sub-optimal agentic searches by reducing uncertainty. In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, 2025.  \n[397] Weiqi Wu, Xin Guan, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Jiumin Cao, Hai Zhao, and Jingren Zhou. Masksearch: A universal pre-training framework to enhance agentic search capability. arXiv preprint arXiv:2505.20285, 2025.  \n[398] Yaxiong Wu, Sheng Liang, Chen Zhang, Yichao Wang, Yongyue Zhang, Huifeng Guo, Ruiming Tang, and Yong Liu. From human memory to ai memory: A survey on memory mechanisms in the era of llms. arXiv preprint arXiv:2504.15965, 2025.  \n[399] Yuhao Wu, Yushi Bai, Zhiqiang Hu, Juanzi Li, and Roy Ka-Wei Lee. Superwriter: Reflection-driven long-form generation with large language models, 2025.  \n[400] xAI. Grok deepsearch, 2025. URL https://grok.com/.  \n[401] Yunjia Xi, Jianghao Lin, Yongzhao Xiao, Zheli Zhou, Rong Shan, Te Gao, Jiachen Zhu, Weiwen Liu, Yong Yu, and Weinan Zhang. A survey of llm-based deep search agents: Paradigm, optimization, evaluation, and challenges. arXiv preprint arXiv:2508.05668, 2025.  \n[402] Yunjia Xi, Jianghao Lin, Menghui Zhu, Yongzhao Xiao, Zhuoying Ou, Jiaqi Liu, Tong Wan, Bo Chen, Weiwen Liu, Yasheng Wang, et al. Infodeepseek: Benchmarking agentic information seeking for retrieval-augmented generation. arXiv preprint arXiv:2505.15872, 2025.\n\n[403] Fei Xia, Bin Li, Yixuan Weng, Shizhu He, Kang Liu, Bin Sun, Shutao Li, and Jun Zhao. MedConQA: Medical conversational question answering system based on knowledge graphs. In Wanxiang Che and Ekaterina Shutova, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 2022.  \n[404] Renqiu Xia, Bo Zhang, Hancheng Ye, Xiangchao Yan, Qi Liu, Hongbin Zhou, Zijun Chen, Peng Ye, Min Dou, Botian Shi, Junchi Yan, and Yu Qiao. Chartx & chartvlm: A versatile benchmark and foundation model for complicated chart reasoning. arXiv preprint arXiv:2402.12185, 2024.  \n[405] Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, and Yu Rong. Analyzing llms' knowledge boundary cognition across languages through the lens of internal representations. arXiv preprint arXiv:2504.13816, 2025.  \n[406] Shitao Xiao, Zheng Liu, Peitian Zhang, Niklas Muennighoff, Defu Lian, and Jian-Yun Nie. C-pack: Packed resources for general chinese embeddings. In Proceedings of the 47th international ACM SIGIR conference on research and development in information retrieval, pages 641-649, 2024.  \n[407] Qiujie Xie, Qiming Feng, Yuejie Zhang, Rui Feng, Tao Zhang, and Shang Gao. Controlcap: Controllable captioning via no-fuss lexicon. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 8326-8330. IEEE, 2024.  \n[408] Qiujie Xie, Yixuan Weng, Minjun Zhu, Fuchen Shen, Shulin Huang, Zhen Lin, Jiahui Zhou, Zilan Mao, Zijie Yang, Linyi Yang, et al. How far are ai scientists from changing the world? arXiv preprint arXiv:2507.23276, 2025.  \n[409] Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms. arXiv preprint arXiv:2306.13063, 2023.  \n[410] Fangyuan Xu, Weijia Shi, and Eunsol Choi. Recomp: Improving retrieval-augmented lms with compression and selective augmentation. arXiv preprint arXiv:2310.04408, 2023.  \n[411] Mufan Xu, Gewen Liang, Kehai Chen, Wei Wang, Xun Zhou, Muyun Yang, Tiejun Zhao, and Min Zhang. Memory-augmented query reconstruction for llm-based knowledge graph reasoning. arXiv preprint arXiv:2503.05193, 2025.  \n[412] Ruiyun Xu, Yue Feng, and Hailiang Chen. Chatgpt vs. google: A comparative study of search performance and user experience. arXiv preprint arXiv:2307.01135, 2023.  \n[413] Tianze Xu, Pengrui Lu, Lyumanshan Ye, Xiangkun Hu, and Pengfei Liu. Researcherbench: Evaluating deep ai research systems on the frontiers of scientific inquiry. arXiv preprint arXiv:2507.16280, 2025.  \n[414] Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, and Yongfeng Zhang. A-mem: Agentic memory for llm agents. arXiv preprint arXiv:2502.12110, 2025.  \n[415] Yiheng Xu and et al. Layoutm: Pre-training of text and layout for document image understanding. In KDD, 2020.  \n[416] Zhenghai Xue, Longtao Zheng, Qian Liu, Yingru Li, Zejun Ma, and Bo An. Simpletir: End-to-end reinforcement learning for multi-turn tool-integrated reasoning, 2025. Notion Blog.\n\n[417] Sikuan Yan, Xiufeng Yang, Zuchao Huang, Ercong Nie, Zifeng Ding, Zonggen Li, Xiaowen Ma, Hinrich Schütze, Volker Tresp, and Yunpu Ma. Memory-r1: Enhancing large language model agents to manage and utilize memories via reinforcement learning. arXiv preprint arXiv:2508.19828, 2025.  \n[418] Linyi Yang and Yixuan Weng. Researchstudio: A human-intervenable framework for building controllable deep-research agents. arXiv preprint arXiv:2510.12194, 2025.  \n[419] Qu Yang, Mang Ye, Zhaohui Cai, Kehua Su, and Bo Du. Composed image retrieval via cross relation network with hierarchical aggregation transformer. IEEE Transactions on Image Processing, 32:4543-4554, 2023.  \n[420] Qu Yang, Mang Ye, Zhaohui Cai, Kehua Su, and Bo Du. Composed image retrieval via cross relation network with hierarchical aggregation transformer. IEEE Transactions on Image Processing, 2023.  \n[421] Qu Yang, Mang Ye, and Bo Du. Emollm: Multimodal emotional understanding meets large language models. arXiv preprint arXiv:2406.16442, 2024.  \n[422] Qu Yang, Qinghongya Shi, Tongxin Wang, and Mang Ye. Uncertain multimodal intention and emotion understanding in the wild. In Proceedings of the Computer Vision and Pattern Recognition Conference, 2025.  \n[423] Wei Yang, Jinwei Xiao, Hongming Zhang, Qingyang Zhang, Yanna Wang, and Bo Xu. Coarse-to-fine grounded memory for llm agent planning. arXiv preprint arXiv:2508.15305, 2025.  \n[424] Yuqing Yang, Ethan Chern, Xipeng Qiu, Graham Neubig, and Pengfei Liu. Alignment for honesty. arXiv preprint arXiv:2312.07000, 2023.  \n[425] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. Hotpotq: A dataset for diverse, explainable multi-hop question answering. arXiv preprint arXiv:1809.09600, 2018.  \n[426] Shunyu Yao and et al. React: Synergizing reasoning and acting in language models. In International Conference on Learning Representations, 2023.  \n[427] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. Advances in neural information processing systems, 2023.  \n[428] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. ReAct: Synergizing reasoning and acting in language models. In International Conference on Learning Representations, 2023.  \n[429] Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, and Juanzi Li. Seakr: Self-aware knowledge retrieval for adaptive retrieval augmented generation. arXiv preprint arXiv:2406.19215, 2024.  \n[430] Guo Yi, Cao Nan, Qi Xiaoyu, Li Haoyang, Shi Danqing, Zhang Jing, Chen Qing, and Weiskopf and, Daniel. Urania: Visualizing data analysis pipelines for natural language-based data exploration. arXiv preprint arXiv:2306.07760, 2023.\n\n[431] Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, and Xuanjing Huang. Do large language models know what they don't know? arXiv preprint arXiv:2305.18153, 2023.  \n[432] Soyoung Yoon, Eunbi Choi, Jiyeon Kim, Hyeongu Yun, Yireun Kim, and Seung-won Hwang. Listt5: Listwise reranking with fusion-in-decoder improves zero-shot retrieval. arXiv preprint arXiv:2402.15838, 2024.  \n[433] Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Berant. Making retrieval-augmented language models robust to irrelevant context. arXiv preprint arXiv:2310.01558, 2023.  \n[434] Ori Yoran, Samuel Joseph Amouyal, Chaitanya Malaviya, Ben Bogin, Ofir Press, and Jonathan Berant. Assistantbench: Can web agents solve realistic and time-consuming tasks? arXiv preprint arXiv:2407.15711, 2024.  \n[435] Fei Xu Yu, Gina Adam, Nathaniel D Bastian, and Tian Lan. Optimizing prompt sequences using monte carlo tree search for llm-based optimization. arXiv preprint arXiv:2508.05995, 2025.  \n[436] Hongli Yu, Tinghong Chen, Jiangtao Feng, Jiangjie Chen, Weinan Dai, Qiying Yu, Ya-Qin Zhang, Wei-Ying Ma, Jingjing Liu, Mingxuan Wang, et al. Memagent: Reshaping long-context llm with multi-conv rl-based memory agent. arXiv preprint arXiv:2507.02259, 2025.  \n[437] Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu Yue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Honglin Yu, Weinan Dai, Yuxuan Song, Xiang Wei, Haodong Zhou, Jingjing Liu, Wei Ma, Ya-Qin Zhang, Lin Yan, Mu Qiao, Yong-Xu Wu, and Mingxuan Wang. Dapo: An open-source llm reinforcement learning system at scale. arXiv preprint arXiv:2503.14476, 2025.  \n[438] Wenhao Yu, Hongming Zhang, Xiaoman Pan, Kaixin Ma, Hongwei Wang, and Dong Yu. Chain-of-note: Enhancing robustness in retrieval-augmented language models. arXiv preprint arXiv:2311.09210, 2023.  \n[439] Yue Yu, Wei Ping, Zihan Liu, Boxin Wang, Jiaxuan You, Chao Zhang, Mohammad Shoeybi, and Bryan Catanzaro. Rankrag: Unifying context ranking with retrieval-augmented generation in llms. Advances in Neural Information Processing Systems, 2024.  \n[440] Zhouliang Yu, Ruotian Peng, Keyi Ding, Yizhe Li, Zhongyuan Peng, Minghao Liu, Yifan Zhang, Zheng Yuan, Huajian Xin, Wenhao Huang, et al. Formalmath: Benchmarking formal mathematical reasoning of large language models. arXiv preprint arXiv:2505.02735, 2025.  \n[441] Tian Yuan, Cui Weiwei, Deng Dazhen, Yi Xinjing, Yang Yurun, Zhang Haidong, and Wu Yingcai. Chartgpt: Leveraging llms to generate charts from abstract natural language. arXiv preprint arXiv:2311.01920, 2023.  \n[442] Weizhe Yuan, Pengfei Liu, and Graham Neubig. Can we automate scientific reviewing? Journal of Artificial Intelligence Research, 2022.  \n[443] Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing Xu, and Jason Weston. Self-rewarding language models. arXiv preprint arXiv:2401.10020, 3, 2024.\n\n[444] Munazza Zaib, Wei Emma Zhang, Quan Z Sheng, Adnan Mahmood, and Yang Zhang. Conversational question answering: A survey. Knowledge and Information Systems, 64(12):3151-3195, 2022.  \n[445] Weihao Zeng, Can Xu, Yingxiu Zhao, Jian-Guang Lou, and Weizhu Chen. Automatic instruction evolving for large language models. arXiv preprint arXiv:2406.00770, 2024.  \n[446] Xinyang Zhai and et al. Siglip: Scaling up visual pre-training with semantics-aware contrastive learning. arXiv preprint arXiv:2303.15343, 2023.  \n[447] Dingchu Zhang, Yida Zhao, Jialong Wu, Baixuan Li, Wenbiao Yin, Liwen Zhang, Yong Jiang, Yufeng Li, Kewei Tu, Pengjun Xie, et al. Evolvedsearch: An iterative self-evolving search agent. arXiv preprint arXiv:2505.22501, 2025.  \n[448] Gaoke Zhang, Bo Wang, Yunlong Ma, Dongming Zhao, and Zifei Yu. Multiple memory systems for enhancing the long-term memory of agent. arXiv preprint arXiv:2508.15294, 2025.  \n[449] Guibin Zhang, Luyang Niu, Junfeng Fang, Kun Wang, Lei Bai, and Xiang Wang. Multi-agent architecture search via agentic supernet. arXiv preprint arXiv:2502.04180, 2025.  \n[450] Hanning Zhang, Shizhe Diao, Yong Lin, Yi Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, and Tong Zhang. R-tuning: Instructing large language models to say 'i don't know'. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2024.  \n[451] Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley A Malin, and Sricharan Kumar. Sac3: Reliable hallucination detection in black-box language models via semantic-aware cross-check consistency. arXiv preprint arXiv:2311.01740, 2023.  \n[452] Liang Zhang, Anwen Hu, Haiyang Xu, Ming Yan, Yichen Xu, Qin Jin, Ji Zhang, and Fei Huang. Tinychart: Efficient chart understanding with visual token merging and program-of-thoughts learning. arXiv preprint arXiv:2404.16635, 2024.  \n[453] Qingjie Zhang, Yujia Fu, Yang Wang, Liu Yan, Tao Wei, Ke Xu, Minlie Huang, and Han Qiu. On the self-awareness of large reasoning models' capability boundaries. arXiv preprint arXiv:2509.24711, 2025.  \n[454] Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q. Weinberger, and Yoav Artzi. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=SkeHuCVFDr.  \n[455] Weinan Zhang, Junwei Liao, Ning Li, Kounianhua Du, and Jianghao Lin. Agentic information retrieval. arXiv preprint arXiv:2410.09713, 2024.  \n[456] Weizhi Zhang, Yangning Li, Yuan-Qi Bei, Junyu Luo, Guancheng Wan, Liangwei Yang, Chenxuan Xie, Yuyao Yang, Wei-Chieh Huang, Chunyu Miao, Henry Peng Zou, Xiao Luo, Yusheng Zhao, Yankai Chen, Chunkit Chan, Peilin Zhou, Xinyang Zhang, Chenwei Zhang, Jingbo Shang, Ming Zhang, Yangqiu Song, Irwin King, and Philip S. Yu. From web search towards agentic deep research: Incentivizing search with reasoning agents. arXiv preprint arXiv:2506.18959, 2025.\n\n[457] Weizhi Zhang, Xinyang Zhang, Chenwei Zhang, Liangwei Yang, Jingbo Shang, Zhepei Wei, Henry Peng Zou, Zijie Huang, Zhengyang Wang, Yifan Gao, et al. Personaagent: When large language model agents meet personalization at test time. arXiv preprint arXiv:2506.06254, 2025.  \n[458] Wenlin Zhang, Xiaopeng Li, Yingyi Zhang, Pengyue Jia, Yichao Wang, Huifeng Guo, Yong Liu, and Xiangyu Zhao. Deep research: A survey of autonomous research agents. arXiv preprint arXiv:2508.12752, 2025.  \n[459] Yiming Zhang, Harshita Diddee, Susan Holm, Hanchen Liu, Xinyue Liu, Vinay Samuel, Barry Wang, and Daphne Ippolito. Noveltybench: Evaluating language models for humanlike diversity. arXiv preprint arXiv:2504.05228, 2025.  \n[460] Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shuiwang Ji, Wei Wang, and Jiawei Han. A comprehensive survey of scientific large language models and their applications in scientific discovery. arXiv preprint arXiv:2406.10833, 2024.  \n[461] Yuge Zhang, Qiyang Jiang, Xingyu Han, Nan Chen, Yuqing Yang, and Kan Ren. Benchmarking data science agents. arXiv preprint arXiv:2402.17168, 2024.  \n[462] Zeyu Zhang, Quanyu Dai, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Jieming Zhu, Zhenhua Dong, and Ji-Rong Wen. A survey on the memory mechanism of large language model based agents. ACM Transactions on Information Systems, 2024.  \n[463] Zeyu Zhang, Quanyu Dai, Rui Li, Xiaohe Bo, Xu Chen, and Zhenhua Dong. Learn to memorize: Optimizing llm-based agents with adaptive memory framework. arXiv preprint arXiv:2508.16629, 2025.  \n[464] Zhilin Zhang, Xiang Zhang, Jiaqi Wei, Yiwei Xu, and Chenyu You. Postergen: Aesthetic-aware paper-to-poster generation via multi-agent llms. arXiv preprint arXiv:2508.17188, 2025.  \n[465] Zijing Zhang, Ziyang Chen, Mingxiao Li, Zhaopeng Tu, and Xiaolong Li. Rlvmr: Reinforcement learning with verifiable meta-reasoning rewards for robust long-horizon agents. arXiv preprint arXiv:2507.22844, 2025.  \n[466] Ziyin Zhang, Jiahao Xu, Zhiwei He, Tian Liang, Qiuzhi Liu, Yansi Li, Linfeng Song, Zhenwen Liang, Zhuosheng Zhang, Rui Wang, et al. Deeptheorem: Advancing llm reasoning for theorem proving through natural language and reinforcement learning. arXiv preprint arXiv:2505.23754, 2025.  \n[467] Andrew Zhao, Yiran Wu, Yang Yue, Tong Wu, Quentin Xu, Matthieu Lin, Shenzhi Wang, Qingyun Wu, Zilong Zheng, and Gao Huang. Absolute zero: Reinforced self-play reasoning with zero data. arXiv preprint arXiv:2505.03335, 2025.  \n[468] Qingfei Zhao, Ruobing Wang, Dingling Xu, Daren Zha, and Limin Liu. R-search: Empowering llm reasoning with search via multi-reward reinforcement learning. arXiv preprint arXiv:2506.04185, 2025.  \n[469] Qinlin Zhao, Jindong Wang, Yixuan Zhang, Yiqiao Jin, Kaijie Zhu, Hao Chen, and Xing Xie. Competeai: Understanding the competition dynamics in large language model-based agents. arXiv preprint arXiv:2310.17512, 2023.\n\n[470] Shengming Zhao, Yuheng Huang, Jiayang Song, Zhijie Wang, Chengcheng Wan, and Lei Ma. Towards understanding retrieval accuracy and prompt quality in rag systems. arXiv preprint arXiv:2411.19463, 2024.  \n[471] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.  \n[472] Wenting Zhao, Nan Jiang, Celine Lee, Justin T Chiu, Claire Cardie, Matthias Gallé, and Alexander M Rush. Commit0: Library generation from scratch. arXiv preprint arXiv:2412.01769, 2024.  \n[473] Zheng Zhao, Clara Vania, Subhradeep Kayal, Naila Khan, Shay B Cohen, and Emine Yilmaz. Personalens: A benchmark for personalization evaluation in conversational ai assistants. arXiv preprint arXiv:2506.09902, 2025.  \n[474] Zhengyi Zhao, Shubo Zhang, Yiming Du, Bin Liang, Baojun Wang, Zhongyang Li, Binyang Li, and Kam-Fai Wong. Eventweave: A dynamic framework for capturing core and supporting events in dialogue systems. arXiv preprint arXiv:2503.23078, 2025.  \n[475] Cheng Zhen, Ervine Zheng, Jilong Kuang, and Geoffrey Jay Tso. Enhancing llm-as-a-judge through active-sampling-based prompt optimization. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, 2025.  \n[476] Danna Zheng, Mirella Lapata, and Jeff Z Pan. Long-form information alignment evaluation beyond atomic facts. arXiv preprint arXiv:2505.15792, 2025.  \n[477] Hanwen Zheng, Sijia Wang, Chris Thomas, and Lifu Huang. Advancing chart question answering with robust chart component recognition. arXiv preprint arXiv:2407.21038, 2024.  \n[478] Hao Zheng, Xinyan Guan, Hao Kong, Jia Zheng, Weixiang Zhou, Hongyu Lin, Yaojie Lu, Ben He, Xianpei Han, and Le Sun. Pptagent: Generating and evaluating presentations beyond text-to-slides. arXiv preprint arXiv:2501.03936, 2025.  \n[479] Hao Zheng, Xinyan Guan, Hao Kong, Jia Zheng, Weixiang Zhou, Hongyu Lin, Yaojie Lu, Ben He, Xianpei Han, and Le Sun. Pptagent: Generating and evaluating presentations beyond text-to-slides, 2025.  \n[480] Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. Minif2f: a cross-system benchmark for formal olympiad-level mathematics. arXiv preprint arXiv:2109.00110, 2021.  \n[481] Yuxiang Zheng, Dayuan Fu, Xiangkun Hu, Xiaojie Cai, Lyumanshan Ye, Pengrui Lu, and Pengfei Liu. Deepresearcher: Scaling deep research via reinforcement learning in real-world environments. arXiv preprint arXiv:2504.03160, 2025.  \n[482] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. Memorybank: Enhancing large language models with long-term memory. In Proceedings of the AAAI Conference on Artificial Intelligence, 2024.  \n[483] Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. Lima: Less is more for alignment. Advances in Neural Information Processing Systems, 2023.\n\n[484] Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022.  \n[485] Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun Zhang, Kun Shao, Linyi Yang, et al. Agentfly: Fine-tuning llm agents without fine-tuning llms. arXiv preprint arXiv:2508.16153, 2025.  \n[486] Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun Zhang, Kun Shao, Linyi Yang, et al. Memento: Fine-tuning llm agents without fine-tuning llms. arXiv preprint arXiv:2508.16153, 2025.  \n[487] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, et al. Webarena: A realistic web environment for building autonomous agents. arXiv preprint arXiv:2307.13854, 2023.  \n[488] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, et al. Webarena: A realistic web environment for building autonomous agents. In The Twelfth International Conference on Learning Representations, 2023.  \n[489] Xiaofeng Zhou, Heyan Huang, and Lizi Liao. Debate, reflect, and distill: Multi-agent feedback with tree-structured preference optimization for efficient language model enhancement. arXiv preprint arXiv:2506.03541, 2025.  \n[490] Yangqiaoyu Zhou, Haokun Liu, Tejes Srivastava, Hongyuan Mei, and Chenhao Tan. Hypothesis generation with large language models. In Proceedings of the 1st Workshop on NLP for Science (NLP4Science), 2024.  \n[491] Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, and Paul Pu Liang. Mem1: Learning to synergize memory and reasoning for efficient long-horizon agents. arXiv preprint arXiv:2506.15841, 2025.  \n[492] Changtai Zhu, Siyin Wang, Ruijun Feng, Kai Song, and Xipeng Qiu. Convsearch-r1: Enhancing query reformulation for conversational search with reasoning via reinforcement learning. arXiv preprint arXiv:2505.15776, 2025.  \n[493] Deyao Zhu, Jun Chen, Xiaogian Shen, Xiang Li, and Mohamed Elhoseiny. MiniGPT-4: Enhancing vision-language understanding with advanced large language models. In The Twelfth International Conference on Learning Representations, 2024.  \n[494] Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, and Dawei Yin. Divide-then-aggregate: An efficient tool learning method via parallel tool invocation. arXiv preprint arXiv:2501.12432, 2025.  \n[495] He Zhu, Tianrui Qin, King Zhu, Heyuan Huang, Yeyi Guan, Jinxiang Xia, Yi Yao, Hanhao Li, Ningning Wang, Pai Liu, et al. Oagents: An empirical study of building effective agents. arXiv preprint arXiv:2506.15741, 2025.  \n[496] Kun Zhu, Xiaocheng Feng, Xiyuan Du, Yuxuan Gu, Weijiang Yu, Haotian Wang, Qianglong Chen, Zheng Chu, Jingchang Chen, and Bing Qin. An information bottleneck perspective for effective noise filtering on retrieval-augmented generation. arXiv preprint arXiv:2406.01549, 2024.\n\n[497] Lianghui Zhu, Xinggang Wang, and Xinlong Wang. Judgelm: Fine-tuned large language models are scalable judges. arXiv preprint arXiv:2310.17631, 2023.  \n[498] Minjun Zhu, Yixuan Weng, Linyi Yang, and Yue Zhang. DeepReview: Improving LLM-based paper review with human-like deep thinking process. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, 2025.  \n[499] Siyu Zhu, Yanbin Jiang, Hejian Sang, Shao Tang, Qingquan Song, Biao He, Rohit Jain, Zhipeng Wang, and Alborz Geramifard. Planner-r1: Reward shaping enables efficient agentic rl with smaller llms. arXiv preprint arXiv:2509.25779, 2025.  \n[500] Wenhong Zhu, Ruobing Xie, Rui Wang, Xingwu Sun, Di Wang, and Pengfei Liu. Proximal supervised fine-tuning. arXiv preprint arXiv:2508.17784, 2025.  \n[501] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory. arXiv preprint arXiv:2305.17144, 2023.  \n[502] Yichen Zhu, Ning Liu, Zhiyuan Xu, Xin Liu, Weibin Meng, Louis Wang, Zhicai Ou, and Jian Tang. Teach less, learn more: On the undistillable classes in knowledge distillation. Advances in Neural Information Processing Systems, 35:32011-32024, 2022.  \n[503] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen. Large language models for information retrieval: A survey. arXiv preprint arXiv:2308.07107, 2023.  \n[504] Zeyu Zhu, Kevin Qinghong Lin, and Mike Zheng Shou. Paper2video: Automatic video generation from scientific papers. arXiv preprint arXiv:2510.05096, 2025.  \n[505] Shengyao Zhuang, Xueguang Ma, Bevan Koopman, Jimmy Lin, and Guido Zuccon. Rank-r1: Enhancing reasoning in llm-based document rerankers via reinforcement learning. arXiv preprint arXiv:2503.06034, 2025.  \n[506] Zhenzhen Zhuang, Jiandong Chen, Hongfeng Xu, Yuwen Jiang, and Jialiang Lin. Large language models for automated scholarly paper review: A survey. Information Fusion, page 103332, 2025.  \n[507] Tang Zineng, Yang Ziyi, Zhu Chenguang, Zeng Michael, and Bansal Mohit. Any-to-any generation via composable diffusion. arXiv preprint arXiv:2305.11846, 2023.",
    "arxiv_id": "2512.02038",
    "error_message": null,
    "embedding": [
      -1.3828125,
      -0.0038909912109375,
      0.498046875,
      -0.099609375,
      -0.66015625,
      1.0703125,
      -0.87890625,
      -2.140625,
      3.21875,
      2.8125,
      -0.3046875,
      3.375,
      2.734375,
      1.34375,
      -2.09375,
      1.703125,
      0.6875,
      -0.08740234375,
      0.265625,
      -8.25,
      0.1962890625,
      1.4375,
      -1.09375,
      -5,
      2.328125,
      -3.203125,
      -0.1806640625,
      1.2734375,
      3.71875,
      -2.015625,
      8.1875,
      -6.8125,
      -1.5546875,
      1.78125,
      -2.3125,
      0.67578125,
      -3.953125,
      -1.2265625,
      6.84375,
      2.578125,
      -5.5,
      0.99609375,
      0.54296875,
      4.09375,
      -0.921875,
      2.578125,
      1.6875,
      -3.6875,
      -4.5625,
      -1.6015625,
      -3.4375,
      -1.890625,
      4.8125,
      -3.171875,
      1.8984375,
      -3.46875,
      -7.3125,
      4.0625,
      -3.78125,
      2.609375,
      0.78125,
      -0.1298828125,
      1.71875,
      -1.46875,
      3.296875,
      2.75,
      1.109375,
      1.796875,
      -0.90625,
      3.078125,
      0.58203125,
      -0.66015625,
      6,
      -3.953125,
      8.25,
      9,
      3.125,
      1.71875,
      -4.5625,
      5.25,
      -1.265625,
      2.53125,
      3.875,
      0.2158203125,
      4.9375,
      1.6640625,
      -0.8046875,
      -2.484375,
      -2.265625,
      4.0625,
      -0.96484375,
      2.140625,
      -2.453125,
      -3.84375,
      -0.80859375,
      1.1484375,
      -0.83203125,
      -2.796875,
      -6.4375,
      -0.1796875,
      -3.34375,
      0.66015625,
      1.671875,
      -7.25,
      -2.0625,
      -2.796875,
      -5.71875,
      -8.625,
      -2.09375,
      -5.21875,
      -1.5234375,
      0.48828125,
      0.1494140625,
      -2.671875,
      3.984375,
      -1.484375,
      4.5625,
      -3.3125,
      -4.40625,
      -0.86328125,
      2.90625,
      0.7890625,
      -0.76171875,
      -0.9453125,
      4.28125,
      3.375,
      -5.40625,
      2.765625,
      6.25,
      -2.15625,
      3.890625,
      -1.0625,
      4.40625,
      -1.3125,
      -10.625,
      -2.296875,
      -1.7421875,
      7.15625,
      2.875,
      6.125,
      -5.5,
      -1.15625,
      -2.265625,
      -5.625,
      2.09375,
      -1.03125,
      -6.0625,
      0.28515625,
      5.59375,
      -4.5625,
      0.76953125,
      1.453125,
      3.265625,
      5.28125,
      -0.83984375,
      -3.796875,
      0.33203125,
      1.3203125,
      0.76953125,
      -0.267578125,
      -0.026123046875,
      2.453125,
      -0.431640625,
      1.203125,
      -1.140625,
      2.125,
      -4.78125,
      -0.71875,
      0.65625,
      0.337890625,
      3.125,
      17.125,
      1.4453125,
      0.12353515625,
      0.3203125,
      3.8125,
      -4.59375,
      7.875,
      1.1796875,
      1.9921875,
      2.03125,
      0.70703125,
      -2.640625,
      4.875,
      -2.15625,
      1.296875,
      3.109375,
      -3.671875,
      2.671875,
      -2.21875,
      2.859375,
      0.80078125,
      0.83984375,
      -0.51171875,
      -3.328125,
      0.2734375,
      2.21875,
      -2.078125,
      -0.72265625,
      0.5390625,
      -0.41796875,
      -11.25,
      -0.87890625,
      -0.32421875,
      -3.84375,
      -0.96875,
      2.953125,
      -4.65625,
      0.921875,
      -0.37890625,
      2.78125,
      2.40625,
      1.546875,
      -1.9453125,
      5.78125,
      1.4375,
      1.515625,
      -1.6640625,
      3.109375,
      0.69140625,
      2.984375,
      4.1875,
      3.3125,
      -1.453125,
      -0.72265625,
      2.046875,
      4.4375,
      5.78125,
      0.84765625,
      4.5,
      1.53125,
      2.5,
      5.59375,
      -3.984375,
      -2.71875,
      -2.125,
      -3.359375,
      0.384765625,
      -0.84375,
      -1.34375,
      -4.34375,
      -0.76953125,
      2.234375,
      1.4140625,
      1.359375,
      -3.390625,
      -0.6796875,
      -0.5234375,
      -3.15625,
      -8.375,
      2.265625,
      6.53125,
      -11.1875,
      -1.84375,
      1.6171875,
      6.875,
      0.6015625,
      -2,
      0.51953125,
      -3.28125,
      5.5,
      -4.6875,
      -5.09375,
      2.28125,
      3.25,
      -0.9453125,
      3.5,
      0.4296875,
      0.216796875,
      -0.400390625,
      1.6953125,
      0.92578125,
      -1.515625,
      2.546875,
      -5.78125,
      3.734375,
      -0.5078125,
      -6.03125,
      -1.6328125,
      -2.125,
      -8.5,
      -7.59375,
      5.40625,
      -3.5625,
      2.796875,
      -0.734375,
      2.390625,
      5.65625,
      -1.375,
      12.9375,
      7.15625,
      1.4140625,
      0.045166015625,
      -0.77734375,
      -5.625,
      1.28125,
      -4.125,
      0.140625,
      -4.8125,
      -0.1865234375,
      3.84375,
      2,
      0.3359375,
      -0.365234375,
      -3.828125,
      5.34375,
      2.40625,
      -3.828125,
      -0.84765625,
      3.828125,
      0.875,
      2.015625,
      9.0625,
      -4.1875,
      4.21875,
      -2.84375,
      -3.5625,
      3.03125,
      3.140625,
      -2.1875,
      -3.90625,
      -6.03125,
      -2.203125,
      -0.275390625,
      -1.453125,
      -0.99609375,
      -0.81640625,
      0.34765625,
      5.15625,
      1.3203125,
      1,
      -1.7265625,
      -7.15625,
      -8.125,
      7.0625,
      0.5234375,
      3.234375,
      2.09375,
      -0.8515625,
      3.359375,
      -4.5,
      -4.46875,
      3.859375,
      -2.265625,
      -0.515625,
      1.6953125,
      3.65625,
      -1.7578125,
      2.0625,
      -6.40625,
      5.21875,
      3.078125,
      1.4921875,
      2.4375,
      8.875,
      -1.4140625,
      6.25,
      -1.640625,
      -0.56640625,
      -2.5625,
      0.76953125,
      -3.953125,
      9.4375,
      -0.08154296875,
      -0.8828125,
      -3.546875,
      -0.62890625,
      1.1484375,
      -1.734375,
      -4.28125,
      1.15625,
      -4.0625,
      2.28125,
      -0.154296875,
      0.6171875,
      -0.36328125,
      1.796875,
      -4.59375,
      -5.1875,
      1.015625,
      -4.0625,
      -1.0078125,
      -0.09130859375,
      0.80859375,
      2.96875,
      2.015625,
      0.625,
      3.984375,
      1.40625,
      -3.984375,
      -1.2421875,
      2.21875,
      -1.9296875,
      2.1875,
      4.5625,
      1.8359375,
      0.8125,
      2.265625,
      -2.859375,
      -1.8828125,
      6.03125,
      -0.2294921875,
      1.671875,
      -1.9921875,
      -5.6875,
      0.61328125,
      0.0047607421875,
      -7.5625,
      2.265625,
      1.0546875,
      0.92578125,
      0.3515625,
      1.3203125,
      0.2255859375,
      1.25,
      4.46875,
      2.109375,
      1.6015625,
      -6.9375,
      -2.890625,
      -3.875,
      3.953125,
      1.5390625,
      -2.4375,
      -0.0089111328125,
      0.7890625,
      0.71875,
      7.84375,
      2.265625,
      5,
      0.042236328125,
      2.46875,
      -4.6875,
      -0.341796875,
      -1.375,
      -4.84375,
      2.84375,
      -3.15625,
      -5.78125,
      3.15625,
      1.390625,
      -1.7109375,
      5.875,
      3.921875,
      -7.1875,
      -0.88671875,
      5.125,
      3.765625,
      -1.6875,
      -2.765625,
      -1.2421875,
      0.65234375,
      -3.171875,
      1.5859375,
      4.1875,
      0.177734375,
      -2.96875,
      3.171875,
      4.34375,
      0.0419921875,
      -1.3515625,
      -1.4609375,
      -2.140625,
      -1.5859375,
      1.828125,
      -0.6875,
      -3.4375,
      3.0625,
      5.90625,
      -7.8125,
      -9.125,
      1.3125,
      -1.3671875,
      -3.625,
      -2.8125,
      3.25,
      0.61328125,
      1.875,
      -7.28125,
      -3.921875,
      -2.5625,
      -2.59375,
      4.03125,
      3.8125,
      -1.1796875,
      -2.796875,
      -4.9375,
      4.90625,
      2.359375,
      1.9296875,
      1.1484375,
      -1.6015625,
      2.484375,
      -6.40625,
      1.3984375,
      1.5,
      7.75,
      -1.5546875,
      -0.0224609375,
      1.4375,
      -7.90625,
      2.625,
      -3.234375,
      -3.390625,
      0.7265625,
      0.1533203125,
      3.65625,
      -2.609375,
      1.5625,
      0.2314453125,
      5.5625,
      -1.5,
      -1.1171875,
      1.9765625,
      -5.125,
      -1.546875,
      1.2734375,
      3.359375,
      1.875,
      -1.515625,
      -3.046875,
      1.90625,
      4.09375,
      -2.546875,
      1.8125,
      -1.7890625,
      -1.53125,
      -4.3125,
      4.0625,
      3.671875,
      4.03125,
      1.0859375,
      -1.453125,
      -2.734375,
      -2.890625,
      0.7109375,
      1.2265625,
      0.4609375,
      2.96875,
      0.447265625,
      3.75,
      3.125,
      -2.109375,
      -1.3984375,
      -1.734375,
      -1.078125,
      -4.5625,
      2.90625,
      1.734375,
      0.11572265625,
      1.53125,
      0.76171875,
      -1.6484375,
      0.54296875,
      3.4375,
      -5.46875,
      -3.46875,
      -3.765625,
      3.140625,
      -1.890625,
      -0.2109375,
      -2.34375,
      2.171875,
      -0.0478515625,
      1.015625,
      -0.392578125,
      2.78125,
      6.1875,
      0.5859375,
      2.21875,
      1.9375,
      2.140625,
      -1.15625,
      -0.29296875,
      0.57421875,
      1.9296875,
      -6.6875,
      -6,
      -3.5625,
      1.7421875,
      7.0625,
      -1.0234375,
      3.09375,
      -3.25,
      3.5,
      -1.734375,
      0.83984375,
      -14.375,
      1.8828125,
      -2.75,
      -3,
      -0.69140625,
      -5.34375,
      0.380859375,
      -2.578125,
      3,
      0.369140625,
      -2.015625,
      2.859375,
      4.8125,
      -0.8984375,
      -3.375,
      1.296875,
      3.8125,
      -2.203125,
      5.125,
      -4.15625,
      -3.34375,
      2.03125,
      -0.349609375,
      3.890625,
      3.515625,
      5.65625,
      -0.3125,
      0.08056640625,
      3.125,
      -4.4375,
      2.796875,
      0.4140625,
      2.453125,
      -1.109375,
      1.8515625,
      -1.3125,
      4.28125,
      -4.90625,
      2.09375,
      0.90234375,
      -1.1171875,
      2.546875,
      6.53125,
      -3.1875,
      -0.671875,
      -0.25390625,
      -1.8046875,
      2.21875,
      5.09375,
      -4.71875,
      2.171875,
      -0.671875,
      -0.73828125,
      0.828125,
      -2.609375,
      0.388671875,
      -1.4375,
      3.1875,
      3.15625,
      -2.15625,
      4.0625,
      2.03125,
      -4.75,
      -0.267578125,
      0.71875,
      -2.1875,
      -3.03125,
      2.5625,
      1.875,
      -0.46875,
      -0.10595703125,
      1.734375,
      -4.3125,
      -4.34375,
      -2.421875,
      3.859375,
      -5.8125,
      2.09375,
      -1.4609375,
      1.6875,
      -1.7734375,
      -4.84375,
      2.390625,
      1.71875,
      6.0625,
      0.95703125,
      2.546875,
      2.03125,
      -3.46875,
      1.78125,
      -3.34375,
      -2.671875,
      0.138671875,
      -4.40625,
      -0.044921875,
      1.484375,
      0.921875,
      0.453125,
      -2.625,
      -3.171875,
      -5.53125,
      -6.40625,
      -3.734375,
      3.703125,
      0.47265625,
      3.125,
      -3.140625,
      2.453125,
      -1.609375,
      -2.40625,
      -0.431640625,
      -2.53125,
      -1.1796875,
      -0.3984375,
      2.171875,
      -4.6875,
      -4.1875,
      5.96875,
      2.171875,
      -1.5546875,
      5.90625,
      0.44921875,
      -2.15625,
      -0.56640625,
      4.8125,
      -1.8203125,
      -0.267578125,
      -1.6171875,
      -1.828125,
      -3.90625,
      -2.984375,
      1.8125,
      -2.375,
      4.1875,
      -3.28125,
      -0.59375,
      -0.67578125,
      -5.84375,
      -1.6171875,
      -0.2431640625,
      -2.75,
      4.8125,
      1.4609375,
      -1.1484375,
      -3.03125,
      5.78125,
      2.359375,
      1.171875,
      2.9375,
      0.1767578125,
      3.28125,
      2.46875,
      4.59375,
      -3.75,
      -6.46875,
      -0.98046875,
      0.51953125,
      -0.08984375,
      3.703125,
      -0.98046875,
      0.81640625,
      4.4375,
      2.234375,
      -5.09375,
      -3.65625,
      3.390625,
      -2.65625,
      -0.84765625,
      -0.1904296875,
      3.21875,
      0.69140625,
      3.015625,
      -2.078125,
      -4.03125,
      0.95703125,
      4.15625,
      0.8828125,
      0.84765625,
      -2.03125,
      3.953125,
      1.296875,
      3.78125,
      -3.828125,
      -5.3125,
      1.578125,
      -0.03759765625,
      -3.953125,
      0.134765625,
      8.8125,
      -3.328125,
      -2.703125,
      -2.046875,
      2.71875,
      3.40625,
      -0.1064453125,
      -0.51953125,
      -3.09375,
      1.4609375,
      0.4375,
      2.734375,
      0.671875,
      -2.453125,
      -2.421875,
      -0.6640625,
      0.259765625,
      -2.625,
      4.03125,
      -1.734375,
      -1.6015625,
      -3.484375,
      0.146484375,
      0.216796875,
      3.65625,
      6.40625,
      -1.40625,
      2.09375,
      3.703125,
      6.84375,
      -2.765625,
      3,
      -0.38671875,
      10.9375,
      -2.609375,
      -1.9765625,
      1.9296875,
      -0.1259765625,
      -0.52734375,
      1.4453125,
      -3.546875,
      -5.84375,
      1.5546875,
      -2.359375,
      -2.34375,
      1.1015625,
      -5.03125,
      -0.0361328125,
      7.9375,
      1.3203125,
      2.78125,
      2.859375,
      5.53125,
      1.640625,
      -1.7734375,
      -2.078125,
      1.2890625,
      -0.93359375,
      0.10400390625,
      3.34375,
      -6.6875,
      2.890625,
      1.0234375,
      3.75,
      2.75,
      -1.15625,
      -4.0625,
      7.3125,
      -0.73828125,
      -0.365234375,
      1.9453125,
      -1.328125,
      1.9140625,
      -0.03857421875,
      0.89453125,
      -5.5625,
      1.9296875,
      5.6875,
      5.3125,
      -1.4296875,
      2.203125,
      -1.0625,
      0.3984375,
      -6.25,
      -0.75390625,
      0.5390625,
      0.443359375,
      -3.375,
      -2.859375,
      -2.4375,
      2.8125,
      -6.15625,
      1.265625,
      -1.6484375,
      -5.46875,
      1.140625,
      2.515625,
      0.67578125,
      0.5703125,
      0.271484375,
      5.59375,
      -0.142578125,
      -2.796875,
      -3.90625,
      -5.53125,
      -1.8984375,
      1.46875,
      0.357421875,
      2.765625,
      3.78125,
      -3.234375,
      1.671875,
      -6.96875,
      0.3671875,
      -3.765625,
      6.625,
      2.5625,
      -3.421875,
      -1.703125,
      -1.0078125,
      -9.5625,
      -6.71875,
      -2.203125,
      -1.625,
      -2.8125,
      -5.15625,
      -1.0546875,
      0.20703125,
      -3.484375,
      -0.1611328125,
      -1.8203125,
      0.97265625,
      3.484375,
      0.39453125,
      1.46875,
      -2.609375,
      2.828125,
      3.75,
      1.921875,
      4.90625,
      2.203125,
      3.984375,
      3.4375,
      -3.15625,
      1.390625,
      -2,
      6.34375,
      -0.94140625,
      8.875,
      2.609375,
      1.5390625,
      -5.84375,
      1.28125,
      -0.0130615234375,
      1.546875,
      -5.4375,
      -0.001556396484375,
      -2.1875,
      0.75390625,
      -0.546875,
      -0.53125,
      -0.205078125,
      -5.6875,
      -1.0546875,
      0.734375,
      -4.25,
      0.302734375,
      5.25,
      -0.021728515625,
      5,
      1.375,
      0.6015625,
      1.28125,
      0.1708984375,
      1.5859375,
      -2.640625,
      3.96875,
      -7.0625,
      0.6953125,
      -0.93359375,
      -3.03125,
      2.0625,
      -5.46875,
      -0.9921875,
      1.796875,
      0.06884765625,
      2.484375,
      4.96875,
      4.84375,
      0.3359375,
      1.1484375,
      -0.236328125,
      2.65625,
      -0.140625,
      -3.78125,
      1.1875,
      1.484375,
      -1.578125,
      -1.421875,
      1.0078125,
      -1.7734375,
      -0.45703125,
      0.2890625,
      -5.4375,
      -1.4296875,
      -3.109375,
      -5.375,
      7.125,
      -0.353515625,
      -0.06689453125,
      3.46875,
      4.125,
      3.265625,
      3.765625,
      0.03759765625,
      3.6875,
      -0.03369140625,
      -0.494140625,
      4.375,
      -2.859375,
      -0.95703125,
      3.015625,
      3,
      4.75,
      -1.109375,
      -2.078125,
      -1.46875,
      1.640625,
      4.09375,
      -0.9453125,
      0.1904296875,
      6.4375,
      1.8515625,
      -1.9453125,
      1.015625,
      -1.8046875,
      -2.25,
      -2.265625,
      0.365234375,
      6.0625,
      6.90625,
      -5.125,
      -2.375,
      -6.78125,
      0.78515625,
      -0.77734375,
      -1.3984375,
      0.072265625,
      1.0703125,
      0.55859375,
      2.515625,
      -0.267578125,
      -1.4921875,
      0.5859375,
      -4.3125,
      -0.1455078125,
      1.8984375,
      -0.453125,
      -0.453125,
      0.494140625,
      4.375,
      -5.34375,
      1.53125,
      1.359375,
      -4.25,
      2.96875,
      0.50390625,
      -1.8046875,
      4.3125,
      1.234375,
      1.0390625,
      0.95703125,
      -2.6875,
      -5.03125,
      -0.1357421875,
      0.21484375,
      3.21875,
      -4.96875,
      -2.453125,
      7.375,
      5.5,
      0.330078125,
      2.765625,
      -2.453125,
      -1.3359375,
      0.2353515625,
      -2.203125,
      -4.5625,
      -1.890625,
      -0.5078125,
      -2.0625,
      -0.0021514892578125,
      -0.96484375,
      -0.32421875,
      1.625,
      -4.59375,
      5,
      -4.4375,
      5.34375,
      -0.93359375,
      -1.9140625,
      -0.177734375,
      -0.09423828125,
      -0.203125,
      -2.078125,
      3.953125,
      1.0234375,
      -1.2109375,
      1.8203125,
      -2.5625,
      -0.006317138671875,
      0.71875,
      -1.9375,
      4.15625,
      -3.3125,
      0.14453125,
      -1.2734375,
      1.546875,
      -7.09375,
      -2.5625,
      -1.453125,
      -0.984375,
      -0.546875,
      -1.15625,
      1.984375,
      -2.125,
      4.375,
      -1.2890625,
      -0.416015625,
      -3.296875,
      -2.234375,
      1.09375,
      -3.03125,
      5.4375,
      2.109375,
      -2.96875,
      -1.1640625,
      -0.75,
      -5.71875,
      -2.984375,
      -0.93359375,
      4.96875,
      -2.34375,
      0.212890625,
      1.5390625,
      1.0234375,
      -2.609375,
      0.93359375,
      0.466796875,
      3.890625,
      0.416015625,
      0.640625,
      3.546875,
      0.11328125,
      1.2734375,
      -4.46875,
      -6.21875,
      -4.6875,
      -1.3125,
      3.59375,
      -4.3125,
      2.6875,
      -2.0625,
      -0.5703125,
      0.5703125,
      -0.8125,
      -0.95703125,
      -0.1494140625,
      3.15625,
      -3.9375,
      0.3828125,
      4.0625,
      0.55078125,
      -0.0010833740234375,
      -2.6875,
      -2.28125,
      -5.125,
      1.140625,
      0.1796875,
      3.0625,
      -1.015625,
      -2.375,
      -1.3359375,
      0.4765625,
      -4.15625,
      -0.7421875,
      5.90625,
      0.875,
      3.25,
      1.65625,
      0.8359375,
      -1.234375,
      -0.271484375,
      0.027099609375,
      4.21875,
      3.234375,
      -2.71875,
      4.3125,
      -2.796875,
      4.09375,
      -1.5078125,
      -0.69921875,
      -7.28125,
      -0.82421875,
      6.53125,
      0.0673828125,
      -1.03125,
      1.65625,
      1.828125,
      2.515625,
      1.21875,
      4.375,
      -2.765625,
      -3.015625,
      -1.3359375,
      3.046875,
      2.09375,
      -3.40625,
      1.1796875,
      3.953125,
      -4.09375,
      2.734375,
      4.15625,
      3.390625,
      -0.7421875,
      4.90625,
      0.072265625,
      -1.1640625,
      -3.78125,
      4.125,
      0.46484375,
      0.322265625,
      -1.4140625,
      -0.51953125,
      -0.58984375,
      0.89453125,
      2.703125,
      3.578125,
      -1.6640625,
      2.390625,
      0.003509521484375,
      2.328125,
      2.5625,
      -1.046875,
      0.484375,
      3.28125,
      1.15625,
      -2.6875,
      2.25,
      -4.78125,
      1.625,
      -1.9296875,
      -8.0625,
      0.00927734375,
      -0.6875,
      -0.671875,
      4.90625,
      1.3203125,
      -0.90625,
      0.6796875,
      -3.1875,
      0.86328125,
      -1.453125,
      -0.4296875,
      1.4921875,
      2.53125,
      -0.59375,
      2.53125,
      -2.703125,
      -2.265625,
      -3.265625,
      2.6875,
      0.8515625,
      1.4765625,
      1.4921875,
      3.53125,
      -3.890625,
      -2.828125,
      -2.875,
      -0.85546875,
      -2.25,
      1.3671875,
      -1.078125,
      2.265625,
      1.671875,
      -3.015625,
      -2.6875,
      -0.435546875,
      -1.25,
      0.82421875,
      1.2734375,
      3.78125,
      -4.96875,
      4.15625,
      -4.90625,
      0.58984375,
      2.6875,
      -1.390625,
      -2.65625,
      -0.42578125,
      -2.5,
      1.921875,
      3.4375,
      -1.7890625,
      -0.1005859375,
      4.34375,
      -0.56640625,
      -1,
      0.412109375,
      0.326171875,
      1.546875,
      0.0322265625,
      0.99609375,
      -1.5859375,
      0.384765625,
      -0.72265625,
      -1,
      1.609375,
      2.234375,
      0.828125,
      5.8125,
      1.7421875,
      -0.2353515625,
      -1.7890625,
      -2.625,
      5.625,
      -0.115234375,
      -3.34375,
      2.859375,
      1.3359375,
      0.031494140625,
      -6.375,
      2.9375,
      2.171875,
      0.298828125,
      3.671875,
      5.59375,
      -1.7578125,
      -2.546875,
      4.15625,
      2.578125,
      -1.0703125,
      -0.06494140625,
      -0.2431640625,
      3.09375,
      -4.0625,
      0.640625,
      -4.53125,
      -0.953125,
      2.265625,
      -2.5625,
      0.8046875,
      -1.625,
      2.109375,
      -3.984375,
      -3,
      0.55859375,
      -0.08251953125,
      1.328125,
      -4.875,
      1.734375,
      1.6328125,
      -0.39453125,
      2.96875,
      -1.4921875,
      -4.84375,
      -2.421875,
      0.640625,
      -5.34375,
      -2.875,
      -7.65625,
      -1.1015625,
      -1.875,
      -0.765625,
      -1.5234375,
      0.7265625,
      1.6015625,
      -1.625,
      -3.671875,
      -1.46875,
      -2.328125,
      -5.46875,
      4.875,
      -2.9375,
      -4.03125,
      -0.59765625,
      0.435546875,
      2.234375,
      5.8125,
      5.8125,
      2.375,
      -2.359375,
      -0.1220703125,
      -0.51171875,
      1.3671875,
      0.78515625,
      1.171875,
      -1.9375,
      -1.1875,
      0.8125,
      -0.34375,
      3.890625,
      -5.53125,
      -1.0234375,
      -2.734375,
      -1.7890625,
      1.546875,
      1.84375,
      -4.3125,
      -0.77734375,
      7.9375,
      -2.46875,
      5.34375,
      2.140625,
      -1.640625,
      -4.53125,
      3.4375,
      -0.244140625,
      4.78125,
      2.9375,
      0.9453125,
      -3.578125,
      2.84375,
      2.609375,
      0.95703125,
      2.28125,
      5.15625,
      -1.625,
      -3.75,
      4.34375,
      0.49609375,
      4.90625,
      -0.408203125,
      0.55078125,
      4.46875,
      -0.6484375,
      3.09375,
      5.03125,
      0.59375,
      -1.875,
      2.859375,
      0.263671875,
      -3.828125,
      -2.46875,
      1.6953125,
      -4.34375,
      -1.421875,
      0.47265625,
      0.048583984375,
      2.171875,
      1.1015625,
      2.328125,
      2.90625,
      3.859375,
      -3.453125,
      0.515625,
      -6.90625,
      4.03125,
      -6.78125,
      1.4765625,
      -6.96875,
      1.34375,
      3.65625,
      5.09375,
      -1.78125,
      -1.8046875,
      2.484375,
      6.125,
      -1.2578125,
      -0.75,
      4.75,
      0.83203125,
      -2.015625,
      -3.4375,
      -2.53125,
      2.84375,
      0.6953125,
      2.125,
      -1.984375,
      0.79296875,
      0.51171875,
      -2.546875,
      -3.75,
      1.28125,
      0.1572265625,
      -6.09375,
      -5.625,
      -4.5625,
      1.125,
      -3.109375,
      3.765625,
      3.40625,
      -0.77734375,
      2.765625,
      0.05322265625,
      1.015625,
      3.28125,
      1.0625,
      0.3125,
      -0.5546875,
      -2.3125,
      0.4921875,
      2.96875,
      -1.6484375,
      2.9375,
      -1.84375,
      2.390625,
      1.9375,
      -2.40625,
      0.349609375,
      -6,
      2.734375,
      1.9375,
      4.125,
      1.265625,
      -2.09375,
      2.40625,
      1.7265625,
      -0.423828125,
      -2.890625,
      -0.79296875,
      -0.046875,
      0.44921875,
      -0.072265625,
      -0.76171875,
      5.6875,
      -0.11474609375,
      1.09375,
      0.05322265625,
      1.7578125,
      -4.625,
      0.63671875,
      -5.71875,
      2.4375,
      -2.765625,
      6.09375,
      2.203125,
      -2.9375,
      -0.240234375,
      0.384765625,
      -1.25,
      0.78515625,
      0.359375,
      -0.3359375,
      0.7421875,
      0.09033203125,
      0.216796875,
      -2.734375,
      1.6640625,
      0.79296875,
      -1.484375,
      -3.421875,
      -0.279296875,
      0.275390625,
      0.447265625,
      -3.546875,
      -1.6484375,
      -2.078125,
      1.984375,
      -0.08056640625,
      -9.625,
      -0.041259765625,
      -0.64453125,
      0.208984375,
      -2.921875,
      1.796875,
      4.5625,
      2.890625,
      4.03125,
      3.859375,
      0.24609375,
      -2.609375,
      4.03125,
      19.125,
      -1.1328125,
      -4.53125,
      -0.0196533203125,
      -1.203125,
      4.4375,
      6.03125,
      1.5,
      1.9140625,
      -0.177734375,
      2.171875,
      2.703125,
      0.75390625,
      1.8046875,
      1,
      -0.0595703125,
      0.75,
      -2.125,
      -0.003509521484375,
      -3.328125,
      0.47265625,
      0.1396484375,
      0.77734375,
      4.78125,
      -0.96484375,
      3.296875,
      0.0537109375,
      -0.443359375,
      -0.076171875,
      -2.796875,
      -1.1484375,
      -0.35546875,
      -2.96875,
      -4.8125,
      -1.4609375,
      -5.96875,
      1.8203125,
      1.3359375,
      -1.9453125,
      -2.140625,
      -2.265625,
      -1.7421875,
      2.125,
      -2.78125,
      -0.43359375,
      3.15625,
      -2.71875,
      -0.240234375,
      -0.64453125,
      -1.5390625,
      -2.5,
      -1.4296875,
      -5.21875,
      0.81640625,
      1.1484375,
      -2.90625,
      0.1357421875,
      -3.90625,
      -4.65625,
      -4.40625,
      -0.5703125,
      -0.6875,
      -2.609375,
      -0.6171875,
      -2.015625,
      -1.859375,
      -2.140625,
      -0.12451171875,
      -1.015625,
      -2.1875,
      -2.65625,
      -1.46875,
      3.703125,
      2.890625,
      1.3828125,
      0.48046875,
      2.40625,
      2.40625,
      0.5234375,
      2.390625,
      -0.66796875,
      0.8828125,
      -1.8125,
      1.1953125,
      -2.734375,
      1.96875,
      -5.3125,
      3.125,
      0.359375,
      0.828125,
      4.5,
      -1.9765625,
      -0.0810546875,
      0.1484375,
      -6.125,
      -2.921875,
      3,
      1.265625,
      -1.640625,
      2.390625,
      2.59375,
      2.484375,
      -0.271484375,
      0.83984375,
      -0.78125,
      -0.31640625,
      5.3125,
      -2.84375,
      0.90625,
      -0.05859375,
      -1.375,
      4.34375,
      1.8671875,
      -0.7890625,
      0.890625,
      2.3125,
      -3.8125,
      -2.671875,
      -2.28125,
      0.78125,
      3.8125,
      2.25,
      -3.59375,
      0.7109375,
      -5.1875,
      -5,
      -3.75,
      -4.53125,
      2.515625,
      -3,
      1.21875,
      -1.0078125,
      -4.03125,
      -1.421875,
      -0.474609375,
      -4.53125,
      2.703125,
      4.75,
      2.28125,
      -1.546875,
      -6.9375,
      1.859375,
      1.5625,
      -2.71875,
      -2.15625,
      3.40625,
      -1.71875,
      2.328125,
      3.890625,
      1.3046875,
      -3.921875,
      1.5234375,
      1.25,
      -3.265625,
      -0.294921875,
      0.90625,
      -2.21875,
      -1.640625,
      -3.296875,
      -0.625,
      -0.03955078125,
      0.2060546875,
      -1.3046875,
      -1.953125,
      -2.234375,
      -0.1572265625,
      3.34375,
      1.1171875,
      -6.53125,
      1.625,
      5.5625,
      -6.5625,
      -1.3515625,
      -2.09375,
      5.09375,
      -3.515625,
      1.796875,
      7.0625,
      0.67578125,
      -1.25,
      3.65625,
      1.671875,
      -0.021484375,
      -6,
      3.421875,
      7.15625,
      -0.431640625,
      1.5703125,
      2.71875,
      0.423828125,
      0.32421875,
      -1.4921875,
      -5.9375,
      5.0625,
      4.59375,
      -4.3125,
      1.3671875,
      -0.478515625,
      1.3984375,
      -1.9453125,
      -2.390625,
      1.921875,
      -0.10107421875,
      2.5625,
      2.4375,
      -1.5859375,
      -4.96875,
      2.046875,
      1.734375,
      -3.71875,
      -5.59375,
      2.4375,
      3.25,
      1.3984375,
      -3.859375,
      5.59375,
      3.671875,
      2.046875,
      -0.51953125,
      1.8046875,
      1.953125,
      1.8359375,
      -4.65625,
      -1.2734375,
      0.0177001953125,
      2.859375,
      -5.28125,
      0.076171875,
      -3.453125,
      4.25,
      -5.625,
      2.046875,
      -1.7265625,
      2.53125,
      -2.6875,
      -4.6875,
      -3.953125,
      4.03125,
      1.21875,
      0.45703125,
      4.40625,
      -0.31640625,
      1.3984375,
      2.078125,
      -3.265625,
      1.9765625,
      1.1875,
      0.53125,
      -0.55859375,
      -0.66796875,
      1.015625,
      0.7734375,
      2.421875,
      -2.234375,
      -2.0625,
      -2.953125,
      -0.98046875,
      0.232421875,
      -4.8125,
      2.578125,
      -0.07958984375,
      -2.625,
      1.8828125,
      -1.9296875,
      -1.59375,
      -0.1181640625,
      1.09375,
      -6.1875,
      4.53125,
      3.59375,
      -5.9375,
      3.203125,
      0.765625,
      -3.703125,
      2.828125,
      -2.828125,
      0.18359375,
      -5.9375,
      0.75390625,
      2.21875,
      -3.6875,
      -2.984375,
      2.71875,
      -2.25,
      -0.9765625,
      -3.734375,
      4.6875,
      0.400390625,
      0.345703125,
      0.11376953125,
      3.59375,
      2.765625,
      -3.125,
      4.03125,
      -2.390625,
      1.078125,
      -2.78125,
      -1.4140625,
      1.8359375,
      -2.328125,
      1.859375,
      3.328125,
      1.984375,
      -8.1875,
      -3.890625,
      0.1337890625,
      -3.703125,
      4.40625,
      0.65625,
      0.287109375,
      -1.9609375,
      0.34765625,
      1.1796875,
      2.921875,
      -4.3125,
      -4.1875,
      -3.46875,
      1.5703125,
      -0.8359375,
      -6.625,
      0.5859375,
      1.0078125,
      -1.3359375,
      -1.9375,
      -1.125,
      -1.3359375,
      -1.0078125,
      0.703125,
      -5.59375,
      1.484375,
      0.55859375,
      1.2734375,
      6.875,
      -1.0390625,
      1.8125,
      4.09375,
      0.98828125,
      -5.375,
      1.75,
      -0.53515625,
      -0.94921875,
      -0.42578125,
      -1.4140625,
      0.68359375,
      -0.365234375,
      1.8359375,
      -6.21875,
      3.890625,
      -0.1875,
      -9.8125,
      4.1875,
      -4,
      0.2275390625,
      0.40234375,
      -5.78125,
      -2.921875,
      4.59375,
      0.0277099609375,
      -0.83203125,
      4.09375,
      -0.05029296875,
      -0.2255859375,
      2.125,
      1.3203125,
      -1.7734375,
      0.3359375,
      2.75,
      -4.46875,
      2.6875,
      2.390625,
      -0.1533203125,
      -3.515625,
      -1.1015625,
      6.0625,
      -0.671875,
      -0.283203125,
      3.65625,
      3.46875,
      0.251953125,
      -0.79296875,
      -4.90625,
      0.0625,
      -0.466796875,
      -2.984375,
      -1.3203125,
      0.1376953125,
      0.64453125,
      -3.515625,
      1.0859375,
      -0.049072265625,
      -3.140625,
      -3.90625,
      -1.828125,
      -2.046875,
      -1.6640625,
      2.28125,
      1.5390625,
      -2.4375,
      2.046875,
      1.4375,
      -0.4453125,
      -2.1875,
      -3.40625,
      1.703125,
      -1.796875,
      -4.65625,
      -1.6015625,
      2.03125,
      -2.546875,
      -1.609375,
      0.53515625,
      -0.041015625,
      -1.4921875,
      -4.09375,
      -4.0625,
      4.71875,
      0.37890625,
      -0.6484375,
      -4.03125,
      -2.484375,
      0.9453125,
      4.75,
      -3.203125,
      -0.62890625,
      -0.72265625,
      1.625,
      -4.28125,
      -4.15625,
      0.6484375,
      -3.15625,
      0.0732421875,
      4.59375,
      2.1875,
      1.484375,
      1.6015625,
      -4.03125,
      -2.53125,
      3.859375,
      5.0625,
      0.326171875,
      -1.65625,
      -0.0791015625,
      -1.7109375,
      2.6875,
      6.71875,
      -3.734375,
      -0.609375,
      1.6953125,
      -0.44140625,
      -0.0947265625,
      -1.28125,
      -0.37109375,
      1.0078125,
      -1.828125,
      2.875,
      0.21484375,
      2.484375,
      3.640625,
      -0.236328125,
      1.0078125,
      -2.203125,
      3.78125,
      -1,
      3.234375,
      2.546875,
      -4.78125,
      1.9765625,
      -5.8125,
      -0.58984375,
      -0.6484375,
      -1.78125,
      0.419921875,
      -1.8125,
      6.21875,
      1.453125,
      -0.384765625,
      -0.03076171875,
      -1.140625,
      5,
      -0.71484375,
      -2.453125,
      -2.6875,
      -0.97265625,
      3.671875,
      -0.08203125,
      -0.62109375,
      -4.34375,
      -1.015625,
      -1.984375,
      2.5625,
      1.7421875,
      0.9609375,
      -1.703125,
      -3.890625,
      -0.85546875,
      4.03125,
      0.5625,
      4.3125,
      3.078125,
      2.3125,
      0.296875,
      -0.357421875,
      1.421875,
      3.5625,
      1.7421875,
      -2.59375,
      -1.5546875,
      2.484375,
      -3.390625,
      -2.53125,
      -1.15625,
      1.5546875,
      -0.29296875,
      3.265625,
      0.361328125,
      -1.2890625,
      -0.6484375,
      -1.3359375,
      -3.296875,
      -1.0390625,
      2.390625,
      3.46875,
      -2.328125,
      2.171875,
      1.9453125,
      2.96875,
      3.296875,
      -0.251953125,
      1.9609375,
      0.1474609375,
      -0.24609375,
      -0.859375,
      -2.15625,
      -1.859375,
      0.46484375,
      0.228515625,
      0.376953125,
      -2.125,
      -3.34375,
      4.0625,
      1.46875,
      -0.11181640625,
      2.984375,
      0.1103515625,
      -1.7890625,
      1.0390625,
      -0.392578125,
      -2.359375,
      1.359375,
      0.0693359375,
      2.640625,
      -0.028564453125,
      -0.369140625,
      1.3125,
      1.6328125,
      0.2431640625,
      1.203125,
      1.296875,
      1.9609375,
      -1.1484375,
      -0.42578125,
      2.0625,
      -2.4375,
      1.953125,
      2.765625,
      1.15625,
      2.3125,
      0.26953125,
      -1.546875,
      1.1796875,
      -3.328125,
      -0.87890625,
      -0.189453125,
      -0.30078125,
      2.515625,
      1.703125,
      1.46875,
      -1.2265625,
      -0.236328125,
      -2.484375,
      -1.859375,
      -2.65625,
      0.3203125,
      -3.671875,
      -1.1484375,
      1.40625,
      -0.4375,
      -2.5,
      0.7265625,
      0.220703125,
      -2.625,
      0.2099609375,
      -3.59375,
      0.86328125,
      -0.85546875,
      -0.296875,
      -1.7265625,
      2.0625,
      -1.9921875,
      0.71875,
      0.267578125,
      -1.5234375,
      -0.125,
      0.216796875,
      -1.71875,
      -1.046875,
      -0.09033203125,
      -0.84375,
      3.640625,
      -0.83203125,
      -0.3203125,
      0.060546875,
      -1.9453125,
      1.6875,
      -0.287109375,
      0.78125,
      3.09375,
      -1.2734375,
      1.765625,
      2.609375,
      2.359375,
      -2.90625,
      -0.65625,
      -1.4765625,
      -0.06005859375,
      0.875,
      -0.96875,
      -0.98828125,
      1.7578125,
      -3.015625,
      -0.259765625,
      3.03125,
      1.9609375,
      -0.0174560546875,
      -0.62890625,
      -0.388671875,
      -1.625,
      0.474609375,
      2.421875,
      -2.140625,
      -0.78515625,
      -3,
      -3.984375,
      -1.15625,
      -0.0400390625,
      1.671875,
      1.765625,
      1.640625,
      -0.66015625,
      1.484375,
      0.39453125,
      -0.345703125,
      -0.390625,
      3.0625,
      0.0908203125,
      -0.82421875,
      -0.66796875,
      2.265625,
      1.078125,
      -1.5078125,
      0.08984375,
      0.0546875,
      2.625,
      2.15625,
      0.6875,
      3.328125,
      -0.1455078125,
      -1.015625,
      3.546875,
      -5.3125,
      -2.671875,
      -3.15625,
      1.640625,
      0.49609375,
      -1.546875,
      -0.345703125,
      2.046875,
      0.390625,
      1.8828125,
      1.890625,
      1.75,
      -0.546875,
      1.53125,
      1.4375,
      -0.150390625,
      1.875,
      -1.5390625,
      -1.8984375,
      -1.1796875,
      -0.38671875,
      -0.62890625,
      1.0078125,
      -2.75,
      2.453125,
      -1.5859375,
      0.5078125,
      0.640625,
      -0.447265625,
      0.3984375,
      2.3125,
      -0.314453125,
      3.484375,
      -0.4453125,
      -0.00921630859375,
      2.734375,
      3.65625,
      -0.7890625,
      0.921875,
      -2.84375,
      -0.06201171875,
      -2.78125,
      3.453125,
      0.58984375,
      1.75,
      0.0732421875,
      -1.734375,
      0.84765625,
      -1.515625,
      2.59375,
      -3.078125,
      2.03125,
      0.255859375,
      -3.921875,
      2.546875,
      1.0546875,
      -0.24609375,
      5.34375,
      -6.5625,
      -0.60546875,
      -2.703125,
      1.5859375,
      3.625,
      -0.224609375,
      1.2734375,
      -3.015625,
      0.490234375,
      -1.125,
      -0.061767578125,
      0.98046875,
      3.140625,
      2.046875,
      -0.365234375,
      -1.3984375,
      -0.95703125,
      -0.486328125,
      -0.12890625,
      -4.09375,
      2.921875,
      -2.1875,
      -0.498046875,
      -3.03125,
      -0.9609375,
      -5.53125,
      -3.4375,
      0.7265625,
      -0.478515625,
      0.1875,
      4.03125,
      -2.75,
      -1.3515625,
      -1.4296875,
      -3.078125,
      4.28125,
      0.0301513671875,
      -2.671875,
      3.734375,
      -0.1845703125,
      3.453125,
      -0.86328125,
      -1.671875,
      -2.28125,
      -1.8359375,
      -0.388671875,
      -2.015625,
      0.42578125,
      -0.189453125,
      -2.96875,
      0.703125,
      -0.1328125,
      -1.46875,
      -1.515625,
      0.9375,
      -0.58203125,
      -0.205078125,
      0.56640625,
      1.640625,
      4.21875,
      -0.35546875,
      1.5546875,
      1.6015625,
      3.15625,
      1.875,
      0.58203125,
      -2.734375,
      -2.21875,
      1.5703125,
      0.59765625,
      0.458984375,
      0.796875,
      0.625,
      3.4375,
      0.138671875,
      0.74609375,
      0.3359375,
      0.546875,
      -1.140625,
      1.3125,
      3.75,
      -6.84375,
      -0.30078125,
      -0.99609375,
      -0.2177734375,
      -0.71875,
      2.53125,
      0.1259765625,
      2.734375,
      1.9921875,
      2.390625,
      1.984375,
      1.3203125,
      0.26953125,
      0.89453125,
      2.5625,
      1.8984375,
      -1.8125,
      -2.421875,
      -0.71484375,
      -0.265625,
      1.7890625,
      0.2275390625,
      2.703125,
      1.4453125,
      -3.015625,
      -0.373046875,
      -0.5390625,
      1.40625,
      3.140625,
      0.58203125,
      -1.609375,
      -0.609375,
      -2.90625,
      3.15625,
      0.083984375,
      1.8359375,
      -0.2001953125,
      1.21875,
      -1.5078125,
      -2.390625,
      -0.78515625,
      -1.78125,
      -1.2421875,
      -1.015625,
      -2.1875,
      0.095703125,
      -4.5,
      0.81640625,
      -2.203125,
      1.59375,
      4.40625,
      3.40625,
      3.953125,
      0.89453125,
      0.173828125,
      3.140625,
      -1.8203125,
      -0.80078125,
      1.578125,
      -1.328125,
      -2.828125,
      -1.3828125,
      0.51171875,
      -2.28125,
      -1.59375,
      -3.515625,
      -0.64453125,
      0.31640625,
      0.98828125,
      -1.6328125,
      -1.5625,
      3.890625,
      -3.859375,
      -1.625,
      -0.94921875,
      -2.046875,
      -0.146484375,
      0.70703125,
      1.5625,
      -0.79296875,
      1.625,
      1.1484375,
      -0.13671875,
      -1.9140625,
      -1.9140625,
      -2.984375,
      -1.1953125,
      -0.84375,
      2.453125,
      -0.2080078125,
      -0.80078125,
      -3.140625,
      2.765625,
      0.52734375,
      0.419921875,
      -0.99609375,
      -1.4921875,
      2.109375,
      3.515625,
      -0.96484375,
      1.4453125,
      -1.3984375,
      0.08740234375,
      -3.65625,
      1.2109375,
      0.111328125,
      0.7421875,
      -0.2021484375,
      2.40625,
      -1.78125,
      1.828125,
      -1.03125,
      0.609375,
      1.5546875,
      -5.3125,
      0.875,
      -2.65625,
      -1.3046875,
      5.25,
      -1.078125,
      1.0390625,
      -3.171875,
      1.375,
      -2.40625,
      3.09375,
      -1.625,
      -0.71484375,
      1.640625,
      0.482421875,
      -1.3671875,
      5.375,
      0.28515625,
      -1.2734375,
      3.640625,
      1.53125,
      -2.359375,
      -1.9296875,
      -0.6875,
      -0.263671875,
      -1.0625,
      -0.6171875,
      -2.34375,
      -2.140625,
      0.443359375,
      -0.6796875,
      -1.3125,
      0.328125,
      4.4375,
      2.015625,
      0.423828125,
      -3.265625,
      1.359375,
      1.125,
      2.109375,
      1.9375,
      0.8828125,
      0.66796875,
      -3.71875,
      -1.0703125,
      -0.46484375,
      2.046875,
      -0.67578125,
      -2.546875,
      -1.6640625,
      1.2265625,
      -0.6875,
      -1.6484375,
      0.89453125,
      -2.765625,
      -0.9296875,
      -1.921875,
      -1.484375,
      -4.5625,
      -0.3828125,
      -2.25,
      3.515625,
      -2.25,
      -2.59375,
      3.796875,
      -0.17578125,
      -2.078125,
      -0.04443359375,
      -1.15625,
      3.109375,
      2.03125,
      -0.384765625,
      -1.421875,
      0.99609375,
      -3.328125,
      3.78125,
      1.4296875,
      4.59375,
      0.6015625,
      -0.92578125,
      0.35546875,
      -1.03125,
      0.37109375,
      0.181640625,
      1.171875,
      2.078125,
      -0.361328125,
      -2.90625,
      4.375,
      1.1015625
    ],
    "summary": "将大语言模型（LLMs）的推理能力与外部工具（如搜索引擎）相结合，使其能够作为研究智能体完成复杂、开放式的任务。该方法通过一个系统化的多阶段流程，实现关键思考、多源信息处理和可验证的输出。",
    "structure": {
      "sections": [
        {
          "title": "Deep Research: A Systematic Survey",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Contents",
          "level": 1,
          "start_line": 21
        },
        {
          "title": "4.3 End-to-End Agentic Reinforcement Learning 31",
          "level": 1,
          "start_line": 67
        },
        {
          "title": "5 Evaluation of Deep Research System 36",
          "level": 1,
          "start_line": 73
        },
        {
          "title": "5.1 Agentic Information Seeking 36",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "5.2 Comprehensive Report Generation 39",
          "level": 1,
          "start_line": 80
        },
        {
          "title": "5.3 AI for Research 41",
          "level": 1,
          "start_line": 87
        },
        {
          "title": "5.4 Software Engineering 43",
          "level": 1,
          "start_line": 94
        },
        {
          "title": "6 Challenges and Outlook 43",
          "level": 1,
          "start_line": 96
        },
        {
          "title": "6.1 Retrieval Timing 43",
          "level": 1,
          "start_line": 98
        },
        {
          "title": "6.2 Memory Evolution 43",
          "level": 1,
          "start_line": 100
        },
        {
          "title": "6.3 Instability in Training Algorithms 45",
          "level": 1,
          "start_line": 106
        },
        {
          "title": "6.4 Evaluation of Deep Research System 46",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "7 Open Discussion: Deep Research to General Intelligence 48",
          "level": 1,
          "start_line": 117
        },
        {
          "title": "8 Conclusion and Future Outlook 49",
          "level": 1,
          "start_line": 123
        },
        {
          "title": "1. Introduction",
          "level": 1,
          "start_line": 125
        },
        {
          "title": "2. Preliminary Concept of Deep Research",
          "level": 1,
          "start_line": 140
        },
        {
          "title": "2.1. What is Deep Research",
          "level": 1,
          "start_line": 142
        },
        {
          "title": "2.2. Understanding Deep Research from Three Phases",
          "level": 1,
          "start_line": 146
        },
        {
          "title": "2.3. Comparing Deep Research with RAG",
          "level": 1,
          "start_line": 168
        },
        {
          "title": "3. Key Components in Deep Research System",
          "level": 1,
          "start_line": 176
        },
        {
          "title": "3.1. Query Planning",
          "level": 1,
          "start_line": 180
        },
        {
          "title": "3.1.1. Parallel Planning",
          "level": 1,
          "start_line": 195
        },
        {
          "title": "3.1.2. Sequential Planning",
          "level": 1,
          "start_line": 207
        },
        {
          "title": "3.1.3. Tree-based Planning",
          "level": 1,
          "start_line": 215
        },
        {
          "title": "Takeaway",
          "level": 1,
          "start_line": 223
        },
        {
          "title": "3.2. Information Acquisition",
          "level": 1,
          "start_line": 231
        },
        {
          "title": "3.2.1. Retrieval Tools",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "Takeaway",
          "level": 1,
          "start_line": 253
        },
        {
          "title": "3.2.2. Retrieval Timing",
          "level": 1,
          "start_line": 257
        },
        {
          "title": "3.2.3. Information Filtering",
          "level": 1,
          "start_line": 291
        },
        {
          "title": "Takeaway",
          "level": 1,
          "start_line": 318
        },
        {
          "title": "3.3. Memory Management",
          "level": 1,
          "start_line": 322
        },
        {
          "title": "3.3.1. Memory Consolidation",
          "level": 1,
          "start_line": 330
        },
        {
          "title": "3.3.2. Memory Indexing",
          "level": 1,
          "start_line": 340
        },
        {
          "title": "3.3.3. Memory Updating",
          "level": 1,
          "start_line": 350
        },
        {
          "title": "3.3.4. Memory Forgetting",
          "level": 1,
          "start_line": 369
        },
        {
          "title": "Takeaway",
          "level": 1,
          "start_line": 380
        },
        {
          "title": "3.4. Answer Generation",
          "level": 1,
          "start_line": 384
        },
        {
          "title": "3.4.1. Integrating Upstream Information",
          "level": 1,
          "start_line": 390
        },
        {
          "title": "3.4.2. Synthesizing Evidence and Maintaining Coherence",
          "level": 1,
          "start_line": 403
        },
        {
          "title": "3.4.3. Structuring Reasoning and Narrative",
          "level": 1,
          "start_line": 418
        },
        {
          "title": "3.4.4. Presentation Generation",
          "level": 1,
          "start_line": 430
        },
        {
          "title": "Takeaway",
          "level": 1,
          "start_line": 436
        },
        {
          "title": "4. Practical Techniques for Optimizing Deep Research Systems",
          "level": 1,
          "start_line": 440
        },
        {
          "title": "4.1. Workflow Prompt Engineering",
          "level": 1,
          "start_line": 450
        },
        {
          "title": "4.1.1. Deep Research System of Anthropic",
          "level": 1,
          "start_line": 454
        },
        {
          "title": "4.2. Supervised Fine-Tuning",
          "level": 1,
          "start_line": 473
        },
        {
          "title": "4.2.1. Strong-to-weak Distillation",
          "level": 1,
          "start_line": 479
        },
        {
          "title": "4.2.2. Iterative Self-Evolving",
          "level": 1,
          "start_line": 493
        },
        {
          "title": "4.3. End-to-End Agentic Reinforcement Learning",
          "level": 1,
          "start_line": 505
        },
        {
          "title": "4.3.1. Preliminary",
          "level": 1,
          "start_line": 509
        },
        {
          "title": "4.3.2. End-to-end Optimization of a Specific Module",
          "level": 1,
          "start_line": 570
        },
        {
          "title": "4.3.3. End-to-end Optimization of an Entire Pipeline",
          "level": 1,
          "start_line": 580
        },
        {
          "title": "Takeaway",
          "level": 1,
          "start_line": 600
        },
        {
          "title": "5. Evaluation of Deep Research System",
          "level": 1,
          "start_line": 606
        },
        {
          "title": "5.1. Agentic Information Seeking",
          "level": 1,
          "start_line": 610
        },
        {
          "title": "5.1.1. Complex Queries",
          "level": 1,
          "start_line": 618
        },
        {
          "title": "5.1.2. Interaction Environment",
          "level": 1,
          "start_line": 632
        },
        {
          "title": "5.2. Comprehensive Report Generation",
          "level": 1,
          "start_line": 642
        },
        {
          "title": "5.2.1. Survey Generation",
          "level": 1,
          "start_line": 646
        },
        {
          "title": "5.2.2. Long-Form Report Generation",
          "level": 1,
          "start_line": 650
        },
        {
          "title": "5.2.3. Poster Generation",
          "level": 1,
          "start_line": 656
        },
        {
          "title": "5.2.4. Slides Generation",
          "level": 1,
          "start_line": 660
        },
        {
          "title": "5.3. AI for Research",
          "level": 1,
          "start_line": 666
        },
        {
          "title": "5.3.1. Idea Generation",
          "level": 1,
          "start_line": 670
        },
        {
          "title": "5.3.2. Experimental Execution",
          "level": 1,
          "start_line": 674
        },
        {
          "title": "5.3.3. Academic Writing",
          "level": 1,
          "start_line": 680
        },
        {
          "title": "5.3.4. Peer Review",
          "level": 1,
          "start_line": 684
        },
        {
          "title": "5.4. Software Engineering",
          "level": 1,
          "start_line": 690
        },
        {
          "title": "6. Challenges and Outlook",
          "level": 1,
          "start_line": 694
        },
        {
          "title": "6.1. Retrieval Timing",
          "level": 1,
          "start_line": 696
        },
        {
          "title": "6.2. Memory Evolution",
          "level": 1,
          "start_line": 702
        },
        {
          "title": "6.2.1. Proactive Personalization Memory Evolution",
          "level": 1,
          "start_line": 706
        },
        {
          "title": "6.2.2. Cognitive-Inspired Structured Memory Evolution",
          "level": 1,
          "start_line": 712
        },
        {
          "title": "6.2.3. Goal-Driven Reinforced Memory Evolution",
          "level": 1,
          "start_line": 720
        },
        {
          "title": "6.3. Instability in Training Algorithms",
          "level": 1,
          "start_line": 726
        },
        {
          "title": "6.3.1. Existing Solutions",
          "level": 1,
          "start_line": 730
        },
        {
          "title": "6.3.2. Future Directions",
          "level": 1,
          "start_line": 736
        },
        {
          "title": "6.4. Evaluation of Deep Research System",
          "level": 1,
          "start_line": 744
        },
        {
          "title": "6.4.1. Logical Evaluation",
          "level": 1,
          "start_line": 750
        },
        {
          "title": "6.4.2. Boundary between Novelty and Hallucination",
          "level": 1,
          "start_line": 756
        },
        {
          "title": "6.4.3. Bias and Efficiency of LLM-as-Judge",
          "level": 1,
          "start_line": 764
        },
        {
          "title": "7. Open Discussion: Deep Research to General Intelligence",
          "level": 1,
          "start_line": 772
        },
        {
          "title": "7.1. Creativity",
          "level": 1,
          "start_line": 776
        },
        {
          "title": "7.2. Fairness",
          "level": 1,
          "start_line": 780
        },
        {
          "title": "7.3. Safety and Reliability",
          "level": 1,
          "start_line": 784
        },
        {
          "title": "8. Conclusion and Future Outlook",
          "level": 1,
          "start_line": 788
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 792
        }
      ]
    },
    "tags": [
      "大语言模型",
      "智能体系统",
      "检索增强生成"
    ],
    "suggested_tags": [
      "大语言模型",
      "智能体系统",
      "检索增强生成",
      "系统综述",
      "AI辅助研究"
    ],
    "tag_suggestions": [
      {
        "name": "大语言模型",
        "confidence": 0.95,
        "reason": "论文核心研究对象是赋能大语言模型（LLMs）进行深度研究，全文围绕如何增强LLMs的推理、检索和生成能力展开。"
      },
      {
        "name": "智能体系统",
        "confidence": 0.9,
        "reason": "论文系统性地探讨了将LLMs构建为能够自主规划、检索、记忆和生成的研究智能体（Research Agents），这是其主要技术范式。"
      },
      {
        "name": "检索增强生成",
        "confidence": 0.85,
        "reason": "论文重点对比并超越了传统的检索增强生成（RAG），提出了更复杂的多阶段、交互式信息获取与整合框架，是RAG的深化与扩展。"
      },
      {
        "name": "系统综述",
        "confidence": 0.8,
        "reason": "本文体裁是一篇系统性综述（Survey），旨在对“深度研究”这一新兴领域进行全面梳理、定义、组件拆解、技术总结与未来展望。"
      },
      {
        "name": "AI辅助研究",
        "confidence": 0.75,
        "reason": "论文明确将“AI for Research”作为核心应用场景之一，包括文献综述、报告生成、学术写作等，旨在利用AI提升科研效率与质量。"
      }
    ],
    "tags_confirmed": true,
    "category": "大语言模型",
    "s2_graph": {
      "citations": [],
      "citations_fetched_at": "2025-12-18T17:19:20.830059",
      "references": [],
      "references_fetched_at": "2025-12-18T17:19:21.143247"
    }
  }
}