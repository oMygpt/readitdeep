{
  "items": {
    "wb-1d8b4206": {
      "id": "wb-1d8b4206",
      "type": "note",
      "title": "ğŸ“Œ  The effect of LLM use on two ...",
      "description": "äººç±»å­¦ä¹ çš„è¿‡ç¨‹",
      "source_paper_id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
      "zone": "notes",
      "created_at": "2025-12-16T02:23:09.458503",
      "data": {
        "original_text": " The effect of LLM use on two foundational aspects of learning â€“ understanding and retaining information â€“ remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity [16] . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs",
        "location": "",
        "is_title_note": false,
        "reflection": "äººç±»å­¦ä¹ çš„è¿‡ç¨‹",
        "reflection_updated_at": "2025-12-16T02:23:34.544645",
        "created_at": "2025-12-16T02:23:09.458220"
      }
    },
    "wb-390fa354": {
      "id": "wb-390fa354",
      "type": "method",
      "title": "åŸºäºè®¤çŸ¥ç­–ç•¥çš„é˜…è¯»ç†è§£å¢å¼ºæ–¹æ³•",
      "description": "é€šè¿‡æ•´åˆMcNamaraå’ŒChiæå‡ºçš„è®¤çŸ¥ç›‘æ§å’Œä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œæ„å»ºç³»ç»Ÿçš„é˜…è¯»ç†è§£å¢å¼ºæµç¨‹ï¼Œé‡ç‚¹åŒ…æ‹¬ç†è§£ç›‘æ§ã€æ–‡æœ¬è§£æå’ŒçŸ¥è¯†æ•´åˆä¸‰ä¸ªæ ¸å¿ƒç¯èŠ‚",
      "source_paper_id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
      "zone": "methods",
      "created_at": "2025-12-16T02:24:44.142948",
      "data": {
        "analysis": {
          "method_name": "åŸºäºè®¤çŸ¥ç­–ç•¥çš„é˜…è¯»ç†è§£å¢å¼ºæ–¹æ³•",
          "method_type": "æµç¨‹",
          "core_idea": "é€šè¿‡æ•´åˆMcNamaraå’ŒChiæå‡ºçš„è®¤çŸ¥ç›‘æ§å’Œä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼Œæ„å»ºç³»ç»Ÿçš„é˜…è¯»ç†è§£å¢å¼ºæµç¨‹ï¼Œé‡ç‚¹åŒ…æ‹¬ç†è§£ç›‘æ§ã€æ–‡æœ¬è§£æå’ŒçŸ¥è¯†æ•´åˆä¸‰ä¸ªæ ¸å¿ƒç¯èŠ‚",
          "innovation_points": [
            "å°†å¤šç§è®¤çŸ¥ç­–ç•¥ç³»ç»ŸåŒ–æ•´åˆä¸ºå¯æ“ä½œçš„é˜…è¯»æµç¨‹",
            "å¼ºè°ƒä¸»åŠ¨å­¦ä¹ ç­–ç•¥åœ¨çŸ¥è¯†ç¼–ç å’Œå­˜å‚¨ä¸­çš„ä½œç”¨"
          ],
          "implementation_steps": [
            "å®æ–½ç†è§£ç›‘æ§ç­–ç•¥ï¼ˆå¦‚ç”Ÿæˆé—®é¢˜è¯„ä¼°ç†è§£ç¨‹åº¦ï¼‰",
            "åº”ç”¨æ–‡æœ¬èšç„¦ç­–ç•¥ï¼ˆå¦‚é‡Šä¹‰ã€æ‹†åˆ†å¤æ‚å¥å­ã€å»ºç«‹æ¦‚å¿µè”ç³»ï¼‰",
            "æ‰§è¡Œä¸»åŠ¨å­¦ä¹ ç­–ç•¥ï¼ˆå¦‚é€‰æ‹©ã€é‡å¤ä»¥æ¿€æ´»å…ˆéªŒçŸ¥è¯†ï¼‰"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "ç†è®ºåŸºç¡€æ‰å®ï¼Œå¼•ç”¨æƒå¨ç ”ç©¶æ”¯æŒ",
              "ç­–ç•¥åˆ†ç±»æ¸…æ™°ï¼Œä¾¿äºå®é™…æ“ä½œ"
            ],
            "weaknesses": [
              "ç¼ºä¹å…·ä½“å®æ–½ç»†èŠ‚å’Œé‡åŒ–æŒ‡æ ‡",
              "æœªè¯´æ˜ä¸åŒç­–ç•¥çš„é€‚ç”¨åœºæ™¯å’Œä¼˜å…ˆçº§"
            ],
            "questions": [
              "è¿™äº›ç­–ç•¥åœ¨ä¸åŒé˜…è¯»ææ–™ç±»å‹ï¼ˆå¦‚ç§‘æŠ€æ–‡çŒ®vsæ–‡å­¦ï¼‰ä¸­çš„æ•ˆæœæ˜¯å¦æœ‰å·®å¼‚ï¼Ÿ",
              "å¦‚ä½•è¯„ä¼°æ¯ç§ç­–ç•¥å¯¹ç†è§£æ•ˆæœçš„å…·ä½“è´¡çŒ®ï¼Ÿ"
            ],
            "suggestions": [
              "å»ºè®®å¢åŠ ç­–ç•¥é€‰æ‹©çš„æ ‡å‡†å’Œè¯„ä¼°æŒ‡æ ‡",
              "å¯è€ƒè™‘å¼€å‘ç›¸åº”çš„è¯„ä¼°å·¥å…·æ¥é‡åŒ–ç­–ç•¥æ•ˆæœ"
            ]
          },
          "reproducibility_score": 6,
          "pseudocode": "# é˜…è¯»ç­–ç•¥æ‰§è¡Œæµç¨‹\n1. åˆå§‹åŒ–é˜…è¯»ä»»åŠ¡å’Œç›®æ ‡\n2. å¾ªç¯æ‰§è¡Œï¼š\n   - ç›‘æ§ç†è§£ç¨‹åº¦ï¼ˆç”Ÿæˆè‡ªæµ‹é—®é¢˜ï¼‰\n   - åº”ç”¨æ–‡æœ¬è§£æç­–ç•¥ï¼ˆé‡Šä¹‰ã€æ‹†åˆ†å¥å­ï¼‰\n   - å®æ–½ä¸»åŠ¨å­¦ä¹ ï¼ˆé€‰æ‹©é‡ç‚¹ã€é‡å¤å…³é”®æ¦‚å¿µï¼‰\n3. è¯„ä¼°ç†è§£æ•ˆæœå¹¶è°ƒæ•´ç­–ç•¥"
        },
        "original_text": "There are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara [35] and Chi [36] . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding [35] . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) [35] . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge [36] . ",
        "location": "",
        "analyzed_at": "2025-12-16T02:24:44.142874"
      }
    },
    "wb-b399bb3b": {
      "id": "wb-b399bb3b",
      "type": "note",
      "title": "ğŸ“Œ We compared the impact of LLM ...",
      "description": "ç¬”è®°çš„ä½œç”¨ä¾æ—§æ˜¯å®ç°å®æ—¶æ€ç»´è®­ç»ƒçš„è¿‡ç¨‹ã€‚",
      "source_paper_id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
      "zone": "notes",
      "created_at": "2025-12-16T02:27:16.752266",
      "data": {
        "original_text": "We compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).",
        "location": "",
        "is_title_note": false,
        "reflection": "ç¬”è®°çš„ä½œç”¨ä¾æ—§æ˜¯å®ç°å®æ—¶æ€ç»´è®­ç»ƒçš„è¿‡ç¨‹ã€‚",
        "reflection_updated_at": "2025-12-16T02:27:48.875404",
        "created_at": "2025-12-16T02:27:16.752217"
      }
    },
    "wb-eb682852": {
      "id": "wb-eb682852",
      "type": "method",
      "title": "éšæœºå¯¹ç…§å®éªŒè®¾è®¡",
      "description": "é€šè¿‡éšæœºåˆ†ç»„æ¯”è¾ƒä¸åŒå­¦ä¹ æ¡ä»¶ï¼ˆLLMã€ä¼ ç»Ÿç¬”è®°ã€LLM+ç¬”è®°ï¼‰å¯¹å­¦ç”Ÿå­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œé‡‡ç”¨é¢„æ³¨å†Œæ’é™¤æ ‡å‡†ç¡®ä¿æ ·æœ¬è´¨é‡",
      "source_paper_id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
      "zone": "methods",
      "created_at": "2025-12-16T02:27:17.009826",
      "data": {
        "analysis": {
          "method_name": "éšæœºå¯¹ç…§å®éªŒè®¾è®¡",
          "method_type": "æµç¨‹",
          "core_idea": "é€šè¿‡éšæœºåˆ†ç»„æ¯”è¾ƒä¸åŒå­¦ä¹ æ¡ä»¶ï¼ˆLLMã€ä¼ ç»Ÿç¬”è®°ã€LLM+ç¬”è®°ï¼‰å¯¹å­¦ç”Ÿå­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œé‡‡ç”¨é¢„æ³¨å†Œæ’é™¤æ ‡å‡†ç¡®ä¿æ ·æœ¬è´¨é‡",
          "innovation_points": [
            "ç»“åˆLLMä¸ä¼ ç»Ÿå­¦ä¹ æ–¹æ³•è¿›è¡Œå¯¹æ¯”å®éªŒ",
            "é‡‡ç”¨é¢„æ³¨å†Œæ’é™¤æ ‡å‡†å¢å¼ºç ”ç©¶ä¸¥è°¨æ€§"
          ],
          "implementation_steps": [
            "æ‹›å‹Ÿ344åå­¦ç”Ÿä½œä¸ºåˆå§‹æ ·æœ¬",
            "åº”ç”¨é¢„æ³¨å†Œæ’é™¤æ ‡å‡†ç­›é€‰æœ‰æ•ˆæ ·æœ¬",
            "éšæœºåˆ†ä¸ºä¸¤ç»„ï¼šGroup 1ï¼ˆLLM vs ç¬”è®°ï¼‰å’ŒGroup 2ï¼ˆLLM vs LLM+ç¬”è®°ï¼‰",
            "æ”¶é›†å­¦ç”ŸèƒŒæ™¯ç‰¹å¾å’Œå­¦ä¹ ä¹ æƒ¯æ•°æ®",
            "å®æ–½ä¸åŒå­¦ä¹ æ¡ä»¶å¹²é¢„å¹¶æµ‹é‡å­¦ä¹ æ•ˆæœ"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "éšæœºåˆ†ç»„è®¾è®¡æœ‰æ•ˆæ§åˆ¶æ··æ‚å˜é‡",
              "æ ·æœ¬é‡è¾ƒå¤§ï¼ˆ344äººï¼‰å¢å¼ºç»Ÿè®¡æ•ˆåŠ›",
              "é¢„æ³¨å†Œæ’é™¤æ ‡å‡†æé«˜æ–¹æ³•é€æ˜åº¦"
            ],
            "weaknesses": [
              "æ€§åˆ«æ¯”ä¾‹ä¸å¹³è¡¡å¯èƒ½å½±å“ç»“æœæ³›åŒ–æ€§",
              "ç¤¾ä¼šç»æµèƒŒæ™¯å¤šæ ·æ€§ä¸è¶³ï¼ˆä»…5.2%å¼±åŠ¿ç¾¤ä½“ï¼‰",
              "LLMä½¿ç”¨ç»éªŒå·®å¼‚å¯èƒ½æ„æˆæ··æ·†å› ç´ "
            ],
            "questions": [
              "éšæœºåˆ†ç»„çš„å…·ä½“å®æ–½æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
              "å¦‚ä½•ç¡®ä¿ä¸åŒç»„åˆ«é—´çš„å¹²é¢„å®æ–½ä¸€è‡´æ€§ï¼Ÿ",
              "é¢„æ³¨å†Œæ’é™¤æ ‡å‡†çš„å…·ä½“å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"
            ],
            "suggestions": [
              "å¢åŠ æ ·æœ¬çš„ç¤¾ä¼šç»æµå¤šæ ·æ€§",
              "å¯¹LLMä½¿ç”¨ç»éªŒè¿›è¡Œæ›´ä¸¥æ ¼çš„åŒ¹é…æ§åˆ¶",
              "æä¾›éšæœºåŒ–è¿‡ç¨‹çš„è¯¦ç»†æ“ä½œè¯´æ˜"
            ]
          },
          "reproducibility_score": 7,
          "pseudocode": "# å®éªŒæµç¨‹ä¼ªä»£ç \n1. åˆå§‹åŒ–: æ‹›å‹Ÿå­¦ç”Ÿæ ·æœ¬(n=344)\n2. ç­›é€‰: åº”ç”¨é¢„æ³¨å†Œæ’é™¤æ ‡å‡†\n3. åˆ†ç»„: éšæœºåˆ†é…è‡³Group1(184äºº)å’ŒGroup2(160äºº)\n4. å¹²é¢„: å®æ–½ä¸åŒå­¦ä¹ æ¡ä»¶\n5. æµ‹é‡: æ”¶é›†å­¦ä¹ æ•ˆæœæ•°æ®\n6. åˆ†æ: æ¯”è¾ƒç»„é—´å·®å¼‚"
        },
        "original_text": "Our study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students \n(\n5.2\n%\n)\n(5.2%) received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).",
        "location": "",
        "analyzed_at": "2025-12-16T02:27:17.009772"
      }
    },
    "wb-f7b3ec2b": {
      "id": "wb-f7b3ec2b",
      "type": "method",
      "title": "ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°æ–¹æ³•",
      "description": "é€šè¿‡ç³»ç»Ÿæ€§çš„åˆ†ç±»æ¡†æ¶å¯¹LLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶è¿›è¡Œå…¨é¢æ¢³ç†ï¼Œä»æ¦‚å¿µå®šä¹‰ã€è®¾è®¡ç»´åº¦åˆ°è¯„ä¼°æ–¹æ³•å»ºç«‹å®Œæ•´çš„åˆ†æä½“ç³»",
      "source_paper_id": "5a74d1e5-32cd-4f2e-9e98-697da1abeeba",
      "zone": "methods",
      "created_at": "2025-12-16T10:20:14.433467",
      "data": {
        "analysis": {
          "method_name": "ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°æ–¹æ³•",
          "method_type": "æµç¨‹",
          "core_idea": "é€šè¿‡ç³»ç»Ÿæ€§çš„åˆ†ç±»æ¡†æ¶å¯¹LLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶è¿›è¡Œå…¨é¢æ¢³ç†ï¼Œä»æ¦‚å¿µå®šä¹‰ã€è®¾è®¡ç»´åº¦åˆ°è¯„ä¼°æ–¹æ³•å»ºç«‹å®Œæ•´çš„åˆ†æä½“ç³»",
          "innovation_points": [
            "æå‡ºè®°å¿†æœºåˆ¶çš„ä¸‰ç»´åˆ†ç±»æ¡†æ¶ï¼ˆæ¥æºã€å½¢å¼ã€æ“ä½œï¼‰",
            "å»ºç«‹è®°å¿†è¯„ä¼°çš„åŒé‡æ ‡å‡†ï¼ˆç›´æ¥è¯„ä¼°ä¸é—´æ¥è¯„ä¼°ï¼‰"
          ],
          "implementation_steps": [
            "æ¦‚å¿µç•Œå®šï¼šæ˜ç¡®è®°å¿†çš„ç‹­ä¹‰å’Œå¹¿ä¹‰å®šä¹‰",
            "å¿…è¦æ€§åˆ†æï¼šä»è®¤çŸ¥å¿ƒç†å­¦ã€è‡ªæˆ‘è¿›åŒ–å’Œåº”ç”¨åœºæ™¯ä¸‰ä¸ªè§†è§’è®ºè¯",
            "è®¾è®¡ç»´åº¦åˆ†æï¼šæŒ‰è®°å¿†æ¥æºã€å­˜å‚¨å½¢å¼å’Œæ“ä½œæœºåˆ¶åˆ†ç±»",
            "è¯„ä¼°æ–¹æ³•æ¢³ç†ï¼šåŒºåˆ†ç›´æ¥è¯„ä¼°å’ŒåŸºäºä»»åŠ¡çš„é—´æ¥è¯„ä¼°",
            "åº”ç”¨åœºæ™¯åˆ†æï¼šå±•ç¤ºè®°å¿†åœ¨å„ç±»æ™ºèƒ½ä½“åº”ç”¨ä¸­çš„é‡è¦æ€§"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "åˆ†ç±»æ¡†æ¶ç³»ç»Ÿå…¨é¢ï¼Œè¦†ç›–è®°å¿†æœºåˆ¶çš„å…³é”®ç»´åº¦",
              "å¤šè§†è§’åˆ†ææ–¹æ³•å¢å¼ºäº†è®ºè¯çš„æ·±åº¦å’Œè¯´æœåŠ›",
              "å®é™…åº”ç”¨åœºæ™¯åˆ†æå¢å¼ºäº†ç ”ç©¶çš„å®ç”¨ä»·å€¼"
            ],
            "weaknesses": [
              "ç¼ºä¹å¯¹å„ç±»è®°å¿†æœºåˆ¶æ•ˆæœçš„å®šé‡æ¯”è¾ƒåˆ†æ",
              "åˆ†ç±»æ ‡å‡†çš„ä¸»è§‚æ€§å¯èƒ½å½±å“æ¡†æ¶çš„æ™®é€‚æ€§",
              "å¯¹è®°å¿†æœºåˆ¶åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸‹çš„é€‚é…æ€§è®¨è®ºä¸è¶³"
            ],
            "questions": [
              "åˆ†ç±»æ¡†æ¶æ˜¯å¦è¦†ç›–äº†æ‰€æœ‰é‡è¦çš„è®°å¿†æœºåˆ¶è®¾è®¡ç»´åº¦ï¼Ÿ",
              "å¦‚ä½•éªŒè¯æ‰€æåˆ†ç±»æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå®Œå¤‡æ€§ï¼Ÿ",
              "ä¸åŒè®°å¿†æœºåˆ¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½å·®å¼‚å¦‚ä½•ï¼Ÿ"
            ],
            "suggestions": [
              "å¢åŠ å¯¹å„ç±»è®°å¿†æœºåˆ¶çš„å®šé‡æ€§èƒ½å¯¹æ¯”åˆ†æ",
              "æä¾›åˆ†ç±»æ¡†æ¶çš„éªŒè¯æ–¹æ³•å’Œè¯„ä¼°æŒ‡æ ‡",
              "æ·±å…¥æ¢è®¨è®°å¿†æœºåˆ¶ä¸å…·ä½“åº”ç”¨åœºæ™¯çš„é€‚é…å…³ç³»"
            ]
          },
          "reproducibility_score": 9,
          "pseudocode": "# æ–‡çŒ®ç»¼è¿°æµç¨‹ä¼ªä»£ç \n1. ç¡®å®šç ”ç©¶èŒƒå›´ï¼šLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶\n2. æ–‡çŒ®æ”¶é›†ä¸ç­›é€‰ï¼šç›¸å…³é¢†åŸŸæ ¸å¿ƒè®ºæ–‡\n3. å»ºç«‹åˆ†ææ¡†æ¶ï¼šæ¦‚å¿µå®šä¹‰â†’è®¾è®¡ç»´åº¦â†’è¯„ä¼°æ–¹æ³•\n4. åˆ†ç±»æ•´ç†ï¼šæŒ‰è®°å¿†æ¥æºã€å½¢å¼ã€æ“ä½œä¸‰ä¸ªç»´åº¦\n5. åº”ç”¨åˆ†æï¼šè¯†åˆ«è®°å¿†åœ¨å„ç±»æ™ºèƒ½ä½“åº”ç”¨ä¸­çš„ä½œç”¨\n6. å±€é™æ€§åˆ†æï¼šè¯†åˆ«å½“å‰ç ”ç©¶çš„ä¸è¶³å’Œæœªæ¥æ–¹å‘"
        },
        "original_text": "Zeyu Zhang $^{1}$ , Xiaohe Bo $^{1}$ , Chen Ma $^{1}$ , Rui Li $^{1}$ , Xu Chen $^{1}$ , Quanyu Dai $^{2}$ , Jieming Zhu $^{2}$ , Zhenhua Dong $^{2}$ , Ji-Rong Wen $^{1}$ $^{1}$ Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China  \n $^{2}$ Huawei Noah's Ark Lab, China  \nzeyuzhang@ruc.edu.cn, xu.chen@ruc.edu.cn\n\n# Abstract\n\nLarge language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematic review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss \"what is\" and \"why do we need\" the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at https://github.com/nuster1128/LLM_Agent_Memory_Survey.\n\n![](images/b45daab8d13fd79cc986247b3fc06262ffed28e4d02cbe98a1354bd006302025.jpg)\n\n![](images/d5e161d1193da83dfe1be348819aad6a4bdb03869f955ecd298067e1feab6c6b.jpg)\n\n![](images/187b77164c1a70c4ae670d8bd352361fe523314e901524b2c8efa1c45be98207.jpg)\n\n![](images/dc6ca064d796b8cf965620450953aef7b73d520974647c31519f759391770029.jpg)\n\n![](images/988fdd8ca1ad763efa9c2c7121e96d48e372dc792e1447264cdc28dca124f586.jpg)\n\n![](images/e058c0bfbdaa099d98aef0f5052982a79eb1e9e4a6056caad3abb3bc1c355a23.jpg)\n\n![](images/c9b5b5879701a03db38905d4800c4893b3f66d5d061507a4b5a8347804f83a4b.jpg)  \nFigure 1: The importance of the memory module in LLM-based agents.\n\n![](images/2dfd1f6e260467d4154b9c01d85fbe0ea21bb866a7617bdf9ad57e17b529a777.jpg)\n\n# Contents\n\n# 1 Introduction 4\n\n# 2 Related Surveys 5\n\n2.1 Surveys on Large Language Models 5  \n2.2 Surveys on Large Language Model-based Agents 7\n\n# 3 What is the Memory of LLM-based Agent 7\n\n3.1 Basic Knowledge 7  \n3.2 Narrow Definition of the Agent Memory 9  \n3.3 Broad Definition of the Agent Memory 9  \n3.4 Memory-assisted Agent-Environment Interaction 9\n\n# 4 Why We Need the Memory in LLM-based Agent 10\n\n4.1 Perspective of Cognitive Psychology 10  \n4.2 Perspective of Self-Evolution 11  \n4.3 Perspective of Agent Applications 11\n\n# 5 How to Implement the Memory of LLM-based Agent 11\n\n5.1 Memory Sources 11\n\n5.1.1 Inside-trial Information 12  \n5.1.2 Cross-trial Information 13  \n5.1.3 External Knowledge 13\n\n5.2 Memory Forms 13\n\n5.2.1 Memory in Textual Form 14  \n5.2.2 Memory in Parametric Form 16  \n5.2.3 Advantages and Disadvantages of Textual and Parametric Memory 17\n\n5.3 Memory Operations 18\n\n5.3.1 Memory Writing 18  \n5.3.2 Memory Management 18  \n5.3.3 Memory Reading 19\n\n# 6 How to Evaluate the Memory in LLM-based Agent 20\n\n6.1 Direct Evaluation 20\n\n6.1.1 Subjective Evaluation 20  \n6.1.2 Objective Evaluation 21\n\n6.2 Indirect Evaluation 22\n\n6.2.1 Conversation 22  \n6.2.2 Multi-source Question-answering 22  \n6.2.3 Long-context Applications 22\n\n6.2.4 Other Tasks 23\n\n6.3 Discussions 23\n\n# 7 Memory-enhanced Agent Applications 23\n\n7.1 Role-playing and Social Simulation 23  \n7.2 Personal Assistant 25  \n7.3 Open-world Game 25  \n7.4 Code Generation 25  \n7.5 Recommendation 26  \n7.6 Expert System in Specific Domains 26  \n7.7 Other Applications 26\n\n# 8 Limitations & Future Directions 27\n\n8.1 More Advances in Parametric Memory 27  \n8.2 Memory in LLM-based Multi-agent Applications 27  \n8.3 Memory-based Lifelong Learning 28  \n8.4 Memory in Humanoid Agent 28\n\n# 9 Conclusion 28\n\n# 1 Introduction\n\n\"Without memory, there is no culture. Without memory, there would be no civilization, no society, no future.\"\n\nElie Wiesel, 1928-2016\n\nRecently, large language models (LLMs) have achieved remarkable success in a large number of domains, ranging from artificial intelligence and software engineering to education and social science [1-3]. Original LLMs usually accomplish different tasks without interacting with environments. However, to achieve the final goal of artificial general intelligence (AGI), intelligent machines should be able to improve themselves by autonomously exploring and learning from the real world. For example, if a trip-planning agent intends to book a ticket, it should send an order request to the ticket website, and observe the response before taking the next action. A personal assistant agent should adjust its behaviors according to the user's feedback, providing personalized responses to improve user's satisfaction. To further push the boundary of LLMs towards AGI, recent years have witnessed a large number of studies on LLM-based agents [3, 4], where the key is to equip LLMs with additional modules to enhance their self-evolving capability in real-world environments.\n\nAmong all the added modules, memory is a key component that differentiates the agents from original LLMs, making an agent truly an agent (see Figure 1). It plays an extremely important role in determining how the agent accumulates knowledge, processes historical experience, retrieves informative knowledge to support its actions, and so on. Around the memory module, people have devoted much effort to designing its information sources, storage forms, and operation mechanisms. For example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory module for enhancing the agent's reasoning capability. Zhong et al. [6] store memory information in the form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7] design both memory reading and writing operations to interact with environments for task solving.\n\nWhile previous studies have designed many promising memory modules, there still lacks a systemic study to view the memory modules from a holistic perspective. To bridge this gap, in this paper, we comprehensively review previous studies to present clear taxonomies and key principles for designing and evaluating the memory module. In specific, we discuss three key problems including: (1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based agents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with, we detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions. Then, we analyze the necessity of memory in LLM-based agents, showing its importance from three perspectives including cognitive psychology, self-evolution, and agent applications. Based on the problems of \"what\" and \"why\", we present commonly used strategies to design and evaluate the memory modules. For the memory design, we discuss previous works from three dimensions, that is, memory sources, memory forms, and memory operations. For the memory evaluation, we introduce two widely used approaches including direct evaluation and indirect evaluation via specific agent tasks. Next, we discuss agent applications including role-playing, social simulation, personal assistant, open-world games, code generation, recommendation, and expert systems, in order to show the importance of the memory module in practical scenarios. At last, we analyze the limitations of existing work and highlight significant future directions.\n\nThe main contributions of this paper can be summarized as follows: (",
        "location": "",
        "analyzed_at": "2025-12-16T10:20:14.433395"
      }
    },
    "wb-0576dd4f": {
      "id": "wb-0576dd4f",
      "type": "code",
      "title": "LLM_Agent_Memory_Survey",
      "description": "è®ºæ–‡ä½œè€…åˆ›å»ºçš„ä»“åº“ï¼Œç”¨äºè·Ÿè¸ªLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶é¢†åŸŸçš„æœ€æ–°è¿›å±•",
      "source_paper_id": "5a74d1e5-32cd-4f2e-9e98-697da1abeeba",
      "zone": "datasets",
      "created_at": "2025-12-16T10:20:25.575763",
      "data": {
        "asset": {
          "name": "LLM_Agent_Memory_Survey",
          "type": "code",
          "url": "https://github.com/nuster1128/LLM_Agent_Memory_Survey",
          "platform": "GitHub",
          "description": "è®ºæ–‡ä½œè€…åˆ›å»ºçš„ä»“åº“ï¼Œç”¨äºè·Ÿè¸ªLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶é¢†åŸŸçš„æœ€æ–°è¿›å±•",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ç”¨äºæŒç»­æ›´æ–°LLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶é¢†åŸŸçš„æœ€æ–°ç ”ç©¶è¿›å±•",
          "verified": false,
          "stars": null
        },
        "original_text": "Zeyu Zhang $^{1}$ , Xiaohe Bo $^{1}$ , Chen Ma $^{1}$ , Rui Li $^{1}$ , Xu Chen $^{1}$ , Quanyu Dai $^{2}$ , Jieming Zhu $^{2}$ , Zhenhua Dong $^{2}$ , Ji-Rong Wen $^{1}$ $^{1}$ Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China  \n $^{2}$ Huawei Noah's Ark Lab, China  \nzeyuzhang@ruc.edu.cn, xu.chen@ruc.edu.cn\n\n# Abstract\n\nLarge language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematic review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss \"what is\" and \"why do we need\" the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at https://github.com/nuster1128/LLM_Agent_Memory_Survey.\n\n![](images/b45daab8d13fd79cc986247b3fc06262ffed28e4d02cbe98a1354bd006302025.jpg)\n\n![](images/d5e161d1193da83dfe1be348819aad6a4bdb03869f955ecd298067e1feab6c6b.jpg)\n\n![](images/187b77164c1a70c4ae670d8bd352361fe523314e901524b2c8efa1c45be98207.jpg)\n\n![](images/dc6ca064d796b8cf965620450953aef7b73d520974647c31519f759391770029.jpg)\n\n![](images/988fdd8ca1ad763efa9c2c7121e96d48e372dc792e1447264cdc28dca124f586.jpg)\n\n![](images/e058c0bfbdaa099d98aef0f5052982a79eb1e9e4a6056caad3abb3bc1c355a23.jpg)\n\n![](images/c9b5b5879701a03db38905d4800c4893b3f66d5d061507a4b5a8347804f83a4b.jpg)  \nFigure 1: The importance of the memory module in LLM-based agents.\n\n![](images/2dfd1f6e260467d4154b9c01d85fbe0ea21bb866a7617bdf9ad57e17b529a777.jpg)\n\n# Contents\n\n# 1 Introduction 4\n\n# 2 Related Surveys 5\n\n2.1 Surveys on Large Language Models 5  \n2.2 Surveys on Large Language Model-based Agents 7\n\n# 3 What is the Memory of LLM-based Agent 7\n\n3.1 Basic Knowledge 7  \n3.2 Narrow Definition of the Agent Memory 9  \n3.3 Broad Definition of the Agent Memory 9  \n3.4 Memory-assisted Agent-Environment Interaction 9\n\n# 4 Why We Need the Memory in LLM-based Agent 10\n\n4.1 Perspective of Cognitive Psychology 10  \n4.2 Perspective of Self-Evolution 11  \n4.3 Perspective of Agent Applications 11\n\n# 5 How to Implement the Memory of LLM-based Agent 11\n\n5.1 Memory Sources 11\n\n5.1.1 Inside-trial Information 12  \n5.1.2 Cross-trial Information 13  \n5.1.3 External Knowledge 13\n\n5.2 Memory Forms 13\n\n5.2.1 Memory in Textual Form 14  \n5.2.2 Memory in Parametric Form 16  \n5.2.3 Advantages and Disadvantages of Textual and Parametric Memory 17\n\n5.3 Memory Operations 18\n\n5.3.1 Memory Writing 18  \n5.3.2 Memory Management 18  \n5.3.3 Memory Reading 19\n\n# 6 How to Evaluate the Memory in LLM-based Agent 20\n\n6.1 Direct Evaluation 20\n\n6.1.1 Subjective Evaluation 20  \n6.1.2 Objective Evaluation 21\n\n6.2 Indirect Evaluation 22\n\n6.2.1 Conversation 22  \n6.2.2 Multi-source Question-answering 22  \n6.2.3 Long-context Applications 22\n\n6.2.4 Other Tasks 23\n\n6.3 Discussions 23\n\n# 7 Memory-enhanced Agent Applications 23\n\n7.1 Role-playing and Social Simulation 23  \n7.2 Personal Assistant 25  \n7.3 Open-world Game 25  \n7.4 Code Generation 25  \n7.5 Recommendation 26  \n7.6 Expert System in Specific Domains 26  \n7.7 Other Applications 26\n\n# 8 Limitations & Future Directions 27\n\n8.1 More Advances in Parametric Memory 27  \n8.2 Memory in LLM-based Multi-agent Applications 27  \n8.3 Memory-based Lifelong Learning 28  \n8.4 Memory in Humanoid Agent 28\n\n# 9 Conclusion 28\n\n# 1 Introduction\n\n\"Without memory, there is no culture. Without memory, there would be no civilization, no society, no future.\"\n\nElie Wiesel, 1928-2016\n\nRecently, large language models (LLMs) have achieved remarkable success in a large number of domains, ranging from artificial intelligence and software engineering to education and social science [1-3]. Original LLMs usually accomplish different tasks without interacting with environments. However, to achieve the final goal of artificial general intelligence (AGI), intelligent machines should be able to improve themselves by autonomously exploring and learning from the real world. For example, if a trip-planning agent intends to book a ticket, it should send an order request to the ticket website, and observe the response before taking the next action. A personal assistant agent should adjust its behaviors according to the user's feedback, providing personalized responses to improve user's satisfaction. To further push the boundary of LLMs towards AGI, recent years have witnessed a large number of studies on LLM-based agents [3, 4], where the key is to equip LLMs with additional modules to enhance their self-evolving capability in real-world environments.\n\nAmong all the added modules, memory is a key component that differentiates the agents from original LLMs, making an agent truly an agent (see Figure 1). It plays an extremely important role in determining how the agent accumulates knowledge, processes historical experience, retrieves informative knowledge to support its actions, and so on. Around the memory module, people have devoted much effort to designing its information sources, storage forms, and operation mechanisms. For example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory module for enhancing the agent's reasoning capability. Zhong et al. [6] store memory information in the form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7] design both memory reading and writing operations to interact with environments for task solving.\n\nWhile previous studies have designed many promising memory modules, there still lacks a systemic study to view the memory modules from a holistic perspective. To bridge this gap, in this paper, we comprehensively review previous studies to present clear taxonomies and key principles for designing and evaluating the memory module. In specific, we discuss three key problems including: (1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based agents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with, we detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions. Then, we analyze the necessity of memory in LLM-based agents, showing its importance from three perspectives including cognitive psychology, self-evolution, and agent applications. Based on the problems of \"what\" and \"why\", we present commonly used strategies to design and evaluate the memory modules. For the memory design, we discuss previous works from three dimensions, that is, memory sources, memory forms, and memory operations. For the memory evaluation, we introduce two widely used approaches including direct evaluation and indirect evaluation via specific agent tasks. Next, we discuss agent applications including role-playing, social simulation, personal assistant, open-world games, code generation, recommendation, and expert systems, in order to show the importance of the memory module in practical scenarios. At last, we analyze the limitations of existing work and highlight significant future directions.\n\nThe main contributions of this paper can be summarized as follows: (",
        "location": "",
        "analyzed_at": "2025-12-16T10:20:25.575693"
      }
    },
    "wb-5b40efa7": {
      "id": "wb-5b40efa7",
      "type": "method",
      "title": "æ— æ³•è¯†åˆ«",
      "description": "æä¾›çš„æ–‡æœ¬ç‰‡æ®µè¿‡äºç®€çŸ­ï¼Œä»…åŒ…å«æ ‡é¢˜'Hello World'ï¼Œæ— æ³•æå–å…·ä½“çš„ç ”ç©¶æ–¹æ³•ä¿¡æ¯",
      "source_paper_id": "c48c530c-6261-425b-9771-bb1d4c8d06d6",
      "zone": "methods",
      "created_at": "2025-12-16T10:36:48.587499",
      "data": {
        "analysis": {
          "method_name": "æ— æ³•è¯†åˆ«",
          "method_type": "æ— æ³•è¯†åˆ«",
          "core_idea": "æä¾›çš„æ–‡æœ¬ç‰‡æ®µè¿‡äºç®€çŸ­ï¼Œä»…åŒ…å«æ ‡é¢˜'Hello World'ï¼Œæ— æ³•æå–å…·ä½“çš„ç ”ç©¶æ–¹æ³•ä¿¡æ¯",
          "innovation_points": [
            "ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•è¯†åˆ«åˆ›æ–°ç‚¹"
          ],
          "implementation_steps": [
            "ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•è¯†åˆ«å…·ä½“æ­¥éª¤"
          ],
          "key_formulas": [
            "æ— "
          ],
          "reviewer_comments": {
            "strengths": [
              "æ–‡æœ¬ç®€æ´æ˜äº†"
            ],
            "weaknesses": [
              "å†…å®¹è¿‡äºç®€ç•¥ï¼Œç¼ºä¹ç ”ç©¶æ–¹æ³•çš„å…·ä½“æè¿°",
              "éœ€è¦éªŒè¯æ˜¯å¦å­˜åœ¨å®Œæ•´çš„ç ”ç©¶æ–¹æ³•æè¿°"
            ],
            "questions": [
              "è®ºæ–‡æ˜¯å¦åŒ…å«å…·ä½“çš„ç ”ç©¶æ–¹æ³•ç« èŠ‚ï¼Ÿ",
              "Hello Worldæ˜¯å¦åªæ˜¯æ ‡é¢˜è€Œéæ–¹æ³•æè¿°ï¼Ÿ",
              "æ˜¯å¦æœ‰é—æ¼çš„æ–‡æœ¬å†…å®¹ï¼Ÿ"
            ],
            "suggestions": [
              "è¯·æä¾›æ›´å®Œæ•´çš„ç ”ç©¶æ–¹æ³•æè¿°ç‰‡æ®µ",
              "ç¡®è®¤æ˜¯å¦æä¾›äº†è¶³å¤Ÿçš„æ–¹æ³•å­¦ç»†èŠ‚"
            ]
          },
          "reproducibility_score": 0,
          "pseudocode": "# ä¿¡æ¯ä¸è¶³ï¼Œæ— æ³•æä¾›ä¼ªä»£ç \n# è¯·æä¾›æ›´è¯¦ç»†çš„æ–¹æ³•æè¿°"
        },
        "original_text": "# Hello World",
        "location": "",
        "analyzed_at": "2025-12-16T10:36:48.587230"
      }
    },
    "wb-3779c248": {
      "id": "wb-3779c248",
      "type": "method",
      "title": "LLM-based Agent Memory ç³»ç»Ÿç»¼è¿°æ–¹æ³•",
      "description": "é€šè¿‡ç³»ç»Ÿæ€§çš„æ–‡çŒ®ç»¼è¿°æ–¹æ³•ï¼Œä»å¤šä¸ªç»´åº¦ï¼ˆå®šä¹‰ã€å¿…è¦æ€§ã€å®ç°ã€è¯„ä¼°ã€åº”ç”¨ï¼‰å…¨é¢åˆ†æLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶çš„ç ”ç©¶ç°çŠ¶",
      "source_paper_id": "c7e2c3e2-0fa8-48ca-9d79-e2847b260c07",
      "zone": "methods",
      "created_at": "2025-12-16T10:40:08.237114",
      "data": {
        "analysis": {
          "method_name": "LLM-based Agent Memory ç³»ç»Ÿç»¼è¿°æ–¹æ³•",
          "method_type": "ç»¼è¿°æ–¹æ³•",
          "core_idea": "é€šè¿‡ç³»ç»Ÿæ€§çš„æ–‡çŒ®ç»¼è¿°æ–¹æ³•ï¼Œä»å¤šä¸ªç»´åº¦ï¼ˆå®šä¹‰ã€å¿…è¦æ€§ã€å®ç°ã€è¯„ä¼°ã€åº”ç”¨ï¼‰å…¨é¢åˆ†æLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶çš„ç ”ç©¶ç°çŠ¶",
          "innovation_points": [
            "é¦–æ¬¡æå‡ºLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶çš„ç³»ç»Ÿæ€§åˆ†ç±»æ¡†æ¶ï¼ˆå†…å­˜æ¥æºã€å½¢å¼ã€æ“ä½œï¼‰",
            "å»ºç«‹è®°å¿†æ¨¡å—çš„å¤šç»´åº¦è¯„ä¼°ä½“ç³»ï¼ˆç›´æ¥è¯„ä¼°ä¸é—´æ¥è¯„ä¼°ï¼‰"
          ],
          "implementation_steps": [
            "æ–‡çŒ®æ”¶é›†ä¸ç­›é€‰ï¼šç³»ç»Ÿæ£€ç´¢LLMæ™ºèƒ½ä½“ç›¸å…³ç ”ç©¶æ–‡çŒ®",
            "åˆ†ç±»æ¡†æ¶æ„å»ºï¼šåŸºäºè®°å¿†åŠŸèƒ½å»ºç«‹å¤šç»´åº¦åˆ†ææ¡†æ¶",
            "å†…å®¹åˆ†æï¼šæå–å„ç ”ç©¶çš„è®°å¿†è®¾è®¡æ¨¡å¼ã€è¯„ä¼°æ–¹æ³•å’Œåº”ç”¨åœºæ™¯",
            "å¯¹æ¯”åˆ†æï¼šè¯†åˆ«ä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨æ¡ä»¶",
            "è¶‹åŠ¿æ€»ç»“ï¼šæç‚¼æœªæ¥ç ”ç©¶æ–¹å‘å’Œå‘å±•è¶‹åŠ¿"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "åˆ†ç±»æ¡†æ¶ç³»ç»Ÿå…¨é¢ï¼Œè¦†ç›–è®°å¿†æœºåˆ¶çš„å…³é”®ç»´åº¦",
              "ç»“åˆè®¤çŸ¥å¿ƒç†å­¦ç†è®ºä¸ºè®°å¿†å¿…è¦æ€§æä¾›ç†è®ºæ”¯æ’‘",
              "å»ºç«‹äº†å¼€æºèµ„æºåº“ä¾¿äºåç»­ç ”ç©¶è·Ÿè¸ª"
            ],
            "weaknesses": [
              "æ–‡çŒ®ç­›é€‰æ ‡å‡†å’Œæ–¹æ³•æœªæ˜ç¡®è¯´æ˜ï¼Œå¯èƒ½å­˜åœ¨é€‰æ‹©åå·®",
              "ç¼ºä¹å¯¹è®°å¿†æœºåˆ¶æ•ˆæœçš„ç³»ç»Ÿæ€§é‡åŒ–æ¯”è¾ƒ",
              "æœªè®¨è®ºä¸åŒè®°å¿†æœºåˆ¶çš„è®¡ç®—å¤æ‚åº¦å’Œèµ„æºéœ€æ±‚"
            ],
            "questions": [
              "æ–‡çŒ®æ£€ç´¢çš„æ—¶é—´èŒƒå›´å’Œæ•°æ®åº“æ˜¯ä»€ä¹ˆï¼Ÿ",
              "å¦‚ä½•ç¡®ä¿åˆ†ç±»æ¡†æ¶çš„å®Œå¤‡æ€§å’Œäº’æ–¥æ€§ï¼Ÿ",
              "è®°å¿†æœºåˆ¶çš„æ€§èƒ½æ¯”è¾ƒæ˜¯å¦æœ‰ç»Ÿä¸€çš„åŸºå‡†æµ‹è¯•ï¼Ÿ"
            ],
            "suggestions": [
              "å¢åŠ æ–‡çŒ®ç­›é€‰çš„é€æ˜åº¦å’Œå¯é‡å¤æ€§æè¿°",
              "å»ºç«‹æ ‡å‡†åŒ–çš„è®°å¿†æœºåˆ¶è¯„ä¼°åŸºå‡†",
              "å¢åŠ å¯¹å®é™…éƒ¨ç½²æŒ‘æˆ˜çš„è®¨è®º"
            ]
          },
          "reproducibility_score": 7,
          "pseudocode": "# ç³»ç»Ÿç»¼è¿°æ–¹æ³•ä¼ªä»£ç \n1. æ–‡çŒ®æ£€ç´¢ä¸ç­›é€‰\n   - è®¾å®šæ£€ç´¢å…³é”®è¯ï¼šLLM agent, memory mechanism\n   - åº”ç”¨çº³å…¥æ’é™¤æ ‡å‡†ç­›é€‰ç›¸å…³æ–‡çŒ®\n2. å†…å®¹åˆ†ææ¡†æ¶æ„å»º\n   - å®šä¹‰åˆ†æç»´åº¦ï¼šè®°å¿†å®šä¹‰ã€å¿…è¦æ€§ã€å®ç°ã€è¯„ä¼°ã€åº”ç”¨\n   - å»ºç«‹å­åˆ†ç±»ä½“ç³»\n3. ç³»ç»Ÿåˆ†ææ‰§è¡Œ\n   - é€ç¯‡æå–å…³é”®ä¿¡æ¯å¹¶å½’ç±»\n   - è¯†åˆ«æ¨¡å¼ã€è¶‹åŠ¿å’Œå·®è·\n4. ç»“æœæ•´åˆä¸éªŒè¯\n   - äº¤å‰éªŒè¯åˆ†ç±»ç»“æœ\n   - æç‚¼æ ¸å¿ƒå‘ç°å’Œæœªæ¥æ–¹å‘"
        },
        "original_text": "Zeyu Zhang $^{1}$ , Xiaohe Bo $^{1}$ , Chen Ma $^{1}$ , Rui Li $^{1}$ , Xu Chen $^{1}$ , Quanyu Dai $^{2}$ , Jieming Zhu $^{2}$ , Zhenhua Dong $^{2}$ , Ji-Rong Wen $^{1}$ $^{1}$ Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China  \n $^{2}$ Huawei Noah's Ark Lab, China  \nzeyuzhang@ruc.edu.cn, xu.chen@ruc.edu.cn\n\n# Abstract\n\nLarge language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematic review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss \"what is\" and \"why do we need\" the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at https://github.com/nuster1128/LLM_Agent_Memory_Survey.\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/b45daab8d13fd79cc986247b3fc06262ffed28e4d02cbe98a1354bd006302025.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/d5e161d1193da83dfe1be348819aad6a4bdb03869f955ecd298067e1feab6c6b.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/187b77164c1a70c4ae670d8bd352361fe523314e901524b2c8efa1c45be98207.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/dc6ca064d796b8cf965620450953aef7b73d520974647c31519f759391770029.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/988fdd8ca1ad763efa9c2c7121e96d48e372dc792e1447264cdc28dca124f586.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/e058c0bfbdaa099d98aef0f5052982a79eb1e9e4a6056caad3abb3bc1c355a23.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/c9b5b5879701a03db38905d4800c4893b3f66d5d061507a4b5a8347804f83a4b.jpg)  \nFigure 1: The importance of the memory module in LLM-based agents.\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/2dfd1f6e260467d4154b9c01d85fbe0ea21bb866a7617bdf9ad57e17b529a777.jpg)\n\n# Contents\n\n# 1 Introduction 4\n\n# 2 Related Surveys 5\n\n2.1 Surveys on Large Language Models 5  \n2.2 Surveys on Large Language Model-based Agents 7\n\n# 3 What is the Memory of LLM-based Agent 7\n\n3.1 Basic Knowledge 7  \n3.2 Narrow Definition of the Agent Memory 9  \n3.3 Broad Definition of the Agent Memory 9  \n3.4 Memory-assisted Agent-Environment Interaction 9\n\n# 4 Why We Need the Memory in LLM-based Agent 10\n\n4.1 Perspective of Cognitive Psychology 10  \n4.2 Perspective of Self-Evolution 11  \n4.3 Perspective of Agent Applications 11\n\n# 5 How to Implement the Memory of LLM-based Agent 11\n\n5.1 Memory Sources 11\n\n5.1.1 Inside-trial Information 12  \n5.1.2 Cross-trial Information 13  \n5.1.3 External Knowledge 13\n\n5.2 Memory Forms 13\n\n5.2.1 Memory in Textual Form 14  \n5.2.2 Memory in Parametric Form 16  \n5.2.3 Advantages and Disadvantages of Textual and Parametric Memory 17\n\n5.3 Memory Operations 18\n\n5.3.1 Memory Writing 18  \n5.3.2 Memory Management 18  \n5.3.3 Memory Reading 19\n\n# 6 How to Evaluate the Memory in LLM-based Agent 20\n\n6.1 Direct Evaluation 20\n\n6.1.1 Subjective Evaluation 20  \n6.1.2 Objective Evaluation 21\n\n6.2 Indirect Evaluation 22\n\n6.2.1 Conversation 22  \n6.2.2 Multi-source Question-answering 22  \n6.2.3 Long-context Applications 22\n\n6.2.4 Other Tasks 23\n\n6.3 Discussions 23\n\n# 7 Memory-enhanced Agent Applications 23\n\n7.1 Role-playing and Social Simulation 23  \n7.2 Personal Assistant 25  \n7.3 Open-world Game 25  \n7.4 Code Generation 25  \n7.5 Recommendation 26  \n7.6 Expert System in Specific Domains 26  \n7.7 Other Applications 26\n\n# 8 Limitations & Future Directions 27\n\n8.1 More Advances in Parametric Memory 27  \n8.2 Memory in LLM-based Multi-agent Applications 27  \n8.3 Memory-based Lifelong Learning 28  \n8.4 Memory in Humanoid Agent 28\n\n# 9 Conclusion 28\n\n# 1 Introduction\n\n\"Without memory, there is no culture. Without memory, there would be no civilization, no society, no future.\"\n\nElie Wiesel, 1928-2016\n\nRecently, large language models (LLMs) have achieved remarkable success in a large number of domains, ranging from artificial intelligence and software engineering to education and social science [1-3]. Original LLMs usually accomplish different tasks without interacting with environments. However, to achieve the final goal of artificial general intelligence (AGI), intelligent machines should be able to improve themselves by autonomously exploring and learning from the real world. For example, if a trip-planning agent intends to book a ticket, it should send an order request to the ticket website, and observe the response before taking the next action. A personal assistant agent should adjust its behaviors according to the user's feedback, providing personalized responses to improve user's satisfaction. To further push the boundary of LLMs towards AGI, recent years have witnessed a large number of studies on LLM-based agents [3, 4], where the key is to equip LLMs with additional modules to enhance their self-evolving capability in real-world environments.\n\nAmong all the added modules, memory is a key component that differentiates the agents from original LLMs, making an agent truly an agent (see Figure 1). It plays an extremely important role in determining how the agent accumulates knowledge, processes historical experience, retrieves informative knowledge to support its actions, and so on. Around the memory module, people have devoted much effort to designing its information sources, storage forms, and operation mechanisms. For example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory module for enhancing the agent's reasoning capability. Zhong et al. [6] store memory information in the form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7] design both memory reading and writing operations to interact with environments for task solving.\n\nWhile previous studies have designed many promising memory modules, there still lacks a systemic study to view the memory modules from a holistic perspective. To bridge this gap, in this paper, we comprehensively review previous studies to present clear taxonomies and key principles for designing and evaluating the memory module. In specific, we discuss three key problems including: (1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based agents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with, we detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions. Then, we analyze the necessity of memory in LLM-based agents, showing its importance from three perspectives including cognitive psychology, self-evolution, and agent applications. Based on the problems of \"what\" and \"why\", we present commonly used strategies to design and evaluate the memory modules. For the memory design, we discuss previous works from three dimensions, that is, memory sources, memory forms, and memory operations. For the memory evaluation, we introduce two widely used approaches including direct evaluation and indirect evaluation via specific agent tasks. Next, we discuss agent applications including ",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:08.237060"
      }
    },
    "wb-95d358cd": {
      "id": "wb-95d358cd",
      "type": "method",
      "title": "å¤šé¢†åŸŸå¤šé€‰é¢˜æ¡ˆä¾‹ç ”ç©¶è¯„ä¼°æ³•",
      "description": "é€šè¿‡é¢„å®šä¹‰çš„å¤šé¢†åŸŸå¤šé€‰é¢˜é›†å¯¹ChatGPTå’ŒDeepSeek AIè¿›è¡Œç³»ç»Ÿæ€§èƒ½åŠ›è¯„ä¼°ï¼Œæ¯”è¾ƒä¸¤è€…åœ¨æŠ€æœ¯å·®å¼‚ã€å®é™…åº”ç”¨å’Œæ€§èƒ½è¡¨ç°ä¸Šçš„ä¼˜åŠ£",
      "source_paper_id": "9866dfe0-a3d7-41a1-99e5-c2ed00636259",
      "zone": "methods",
      "created_at": "2025-12-16T10:40:13.155391",
      "data": {
        "analysis": {
          "method_name": "å¤šé¢†åŸŸå¤šé€‰é¢˜æ¡ˆä¾‹ç ”ç©¶è¯„ä¼°æ³•",
          "method_type": "è¯„ä¼°æ–¹æ³•",
          "core_idea": "é€šè¿‡é¢„å®šä¹‰çš„å¤šé¢†åŸŸå¤šé€‰é¢˜é›†å¯¹ChatGPTå’ŒDeepSeek AIè¿›è¡Œç³»ç»Ÿæ€§èƒ½åŠ›è¯„ä¼°ï¼Œæ¯”è¾ƒä¸¤è€…åœ¨æŠ€æœ¯å·®å¼‚ã€å®é™…åº”ç”¨å’Œæ€§èƒ½è¡¨ç°ä¸Šçš„ä¼˜åŠ£",
          "innovation_points": [
            "é‡‡ç”¨æ ‡å‡†åŒ–çš„å¤šé€‰é¢˜è¯„ä¼°æ¡†æ¶ç¡®ä¿ç»“æœå¯æ¯”æ€§",
            "è·¨é¢†åŸŸç»¼åˆè¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›"
          ],
          "implementation_steps": [
            "è®¾è®¡æ¶µç›–å¤šä¸ªé¢†åŸŸçš„å¤šé€‰é¢˜é›†",
            "åˆ†åˆ«å¯¹ChatGPTå’ŒDeepSeek AIè¿›è¡Œæµ‹è¯•",
            "è®°å½•å’Œåˆ†ææ¨¡å‹å›ç­”çš„å‡†ç¡®æ€§å’Œè´¨é‡",
            "å¯¹æ¯”è¯„ä¼°ä¸¤æ¨¡å‹çš„ä¼˜åŠ¿å’Œå±€é™æ€§"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "è¯„ä¼°æ–¹æ³•æ ‡å‡†åŒ–ä¾¿äºç»“æœæ¯”è¾ƒ",
              "å¤šé¢†åŸŸè¦†ç›–å¢å¼ºäº†è¯„ä¼°çš„å…¨é¢æ€§"
            ],
            "weaknesses": [
              "ç¼ºä¹è¯¦ç»†çš„é¢˜ç›®è®¾è®¡å’Œè¯„åˆ†æ ‡å‡†è¯´æ˜",
              "æ ·æœ¬é‡å¤§å°å’Œä»£è¡¨æ€§æœªæ˜ç¡®è¯´æ˜"
            ],
            "questions": [
              "å¤šé€‰é¢˜é›†çš„å…·ä½“è®¾è®¡åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ",
              "å¦‚ä½•ç¡®ä¿è¯„ä¼°ç»“æœçš„ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Ÿ",
              "æ˜¯å¦è€ƒè™‘äº†æ¨¡å‹å›ç­”çš„æ·±åº¦å’Œåˆ›é€ æ€§ï¼Ÿ"
            ],
            "suggestions": [
              "æä¾›è¯¦ç»†çš„é¢˜ç›®æ ·ä¾‹å’Œè¯„åˆ†æ ‡å‡†",
              "å¢åŠ æ ·æœ¬é‡å’Œç»Ÿè®¡åˆ†ææ–¹æ³•",
              "è¡¥å……å®šæ€§åˆ†æä»¥è¯„ä¼°å›ç­”è´¨é‡"
            ]
          },
          "reproducibility_score": 6,
          "pseudocode": "# æ¨¡å‹è¯„ä¼°æµç¨‹\n1. åˆå§‹åŒ–ï¼šå‡†å¤‡å¤šé¢†åŸŸå¤šé€‰é¢˜åº“\n2. æµ‹è¯•å¾ªç¯ï¼šå¯¹æ¯ä¸ªæ¨¡å‹ä¾æ¬¡æµ‹è¯•æ‰€æœ‰é¢˜ç›®\n3. è¯„åˆ†ï¼šè®°å½•å›ç­”å‡†ç¡®æ€§å’Œè´¨é‡\n4. åˆ†æï¼šå¯¹æ¯”ä¸¤æ¨¡å‹åœ¨å„é¢†åŸŸçš„è¡¨ç°å·®å¼‚\n5. è¾“å‡ºï¼šç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š"
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectio",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:13.155357"
      }
    },
    "wb-17d8d139": {
      "id": "wb-17d8d139",
      "type": "code",
      "title": "LLM_Agent_Memory_Survey",
      "description": "è®ºæ–‡ä½œè€…åˆ›å»ºçš„ä»“åº“ï¼Œç”¨äºè·Ÿè¸ªLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶é¢†åŸŸçš„æœ€æ–°è¿›å±•",
      "source_paper_id": "c7e2c3e2-0fa8-48ca-9d79-e2847b260c07",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:18.792278",
      "data": {
        "asset": {
          "name": "LLM_Agent_Memory_Survey",
          "type": "code",
          "url": "https://github.com/nuster1128/LLM_Agent_Memory_Survey",
          "platform": "GitHub",
          "description": "è®ºæ–‡ä½œè€…åˆ›å»ºçš„ä»“åº“ï¼Œç”¨äºè·Ÿè¸ªLLMæ™ºèƒ½ä½“è®°å¿†æœºåˆ¶é¢†åŸŸçš„æœ€æ–°è¿›å±•",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ç”¨äºæŒç»­æ›´æ–°è¯¥é¢†åŸŸçš„ç›¸å…³ç ”ç©¶èµ„æº",
          "verified": true,
          "stars": null
        },
        "original_text": "Zeyu Zhang $^{1}$ , Xiaohe Bo $^{1}$ , Chen Ma $^{1}$ , Rui Li $^{1}$ , Xu Chen $^{1}$ , Quanyu Dai $^{2}$ , Jieming Zhu $^{2}$ , Zhenhua Dong $^{2}$ , Ji-Rong Wen $^{1}$ $^{1}$ Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China  \n $^{2}$ Huawei Noah's Ark Lab, China  \nzeyuzhang@ruc.edu.cn, xu.chen@ruc.edu.cn\n\n# Abstract\n\nLarge language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematic review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss \"what is\" and \"why do we need\" the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at https://github.com/nuster1128/LLM_Agent_Memory_Survey.\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/b45daab8d13fd79cc986247b3fc06262ffed28e4d02cbe98a1354bd006302025.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/d5e161d1193da83dfe1be348819aad6a4bdb03869f955ecd298067e1feab6c6b.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/187b77164c1a70c4ae670d8bd352361fe523314e901524b2c8efa1c45be98207.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/dc6ca064d796b8cf965620450953aef7b73d520974647c31519f759391770029.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/988fdd8ca1ad763efa9c2c7121e96d48e372dc792e1447264cdc28dca124f586.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/e058c0bfbdaa099d98aef0f5052982a79eb1e9e4a6056caad3abb3bc1c355a23.jpg)\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/c9b5b5879701a03db38905d4800c4893b3f66d5d061507a4b5a8347804f83a4b.jpg)  \nFigure 1: The importance of the memory module in LLM-based agents.\n\n![](/uploads/images/c7e2c3e2-0fa8-48ca-9d79-e2847b260c07/2dfd1f6e260467d4154b9c01d85fbe0ea21bb866a7617bdf9ad57e17b529a777.jpg)\n\n# Contents\n\n# 1 Introduction 4\n\n# 2 Related Surveys 5\n\n2.1 Surveys on Large Language Models 5  \n2.2 Surveys on Large Language Model-based Agents 7\n\n# 3 What is the Memory of LLM-based Agent 7\n\n3.1 Basic Knowledge 7  \n3.2 Narrow Definition of the Agent Memory 9  \n3.3 Broad Definition of the Agent Memory 9  \n3.4 Memory-assisted Agent-Environment Interaction 9\n\n# 4 Why We Need the Memory in LLM-based Agent 10\n\n4.1 Perspective of Cognitive Psychology 10  \n4.2 Perspective of Self-Evolution 11  \n4.3 Perspective of Agent Applications 11\n\n# 5 How to Implement the Memory of LLM-based Agent 11\n\n5.1 Memory Sources 11\n\n5.1.1 Inside-trial Information 12  \n5.1.2 Cross-trial Information 13  \n5.1.3 External Knowledge 13\n\n5.2 Memory Forms 13\n\n5.2.1 Memory in Textual Form 14  \n5.2.2 Memory in Parametric Form 16  \n5.2.3 Advantages and Disadvantages of Textual and Parametric Memory 17\n\n5.3 Memory Operations 18\n\n5.3.1 Memory Writing 18  \n5.3.2 Memory Management 18  \n5.3.3 Memory Reading 19\n\n# 6 How to Evaluate the Memory in LLM-based Agent 20\n\n6.1 Direct Evaluation 20\n\n6.1.1 Subjective Evaluation 20  \n6.1.2 Objective Evaluation 21\n\n6.2 Indirect Evaluation 22\n\n6.2.1 Conversation 22  \n6.2.2 Multi-source Question-answering 22  \n6.2.3 Long-context Applications 22\n\n6.2.4 Other Tasks 23\n\n6.3 Discussions 23\n\n# 7 Memory-enhanced Agent Applications 23\n\n7.1 Role-playing and Social Simulation 23  \n7.2 Personal Assistant 25  \n7.3 Open-world Game 25  \n7.4 Code Generation 25  \n7.5 Recommendation 26  \n7.6 Expert System in Specific Domains 26  \n7.7 Other Applications 26\n\n# 8 Limitations & Future Directions 27\n\n8.1 More Advances in Parametric Memory 27  \n8.2 Memory in LLM-based Multi-agent Applications 27  \n8.3 Memory-based Lifelong Learning 28  \n8.4 Memory in Humanoid Agent 28\n\n# 9 Conclusion 28\n\n# 1 Introduction\n\n\"Without memory, there is no culture. Without memory, there would be no civilization, no society, no future.\"\n\nElie Wiesel, 1928-2016\n\nRecently, large language models (LLMs) have achieved remarkable success in a large number of domains, ranging from artificial intelligence and software engineering to education and social science [1-3]. Original LLMs usually accomplish different tasks without interacting with environments. However, to achieve the final goal of artificial general intelligence (AGI), intelligent machines should be able to improve themselves by autonomously exploring and learning from the real world. For example, if a trip-planning agent intends to book a ticket, it should send an order request to the ticket website, and observe the response before taking the next action. A personal assistant agent should adjust its behaviors according to the user's feedback, providing personalized responses to improve user's satisfaction. To further push the boundary of LLMs towards AGI, recent years have witnessed a large number of studies on LLM-based agents [3, 4], where the key is to equip LLMs with additional modules to enhance their self-evolving capability in real-world environments.\n\nAmong all the added modules, memory is a key component that differentiates the agents from original LLMs, making an agent truly an agent (see Figure 1). It plays an extremely important role in determining how the agent accumulates knowledge, processes historical experience, retrieves informative knowledge to support its actions, and so on. Around the memory module, people have devoted much effort to designing its information sources, storage forms, and operation mechanisms. For example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory module for enhancing the agent's reasoning capability. Zhong et al. [6] store memory information in the form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7] design both memory reading and writing operations to interact with environments for task solving.\n\nWhile previous studies have designed many promising memory modules, there still lacks a systemic study to view the memory modules from a holistic perspective. To bridge this gap, in this paper, we comprehensively review previous studies to present clear taxonomies and key principles for designing and evaluating the memory module. In specific, we discuss three key problems including: (1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based agents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with, we detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions. Then, we analyze the necessity of memory in LLM-based agents, showing its importance from three perspectives including cognitive psychology, self-evolution, and agent applications. Based on the problems of \"what\" and \"why\", we present commonly used strategies to design and evaluate the memory modules. For the memory design, we discuss previous works from three dimensions, that is, memory sources, memory forms, and memory operations. For the memory evaluation, we introduce two widely used approaches including direct evaluation and indirect evaluation via specific agent tasks. Next, we discuss agent applications including ",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:18.792221"
      }
    },
    "wb-f91d1499": {
      "id": "wb-f91d1499",
      "type": "method",
      "title": "åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ¨¡å—åŒ–è™šæ‹Ÿæ•™å­¦åŠ©æ‰‹æ¡†æ¶",
      "description": "åˆ©ç”¨ChatGPTæ„å»ºæ— éœ€è®­ç»ƒçš„æ¨¡å—åŒ–è™šæ‹Ÿæ•™å­¦åŠ©æ‰‹ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ç»“åˆå¤šæ–‡æ¡£å¤„ç†èƒ½åŠ›ï¼Œè§£å†³æ•™è‚²é¢†åŸŸé—®ç­”ä¸­çš„å¹»è§‰å’Œå®‰å…¨é—®é¢˜",
      "source_paper_id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
      "zone": "methods",
      "created_at": "2025-12-16T10:40:22.242879",
      "data": {
        "analysis": {
          "method_name": "åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ¨¡å—åŒ–è™šæ‹Ÿæ•™å­¦åŠ©æ‰‹æ¡†æ¶",
          "method_type": "æ¡†æ¶",
          "core_idea": "åˆ©ç”¨ChatGPTæ„å»ºæ— éœ€è®­ç»ƒçš„æ¨¡å—åŒ–è™šæ‹Ÿæ•™å­¦åŠ©æ‰‹ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ç»“åˆå¤šæ–‡æ¡£å¤„ç†èƒ½åŠ›ï¼Œè§£å†³æ•™è‚²é¢†åŸŸé—®ç­”ä¸­çš„å¹»è§‰å’Œå®‰å…¨é—®é¢˜",
          "innovation_points": [
            "é›¶è®­ç»ƒéƒ¨ç½²ï¼šç›´æ¥åˆ©ç”¨é¢„è®­ç»ƒChatGPTï¼Œæ— éœ€é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒ",
            "å¤šæ–‡æ¡£æ™ºèƒ½å¤„ç†ï¼šèƒ½å¤Ÿå¤„ç†å¤§å‹æ•™æå’Œè¯¾ç¨‹èµ„æ–™ï¼Œæ”¯æŒæ™ºèƒ½æ•™ç§‘ä¹¦åº”ç”¨",
            "ç»¼åˆå®‰å…¨æœºåˆ¶ï¼šé›†æˆæ–‡æœ¬è•´å«éªŒè¯ã€æ¯’æ€§è¿‡æ»¤å’Œç¤¼è²Œæç¤ºç­‰å¤šé‡å®‰å…¨æªæ–½"
          ],
          "implementation_steps": [
            "æ–‡æ¡£é¢„å¤„ç†ï¼šä½¿ç”¨å¯†é›†æ®µè½æ£€ç´¢(DPR)å¯¹å¤§å‹æ–‡æ¡£è¿›è¡Œç´¢å¼•å’Œåˆ†å—",
            "æŸ¥è¯¢å¤„ç†ï¼šé€šè¿‡é—®é¢˜ç›¸å…³æ€§åˆ†ç±»å™¨ç­›é€‰æœ‰æ•ˆé—®é¢˜ï¼Œæ£€ç´¢ç›¸å…³æ–‡æ¡£æ®µè½",
            "å“åº”ç”Ÿæˆï¼šåŸºäºæ£€ç´¢åˆ°çš„æ®µè½ï¼Œåˆ©ç”¨ChatGPTç”Ÿæˆå¸¦å¼•ç”¨çš„å›ç­”",
            "å®‰å…¨éªŒè¯ï¼šåº”ç”¨æ–‡æœ¬è•´å«éªŒè¯äº‹å®ä¸€è‡´æ€§ï¼Œæ¯’æ€§è¿‡æ»¤å™¨ç¡®ä¿å†…å®¹å®‰å…¨"
          ],
          "key_formulas": [
            "DPRæ£€ç´¢å…¬å¼ï¼šscore(q,p) = E_Q(q)^T E_P(p)ï¼Œå…¶ä¸­E_Qå’ŒE_Pä¸ºæŸ¥è¯¢å’Œæ®µè½çš„ç¼–ç å™¨"
          ],
          "reviewer_comments": {
            "strengths": [
              "æ–¹æ³•å…·æœ‰é«˜åº¦å¯å¤ç°æ€§ï¼Œå®Œå…¨åŸºäºå…¬å¼€èµ„æºæ„å»º",
              "æ¨¡å—åŒ–è®¾è®¡ä¾¿äºæ‰©å±•æ–°åŠŸèƒ½API",
              "ç»¼åˆè§£å†³äº†LLMåœ¨æ•™è‚²åº”ç”¨ä¸­çš„å…³é”®æŒ‘æˆ˜ï¼ˆå¹»è§‰ã€å®‰å…¨ï¼‰"
            ],
            "weaknesses": [
              "ä¾èµ–ChatGPT APIå¯èƒ½å¸¦æ¥æˆæœ¬å’Œå¯ç”¨æ€§é—®é¢˜",
              "æ–‡æœ¬è•´å«éªŒè¯çš„æ•ˆæœæœªåœ¨æ–‡ä¸­å……åˆ†é‡åŒ–è¯„ä¼°",
              "å¯¹è¶…é•¿æ–‡æ¡£çš„å¤„ç†æ•ˆç‡å¯èƒ½æˆä¸ºç“¶é¢ˆ"
            ],
            "questions": [
              "DPRæ£€ç´¢çš„å‡†ç¡®ç‡åœ¨ä¸åŒç±»å‹æ•™æä¸Šçš„è¡¨ç°å¦‚ä½•ï¼Ÿ",
              "å®‰å…¨è¿‡æ»¤æœºåˆ¶æ˜¯å¦ä¼šå¯¼è‡´è¿‡åº¦ä¿å®ˆï¼Œå½±å“å›ç­”çš„å®Œæ•´æ€§ï¼Ÿ",
              "ä¸ä¼ ç»ŸåŸºäºçŸ¥è¯†åº“çš„æ–¹æ³•ç›¸æ¯”ï¼Œå“åº”å»¶è¿Ÿæ˜¯å¦å¯æ¥å—ï¼Ÿ"
            ],
            "suggestions": [
              "å¢åŠ å¯¹ä¸åŒè§„æ¨¡æ–‡æ¡£å¤„ç†èƒ½åŠ›çš„ç³»ç»Ÿè¯„ä¼°",
              "æä¾›é”™è¯¯æ¡ˆä¾‹åˆ†æï¼Œæ˜ç¡®å„æ¨¡å—çš„å¤±è´¥æ¨¡å¼",
              "è€ƒè™‘åŠ å…¥ç”¨æˆ·åé¦ˆæœºåˆ¶ä»¥æŒç»­ä¼˜åŒ–ç³»ç»Ÿè¡¨ç°"
            ]
          },
          "reproducibility_score": 8,
          "pseudocode": "# Jill Watsonæ ¸å¿ƒæµç¨‹ä¼ªä»£ç \n1. åˆå§‹åŒ–æ–‡æ¡£ç´¢å¼•ç³»ç»Ÿ\n   - åŠ è½½è¯¾ç¨‹æ–‡æ¡£(Slides, Notes, Syllabus)\n   - ä½¿ç”¨DPRæ„å»ºæ®µè½ç´¢å¼•\n\n2. ä¸»å¾ªç¯å¤„ç†ç”¨æˆ·æŸ¥è¯¢\n   - While æœ‰æ–°æŸ¥è¯¢:\n   -   é€šè¿‡ç›¸å…³æ€§åˆ†ç±»å™¨éªŒè¯é—®é¢˜æœ‰æ•ˆæ€§\n   -   ä½¿ç”¨DPRæ£€ç´¢æœ€ç›¸å…³æ–‡æ¡£æ®µè½\n   -   æ„å»ºåŒ…å«æ£€ç´¢æ®µè½å’Œç¤¼è²Œæç¤ºçš„ChatGPTè¾“å…¥\n   -   ç”Ÿæˆå¸¦æ–‡æ¡£å¼•ç”¨çš„å›ç­”\n   -   åº”ç”¨æ–‡æœ¬è•´å«éªŒè¯äº‹å®ä¸€è‡´æ€§\n   -   é€šè¿‡æ¯’æ€§è¿‡æ»¤å™¨æ£€æŸ¥å†…å®¹å®‰å…¨\n   -   è¿”å›éªŒè¯é€šè¿‡çš„å›ç­”\n\n3. è¾“å‡ºå¸¦å¼•ç”¨çš„å®‰å…¨å›ç­”"
        },
        "original_text": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid h",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:22.242849"
      }
    },
    "wb-9db9d05b": {
      "id": "wb-9db9d05b",
      "type": "code",
      "title": "ChatGPT",
      "description": "OpenAIå¼€å‘çš„å¯¹è¯AIå·¥å…·ï¼ŒåŸºäºGPT-3.5å’ŒGPT-4æ¶æ„",
      "source_paper_id": "9866dfe0-a3d7-41a1-99e5-c2ed00636259",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:31.670193",
      "data": {
        "asset": {
          "name": "ChatGPT",
          "type": "api",
          "url": "https://openai.com/chatgpt",
          "platform": "OpenAI",
          "description": "OpenAIå¼€å‘çš„å¯¹è¯AIå·¥å…·ï¼ŒåŸºäºGPT-3.5å’ŒGPT-4æ¶æ„",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºå¯¹æ¯”åˆ†æçš„ä¸»è¦ç ”ç©¶å¯¹è±¡ä¹‹ä¸€",
          "verified": true,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectio",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:31.670098"
      }
    },
    "wb-7ed54033": {
      "id": "wb-7ed54033",
      "type": "code",
      "title": "DeepSeek AI",
      "description": "ç”±Liang Wenfengæå‡ºçš„æ–°å‹NLPæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ChatGPTçš„å±€é™æ€§",
      "source_paper_id": "9866dfe0-a3d7-41a1-99e5-c2ed00636259",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:31.673958",
      "data": {
        "asset": {
          "name": "DeepSeek AI",
          "type": "model",
          "url": "https://github.com/deepseek-ai",
          "platform": "GitHub",
          "description": "ç”±Liang Wenfengæå‡ºçš„æ–°å‹NLPæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ChatGPTçš„å±€é™æ€§",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºå¯¹æ¯”åˆ†æçš„ä¸»è¦ç ”ç©¶å¯¹è±¡ä¹‹ä¸€",
          "verified": false,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectio",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:31.673376"
      }
    },
    "wb-a91a407b": {
      "id": "wb-a91a407b",
      "type": "code",
      "title": "GPTç³»åˆ—æ¨¡å‹",
      "description": "GPTã€GPT-3.5ã€GPT-4ç­‰transformer-basedè¯­è¨€æ¨¡å‹",
      "source_paper_id": "9866dfe0-a3d7-41a1-99e5-c2ed00636259",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:31.676871",
      "data": {
        "asset": {
          "name": "GPTç³»åˆ—æ¨¡å‹",
          "type": "model",
          "url": "https://openai.com/gpt",
          "platform": "OpenAI",
          "description": "GPTã€GPT-3.5ã€GPT-4ç­‰transformer-basedè¯­è¨€æ¨¡å‹",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºChatGPTçš„åŸºç¡€æ¶æ„è¢«è®¨è®º",
          "verified": true,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectio",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:31.676819"
      }
    },
    "wb-5fced375": {
      "id": "wb-5fced375",
      "type": "code",
      "title": "ChatGPT",
      "description": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå¯¹è¯ç”Ÿæˆå’Œé—®ç­”",
      "source_paper_id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:45.714173",
      "data": {
        "asset": {
          "name": "ChatGPT",
          "type": "api",
          "url": "https://openai.com/chatgpt",
          "platform": "OpenAI",
          "description": "å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”¨äºå¯¹è¯ç”Ÿæˆå’Œé—®ç­”",
          "license": "å•†ä¸šAPI",
          "usage_in_paper": "ä½œä¸ºJill Watsonç³»ç»Ÿçš„æ ¸å¿ƒå¯¹è¯å¼•æ“",
          "verified": true,
          "stars": null
        },
        "original_text": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid h",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:45.714139"
      }
    },
    "wb-90a3fb13": {
      "id": "wb-90a3fb13",
      "type": "code",
      "title": "GPT-3.5",
      "description": "GPT-3çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œæ”¯æŒæŒ‡ä»¤è·Ÿéšå’Œå¯¹è¯",
      "source_paper_id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:45.715296",
      "data": {
        "asset": {
          "name": "GPT-3.5",
          "type": "model",
          "url": "https://openai.com/gpt-3.5",
          "platform": "OpenAI",
          "description": "GPT-3çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œæ”¯æŒæŒ‡ä»¤è·Ÿéšå’Œå¯¹è¯",
          "license": "å•†ä¸šAPI",
          "usage_in_paper": "ä½œä¸ºChatGPTçš„åŸºç¡€æ¨¡å‹",
          "verified": true,
          "stars": null
        },
        "original_text": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid h",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:45.715284"
      }
    },
    "wb-19a61a30": {
      "id": "wb-19a61a30",
      "type": "code",
      "title": "Dense Passage Retrieval (DPR)",
      "description": "å¯†é›†æ®µè½æ£€ç´¢æ¨¡å‹ï¼Œç”¨äºæ–‡æ¡£æ£€ç´¢",
      "source_paper_id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:45.716172",
      "data": {
        "asset": {
          "name": "Dense Passage Retrieval (DPR)",
          "type": "model",
          "url": "https://github.com/facebookresearch/DPR",
          "platform": "GitHub",
          "description": "å¯†é›†æ®µè½æ£€ç´¢æ¨¡å‹ï¼Œç”¨äºæ–‡æ¡£æ£€ç´¢",
          "license": "MIT",
          "usage_in_paper": "ç”¨äºä»å¤§å‹æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³æ®µè½",
          "verified": true,
          "stars": null
        },
        "original_text": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid h",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:45.716164"
      }
    },
    "wb-4530a7e0": {
      "id": "wb-4530a7e0",
      "type": "code",
      "title": "HuggingGPT",
      "description": "åŸºäºChatGPTçš„å¤šæ¨¡å‹åä½œç³»ç»Ÿ",
      "source_paper_id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:45.717356",
      "data": {
        "asset": {
          "name": "HuggingGPT",
          "type": "tool",
          "url": "https://github.com/microsoft/JARVIS",
          "platform": "GitHub",
          "description": "åŸºäºChatGPTçš„å¤šæ¨¡å‹åä½œç³»ç»Ÿ",
          "license": "MIT",
          "usage_in_paper": "ä½œä¸ºç›¸å…³å·¥ä½œçš„å¯¹æ¯”ç³»ç»Ÿ",
          "verified": true,
          "stars": null
        },
        "original_text": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid h",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:45.717329"
      }
    },
    "wb-ec355c0b": {
      "id": "wb-ec355c0b",
      "type": "code",
      "title": "LangChain",
      "description": "ç”¨äºæ„å»ºLLMåº”ç”¨çš„å¼€å‘æ¡†æ¶",
      "source_paper_id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
      "zone": "datasets",
      "created_at": "2025-12-16T10:40:45.718389",
      "data": {
        "asset": {
          "name": "LangChain",
          "type": "tool",
          "url": "https://github.com/langchain-ai/langchain",
          "platform": "GitHub",
          "description": "ç”¨äºæ„å»ºLLMåº”ç”¨çš„å¼€å‘æ¡†æ¶",
          "license": "MIT",
          "usage_in_paper": "ä½œä¸ºç›¸å…³å·¥ä½œçš„å¯¹æ¯”ç³»ç»Ÿ",
          "verified": true,
          "stars": null
        },
        "original_text": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid h",
        "location": "",
        "analyzed_at": "2025-12-16T10:40:45.718377"
      }
    },
    "wb-3bb1a1fe": {
      "id": "wb-3bb1a1fe",
      "type": "method",
      "title": "åŸºäºå¤šé¢†åŸŸé€‰æ‹©é¢˜çš„å¯¹æ¯”è¯„ä¼°æ–¹æ³•",
      "description": "é€šè¿‡é¢„å…ˆå®šä¹‰çš„å¤šé¢†åŸŸé€‰æ‹©é¢˜é›†ï¼Œç³»ç»Ÿæ¯”è¾ƒChatGPTå’ŒDeepSeek AIåœ¨æŠ€æœ¯å·®å¼‚ã€å®é™…åº”ç”¨å’Œæ€§èƒ½è¡¨ç°æ–¹é¢çš„èƒ½åŠ›",
      "source_paper_id": "eda55281-9bde-4cff-a438-6a89ea992f96",
      "zone": "methods",
      "created_at": "2025-12-16T10:57:37.035176",
      "data": {
        "analysis": {
          "method_name": "åŸºäºå¤šé¢†åŸŸé€‰æ‹©é¢˜çš„å¯¹æ¯”è¯„ä¼°æ–¹æ³•",
          "method_type": "è¯„ä¼°æ–¹æ³•",
          "core_idea": "é€šè¿‡é¢„å…ˆå®šä¹‰çš„å¤šé¢†åŸŸé€‰æ‹©é¢˜é›†ï¼Œç³»ç»Ÿæ¯”è¾ƒChatGPTå’ŒDeepSeek AIåœ¨æŠ€æœ¯å·®å¼‚ã€å®é™…åº”ç”¨å’Œæ€§èƒ½è¡¨ç°æ–¹é¢çš„èƒ½åŠ›",
          "innovation_points": [
            "é‡‡ç”¨æ ‡å‡†åŒ–é—®é¢˜é›†è¿›è¡Œæ¨ªå‘å¯¹æ¯”è¯„ä¼°",
            "å¤šé¢†åŸŸè¦†ç›–çš„ç»¼åˆè¯„ä¼°æ¡†æ¶"
          ],
          "implementation_steps": [
            "è®¾è®¡é¢„å®šä¹‰çš„å¤šé¢†åŸŸé€‰æ‹©é¢˜é›†",
            "åœ¨ä¸¤ä¸ªæ¨¡å‹ä¸Šåˆ†åˆ«æ‰§è¡Œæµ‹è¯•",
            "åˆ†æå„æ¨¡å‹çš„ä¼˜åŠ¿å’Œå±€é™æ€§"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "æ–¹æ³•ç®€å•æ˜“è¡Œï¼Œå…·æœ‰å¯é‡å¤æ€§",
              "å¤šé¢†åŸŸè¦†ç›–ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§"
            ],
            "weaknesses": [
              "ç¼ºä¹è¯¦ç»†çš„è¯„ä¼°æŒ‡æ ‡å’Œè¯„åˆ†æ ‡å‡†",
              "é—®é¢˜é›†çš„è®¾è®¡åŸåˆ™å’Œä»£è¡¨æ€§æœªæ˜ç¡®è¯´æ˜",
              "æ ·æœ¬é‡å¤§å°å’Œç»Ÿè®¡æ˜¾è‘—æ€§æœªæåŠ"
            ],
            "questions": [
              "é€‰æ‹©é¢˜é›†çš„å…·ä½“é¢†åŸŸåˆ†å¸ƒå’Œæ•°é‡æ˜¯å¤šå°‘ï¼Ÿ",
              "è¯„ä¼°ç»“æœçš„é‡åŒ–æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
              "å¦‚ä½•ç¡®ä¿é—®é¢˜é›†çš„å®¢è§‚æ€§å’Œæ— åæ€§ï¼Ÿ"
            ],
            "suggestions": [
              "æ˜ç¡®è¯„ä¼°æŒ‡æ ‡å’Œè¯„åˆ†ä½“ç³»",
              "æä¾›é—®é¢˜é›†çš„è¯¦ç»†æè¿°å’Œé€‰æ‹©ä¾æ®",
              "å¢åŠ ç»Ÿè®¡åˆ†ææ–¹æ³•æ¥éªŒè¯ç»“æœæ˜¾è‘—æ€§"
            ]
          },
          "reproducibility_score": 6,
          "pseudocode": "# æ¨¡å‹å¯¹æ¯”è¯„ä¼°æµç¨‹\n1. åˆå§‹åŒ–ï¼šå‡†å¤‡å¤šé¢†åŸŸé€‰æ‹©é¢˜æ•°æ®é›†\n2. ä¸»å¾ªç¯ï¼šåˆ†åˆ«åœ¨ChatGPTå’ŒDeepSeek AIä¸Šè¿è¡Œæµ‹è¯•\n3. è¾“å‡ºï¼šç”Ÿæˆæ€§èƒ½å¯¹æ¯”åˆ†ææŠ¥å‘Š"
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) ",
        "location": "",
        "analyzed_at": "2025-12-16T10:57:37.035118"
      }
    },
    "wb-8347bbc4": {
      "id": "wb-8347bbc4",
      "type": "code",
      "title": "DeepSeek-R1-Zero",
      "description": "å®Œå…¨å¼€æºçš„LLMæ¨¡å‹ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç›´æ¥åº”ç”¨äºåŸºç¡€æ¨¡å‹ï¼Œç»•è¿‡ä¼ ç»Ÿç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œå…·æœ‰è‡ªæˆ‘éªŒè¯ã€åæ€å’Œé•¿å¯¹è¯èƒ½åŠ›",
      "source_paper_id": "eda55281-9bde-4cff-a438-6a89ea992f96",
      "zone": "datasets",
      "created_at": "2025-12-16T10:58:04.024092",
      "data": {
        "asset": {
          "name": "DeepSeek-R1-Zero",
          "type": "model",
          "url": "æœªçŸ¥ï¼ˆè®ºæ–‡æåŠä½†æœªæä¾›å…·ä½“é“¾æ¥ï¼‰",
          "platform": "DeepSeek AI",
          "description": "å®Œå…¨å¼€æºçš„LLMæ¨¡å‹ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç›´æ¥åº”ç”¨äºåŸºç¡€æ¨¡å‹ï¼Œç»•è¿‡ä¼ ç»Ÿç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œå…·æœ‰è‡ªæˆ‘éªŒè¯ã€åæ€å’Œé•¿å¯¹è¯èƒ½åŠ›",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºChatGPTçš„å¯¹æ¯”æ¨¡å‹è¿›è¡Œæ€§èƒ½è¯„ä¼°",
          "verified": false,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/eda55281-9bde-4cff-a438-6a89ea992f96/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T10:58:04.024037"
      }
    },
    "wb-9179bd57": {
      "id": "wb-9179bd57",
      "type": "code",
      "title": "GPTç³»åˆ—æ¨¡å‹ï¼ˆGPT-1åˆ°GPT-4ï¼‰",
      "description": "ä»GPT-1ï¼ˆ1.17äº¿å‚æ•°ï¼‰åˆ°GPT-4ï¼ˆä¼°è®¡1T+å‚æ•°ï¼‰çš„ç”Ÿæˆå¼é¢„è®­ç»ƒå˜æ¢å™¨æ¨¡å‹ç³»åˆ—",
      "source_paper_id": "eda55281-9bde-4cff-a438-6a89ea992f96",
      "zone": "datasets",
      "created_at": "2025-12-16T10:58:04.027084",
      "data": {
        "asset": {
          "name": "GPTç³»åˆ—æ¨¡å‹ï¼ˆGPT-1åˆ°GPT-4ï¼‰",
          "type": "model",
          "url": "https://openai.com/api/",
          "platform": "OpenAI",
          "description": "ä»GPT-1ï¼ˆ1.17äº¿å‚æ•°ï¼‰åˆ°GPT-4ï¼ˆä¼°è®¡1T+å‚æ•°ï¼‰çš„ç”Ÿæˆå¼é¢„è®­ç»ƒå˜æ¢å™¨æ¨¡å‹ç³»åˆ—",
          "license": "å•†ä¸šAPI",
          "usage_in_paper": "ä½œä¸ºåŸºå‡†æ¨¡å‹ä¸DeepSeek AIè¿›è¡Œå¯¹æ¯”åˆ†æ",
          "verified": true,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/eda55281-9bde-4cff-a438-6a89ea992f96/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T10:58:04.027023"
      }
    },
    "wb-14c615a4": {
      "id": "wb-14c615a4",
      "type": "code",
      "title": "ChatGPT",
      "description": "åŸºäºGPT-3.5å’ŒGPT-4æ¶æ„çš„å¯¹è¯AIç³»ç»Ÿï¼Œæ”¯æŒå¤šç§åº”ç”¨åœºæ™¯",
      "source_paper_id": "eda55281-9bde-4cff-a438-6a89ea992f96",
      "zone": "datasets",
      "created_at": "2025-12-16T10:58:04.037687",
      "data": {
        "asset": {
          "name": "ChatGPT",
          "type": "api",
          "url": "https://chat.openai.com/",
          "platform": "OpenAI",
          "description": "åŸºäºGPT-3.5å’ŒGPT-4æ¶æ„çš„å¯¹è¯AIç³»ç»Ÿï¼Œæ”¯æŒå¤šç§åº”ç”¨åœºæ™¯",
          "license": "å•†ä¸šæœåŠ¡",
          "usage_in_paper": "ä¸»è¦å¯¹æ¯”å¯¹è±¡ï¼Œåœ¨å¤šé¢†åŸŸé€‰æ‹©é¢˜æµ‹è¯•ä¸­ä½œä¸ºåŸºå‡†",
          "verified": true,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/eda55281-9bde-4cff-a438-6a89ea992f96/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T10:58:04.037650"
      }
    },
    "wb-88124e5e": {
      "id": "wb-88124e5e",
      "type": "method",
      "title": "ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°",
      "description": "å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨è¿›è¡Œå…¨é¢ç³»ç»Ÿçš„æ¢³ç†å’Œåˆ†æï¼Œæ€»ç»“å½“å‰æŠ€æœ¯ç°çŠ¶ã€æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "methods",
      "created_at": "2025-12-16T11:02:33.999713",
      "data": {
        "analysis": {
          "method_name": "ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°",
          "method_type": "æµç¨‹",
          "core_idea": "å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨è¿›è¡Œå…¨é¢ç³»ç»Ÿçš„æ¢³ç†å’Œåˆ†æï¼Œæ€»ç»“å½“å‰æŠ€æœ¯ç°çŠ¶ã€æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘",
          "innovation_points": [
            "å°†LLMsä¸æ•™è‚²é¢†åŸŸæ·±åº¦ç»“åˆçš„ç³»ç»Ÿæ€§åˆ†ææ¡†æ¶",
            "å¤šç»´åº¦æ•´åˆæŠ€æœ¯ç‰¹ç‚¹ä¸æ•™è‚²åº”ç”¨åœºæ™¯"
          ],
          "implementation_steps": [
            "æ€»ç»“LLMEduç°çŠ¶",
            "åˆ†æLLMsä¸æ•™è‚²ç‰¹ç‚¹",
            "è¯„ä¼°æ•´åˆæ•ˆç›Š",
            "å›é¡¾æŠ€æœ¯æ•´åˆè¿‡ç¨‹",
            "è¯†åˆ«æŒ‘æˆ˜ä¸æœªæ¥å±•æœ›"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "ç ”ç©¶ä¸»é¢˜å…·æœ‰é‡è¦ç°å®æ„ä¹‰",
              "ç³»ç»Ÿæ€§æ¡†æ¶æœ‰åŠ©äºå…¨é¢ç†è§£é¢†åŸŸå‘å±•"
            ],
            "weaknesses": [
              "ç¼ºä¹å…·ä½“å®è¯æ•°æ®æ”¯æŒ",
              "æ–¹æ³•è®ºæè¿°ä¸å¤Ÿè¯¦ç»†"
            ],
            "questions": [
              "æ–‡çŒ®ç­›é€‰æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
              "å¦‚ä½•ç¡®ä¿ç»¼è¿°çš„å…¨é¢æ€§å’Œä»£è¡¨æ€§ï¼Ÿ",
              "åˆ†ææ¡†æ¶çš„ç†è®ºåŸºç¡€æ˜¯ä»€ä¹ˆï¼Ÿ"
            ],
            "suggestions": [
              "æ˜ç¡®æ–‡çŒ®æ£€ç´¢å’Œç­›é€‰æµç¨‹",
              "å¢åŠ å…·ä½“æ¡ˆä¾‹åˆ†æ",
              "æä¾›æ›´è¯¦ç»†çš„åˆ†ææ¡†æ¶"
            ]
          },
          "reproducibility_score": 6,
          "pseudocode": "# ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°æµç¨‹\n1. ç¡®å®šç ”ç©¶èŒƒå›´å’Œç›®æ ‡\n2. æ–‡çŒ®æ£€ç´¢ä¸ç­›é€‰\n3. å†…å®¹åˆ†æä¸åˆ†ç±»\n4. æŒ‘æˆ˜è¯†åˆ«ä¸è¶‹åŠ¿åˆ†æ\n5. ç»“è®ºä¸å±•æœ›"
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, ed",
        "location": "",
        "analyzed_at": "2025-12-16T11:02:33.999628"
      }
    },
    "wb-432fae61": {
      "id": "wb-432fae61",
      "type": "code",
      "title": "MathGPT",
      "description": "ä¸“æ³¨äºæ•°å­¦é¢†åŸŸçš„è¯­è¨€æ¨¡å‹ï¼Œåœ¨AGIEvalåŸºå‡†æµ‹è¯•ä¸­å‡†ç¡®ç‡è¾¾åˆ°60.34%",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.417095",
      "data": {
        "asset": {
          "name": "MathGPT",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "TAL",
          "description": "ä¸“æ³¨äºæ•°å­¦é¢†åŸŸçš„è¯­è¨€æ¨¡å‹ï¼Œåœ¨AGIEvalåŸºå‡†æµ‹è¯•ä¸­å‡†ç¡®ç‡è¾¾åˆ°60.34%",
          "license": "æœªçŸ¥",
          "usage_in_paper": "æ•°å­¦é—®é¢˜æ±‚è§£å’Œè¾…å¯¼",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.417028"
      }
    },
    "wb-be400a1e": {
      "id": "wb-be400a1e",
      "type": "code",
      "title": "ERNIE Bot",
      "description": "ç™¾åº¦å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨ç™¾åº¦ç™¾ç§‘ä½œä¸ºè®­ç»ƒææ–™",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.422313",
      "data": {
        "asset": {
          "name": "ERNIE Bot",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "Baidu",
          "description": "ç™¾åº¦å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨ç™¾åº¦ç™¾ç§‘ä½œä¸ºè®­ç»ƒææ–™",
          "license": "æœªçŸ¥",
          "usage_in_paper": "çŸ¥è¯†é—®ç­”å’Œæ•™è‚²å†…å®¹ç”Ÿæˆ",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.422279"
      }
    },
    "wb-edcd83a3": {
      "id": "wb-edcd83a3",
      "type": "code",
      "title": "Tongyi Qianwen",
      "description": "é˜¿é‡Œå·´å·´é›†å›¢å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.427426",
      "data": {
        "asset": {
          "name": "Tongyi Qianwen",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "Alibaba",
          "description": "é˜¿é‡Œå·´å·´é›†å›¢å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹",
          "license": "æœªçŸ¥",
          "usage_in_paper": "æ•™è‚²é¢†åŸŸçš„åº”ç”¨æ¢ç´¢",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.427394"
      }
    },
    "wb-131382ad": {
      "id": "wb-131382ad",
      "type": "code",
      "title": "ChatGLM",
      "description": "æ¸…åå¤§å­¦å¼€å‘çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.432676",
      "data": {
        "asset": {
          "name": "ChatGLM",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "Tsinghua University",
          "description": "æ¸…åå¤§å­¦å¼€å‘çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹",
          "license": "æœªçŸ¥",
          "usage_in_paper": "æ•™è‚²ç ”ç©¶å’Œåº”ç”¨",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.432615"
      }
    },
    "wb-cd300c3f": {
      "id": "wb-cd300c3f",
      "type": "code",
      "title": "Baichuan",
      "description": "å¼€æºå¤§è¯­è¨€æ¨¡å‹",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.438529",
      "data": {
        "asset": {
          "name": "Baichuan",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "æœªçŸ¥",
          "description": "å¼€æºå¤§è¯­è¨€æ¨¡å‹",
          "license": "æœªçŸ¥",
          "usage_in_paper": "æ•™è‚²é¢†åŸŸçš„é€šç”¨åŒ–åº”ç”¨",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.438492"
      }
    },
    "wb-bece9d46": {
      "id": "wb-bece9d46",
      "type": "code",
      "title": "InternLM",
      "description": "å¼€æºå¤§è¯­è¨€æ¨¡å‹",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.444781",
      "data": {
        "asset": {
          "name": "InternLM",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "æœªçŸ¥",
          "description": "å¼€æºå¤§è¯­è¨€æ¨¡å‹",
          "license": "æœªçŸ¥",
          "usage_in_paper": "æ•™è‚²é¢†åŸŸçš„é€šç”¨åŒ–åº”ç”¨",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.444744"
      }
    },
    "wb-49359d09": {
      "id": "wb-49359d09",
      "type": "code",
      "title": "Qwen-7B/Qwen-14B",
      "description": "å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒQwen-14Bå‡†ç¡®ç‡è¶…è¿‡70%",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.451138",
      "data": {
        "asset": {
          "name": "Qwen-7B/Qwen-14B",
          "type": "model",
          "url": "æœªçŸ¥",
          "platform": "æœªçŸ¥",
          "description": "å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒQwen-14Bå‡†ç¡®ç‡è¶…è¿‡70%",
          "license": "æœªçŸ¥",
          "usage_in_paper": "æ•™è‚²é¢†åŸŸçš„é€šç”¨åŒ–åº”ç”¨",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.451110"
      }
    },
    "wb-24cfa1c9": {
      "id": "wb-24cfa1c9",
      "type": "code",
      "title": "Khanmigo",
      "description": "åŸºäºLLMçš„æ•™è‚²å·¥å…·ï¼Œé€šè¿‡æé—®å¼•å¯¼å­¦ç”Ÿè‡ªä¸»å¯»æ‰¾ç­”æ¡ˆ",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.458176",
      "data": {
        "asset": {
          "name": "Khanmigo",
          "type": "tool",
          "url": "æœªçŸ¥",
          "platform": "Khan Academy",
          "description": "åŸºäºLLMçš„æ•™è‚²å·¥å…·ï¼Œé€šè¿‡æé—®å¼•å¯¼å­¦ç”Ÿè‡ªä¸»å¯»æ‰¾ç­”æ¡ˆ",
          "license": "æœªçŸ¥",
          "usage_in_paper": "å¼•å¯¼å¼å­¦ä¹ åº”ç”¨",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.458142"
      }
    },
    "wb-2186a821": {
      "id": "wb-2186a821",
      "type": "code",
      "title": "MagicSchool",
      "description": "åŸºäºOpenAI LLMæŠ€æœ¯çš„å•†ä¸šè¾…åŠ©å·¥å…·",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.465717",
      "data": {
        "asset": {
          "name": "MagicSchool",
          "type": "tool",
          "url": "æœªçŸ¥",
          "platform": "æœªçŸ¥",
          "description": "åŸºäºOpenAI LLMæŠ€æœ¯çš„å•†ä¸šè¾…åŠ©å·¥å…·",
          "license": "æœªçŸ¥",
          "usage_in_paper": "å­¦ç”Ÿä½œä¸šè¯„ä¼°å’Œåé¦ˆ",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.465683"
      }
    },
    "wb-fccfea7e": {
      "id": "wb-fccfea7e",
      "type": "code",
      "title": "Eduaide",
      "description": "åŸºäºOpenAI LLMæŠ€æœ¯çš„æ•™è‚²è¾…åŠ©å·¥å…·",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "datasets",
      "created_at": "2025-12-16T11:03:28.474667",
      "data": {
        "asset": {
          "name": "Eduaide",
          "type": "tool",
          "url": "æœªçŸ¥",
          "platform": "æœªçŸ¥",
          "description": "åŸºäºOpenAI LLMæŠ€æœ¯çš„æ•™è‚²è¾…åŠ©å·¥å…·",
          "license": "æœªçŸ¥",
          "usage_in_paper": "å­¦ç”Ÿä½œä¸šè¯„ä¼°å’Œåé¦ˆ",
          "verified": false,
          "stars": null
        },
        "original_text": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642â€“652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123â€“159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855â€“5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., SuwaÅ‚a, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69â€“80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1â€“35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190â€“200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Ã…., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1â€“24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776â€“5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., GaÅ¡eviÄ‡, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279â€“297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512â€“527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831â€“833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
        "location": "",
        "analyzed_at": "2025-12-16T11:03:28.474630"
      }
    },
    "wb-a6d535f5": {
      "id": "wb-a6d535f5",
      "type": "method",
      "title": "ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°",
      "description": "é€šè¿‡ç³»ç»Ÿæ€§åœ°æ”¶é›†ã€æ€»ç»“å’Œåˆ†æç°æœ‰å…³äºå¤§è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸï¼ˆLLMEduï¼‰åº”ç”¨çš„ç ”ç©¶æ–‡çŒ®ï¼Œå…¨é¢æ¢³ç†è¯¥é¢†åŸŸçš„ç°çŠ¶ã€æŠ€æœ¯ã€æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘ã€‚",
      "source_paper_id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
      "zone": "methods",
      "created_at": "2025-12-16T12:52:08.026353",
      "data": {
        "analysis": {
          "method_name": "ç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°",
          "method_type": "æµç¨‹",
          "core_idea": "é€šè¿‡ç³»ç»Ÿæ€§åœ°æ”¶é›†ã€æ€»ç»“å’Œåˆ†æç°æœ‰å…³äºå¤§è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸï¼ˆLLMEduï¼‰åº”ç”¨çš„ç ”ç©¶æ–‡çŒ®ï¼Œå…¨é¢æ¢³ç†è¯¥é¢†åŸŸçš„ç°çŠ¶ã€æŠ€æœ¯ã€æŒ‘æˆ˜å’Œæœªæ¥å‘å±•æ–¹å‘ã€‚",
          "innovation_points": [
            "å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸æ•™è‚²ï¼ˆEduï¼‰çš„ç»“åˆä½œä¸ºä¸€ä¸ªæ˜ç¡®çš„äº¤å‰ç ”ç©¶é¢†åŸŸï¼ˆLLMEduï¼‰è¿›è¡Œç³»ç»Ÿæ€§å®¡è§†ï¼Œè€Œéé›¶æ•£è®¨è®ºã€‚",
            "æ„å»ºäº†ä¸€ä¸ªä»ç°çŠ¶æ€»ç»“ã€æŠ€æœ¯ç‰¹æ€§åˆ†æã€æ•´åˆè¿‡ç¨‹å›é¡¾åˆ°æŒ‘æˆ˜ä¸å‰æ™¯è®¨è®ºçš„å®Œæ•´åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨ä¸ºè¯¥æ–°å…´é¢†åŸŸæä¾›ç»“æ„åŒ–æ¦‚è§ˆã€‚"
          ],
          "implementation_steps": [
            "ç¬¬ä¸€æ­¥ï¼šç•Œå®šç ”ç©¶èŒƒå›´ï¼Œæ˜ç¡®èšç„¦äºâ€œå¤§è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²ä¸­çš„åº”ç”¨ï¼ˆLLMEduï¼‰â€ã€‚",
            "ç¬¬äºŒæ­¥ï¼šç³»ç»Ÿæ”¶é›†ä¸æ¢³ç†è¯¥é¢†åŸŸçš„ç›¸å…³ç ”ç©¶æ–‡çŒ®ã€æŠ€æœ¯æŠ¥å‘Šå’Œåº”ç”¨æ¡ˆä¾‹ã€‚",
            "ç¬¬ä¸‰æ­¥ï¼šæŒ‰ç…§é¢„è®¾æ¡†æ¶ï¼ˆç°çŠ¶ã€æŠ€æœ¯ã€æ•´åˆè¿‡ç¨‹ã€æŒ‘æˆ˜ã€å‰æ™¯ï¼‰å¯¹èµ„æ–™è¿›è¡Œå½’çº³ã€æ€»ç»“ä¸åˆ†æã€‚",
            "ç¬¬å››æ­¥ï¼šç»¼åˆåˆ†æç»“æœï¼Œå½¢æˆå…³äºæŠ€æœ¯ç°çŠ¶ã€å®è·µæŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘çš„å…¨é¢è®ºè¿°ã€‚"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "æ–¹æ³•é€‰æ‹©æ°å½“ï¼šå¯¹äºâ€œè°ƒæŸ¥/ç»¼è¿°â€ç±»è®ºæ–‡ï¼Œç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°æ˜¯æ ‡å‡†ä¸”ä¸¥è°¨çš„ç ”ç©¶æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆè¾¾æˆå…¨é¢æ¦‚è¿°é¢†åŸŸç°çŠ¶çš„ç›®çš„ã€‚",
              "ç»“æ„æ¸…æ™°ï¼šè®ºæ–‡ç‰‡æ®µä¸­æ¦‚è¿°çš„åˆ†ææ¡†æ¶ï¼ˆä»ç°çŠ¶åˆ°å‰æ™¯ï¼‰é€»è¾‘è¿è´¯ï¼Œæœ‰åŠ©äºè¯»è€…ç³»ç»Ÿæ€§åœ°ç†è§£LLMEduè¿™ä¸€äº¤å‰é¢†åŸŸã€‚",
              "å…·æœ‰æ—¶æ•ˆæ€§ä¸å‰ç»æ€§ï¼šèšç„¦äºLLMsè¿™ä¸€å¿«é€Ÿå‘å±•çš„æŠ€æœ¯åœ¨æ•™è‚²ä¸­çš„åº”ç”¨ï¼Œé€‰é¢˜å‰æ²¿ï¼Œç»¼è¿°ç»“è®ºèƒ½ä¸ºåç»­ç ”ç©¶å’Œå®è·µæä¾›å‚è€ƒã€‚"
            ],
            "weaknesses": [
              "æ–¹æ³•æè¿°è¿‡äºç¬¼ç»Ÿï¼šç‰‡æ®µä¸­ä»…æåŠâ€œconduct a systematic reviewâ€ï¼Œä½†æœªè¯¦ç»†è¯´æ˜æ–‡çŒ®æ£€ç´¢ç­–ç•¥ï¼ˆå¦‚æ•°æ®åº“ã€å…³é”®è¯ã€æ—¶é—´èŒƒå›´ï¼‰ã€æ–‡çŒ®çº³å…¥ä¸æ’é™¤æ ‡å‡†ã€è´¨é‡è¯„ä¼°æ–¹æ³•ç­‰å…³é”®ç»†èŠ‚ï¼Œè¿™é™ä½äº†æ–¹æ³•çš„é€æ˜åº¦å’Œå¯é‡å¤æ€§ã€‚",
              "æ½œåœ¨çš„é€‰æ‹©åå€šé£é™©ï¼šç”±äºæœªè¯´æ˜æ–‡çŒ®ç­›é€‰æµç¨‹ï¼Œç»¼è¿°æ‰€æ¶µç›–çš„æ–‡çŒ®èŒƒå›´å¯èƒ½ä¸å…¨é¢æˆ–ä¸å…·ä»£è¡¨æ€§ï¼Œå½±å“ç»“è®ºçš„æ™®é€‚æ€§ã€‚",
              "ç¼ºä¹å¯¹æ–¹æ³•å±€é™æ€§çš„åæ€ï¼šæœªè®¨è®ºä½œä¸ºç»¼è¿°æ–¹æ³•å›ºæœ‰çš„å±€é™æ€§ï¼Œå¦‚ä¾èµ–äºäºŒæ‰‹èµ„æ–™ã€éš¾ä»¥è¿›è¡ŒåŸåˆ›æ€§å› æœæ¨æ–­ç­‰ã€‚"
            ],
            "questions": [
              "æ–‡çŒ®æ£€ç´¢çš„å…·ä½“ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿä½¿ç”¨äº†å“ªäº›å­¦æœ¯æ•°æ®åº“ï¼Ÿå…³é”®è¯ç»„åˆå¦‚ä½•è®¾å®šï¼Ÿæ£€ç´¢æ—¶é—´èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ",
              "æ–‡çŒ®çš„çº³å…¥ä¸æ’é™¤æ ‡å‡†æ˜¯å¦‚ä½•åˆ¶å®šçš„ï¼Ÿä¾‹å¦‚ï¼Œæ˜¯å¦åŒ…æ‹¬é¢„å°æœ¬ã€æŠ€æœ¯æŠ¥å‘Šæˆ–ç‰¹å®šè¯­è¨€çš„ç ”ç©¶ï¼Ÿ",
              "æ˜¯å¦å¯¹çº³å…¥æ–‡çŒ®çš„è´¨é‡æˆ–ç›¸å…³æ€§è¿›è¡Œäº†è¯„ä¼°æˆ–åˆ†çº§ï¼Ÿå¦‚ä½•ç¡®ä¿ç»¼è¿°è¦†ç›–äº†è¯¥é¢†åŸŸæœ€å…·ä»£è¡¨æ€§çš„å·¥ä½œï¼Ÿ",
              "åœ¨åˆ†æå’Œç»¼åˆä¸åŒæ–‡çŒ®è§‚ç‚¹æ—¶ï¼Œå¦‚ä½•å¤„ç†å¯èƒ½å­˜åœ¨çŸ›ç›¾æˆ–å†²çªçš„ç ”ç©¶å‘ç°ï¼Ÿ"
            ],
            "suggestions": [
              "åœ¨è®ºæ–‡çš„æ–¹æ³•è®ºéƒ¨åˆ†ï¼Œè¯¦ç»†è¡¥å……â€œç³»ç»Ÿæ€§ç»¼è¿°â€çš„æ‰§è¡Œæ­¥éª¤ï¼ŒåŒ…æ‹¬ï¼š1ï¼‰æ–‡çŒ®æ£€ç´¢ç­–ç•¥ï¼ˆæ•°æ®åº“ã€å…³é”®è¯ã€æ—¶é—´è·¨åº¦ï¼‰ï¼›2ï¼‰æ–‡çŒ®ç­›é€‰æµç¨‹ï¼ˆåˆç­›ã€å…¨æ–‡ç­›é€‰ï¼‰åŠæ ‡å‡†ï¼ˆçº³å…¥/æ’é™¤æ ‡å‡†ï¼‰ï¼›3ï¼‰æ•°æ®æå–ä¸ç»¼åˆçš„æ–¹æ³•ã€‚",
              "è€ƒè™‘ä½¿ç”¨å¦‚PRISMAï¼ˆç³»ç»Ÿç»¼è¿°å’ŒèŸèƒåˆ†æä¼˜å…ˆæŠ¥å‘Šæ¡ç›®ï¼‰çš„æµç¨‹å›¾æ¥å¯è§†åŒ–æ–‡çŒ®ç­›é€‰è¿‡ç¨‹ï¼Œä»¥å¢å¼ºæ–¹æ³•çš„ä¸¥è°¨æ€§å’Œé€æ˜åº¦ã€‚",
              "åœ¨è®¨è®ºéƒ¨åˆ†ï¼Œå¢åŠ å¯¹æœ¬æ¬¡ç»¼è¿°æ–¹æ³•å±€é™æ€§çš„è¯´æ˜ï¼Œä¾‹å¦‚å¯¹éè‹±è¯­æ–‡çŒ®ã€ç°è‰²æ–‡çŒ®ï¼ˆå¦‚è¡Œä¸šæŠ¥å‘Šï¼‰è¦†ç›–å¯èƒ½ä¸è¶³ç­‰ï¼Œå¹¶è¯´æ˜è¿™äº›å±€é™æ€§å¯¹ç»“è®ºå¯èƒ½äº§ç”Ÿçš„å½±å“ã€‚"
            ]
          },
          "reproducibility_score": 5,
          "pseudocode": "# ä¼ªä»£ç ï¼šç³»ç»Ÿæ€§æ–‡çŒ®ç»¼è¿°æµç¨‹ï¼ˆåŸºäºç‰‡æ®µæ¨æ–­çš„ç†æƒ³åŒ–æµç¨‹ï¼‰\n1. åˆå§‹åŒ–ï¼š\n   - å®šä¹‰ç ”ç©¶é—®é¢˜ï¼šç»¼è¿°LLMEduçš„ç°çŠ¶ã€æŠ€æœ¯ã€æŒ‘æˆ˜ä¸å‰æ™¯ã€‚\n   - ç¡®å®šåˆ†ææ¡†æ¶ï¼šç°çŠ¶æ€»ç»“ã€æŠ€æœ¯ä»‹ç»ã€æ•´åˆè¿‡ç¨‹ã€æŒ‘æˆ˜åˆ†æã€å‰æ™¯å±•æœ›ã€‚\n2. ä¸»å¾ªç¯ï¼ˆæ–‡çŒ®å¤„ç†ï¼‰ï¼š\n   - æ­¥éª¤Aï¼ˆæ£€ç´¢ï¼‰ï¼šåœ¨å­¦æœ¯æ•°æ®åº“ä¸­ä½¿ç”¨é¢„è®¾å…³é”®è¯ç»„åˆè¿›è¡Œæ£€ç´¢ã€‚\n   - æ­¥éª¤Bï¼ˆç­›é€‰ï¼‰ï¼šæ ¹æ®çº³å…¥/æ’é™¤æ ‡å‡†å¯¹æ£€ç´¢ç»“æœè¿›è¡Œæ ‡é¢˜ã€æ‘˜è¦ã€å…¨æ–‡ä¸‰çº§ç­›é€‰ã€‚\n   - æ­¥éª¤Cï¼ˆæå–ï¼‰ï¼šä»æœ€ç»ˆçº³å…¥çš„æ–‡çŒ®ä¸­æå–ä¸åˆ†ææ¡†æ¶ç›¸å…³çš„ä¿¡æ¯ï¼ˆå¦‚åº”ç”¨åœºæ™¯ã€æŠ€æœ¯ç»†èŠ‚ã€æŠ¥å‘Šæ•ˆæœã€æŒ‡å‡ºé—®é¢˜ç­‰ï¼‰ã€‚\n   - æ­¥éª¤Dï¼ˆç»¼åˆï¼‰ï¼šå°†æå–çš„ä¿¡æ¯æŒ‰ç…§åˆ†ææ¡†æ¶è¿›è¡Œå½’ç±»ã€æ¯”è¾ƒã€å½’çº³å’Œæ€»ç»“ï¼Œè¯†åˆ«å…±åŒç‚¹ã€å·®å¼‚ç‚¹å’Œç ”ç©¶ç©ºç™½ã€‚\n3. è¾“å‡ºï¼š\n   - ç”Ÿæˆç»“æ„åŒ–ç»¼è¿°æŠ¥å‘Šï¼ŒåŒ…å«å¼•è¨€ã€æ–¹æ³•ï¼ˆè¯¦ç»†ï¼‰ã€ç°çŠ¶åˆ†æã€æŠ€æœ¯æ¢³ç†ã€æ•´åˆè¿‡ç¨‹ã€æŒ‘æˆ˜è®¨è®ºã€æœªæ¥å±•æœ›ã€ç»“è®ºç­‰éƒ¨åˆ†ã€‚"
        },
        "original_text": "Artificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.",
        "location": "",
        "analyzed_at": "2025-12-16T12:52:08.026313"
      }
    },
    "wb-370d40e7": {
      "id": "wb-370d40e7",
      "type": "method",
      "title": "åŸºäºé¢„å®šä¹‰å¤šé¢†åŸŸé€‰æ‹©é¢˜çš„å¯¹æ¯”æ¡ˆä¾‹ç ”ç©¶æ³•",
      "description": "é€šè¿‡è®¾è®¡ä¸€å¥—è¦†ç›–å¤šä¸ªé¢†åŸŸçš„æ ‡å‡†åŒ–é€‰æ‹©é¢˜é›†ï¼Œå¯¹ChatGPTå’ŒDeepSeek AIè¿›è¡Œç³»ç»Ÿæ€§æµ‹è¯•ä¸å¯¹æ¯”ï¼Œä»¥è¯„ä¼°å…¶èƒ½åŠ›å·®å¼‚ã€ä¼˜åŠ¿ä¸å±€é™ã€‚",
      "source_paper_id": "2cd0da84-59cb-40bc-bb23-771b1d632125",
      "zone": "methods",
      "created_at": "2025-12-16T13:21:21.068788",
      "data": {
        "analysis": {
          "method_name": "åŸºäºé¢„å®šä¹‰å¤šé¢†åŸŸé€‰æ‹©é¢˜çš„å¯¹æ¯”æ¡ˆä¾‹ç ”ç©¶æ³•",
          "method_type": "è¯„ä¼°æ–¹æ³•",
          "core_idea": "é€šè¿‡è®¾è®¡ä¸€å¥—è¦†ç›–å¤šä¸ªé¢†åŸŸçš„æ ‡å‡†åŒ–é€‰æ‹©é¢˜é›†ï¼Œå¯¹ChatGPTå’ŒDeepSeek AIè¿›è¡Œç³»ç»Ÿæ€§æµ‹è¯•ä¸å¯¹æ¯”ï¼Œä»¥è¯„ä¼°å…¶èƒ½åŠ›å·®å¼‚ã€ä¼˜åŠ¿ä¸å±€é™ã€‚",
          "innovation_points": [
            "é‡‡ç”¨æ ‡å‡†åŒ–ã€å¯å¤ç°çš„è¯„ä¼°æ¡†æ¶ï¼ˆé¢„å®šä¹‰é—®é¢˜é›†ï¼‰è¿›è¡Œæ¨¡å‹å¯¹æ¯”ï¼Œå‡å°‘äº†è¯„ä¼°çš„ä¸»è§‚æ€§å’Œéšæœºæ€§ã€‚",
            "å°†è¯„ä¼°èŒƒå›´æ‰©å±•åˆ°â€œå¤šä¸ªé¢†åŸŸâ€ï¼Œæ—¨åœ¨å…¨é¢è€ƒå¯Ÿæ¨¡å‹åœ¨ä¸åŒçŸ¥è¯†èƒŒæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ï¼Œè€Œéå±€é™äºå•ä¸€ä»»åŠ¡ã€‚"
          ],
          "implementation_steps": [
            "æ­¥éª¤1ï¼šè®¾è®¡å¹¶ç¡®å®šä¸€ä¸ªè¦†ç›–å¤šä¸ªçŸ¥è¯†é¢†åŸŸçš„é¢„å®šä¹‰é€‰æ‹©é¢˜é›†ã€‚",
            "æ­¥éª¤2ï¼šä½¿ç”¨åŒä¸€å¥—é—®é¢˜é›†ï¼Œåˆ†åˆ«å‘ChatGPTå’ŒDeepSeek AIæ¨¡å‹æé—®ã€‚",
            "æ­¥éª¤3ï¼šæ”¶é›†å¹¶åˆ†æä¸¤ä¸ªæ¨¡å‹çš„å›ç­”ï¼Œä»å‡†ç¡®æ€§ã€æ¨ç†è¿‡ç¨‹ã€å›ç­”é£æ ¼ç­‰æ–¹é¢è¿›è¡Œå®šæ€§æˆ–å®šé‡å¯¹æ¯”ã€‚",
            "æ­¥éª¤4ï¼šåŸºäºå¯¹æ¯”ç»“æœï¼Œæ€»ç»“å„æ¨¡å‹çš„ä¼˜åŠ¿ã€å±€é™åŠæŠ€æœ¯æ¼”è¿›æ–¹å‘ã€‚"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "æ–¹æ³•æ¸…æ™°ã€ç›´æ¥ï¼Œæ˜“äºç†è§£å’Œå¤ç°ï¼Œä¸ºæ¨¡å‹å¯¹æ¯”æä¾›äº†å¯æ“ä½œçš„åŸºç¡€æ¡†æ¶ã€‚",
              "å…³æ³¨å¤šé¢†åŸŸè¯„ä¼°ï¼Œæœ‰åŠ©äºæ­ç¤ºæ¨¡å‹èƒ½åŠ›çš„å¹¿åº¦ä¸ä¸€è‡´æ€§ï¼Œæ¯”å•ä¸€é¢†åŸŸæµ‹è¯•æ›´å…·å‚è€ƒä»·å€¼ã€‚"
            ],
            "weaknesses": [
              "æ–¹æ³•æè¿°è¿‡äºç®€ç•¥ï¼Œç¼ºä¹å…³é”®ç»†èŠ‚ï¼šå¦‚é€‰æ‹©é¢˜çš„å…·ä½“é¢†åŸŸã€æ•°é‡ã€éš¾åº¦åˆ†å¸ƒã€è¯„ä¼°æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€ç½®ä¿¡åº¦ç­‰ï¼‰å‡æœªè¯´æ˜ã€‚",
              "å‡è®¾â€œé¢„å®šä¹‰é€‰æ‹©é¢˜é›†â€èƒ½å…¨é¢ä»£è¡¨æ¨¡å‹çš„â€œèƒ½åŠ›â€ï¼Œä½†é€‰æ‹©é¢˜å½¢å¼å¯èƒ½æ— æ³•æœ‰æ•ˆè¯„ä¼°æ¨¡å‹çš„åˆ›é€ æ€§ã€å¤æ‚æ¨ç†ã€é•¿æ–‡æœ¬ç”Ÿæˆæˆ–ä¼¦ç†å¯¹é½ç­‰å…³é”®ç»´åº¦ã€‚",
              "æœªæåŠå®éªŒè®¾ç½®çš„å…³é”®æ§åˆ¶å˜é‡ï¼Œå¦‚æ¨¡å‹ç‰ˆæœ¬ã€æç¤ºè¯å·¥ç¨‹ã€æ¸©åº¦å‚æ•°ç­‰ï¼Œè¿™äº›ä¼šæå¤§å½±å“ç»“æœå¯æ¯”æ€§ã€‚"
            ],
            "questions": [
              "é¢„å®šä¹‰é—®é¢˜é›†çš„å…·ä½“æ„æˆæ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•ä¿è¯å…¶åœ¨å„é¢†åŸŸçš„ä»£è¡¨æ€§å’Œéš¾åº¦å¹³è¡¡ï¼Ÿ",
              "é™¤äº†é€‰æ‹©é¢˜ç­”æ¡ˆçš„æ­£ç¡®ä¸å¦ï¼Œæ˜¯å¦å¯¹æ¨¡å‹çš„æ¨ç†é“¾ã€é”™è¯¯ç±»å‹ã€ä¸ç¡®å®šæ€§è¡¨è¾¾è¿›è¡Œäº†æ›´æ·±åº¦çš„åˆ†æï¼Ÿ",
              "å®éªŒæ˜¯å¦è¿›è¡Œäº†å¤šæ¬¡è¿è¡Œä»¥ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Ÿå¦‚ä½•ç¡®ä¿è¯„ä¼°ç»“æœä¸å—æ¨¡å‹éšæœºæ€§çš„å½±å“ï¼Ÿ"
            ],
            "suggestions": [
              "åœ¨è®ºæ–‡ä¸­è¯¦ç»†é™„å½•é—®é¢˜é›†ï¼Œæˆ–è‡³å°‘è¯´æ˜å…¶è§„æ¨¡ã€é¢†åŸŸåˆ†ç±»åŠæ¥æºï¼ˆå¦‚åŸºäºæ ‡å‡†è€ƒè¯•é¢˜åº“æˆ–ä¸“å®¶æ„å»ºï¼‰ã€‚",
              "è¡¥å……æ›´ä¸°å¯Œçš„è¯„ä¼°ç»´åº¦ï¼Œä¾‹å¦‚å¼•å…¥å¼€æ”¾å¼é—®é¢˜ã€ä¼¦ç†å›°å¢ƒåœºæ™¯ã€ä»£ç ç”Ÿæˆæˆ–éœ€è¦å¤šæ­¥æ¨ç†çš„ä»»åŠ¡ã€‚",
              "æ˜ç¡®æŠ¥å‘Šå®éªŒé…ç½®ç»†èŠ‚ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„å…·ä½“ç‰ˆæœ¬ã€APIå‚æ•°ã€æç¤ºè¯æ¨¡æ¿ï¼Œå¹¶å»ºè®®è¿›è¡Œå¤šæ¬¡é‡‡æ ·å¹¶æŠ¥å‘Šå¹³å‡æ€§èƒ½åŠæ–¹å·®ã€‚"
            ]
          },
          "reproducibility_score": 5,
          "pseudocode": "# ä¼ªä»£ç  - åŸºäºè®ºæ–‡ç‰‡æ®µæè¿°çš„æ¨æ–­\n1. åˆå§‹åŒ–:\n   - å®šä¹‰è¯„ä¼°é—®é¢˜é›† Q = {q1, q2, ..., qn}ï¼Œæ¯ä¸ªé—®é¢˜qiå…³è”ä¸€ä¸ªé¢†åŸŸdiå’Œé€‰é¡¹é›†Oiã€‚\n   - åˆå§‹åŒ–æ¨¡å‹åˆ—è¡¨ M = [ChatGPT, DeepSeek_AI]ã€‚\n   - åˆå§‹åŒ–ç»“æœå­—å…¸ Results = {}ã€‚\n2. ä¸»å¾ªç¯:\n   For each æ¨¡å‹ m in M:\n       For each é—®é¢˜ q in Q:\n           response = m.query(q.prompt)  # å‘æ¨¡å‹æé—®\n           answer = extract_answer(response)  # ä»å“åº”ä¸­æå–ç­”æ¡ˆé€‰é¡¹\n           is_correct = (answer == q.ground_truth)\n           è®°å½• (q.id, m.name, answer, is_correct, response) åˆ° Results\n3. è¾“å‡º:\n   - è®¡ç®—æ¯ä¸ªæ¨¡å‹åœ¨å„é¢†åŸŸçš„å‡†ç¡®ç‡ã€‚\n   - å¯¹æ¯”åˆ†æä¸¤ä¸ªæ¨¡å‹çš„é”™è¯¯æ¨¡å¼ã€å›ç­”é£æ ¼å·®å¼‚ã€‚\n   - ç”Ÿæˆæ¨¡å‹èƒ½åŠ›å¯¹æ¯”æ€»ç»“æŠ¥å‘Šã€‚"
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) ",
        "location": "",
        "analyzed_at": "2025-12-16T13:21:21.068738"
      }
    },
    "wb-2496aaf3": {
      "id": "wb-2496aaf3",
      "type": "code",
      "title": "DeepSeek-R1",
      "description": "Fully open-source LLM model developed by Chinese AI research lab in 2023, launched in 2025. Features RL-based training bypassing SFT, self-verification, reflection, and chain-of-thought reasoning.",
      "source_paper_id": "2cd0da84-59cb-40bc-bb23-771b1d632125",
      "zone": "datasets",
      "created_at": "2025-12-16T13:21:54.239126",
      "data": {
        "asset": {
          "name": "DeepSeek-R1",
          "type": "model",
          "url": "https://huggingface.co/deepseek-ai",
          "platform": "Huggingface",
          "description": "Fully open-source LLM model developed by Chinese AI research lab in 2023, launched in 2025. Features RL-based training bypassing SFT, self-verification, reflection, and chain-of-thought reasoning.",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºChatGPTçš„å¯¹æ¯”æ¨¡å‹è¿›è¡Œè¯¦ç»†åˆ†æï¼Œè¯„ä¼°å…¶æ¶æ„ã€æ€§èƒ½ã€ä¼¦ç†è€ƒé‡ç­‰æ–¹é¢çš„æ”¹è¿›ã€‚",
          "verified": false,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/2cd0da84-59cb-40bc-bb23-771b1d632125/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T13:21:54.239044"
      }
    },
    "wb-ac1413ff": {
      "id": "wb-ac1413ff",
      "type": "code",
      "title": "DeepSeek-R1-Zero",
      "description": "A novel LLM approach where reinforcement learning is directly applied to the base model, bypassing supervised fine-tuning (SFT). Enables autonomous exploration of chain-of-thought reasoning strategies.",
      "source_paper_id": "2cd0da84-59cb-40bc-bb23-771b1d632125",
      "zone": "datasets",
      "created_at": "2025-12-16T13:21:54.264867",
      "data": {
        "asset": {
          "name": "DeepSeek-R1-Zero",
          "type": "model",
          "url": "https://huggingface.co/deepseek-ai",
          "platform": "Huggingface",
          "description": "A novel LLM approach where reinforcement learning is directly applied to the base model, bypassing supervised fine-tuning (SFT). Enables autonomous exploration of chain-of-thought reasoning strategies.",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºDeepSeek AIçš„åˆ›æ–°è®­ç»ƒæ–¹æ³•æ¡ˆä¾‹ï¼Œè¯´æ˜å…¶å¦‚ä½•å®ç°è‡ªæˆ‘éªŒè¯ã€åæ€å’Œç”Ÿæˆå¤æ‚æ¨ç†é“¾ã€‚",
          "verified": false,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/2cd0da84-59cb-40bc-bb23-771b1d632125/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T13:21:54.264834"
      }
    },
    "wb-bc34fecf": {
      "id": "wb-bc34fecf",
      "type": "code",
      "title": "GPTç³»åˆ— (GPT-1, GPT-2, GPT-3, GPT-3.5, GPT-4)",
      "description": "Generative Pre-trained Transformer series by OpenAI, evolving from 117M to 1T+ parameters. Foundation models for ChatGPT.",
      "source_paper_id": "2cd0da84-59cb-40bc-bb23-771b1d632125",
      "zone": "datasets",
      "created_at": "2025-12-16T13:21:54.277069",
      "data": {
        "asset": {
          "name": "GPTç³»åˆ— (GPT-1, GPT-2, GPT-3, GPT-3.5, GPT-4)",
          "type": "model",
          "url": "https://openai.com/api/",
          "platform": "OpenAI API",
          "description": "Generative Pre-trained Transformer series by OpenAI, evolving from 117M to 1T+ parameters. Foundation models for ChatGPT.",
          "license": "å•†ä¸š/ç ”ç©¶",
          "usage_in_paper": "ä½œä¸ºChatGPTçš„æŠ€æœ¯èƒŒæ™¯å’Œæ¼”å˜å†å²è¿›è¡Œè¯¦ç»†å›é¡¾å’Œæ¯”è¾ƒï¼ˆè§è¡¨Iï¼‰ã€‚",
          "verified": false,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/2cd0da84-59cb-40bc-bb23-771b1d632125/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T13:21:54.277029"
      }
    },
    "wb-31322e39": {
      "id": "wb-31322e39",
      "type": "code",
      "title": "ChatGPT",
      "description": "Advanced conversational AI chatbot by OpenAI, based on GPT-3.5/GPT-4, fine-tuned with RLHF.",
      "source_paper_id": "2cd0da84-59cb-40bc-bb23-771b1d632125",
      "zone": "datasets",
      "created_at": "2025-12-16T13:21:54.288305",
      "data": {
        "asset": {
          "name": "ChatGPT",
          "type": "api",
          "url": "https://chat.openai.com/",
          "platform": "OpenAI",
          "description": "Advanced conversational AI chatbot by OpenAI, based on GPT-3.5/GPT-4, fine-tuned with RLHF.",
          "license": "å•†ä¸š",
          "usage_in_paper": "ä½œä¸ºä¸»è¦å¯¹æ¯”å¯¹è±¡ï¼Œä¸DeepSeek AIåœ¨æ¶æ„ã€æ€§èƒ½ã€ä¼¦ç†ã€åº”ç”¨ç­‰å¤šç»´åº¦è¿›è¡Œæ¯”è¾ƒåˆ†æã€‚",
          "verified": false,
          "stars": null
        },
        "original_text": "# From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n\nSimrandeep Singh $^{1}$ , Shreya Bansal $^{2}$ , Abdulmotaleb El Saddik $^{3}$ , Mukesh Saini $^{2}$\n\n<sup>1</sup>Chandigarh University\n\n$^{2}$ Indian Institute of Technology Ropar\n\n<sup>3</sup>University of Ottawa\n\nAbstractâ€”The rapid advancement of artificial intelligence (AI) has reshaped the field of natural language processing (NLP), with models like OpenAI's ChatGPT and DeepSeek AI. Although ChatGPT established a strong foundation for conversational AI, DeepSeek AI introduces significant improvements in architecture, performance, and ethical considerations. This paper presents a detailed analysis of the evolution from ChatGPT to DeepSeek AI, highlighting their technical differences, practical applications, and broader implications for AI development. To assess their capabilities, we conducted a case study using a predefined set of multiple choice questions in various domains, evaluating the strengths and limitations of each model. By examining these aspects, we provide valuable insight into the future trajectory of AI, its potential to transform industries, and key research directions for improving AI-driven language models.\n\nIndex Termsâ€”Conversational AI, Large Language Models (LLMs), Natural Language Processing (NLP).\n\n# I. INTRODUCTION\n\nIn today's era, artificial intelligence (AI) is the most significant development in technology; everyone is talking about AI. Its applications are spanning in every field, such as healthcare[1][2], robotics[3][4], finance[5][6], engineering[7][8], cybersecurity[9][10], agriculture[11][12], retail[13], chatbots(Siri, Alexa)[14][15], manufacturing[16] [17], entertainment[18][19], business & marketing[20][21], media[22][23], transportation [24][25], and many more.\n\nAI is helping and facilitating human beings by opening doors for more advanced solutions for the challenges faced by society and pushing the boundaries of conventional methodology to redefine possibilities. AI is a tool derived by computer science engineers to tackle cognitive challenges traditionally associated with human intelligence. It provides solutions for problem-solving, learning, recognizing patterns, summarization, sentiment analysis, chatbots, machine translation, etc. The major agenda of AI is to make the daily life routine of individuals really enjoyable, easy, efficient, convenient, and automated. AI is achieved through machine learning by adopting human-like intelligence and mimicking human behavior, training itself using advanced technologies. It is an essential tool in both practical and entertaining contexts due to its capacity to help humans with a variety of tasks.\n\nOne of the sought-after fields in AI is Natural Language Processing (NLP) [26][27], which has become a widely discussed\n\ntopic after the invention of ChatGPT and similar other tools. However, NLP has several older tools such as ELIZA (1966) [28], SHRDLU (1968-1970) [29], PARRY (1972) [30], LISP-Based NLP Systems (1980s) [31], WordNet (1985-Present) [32], Hidden Markov Models (HMM)[33], Latent Semantic Analysis (LSA) (1990s) [34], Stanford NLP (2000s-Present), which have paved the way for modern deep learning-based models. Human language is a complex phenomenon, having thousands of languages with millions of words and multiple meanings. NLP has emerged as a multidisciplinary field combining AI with linguistics and allows for more significant and realistic communications. NLP can understand, communicate, and interpret language while also facilitating interaction between computers and human language by being trained using machine learning, deep learning, or computational linguistics. NLP includes many steps; after dividing long sentences into individual tokens in tokenization, the position and context of each token are analyzed in tagging. Lemmatization and stemming assist in eliminating affixes and determining the root form of a complete word, which ensures its meaning does not lose contextual flavor. The last phase of processing is chunking, which combines disparate linguistic components into more coherent, structured, and meaningful units [35].\n\nThe introduction of transformer models[36][37] has revolutionized the field of NLP[38][39]. These models, such as GPT[40][41][42], have significantly advanced the capabilities of NLP systems, making them more efficient and effective. Now, machines are becoming more friendly with humans, and models are capable of generating text with human feel and expression. The core of the transformer model is the attention mechanism [43][44], which dynamically gives more attention to key points in the input sequence, making the model capable of tackling sequence-to-sequence tasks, question answering, sentiment analysis, and language modeling with more efficiency. Thus, they can generate new text, understand new patterns and relationships among words, and finally enhance the system's understanding capability.\n\nOne of the major players driving this revolution is OpenAI, established in 2015 as an American artificial intelligence (AI) research lab founded by a group of engineers, researchers, and businesspeople. It has two subsidiary companiesâ€”OpenAI Inc. and OpenAI Global LLCâ€”serving non-profit and com\n\nmercial purposes. The organization has received significant support from well-known individuals and companies, including Microsoft Corporation, Elon Musk, Sam Altman, Ilya Sutskever, and Greg Brockman, who are also co-founders and key investors. The vision behind OpenAI is to develop artificial general intelligence (AGI) [45] that surpasses human capabilities, intending to benefit all of humanity. Several machine learning tools, such as DALL-E [46] and ChatGPT [40], have emerged as OpenAI products and are available for public use. ChatGPT, in particular, gained immense popularity, attracting over a million users within just one week of its launch. OpenAI launched ChatGPT on 30th November 2022, which is based on the GPT-3.5 [47] and GPT-4[40] architectures. It has become a widely used innovative tool because of its coherence and versatile applications. It is an advanced chatbot capable of handling a variety of applications such as answering questions, writing code, creating content, providing customer support, assisting with education, drafting emails and meeting minutes, generating ideas, writing project reports, offering healthcare assistance, correcting grammar, conducting research analysis, translating languages, and much more. Its streamlined architecture helps to interpret user input efficiently and provide a response, which mimics real human language. However, ChatGPT possesses many shortcomings, such as high computation cost, a less focused approach, and a higher price point. To resolve these shortcomings, Liang Wenfeng proposed a fresh perspective to NLP models, i.e., Deepseek AI [48].\n\n# II. BACKGROUND\n\nThis section reviews the evolution of ChatGPT, highlighting its development and capabilities across different versions. It also introduces DeepSeek AI, a new approach that aims to address some of the limitations of current models like ChatGPT, offering a more efficient and task-focused paradigm for NLP.\n\n# A. ChatGPT: A Pioneering Model\n\nChatGPT is a publicly available AI tool developed by OpenAI, marking a significant advancement in natural language processing (NLP) and conversational AI. The basic building block of ChatGPT is a large language model (LLM) [49][50] architecture, which includes embedding, encoder-decoder layers [51], positional encoding, self-attention mechanisms, feedforward networks, add & normalization layers, and multi-head attention. ChatGPT is a highly sophisticated chatbot implemented through a deep neural network architecture using a transformer framework to generate coherent and contextually relevant text. It belongs to a group of widely used transformer-based models including Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformers (GPT). ChatGPT is a language model that comprehends human-like text across a wide range of applications such as sentence completion, translation, and conversational interaction. It simulates conversations with human users and generates human-like outputs. Its conversational abilities are\n\nenhanced using fine-tuning conducted by reinforcement learning with human feedback (RLHF) [52]. The capabilities of this model are enhanced using extensive pre-training conducted using diverse datasets sourced from various books, articles, websites, and other textual content. utilizing high-end GPUs.\n\n# B. Evolution of ChatGPT\n\nLarge language models (LLMs) act as a foundation stone for the rapid evolution of natural language processing (NLP). After the significant advancement of LLM, ChatGPT has undergone multiple iterations in a short period. Within 2 years only, ChatGPT has quickly improved its capabilities and performance parameters. The groundbreaking transformer models laid the foundation for more advanced large language models. These transformer models have demonstrated significant improvements over traditional Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) [53] models. The encoder-decoder architecture of transformers has proven a seismic shift in the deep learning horizon. As illustrated in Fig. 2, the transformer model shows parallel processing abilities and is trained to understand and generate human-like text. RNNs and LSTMs face challenges such as vanishing gradients [54] when dealing with long dependencies. However, transformers excel in parallel processing due to their reliance on the 'attention mechanism', which enables them to capture relationships across long data sequences. The first GPT-1 model [55], introduced in mid-2018, utilized auto-regressive language modeling as an unsupervised pre-training approach. This approach set the foundation for pre-training on large text corpora followed by fine-tuning, becoming a standard methodology for various NLP tasks. During the pre-training phase, the GPT model uses a traditional language modeling objective, as illustrated in Eq. 1:\n\n$$\nL _ {1} (u) = \\sum_ {i} \\log P \\left(u _ {i} \\mid u _ {i - k}, \\dots , u _ {i - 1}\\right) \\tag {1}\n$$\n\nwhere  $u_{i}$  is the current token,  $u_{i-1}, u_{i-2}, \\ldots, u_{i-k}$  are the previous  $k$  context tokens, and  $P$  is the probability function modeled using a decoder-only transformer. After pre-training, the model is fine-tuned for specific tasks through supervised learning, where it is trained on relevant datasets with input transformations. During inference, GPT-1 generates new sequences, utilizing the 117 million parameters it was trained on. The training process involved processing around 7,000 unpublished books.\n\nOpenAI released GPT-2 in 2019 [56], featuring a 1.5 billion-parameter transformer. The model includes parameters such as a vocabulary size of over 50,000, 12 attention heads, 12 layers, and a batch size of 512. It was trained on 8 million web texts or web pages, without the need for supervised fine-tuning. A notable feature of GPT is its ability to perform zero-shot learning, enabling it to handle tasks it has not been explicitly trained for. This capability is achieved by leveraging patterns and knowledge acquired during training to generalize across unseen tasks. For instance, the model can classify sentiment or generate creative content without requiring specific task-related examples in its training data. Language modeling used\n\nTABLEI COMPARISON OF GPT MODEL EVOLUTION FROM GPT-1 TO GPT-4  \n\n<table><tr><td>Feature</td><td>GPT-1 (2018)</td><td>GPT-2 (2019)</td><td>GPT-3 (2020)</td><td>GPT-3.5 (2022)</td><td>GPT-4 (2023)</td></tr><tr><td>Parameters</td><td>117 million</td><td>1.5 billion</td><td>175 billion</td><td>200-300 billion</td><td>Estimated 1T+ (not officially disclosed)</td></tr><tr><td>Training Data</td><td>BooksCorpus ~7K books</td><td>WebText (8M web-pages)</td><td>570GB of text from books, articles, and the internet</td><td>Improved over GPT-3 with better filtering</td><td>Vast collection of data scraped from the internet, including books, websites, scientific papers, etc.</td></tr><tr><td>Context Length</td><td>~512 tokens</td><td>~1024 tokens</td><td>~2048 tokens</td><td>~4096 tokens</td><td>~32K &amp; ~128K tokens in GPT-4 Turbo</td></tr><tr><td>Transformer Layers</td><td>12</td><td>48</td><td>96</td><td>Similar to GPT-3</td><td>Estimated 100+</td></tr><tr><td>Modality</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text only</td><td>Text + Images (Multimodal)</td></tr><tr><td>Multilingual Support</td><td>Limited English</td><td>Basic multilingual understanding</td><td>Supports multiple languages but mainly trained in English</td><td>Better non-English understanding</td><td>Strong multilingual capabilities (supports 25+ languages well)</td></tr><tr><td>Few-shot Learning</td><td>No</td><td>Partial</td><td>Yes</td><td>Improved</td><td>Advanced Few-shot &amp; Zero-shot learning</td></tr><tr><td>Logical Reasoning</td><td>Weak</td><td>Moderate</td><td>Better, but inconsistent</td><td>Improved, but still flawed</td><td>Strongest yet, closer to human-level reasoning</td></tr><tr><td>Performance on Benchmarks</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best so far (passes simulated bar exam, high SAT/GRE scores, etc.)</td></tr><tr><td>Creativity</td><td>Low</td><td>Moderate</td><td>High</td><td>Higher</td><td>Best for creative writing, storytelling, and code generation</td></tr><tr><td>Factual Accuracy</td><td>Poor</td><td>Moderate</td><td>Often hallucinates</td><td>Fewer hallucinations</td><td>Most reliable, fewer hallucinations</td></tr><tr><td>Computation Cost</td><td>Low</td><td>High</td><td>Very high</td><td>Optimized over GPT-3</td><td>Very high, but optimized efficiency</td></tr><tr><td>Internet Access</td><td>No</td><td>No</td><td>No</td><td>No</td><td>No direct access, but trained on a larger dataset</td></tr><tr><td>Fine-tuning Capability</td><td>Limited</td><td>Somewhat customizable</td><td>Available for enterprises</td><td>More customizable</td><td>Advanced fine-tuning support</td></tr><tr><td>Code Generation</td><td>Very basic</td><td>Improved</td><td>Strong (GPT-3 Codex used in GitHub Copilot)</td><td>Even better</td><td>Best for programming, used in AI coding tools</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>High</td><td>Still significant</td><td>Moderate, but problematic</td><td>Improved with better moderation</td><td>Best moderation &amp; bias reduction</td></tr><tr><td>Accessibility</td><td>Research only</td><td>Open to public (some restrictions)</td><td>Commercial API (GPT-3.5 Turbo made it cheaper)</td><td>API &amp; ChatGPT integration</td><td>ChatGPT-4 available via API and subscription</td></tr><tr><td>Cost</td><td>Low</td><td>High (due to more parameters)</td><td>Very high (expensive inference)</td><td>More cost-effective than GPT-3</td><td>GPT-4 Turbo made it cheaper and faster</td></tr></table>\n\nin GPT 2 is given by Eq. 2, which represents the probabilistic framework for the probability of a sequence  $u_{i}$  given its preceding states  $u_{i-1}$ , modeled as a product of conditional probabilities.\n\n$$\np (x) = \\prod_ {i = 1} ^ {n} P \\left(u _ {i} \\mid u _ {1}, \\dots , u _ {n - 1}\\right) \\tag {2}\n$$\n\nThe architecture of GPT-3 [47] doesn't have much variation as compared to GPT-2, the key change carried in GPT-3 is the use of alternating dense and locally banded sparse attention\n\npatterns within the transformer framework. This extensive dataset, comprising about 410 billion tokens, allowed the autoregressive language model (GPT-3) to develop a broad understanding of language patterns and contextual relationships and was introduced in 2020. Training was carried out on the huge data, comprising of approximately 570GB of text after filtering, sourced from Common Crawl (60% of the training mix), WebText2 (19 billion, 22% training weight), Books1 (19 billion, 8% training weight), Books2 (55 billion, 8% training weight), and Wikipedia (3 billion, 2% training weight). GPT-3\n\n![](/uploads/images/2cd0da84-59cb-40bc-bb23-771b1d632125/bb1d54955d6d4a3faf88ee131d86b3f0a6c2442d48eadbf5e6025dedeab7cd81.jpg)  \nFig. 1. Evolution of GPT: From Version 1 to 4\n\nis utilized without gradient updating or fine-tuning, based on tasks and a small set of demonstrations specified only in terms of text interaction with the model. GPT-3 is a few-shot and multitask model trained on 8 models of different sizes, having trainable parameters ranging between 125M to 175B. GPT-3 is  $10\\mathrm{x}$  more advanced than previous versions and has wide applications such as language translation, content creation, text classification, sentiment extraction, creative writing, writing assistance, research and analysis, generating code, business guidelines, and more. GPT-3.5 is just a fine-tuned and iterated version of GPT-3, introduced in the year 2022. It is capable of generating more realistic, relative, and coherent text as compared to previous versions. The parameters of GPT-3 and 3.5 have increased significantly, representing a substantial improvement over earlier versions. OpenAI launched ChatGPT in 2023 and the foundation model is GPT-3.5. GPT-3.5 is capable of generating human-like text known as humanized AI, showing deeper knowledge of the semantics and context of text, and hence enabling it to perform better for technical and report writing.\n\nGPT-4 [40] entered the public domain on March 14, 2023, with improved reasoning ability. It shows multimodal behavior, i.e. compatible with both text and images as inputs. This behavior enables GPT-4 to understand visuals, spoken words, and text information, which has enhanced its ability to respond to complex and comprehend long-term contexts. This significant improvement has enabled GPT-4 to store longer versions of data, preserve details throughout the conversation, and provide more ethical and fair outputs. All these developments are summarized in Table I, which highlights the key differences and advancements across each GPT iteration.\n\n# C. DeepSeek AI: A Paradigm Shift\n\nDeepSeek AI, developed by DeepSeek, builds on the foundation of ChatGPT but introduces significant innovations. It comes with the motive to enhance Artificial General Intelligence (AGI) and to make it a reality. It includes advanced finetuning techniques, a deeper focus on contextual understanding, Graph Neural Networks (GNNs) [57], Reinforcement Learning, or Memory-Augmented Networks [58], and a focus on ethical AI practices. DeepSeek AI has been declared to be more domain-specific and aims to overcome the limitations of ChatGPT. DeepSeek is using the model with optimized efficiency, reducing biases, and providing more customized responses. The clear agenda of its development seems to shift toward more responsible and adaptable AI systems.\n\n# III. KEY DEVIATIONS AND ADVANCEMENTS\n\nThe Chinese AI research lab established in 2023 developed the fully open-source DeepSeek R1 model and launched it for the public in 2025. It is getting significant attention worldwide due to its cost-effective training. It varies from its counterpart in terms of reasoning and non-reasoning capabilities, such as self-verification, reflection, and long conversations. On the architecture level, it replaces supervised fine-tuning with reinforcement learning (RL), a training pipeline involving two RL stages, and two supervised fine-tuning (SFT) stages.\n\nDeepSeek-R1-Zero represents a novel approach in LLM model, RL directly applied to the base model and bypassing the traditional supervised fine-tuning (SFT) stage. This innovative method enables the model to autonomously explore and develop chain-of-thought (CoT) reasoning strategies for tackling complex problems. This training approach helps DeepSeek-R1-Zero to achieve significant advancements in AI, such as self-verification, reflection, and the generation of extensive chains of thought. Self-verification helps to assess and validate its own outputs, and reflection presents an introspective analysis of its reasoning process. It demonstrates the capabilities of RL-based training to foster more sophisticated and self-aware language models.\n\nAdditionally, DeepSeek's performance has improved using model distillation [59], which enables smaller models to achieve the reasoning abilities of larger models. The total training cost is significantly lower than that of other renowned LLM models like Google and OpenAI, which have spent much more on similar foundation models. The cost per inference is also much lower, making it an attractive option for scalable deployment.\n\nChinese AI research lab has utilized H800 chips, employing techniques like mixture-of-experts and multi-head latent attention to compensate for lower computational power. This breakthrough allowed the model to perform effectively despite hardware constraints. The following subsections outline its architectural improvements, performance metrics, ethical considerations, and practical applications.\n\n# A. Architectural Improvements\n\n1) Model Size and Efficiency: ChatGPT relies on a massive number of parameters (e.g., 175 billion in GPT-3), which contributes to its high computational costs. DeepSeek AI, on the other hand, employs a more efficient architecture, reducing parameter counts while maintaining or even improving performance. This is achieved through techniques like sparse attention mechanisms and model distillation.  \n2) Fine-Tuning and Adaptability: DeepSeek AI incorporates advanced fine-tuning methods, such as reinforcement learning from human feedback (RLHF) and domain-specific pre-training. This allows the model to adapt more effectively to specialized tasks, such as medical diagnosis or legal document analysis.  \n3) Group Relative Policy Optimization (GRPO): To reduce the computational expenses associated with reinforcement learning (RL), DeepSeek employs Group Relative\n\nPolicy Optimization (GRPO), a method introduced by Shao et al. [60] in 2024. GRPO is an online learning algorithm that offers a more efficient alternative to traditional approaches by eliminating the need for a separate critic model. GRPO aims to maximize the advantage of the generated completions that help a model to learn better by comparing different actions and making small, controlled updates using a group of observations.\n\nInstead of using a critic, GRPO employs a group-based evaluation strategy. The algorithm generates multiple outputs from the existing policy  $(\\pi_{\\theta_{\\mathrm{old}}})$  for each given question or prompt. It then uses these outputs to establish a baseline for performance evaluation. The optimization process for the policy model  $(\\pi_{\\theta})$  involves maximizing an objective function that compares the relative performance of outputs within each group. This approach allows for a more streamlined and cost-effective training process while maintaining the ability to improve the model's performance. The group reinforcement learning objective (GRPO) is defined by Eq. 3.\n\n$$\nL _ {\\mathrm {G R P O}} (\\theta) = L _ {\\mathrm {c l i p}} (\\theta) - w _ {1} D _ {\\mathrm {K L}} \\left(\\pi_ {\\theta} \\| \\pi_ {\\text {o r i g}}\\right) \\tag {3}\n$$\n\nwhere:\n\n-  $L_{\\mathrm{clip}}(\\theta)$  is the clipped surrogate loss, similar to PPO.  \n-  $D_{\\mathrm{KL}}(\\pi_{\\theta} \\| \\pi_{\\mathrm{orig}})$  is the KL divergence term.  \n-  $w_{1}$  is a weight parameter.\n\nThe advantage for each response in a group is calculated by Eq. 4:\n\n$$\nA _ {i} = \\frac {R _ {\\phi} \\left(r _ {i}\\right) - \\operatorname {m e a n} (G)}{\\operatorname {s t d} (G)} \\tag {4}\n$$\n\nWhere:\n\n-  $R_{\\phi}(r_i)$  is the reward for response  $r_i$ .  \n-  $G$  is the group of responses.  \n- std is the standard deviation.\n\n# B. Performance Metrics\n\n1) Contextual Understanding: One of ChatGPT's limitations is its tendency to lose context in long conversations. DeepSeek AI addresses this by implementing memory-augmented architectures, enabling it to maintain coherence over extended interactions.  \n2) Bias Mitigation: ChatGPT has been criticized for generating biased or inappropriate content due to biases in its training data. DeepSeek AI employs debiasing algorithms and curated datasets to minimize such occurrences, ensuring more equitable and responsible outputs.  \n3) Multilingual Capabilities: While ChatGPT supports multiple languages, DeepSeek AI enhances this capability by incorporating low-resource languages and improving translation accuracy through cross-lingual transfer learning.\n\n# C. Ethical Considerations\n\n1) Transparency and Explainability: DeepSeek AI prioritizes transparency by providing users with insights into\n\nhow responses are generated and mechanisms to improve response quality over time. This includes explainable AI (XAI) [61][62] techniques such as SHAP (Shapley additive explanations) [63] and LIME (Local interpretable model-agnostic explanations)[64] that highlight the reasoning behind specific outputs. It doesn't use a black box mechanism; instead, the decision-making process is made traceable and auditable.\n\n2) User Privacy: DeepSeek AI incorporates cutting-edge privacy-preserving measures, such as differential privacy[65] and federated learning[66], to ensure that user interactions remain confidential. It protects user data and unauthorized surveillance by adding mathematical noise to the signal. Federated or collaborative learning ensures the training of models on the local hardware and transmits weights and biases to a central server for improving the global model.  \n3) Ethical Alignment: DeepSeek AI is designed with ethical guidelines such as fairness, accountability, and inclusivity embedded into its training process, reducing the risk of harmful or unethical outputs. DeepSeek models undergo rigorous bias detection using fairness-aware algorithms to detect harmful, adult, misleading, or offensive content. The model is improved for ethical consideration using reinforcement learning with human feedback (RLHF) to improve ethical decision-making over time.\n\n# D. Practical Applications\n\n1) Industry-Specific Solutions: DeepSeek AI offers tailored solutions for various industries. For example, in healthcare, it can assist with medical diagnosis and patient communication. At the same time, it can analyze market trends, risk assessment, investment decisions, fraud detection, customer service and generate reports in finance. Retail market, education, and autonomous systems are other industries where DeepSeek is transforming conventional techniques.  \n2) Real-Time Adaptability: Unlike ChatGPT, which operates primarily in a static manner, DeepSeek AI can adapt to real-time changes in input, making it suitable for dynamic environments such as live customer support or interactive education. It is best suited for applications where immediate response is required, such as traffic adaptive traffic light signals, detecting fraudulent transactions in finance, personalized tutoring according to the aptitude level of students, report generation for MRI, CT, and other scans, real-time sentiment analysis, and market trends.  \n3) Creative Applications: DeepSeek AI's enhanced creativity and coherence make it a valuable tool for content creation, including writing, music composition, and graphic design. It finds vast applications in the areas such as drafting content, brainstorming, or writing code, take notes, making minutes of meetings; discovering complex reasoning patterns, interactive storytelling, simulations for complex systems, idea generation, design optimization and many more.\n\n# IV. COMPARATIVE ANALYSIS\n\nDeepSeek is also open-sourced, promoting competition and encouraging further advancements in AI development. This could lead to reduced costs and better models in the future, benefiting companies and users worldwide. This section provides a detailed comparison of ChatGPT and DeepSeek AI across several dimensions such as model architecture, training data and methodology, reinforcement learning, computational efficiency, context, and ethical, and societal implications along with summarized Tables. II and III. Here deeper discussion and insights of training, capabilities, and limitations are presented.\n\n# 1) Model Architecture\n\n- ChatGPT: It is a general-purpose language model based on OpenAI's GPT-3.5 or GPT-4 architecture, employing a dense Transformer model with a focus on large-scale pre-training and fine-tuning using Reinforcement Learning from Human Feedback (RLHF). It undergoes large-scale pretraining and offers high computational cost with high latency\n\n- DeepSeek AI: It utilizes an optimized and hybrid Transformer architecture with enhanced attention and active learning mechanisms, improving context retention and reducing token dependencies for better long-form coherence. It is best suited for potentially domain-specific or task-optimized applications.\n\n# 2) Training Data and Methodology\n\n- ChatGPT: Trained on a diverse dataset, including internet text, books, and academic papers, with additional fine-tuning through RLHF.\n\n- DeepSeek AI: Employs a more dynamic dataset integration approach, incorporating real-time updates and domain-specific datasets for improved adaptability in specialized fields.\n\n# 3) Reinforcement Learning and Optimization\n\n- ChatGPT: Uses RLHF to refine responses and improve user alignment, focusing on reducing biases and enhancing conversational relevance.\n\n- DeepSeek AI: Advances RLHF with dynamic reinforcement mechanisms, incorporating adaptive reward modeling and improved human-AI feedback loops for more fine-tuned responses.\n\n# 4) Computational Efficiency and Scalability\n\n- ChatGPT: Requires significant computational resources due to its dense architecture and extensive training cycles.\n\n- DeepSeek AI: Employs model compression techniques such as knowledge distillation and quantization to optimize performance and reduce computational overhead.\n\n# 5) Context Window and Memory Retention\n\n- ChatGPT: Supports a large but fixed context window, limiting its ability to recall previous interactions beyond a certain token limit.\n\n- DeepSeek AI: Implements an improved context window management system, allowing better retention of conversational history across longer interactions.\n\n# 6) Societal and Ethical Implications\n\n- Bias and Fairness: Both models face challenges related to bias in AI-generated content. DeepSeek AI's emphasis on domain-specific customization offers potential for greater fairness but also introduces risks of overfitting to specific viewpoints.\n\n- Impact on the Workforce: AI language models are increasingly influencing industries such as content creation, customer support, and programming. While they enhance productivity, they also raise concerns about job displacement and the need for new skill sets.\n\n7) Ethical Considerations and Future Regulation: As AI becomes more pervasive, regulatory frameworks will play a crucial role in mitigating misuse. Transparency in training methodologies and responsible AI deployment remain key areas of discussion.\n\n# A. Case study\n\nWe have conducted a comprehensive evaluation assessment of ChatGPT and DeepSeek models by asking a predefined set of multiple-choice questions spanning various domains. The results of the comparative case study are represented in Table IV. It evaluates the performance capabilities of ChatGPT and DeepSeek across 24 domains using multiple-choice questions. The table reports the number of Total Questions posed to each model, along with the number of Total Correct answers and the corresponding Accuracy  $(\\%)$  for both ChatGPT and DeepSeek.\n\nOverall, DeepSeek AI outperforms ChatGPT in terms of accuracy across most domains. For example, in the tourism domain, DeepSeek AI correctly answered 85 of 100 questions, resulting in an accuracy of  $85\\%$ , while ChatGPT correctly answered 53 of 100 questions, with an accuracy of  $53\\%$ . Similarly, in the Physics domain, DeepSeek AI achieved  $92\\%$  accuracy, correctly answering 46 out of 50 questions, while ChatGPT answered 43 out of 50 questions, achieving  $86\\%$  accuracy.\n\nHowever, there are domains where ChatGPT performed equally or better than DeepSeek AI. For example, in Psychology and Economics, both models achieved perfect accuracy, answering all questions correctly (100%). In domains like Mechanical Engineering, Botany, and Commerce, the performance of both models are more comparable. For example, in Mechanical Engineering, both ChatGPT and DeepSeek AI correctly answered 39 of 50 questions, resulting in an accuracy of 78% for both.\n\nIn mathematics, DeepSeek AI performed better, achieving perfect accuracy by answering all 53 questions correctly (100%), while ChatGPT answered 43 of 53 questions, resulting in an accuracy of  $81\\%$ . This shows that DeepSeek AI outperforms ChatGPT in mathematics by achieving higher accuracy. Similarly, in Commerce, DeepSeek AI outperformed ChatGPT, answering 49 out of 50 questions correctly (98% accuracy) compared to ChatGPT's 42 correct answers (84% accuracy).\n\nA comprehensive summary of the overall performance of both models is provided at the bottom of the table. Across all\n\nTABLE II COMPARISON OF DEEPSEEK AI AND GPT SERIES (GPT-1 TO GPT-4)  \n\n<table><tr><td>Feature</td><td>DeepSeek AI</td><td>GPT Series (GPT-1 to GPT-4)</td></tr><tr><td>Parameters</td><td>Likely in the range of tens to hundreds of billions (exact number undisclosed)</td><td>Ranges from 117M (GPT-1) to 1T+ (GPT-4).</td></tr><tr><td>Training Data</td><td>Large-scale, diverse datasets, possibly including multi-lingual and multimodal data.</td><td>Evolved from BooksCorpus (7K books) to a massive, diverse dataset including text and images.</td></tr><tr><td>Context Length</td><td>Likely competitive with GPT-4 (e.g., 128K tokens or more).</td><td>Improved from 512 tokens (GPT-1) to 128K tokens (GPT-4 Turbo).</td></tr><tr><td>Transformer Layers</td><td>Likely similar to GPT-4 (100+ layers).</td><td>Increased from 12 layers (GPT-1) to 100+ layers (GPT-4).</td></tr><tr><td>Modality</td><td>Likely multimodal (text + images + potentially other modalities).</td><td>GPT-4 introduced multimodal capabilities (text + im-ages).</td></tr><tr><td>Multilingual Support</td><td>Strong multilingual capabilities, possibly supporting 25+ languages.</td><td>Improved from limited English (GPT-1) to strong mul-tingual support (GPT-4).</td></tr><tr><td>Few-shot Learning</td><td>Advanced few-shot and zero-shot learning capabilities.</td><td>Improved from none (GPT-1) to advanced few-shot and zero-shot learning (GPT-4).</td></tr><tr><td>Logical Reasoning</td><td>Strong logical reasoning, potentially competitive with GPT-4.</td><td>Improved from weak (GPT-1) to human-level reasoning (GPT-4).</td></tr><tr><td>Performance on Benchmarks</td><td>Likely competitive with GPT-4 on standard benchmarks.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Creativity</td><td>High creativity in text generation, storytelling, and code generation.</td><td>Improved from low (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Factual Accuracy</td><td>Improved factual accuracy with fewer hallucinations.</td><td>Improved from poor (GPT-1) to most reliable (GPT-4).</td></tr><tr><td>Computation Cost</td><td>Likely high but optimized for efficiency.</td><td>Increased from low (GPT-1) to very high but optimized (GPT-4).</td></tr><tr><td>Internet Access</td><td>No direct access, but trained on up-to-date datasets.</td><td>No direct access, but GPT-4 trained on a larger, more recent dataset.</td></tr><tr><td>Fine-tuning Capability</td><td>Advanced fine-tuning support for enterprises.</td><td>Improved from limited (GPT-1) to advanced fine-tuning support (GPT-4).</td></tr><tr><td>Code Generation</td><td>Strong code generation capabilities, possibly competitive with GPT-4.</td><td>Improved from very basic (GPT-1) to best-in-class (GPT-4).</td></tr><tr><td>Bias &amp; Ethical Issues</td><td>Likely improved moderation and bias reduction.</td><td>Improved from high (GPT-1) to best moderation and bias reduction (GPT-4).</td></tr><tr><td>Accessibility</td><td>Likely available via API and subscription models.</td><td>Improved from research-only (GPT-1) to API and sub-scription models (GPT-4).</td></tr><tr><td>Cost</td><td>Likely competitive with GPT-4 Turbo in terms of cost-effectiveness.</td><td>Improved from low (GPT-1) to cost-effective (GPT-4 Turbo).</td></tr></table>\n\n1429 questions tested, DeepSeek AI answered 1245 questions correctly, achieving an overall accuracy of  $87\\%$ . In comparison, ChatGPT answered 1140 questions correctly, with a total accuracy of  $79\\%$ . This overall performance reinforces the trend that DeepSeek AI generally outperforms ChatGPT in terms of accuracy across a wide range of domains.\n\nIn summary, while ChatGPT performs well in many domains, DeepSeek AI consistently delivers higher accuracy in most cases, with notable exceptions like Psychology and Economics where both models perform equally. DeepSeek AI also shows particular strength in domains like Mathematics, where it achieved perfect accuracy, while ChatGPT's accuracy was lower.\n\n# V. IMPLICATIONS FOR FUTURE RESEARCH\n\nThe transition from ChatGPT to DeepSeek AI presents new opportunities for researchers to explore advancements in AI, particularly in efficiency, accuracy, and ethical considerations. DeepSeek AI demonstrates improved performance across various domains, leveraging optimized training techniques and better resource management. While ChatGPT has shown strong capabilities in multiple applications, DeepSeek AI\n\nconsistently achieves higher accuracy, particularly in technical fields such as mathematics. However, generative capabilities and reasoning accuracy remain critical areas of focus, as both models exhibit strengths and limitations in complex problem-solving and creative generation.\n\nThis shift highlights several key areas for future research. One crucial aspect is the development of efficient training algorithms that enable large models to be trained with reduced computational resources, making AI more sustainable and accessible. Additionally, multimodal integration is an important direction, allowing AI systems to process and combine text, audio, and visual inputs for more comprehensive understanding and interaction. Another area of interest is continuous learning, which enables AI models to adapt and improve over time based on user interactions, leading to more personalized and dynamic responses. The accuracy of generative AI also requires further enhancement, ensuring that AI-generated content remains coherent, contextually relevant, and factually accurate. Moreover, reasoning capabilities must be strengthened to allow AI models to provide more reliable and logically sound responses in complex scenarios.\n\nFurthermore, the need for ethical AI development remains\n\nTABLE III COMPARISON BETWEEN CHATGPT AND DEEPSEEK AI  \n\n<table><tr><td>Dimension</td><td>ChatGPT</td><td>DeepSeek AI</td></tr><tr><td>Architecture</td><td>Transformer-based, large parameter count</td><td>Optimized architecture, fewer parameters</td></tr><tr><td>Fine-Tuning</td><td>General-purpose fine-tuning</td><td>Domain-specific fine-tuning</td></tr><tr><td>Contextual Understanding</td><td>Limited in long conversations</td><td>Enhanced with memory-augmented systems</td></tr><tr><td>Bias Mitigation</td><td>Limited debiasing techniques</td><td>Advanced debiasing algorithms</td></tr><tr><td>Ethical Alignment</td><td>Basic ethical guidelines</td><td>Embedded ethical frameworks</td></tr><tr><td>Computational Efficiency</td><td>High computational costs</td><td>Optimized for efficiency</td></tr><tr><td>Real-Time Adaptability</td><td>Limited</td><td>High</td></tr></table>\n\nTABLE IV CASE STUDY: PERFORMANCE COMPARISON OFchatGPT AND DEEPSEEK MULTIPLE CHOICE QUESTIONS ACROSS VARIOUS DOMAINS  \n\n<table><tr><td rowspan=\"2\">Domain</td><td rowspan=\"2\">Total Questions</td><td colspan=\"2\">ChatGPT</td><td colspan=\"2\">DeepSeek</td></tr><tr><td>Total Correct</td><td>Accuracy (%)</td><td>Total Correct</td><td>Accuracy (%)</td></tr><tr><td>Tourism</td><td>100</td><td>53</td><td>53%</td><td>85</td><td>85%</td></tr><tr><td>Psychology</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physics</td><td>50</td><td>43</td><td>86%</td><td>46</td><td>92%</td></tr><tr><td>Mechanical</td><td>50</td><td>39</td><td>78%</td><td>39</td><td>78%</td></tr><tr><td>Mathematics</td><td>53</td><td>43</td><td>81%</td><td>53</td><td>100%</td></tr><tr><td>English</td><td>101</td><td>64</td><td>63%</td><td>78</td><td>77%</td></tr><tr><td>CSE</td><td>50</td><td>49</td><td>98%</td><td>48</td><td>96%</td></tr><tr><td>ECE</td><td>55</td><td>48</td><td>87%</td><td>50</td><td>90%</td></tr><tr><td>Botany</td><td>50</td><td>50</td><td>100%</td><td>48</td><td>96%</td></tr><tr><td>Biotechnology</td><td>100</td><td>74</td><td>74%</td><td>90</td><td>90%</td></tr><tr><td>Computer Applications</td><td>50</td><td>40</td><td>80%</td><td>44</td><td>88%</td></tr><tr><td>Electrical Engineering</td><td>55</td><td>46</td><td>84%</td><td>49</td><td>89%</td></tr><tr><td>Law</td><td>50</td><td>45</td><td>90%</td><td>42</td><td>84%</td></tr><tr><td>Civil</td><td>51</td><td>46</td><td>90%</td><td>45</td><td>88%</td></tr><tr><td>Commerce</td><td>50</td><td>42</td><td>84%</td><td>49</td><td>98%</td></tr><tr><td>Mass Communication</td><td>50</td><td>47</td><td>94%</td><td>40</td><td>80%</td></tr><tr><td>Chemistry</td><td>50</td><td>27</td><td>54%</td><td>37</td><td>74%</td></tr><tr><td>Economics</td><td>50</td><td>50</td><td>100%</td><td>50</td><td>100%</td></tr><tr><td>Physiotherapy</td><td>64</td><td>63</td><td>98%</td><td>63</td><td>98%</td></tr><tr><td>Optometry</td><td>50</td><td>45</td><td>90%</td><td>49</td><td>98%</td></tr><tr><td>Pharma Sciences</td><td>50</td><td>36</td><td>72%</td><td>32</td><td>64%</td></tr><tr><td>Education</td><td>100</td><td>57</td><td>57%</td><td>75</td><td>75%</td></tr><tr><td>Business Management</td><td>50</td><td>41</td><td>82%</td><td>42</td><td>84%</td></tr><tr><td>Nutrition and Diet</td><td>50</td><td>42</td><td>84%</td><td>41</td><td>82%</td></tr><tr><td>Total</td><td>1429</td><td>1140</td><td>79%</td><td>1245</td><td>87%</td></tr></table>\n\ncritical, emphasizing the establishment of global standards for fairness, transparency, and bias mitigation. Finally, human-AI collaboration is an emerging field that explores ways to enhance synergy between humans and AI, particularly in creative and decision-making processes. These research directions will shape the future of AI, making systems more efficient, accurate, interactive, and ethically responsible.\n\n# VI. CONCLUSION\n\nThe evolution from ChatGPT to DeepSeek AI represents a significant milestone in the development of conversational AI. By addressing the limitations of ChatGPT and introducing innovative features, DeepSeek AI sets a new standard for\n\nperformance, efficiency, and ethical responsibility. Our comparative evaluation also highlights DeepSeek AI's superior performance across multiple domains. As AI continues to evolve, maintaining a focus on transparency, fairness, and responsible development is essential to maximize its social benefits. Future researchers and developers in this field should explore techniques for improving contextual understanding, reducing biases, and optimizing AI efficiency for real-world applications. Furthermore, advances in interpretability and human-AI collaboration will be crucial in making AI systems more reliable and beneficial. The improvements and innovations explored in this paper outline a clear path for future research and progress in artificial intelligence.\n\n# REFERENCES\n\n[1] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. Ai in health and medicine. Nature medicine, 28(1):31-38, 2022.  \n[2] Kevin B Johnson, Wei-Qi Wei, Dilhan Weeraratne, Mark E Frisse, Karl Misulis, Kyu Rhee, Juan Zhao, and Jane L Snowdon. Precision medicine, ai, and the future of personalized health care. Clinical and translational science, 14(1):86-93, 2021.  \n[3] Mohsen Soori, Behrooz Arezoo, and Roza Dastres. Artificial intelligence, machine learning and deep learning in advanced robotics, a review. Cognitive Robotics, 3:54-70, 2023.  \n[4] Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T Martin McGinnity, and JÃ¶rn Mehnen. The challenges and opportunities of human-centered ai for trustworthy robots and autonomous systems. IEEE Transactions on Cognitive and Developmental Systems, 14(4):1398-1412, 2021.  \n[5] Longbing Cao. Ai in finance: challenges, techniques, and opportunities. ACM Computing Surveys (CSUR), 55(3):1-38, 2022.  \n[6] Arash Bahrammirzaee. A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems. Neural Computing and Applications, 19(8):1165-1195, 2010.  \n[7] MZ Naser and Amir H Alavi. Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences. Architecture, Structures and Construction, 3(4):499-517, 2023.  \n[8] Nurullah YÃ¼ksel, HÃ¼seyin RÄ±za BÃ¶rklÃ¼, HÃ¼seyin KÃ¼rÅŸad Sezer, and Olcay Ersel Canyurt. Review of artificial intelligence applications in engineering design perspective. Engineering Applications of Artificial Intelligence, 118:105697, 2023.  \n[9] Ramanpreet Kaur, DuÅ¡an GabrijelÄiÄ‡, and Tomaz Klobuchar. Artificial intelligence for cybersecurity: Literature review and future research directions. Information Fusion, 97:101804, 2023.  \n[10] Haru Hong Khanh and Alex Khang. The role of artificial intelligence in blockchain applications. In Reinventing Manufacturing and Business Processes through Artificial Intelligence, pages 19-38. CRC Press, 2021.  \n[11] A Subeesh and CR Mehta. Automation and digitization of agriculture using artificial intelligence and internet of things. Artificial Intelligence in Agriculture, 5:278-291, 2021.  \n[12] Kirtan Jha, Aalap Doshi, Poojan Patel, and Manan Shah. A comprehensive review on automation in agriculture using artificial intelligence. Artificial Intelligence in Agriculture, 2:1-12, 2019.  \n[13] Abhijit Guha, Dhruv Grewal, Praveen K Kopalle, Michael Hoenlein, Matthew J Schneider, Hyunseok Jung, Rida Moustafa, Dinesh R Hegde, and Gary Hawkins. How artificial intelligence will affect the future of retailing. Journal of Retailing, 97(1):28-41, 2021.  \n[14] Lasha Labadze, Maya Grigolia, and Lela Machaidze. Role of ai chatbots in education: systematic literature review. International Journal of Educational Technology in Higher Education, 20(1):56, 2023.  \n[15] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. Chatgpt and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5):570-581, 2023.  \n[16] Chandan K Sahu, Crystal Young, and Rahul Rai. Artificial intelligence (ai) in augmented reality (ar)-assisted manufacturing applications: a review. International journal of production research, 59(16):4903-4959, 2021.  \n[17] Bo-hu Li, Bao-cun Hou, Wen-tao Yu, Xiao-bing Lu, and Chun-wei Yang. Applications of artificial intelligence in intelligent manufacturing: a review. Frontiers of Information Technology & Electronic Engineering, 18(1):86-96, 2017.  \n[18] Giri Gandu Hallur, Sandeep Prabhu, and Avinash Aslekar. Entertainment in era of ai, big data & iot. Digital Entertainment: The Next Evolution in Service Sector, pages 87-109, 2021.  \n[19] Sen Li, Feng Yuan, and Jianye Liu. Smart city vr landscape planning and user virtual entertainment experience based on artificial intelligence. Entertainment Computing, 51:100743, 2024.  \n[20] Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, and John Krogstie. Artificial intelligence and business value: A literature review. Information Systems Frontiers, 24(5):1709-1734, 2022.  \n[21] Ming-Hui Huang and Roland T Rust. A strategic framework for artificial intelligence in marketing. Journal of the academy of marketing science, 49:30-50, 2021.  \n[22] Mathias-Felipe de Lima-Santos and Wilson Ceron. Artificial intelligence in news media: current perceptions and future outlook. Journalism and media, 3(1):13-26, 2021.\n\n[23] Fabia Ioscote, Adriana GonÃ§alves, and Claudia Quadros. Artificial intelligence in journalism: A ten-year retrospective of scientific articles (2014-2023). Journalism and Media, 5(3):873-891, 2024.  \n[24] Fei-Yue Wang, Yilun Lin, Petros A Ioannou, Ljubo Vlacic, Xiaoming Liu, Azim Eskandarian, Yisheng Lv, Xiaoxiang Na, David Cebon, Jiaqi Ma, et al. Transportation 5.0: The dao to safe, secure, and sustainable intelligent transportation systems. IEEE Transactions on Intelligent Transportation Systems, 24(10):10262-10278, 2023.  \n[25] Rusul Abduljabbar, Hussein Dia, Sohani Liyanage, and Saeed Asadi Bagloee. Applications of artificial intelligence in transport: An overview. Sustainability, 11(1):189, 2019.  \n[26] Daniel W Otter, Julian R Medina, and Jugal K Kalita. A survey of the usages of deep learning for natural language processing. IEEE transactions on neural networks and learning systems, 32(2):604-624, 2020.  \n[27] Hobson Lane and Maria Dyshel. Natural language processing in action. Simon and Schuster, 2025.  \n[28] Joseph Weizenbaum. Elizaâ€”a computer program for the study of natural language communication between man and machine. Communications of the ACM, 9(1):36-45, 1966.  \n[29] Terry Winograd. Procedures as a representation for data in a computer program for understanding natural language. Technical Report AIM-235, MIT Artificial Intelligence Laboratory, 1971.  \n[30] GÃ¼ven GÃ¼zeldere and Stefano Franchi. Dialogues with colorful â€œpersonalitiesâ€ of early ai. Stanford Humanities Review, 4(2):161-169, 1995.  \n[31] John Foderaro. Lisp: introduction. Communications of the ACM, 34(9):27, 1991.  \n[32] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.  \n[33] Lawrence Rabiner and Biinghwang Juang. An introduction to hidden markov models. *ieee assp magazine*, 3(1):4-16, 1986.  \n[34] Thomas K Landauer, Peter W Foltz, and Darrell Lahan. An introduction to latent semantic analysis. Discourse processes, 25(2-3):259-284, 1998.  \n[35] Dan Jurafsky. Speech & language processing. Pearson Education India, 2000.  \n[36] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. Advances in neural information processing systems, 34:15908-15919, 2021.  \n[37] Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah. Transformers in vision: A survey. ACM computing surveys (CSUR), 54(10s):1-41, 2022.  \n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumont, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtopicz, et al. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, pages 38-45, 2020.  \n[39] Anthony Gillioz, Jacky Casas, Elena Mugellini, and Omar Abou Khaled. Overview of the transformer-based models for nlp tasks. In 2020 15th Conference on computer science and information systems (FedCSIS), pages 179-183. IEEE, 2020.  \n[40] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \n[41] Luciano Floridi and Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines*, 30:681â€“694, 2020.  \n[42] Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt understands, too. AI Open, 5:208-215, 2024.  \n[43] A Vaswani. Attention is all you need. Advances in Neural Information Processing Systems, 2017.  \n[44] Sneha Chaudhari, Varun Mithal, Gungor Polatkan, and Rohan Ramanath. An attentive survey of attention models. ACM Transactions on Intelligent Systems and Technology (TIST), 12(5):1-32, 2021.  \n[45] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo, Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. Towards artificial general intelligence via a multimodal foundation model. Nature Communications, 13(1):3094, 2022.  \n[46] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022.  \n[47] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\n\n[48] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024.  \n[49] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM transactions on intelligent systems and technology, 15(3):1-45, 2024.  \n[50] Zijing Liang, Yanjie Xu, Yifan Hong, Penghui Shang, Qi Wang, Qiang Fu, and Ke Liu. A survey of multimodel large language models. In Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering, pages 405-409, 2024.  \n[51] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence, 39(12):2481-2495, 2017.  \n[52] Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles L Isbell, and Andrea L Thomaz. Policy shaping: Integrating human feedback with reinforcement learning. Advances in neural information processing systems, 26, 2013.  \n[53] Alex Sherstinsky. Fundamentals of recurrent neural network (rnn) and long short-term memory (lstm) network. Physica D: Nonlinear Phenomena, 404:132306, 2020.  \n[54] Sepp Hochreiter. The vanishing gradient problem during learning recurrent neural nets and problem solutions. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02):107-116, 1998.  \n[55] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Technical report, OpenAI, San Francisco, CA, USA, 2018.  \n[56] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.  \n[57] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems, 32(1):4-24, 2020.  \n[58] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR, 2016.  \n[59] Jianping Gou, Baosheng Yu, Stephen J Maybank, and Dacheng Tao. Knowledge distillation: A survey. International Journal of Computer Vision, 129(6):1789-1819, 2021.  \n[60] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.  \n[61] Sajid Ali, Tamer Abuhmed, Shaker El-Sappagh, Khan Muhammad, Jose M Alonso-Moral, Roberto Confalonieri, Riccardo Guidotti, Javier Del Ser, Natalia Diaz-Rodriguez, and Francisco Herrera. Explainable artificial intelligence (xai): What we know and what is left to attain trustworthy artificial intelligence. Information fusion, 99:101805, 2023.  \n[62] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9):1-33, 2023.  \n[63] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.  \n[64] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135-1144, 2016.  \n[65] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC conference on computer and communications security, pages 308-318, 2016.  \n[66] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017.",
        "location": "",
        "analyzed_at": "2025-12-16T13:21:54.288265"
      }
    },
    "wb-f67660e4": {
      "id": "wb-f67660e4",
      "type": "method",
      "title": "é¢„æ³¨å†Œéšæœºå¯¹ç…§å®éªŒï¼ˆç»“åˆç»„å†…ä¸ç»„é—´è®¾è®¡ï¼‰",
      "description": "é€šè¿‡é¢„æ³¨å†Œçš„éšæœºå¯¹ç…§å®éªŒï¼Œåœ¨çœŸå®å­¦æ ¡ç¯å¢ƒä¸­æ¯”è¾ƒå•ç‹¬ä½¿ç”¨LLMã€ä¼ ç»Ÿç¬”è®°ä»¥åŠä¸¤è€…ç»“åˆå¯¹ä¸­å­¦ç”Ÿé˜…è¯»ç†è§£ä¸è®°å¿†çš„å½±å“ï¼Œå¹¶é‡‡ç”¨å®šé‡ä¸å®šæ€§ç›¸ç»“åˆçš„æ··åˆæ–¹æ³•è¿›è¡Œåˆ†æã€‚",
      "source_paper_id": "659fea70-f22c-4b54-9382-aa768ec096e8",
      "zone": "methods",
      "created_at": "2025-12-16T13:37:14.805824",
      "data": {
        "analysis": {
          "method_name": "é¢„æ³¨å†Œéšæœºå¯¹ç…§å®éªŒï¼ˆç»“åˆç»„å†…ä¸ç»„é—´è®¾è®¡ï¼‰",
          "method_type": "æµç¨‹",
          "core_idea": "é€šè¿‡é¢„æ³¨å†Œçš„éšæœºå¯¹ç…§å®éªŒï¼Œåœ¨çœŸå®å­¦æ ¡ç¯å¢ƒä¸­æ¯”è¾ƒå•ç‹¬ä½¿ç”¨LLMã€ä¼ ç»Ÿç¬”è®°ä»¥åŠä¸¤è€…ç»“åˆå¯¹ä¸­å­¦ç”Ÿé˜…è¯»ç†è§£ä¸è®°å¿†çš„å½±å“ï¼Œå¹¶é‡‡ç”¨å®šé‡ä¸å®šæ€§ç›¸ç»“åˆçš„æ··åˆæ–¹æ³•è¿›è¡Œåˆ†æã€‚",
          "innovation_points": [
            "åœ¨æ•™è‚²æŠ€æœ¯ç ”ç©¶ä¸­å¼•å…¥é¢„æ³¨å†Œéšæœºå¯¹ç…§å®éªŒï¼Œå¢å¼ºäº†ç ”ç©¶çš„ä¸¥è°¨æ€§å’Œé€æ˜åº¦ã€‚",
            "ç»“åˆäº†ç»„å†…ä¸ç»„é—´è®¾è®¡å…ƒç´ ï¼Œå…è®¸åœ¨åŒä¸€ç ”ç©¶ä¸­æ§åˆ¶ä¸ªä½“å·®å¼‚å¹¶æ¯”è¾ƒå¤šç§å¹²é¢„æªæ–½ã€‚",
            "åœ¨çœŸå®ä¸­å­¦è¯¾å ‚ç¯å¢ƒä¸­ç ”ç©¶LLMå¯¹å¹´è½»å­¦ä¹ è€…çš„å½±å“ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºé«˜ç­‰æ•™è‚²çš„ç©ºç™½ã€‚"
          ],
          "implementation_steps": [
            "æ‹›å‹Ÿ405å14-15å²çš„ä¸­å­¦ç”Ÿä½œä¸ºå‚ä¸è€…ã€‚",
            "è®¾è®¡å®éªŒï¼šå‚ä¸è€…å­¦ä¹ ä¸¤ç¯‡æ–‡æœ¬æ®µè½ï¼Œå¹¶åœ¨ä¸‰å¤©åå®Œæˆç†è§£ä¸è®°å¿†æµ‹è¯•ã€‚",
            "éšæœºåˆ†é…å‚ä¸è€…åˆ°ä¸åŒçš„å¹²é¢„æ¡ä»¶ï¼ˆå¦‚ï¼šä»…ä½¿ç”¨LLMã€ä»…åšç¬”è®°ã€ä¸¤è€…ç»“åˆï¼‰ã€‚",
            "å®æ–½é¢„æ³¨å†Œæ–¹æ¡ˆï¼Œç¡®ä¿æ•°æ®åˆ†æè®¡åˆ’çš„é€æ˜æ€§ã€‚",
            "æ”¶é›†å®šé‡æ•°æ®ï¼ˆæµ‹è¯•æˆç»©ï¼‰å’Œå®šæ€§æ•°æ®ï¼ˆå­¦ç”Ÿåå¥½ã€æ„ŸçŸ¥å¸®åŠ©æ€§ã€æç¤ºè¡Œä¸ºï¼‰ã€‚",
            "è¿›è¡Œå®šé‡ç»Ÿè®¡åˆ†æï¼ˆå¦‚æ¯”è¾ƒç»„é—´å·®å¼‚çš„æ˜¾è‘—æ€§ï¼‰å’Œå®šæ€§åˆ†æï¼ˆå¦‚è¯†åˆ«æç¤ºè¡Œä¸ºçš„â€œåŸå‹â€ï¼‰ã€‚"
          ],
          "key_formulas": [],
          "reviewer_comments": {
            "strengths": [
              "æ–¹æ³•è®¾è®¡ä¸¥è°¨ï¼Œé‡‡ç”¨é¢„æ³¨å†Œå’Œéšæœºå¯¹ç…§å®éªŒï¼Œèƒ½æœ‰æ•ˆæ§åˆ¶æ··æ‚å˜é‡ï¼Œå› æœæ¨æ–­åŠ›å¼ºã€‚",
              "ç ”ç©¶åœºæ™¯å…·æœ‰é«˜ç”Ÿæ€æ•ˆåº¦ï¼Œåœ¨çœŸå®å­¦æ ¡ç¯å¢ƒä¸­è¿›è¡Œï¼Œç»“æœæ›´å…·ç°å®æŒ‡å¯¼æ„ä¹‰ã€‚",
              "é‡‡ç”¨æ··åˆç ”ç©¶æ–¹æ³•ï¼Œç»“åˆå®šé‡ç»“æœä¸å®šæ€§æ´å¯Ÿï¼Œå¯¹ç°è±¡çš„è§£é‡Šæ›´ä¸ºå…¨é¢å’Œæ·±å…¥ã€‚"
            ],
            "weaknesses": [
              "æ‘˜è¦æœªæä¾›å…·ä½“çš„éšæœºåŒ–æ–¹æ³•ã€ç›²æ³•å®æ–½ç»†èŠ‚åŠç»Ÿè®¡æ£€éªŒçš„å…·ä½“æ–¹æ³•ï¼ˆå¦‚ANOVAæˆ–tæ£€éªŒï¼‰ï¼Œå¯é‡å¤æ€§è¯„ä¼°å—é™ã€‚",
              "â€œä¸‰å¤©åâ€çš„å»¶è¿Ÿæµ‹è¯•å¯èƒ½æ— æ³•å……åˆ†æ•æ‰â€œé•¿æœŸâ€è®°å¿†æ•ˆæœï¼Œå¯¹â€œé•¿æœŸâ€çš„å®šä¹‰å’Œæµ‹é‡æœ‰å¾…å•†æ¦·ã€‚",
              "ç ”ç©¶å¯èƒ½å—åˆ°éœæ¡‘æ•ˆåº”æˆ–ç¤¾ä¼šæœŸæœ›åå·®çš„å½±å“ï¼Œå­¦ç”ŸçŸ¥é“è‡ªå·±åœ¨è¢«ç ”ç©¶ï¼Œå¯èƒ½æ”¹å˜å…¶è‡ªç„¶è¡Œä¸ºã€‚"
            ],
            "questions": [
              "éšæœºåŒ–æ˜¯å¦‚ä½•å…·ä½“å®æ–½çš„ï¼Ÿæ˜¯å­¦ç”Ÿä¸ªä½“éšæœºåŒ–ï¼Œè¿˜æ˜¯ä»¥ç­çº§ä¸ºå•ä½è¿›è¡Œæ•´ç¾¤éšæœºåŒ–ï¼Ÿ",
              "åœ¨â€œä¸¤è€…ç»“åˆâ€çš„æ¡ä»¶ä¸‹ï¼Œå­¦ç”Ÿä½¿ç”¨LLMå’Œåšç¬”è®°çš„å…·ä½“é¡ºåºã€æ—¶é•¿å’Œäº’åŠ¨æ–¹å¼æ˜¯å¦‚ä½•è§„å®šå’Œæ§åˆ¶çš„ï¼Ÿ",
              "å¯¹äºå®šæ€§åˆ†æä¸­è¯†åˆ«çš„â€œæç¤ºè¡Œä¸ºåŸå‹â€ï¼Œå…¶ç¼–ç æ¡†æ¶ã€ä¿¡åº¦æ£€éªŒè¿‡ç¨‹ä»¥åŠåˆ†æè€…çš„ç‹¬ç«‹æ€§å¦‚ä½•ï¼Ÿ"
            ],
            "suggestions": [
              "åœ¨è®ºæ–‡æ–¹æ³•éƒ¨åˆ†è¯¦ç»†è¯´æ˜éšæœºåŒ–ä¸åˆ†é…éšè—çš„å…·ä½“æµç¨‹ï¼Œå¹¶æŠ¥å‘ŠåŸºçº¿ç‰¹å¾çš„å¹³è¡¡æ€§æ£€éªŒã€‚",
              "è€ƒè™‘å¢åŠ æ›´é•¿æœŸçš„éšè®¿æµ‹è¯•ï¼ˆå¦‚ä¸€å‘¨æˆ–ä¸€ä¸ªæœˆåï¼‰ï¼Œä»¥æ›´ç¨³å¥åœ°è¯„ä¼°è®°å¿†çš„ä¿æŒæ•ˆæœã€‚",
              "åœ¨è®¨è®ºéƒ¨åˆ†æ›´æ·±å…¥åœ°æ¢è®¨å­¦ç”Ÿâ€œåå¥½â€ä¸â€œå®é™…æ•ˆæœâ€åˆ†ç¦»ç°è±¡çš„å¯èƒ½åŸå› ï¼ˆå¦‚å…ƒè®¤çŸ¥é”™è§‰ã€è®¤çŸ¥è´Ÿè·è½¬ç§»ç­‰ï¼‰ã€‚"
            ]
          },
          "reproducibility_score": 8,
          "pseudocode": "# å®éªŒæµç¨‹ä¼ªä»£ç \n1. åˆå§‹åŒ–: æ‹›å‹ŸN=405åä¸­å­¦ç”Ÿï¼Œå‡†å¤‡æ–‡æœ¬ææ–™Aå’ŒBï¼Œè®¾è®¡æµ‹è¯•é¢˜ï¼Œé¢„æ³¨å†Œåˆ†æè®¡åˆ’ã€‚\n2. éšæœºåˆ†é…: å°†å‚ä¸è€…éšæœºåˆ†é…åˆ°å®éªŒæ¡ä»¶ï¼ˆå¦‚ï¼šæ¡ä»¶1: ä»…LLMï¼›æ¡ä»¶2: ä»…ç¬”è®°ï¼›æ¡ä»¶3: LLM+ç¬”è®°ï¼‰ã€‚\n3. å­¦ä¹ é˜¶æ®µ: For æ¯ä¸ªå‚ä¸è€… in æ‰€æœ‰å‚ä¸è€…:\n    a. åœ¨æŒ‡å®šæ¡ä»¶ä¸‹å­¦ä¹ æ–‡æœ¬Aã€‚\n    b. ï¼ˆæ ¹æ®è®¾è®¡ï¼‰å¯èƒ½åœ¨å­¦ä¹ æ–‡æœ¬Bæ—¶åˆ‡æ¢æ¡ä»¶ï¼ˆç»„å†…å…ƒç´ ï¼‰ã€‚\n4. å»¶è¿Ÿæµ‹è¯•: ç­‰å¾…3å¤©åï¼Œå¯¹æ‰€æœ‰å‚ä¸è€…è¿›è¡Œé˜…è¯»ç†è§£ä¸è®°å¿†æµ‹è¯•ã€‚\n5. æ•°æ®æ”¶é›†: æ”¶é›†æµ‹è¯•æˆç»©ï¼ˆå®šé‡ï¼‰ï¼Œå¹¶é€šè¿‡é—®å·/è®¿è°ˆæ”¶é›†å¯¹å·¥å…·åå¥½å’Œæ„ŸçŸ¥çš„å®šæ€§æ•°æ®ã€‚\n6. æ•°æ®åˆ†æ: \n    a. å®šé‡åˆ†æ: æ¯”è¾ƒä¸åŒæ¡ä»¶é—´çš„æµ‹è¯•æˆç»©å·®å¼‚ï¼ˆå¦‚ä½¿ç”¨æ–¹å·®åˆ†æï¼‰ã€‚\n    b. å®šæ€§åˆ†æ: å¯¹å¼€æ”¾å¼å›ç­”è¿›è¡Œä¸»é¢˜åˆ†æï¼Œè¯†åˆ«è¡Œä¸ºåŸå‹ã€‚\n7. è¾“å‡º: ç»¼åˆå®šé‡ä¸å®šæ€§ç»“æœï¼Œå¾—å‡ºç»“è®ºä¸å¯ç¤ºã€‚"
        },
        "original_text": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentr",
        "location": "",
        "analyzed_at": "2025-12-16T13:37:14.805761"
      }
    },
    "wb-850ade73": {
      "id": "wb-850ade73",
      "type": "code",
      "title": "å®éªŒä»£ç ä»“åº“",
      "description": "è®ºæ–‡ä¸­å®éªŒä½¿ç”¨çš„Webåº”ç”¨ç¨‹åºä»£ç ä»“åº“ï¼ŒåŒ…å«å‰ç«¯ç•Œé¢å’Œåç«¯é€»è¾‘ï¼Œç”¨äºåœ¨å­¦æ ¡ç¯å¢ƒä¸­è¿›è¡Œéšæœºå¯¹ç…§å®éªŒã€‚",
      "source_paper_id": "659fea70-f22c-4b54-9382-aa768ec096e8",
      "zone": "datasets",
      "created_at": "2025-12-16T13:37:44.583835",
      "data": {
        "asset": {
          "name": "å®éªŒä»£ç ä»“åº“",
          "type": "code",
          "url": "github.com",
          "platform": "GitHub",
          "description": "è®ºæ–‡ä¸­å®éªŒä½¿ç”¨çš„Webåº”ç”¨ç¨‹åºä»£ç ä»“åº“ï¼ŒåŒ…å«å‰ç«¯ç•Œé¢å’Œåç«¯é€»è¾‘ï¼Œç”¨äºåœ¨å­¦æ ¡ç¯å¢ƒä¸­è¿›è¡Œéšæœºå¯¹ç…§å®éªŒã€‚",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ç”¨äºæ„å»ºå®éªŒå¹³å°ï¼Œå­¦ç”Ÿé€šè¿‡æµè§ˆå™¨è®¿é—®è¯¥åº”ç”¨å®Œæˆå­¦ä¹ ä»»åŠ¡å’Œæµ‹è¯•ã€‚",
          "verified": false,
          "stars": null
        },
        "original_text": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning â€“ understanding and retaining information â€“ remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately â€”through semantic analysis involving meaning, inferences, and implicationsâ€” can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies â€“ note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-takingâ€”whether done alone or alongside LLM usageâ€”produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learningâ€”offering opportunities to clarify, explore, and contextualise materialâ€”but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot â‘¡\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 â€“ upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. AleksiÄ‡-Maslac, F. BoroviÄ‡, and Z. BioÄina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan KÃ¼chemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan GÃ¼nnmann, Eyke HÃ¼llermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, JÃ¼rgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434â€“442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163â€“182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162â€“185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371â€“395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias NÃ¼ckles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 Ã— 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 Ã— 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 Ã— 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 Ã— 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 Ã— 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 Ã— 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 Ã— 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 Ã— 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 Ã— 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 Ã— 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 Ã— 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 Ã— 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 Ã— 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (â‰¥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (â‰¥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\nÂ· figuring out what the main ideas and concepts in the text are,\nÂ· what they mean,\nÂ· how they relate to each other, and\nÂ· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\nÂ· The meaning of important words and concepts\nÂ· The meaning of complex sentences\nÂ· The key points or ideas, such as the dates, places, people and events\nÂ· The connections between places, people and events\nÂ· What happened, and why and how it happened\nÂ· Similarities and differences between ideas and concepts\nÂ· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\nYou can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\n You can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 Ã— 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 Ã— 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 Ã— 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 Ã— 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 Ã— 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 Ã— 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 Ã— 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 Ã— 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 Ã— 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 Ã— 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 Ã— 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 Ã— 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 Ã— 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 Ã— 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 Ã— 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 Ã— 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 Ã— 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 Ã— 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 Ã— 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 Ã— 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 Ã— 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 Ã— 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 Ã— 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 Ã— 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 Ã— 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 Ã— 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 Ã— 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>â€œIt took less time to use the LLMâ€, â€œNotes take too much time.â€</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>â€œThe note-taking seemedunnec-\nsessary as the bot already helped explainâ€, â€œUsing one sort of meant I didnâ€™t need the other.â€</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you donâ€™t have to do the work your-\nself. The task becomes easier if you donâ€™t have to take notes.</td><td>â€œDidnâ€™t have to do any workâ€, â€œClarify any information I didnâ€™t know immediately without hav-\ning to scour the textâ€, â€œIt was difficult to take notes at the same time as using the chatbot.â€</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>â€œI didnâ€™t have enough time to ask as many questions when taking notesâ€, â€œI had more time to un-\nderstand the text.â€</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.â€</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>â€œLess time-consumingâ€, â€œMuch quicker.â€</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>â€œMore simpleâ€, â€œIt was easier.â€</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>â€œActively engaging with the botâ€, â€œFelt more interactive.â€</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>â€œEnjoyed reading its responsesâ€, â€œMore fun to use.â€</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>â€œAllowed me to focus more on the text.â€</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>â€œIt gives you a better understandingâ€, â€œI could confirm anything I was unsure of to ensure I understood it.â€</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>â€œThe AI helped me to learn more efficientlyâ€, â€œI was able to understand and learn the text a lot easier and quicker at a higher level.â€</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you donâ€™t understand.</td><td>â€œAsk any relevant questionsâ€, â€œIf I had a question, it could answer it.â€</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>â€œI was given more backgroundâ€, â€œIt gives me the full context.â€</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>â€œIt puts it in a simpler way and formâ€, â€œI can ask the AI chatbot to rephrase key pointsâ€, â€œIt can summarise key points.â€</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>â€œIt has stuck in my head moreâ€, â€œGiving me prompt questions, mnemonics, etc., which helped me rememberâ€, â€œTook less time to memorise than note-taking.â€</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>â€œI can remember things better when I write them downâ€, â€œMore helpful for developing recallâ€, â€œI learned more with note-takingâ€, â€œJust gave more background, rather than consolidating the knowledge.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>â€œIt was easier for me to understand what I was readingâ€, â€œI was understanding it moreâ€, â€œTest what you have learned by paraphrasing.â€</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>â€œBetter active readingâ€, â€œAllows me to actively engage.â€</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>â€œYou have to personally analyse itâ€, â€œI could condense the information into my own wordsâ€, â€œMade me think for myselfâ€, â€œIt is your view on the matter you are looking atâ€, â€œAlows me to feel proud of my work in the future.â€</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>â€œI was able to break down and process the textâ€, â€œSummarising the second text myself helped me to process the information.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œI am able to write down my own knowledge of what I had learnedâ€, â€œI could actually learn the information rather than being told it.â€</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>â€œI can come back to these notes at a later date if I am doing revisionâ€, â€œNote-taking gives you something better to look back on in future.â€</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>â€œEasier to summariseâ€, â€œIDK, easier.â€</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>â€œIt is easy to organise my notesâ€, â€œIt is easier to keep track of your train of thoughtsâ€, â€œHelped me to break down the text into smaller chunks.â€</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>â€œI found myself easily distracted by the AI and was more tempted to ask random questionsâ€, â€œItâ€™s not clear as it gives too much information.â€</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>â€œIt felt that it was just repeating it-self.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>â€œI struggled to think of questions to ask the AIâ€, â€œThe text was very easy therefore didnâ€™t feel the need to ask many questions.â€</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>â€œI enjoy using both at the same timeâ€, â€œIf I had to use the chatbot and ask it 20 questions, I would be very bored.â€</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>â€œIt was easier to have my key notes summarised as well as text with more detailâ€, â€œIt allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isnâ€™t clear.â€</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>â€œMost helpful and easy to learnâ€, â€œBecause I find it easier to remember and learn this way.â€</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>â€œIn order for me to process this, I find note-taking at the same time very helpful.â€</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>â€œIf I am only using the chatbot, then I have to scroll up to find what I am looking forâ€, â€œIt was easier to keep track of things and go back over them.â€</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>â€œIt meant I was doing actual work.â€</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>â€œI like to write out information as I think it helps me remember it better.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>â€œSimplifying it on paper made it easier to understand and remember.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œYou learn moreâ€, â€œYou can simplify what you have learnt in the notes.â€</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>â€œSome of the questions I had for the bot were not answered explicitly.â€</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>â€œYou will not get an AI chatbot at all times.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>â€œI wasnâ€™t sure what I was supposed to say to the bot. It was just kinda irritating.â€</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: â€œHelp me to summarise this paragraphâ€, â€œSummarise the textâ€, â€œGive me a summary of the first paragraphâ€, â€œTell me what this text is about.â€</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: â€œMake notes for the first paragraph.â€</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: â€œWhat are the main points?â€, â€œGive me all the important datesâ€, â€œWhatâ€™s the takeaway message?â€</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: â€œPut the important dates into chronological orderâ€, â€œGive me a timeline of the events.â€</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: â€œWhat does apartheid mean?â€, â€œWhat is a colony?â€, â€œWhat is a missile?â€, â€œI donâ€™t know what a blockade is.â€</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: â€œExplain this in simple wordsâ€, â€œMake the text simplerâ€, â€œWhat does this sentence mean?â€, â€œSimplify this text.â€</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: â€œThe US did not like Cuba because they thought that Castro was a communist, right?â€, â€œSo it was one officer that prevented the whole war?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide contextâ€”information that is not too central for understanding the text but could be relevant.\nExamples: â€œWho was Kennedy?â€, â€œWhat was Mandela famous for?â€, â€œTell me more about Cubaâ€, â€œHow many British colonies were there in Africa?â€, â€œWhere were the Turkish missiles located?â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: â€œWhy did the US not like Castro?â€, â€œWhy did the exiles invade Cuba?â€, â€œHow did black people feel during apartheid?â€</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: â€œWhat are examples of how apartheid affected daily life?â€, â€œIs there an analogy that explains the Cold War tensions?â€, â€œWhat unfair laws were passed?â€, â€œWhat were some of the boycotts?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: â€œHow is apartheid different from segregation in the US?â€, â€œCompare Kennedy and Khrushchev&#x27;s leadership styles.â€</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: â€œWhat are the strengths and weaknesses of Kennedy&#x27;s decision?â€, â€œEvaluate the effectiveness of the blockade.â€</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: â€œWhat were the long-term effects of the crisis?â€, â€œWhat is the situation like now?â€, â€œWhy should I care or learn about this?â€</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: â€œMake a mnemonicâ€, â€œWrite four questions about the textâ€, â€œHow can I remember this better?â€</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: â€œSummarize the main points in bullet pointsâ€, â€œCan you create a chart of the different policies?â€, â€œUse only a few wordsâ€, â€œMake it short.â€</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: â€œI donâ€™t understand what you saidâ€, â€œExplain that again but shorterâ€, â€œWhat do you mean?â€,\nâ€œSimpler pleaseâ€, â€œCan you write that in simpler terms?â€, â€œMake the summary shorter.â€</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: â€œHow are you?â€, â€œThank youâ€, â€œHello.â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: â€œWhat are your sources?â€, â€œWhy should I believe you?â€, â€œI think your answer is wrong.â€</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: â€œNelson Mandelaâ€, â€œIn 1910, four British colonies joined to create the Union of South Africaâ€, â€œMissile.â€</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: â€œWho is Che Guevara?â€, â€œWhat is the song Abraxas?â€</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that donâ€™t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: â€œasdfghâ€, â€œ.â€, â€œ123â€, â€œ???â€</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
        "location": "",
        "analyzed_at": "2025-12-16T13:37:44.583776"
      }
    },
    "wb-8b278cd9": {
      "id": "wb-8b278cd9",
      "type": "code",
      "title": "GPT-3.5 Turbo (Azure-hosted)",
      "description": "é€šè¿‡Azureæ‰˜ç®¡çš„OpenAI GPT-3.5 Turboæ¨¡å‹å®ä¾‹ï¼Œç”¨äºæä¾›å®éªŒä¸­çš„LLMèŠå¤©åŠŸèƒ½ã€‚",
      "source_paper_id": "659fea70-f22c-4b54-9382-aa768ec096e8",
      "zone": "datasets",
      "created_at": "2025-12-16T13:37:44.613704",
      "data": {
        "asset": {
          "name": "GPT-3.5 Turbo (Azure-hosted)",
          "type": "model",
          "url": "https://azure.microsoft.com/en-us/products/ai-services/openai-service",
          "platform": "Azure OpenAI",
          "description": "é€šè¿‡Azureæ‰˜ç®¡çš„OpenAI GPT-3.5 Turboæ¨¡å‹å®ä¾‹ï¼Œç”¨äºæä¾›å®éªŒä¸­çš„LLMèŠå¤©åŠŸèƒ½ã€‚",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ä½œä¸ºå®éªŒä¸­çš„LLMå·¥å…·ï¼Œå­¦ç”Ÿé€šè¿‡è‡ªå®šä¹‰ç•Œé¢ä¸å…¶äº¤äº’ï¼Œç”¨äºç†è§£å†å²æ–‡æœ¬ã€‚",
          "verified": true,
          "stars": null
        },
        "original_text": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning â€“ understanding and retaining information â€“ remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately â€”through semantic analysis involving meaning, inferences, and implicationsâ€” can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies â€“ note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-takingâ€”whether done alone or alongside LLM usageâ€”produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learningâ€”offering opportunities to clarify, explore, and contextualise materialâ€”but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot â‘¡\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 â€“ upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. AleksiÄ‡-Maslac, F. BoroviÄ‡, and Z. BioÄina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan KÃ¼chemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan GÃ¼nnmann, Eyke HÃ¼llermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, JÃ¼rgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434â€“442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163â€“182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162â€“185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371â€“395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias NÃ¼ckles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 Ã— 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 Ã— 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 Ã— 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 Ã— 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 Ã— 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 Ã— 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 Ã— 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 Ã— 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 Ã— 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 Ã— 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 Ã— 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 Ã— 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 Ã— 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (â‰¥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (â‰¥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\nÂ· figuring out what the main ideas and concepts in the text are,\nÂ· what they mean,\nÂ· how they relate to each other, and\nÂ· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\nÂ· The meaning of important words and concepts\nÂ· The meaning of complex sentences\nÂ· The key points or ideas, such as the dates, places, people and events\nÂ· The connections between places, people and events\nÂ· What happened, and why and how it happened\nÂ· Similarities and differences between ideas and concepts\nÂ· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\nYou can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\n You can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 Ã— 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 Ã— 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 Ã— 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 Ã— 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 Ã— 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 Ã— 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 Ã— 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 Ã— 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 Ã— 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 Ã— 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 Ã— 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 Ã— 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 Ã— 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 Ã— 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 Ã— 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 Ã— 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 Ã— 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 Ã— 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 Ã— 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 Ã— 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 Ã— 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 Ã— 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 Ã— 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 Ã— 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 Ã— 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 Ã— 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 Ã— 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>â€œIt took less time to use the LLMâ€, â€œNotes take too much time.â€</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>â€œThe note-taking seemedunnec-\nsessary as the bot already helped explainâ€, â€œUsing one sort of meant I didnâ€™t need the other.â€</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you donâ€™t have to do the work your-\nself. The task becomes easier if you donâ€™t have to take notes.</td><td>â€œDidnâ€™t have to do any workâ€, â€œClarify any information I didnâ€™t know immediately without hav-\ning to scour the textâ€, â€œIt was difficult to take notes at the same time as using the chatbot.â€</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>â€œI didnâ€™t have enough time to ask as many questions when taking notesâ€, â€œI had more time to un-\nderstand the text.â€</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.â€</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>â€œLess time-consumingâ€, â€œMuch quicker.â€</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>â€œMore simpleâ€, â€œIt was easier.â€</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>â€œActively engaging with the botâ€, â€œFelt more interactive.â€</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>â€œEnjoyed reading its responsesâ€, â€œMore fun to use.â€</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>â€œAllowed me to focus more on the text.â€</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>â€œIt gives you a better understandingâ€, â€œI could confirm anything I was unsure of to ensure I understood it.â€</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>â€œThe AI helped me to learn more efficientlyâ€, â€œI was able to understand and learn the text a lot easier and quicker at a higher level.â€</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you donâ€™t understand.</td><td>â€œAsk any relevant questionsâ€, â€œIf I had a question, it could answer it.â€</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>â€œI was given more backgroundâ€, â€œIt gives me the full context.â€</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>â€œIt puts it in a simpler way and formâ€, â€œI can ask the AI chatbot to rephrase key pointsâ€, â€œIt can summarise key points.â€</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>â€œIt has stuck in my head moreâ€, â€œGiving me prompt questions, mnemonics, etc., which helped me rememberâ€, â€œTook less time to memorise than note-taking.â€</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>â€œI can remember things better when I write them downâ€, â€œMore helpful for developing recallâ€, â€œI learned more with note-takingâ€, â€œJust gave more background, rather than consolidating the knowledge.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>â€œIt was easier for me to understand what I was readingâ€, â€œI was understanding it moreâ€, â€œTest what you have learned by paraphrasing.â€</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>â€œBetter active readingâ€, â€œAllows me to actively engage.â€</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>â€œYou have to personally analyse itâ€, â€œI could condense the information into my own wordsâ€, â€œMade me think for myselfâ€, â€œIt is your view on the matter you are looking atâ€, â€œAlows me to feel proud of my work in the future.â€</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>â€œI was able to break down and process the textâ€, â€œSummarising the second text myself helped me to process the information.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œI am able to write down my own knowledge of what I had learnedâ€, â€œI could actually learn the information rather than being told it.â€</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>â€œI can come back to these notes at a later date if I am doing revisionâ€, â€œNote-taking gives you something better to look back on in future.â€</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>â€œEasier to summariseâ€, â€œIDK, easier.â€</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>â€œIt is easy to organise my notesâ€, â€œIt is easier to keep track of your train of thoughtsâ€, â€œHelped me to break down the text into smaller chunks.â€</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>â€œI found myself easily distracted by the AI and was more tempted to ask random questionsâ€, â€œItâ€™s not clear as it gives too much information.â€</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>â€œIt felt that it was just repeating it-self.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>â€œI struggled to think of questions to ask the AIâ€, â€œThe text was very easy therefore didnâ€™t feel the need to ask many questions.â€</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>â€œI enjoy using both at the same timeâ€, â€œIf I had to use the chatbot and ask it 20 questions, I would be very bored.â€</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>â€œIt was easier to have my key notes summarised as well as text with more detailâ€, â€œIt allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isnâ€™t clear.â€</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>â€œMost helpful and easy to learnâ€, â€œBecause I find it easier to remember and learn this way.â€</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>â€œIn order for me to process this, I find note-taking at the same time very helpful.â€</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>â€œIf I am only using the chatbot, then I have to scroll up to find what I am looking forâ€, â€œIt was easier to keep track of things and go back over them.â€</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>â€œIt meant I was doing actual work.â€</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>â€œI like to write out information as I think it helps me remember it better.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>â€œSimplifying it on paper made it easier to understand and remember.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œYou learn moreâ€, â€œYou can simplify what you have learnt in the notes.â€</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>â€œSome of the questions I had for the bot were not answered explicitly.â€</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>â€œYou will not get an AI chatbot at all times.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>â€œI wasnâ€™t sure what I was supposed to say to the bot. It was just kinda irritating.â€</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: â€œHelp me to summarise this paragraphâ€, â€œSummarise the textâ€, â€œGive me a summary of the first paragraphâ€, â€œTell me what this text is about.â€</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: â€œMake notes for the first paragraph.â€</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: â€œWhat are the main points?â€, â€œGive me all the important datesâ€, â€œWhatâ€™s the takeaway message?â€</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: â€œPut the important dates into chronological orderâ€, â€œGive me a timeline of the events.â€</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: â€œWhat does apartheid mean?â€, â€œWhat is a colony?â€, â€œWhat is a missile?â€, â€œI donâ€™t know what a blockade is.â€</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: â€œExplain this in simple wordsâ€, â€œMake the text simplerâ€, â€œWhat does this sentence mean?â€, â€œSimplify this text.â€</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: â€œThe US did not like Cuba because they thought that Castro was a communist, right?â€, â€œSo it was one officer that prevented the whole war?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide contextâ€”information that is not too central for understanding the text but could be relevant.\nExamples: â€œWho was Kennedy?â€, â€œWhat was Mandela famous for?â€, â€œTell me more about Cubaâ€, â€œHow many British colonies were there in Africa?â€, â€œWhere were the Turkish missiles located?â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: â€œWhy did the US not like Castro?â€, â€œWhy did the exiles invade Cuba?â€, â€œHow did black people feel during apartheid?â€</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: â€œWhat are examples of how apartheid affected daily life?â€, â€œIs there an analogy that explains the Cold War tensions?â€, â€œWhat unfair laws were passed?â€, â€œWhat were some of the boycotts?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: â€œHow is apartheid different from segregation in the US?â€, â€œCompare Kennedy and Khrushchev&#x27;s leadership styles.â€</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: â€œWhat are the strengths and weaknesses of Kennedy&#x27;s decision?â€, â€œEvaluate the effectiveness of the blockade.â€</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: â€œWhat were the long-term effects of the crisis?â€, â€œWhat is the situation like now?â€, â€œWhy should I care or learn about this?â€</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: â€œMake a mnemonicâ€, â€œWrite four questions about the textâ€, â€œHow can I remember this better?â€</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: â€œSummarize the main points in bullet pointsâ€, â€œCan you create a chart of the different policies?â€, â€œUse only a few wordsâ€, â€œMake it short.â€</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: â€œI donâ€™t understand what you saidâ€, â€œExplain that again but shorterâ€, â€œWhat do you mean?â€,\nâ€œSimpler pleaseâ€, â€œCan you write that in simpler terms?â€, â€œMake the summary shorter.â€</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: â€œHow are you?â€, â€œThank youâ€, â€œHello.â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: â€œWhat are your sources?â€, â€œWhy should I believe you?â€, â€œI think your answer is wrong.â€</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: â€œNelson Mandelaâ€, â€œIn 1910, four British colonies joined to create the Union of South Africaâ€, â€œMissile.â€</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: â€œWho is Che Guevara?â€, â€œWhat is the song Abraxas?â€</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that donâ€™t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: â€œasdfghâ€, â€œ.â€, â€œ123â€, â€œ???â€</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
        "location": "",
        "analyzed_at": "2025-12-16T13:37:44.613629"
      }
    },
    "wb-227968a8": {
      "id": "wb-227968a8",
      "type": "code",
      "title": "GPT-4 (Azure OpenAI API)",
      "description": "é€šè¿‡Azure OpenAI APIè®¿é—®çš„GPT-4æ¨¡å‹ï¼Œç”¨äºè‡ªåŠ¨åŒ–ç¼–ç å­¦ç”Ÿæç¤ºçš„å®šæ€§åˆ†æã€‚",
      "source_paper_id": "659fea70-f22c-4b54-9382-aa768ec096e8",
      "zone": "datasets",
      "created_at": "2025-12-16T13:37:44.644893",
      "data": {
        "asset": {
          "name": "GPT-4 (Azure OpenAI API)",
          "type": "api",
          "url": "https://azure.microsoft.com/en-us/products/ai-services/openai-service",
          "platform": "Azure OpenAI",
          "description": "é€šè¿‡Azure OpenAI APIè®¿é—®çš„GPT-4æ¨¡å‹ï¼Œç”¨äºè‡ªåŠ¨åŒ–ç¼–ç å­¦ç”Ÿæç¤ºçš„å®šæ€§åˆ†æã€‚",
          "license": "æœªçŸ¥",
          "usage_in_paper": "ç”¨äºåˆ†æ4929ä¸ªå­¦ç”Ÿæç¤ºï¼Œé€šè¿‡è‡ªåŠ¨åŒ–è„šæœ¬è¿›è¡Œåˆ†å±‚ç¼–ç åˆ†ç±»ã€‚",
          "verified": true,
          "stars": null
        },
        "original_text": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning â€“ understanding and retaining information â€“ remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately â€”through semantic analysis involving meaning, inferences, and implicationsâ€” can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies â€“ note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-takingâ€”whether done alone or alongside LLM usageâ€”produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learningâ€”offering opportunities to clarify, explore, and contextualise materialâ€”but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot â‘¡\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 â€“ upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. AleksiÄ‡-Maslac, F. BoroviÄ‡, and Z. BioÄina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan KÃ¼chemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan GÃ¼nnmann, Eyke HÃ¼llermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, JÃ¼rgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434â€“442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163â€“182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162â€“185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371â€“395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias NÃ¼ckles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 Ã— 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 Ã— 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 Ã— 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 Ã— 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 Ã— 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 Ã— 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 Ã— 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 Ã— 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 Ã— 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 Ã— 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 Ã— 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 Ã— 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 Ã— 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (â‰¥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (â‰¥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\nÂ· figuring out what the main ideas and concepts in the text are,\nÂ· what they mean,\nÂ· how they relate to each other, and\nÂ· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\nÂ· The meaning of important words and concepts\nÂ· The meaning of complex sentences\nÂ· The key points or ideas, such as the dates, places, people and events\nÂ· The connections between places, people and events\nÂ· What happened, and why and how it happened\nÂ· Similarities and differences between ideas and concepts\nÂ· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\nYou can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\n You can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 Ã— 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 Ã— 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 Ã— 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 Ã— 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 Ã— 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 Ã— 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 Ã— 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 Ã— 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 Ã— 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 Ã— 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 Ã— 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 Ã— 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 Ã— 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 Ã— 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 Ã— 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 Ã— 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 Ã— 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 Ã— 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 Ã— 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 Ã— 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 Ã— 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 Ã— 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 Ã— 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 Ã— 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 Ã— 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 Ã— 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 Ã— 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>â€œIt took less time to use the LLMâ€, â€œNotes take too much time.â€</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>â€œThe note-taking seemedunnec-\nsessary as the bot already helped explainâ€, â€œUsing one sort of meant I didnâ€™t need the other.â€</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you donâ€™t have to do the work your-\nself. The task becomes easier if you donâ€™t have to take notes.</td><td>â€œDidnâ€™t have to do any workâ€, â€œClarify any information I didnâ€™t know immediately without hav-\ning to scour the textâ€, â€œIt was difficult to take notes at the same time as using the chatbot.â€</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>â€œI didnâ€™t have enough time to ask as many questions when taking notesâ€, â€œI had more time to un-\nderstand the text.â€</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.â€</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>â€œLess time-consumingâ€, â€œMuch quicker.â€</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>â€œMore simpleâ€, â€œIt was easier.â€</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>â€œActively engaging with the botâ€, â€œFelt more interactive.â€</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>â€œEnjoyed reading its responsesâ€, â€œMore fun to use.â€</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>â€œAllowed me to focus more on the text.â€</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>â€œIt gives you a better understandingâ€, â€œI could confirm anything I was unsure of to ensure I understood it.â€</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>â€œThe AI helped me to learn more efficientlyâ€, â€œI was able to understand and learn the text a lot easier and quicker at a higher level.â€</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you donâ€™t understand.</td><td>â€œAsk any relevant questionsâ€, â€œIf I had a question, it could answer it.â€</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>â€œI was given more backgroundâ€, â€œIt gives me the full context.â€</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>â€œIt puts it in a simpler way and formâ€, â€œI can ask the AI chatbot to rephrase key pointsâ€, â€œIt can summarise key points.â€</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>â€œIt has stuck in my head moreâ€, â€œGiving me prompt questions, mnemonics, etc., which helped me rememberâ€, â€œTook less time to memorise than note-taking.â€</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>â€œI can remember things better when I write them downâ€, â€œMore helpful for developing recallâ€, â€œI learned more with note-takingâ€, â€œJust gave more background, rather than consolidating the knowledge.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>â€œIt was easier for me to understand what I was readingâ€, â€œI was understanding it moreâ€, â€œTest what you have learned by paraphrasing.â€</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>â€œBetter active readingâ€, â€œAllows me to actively engage.â€</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>â€œYou have to personally analyse itâ€, â€œI could condense the information into my own wordsâ€, â€œMade me think for myselfâ€, â€œIt is your view on the matter you are looking atâ€, â€œAlows me to feel proud of my work in the future.â€</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>â€œI was able to break down and process the textâ€, â€œSummarising the second text myself helped me to process the information.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œI am able to write down my own knowledge of what I had learnedâ€, â€œI could actually learn the information rather than being told it.â€</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>â€œI can come back to these notes at a later date if I am doing revisionâ€, â€œNote-taking gives you something better to look back on in future.â€</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>â€œEasier to summariseâ€, â€œIDK, easier.â€</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>â€œIt is easy to organise my notesâ€, â€œIt is easier to keep track of your train of thoughtsâ€, â€œHelped me to break down the text into smaller chunks.â€</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>â€œI found myself easily distracted by the AI and was more tempted to ask random questionsâ€, â€œItâ€™s not clear as it gives too much information.â€</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>â€œIt felt that it was just repeating it-self.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>â€œI struggled to think of questions to ask the AIâ€, â€œThe text was very easy therefore didnâ€™t feel the need to ask many questions.â€</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>â€œI enjoy using both at the same timeâ€, â€œIf I had to use the chatbot and ask it 20 questions, I would be very bored.â€</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>â€œIt was easier to have my key notes summarised as well as text with more detailâ€, â€œIt allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isnâ€™t clear.â€</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>â€œMost helpful and easy to learnâ€, â€œBecause I find it easier to remember and learn this way.â€</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>â€œIn order for me to process this, I find note-taking at the same time very helpful.â€</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>â€œIf I am only using the chatbot, then I have to scroll up to find what I am looking forâ€, â€œIt was easier to keep track of things and go back over them.â€</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>â€œIt meant I was doing actual work.â€</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>â€œI like to write out information as I think it helps me remember it better.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>â€œSimplifying it on paper made it easier to understand and remember.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œYou learn moreâ€, â€œYou can simplify what you have learnt in the notes.â€</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>â€œSome of the questions I had for the bot were not answered explicitly.â€</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>â€œYou will not get an AI chatbot at all times.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>â€œI wasnâ€™t sure what I was supposed to say to the bot. It was just kinda irritating.â€</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: â€œHelp me to summarise this paragraphâ€, â€œSummarise the textâ€, â€œGive me a summary of the first paragraphâ€, â€œTell me what this text is about.â€</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: â€œMake notes for the first paragraph.â€</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: â€œWhat are the main points?â€, â€œGive me all the important datesâ€, â€œWhatâ€™s the takeaway message?â€</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: â€œPut the important dates into chronological orderâ€, â€œGive me a timeline of the events.â€</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: â€œWhat does apartheid mean?â€, â€œWhat is a colony?â€, â€œWhat is a missile?â€, â€œI donâ€™t know what a blockade is.â€</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: â€œExplain this in simple wordsâ€, â€œMake the text simplerâ€, â€œWhat does this sentence mean?â€, â€œSimplify this text.â€</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: â€œThe US did not like Cuba because they thought that Castro was a communist, right?â€, â€œSo it was one officer that prevented the whole war?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide contextâ€”information that is not too central for understanding the text but could be relevant.\nExamples: â€œWho was Kennedy?â€, â€œWhat was Mandela famous for?â€, â€œTell me more about Cubaâ€, â€œHow many British colonies were there in Africa?â€, â€œWhere were the Turkish missiles located?â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: â€œWhy did the US not like Castro?â€, â€œWhy did the exiles invade Cuba?â€, â€œHow did black people feel during apartheid?â€</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: â€œWhat are examples of how apartheid affected daily life?â€, â€œIs there an analogy that explains the Cold War tensions?â€, â€œWhat unfair laws were passed?â€, â€œWhat were some of the boycotts?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: â€œHow is apartheid different from segregation in the US?â€, â€œCompare Kennedy and Khrushchev&#x27;s leadership styles.â€</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: â€œWhat are the strengths and weaknesses of Kennedy&#x27;s decision?â€, â€œEvaluate the effectiveness of the blockade.â€</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: â€œWhat were the long-term effects of the crisis?â€, â€œWhat is the situation like now?â€, â€œWhy should I care or learn about this?â€</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: â€œMake a mnemonicâ€, â€œWrite four questions about the textâ€, â€œHow can I remember this better?â€</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: â€œSummarize the main points in bullet pointsâ€, â€œCan you create a chart of the different policies?â€, â€œUse only a few wordsâ€, â€œMake it short.â€</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: â€œI donâ€™t understand what you saidâ€, â€œExplain that again but shorterâ€, â€œWhat do you mean?â€,\nâ€œSimpler pleaseâ€, â€œCan you write that in simpler terms?â€, â€œMake the summary shorter.â€</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: â€œHow are you?â€, â€œThank youâ€, â€œHello.â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: â€œWhat are your sources?â€, â€œWhy should I believe you?â€, â€œI think your answer is wrong.â€</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: â€œNelson Mandelaâ€, â€œIn 1910, four British colonies joined to create the Union of South Africaâ€, â€œMissile.â€</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: â€œWho is Che Guevara?â€, â€œWhat is the song Abraxas?â€</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that donâ€™t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: â€œasdfghâ€, â€œ.â€, â€œ123â€, â€œ???â€</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
        "location": "",
        "analyzed_at": "2025-12-16T13:37:44.644843"
      }
    },
    "wb-fcf30a07": {
      "id": "wb-fcf30a07",
      "type": "dataset",
      "title": "å†å²æ–‡æœ¬æ•°æ®é›†",
      "description": "ä»OpenStaxæ•™ç§‘ä¹¦ã€ŠWorld History, Volume 2: from 1400ã€‹å’Œã€ŠU.S. Historyã€‹æ”¹ç¼–çš„ä¸¤ä¸ªå†å²æ–‡æœ¬æ®µè½ï¼Œä¸»é¢˜ä¸ºå—éç§æ—éš”ç¦»å’Œå¤å·´å¯¼å¼¹å±æœºã€‚",
      "source_paper_id": "659fea70-f22c-4b54-9382-aa768ec096e8",
      "zone": "datasets",
      "created_at": "2025-12-16T13:37:44.665480",
      "data": {
        "asset": {
          "name": "å†å²æ–‡æœ¬æ•°æ®é›†",
          "type": "dataset",
          "url": "https://openstax.org/",
          "platform": "OpenStax",
          "description": "ä»OpenStaxæ•™ç§‘ä¹¦ã€ŠWorld History, Volume 2: from 1400ã€‹å’Œã€ŠU.S. Historyã€‹æ”¹ç¼–çš„ä¸¤ä¸ªå†å²æ–‡æœ¬æ®µè½ï¼Œä¸»é¢˜ä¸ºå—éç§æ—éš”ç¦»å’Œå¤å·´å¯¼å¼¹å±æœºã€‚",
          "license": "Creative Commons Attribution License",
          "usage_in_paper": "ä½œä¸ºå®éªŒææ–™ï¼Œå­¦ç”Ÿé˜…è¯»å¹¶å­¦ä¹ è¿™ä¸¤ä¸ªæ–‡æœ¬æ®µè½ï¼Œç„¶åæ¥å—ç†è§£å’Œè®°å¿†æµ‹è¯•ã€‚",
          "verified": true,
          "stars": null
        },
        "original_text": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning â€“ understanding and retaining information â€“ remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately â€”through semantic analysis involving meaning, inferences, and implicationsâ€” can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies â€“ note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-takingâ€”whether done alone or alongside LLM usageâ€”produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learningâ€”offering opportunities to clarify, explore, and contextualise materialâ€”but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot â‘¡\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 â€“ upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. AleksiÄ‡-Maslac, F. BoroviÄ‡, and Z. BioÄina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan KÃ¼chemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan GÃ¼nnmann, Eyke HÃ¼llermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, JÃ¼rgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434â€“442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163â€“182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162â€“185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371â€“395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias NÃ¼ckles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 Ã— 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 Ã— 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 Ã— 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 Ã— 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 Ã— 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 Ã— 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 Ã— 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 Ã— 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 Ã— 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 Ã— 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 Ã— 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 Ã— 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 Ã— 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (â‰¥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (â‰¥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\nÂ· figuring out what the main ideas and concepts in the text are,\nÂ· what they mean,\nÂ· how they relate to each other, and\nÂ· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\nÂ· The meaning of important words and concepts\nÂ· The meaning of complex sentences\nÂ· The key points or ideas, such as the dates, places, people and events\nÂ· The connections between places, people and events\nÂ· What happened, and why and how it happened\nÂ· Similarities and differences between ideas and concepts\nÂ· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\nYou can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\nÂ· Explain the meaning of important words and concepts\nÂ· Rephrase or simplify complex sentences and explain them\nÂ· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\nÂ· Clarify information you donâ€™t understand\nÂ· Explain the connections between places, people and events\nÂ· Explain what happened, and why and how it happened\nÂ· Identify similarities and differences between ideas and concepts\nÂ· Check your understanding of the text\n You can also:\nÂ· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\nÂ· Ask follow-up questions\nÂ· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 Ã— 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 Ã— 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 Ã— 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 Ã— 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 Ã— 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 Ã— 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 Ã— 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 Ã— 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 Ã— 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 Ã— 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 Ã— 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 Ã— 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 Ã— 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 Ã— 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 Ã— 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 Ã— 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 Ã— 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 Ã— 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 Ã— 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 Ã— 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 Ã— 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 Ã— 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 Ã— 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 Ã— 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 Ã— 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 Ã— 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 Ã— 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>â€œIt took less time to use the LLMâ€, â€œNotes take too much time.â€</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>â€œThe note-taking seemedunnec-\nsessary as the bot already helped explainâ€, â€œUsing one sort of meant I didnâ€™t need the other.â€</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you donâ€™t have to do the work your-\nself. The task becomes easier if you donâ€™t have to take notes.</td><td>â€œDidnâ€™t have to do any workâ€, â€œClarify any information I didnâ€™t know immediately without hav-\ning to scour the textâ€, â€œIt was difficult to take notes at the same time as using the chatbot.â€</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>â€œI didnâ€™t have enough time to ask as many questions when taking notesâ€, â€œI had more time to un-\nderstand the text.â€</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.â€</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>â€œLess time-consumingâ€, â€œMuch quicker.â€</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>â€œMore simpleâ€, â€œIt was easier.â€</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>â€œActively engaging with the botâ€, â€œFelt more interactive.â€</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>â€œEnjoyed reading its responsesâ€, â€œMore fun to use.â€</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>â€œAllowed me to focus more on the text.â€</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>â€œIt gives you a better understandingâ€, â€œI could confirm anything I was unsure of to ensure I understood it.â€</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>â€œThe AI helped me to learn more efficientlyâ€, â€œI was able to understand and learn the text a lot easier and quicker at a higher level.â€</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you donâ€™t understand.</td><td>â€œAsk any relevant questionsâ€, â€œIf I had a question, it could answer it.â€</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>â€œI was given more backgroundâ€, â€œIt gives me the full context.â€</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>â€œIt puts it in a simpler way and formâ€, â€œI can ask the AI chatbot to rephrase key pointsâ€, â€œIt can summarise key points.â€</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>â€œIt has stuck in my head moreâ€, â€œGiving me prompt questions, mnemonics, etc., which helped me rememberâ€, â€œTook less time to memorise than note-taking.â€</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>â€œI can remember things better when I write them downâ€, â€œMore helpful for developing recallâ€, â€œI learned more with note-takingâ€, â€œJust gave more background, rather than consolidating the knowledge.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>â€œIt was easier for me to understand what I was readingâ€, â€œI was understanding it moreâ€, â€œTest what you have learned by paraphrasing.â€</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>â€œBetter active readingâ€, â€œAllows me to actively engage.â€</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>â€œYou have to personally analyse itâ€, â€œI could condense the information into my own wordsâ€, â€œMade me think for myselfâ€, â€œIt is your view on the matter you are looking atâ€, â€œAlows me to feel proud of my work in the future.â€</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>â€œI was able to break down and process the textâ€, â€œSummarising the second text myself helped me to process the information.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œI am able to write down my own knowledge of what I had learnedâ€, â€œI could actually learn the information rather than being told it.â€</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>â€œI can come back to these notes at a later date if I am doing revisionâ€, â€œNote-taking gives you something better to look back on in future.â€</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>â€œEasier to summariseâ€, â€œIDK, easier.â€</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>â€œIt is easy to organise my notesâ€, â€œIt is easier to keep track of your train of thoughtsâ€, â€œHelped me to break down the text into smaller chunks.â€</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>â€œI found myself easily distracted by the AI and was more tempted to ask random questionsâ€, â€œItâ€™s not clear as it gives too much information.â€</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>â€œIt felt that it was just repeating it-self.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>â€œI struggled to think of questions to ask the AIâ€, â€œThe text was very easy therefore didnâ€™t feel the need to ask many questions.â€</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>â€œI enjoy using both at the same timeâ€, â€œIf I had to use the chatbot and ask it 20 questions, I would be very bored.â€</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>â€œIt was easier to have my key notes summarised as well as text with more detailâ€, â€œIt allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isnâ€™t clear.â€</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>â€œMost helpful and easy to learnâ€, â€œBecause I find it easier to remember and learn this way.â€</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>â€œIn order for me to process this, I find note-taking at the same time very helpful.â€</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>â€œIf I am only using the chatbot, then I have to scroll up to find what I am looking forâ€, â€œIt was easier to keep track of things and go back over them.â€</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>â€œIt meant I was doing actual work.â€</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>â€œI like to write out information as I think it helps me remember it better.â€</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>â€œSimplifying it on paper made it easier to understand and remember.â€</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>â€œYou learn moreâ€, â€œYou can simplify what you have learnt in the notes.â€</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>â€œSome of the questions I had for the bot were not answered explicitly.â€</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>â€œYou will not get an AI chatbot at all times.â€</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>â€œI wasnâ€™t sure what I was supposed to say to the bot. It was just kinda irritating.â€</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: â€œHelp me to summarise this paragraphâ€, â€œSummarise the textâ€, â€œGive me a summary of the first paragraphâ€, â€œTell me what this text is about.â€</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: â€œMake notes for the first paragraph.â€</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: â€œWhat are the main points?â€, â€œGive me all the important datesâ€, â€œWhatâ€™s the takeaway message?â€</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: â€œPut the important dates into chronological orderâ€, â€œGive me a timeline of the events.â€</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: â€œWhat does apartheid mean?â€, â€œWhat is a colony?â€, â€œWhat is a missile?â€, â€œI donâ€™t know what a blockade is.â€</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: â€œExplain this in simple wordsâ€, â€œMake the text simplerâ€, â€œWhat does this sentence mean?â€, â€œSimplify this text.â€</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: â€œThe US did not like Cuba because they thought that Castro was a communist, right?â€, â€œSo it was one officer that prevented the whole war?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide contextâ€”information that is not too central for understanding the text but could be relevant.\nExamples: â€œWho was Kennedy?â€, â€œWhat was Mandela famous for?â€, â€œTell me more about Cubaâ€, â€œHow many British colonies were there in Africa?â€, â€œWhere were the Turkish missiles located?â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: â€œWhy did the US not like Castro?â€, â€œWhy did the exiles invade Cuba?â€, â€œHow did black people feel during apartheid?â€</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: â€œWhat are examples of how apartheid affected daily life?â€, â€œIs there an analogy that explains the Cold War tensions?â€, â€œWhat unfair laws were passed?â€, â€œWhat were some of the boycotts?â€</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: â€œHow is apartheid different from segregation in the US?â€, â€œCompare Kennedy and Khrushchev&#x27;s leadership styles.â€</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: â€œWhat are the strengths and weaknesses of Kennedy&#x27;s decision?â€, â€œEvaluate the effectiveness of the blockade.â€</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: â€œWhat were the long-term effects of the crisis?â€, â€œWhat is the situation like now?â€, â€œWhy should I care or learn about this?â€</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: â€œMake a mnemonicâ€, â€œWrite four questions about the textâ€, â€œHow can I remember this better?â€</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: â€œSummarize the main points in bullet pointsâ€, â€œCan you create a chart of the different policies?â€, â€œUse only a few wordsâ€, â€œMake it short.â€</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: â€œI donâ€™t understand what you saidâ€, â€œExplain that again but shorterâ€, â€œWhat do you mean?â€,\nâ€œSimpler pleaseâ€, â€œCan you write that in simpler terms?â€, â€œMake the summary shorter.â€</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: â€œHow are you?â€, â€œThank youâ€, â€œHello.â€</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: â€œWhat are your sources?â€, â€œWhy should I believe you?â€, â€œI think your answer is wrong.â€</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: â€œNelson Mandelaâ€, â€œIn 1910, four British colonies joined to create the Union of South Africaâ€, â€œMissile.â€</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: â€œWho is Che Guevara?â€, â€œWhat is the song Abraxas?â€</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that donâ€™t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: â€œasdfghâ€, â€œ.â€, â€œ123â€, â€œ???â€</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
        "location": "",
        "analyzed_at": "2025-12-16T13:37:44.665444"
      }
    }
  },
  "global_workbench": {
    "methods": [
      "wb-390fa354",
      "wb-eb682852",
      "wb-f7b3ec2b",
      "wb-5b40efa7",
      "wb-3779c248",
      "wb-95d358cd",
      "wb-f91d1499",
      "wb-3bb1a1fe",
      "wb-88124e5e",
      "wb-a6d535f5",
      "wb-370d40e7",
      "wb-f67660e4"
    ],
    "datasets": [
      "wb-0576dd4f",
      "wb-17d8d139",
      "wb-9db9d05b",
      "wb-7ed54033",
      "wb-a91a407b",
      "wb-5fced375",
      "wb-90a3fb13",
      "wb-19a61a30",
      "wb-4530a7e0",
      "wb-ec355c0b",
      "wb-8347bbc4",
      "wb-9179bd57",
      "wb-14c615a4",
      "wb-432fae61",
      "wb-be400a1e",
      "wb-edcd83a3",
      "wb-131382ad",
      "wb-cd300c3f",
      "wb-bece9d46",
      "wb-49359d09",
      "wb-24cfa1c9",
      "wb-2186a821",
      "wb-fccfea7e",
      "wb-2496aaf3",
      "wb-ac1413ff",
      "wb-bc34fecf",
      "wb-31322e39",
      "wb-850ade73",
      "wb-8b278cd9",
      "wb-227968a8",
      "wb-fcf30a07"
    ],
    "notes": [
      "wb-1d8b4206",
      "wb-b399bb3b"
    ]
  },
  "paper_workbenches": {
    "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e": {
      "methods": [
        "wb-390fa354",
        "wb-eb682852"
      ],
      "datasets": [],
      "notes": [
        "wb-1d8b4206",
        "wb-b399bb3b"
      ]
    },
    "5a74d1e5-32cd-4f2e-9e98-697da1abeeba": {
      "methods": [
        "wb-f7b3ec2b"
      ],
      "datasets": [
        "wb-0576dd4f"
      ],
      "notes": []
    },
    "c48c530c-6261-425b-9771-bb1d4c8d06d6": {
      "methods": [
        "wb-5b40efa7"
      ],
      "datasets": [],
      "notes": []
    },
    "c7e2c3e2-0fa8-48ca-9d79-e2847b260c07": {
      "methods": [
        "wb-3779c248"
      ],
      "datasets": [
        "wb-17d8d139"
      ],
      "notes": []
    },
    "9866dfe0-a3d7-41a1-99e5-c2ed00636259": {
      "methods": [
        "wb-95d358cd"
      ],
      "datasets": [
        "wb-9db9d05b",
        "wb-7ed54033",
        "wb-a91a407b"
      ],
      "notes": []
    },
    "d572a494-7e2b-4328-819b-57bc6f24cdc8": {
      "methods": [
        "wb-f91d1499"
      ],
      "datasets": [
        "wb-5fced375",
        "wb-90a3fb13",
        "wb-19a61a30",
        "wb-4530a7e0",
        "wb-ec355c0b"
      ],
      "notes": []
    },
    "eda55281-9bde-4cff-a438-6a89ea992f96": {
      "methods": [
        "wb-3bb1a1fe"
      ],
      "datasets": [
        "wb-8347bbc4",
        "wb-9179bd57",
        "wb-14c615a4"
      ],
      "notes": []
    },
    "2c6ea33c-9a9e-4547-949a-69351fc70f65": {
      "methods": [
        "wb-88124e5e",
        "wb-a6d535f5"
      ],
      "datasets": [
        "wb-432fae61",
        "wb-be400a1e",
        "wb-edcd83a3",
        "wb-131382ad",
        "wb-cd300c3f",
        "wb-bece9d46",
        "wb-49359d09",
        "wb-24cfa1c9",
        "wb-2186a821",
        "wb-fccfea7e"
      ],
      "notes": []
    },
    "2cd0da84-59cb-40bc-bb23-771b1d632125": {
      "methods": [
        "wb-370d40e7"
      ],
      "datasets": [
        "wb-2496aaf3",
        "wb-ac1413ff",
        "wb-bc34fecf",
        "wb-31322e39"
      ],
      "notes": []
    },
    "659fea70-f22c-4b54-9382-aa768ec096e8": {
      "methods": [
        "wb-f67660e4"
      ],
      "datasets": [
        "wb-850ade73",
        "wb-8b278cd9",
        "wb-227968a8",
        "wb-fcf30a07"
      ],
      "notes": []
    }
  }
}