{
  "0a6aae26-e1da-42f9-80f6-19a4250dbeaa": {
    "id": "0a6aae26-e1da-42f9-80f6-19a4250dbeaa",
    "filename": "高等教育的数智变革：基本逻辑、趋势特点及实践应对_李雪.pdf",
    "file_path": "./uploads/papers/0a6aae26-e1da-42f9-80f6-19a4250dbeaa.pdf",
    "status": "completed",
    "title": "高等教育的数智变革:",
    "category": "高等教育",
    "markdown_content": "# 高等教育的数智变革:\n\n# 基本逻辑、趋势特点及实践应对\n\n李雪 李永强\n\n以ChatGPT、DeepSeek等为代表的智能科学与技术的加速迭代升级及其在人类生产生活中的广泛应用正在不断改变着人类的物质生产方式、知识创新逻辑、人际交往模式和组织行为方式，其对高等教育的影响、渗透和改变远远超出了一般意义上科学技术的教育领域应用层面，引发了高等教育人才培养目标、知识创新生态、课程教学范式和大学治理体系等全方位深层次变革。高等教育正呈现出人才培养目标从专业知识教育转向未来素养培养、知识创新生态从大学组织内部转向多元主体协同、课程教学范式从传统教学转向智慧教育、教育治理体系从技术赋能转向系统重构等许多新的趋势特点。在国家高等教育体系中占据重要地位的高水平研究型大学应深刻把握这些新的趋势特点，全面推进发展范式、创新生态、育人体系、治理体系和评价体系的系统性改革，为我国建成世界高等教育中心、更好地服务教育强国建设发挥好示范引领作用。\n\n关键词：高等教育；数智变革；基本逻辑；趋势特点；高水平研究型大学；应对策略\n\n中图分类号：F0-4；G642 文献标识码：A 文章编号：1003—5656(2025)07—0076—11\n\nDOI:10.16158/j.cnki.51-1312/f.2025.07.007\n\n# 一、引言与文献综述\n\n从历史来看，教育既是推动科学技术革命的重要力量，也是被科学技术不断重塑的重要对象。学校的诞生、文字的出现、印刷术的发明以及电子计算机等现代科学技术在教育领域中广泛运用被视为导致人类四次教育革命的标志性事件。科技革命对教育的影响是深层次、全方位甚至颠覆性的，特别是现代社会，从计算机问世、互联网普及到人工智能的超常崛起，科学技术的迅速发展及其在教育领域的广泛运用推动了教育从思想、内容、方式到体制的重大变革，从而重塑了教育在不同时代的独特形态。\n\n“当前，新一轮科技革命和产业变革蓄势待发，人工智能技术加速迭代，正迎来爆发式发展，深刻改变人类生产生活方式、知识供给模式和科研创新范式，进而重塑思维方式与观念，教育已经进入改变底层逻辑、重塑教育生态，资源共创分享、消弭数字鸿沟，素质能力重构、促进全面发展，全球开放合作、推动文明互鉴的智能时代。”[1]显然，以ChatGPT、DeepSeek等为代表的生成式人工智能大模型在高等教育领域的应用推广引起了广泛关注和讨论，这些讨论主要集中在三个方向：一是研究生成式人工智能在高等教育领域的应用场景、风险挑战与治理对策，[2-6]整体上表现出乐观的欢迎和展望，也分析了包括伦理风险在内的可能局限和隐患。[7-8]有研究者用“ChatGPT究竟是‘阿拉丁神灯’还是‘潘多拉魔盒’”[9]形象概括了“ChatGPT教育应用的潜能与风险”①，ChatGPT既具有赋能教学创新的潜能，也存在诸如学业诚信、过度依赖、伦理问题等风险，这种相对客观的分析在一定程度上既保持了理性的乐观，也警醒过度沉迷的危害。二是聚焦教学内容、教学方式、教师素质、教育治理等高等教育的某个方面、要素或环节来分析人工智能对高等教育的影响，[10-11]总体上朝着更加细化和具体的方向深入。三是深入以ChatGPT\n\n等为代表的生成式人工智能大模型的基本原理、设计理念、技术架构及未来发展去分析把握其对高等教育的深刻影响，[12-13]得出一些更具有科学和技术基础的结论，这类研究对研究者的人工智能素养具有较高的要求。\n\n已有研究开拓了人们对数智革命影响高等教育变革趋势特点的深入认识，其中一些观点、洞见以及相应的实践探索为本文的分析研究提供了很好的借鉴和参照。但我们同时注意到，当前研究视角更侧重于科学技术在教育领域的应用层面，即从教育技术学的视角来审视智能科学与技术对高等教育的影响，缺乏相对宏观的分析视角和系统的分析，尤其是对数智革命如何影响高等教育变革的底层或基本逻辑缺乏深入的分析，没有很好做到“跳出教育看教育”。高等教育作为社会大系统的一个子系统，与整个社会大系统及其他子系统存在着内在的本质联系，与人类的物质生产方式、知识创新逻辑、人际交往模式、组织行为方式等具有深度同构关系。因而，分析数智革命对高等教育的影响不能仅仅局限在教育系统内部，必须深入把握以人工智能为代表的数智革命如何影响高等教育变革的基本逻辑，分析其趋势特点并作出更有前瞻性和针对性的实践应对，而这正是本文关注和分析的重点所在。\n\n# 二、高等教育数智变革的基本逻辑\n\n“人工智能是新一轮科技革命和产业变革的重要驱动力量，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。”[14]数智革命加速创新并快速融入经济社会发展各领域全过程，重塑千行万业的速度之快、辐射范围之广、影响程度之深前所未有。中国、美国、英国、德国、日本等世界主要强国都把加快人工智能的发展作为推动第四次科技革命和产业变革的突破口，相继出台了体现国家意志的重大战略规划和行动，抢占新一轮科技革命和产业变革的制高点。数智革命正在改变人类生活的方方面面，重塑人类社会的整体面貌，进而要求高等教育必须及时作出相应的回应和变革。\n\n# （一）数智革命改变了人类的物质生产方式\n\n“生产力质态的每一次演进和发展，都是以重大科技创新为主导，形成新的生产方式，引发生产力产生质变，推动新的产业变革和社会变革。”[15]2023年6—7月，全球著名咨询机构麦肯锡相继发布《生成式AI的经济潜力：下一个生产力前沿》《2023技术趋势展望》两份研究报告，[16-17]前者通过对47个国家及地区的850种职业（覆盖全球  $80\\%$  以上劳动人口）的深入研究探讨了人工智能发展对全球经济的潜在影响，预测2030年至2060年之间，将有  $50\\%$  的职业逐渐被人工智能所取代，使当前  $60\\% -70\\%$  的工作实现自动化；后者评估认为生成式人工智能(Generative AI)“已经成为一个响亮的入口，并已经显示出变革性商业影响的潜力……在应用性人工智能(Applied AI)和机器学习工业化(Industrializing machine learning)等现有技术的基础上，生成式人工智能(Generative AI)在大多数行业都具有很高的潜力和适用性”。2024年11月，国际权威分析机构沙利文(Frost & Sullivan)发布《2024年中国行业大模型市场报告》，[18]全面分析了包括工业大模型在内的多个领域中国行业大模型发展态势，百度文心、商汤日日新·商量、腾讯混元以及华为盘古等大规模预训练模型在各行业中广泛应用展现出强大的语言理解和生成能力以及跨领域的泛化能力，已经广泛渗透到金融、教育、医疗、电商、传媒、法律等领域，被用于智能客服、智能写作、自动摘要、文本生成、知识问答、个性化推荐等多个应用场景，有效提升行业服务效率和服务质量。\n\n当前，随着自动化系统和机器人在制造业、物流和服务领域的广泛应用，自动化、数字化、智能化已成为智能时代的重要趋势，这不仅大幅提升了生产效率，同时也显著降低了人力成本。从更广的范围来看，传统产业正在为适应科技变革趋势而大规模采用智能化技术，越来越多的传统工作岗位正被自动\n\n化控制系统所替代，同时一系列新产业、新形态、新模式加速涌现，新兴产业和未来产业正在成为发达国家争先抢夺的未来制高点，国家之间在科技领域的激烈竞争正好反映出全球科技生态与未来发展方向的新动向。这一系列变化预示着人类的物质生产方式正在被以人工智能为核心的数智革命所改变、重塑或催生，从而导致了社会生产力形态的革命性变化，催生新质生产力，并引发生产力全球布局、国家经济结构、世界商业模式、社会组织形态等深层次甚至是颠覆性的变革。高等学校作为为人类经济社会发展提供思想、知识、技术和人才的最重要机构，其学科专业的设立演进、教学内容的更新迭代以及课程体系的持续变革，无不映射着高等教育对科技革命及由其推动的产业变革的积极回应。因而，高等教育必须积极适应和引领这种生产力形态的变革趋势，在教育理念、发展战略、培养目标、学科专业布局等方面进行系统性的变革，从而形成适应数智革命的新的发展范式。\n\n# （二）数智革命重塑了人类的知识生产逻辑\n\n马克思认为，“符合社会全部需要的生产”应当包括“劳动力的生产”“物质的生产”和“精神的生产”。[19]26-53科学技术不只是物质生产力函数的重要要素，也是人类知识生产力函数的重要因素，是引发知识生产模式变革的决定性力量。随着数智技术的发展，人们越来越深刻地感知到，知识生产、创造与分享的模式和生态正在发生重大变化。首位华人图灵奖获得者、著名的计算机科学家姚期智说，“从20年前的人脸识别，到后来的下围棋，这些单一的，人类觉得困难的工作，人工智能可以做到超过人类。近年来，伴随大模型的出现，人工智能在语言能力上表现出非凡的智能，我们现在都感觉到，最好的大模型确实比普通人，甚至是受过高等教育的人显得更加聪明。”[20]OpenAI公司相继发布的ChatGPT、Sora和o4，基于对人类认知过程尤其是人脑机制的有限认知，设计了模拟神经网络的transformer架构，并通过参数扩张实现了对认知过程的更精准模拟，其超常学习能力所形成的更为广博的知识积累、能力整合等能更好地突破人脑的局限性，在诸多领域已经表现得比人类更加“智能”，在特定的功能上远超人类大脑。2025年初，国产开源大模型DeepSeek凭借其强大的语言处理、知识推理与专业文本生成能力迅速在国内掀起了一股人工智能热潮，其以自主训练、中文强化、国产算力适配为特点引发了国内众多高校纷纷跟进部署并进行应用开发。\n\n人类传统的知识生产在很大程度上是科学共同体依托学科进行的。人工智能能够跨越学科的界限，整合不同领域的知识和方法，实现对具体问题的多角度、多层次、多维度思考，这突破了传统的学科专业细分领域更加窄化和具体的限制，跨越了传统知识创新的学科界限的束缚，在一定程度上颠覆了人类传统的知识生产逻辑。可以预见的是，随着人工智能的不断迭代升级，其卓越的自然语言理解和生成能力使其可以处理多学科领域的知识，跨越传统学科边界并将不同领域的知识融合在一起，还可以根据用户需求和问题生成高度个性化的知识单元，使知识可以更细化，更有针对性，而不受传统学科框架的限制。近期，DeepMind发布了《A new golden age of discovery-Seizing the AI for Science opportunity》报告，从知识、数据、模型、实验、解决方案五个维度揭示了AI for Science的最新应用前景和结果。[21]2024年，“AI教父”Geoffrey Hinton博士与John Hopfield教授因“他们在机器学习领域的开创性贡献”获得了诺贝尔物理学奖，“AlphaFold之父”Demis Hassabis博士和John Jumper博士以及华盛顿大学David Baker却因为“其借助AI工具分别因蛋白质结构预测和计算蛋白设计的贡献”而获得了诺贝尔化学奖。因而，人工智能对人类知识的生产方式、工具、效率、结果及其呈现方式等都产生了深刻的影响，必然重塑高等教育的知识生产模式和创新生态，并推动高等教育内容生成方式、结果、效率的转变。\n\n# （三）数智革命重构了人类的人际交往模式\n\n人与自然、人与社会、人与自我是人必须处理的三种关系。人的社会性是人的本质属性，这一属性是在人的社会交往中形成并展现出来的，而人与人的对话是社会交往的重要形式和途径，人作为“对话\n\n中的人”是人的交往活动与属性的重要体现。习近平总书记指出，以信息技术、人工智能为代表的新兴科技快速发展，大大拓展了时间、空间和人们认知范围，人类正在进入一个“人机物”三元融合的万物智能互联时代。[22]数字技术发展出人的数字交往这种新的交往方式，而数字技术演进到人工智能大模型后，人与智能机器的对话则具有了人与人对话的功能，以大模型为对象的人机对话将深刻改变人的交往方式，这对人的社会性的形成和发展具有十分重要的意义，或使“人机对话中的人”成为“对话中的人”的新常态。[23]人工智能改变了传统的人际交往模式，特别是第三个智能变量“机”的加入，打破了人际交往的时空限制、虚实界限和结构方式。人工智能已经可以创造虚拟的环境，让人们有更丰富的社交体验。OpenAI“文生视频”大模型Sora展现了令人惊叹的视频生成效果，甚至在部分样片中还展现了对“物理规律”超强的学习能力。可以预料的是，随着人工智能技术的不断进步，在未来人类生活的各个领域必然是一个人与机器人相处的世界。\n\n大学的教育教学范式一定程度上是人际交往模式在高等教育领域的表现，教师的教与学生的学都受到社会人际交互模式的影响。过去许多年来，虽然人工智能常常有各种创新，但“人机交互”都不足以认为可以挑战人类的现场互动，广泛存在的主要互动模式还是师生二元之间的，直到能让机器“听懂人话”的自然语言处理技术被应用于生成式人工智能才从根本上改变人们对“人机交互”的理解，并逐步消解教育的互动性原则。[24]同时，信息技术的快速发展，已使教育的内涵不再仅仅局限于学校之中，移动学习、泛在学习等新型教育模式使得学习的控制权逐渐从教师、管理者转移到了学习者手中，从而动摇了诞生于大工业时代，以标准化、教导主义和教师控制来批量培养人才的现行教育体系。[25][126-141]新一代人工智能技术对教育系统的干预导致了人机协同教育模式的出现，这一变革引发了学习者的学习方式、认知方式和互动模式的转变，并有望塑造以学生为中心的学习生态。[26]显然，在智能科学与技术的加持下，人类的人际交互模式正在不断被重构，高等教育中传统的面对面教学和纸质教材逐渐被在线学习平台、虚拟教师和个性化学习应用所替代，这种改变推动了教学范式朝着更加灵活、多样化、个性化的方向发展，尤其是使得大规模的因材施教成为新的可能。\n\n# （四）数智革命改变了人类的组织行为方式\n\n人类社会每进入一个新的阶段，都会产生一种新的合作方式、一种新的组织模式，从而催生新的组织形态。从历史来看，从手工时代的家庭作坊到工业革命时期的工厂体系，从现代社会的企业组织到后工业时代的平台组织，每一次技术的飞跃都导致组织结构及其运行方式的重大调整，从单一形态到多元形态，社会组织形态的演变展现了其适应性和灵活性，不断满足社会经济发展的新需求。从这个变迁的历程中可以窥见，科技革命不只是社会生产效率提升的驱动力量，也是社会组织模式变革的驱动力量，更深刻地影响着社会组织的形态和运作方式。数智技术以其智能化、去中心化、自适应性等特征深刻影响组织成员的可塑性、组织结构的灵活性和组织控制的科学性，改变了人类的社会组织形态和行为方式。其智能化特性赋予了其处理大量信息、制定复杂决策并模仿人类智能的能力，这种智能化技术可用来自动执行和优化各种任务，进而提升工作效率与质量。其去中心化特征导致决策与控制不再依赖于单一的权威，这深深地影响了组织内权力的分配格局及组织结构的变化。其自适应性使其能够学习和适应新的环境与需求，这使得组织内的成员不得不为满足快速变化的新的工作要求而适应并利用这些新技术。因而，随着数智技术加速融入组织体系变革，必将导致组织结构调整、流程再造和文化重塑，结构将变得更加扁平化，管理流程更强调快速响应外部变化和内部高度协同，组织文化更强调组织、员工与服务对象之间的价值共创。\n\n大学本质上是由教师、学生、管理者构成的教育共同体。现代大学已经发展成为一个结构复杂、功能多样、属员众多的组织。从组织行为学的视角来看，一个组织在不同成长阶段的组织结构、领导方式、\n\n管理体制、员工心态都有其特点，组织变革伴随组织成长的各个阶段，不同成长阶段要求不同的组织模式与之相适应。由于大学教育是由国家、家庭、教师、学生、用人单位等多元主体共同完成的，不同的群体都对大学有着不同的期待，因而大学具有典型的利益相关者组织的属性，大学治理就是要解决能在冲突和多元利益状况下管理其一般事务的组织性框架及体制机制建设的问题。如何确保大学内部各个机构、系统之间功能定位明确、职能职责清晰、运转科学高效，大学的治理体系和治理能力尤为重要。由数智革命驱动的社会组织形态的变革必然对大学治理产生深远的影响，使得多元、多层级的教育利益相关者与多功能、多样态的智能机器合作，综合利用行政管理和技术支撑等治理手段，可以推动实现人机交互、优势互补、高效合作的现代化教育治理。[27]\n\n# 三、高等教育数智变革的趋势特点\n\n数智革命正在迅速改变人类的物质生产方式、知识生产逻辑、人际交往模式和组织行为方式，这些深层次的改变都会直接映射到高等教育领域，引发高等教育人才培养目标、知识创新生态、课程教学范式、内部治理体系等的系统性深层次变革，从而使得智能时代的高等教育呈现出新的趋势特点。\n\n# （一）人才培养目标从专业知识教育转向未来素养培养\n\n培养什么人、怎样培养人、为谁培养人是教育的根本问题。随着人工智能不断取得重要突破，高等教育应该培养什么样的人以适应科技革命和产业变革的需求是高等教育要思考解决的根本问题。有人认为应包括人工智能思维、创造创新能力、沟通能力、团队协作能力、提出问题的能力和在人工智能协助下的学习能力；[4]有人认为应更加注重凸显学生的个性化优势的品质，加强学生创新品质、情感品质、道德感、价值观，以及人工智能相关素质能力的培养，向复合型人才培养模式转型；[28]有人则强调了人工智能时代批判性思考和解决问题的重要性，认为学校教育的重心应从知识、技能和职业准备转向人工智能时代的适应性学习。[6]显然，大家越来越深刻地体会到，现代大学作为工业化时代的产物，一直致力于规模化地培养符合社会生产需求的人才，然而，其教育内容已和人工智能时代日益凸显的创新人才挖掘和培养需求产生矛盾，[29]传统的人才培养目标及与之相适应的培养模式已经难以适应一个高度智能化的未来社会对受教育者的需求。\n\n要适应、把握和引领智能时代人类物质生产方式、知识创新逻辑等变化所导致对未来社会人才素养需求的改变，高等教育就必须重塑自己的人才培养目标，致力于培养适应一个更加智能化时代所需的人的前瞻能力和未来素养，这至少包括：一是“显而易见”的智能素养，包括数据思维、智能技术、人机协同能力等；二是深度学习能力。深度学习能力是智能生命快速迭代的根本所在，这是以ChatGPT为代表的生成式人工智能给予我们的最大启示；三是对未来的良好适应和创造能力。数智技术加速融入人类生产生活各领域，也迅速放大了更大范围和更深层次的易变性、不确定性、复杂性和模糊性，这对学生的适应能力、批判性思维和创新能力的需求更甚以往。因而，除了让学生具备传统的知识、能力、素养外，最核心的是学生的智能素养、深度学习能力以及对未来的适应能力和创造能力，与之相应的人才培养标准、模式、机制和评价也要随之发生改变，高等教育应据此重构自身人才培养体系。\n\n# （二）知识创新生态从大学组织内部转向多元主体协同\n\n大学的核心功能是知识的传承、创造与传播，并以其生产创造的知识培养和造就社会所需的各类人才，因此大学的知识生产本质上是知识和知识生产者的生产与再生产的过程。就新知识的生产而言，现代社会还没有创造出任何可以与大学相提并论的机构。[30]2-89传统大学知识生产主要依靠学者的知识积累及创新转化，而生成式人工智能跳过了学科、专业、领域等的限制，直接切入知识本身，形成更加细化的知识单元，并导致这些曾经归属不同学科的知识单元形成新的知识体系，促进了跨学科和超学科\n\n的知识整合，更好地满足了人类认识复杂性问题的需要，导致知识创新的主体、科学研究的范式、以学科为基础的传统组织模式等都发生了改变，也会导致知识创新模式的重构以及新的知识体系的涌现，对人类知识的生产方式、效率、结果及其呈现方式等都产生了深刻的影响。\n\n高等教育必须前瞻数智革命对大学知识创新逻辑的影响，不断突破传统的知识生产模式及相应的专业教育局限。一是科研范式将发生转变，AI for Science的重要作用将得到充分的彰显，基于复杂神经网络的深度学习能力极大提高了知识生产效率和更新速度，自然科学领域实验验证和社会科学领域定量研究的内容和形式都在被改变，作为创新主体的教师的知识结构优化尤其是数智素养的提升将成为影响大学创新能力提升的关键。中山大学医学院、阿里云与悉尼大学的研究团队利用其开发的深度学习算法LucaProt发现了超过16万种RNA病毒，包括7万种首次发现的新病毒，揭示了大量前所未知的病毒“暗物质”[31]“人工智能的算法模型能够挖掘出我们之前忽略或根本不知道的病毒，这种能力在疾病防控和新病原的快速识别中尤为重要。特别是在疫情暴发时，人工智能的速度和精度可以帮助科学家更快地锁定潜在病原体。”[32]如果没有人工智能，这项工作是不可能想象的。二是知识生产组织模式将催生新的创新联合体，多学科、跨学科和超学科成为科学革命最重要的途径，知识生产必然在更大范围和更深层次上超越传统的学术共同体的范畴，一些新形态的创新联合体将成为推动知识创新的重要组织形式。三是基础设施建设将实现新的升级，传统实验室、教室等教学科研设施将不得不为适应数智革命而改变，以数据、算力、智能互联设施、大模型等为主体的新型公共基础设施建设将不得不加快，学科、专业、课程、教材等数智化转型将步入快车道。四是人类知识版图将得到极大拓展，人工智能自身的领域及其在众多已知和未知领域的广泛应用必将催生许多新的知识领域，从而重塑人类的知识版图。因而，高等教育必须从学科专业设置、科学研究范式转变、创新平台团队的组建等方面入手构建新的创新生态，进而推动教育内容生成方式、结果、效率的转变。\n\n# （三）课程教学范式从传统教学转向智慧教育\n\n大学存在的理由就是促进社会交往，“我们可以展望未来10到20年，大学的一部分功能是促进社交，另一部分则是帮助学生更全面地了解社会。”[33]实际上，教育千百年来常被认为是一项互动性的艺术，传统上教育领域中的互动特指人与人的互动，而“互动”对促进学生知识建构、能力提升、人格养成等方面有至关重要的意义。古希腊的学园时期，受制于信息传播方式、手段的影响，口耳相传是当时主要的教学范式；随着科技的进步，尤其是电子信息技术的进步，声光电热等各种现代科技的发展导致人际交互的场地局限、方式局限等不断被突破，大学开放与开放大学成为教育领域重要的形式，以慕课、可汗学院等为代表的高等教育领域的新型教学范式得到了发展。当前，以AI为牵引的“大数据+大算法+大模型”，让教育教学从大规模、标准化转向个性化、智能化，实现了规模化教学和个性化学习的有机统一。\n\n人工智能技术正在改变传统的工业时代的教与学的方式，智能时代教育新生态的重构已经开始，高等教育必须适应人工智能发展所导致的人际交互模式的改变对高等教育教学范式的影响。一是交互场域从现实空间走向虚实融合，泛在化、个性化自适应学习越来越受关注，智能教学软件、在线资源、虚拟现实技术等在教学中广泛应用，不仅仅能够极大拓展学生的学习空间，未来学习中心、未来课堂等越来越赋予学生学习更大的自主性，尤为重要的是能够满足学生的个性化差异的需求，设计更科学、更富吸引力的教育环境，使得大规模的因材施教成为可能。二是人际交互结构从二元转向三元，“机”不仅是中介变量，而且是自变量甚至因变量，人机协同已延伸至跨界融合，教学的组织形态由过去“师一生”二元模式转变为“师一生一机”多向交互的开放学习生态，“师一机”协同的复合教育者与“生一机”协同的复合学习者，[34]可延伸师生的感知与认知，增强师生互动与体验，以升维方式实现信息传播方式的转变\n\n与内容创造的共享，促使教育范式向“学为中心”的技能本位迈进，并为广泛的人机互动和人际互联创建创新生态。[26]三是人际交互方式从口耳相传转向声光电图文并茂，技术始终在拓展人类表达与理解的边界，声光电与图文、视频、虚拟现实（VR）、增强现实（AR）等技术融合，形成多模态交互，让人际交互的实时性、互动性、沉浸感空前增强，这种由智能技术驱动的交互媒介的迭代升级不仅改变了信息传递的形态，更重塑了师生认知模式、社会关系与文化生态。因而，适应社会交往方式的改变对教育课程教学范式的影响，必须加强智慧教育基本科学问题、关键核心技术、重要应用示范等方面研究，探究新的人类学习机制，[2]打造泛在化学习的数字化校园，创新具有交互式的学习场域、创新多元化互动教学模式，设计更科学、更富吸引力的教育环境，让学生的学和教师的教更富有效率，以塑造更符合学生和教师需求的教育体验，实现教学范式的重大改革。\n\n# （四）教育治理体系从技术赋能转向系统重构\n\n数字化技术使得信息的获取和传播变得更加快捷和广泛，改变了人们的日常生活方式。运用人工智能等现代科学与技术进行教育治理创新，是智能技术赋能教育发展的重要一环。在智能技术的不断渗透下，现代大学不得不考虑科技对高等教育管理范式的影响。高等教育必须积极适应人工智能快速发展导致的组织行为模式的变革趋势，特别是适应信息技术进步与知识创造分享融合发展的教育形态、学习生态和创新生态，加快建设精准全面、集成共享的教师和学生数据库，建立以数据治理为核心、数智技术为驱动的决策支持系统和集中调度平台，围绕网络安全、数据安全、内部控制等管理服务现代化要求，整体推进教育管理与业务流程再造，从而提升教育治理的效能和水平。当然，虽然人工智能可以处理大多数日常任务，但复杂的决策和创新仍需要人类的智慧，在大学治理的各个环节的选择与决策中，人类的创造力仍然是无法替代的关键。\n\n高等教育必须积极适应人工智能快速发展导致的组织行为模式的变革趋势，围绕信息系统、数据安全、内部控制等管理服务现代化要求，整体推进教育管理与业务流程再造，从而提升治理效能和水平。一是治理理念上，要坚持有利于实现大学的本质功能，最能够激发大学的教育家精神和科学家创造力的根本导向，真正把以人为本、学术为魂贯穿大学治理的各个方面和环节。二是治理主体上，应恰当处理不同权利主体之间的利益与风险分配问题，包括教师、学生和管理者在内的大学组织成员的治理理念、素养构成、行为方式等将成为影响大学治理效能的重要因素。三是治理结构上，扁平化、模块化和科学化将突破现有的科层管理结构，大学组织内部及其与社会之间的部门联动、数据互通、资源协同等必将导致条块分割的治理结构被改变。四是治理方式上，由数据驱动的大学治理必将进一步提升决策的科学化、管理的精细化、服务的精准化。现实中，每一所大学都有自己的文化传统、行为习惯、管理文化、资源配置方式，大学的治理理念、治理结构、治理方式等必须不断突破传统的惯性运作，才能构建与高等教育数智变革趋势相适应的治理体系。\n\n# 四、高等教育数智变革的实践应对\n\n“每一次科技革命和产业变革都给教育带来跨越式发展”。①历史表明，世界教育中心、世界科学中心、世界人才中心本质上具有深度的同构逻辑和共生关系。我国是一个高等教育大国，高水平研究型大学在国家高等教育体系和创新体系中具有特殊而重要的地位，必须深刻把握高等教育数智变革的基本逻辑和趋势特点，加快推进发展范式、创新生态、育人体系、治理体系、评价体系的整体性重塑，着力构建符合自身发展目标定位、优势特色和阶段特点的高质量发展体系，在高等教育数智变革中发挥好示\n\n范引领作用。①\n\n# （一）推进教育发展范式系统性变革\n\n高等教育的数智变革不是高等教育传统发展路径的“局部改良”，而是一场深刻的“范式革命”。高水平研究型大学须前瞻把握数智革命影响高等教育变革的底层逻辑，一体推进自身办学理念、发展方式、重大战略的系统性改革，探索一种集思想、理念、标准、评价等为一体的发展新范式。办学理念方面，要牢牢把握教育的政治属性、人民属性、战略属性，以科技发展、国家战略需求为牵引，把为学生提供超越传统知识教育、能力培养和素养养成之上的未来教育作为重要理念，构建智慧教育生态系统，着力培养学生的家国情怀、创新能力、国际视野和未来素养，为每一个学生应对不确定的未来而做好准备。发展方式方面，突出高质量发展主题和内涵式发展主线，充分发挥数智技术在实施大规模因材施教、提升知识生产效率、推动产教深度融合、促进国际创新资源互通方面的重要作用，强化技术驱动、智慧赋能、跨界融合，以数据生态延伸创新生态，探索面向智能时代的高等教育发展新路径。重大战略方面，将以人工智能为代表的现代科技作为战略性变量融入知识生产、人才培养、科技创新、产教融合等创新生态，带动育人方式、办学模式、管理体制、保障机制全方位系统性变革，在回应科技革命和产业变革中加快推进高等教育战略转型。如西南财经大学以建设“新财经”探索高等财经教育发展的新范式，其基本方向就是积极适应和引领现代经济、科技和教育深刻变革，坚持以服务中国式现代化为根本使命、以培养财经拔尖人才为根本任务、以推动建构中国自主知识体系和支撑国家高水平科技自立自强为核心目标、以跨学科和促融通为基本路径、以全面数智赋能为关键动力，着力推进大学功能、学科要素和组织成员的系统性、深层次变革，加快建设财经特色鲜明的世界一流大学。\n\n# （二）推进大学创新生态系统性重构\n\n数智革命正在重构科学研究的底层逻辑和大学的创新生态体系。高水平研究型大学应一体推进学科建设、科研创新和人才发展系统性改革，实现学科布局优化、攻关方向聚焦、人才队伍适配深度耦合，提升创新体系的整体效能，为人类社会发展和文明进步贡献中国智慧。大力优化学科专业布局，着力健全科技创新发展、国家重大战略和区域产业布局需求牵引的学科专业设置调整机制，加快推进传统学科专业数智化转型，布局建设集成电路、人工智能、量子计算、网络空间安全、数据科学等一批能更好支撑发展新质生产力的新兴交叉学科专业，打造优势学科专业集群。推动科学研究范式转换，发挥AI处理海量科研数据（如清华3000+临床病例库）、辅助实验设计、协助数据分析（如DeepMind的AlphaScience项目）、发现传统方法难以捕捉的规律等方面的优势，提升教师的数智素养和创新效率，推动科研范式从假设驱动向数据驱动、从单一学科向交叉融合、从线性研究向非线性创新转变。创新科研组织模式，更加突出与产业发展、社会需求和科技前沿紧密衔接，打破学科边界、学术阻隔、学院壁垒和认知偏见，推动教育链、人才链、产业链、创新链深度融合，建设跨学科、超学科融合的新型创新联合体，提升科学研究组织化水平和原始创新能级。加快新型基础设施建设，建设数据中心、算力中心、智能感知、学科大模型等新型基础设施。如武汉理工大学紧扣云、网、数、端四大要素系统推进算力、网络、数据、平台四大基础要素建设；中国地质大学“元古大模型”利用多模态大模型技术除开展常规的地学图谱形成、地学知识问答外，还具备岩石、化石的智能鉴定、化石物种的智能鉴定、化石图像的智能解译、古生物化石复原、地质文献数据抽取等特色功能。\n\n# （三）推进人才培养体系系统性重塑\n\n教育的目标不是装备学生应对已知的世界，而是赋予他们重塑世界的能力。高水平研究型大学应\n\n着眼数智时代对拔尖创新人才道德伦理、知识结构、能力素养的新需求，一体推进人才培养标准、模式和机制系统性改革，完善以育人育才为中心的教育格局，重塑人才培养的新体系。优化人才培养标准，突出学生数智素养、创新潜能、人机协同能力培养，全面加强专业、课程、教材等标准体系建设，分类构建各学科专业知识图谱、能力图谱、素质图谱。如北京理工大学“知识图谱驱动的智慧教学系统”构建覆盖全校70+本科专业的知识图谱，实现跨学科知识贯通，形成可追溯的知识网络。创新人才培养模式，以跨学科和促融通为主要路径，深化学科、专业、课程交叉融合，转变课程教学范式，实施基于AI的精准教学。如北京大学的“北大问学”平台、中国人民大学“人大未来课堂AI智能助手”、清华大学构建“数据驱动-认知增强-人机协同”的新型的数智教育平台、教学模式等正在实现学生从“标准化生产”到“个性化培育”的转变，尊重和满足课堂中不同层次群体的多样化学习需求和自主选择的权利。健全人才培养机制，进一步完善拔尖人才的发现和培养机制，持续深化产教融合、科教融汇，与行业企业联合打造数字化的课程教材体系，以项目和任务设定牵引课堂，让学生在项目化的场景中学习用知识解决复杂问题，提升拔尖创新人才自主培养能力。如武汉大学通过构建“知识一能力一素质”三位一体的培养体系，让学生在掌握专业知识基础上具备引领未来的关键能力。\n\n# （四）推进内部治理体系系统性优化\n\n大学治理主要解决能在多元利益状况下管理其一般事务的组织性框架及体制机制的问题，尤其是通过内部制度安排，确定包括组织结构的分层、内部权力体系的构成等内部组织结构和运行机制。高水平研究型大学应一体推进治理理念、结构、方式系统性改革，构建体现大学本质规律、符合时代要求、适应中国国情的现代大学制度。在治理理念方面，坚持把促进师生的全面发展摆在首位，充分利用数智技术全面感知、高速传播、跨域交互的优势，推动大学治理从单一管理走向多元共治，增强治理的民主性和科学性。在治理结构方面，利用数智技术优化治理结构，降低信息横向和纵向通达的时间，打通部门之间的行政壁垒，着力解决部门职责交叉边界不清的问题；纵向缩减管理层级降低管理重心，赋予二级单位更大的资源分配权、指挥决策权和管理自主权，增强二级单位推动发展的自主性和创造性。如西北工业大学、南京航空航天大学等正在以大部制、扁平化改革推动大学治理结构优化，进一步核减管理人员的规模。在治理方式上，强化数据驱动的治理效能提升，重塑管理服务流程，建设AI应用生态，进一步提升决策的科学化、管理的精细化、服务的精准化。如西南财经大学与同方知网合作建设学校事业发展数据中台，以学科发展监测、评价等为应用场景实现内部治理信息系统互联互通；同济大学“基于ChatTJ的智慧招生管理平台”实现了大模型技术应用与招生服务的垂直融合。\n\n# （五）推进教育评价体系系统性改革\n\n教育评价事关教育发展方向，有什么样的评价指挥棒，就有什么样的办学导向。研究型大学推动构建自主评价体系须紧紧围绕教育强国建设战略目标和高等教育高质量发展战略主线，在教育评价体系的价值导向、指标设计、评价方式和结果应用上都要前瞻由数智革命驱动的人才培养目标、知识创新生态、课程教学范式、内部治理体系等高等教育的系统性深层次变革趋势，从而构建多元主体参与、符合我国实际、具有世界水平的教育评价体系。价值导向上，深入研究教育强国的具体内涵及其在大学评价中的具体体现，把引领加快建设中国特色世界一流大学和优势学科，更好培养国家急需创新人才、建构中国自主知识体系、支撑国家科技自立自强作为教育评价改革的根本导向，彰显中国教育发展的时代特征和教育评价改革的基本方向。指标设计上，突出扎根中国大地与借鉴世界经验相结合，创造性地吸取国外高等教育评价体系的合理元素，更加注重学科专业与生产力形态变革的适配度、原始创新贡献、学生数智素养培养、课程教学范式转变、内部治理效能等表征高等教育数智变革的新成效。评价方式上，优化基于指标内涵的评价方式，根据指标类型选择评价方式，积极探索多元主体评价、定量与定性\n\n相结合的融合评价，突出评价开放性、自主性、发展性，更加注重大数据、区块链、人工智能等新技术的应用，创新评价的工具、模型、方式，提升评价的科学性和有效性。结果应用上，强化评价结果的诊断功能和促进发展的功效，更加注重教育评价体系在推动大学办学模式、创新生态、育人体系创新中的引领作用，更好地服务国家的世界重要人才中心和创新高地建设。\n\n# 五、结 语\n\n教育部部长怀进鹏在世界教育大会上强调，发展数字教育，推动教育数字化转型，是大势所趋、发展所需、改革所向。随着智能科学与技术尤其是人工智能逐步从“狭义人工智能”（ANI）、“通用人工智能”（AGI）向“超级人工智能”（ASI）发展进阶，可以预料的是，社会各领域观念变革、结构重构、流程再造的广度、深度和速度必将加速演进，数智革命必将会持续渗透和扩大到高等教育的各个领域和层面，成为影响高等教育时代变革的关键动能，从而不断重塑智能时代高等教育的新形态。\n\n# 参考文献：\n\n[1]中国学位与研究生教育学会.怀进鹏在2025世界数字教育大会作主旨演讲[EB/OL].(2025-05-15)[2025-06-06].https://mp.weixin.qq.com/s/re-chwa47TZHqeqlajG3g.  \n[2]杨宗凯等. ChatGPT/生成式人工智能对教育的影响探析及应对策略[J]. 华东师范大学学报(教育科学版), 2023, 41(7): 26-35.  \n[3]徐和祥，申利侠.“智能+教育”：应用场景、风险挑战与治理对策[J].复旦教育论坛，2023,21(2):24-30.  \n[4]蒋里.AI驱动教育改革:ChatGPT/GPT的影响及展望[J].华东师范大学学报(教育科学版),2023,41(7):143-150.  \n[5]陈静远,胡丽雅,吴飞. ChatGPT/生成式人工智能促进以知识点为核心的教学模式变革研究[J].华东师范大学学报(教育科学版),2023,41(7):177-186.  \n[6]焦建利. ChatGPT: 学校教育的朋友还是敌人? [J]. 现代教育技术, 2023, 33(4):5-15.  \n[7]冯永刚,屈玲. ChatGPT运用于教育的伦理风险及其防控[J]. 内蒙古社会科学,2023,44(4):34-42.  \n[8]冯雨奂. ChatGPT 在教育领域的应用价值、潜在伦理风险与治理路径[J]. 思想理论教育, 2023(4):26-32.  \n[9]王佑镁，王旦，梁炜怡，等.“阿拉丁神灯”还是“潘多拉魔盒”：ChatGPT教育应用的潜能与风险[J].现代远程教育研究，2023,35(2):48-56.  \n[10]张务农，汤洁.知与非知——再论人工智能应用对教学主体的影响[J].电化教育研究,2023,44(3):36-43.  \n[11]张缨斌.感知情境与人在回路的智能教育——《人工智能与教学的未来：见解与提议》要点与反思[J].开放教育研究,2023,29(4):11-20.  \n[12]克劳斯·迈因策尔,贾积有,张誉月. ChatGPT和人工智能:从基本原理到教育应用[J].北京大学教育评论,2023,21(1):35-48.  \n[13]李会春. ChatGPT的智慧生成特征及对高等教育的挑战[J]. 江苏高教, 2023(8):1-12.  \n[14]学习强国. 习近平主持十九届中共中央政治局第九次集体学习[EB/OL].(2018-10-31)[2025-06-06].https://www.xuexi.cn/429f88258b2897476c9730c4d81161ee/e43e220633a65f9b6d8b53712cba9caa.html.  \n[15]李晓红.科技创新是发展新质生产力的核心要素[J].中国信息化,2024(7):5-7.  \n[16]MCKINSEY, COMPANY. The economic potential of generative AI: the next productivity frontier[EB/OL]. McKinsey & Company, (2023-06-14) [2025-05-06]. https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier.  \n[17]MCKINSEY, COMPANY. Technology trends outlook 2023[R/OL]. [2025-05-06]. https://www.mckinsey.com/~media/mckinsey/business%20functions/mckinsey%20digital/our%20insights/mckinsey%20technology%20trends%20outlook%202023/mckinsey-technology-trends-outlook-2023-v5.pdf.  \n[18]FROST,SULLIVAN CHINA.2024年中国行业大模型市场报告[R/OL].FROST & SULLIVAN CHINA,2024[2025-05-06].https://www.frostchina.com/content/insight/detail/67346fe60bc989123b87e56d.\n\n[19]马克思.政治经济学批判大纲(1857—1858年手稿)导言[M//马克思恩格斯全集:第30卷.北京:人民出版社, 1995.  \n[20]新浪网. 院士洞见 | 首位华人图灵奖获得者、中科院院士姚期智《人工智能的科学视角》演讲全文[EB/OL]. (2024-10-04)[2025-05-06]. https://k.sina.com.cn/article_6375433705_17c0165e901901cy4q.html.  \n[21]中国科学院网信工作网. DeepMind 发布报告 AI for Science 黄金时代已来[EB/OL].(2024-12-19)[2025-05-06]. https://ecas.cas.cn/xxkw/kbcd/201115_146563/ml/xxhcxyyyal/202412/t20241219_5042988.html.  \n[22]习近平.论科技自立自强[M].北京：中央文献出版社，2023.  \n[23]肖峰.大模型时代的数字交往：“对话中的人”及其新形态[J].人民论坛·学术前沿,2024(19):65-72.  \n[24]李会春. ChatGPT技术热潮下教育变革的挑战和对策[J]. 复旦教育论坛, 2023, 21(2):13-23.  \n[25]阿兰·柯林斯,理查德·哈尔弗森.技术时代重新思考教育:数字革命与美国的学校教育[M].上海:华东师范大学出版社,2013.  \n[26]祝智庭,戴岭,赵晓伟. “近未来”人机协同教育发展新思路[J]. 开放教育研究,2023,29(5):4-13.  \n[27]陈星,吴叶林.人机协同教育治理的障碍与突破[J].现代远程教育研究,2022,34(1):40-47.  \n[28]朱永新,杨帆. ChatGPT/生成式人工智能与教育创新:机遇、挑战以及未来[J].华东师范大学学报(教育科学版), 2023,41(7):1-14.  \n[29]顾小清,胡艺龄,郝祥军. AGI临近了吗:ChatGPT热潮之下再看人工智能与未来教育发展[J].华东师范大学学报(教育科学版),2023,41(7):117-130.  \n[30]海尔格·诺沃特尼，等.反思科学：不确定性时代的知识与公众[M].上海：上海交通大学出版社，2011.  \n[31]HOU X, et al. Using artificial intelligence to document the hidden RNA viosphere[J].Cell, 2024,187(23):6929-6942.  \n[32]中山大学医学院.科研动态|我院施葵教授团队借助人工智能技术开展病毒学研究大幅拓宽RNA病毒库[EB/OL].(2024-10-11)[2025-05-06].https://szmed.sysu.edu.cn/zh-hans/article/2951.  \n[33]科学网.诺奖得主乔治·斯穆特:未来的大学教育中,知识传授将不再重要[EB/OL].(2024-11-01)[2025-05-06].https://news.sciencenet.cn/htmlnews/2024/11/533132.shtml.  \n[34]沈书生,祝智庭. ChatGPT类产品:内在机制及其对学习评价的影响[J]. 中国远程教育,2023(4):8-15.\n\n# Digital-Intelligent Transformation in Higher Education:\n\n# Fundamental Logic, Trends and Characteristics, and Practical Responses\n\n# Li Xue, Li Yongqiang\n\nAbstract: The accelerated iteration and upgrading of intelligent science and technology, represented by ChatGPT and DeepSeek, and their widespread application in human production and life are constantly changing the way humans produce material goods, the logic of knowledge innovation, interpersonal interaction patterns, and organizational behavior. Its impact, penetration, and transformation of higher education extend far beyond the application of science and technology in education in the general sense, triggering comprehensive and profound changes in the objectives of talent cultivation, the knowledge innovation ecosystem, course teaching paradigms, and university governance systems in higher education. Higher education is showing many new trends and characteristics, such as a shift in talent cultivation goals from professional knowledge education to future literacy cultivation, a shift in the knowledge innovation ecosystem from within university organizations to multi-subject collaboration, a shift in course teaching paradigms from traditional teaching to smart education, and a shift in education governance systems from technology empowerment to systemic reconstruction. High-level research universities, which occupy an important position in the national higher education system, should thoroughly grasp these new trends and characteristics, comprehensively promote systematic reforms in development models, innovation ecosystems, education systems, governance systems, and evaluation systems, and play an exemplary and leading role in building a world-class higher education center and better serving the construction of an education powerhouse.\n\nKeywords: Higher Education; Digital-Intelligent Transformation; Fundamental Logic; Trends and Characteristics; High-level Research Universities; Response Strategies\n\n(收稿日期:2025—05—28 责任编辑:赵爱清)",
    "translated_content": null,
    "created_at": "2025-12-15 11:36:36.339515",
    "updated_at": "2025-12-15 11:36:53.450787",
    "analysis": {
      "paper_id": "0a6aae26-e1da-42f9-80f6-19a4250dbeaa",
      "status": "completed",
      "started_at": "2025-12-21T13:15:36.392217",
      "completed_at": "2025-12-21T13:16:52.146538",
      "summary": "# 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 当前研究多从教育技术应用层面分析AI影响，缺乏对高等教育变革底层逻辑的系统性分析 [cite]引言最后一段 |\n| **核心方案** | 提出从物质生产方式、知识生产逻辑、人际交往模式、组织行为方式四个维度分析数智革命对高等教育的基本影响机制 |\n| **关键概念** | \"基本逻辑\"指技术革命通过改变社会基础结构（生产力/知识生产/交往模式/组织形态）倒逼高等教育系统性变革的传导路径 |\n| **核心数据** | 引用麦肯锡(2023)、沙利文(2024)等机构报告数据，以及姚期智、Geoffrey Hinton等权威观点作为论据支撑 |\n| **主要结论** | 高等教育呈现人才培养目标转向未来素养、知识创新生态转向多元协同、教学范式转向智慧教育、治理体系转向系统重构四大趋势 [cite]第三部分 |\n\n# 💡 费曼深度解读 (The Feynman Explanation)\n\n**给厨师朋友的解释：**\n\n想象你是个传统餐厅的主厨，原来你只需要教徒弟切菜、炒菜的标准流程（就像大学教专业知识）。突然市面上出现了**智能炒菜机器人**（好比ChatGPT），它不仅能完美复制你的菜谱，还能自己创新菜式。\n\n这时候问题来了：\n- **原来的教学方式**（=传统高等教育）：继续教徒弟背菜谱、练刀工，但机器人做得更好更快\n- **DESIGNER的思维**（=本文的\"基本逻辑\"）：意识到必须改变教学本质！你要教的不再是\"如何炒宫保鸡丁\"，而是：\n  1. **理解食物化学原理**（物质生产方式变革）\n  2. **创新融合菜系的能力**（知识生产逻辑重塑）  \n  3. **与食客、机器人协作设计菜单**（人际交往模式改变）\n  4. **管理智能厨房团队**（组织行为方式转型）\n\n**为什么这样教出来的徒弟更厉害？**\n因为当机器人已经掌握所有现有菜谱时，人类的价值在于**理解变化背后的规律**，并创造新的可能性。就像本文指出，高等教育的核心不再是传授已知知识，而是培养适应未知未来的底层能力 [cite]第三部分第一节。\n\n# ⚔️ 对抗性评审 (The Adversarial Review)\n\n**Reviewer #2 的尖锐质疑：**\n\n1. **概念操作化不足**：论文将\"基本逻辑\"分解为四个维度看似系统，但缺乏明确的测量指标或验证方法。例如\"知识生产逻辑重塑\"如何区别于传统的跨学科研究？这种分析框架是否具有可证伪性？\n\n2. **证据链薄弱**：大量依赖二手报告（如麦肯锡预测）和权威引述，缺乏一手实证数据。特别是关于\"人际交往模式重构\"的论断，仅基于技术可能性推论，未提供教育场景中人机互动的实际案例观察 [cite]第二部分第三节。\n\n3. **对策建议空泛**：第四部分提出的\"实践应对\"停留在政策宣言层面（如\"重构治理体系\"），缺乏具体实施路径。如何平衡技术赋能与教育本质？在现有体制约束下如何落地？这些关键难点被战略性回避。\n\n# 📝 一句话总结 (The Takeaway)\n\n如果我只记这篇论文的一个贡献，那应该是：**首次将数智革命对高等教育的影响机制系统性地归结为\"生产力-知识生产-交往模式-组织行为\"四重逻辑的连锁变革**，为理解教育数字化转型提供了宏观分析框架。",
      "methods": [
        {
          "name": "文献综述法",
          "description": "通过系统梳理和分析已有研究成果，为研究提供理论基础和研究方向。该方法有助于识别研究空白并确定本文的研究重点。",
          "location": {
            "start_line": 23,
            "end_line": 25,
            "text_snippet": "已有研究开拓了人们对数智革命影响高等教育变革趋势特点的深入认识，其中一些观点、洞见以及相应的实践探索为本文的分析研究提供了很好的借鉴和参照。"
          }
        },
        {
          "name": "逻辑分析法",
          "description": "从宏观视角分析数智革命影响高等教育的内在因果关系和基本规律。该方法强调跳出教育系统本身，从社会大系统的角度进行系统性分析。",
          "location": {
            "start_line": 23,
            "end_line": 25,
            "text_snippet": "分析数智革命对高等教育的影响不能仅仅局限在教育系统内部，必须深入把握以人工智能为代表的数智革命如何影响高等教育变革的基本逻辑。"
          }
        },
        {
          "name": "案例分析法",
          "description": "通过引用具体的研究报告、技术产品和权威奖项等实例，支撑和论证数智革命带来的实际影响。该方法使分析更具说服力和现实基础。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "高等教育的数智变革:",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "基本逻辑、趋势特点及实践应对",
            "level": 1,
            "start_line": 3
          },
          {
            "title": "一、引言与文献综述",
            "level": 1,
            "start_line": 15
          },
          {
            "title": "二、高等教育数智变革的基本逻辑",
            "level": 1,
            "start_line": 25
          },
          {
            "title": "（一）数智革命改变了人类的物质生产方式",
            "level": 1,
            "start_line": 29
          },
          {
            "title": "（二）数智革命重塑了人类的知识生产逻辑",
            "level": 1,
            "start_line": 37
          },
          {
            "title": "（三）数智革命重构了人类的人际交往模式",
            "level": 1,
            "start_line": 43
          },
          {
            "title": "（四）数智革命改变了人类的组织行为方式",
            "level": 1,
            "start_line": 51
          },
          {
            "title": "三、高等教育数智变革的趋势特点",
            "level": 1,
            "start_line": 59
          },
          {
            "title": "（一）人才培养目标从专业知识教育转向未来素养培养",
            "level": 1,
            "start_line": 63
          },
          {
            "title": "（二）知识创新生态从大学组织内部转向多元主体协同",
            "level": 1,
            "start_line": 69
          },
          {
            "title": "（三）课程教学范式从传统教学转向智慧教育",
            "level": 1,
            "start_line": 77
          },
          {
            "title": "（四）教育治理体系从技术赋能转向系统重构",
            "level": 1,
            "start_line": 85
          },
          {
            "title": "四、高等教育数智变革的实践应对",
            "level": 1,
            "start_line": 91
          },
          {
            "title": "（一）推进教育发展范式系统性变革",
            "level": 1,
            "start_line": 97
          },
          {
            "title": "（二）推进大学创新生态系统性重构",
            "level": 1,
            "start_line": 101
          },
          {
            "title": "（三）推进人才培养体系系统性重塑",
            "level": 1,
            "start_line": 105
          },
          {
            "title": "（四）推进内部治理体系系统性优化",
            "level": 1,
            "start_line": 111
          },
          {
            "title": "（五）推进教育评价体系系统性改革",
            "level": 1,
            "start_line": 115
          },
          {
            "title": "五、结 语",
            "level": 1,
            "start_line": 121
          },
          {
            "title": "参考文献：",
            "level": 1,
            "start_line": 125
          },
          {
            "title": "Digital-Intelligent Transformation in Higher Education:",
            "level": 1,
            "start_line": 163
          },
          {
            "title": "Fundamental Logic, Trends and Characteristics, and Practical Responses",
            "level": 1,
            "start_line": 165
          },
          {
            "title": "Li Xue, Li Yongqiang",
            "level": 1,
            "start_line": 167
          }
        ]
      },
      "error_message": null
    },
    "summary": "# 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 当前研究多从教育技术应用层面分析AI影响，缺乏对高等教育变革底层逻辑的系统性分析 [cite]引言最后一段 |\n| **核心方案** | 提出从物质生产方式、知识生产逻辑、人际交往模式、组织行为方式四个维度分析数智革命对高等教育的基本影响机制 |\n| **关键概念** | \"基本逻辑\"指技术革命通过改变社会基础结构（生产力/知识生产/交往模式/组织形态）倒逼高等教育系统性变革的传导路径 |\n| **核心数据** | 引用麦肯锡(2023)、沙利文(2024)等机构报告数据，以及姚期智、Geoffrey Hinton等权威观点作为论据支撑 |\n| **主要结论** | 高等教育呈现人才培养目标转向未来素养、知识创新生态转向多元协同、教学范式转向智慧教育、治理体系转向系统重构四大趋势 [cite]第三部分 |\n\n# 💡 费曼深度解读 (The Feynman Explanation)\n\n**给厨师朋友的解释：**\n\n想象你是个传统餐厅的主厨，原来你只需要教徒弟切菜、炒菜的标准流程（就像大学教专业知识）。突然市面上出现了**智能炒菜机器人**（好比ChatGPT），它不仅能完美复制你的菜谱，还能自己创新菜式。\n\n这时候问题来了：\n- **原来的教学方式**（=传统高等教育）：继续教徒弟背菜谱、练刀工，但机器人做得更好更快\n- **DESIGNER的思维**（=本文的\"基本逻辑\"）：意识到必须改变教学本质！你要教的不再是\"如何炒宫保鸡丁\"，而是：\n  1. **理解食物化学原理**（物质生产方式变革）\n  2. **创新融合菜系的能力**（知识生产逻辑重塑）  \n  3. **与食客、机器人协作设计菜单**（人际交往模式改变）\n  4. **管理智能厨房团队**（组织行为方式转型）\n\n**为什么这样教出来的徒弟更厉害？**\n因为当机器人已经掌握所有现有菜谱时，人类的价值在于**理解变化背后的规律**，并创造新的可能性。就像本文指出，高等教育的核心不再是传授已知知识，而是培养适应未知未来的底层能力 [cite]第三部分第一节。\n\n# ⚔️ 对抗性评审 (The Adversarial Review)\n\n**Reviewer #2 的尖锐质疑：**\n\n1. **概念操作化不足**：论文将\"基本逻辑\"分解为四个维度看似系统，但缺乏明确的测量指标或验证方法。例如\"知识生产逻辑重塑\"如何区别于传统的跨学科研究？这种分析框架是否具有可证伪性？\n\n2. **证据链薄弱**：大量依赖二手报告（如麦肯锡预测）和权威引述，缺乏一手实证数据。特别是关于\"人际交往模式重构\"的论断，仅基于技术可能性推论，未提供教育场景中人机互动的实际案例观察 [cite]第二部分第三节。\n\n3. **对策建议空泛**：第四部分提出的\"实践应对\"停留在政策宣言层面（如\"重构治理体系\"），缺乏具体实施路径。如何平衡技术赋能与教育本质？在现有体制约束下如何落地？这些关键难点被战略性回避。\n\n# 📝 一句话总结 (The Takeaway)\n\n如果我只记这篇论文的一个贡献，那应该是：**首次将数智革命对高等教育的影响机制系统性地归结为\"生产力-知识生产-交往模式-组织行为\"四重逻辑的连锁变革**，为理解教育数字化转型提供了宏观分析框架。",
    "structure": {
      "sections": [
        {
          "title": "高等教育的数智变革:",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "基本逻辑、趋势特点及实践应对",
          "level": 1,
          "start_line": 3
        },
        {
          "title": "一、引言与文献综述",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "二、高等教育数智变革的基本逻辑",
          "level": 1,
          "start_line": 25
        },
        {
          "title": "（一）数智革命改变了人类的物质生产方式",
          "level": 1,
          "start_line": 29
        },
        {
          "title": "（二）数智革命重塑了人类的知识生产逻辑",
          "level": 1,
          "start_line": 37
        },
        {
          "title": "（三）数智革命重构了人类的人际交往模式",
          "level": 1,
          "start_line": 43
        },
        {
          "title": "（四）数智革命改变了人类的组织行为方式",
          "level": 1,
          "start_line": 51
        },
        {
          "title": "三、高等教育数智变革的趋势特点",
          "level": 1,
          "start_line": 59
        },
        {
          "title": "（一）人才培养目标从专业知识教育转向未来素养培养",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "（二）知识创新生态从大学组织内部转向多元主体协同",
          "level": 1,
          "start_line": 69
        },
        {
          "title": "（三）课程教学范式从传统教学转向智慧教育",
          "level": 1,
          "start_line": 77
        },
        {
          "title": "（四）教育治理体系从技术赋能转向系统重构",
          "level": 1,
          "start_line": 85
        },
        {
          "title": "四、高等教育数智变革的实践应对",
          "level": 1,
          "start_line": 91
        },
        {
          "title": "（一）推进教育发展范式系统性变革",
          "level": 1,
          "start_line": 97
        },
        {
          "title": "（二）推进大学创新生态系统性重构",
          "level": 1,
          "start_line": 101
        },
        {
          "title": "（三）推进人才培养体系系统性重塑",
          "level": 1,
          "start_line": 105
        },
        {
          "title": "（四）推进内部治理体系系统性优化",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "（五）推进教育评价体系系统性改革",
          "level": 1,
          "start_line": 115
        },
        {
          "title": "五、结 语",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "参考文献：",
          "level": 1,
          "start_line": 125
        },
        {
          "title": "Digital-Intelligent Transformation in Higher Education:",
          "level": 1,
          "start_line": 163
        },
        {
          "title": "Fundamental Logic, Trends and Characteristics, and Practical Responses",
          "level": 1,
          "start_line": 165
        },
        {
          "title": "Li Xue, Li Yongqiang",
          "level": 1,
          "start_line": 167
        }
      ]
    },
    "tags": [
      "高等教育",
      "教育数字化",
      "人工智能教育应用"
    ],
    "suggested_tags": [
      "高等教育",
      "教育数字化",
      "人工智能教育应用",
      "教育变革",
      "智慧教育"
    ],
    "tag_suggestions": [
      {
        "name": "高等教育",
        "confidence": 0.98,
        "reason": "论文核心研究领域，系统分析高等教育在数智时代的变革逻辑、趋势特点和实践应对"
      },
      {
        "name": "教育数字化",
        "confidence": 0.95,
        "reason": "重点探讨人工智能技术对教育系统的全方位影响，包括教学范式、知识生产、治理体系等数字化转型"
      },
      {
        "name": "人工智能教育应用",
        "confidence": 0.92,
        "reason": "深入分析ChatGPT、DeepSeek等生成式AI在高等教育中的具体应用场景和影响机制"
      },
      {
        "name": "教育变革",
        "confidence": 0.9,
        "reason": "从基本逻辑层面探讨数智革命引发的教育理念、培养目标、创新生态等系统性变革"
      },
      {
        "name": "智慧教育",
        "confidence": 0.88,
        "reason": "涉及课程教学范式从传统教学向智慧教育的转变，分析人机协同教育模式的发展趋势"
      }
    ],
    "tags_confirmed": true
  },
  "e18fee52-bfb3-42f7-b457-ec1c57804020": {
    "id": "e18fee52-bfb3-42f7-b457-ec1c57804020",
    "filename": "2505.10468v1.pdf",
    "file_path": "./uploads/papers/e18fee52-bfb3-42f7-b457-ec1c57804020.pdf",
    "status": "completed",
    "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges",
    "category": null,
    "markdown_content": "# AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges\n\nRanjan Sapkota\\*†, Konstantinos I. Roumeliotis†, Manoj Karkee\\*‡\n\n* Cornell University, Department of Environmental and Biological Engineering, USA\n\n$^{\\dagger}$ Department of Informatics and Telecommunications, University of the Peloponnese, 22131 Tripoli, Greece\n\n†Corresponding authors: rs2672@cornell.edu, mk2684@cornell.edu\n\nAbstract—This review critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven by LLMs and LIMs for narrow, task-specific automation. Generative AI is positioned as a precursor, with AI Agents advancing through tool integration, prompt engineering, and reasoning enhancements. In contrast, Agentic AI systems represent a paradigmatic shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and orchestrated autonomy. Through a sequential evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both paradigms. Application domains such as customer support, scheduling, and data summarization are contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure and propose targeted solutions such as ReAct loops, RAG, orchestration layers, and causal modeling. This work aims to provide a definitive roadmap for developing robust, scalable, and explainable AI-driven systems.\n\nIndex Terms—AI Agents, Agentic AI, Autonomy, Reasoning, Context Awareness, Multi-Agent Systems, Conceptual Taxonomy, vision-language model\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/3ed2affe58af5dd7192c50358456dc7a45d2e51af029c5bbeb82e1fceef60900.jpg)  \nFig. 1: Global Google search trends showing rising interest in \"AI Agents\" and \"Agentic AI\" since November 2022 (ChatGPT Era).\n\n# I. INTRODUCTION\n\nPrior to the widespread adoption of AI agents and agentic AI around 2022 (Before ChatGPT Era), the development of autonomous and intelligent agents was deeply rooted in foundational paradigms of artificial intelligence, particularly multi-agent systems (MAS) and expert systems, which emphasized social action and distributed intelligence [1], [2].\n\nNotably, Castelfranchi [3] laid critical groundwork by introducing ontological categories for social action, structure, and mind, arguing that sociality emerges from individual agents' actions and cognitive processes in a shared environment, with concepts like goal delegation and adoption forming the basis for cooperation and organizational behavior. Similarly, Ferber [4] provided a comprehensive framework for MAS, defining agents as entities with autonomy, perception, and communication capabilities, and highlighting their applications in distributed problem-solving, collective robotics, and synthetic world simulations. These early works established that individual social actions and cognitive architectures are fundamental to modeling collective phenomena, setting the stage for modern AI agents. This paper builds on these insights to explore how social action modeling, as proposed in [3], [4], informs the design of AI agents capable of complex, socially intelligent interactions in dynamic environments.\n\nThese systems were designed to perform specific tasks with predefined rules, limited autonomy, and minimal adaptability to dynamic environments. Agent-like systems were primarily reactive or deliberative, relying on symbolic reasoning, rule-based logic, or scripted behaviors rather than the learning-driven, context-aware capabilities of modern AI agents [5], [6]. For instance, expert systems used knowledge bases and inference engines to emulate human decision-making in domains like medical diagnosis (e.g., MYCIN [7]). Reactive agents, such as those in robotics, followed sense-act cycles based on hardcoded rules, as seen in early autonomous vehicles like the Stanford Cart [8]. Multi-agent systems facilitated coordination among distributed entities, exemplified by auction-based resource allocation in supply chain management [9], [10]. Scripted AI in video games, like NPC behaviors in early RPGs, used predefined decision trees [11]. Furthermore, BDI (Belief-Desire-Intention) architectures enabled goal-directed behavior in software agents, such as those in air traffic control simulations [12], [13]. These early systems lacked the generative capacity, self-learning, and environmental adaptability of modern agentic AI, which leverages deep learning, reinforcement learning, and large-scale data [14].\n\nRecent public and academic interest in AI Agents and Agentic AI reflects this broader transition in system capabilities. As illustrated in Figure 1, Google Trends data demonstrates a significant rise in global search interest for both terms\n\nfollowing the emergence of large-scale generative models in late 2022. This shift is closely tied to the evolution of agent design from the pre-2022 era, where AI agents operated in constrained, rule-based environments, to the post-ChatGPT period marked by learning-driven, flexible architectures [15]–[17]. These newer systems enable agents to refine their performance over time and interact autonomously with unstructured, dynamic inputs [18]–[20]. For instance, while pre-modern expert systems required manual updates to static knowledge bases, modern agents leverage emergent neural behaviors to generalize across tasks [17]. The rise in trend activity reflects increasing recognition of these differences. Moreover, applications are no longer confined to narrow domains like simulations or logistics, but now extend to open-world settings demanding real-time reasoning and adaptive control. This momentum, as visualized in Figure 1, underscores the significance of recent architectural advances in scaling autonomous agents for real-world deployment.\n\nThe release of ChatGPT in November 2022 marked a pivotal inflection point in the development and public perception of artificial intelligence, catalyzing a global surge in adoption, investment, and research activity [21]. In the wake of this breakthrough, the AI landscape underwent a rapid transformation, shifting from the use of standalone LLMs toward more autonomous, task-oriented frameworks [22]. This evolution progressed through two major post generative phases: AI Agents and Agentic AI. Initially, the widespread success of ChatGPT popularized Generative Agents, which are LLM-based systems designed to produce novel outputs such as text, images, and code from user prompts [23], [24]. These agents were quickly adopted across applications ranging from conversational assistants (e.g., GitHub Copilot [25]) and content-generation platforms (e.g., Jasper [26]) to creative tools (e.g., Midjourney [27]), revolutionizing domains like digital design, marketing, and software prototyping throughout 2023.\n\nBuilding on this generative foundation, a new class of systems known as AI Agents emerged. These agents enhanced LLMs with capabilities for external tool use, function calling, and sequential reasoning, enabling them to retrieve real-time information and execute multi-step workflows autonomously [28], [29]. Frameworks such as AutoGPT [30] and BabyAGI (https://github.com/yoheinakajima/babyagi) exemplified this transition, showcasing how LLMs could be embedded within feedback loops to dynamically plan, act, and adapt in goal-driven environments [31], [32]. By late 2023, the field had advanced further into the realm of Agentic AI complex, multi-agent systems in which specialized agents collaboratively decompose goals, communicate, and coordinate toward shared objectives. Architectures such as CrewAI demonstrate how these agentic frameworks can orchestrate decision-making across distributed roles, facilitating intelligent behavior in high-stakes applications including autonomous robotics, logistics management, and adaptive decision-support [33]-[36].\n\nAs the field progresses from Generative Agents toward increasingly autonomous systems, it becomes critically impor-\n\ntant to delineate the technological and conceptual boundaries between AI Agents and Agentic AI. While both paradigms build upon large LLMs and extend the capabilities of generative systems, they embody fundamentally different architectures, interaction models, and levels of autonomy. AI Agents are typically designed as single-entity systems that perform goal-directed tasks by invoking external tools, applying sequential reasoning, and integrating real-time information to complete well-defined functions [17], [37]. In contrast, Agentic AI systems are composed of multiple, specialized agents that coordinate, communicate, and dynamically allocate subtasks within a broader workflow [14], [38]. This architectural distinction underpins profound differences in scalability, adaptability, and application scope.\n\nUnderstanding and formalizing the taxonomy between these two paradigms (AI Agents and Agentic AI) is scientifically significant for several reasons. First, it enables more precise system design by aligning computational frameworks with problem complexity ensuring that AI Agents are deployed for modular, tool-assisted tasks, while Agentic AI is reserved for orchestrated multi-agent operations. Moreover, it allows for appropriate benchmarking and evaluation: performance metrics, safety protocols, and resource requirements differ markedly between individual-task agents and distributed agent systems. Additionally, clear taxonomy reduces development inefficiencies by preventing the misapplication of design principles such as assuming inter-agent collaboration in a system architected for single-agent execution. Without this clarity, practitioners risk both under-engineering complex scenarios that require agentic coordination and over-engineering simple applications that could be solved with a single AI Agent.\n\nSince the field of artificial intelligence has seen significant advancements, particularly in the development of AI Agents and Agentic AI. These terms, while related, refer to distinct concepts with different capabilities and applications. This article aims to clarify the differences between AI Agents and Agentic AI, providing researchers with a foundational understanding of these technologies. The objective of this study is to formalize the distinctions, establish a shared vocabulary, and provide a structured taxonomy between AI Agents and Agentic AI that informs the next generation of intelligent agent design across academic and industrial domains, as illustrated in Figure 2.\n\nThis review provides a comprehensive conceptual and architectural analysis of the progression from traditional AI Agents to emergent Agentic AI systems. Rather than organizing the study around formal research questions, we adopt a sequential, layered structure that mirrors the historical and technical evolution of these paradigms. Beginning with a detailed description of our search strategy and selection criteria, we first establish the foundational understanding of AI Agents by analyzing their defining attributes, such as autonomy, reactivity, and tool-based execution. We then explore the critical role of foundational models specifically LLMs and Large Image Models (LIMs) which serve as the core reasoning and perceptual substrates that drive agentic behavior. Subsequent\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/4cfcf39fb9cd1cdf5e4482e29b6cccd9aa88dd4a3f10bc1d8be7845ac3d1d65e.jpg)  \nFig. 2: Mindmap of Research Questions relevant to AI Agents and Agentic AI. Each color-coded branch represents a key dimension of comparison: Architecture, Mechanisms, Scope/Complexity, Interaction, and Autonomy.\n\nsections examine how generative AI systems have served as precursors to more dynamic, interactive agents, setting the stage for the emergence of Agentic AI. Through this lens, we trace the conceptual leap from isolated, single-agent systems to orchestrated multi-agent architectures, highlighting their structural distinctions, coordination strategies, and collaborative mechanisms. We further map the architectural evolution by dissecting the core system components of both AI Agents and Agentic AI, offering comparative insights into their planning, memory, orchestration, and execution layers. Building upon this foundation, we review application domains spanning customer support, healthcare, research automation, and robotics, categorizing real-world deployments by system capabilities and coordination complexity. We then assess key challenges faced by both paradigms including hallucination, limited reasoning depth, causality deficits, scalability issues, and governance risks. To address these limitations, we outline emerging solutions such as retrieval-augmented generation, tool-based reasoning, memory architectures, and simulation-based planning. The review culminates in a forward-looking roadmap that envisions the convergence of modular AI Agents and orchestrated Agentic AI in mission-critical domains. Overall, this paper aims to provide researchers with a structured taxonomy and actionable insights to guide the design, deployment, and evaluation of next-generation agentic systems.\n\n# A. Methodology Overview\n\nThis review adopts a structured, multi-stage methodology designed to capture the evolution, architecture, application,\n\nand limitations of AI Agents and Agentic AI. The process is visually summarized in Figure 3, which delineates the sequential flow of topics explored in this study. The analytical framework was organized to trace the progression from basic agentic constructs rooted in LLMs to advanced multi-agent orchestration systems. Each step of the review was grounded in rigorous literature synthesis across academic sources and AI-powered platforms, enabling a comprehensive understanding of the current landscape and its emerging trajectories.\n\nThe review begins by establishing a foundational understanding of AI Agents, examining their core definitions, design principles, and architectural modules as described in the literature. These include components such as perception, reasoning, and action selection, along with early applications like customer service bots and retrieval assistants. This foundational layer serves as the conceptual entry point into the broader agentic paradigm.\n\nNext, we delve into the role of LLMs as core reasoning components, emphasizing how pre-trained language models underpin modern AI Agents. This section details how LLMs, through instruction fine-tuning and reinforcement learning from human feedback (RLHF), enable natural language interaction, planning, and limited decision-making capabilities. We also identify their limitations, such as hallucinations, static knowledge, and a lack of causal reasoning.\n\nBuilding on these foundations, the review proceeds to the emergence of Agentic AI, which represents a significant conceptual leap. Here, we highlight the transformation from tool-augmented single-agent systems to collaborative, distributed ecosystems of interacting agents. This shift is driven by the need for systems capable of decomposing goals, assigning subtasks, coordinating outputs, and adapting dynamically to changing contexts capabilities that surpass what isolated AI Agents can offer.\n\nThe next section examines the architectural evolution from AI Agents to Agentic AI systems, contrasting simple, modular agent designs with complex orchestration frameworks. We describe enhancements such as persistent memory, meta-agent coordination, multi-agent planning loops (e.g., ReAct and Chain-of-Thought prompting), and semantic communication protocols. Comparative architectural analysis is supported with examples from platforms like AutoGPT, CrewAI, and Lang-Graph.\n\nFollowing the architectural exploration, the review presents an in-depth analysis of application domains where AI Agents and Agentic AI are being deployed. This includes six key application areas for each paradigm, ranging from knowledge retrieval, email automation, and report summarization for AI Agents, to research assistants, robotic swarms, and strategic business planning for Agentic AI. Use cases are discussed in the context of system complexity, real-time decision-making, and collaborative task execution.\n\nSubsequently, we address the challenges and limitations inherent to both paradigms. For AI Agents, we focus on issues like hallucination, prompt brittleness, limited planning ability, and lack of causal understanding. For Agentic AI, we identify\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/5e2d098f86347ed88c2f8499ef0bbaa689a73aa3e70f248aa88cb518a8aba709.jpg)  \nFig. 3: Methodology pipeline from foundational AI agents to Agentic AI systems, applications, limitations, and solution strategies.\n\nhigher-order challenges such as inter-agent misalignment, error propagation, unpredictability of emergent behavior, explainability deficits, and adversarial vulnerabilities. These problems are critically examined with references to recent experimental studies and technical reports.\n\nFinally, the review outlines potential solutions to overcome these challenges, drawing on recent advances in causal modeling, retrieval-augmented generation (RAG), multi-agent memory frameworks, and robust evaluation pipelines. These strategies are discussed not only as technical fixes but as foundational requirements for scaling agentic systems into high-stakes domains such as healthcare, finance, and autonomous robotics.\n\nTaken together, this methodological structure enables a comprehensive and systematic assessment of the state of AI Agents and Agentic AI. By sequencing the analysis across foundational understanding, model integration, architectural growth, applications, and limitations, the study aims to provide both theoretical clarity and practical guidance to researchers and practitioners navigating this rapidly evolving field.\n\n1) Search Strategy: To construct this review, we implemented a hybrid search methodology combining traditional academic repositories and AI-enhanced literature discovery tools. Specifically, twelve platforms were queried: academic databases such as Google Scholar, IEEE Xplore, ACM Digital Library, Scopus, Web of Science, ScienceDirect, and arXiv; and AI-powered interfaces including ChatGPT, Perplexity.ai, DeepSeek, Hugging Face Search, and Grok. Search queries incorporated Boolean combinations of terms such as \"AI Agents,\" \"Agentic AI,\" \"LLM Agents,\" \"Tool-augmented LLMs,\" and \"Multi-Agent AI Systems.\"\n\nTargeted queries such as \"Agentic AI + Coordination +\n\nPlanning,\" and \"AI Agents + Tool Usage + Reasoning\" were employed to retrieve papers addressing both conceptual underpinnings and system-level implementations. Literature inclusion was based on criteria such as novelty, empirical evaluation, architectural contribution, and citation impact. The rising global interest in these technologies illustrated in Figure 1 using Google Trends data reinforces the urgency of synthesizing this emerging knowledge space.\n\n# II. FOUNDATIONAL UNDERSTANDING OF AI AGENTS\n\nAI Agents are an autonomous software entities engineered for goal-directed task execution within bounded digital environments [14], [39]. These agents are defined by their ability to perceive structured or unstructured inputs [40], reason over contextual information [41], [42], and initiate actions toward achieving specific objectives, often acting as surrogates for human users or subsystems [43]. Unlike conventional automation scripts, which follow deterministic workflows, AI agents demonstrate reactive intelligence and limited adaptability, allowing them to interpret dynamic inputs and reconfigure outputs accordingly [44]. Their adoption has been reported across a range of application domains, including customer service automation [45], [46], personal productivity assistance [47], internal information retrieval [48], [49], and decision support systems [50], [51].\n\n1) Overview of Core Characteristics of AI Agents: AI Agents are widely conceptualized as instantiated operational embodiments of artificial intelligence designed to interface with users, software ecosystems, or digital infrastructures in pursuit of goal-directed behavior [52]–[54]. These agents distinguish themselves from general-purpose LLMs by exhibiting structured initialization, bounded autonomy, and persistent\n\ntask orientation. While LLMs primarily function as reactive prompt followers [55], AI Agents operate within explicitly defined scopes, engaging dynamically with inputs and producing actionable outputs in real-time environments [56].\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/b3f3b81e4c6726d994ba88d2ae2100d82522360cbade29e2e6c02e6a872fdd37.jpg)  \nFig. 4: Core characteristics of AI Agents autonomy, task-specificity, and reactivity illustrated with symbolic representations for agent design and operational behavior.\n\nFigure 4 illustrates the three foundational characteristics that recur across architectural taxonomies and empirical deployments of AI Agents. These include autonomy, task-specificity, and reactivity with adaptation. First, autonomy denotes the agent's ability to act independently post-deployment, minimizing human-in-the-loop dependencies and enabling largescale, unattended operation [46], [57]. Second, task-specificity encapsulates the design philosophy of AI agents being specialized for narrowly scoped tasks allowing high-performance optimization within a defined functional domain such as scheduling, querying, or filtering [58], [59]. Third, reactivity refers to an agent's capacity to respond to changes in its environment, including user commands, software states, or API responses; when extended with adaptation, this includes feedback loops and basic learning heuristics [17], [60].\n\nTogether, these three traits provide a foundational profile for understanding and evaluating AI Agents across deployment scenarios. The remainder of this section elaborates on each characteristic, offering theoretical grounding and illustrative examples.\n\n- Autonomy: A central feature of AI Agents is their ability to function with minimal or no human intervention after deployment [57]. Once initialized, these agents are capable of perceiving environmental inputs, reasoning over contextual data, and executing predefined or adaptive actions in real-time [17]. Autonomy enables scalable deployment in applications where persistent oversight is impractical, such as customer support bots or scheduling assistants [46], [61].  \n- Task-Specificity: AI Agents are purpose-built for narrow, well-defined tasks [58], [59]. They are optimized to execute repeatable operations within a fixed domain, such as email filtering [62], [63], database querying [64], or calendar coordination [38], [65]. This task specialization allows for efficiency, interpretability, and high precision\n\nin automation tasks where general-purpose reasoning is unnecessary or inefficient.\n\n- Reactivity and Adaptation: AI Agents often include basic mechanisms for interacting with dynamic inputs, allowing them to respond to real-time stimuli such as user requests, external API calls, or state changes in software environments [17], [60]. Some systems integrate rudimentary learning [66] through feedback loops [67], [68], heuristics [69], or updated context buffers to refine behavior over time, particularly in settings like personalized recommendations or conversation flow management [70]-[72].\n\nThese core characteristics collectively enable AI Agents to serve as modular, lightweight interfaces between pretrained AI models and domain-specific utility pipelines. Their architectural simplicity and operational efficiency position them as key enablers of scalable automation across enterprise, consumer, and industrial settings. While limited in reasoning depth compared to more general AI systems, their high usability and performance within constrained task boundaries have made them foundational components in contemporary intelligent system design.\n\n2) Foundational Models: The Role of LLMs and LIMs: The foundational progress in AI agents has been significantly accelerated by the development and deployment of LLMs and LIMs, which serve as the core reasoning and perception engines in contemporary agent systems. These models enable AI agents to interact intelligently with their environments, understand multimodal inputs, and perform complex reasoning tasks that go beyond hard-coded automation.\n\nLLMs such as GPT-4 [73] and PaLM [74] are trained on massive datasets of text from books, web content, and dialogue corpora. These models exhibit emergent capabilities in natural language understanding, question answering, summarization, dialogue coherence, and even symbolic reasoning [75], [76]. Within AI agent architectures, LLMs serve as the primary decision-making engine, allowing the agent to parse user queries, plan multi-step solutions, and generate naturalistic responses. For instance, an AI customer support agent powered by GPT-4 can interpret customer complaints, query backend systems via tool integration, and respond in a contextually appropriate and emotionally aware manner [77].\n\nLarge Image Models (LIMs) such as CLIP [78] and BLIP-2 [79] extend the agent's capabilities into the visual domain. Trained on image-text pairs, LIMs enable perception-based tasks including image classification, object detection, and vision-language grounding. These capabilities are increasingly vital for agents operating in domains such as robotics [80], autonomous vehicles [81], [82], and visual content moderation [83], [84].\n\nFor example, as illustrated in Figure 5 in an autonomous drone agent tasked with inspecting orchards, a LIM can identify diseased fruits or damaged branches by interpreting live aerial imagery and triggering predefined intervention protocols. Upon detection, the system autonomously triggers predefined intervention protocols, such as notifying horti\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/e21f8f305fc6c01732664186819ab633e78e369e8b7bc2bc85abf19d0ccb8146.jpg)  \nFig. 5: An AI agent-enabled drone autonomously inspects an orchard, identifying diseased fruits and damaged branches using vision models, and triggers real-time alerts for targeted horticultural interventions\n\ncultural staff or marking the location for targeted treatment without requiring human intervention [17], [57]. This workflow exemplifies the autonomy and reactivity of AI agents in agricultural environment and recent literature underscores the growing sophistication of such drone-based AI agents. Chitra et al. [85] provide a comprehensive overview of AI algorithms foundational to embodied agents, highlighting the integration of computer vision, SLAM, reinforcement learning, and sensor fusion. These components collectively support real-time perception and adaptive navigation in dynamic environments. Kourav et al. [86] further emphasize the role of natural language processing and large language models in generating drone action plans from human-issued queries, demonstrating how LLMs support naturalistic interaction and mission planning. Similarly, Natarajan et al. [87] explore deep learning and reinforcement learning for scene understanding, spatial mapping, and multi-agent coordination in aerial robotics. These studies converge on the critical importance of AI-driven autonomy, perception, and decision-making in advancing drone-based agents.\n\nImportantly, LLMs and LIMs are often accessed via inference APIs provided by cloud-based platforms such as OpenAI https://openai.com/, HuggingFace https://huggingface.co/, and Google Gemini https://gemini.google.com/app. These services abstract away the complexity of model training and fine-tuning, enabling developers to rapidly build and deploy agents equipped with state-of-the-art reasoning and perceptual abilities. This composability accelerates prototyping and allows agent frameworks like LangChain [88] and AutoGen [89] to orchestrate LLM and LIM outputs across task workflows. In short, foundational models give modern AI agents their basic understanding of language and visuals. Language models help them reason with words, and image models help them understand pictures-working together, they allow AI to make\n\nsmart decisions in complex situations.\n\n3) Generative AI as a Precursor: A consistent theme in the literature is the positioning of generative AI as the foundational precursor to agentic intelligence. These systems primarily operate on pretrained LLMs and LIMs, which are optimized to synthesize novel content text, images, audio, or code based on input prompts. While highly expressive, generative models fundamentally exhibit reactive behavior: they produce output only when explicitly prompted and do not pursue goals autonomously or engage in self-initiated reasoning [90], [91].\n\n# Key Characteristics of Generative AI:\n\n- Reactivity: As non-autonomous systems, generative models are exclusively input-driven [92], [93]. Their operations are triggered by user-specified prompts and they lack internal states, persistent memory, or goal-following mechanisms [94]-[96].  \n- Multimodal Capability: Modern generative systems can produce a diverse array of outputs, including coherent narratives, executable code, realistic images, and even speech transcripts. For instance, models like GPT-4 [73], PaLM-E [97], and BLIP-2 [79] exemplify this capacity, enabling language-to-image, image-to-text, and cross-modal synthesis tasks.  \n- Prompt Dependency and Statelessness: Generative systems are stateless in that they do not retain context across interactions unless explicitly provided [98], [99]. Their design lacks intrinsic feedback loops [100], state management [101], [102], or multi-step planning a requirement for autonomous decision-making and iterative goal refinement [103], [104].\n\nDespite their remarkable generative fidelity, these systems are constrained by their inability to act upon the environment or manipulate digital tools independently. For instance, they cannot search the internet, parse real-time data, or interact with APIs without human-engineered wrappers or scaffolding layers. As such, they fall short of being classified as true AI Agents, whose architectures integrate perception, decision-making, and external tool-use within closed feedback loops.\n\nThe limitations of generative AI in handling dynamic tasks, maintaining state continuity, or executing multi-step plans led to the development of tool-augmented systems, commonly referred to as AI Agents [105]. These systems build upon the language processing backbone of LLMs but introduce additional infrastructure such as memory buffers, tool-calling APIs, reasoning chains, and planning routines to bridge the gap between passive response generation and active task completion. This architectural evolution marks a critical shift in AI system design: from content creation to autonomous utility [106], [107]. The trajectory from generative systems to AI agents underscores a progressive layering of functionality that ultimately supports the emergence of agentic behaviors.\n\n# A. Language Models as the Engine for AI Agent Progression\n\nThe emergence of Ai agent as a transformative paradigm in artificial intelligence is closely tied to the evolution and repurposing of large-scale language models such as GPT-3\n\n[108], Llama [109], T5 [110], Baichuan 2 [111] and GPT3mix [112]. A substantial and growing body of research confirms that the leap from reactive generative models to autonomous, goal-directed agents is driven by the integration of LLMs as core reasoning engines within dynamic agentic systems. These models, originally trained for natural language processing tasks, are increasingly embedded in frameworks that require adaptive planning [113], [114], real-time decision-making [115], [116], and environment-aware behavior [117].\n\n1) LLMs as Core Reasoning Components:\n\nLLMs such as GPT-4 [73], PaLM [74], Claude https://www.anthropic.com/news/claude-3-5-sonnet, and LLaMA [109] are pre-trained on massive text corpora using self-supervised objectives and fine-tuned using techniques such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) [118], [119]. These models encode rich statistical and semantic knowledge, allowing them to perform tasks like inference, summarization, code generation, and dialogue management. In agentic contexts, however, their capabilities are repurposed not merely to generate responses, but to serve as cognitive substrates interpreting user goals, generating action plans, selecting tools, and managing multi-turn workflows.\n\nRecent work identifies these models as central to the architecture of contemporary agentic systems. For instance, AutoGPT [30] and BabyAGI https://github.com/yoheinakajima/babyagi use GPT-4 as both a planner and executor: the model analyzes high-level objectives, decomposes them into actionable subtasks, invokes external APIs as needed, and monitors progress to determine subsequent actions. In such systems, the LLM operates in a loop of prompt processing, state updating, and feedback-based correction, closely emulating autonomous decision-making.\n\n2) Tool-Augmented AI Agents: Enhancing Functionality: To overcome limitations inherent to generative-only systems such as hallucination, static knowledge cutoffs, and restricted interaction scopes, researchers have proposed the concept of tool-augmented LLM agents [120] such as Easytool [121], Gentopia [122], and ToolFive [123]. These systems integrate external tools, APIs, and computation platforms into the agent's reasoning pipeline, allowing for real-time information access, code execution, and interaction with dynamic data environments.\n\nTool Invocation. When an agent identifies a need that cannot be addressed through its internal knowledge such as querying a current stock price, retrieving up-to-date weather information, or executing a script, it generates a structured function call or API request [124], [125]. These calls are typically formatted in JSON, SQL, or Python, depending on the target service, and routed through an orchestration layer that executes the task.\n\nResult Integration. Once a response is received from the tool, the output is parsed and reincorporated into the LLM's context window. This enables the agent to synthesize new reasoning paths, update its task status, and decide on the next step. The ReAct framework [126] exemplifies this architecture\n\nby combining reasoning (Chain-of-Thought prompting) and action (tool use), with LLMs alternating between internal cognition and external environment interaction.\n\n3) Illustrative Examples and Emerging Capabilities: Tool-augmented LLM agents have demonstrated capabilities across a range of applications. In AutoGPT [30], the agent may plan a product market analysis by sequentially querying the web, compiling competitor data, summarizing insights, and generating a report. In a coding context, tools like GPT-Engineer combine LLM-driven design with local code execution environments to iteratively develop software artifacts [127], [128]. In research domains, systems like Paper-QA [129] utilize LLMs to query vectorized academic databases, grounding answers in retrieved scientific literature to ensure factual integrity.\n\nThese capabilities have opened pathways for more robust behavior of AI agents such as long-horizon planning, cross-tool coordination, and adaptive learning loops. Nevertheless, the inclusion of tools also introduces new challenges in orchestration complexity, error propagation, and context window limitations all active areas of research. The progression toward AI Agents is inseparable from the strategic integration of LLMs as reasoning engines and their augmentation through structured tool use. This synergy transforms static language models into dynamic cognitive entities capable of perceiving, planning, acting, and adapting setting the stage for multi-agent collaboration, persistent memory, and scalable autonomy.\n\nFigure 6 illustrates a representative case: a news query agent that performs real-time web search, summarizes retrieved documents, and generates an articulate, context-aware answer. Such workflows have been demonstrated in implementations using LangChain, AutoGPT, and OpenAI function-calling paradigms.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/72dfa69d3bad63c0cdb90e6887bf14d1bfeeb9216ca91fa47b43bebc6f0af2fc.jpg)  \nFig. 6: Workflow of an AI Agent performing real-time news search, summarization, and answer generation, as commonly described in the literature (e.g., Author, Year).\n\n# III. THE EMERGENCE OF AGENTIC AI FROM AI AGENT FOUNDATIONS\n\nWhile AI Agents represent a significant leap in artificial intelligence capabilities, particularly in automating narrow tasks through tool-augmented reasoning, recent literature identifies notable limitations that constrain their scalability in complex, multi-step, or cooperative scenarios [130]–[132]. These constraints have catalyzed the development of a more advanced paradigm: Agentic AI. This emerging class of systems extends the capabilities of traditional agents by enabling multiple intelligent entities to collaboratively pursue goals through structured communication [133]–[135], shared memory [136], [137], and dynamic role assignment [14].\n\n1) Conceptual Leap: From Isolated Tasks to Coordinated Systems: AI Agents, as explored in prior sections, integrate LLMs with external tools and APIs to execute narrowly scoped operations such as responding to customer queries, performing document retrieval, or managing schedules. However, as use cases increasingly demand context retention, task interdependence, and adaptability across dynamic environments, the single-agent model proves insufficient [138], [139].\n\nAgentic AI systems represent an emergent class of intelligent architectures in which multiple specialized agents collaborate to achieve complex, high-level objectives. As defined in recent frameworks, these systems are composed of modular agents each tasked with a distinct subcomponent of a broader goal and coordinated through either a centralized orchestrator or a decentralized protocol [16], [134]. This structure signifies a conceptual departure from the atomic, reactive behaviors typically observed in single-agent architectures, toward a form of system-level intelligence characterized by dynamic inter-agent collaboration.\n\nA key enabler of this paradigm is goal decomposition, wherein a user-specified objective is automatically parsed and divided into smaller, manageable tasks by planning agents [38]. These subtasks are then distributed across the agent network. Multi-step reasoning and planning mechanisms facilitate the dynamic sequencing of these subtasks, allowing the system to adapt in real time to environmental shifts or partial task failures. This ensures robust task execution even under uncertainty [14].\n\nInter-agent communication is mediated through distributed communication channels, such as asynchronous messaging queues, shared memory buffers, or intermediate output exchanges, enabling coordination without necessitating continuous central oversight [14], [140]. Furthermore, reflective reasoning and memory systems allow agents to store context across multiple interactions, evaluate past decisions, and iteratively refine their strategies [141]. Collectively, these capabilities enable Agentic AI systems to exhibit flexible, adaptive, and collaborative intelligence that exceeds the operational limits of individual agents.\n\nA widely accepted conceptual illustration in the literature delineates the distinction between AI Agents and Agentic AI through the analogy of smart home systems. As depicted in\n\nFigure 7, the left side represents a traditional AI Agent in the form of a smart thermostat. This standalone agent receives a user-defined temperature setting and autonomously controls the heating or cooling system to maintain the target temperature. While it demonstrates limited autonomy such as learning user schedules or reducing energy usage during absence, it operates in isolation, executing a singular, well-defined task without engaging in broader environmental coordination or goal inference [17], [57].\n\nIn contrast, the right side of Figure 7 illustrates an Agentic AI system embedded in a comprehensive smart home ecosystem. Here, multiple specialized agents interact synergistically to manage diverse aspects such as weather forecasting, daily scheduling, energy pricing optimization, security monitoring, and backup power activation. These agents are not just reactive modules; they communicate dynamically, share memory states, and collaboratively align actions toward a high-level system goal (e.g., optimizing comfort, safety, and energy efficiency in real time). For instance, a weather forecast agent might signal upcoming heatwaves, prompting early pre-cooling via solar energy before peak pricing hours, as coordinated by an energy management agent. Simultaneously, the system might delay high-energy tasks or activate surveillance systems during occupant absence, integrating decisions across domains. This figure embodies the architectural and functional leap from task-specific automation to adaptive, orchestrated intelligence. The AI Agent acts as a deterministic component with limited scope, while Agentic AI reflects distributed intelligence, characterized by goal decomposition, inter-agent communication, and contextual adaptation, hallmarks of modern agentic AI frameworks.\n\n2) Key Differentiators between AI Agents and Agentic AI: To systematically capture the evolution from Generative AI to AI Agents and further to Agentic AI, we structure our comparative analysis around a foundational taxonomy where Generative AI serves as the baseline. While AI Agents and Agentic AI represent increasingly autonomous and interactive systems, both paradigms are fundamentally grounded in generative architectures, especially LLMs and LIMs. Consequently, each comparative table in this subsection includes Generative AI as a reference column to highlight how agentic behavior diverges and builds upon generative foundations.\n\nA set of fundamental distinctions between AI Agents and Agentic AI particularly in terms of scope, autonomy, architectural composition, coordination strategy, and operational complexity are synthesized in Table I, derived from close analysis of prominent frameworks such as AutoGen [89] and ChatDev [142]. These comparisons provide a multi-dimensional view of how single-agent systems transition into coordinated, multiagent ecosystems. Through the lens of generative capabilities, we trace the increasing sophistication in planning, communication, and adaptation that characterizes the shift toward Agentic AI.\n\nWhile Table I delineates the foundational and operational differences between AI Agents and Agentic AI, a more granular taxonomy is required to understand how these paradigms\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/7aeb83720d2279405e2da9490dd653317c44498a9f9c9397d4a57a824791c4f6.jpg)  \nFig. 7: Comparative illustration of AI Agent vs. Agentic AI, synthesizing conceptual distinctions found in the literature (e.g., Author, Year). Left: A single-task AI Agent. Right: A multi-agent, collaborative Agentic AI system.\n\nemerge from and relate to broader generative frameworks. Specifically, the conceptual and cognitive progression from static Generative AI systems to tool-augmented AI Agents, and further to collaborative Agentic AI ecosystems, necessitates an integrated comparative framework. This transition is not merely structural but also functional encompassing how initiation mechanisms, memory use, learning capacities, and orchestration strategies evolve across the agentic spectrum. Moreover, recent studies suggest the emergence of hybrid paradigms such as \"Generative Agents,\" which blend generative modeling with modular task specialization, further complicating the agentic landscape. In order to capture these nuanced relationships, Table II synthesizes the key conceptual and cognitive dimensions across four archetypes: Generative AI, AI Agents, Agentic AI, and inferred Generative Agents. By positioning Generative AI as a baseline technology, this taxonomy highlights the scientific continuum that spans from passive content generation to interactive task execution and finally to autonomous, multi-agent orchestration. This multitiered lens is critical for understanding both the current capabilities and future trajectories of agentic intelligence across applied and theoretical domains.\n\nTo further operationalize the distinctions outlined in Table I, Tables III and II extend the comparative lens to encompass a broader spectrum of agent paradigms including\n\nAI Agents, Agentic AI, and emerging Generative Agents. Table III presents key architectural and behavioral attributes that highlight how each paradigm differs in terms of primary capabilities, planning scope, interaction style, learning dynamics, and evaluation criteria. AI Agents are optimized for discrete task execution with limited planning horizons and rely on supervised or rule-based learning mechanisms. In contrast, Agentic AI systems extend this capacity through multi-step planning, meta-learning, and inter-agent communication, positioning them for use in complex environments requiring autonomous goal setting and coordination. Generative Agents, as a more recent construct, inherit LLM-centric pretraining capabilities and excel in producing multimodal content creatively, yet they lack the proactive orchestration and state-persistent behaviors seen in Agentic AI systems.\n\nThe second table (Table III) provides a process-driven comparison across three agent categories: Generative AI, AI Agents, and Agentic AI. This framing emphasizes how functional pipelines evolve from prompt-driven single-model inference in Generative AI, to tool-augmented execution in AI Agents, and finally to orchestrated agent networks in Agentic AI. The structure column underscores this progression: from single LLMs to integrated toolchains and ultimately to distributed multi-agent systems. Access to external data, a key operational requirement for real-world utility, also increases\n\nTABLE I: Key Differences Between AI Agents and Agentic AI  \n\n<table><tr><td>Feature</td><td>AI Agents</td><td>Agentic AI</td></tr><tr><td>Definition</td><td>Autonomous software programs that perform specific tasks.</td><td>Systems of multiple AI agents collaborating to achieve complex goals.</td></tr><tr><td>Autonomy Level</td><td>High autonomy within specific tasks.</td><td>Higher autonomy with the ability to manage multi-step, complex tasks.</td></tr><tr><td>Task Complexity</td><td>Typically handle single, specific tasks.</td><td>Handle complex, multi-step tasks requiring coordination.</td></tr><tr><td>Collaboration</td><td>Operate independently.</td><td>Involve multi-agent collaboration and information sharing.</td></tr><tr><td>Learning and Adaptation</td><td>Learn and adapt within their specific domain.</td><td>Learn and adapt across a wider range of tasks and environments.</td></tr><tr><td>Applications</td><td>Customer service chatbots, virtual assistants, automated workflows.</td><td>Supply chain management, business process optimization, virtual project managers.</td></tr></table>\n\nin sophistication, from absent or optional in Generative AI to modular and coordinated in Agentic AI. Collectively, these comparative views reinforce that the evolution from generative to agentic paradigms is marked not just by increasing system complexity but also by deeper integration of autonomy, memory, and decision-making across multiple levels of abstraction.\n\nFurthermore, to provide a deeper multi-dimensional understanding of the evolving agentic landscape, Tables V through IX extend the comparative taxonomy to dissect five critical dimensions: core function and goal alignment, architectural composition, operational mechanism, scope and complexity, and interaction-autonomy dynamics. These dimensions serve to not only reinforce the structural differences between Generative AI, AI Agents, and Agentic AI, but also introduce an emergent category Generative Agents representing modular agents designed for embedded subtask-level generation within broader workflows. Table V situates the three paradigms in terms of their overarching goals and functional intent. While Generative AI centers on prompt-driven content generation, AI Agents emphasize tool-based task execution, and Agentic AI systems orchestrate full-fledged workflows. This functional expansion is mirrored architecturally in Table VI, where the system design transitions from single-model reliance (in Generative AI) to multi-agent orchestration and shared memory utilization in Agentic AI. Table VII then outlines how these paradigms differ in their workflow execution pathways, highlighting the rise of inter-agent coordination and hierarchical communication as key drivers of agentic behavior.\n\nFurthermore, Table VIII explores the increasing scope and operational complexity handled by these systems ranging from isolated content generation to adaptive, multi-agent collaboration in dynamic environments. Finally, Table IX synthesizes the varying degrees of autonomy, interaction style,\n\nand decision-making granularity across the paradigms. These tables collectively establish a rigorous framework to classify and analyze agent-based AI systems, laying the groundwork for principled evaluation and future design of autonomous, intelligent, and collaborative agents operating at scale.\n\nEach of the comparative tables presented from Table V through Table IX offers a layered analytical lens to isolate the distinguishing attributes of Generative AI, AI Agents, and Agentic AI, thereby grounding the conceptual taxonomy in concrete operational and architectural features. Table V, for instance, addresses the most fundamental layer of differentiation: core function and system goal. While Generative AI is narrowly focused on reactive content production conditioned on user prompts, AI Agents are characterized by their ability to perform targeted tasks using external tools. Agentic AI, by contrast, is defined by its ability to pursue high-level goals through the orchestration of multiple subagents each addressing a component of a broader workflow. This shift from output generation to workflow execution marks a critical inflection point in the evolution of autonomous systems.\n\nIn Table VI, the architectural distinctions are made explicit, especially in terms of system composition and control logic. Generative AI relies on a single model with no built-in capability for tool use or delegation, whereas AI Agents combine language models with auxiliary APIs and interface mechanisms to augment functionality. Agentic AI extends this further by introducing multi-agent systems where collaboration, memory persistence, and orchestration protocols are central to the system's operation. This expansion is crucial for enabling intelligent delegation, context preservation, and dynamic role assignment capabilities absent in both generative and single-agent systems. Likewise in Table VII dives deeper into how these systems function operationally, emphasizing differences in execution logic and information flow. Unlike Generative AI's linear pipeline (prompt  $\\rightarrow$  output), AI Agents implement procedural mechanisms to incorporate tool responses midprocess. Agentic AI introduces recursive task reallocation and cross-agent messaging, thus facilitating emergent decision-making that cannot be captured by static LLM outputs alone. Table VIII further reinforces these distinctions by mapping each system's capacity to handle task diversity, temporal scale, and operational robustness. Here, Agentic AI emerges as uniquely capable of supporting high-complexity goals that demand adaptive, multi-phase reasoning and execution strategies.\n\nFurthermore, Table IX brings into sharp relief the operational and behavioral distinctions across Generative AI, AI Agents, and Agentic AI, with a particular focus on autonomy levels, interaction styles, and inter-agent coordination. Generative AI systems, typified by models such as GPT-3 [108] and DALL-E https://openai.com/index/dall-e-3/, remain reactive generating content solely in response to prompts without maintaining persistent state or engaging in iterative reasoning. In contrast, AI Agents such as those constructed with LangChain [88] or MetaGPT [143], exhibit a higher degree of autonomy, capable of initiating external tool invocations and adapting behaviors within bounded tasks. However,\n\nTABLE II: Taxonomy Summary of AI Agent Paradigms: Conceptual and Cognitive Dimensions  \n\n<table><tr><td>Conceptual Dimension</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Initiation Type</td><td>Prompt-triggered by user or input</td><td>Prompt or goal-triggered with tool use</td><td>Goal-initiated or orchestrated task</td><td>Prompt or system-level trigger</td><td>Prompt or system-level trigger</td></tr><tr><td>Goal Flexibility</td><td>(None) fixed per prompt</td><td>(Low) executes specific goal</td><td>(High) decomposes and adapts goals</td><td>(Low) guided by subtask goal</td><td>(Low) guided by subtask goal</td></tr><tr><td>Temporal Continuity</td><td>Stateless, single-session output</td><td>Short-term continuity within task</td><td>Persistent across workflow stages</td><td>Context-limited to subtask</td><td>Persistent across workflow stages</td></tr><tr><td>Learning/Adaptation</td><td>Static (pretrained)</td><td>(Might in future) Tool selection strategies may evolve</td><td>(Yes) Learns from outcomes</td><td>Typically static; limited adaptation</td><td>Typically static; limited adaptation</td></tr><tr><td>Memory Use</td><td>No memory or short context window</td><td>Optional memory or tool cache</td><td>Shared episodic/task memory</td><td>Subtask-local or contextual memory</td><td>Subtask-local or contextual memory</td></tr><tr><td>Coordination Strategy</td><td>None (single-step process)</td><td>Isolated task execution</td><td>Hierarchical or decentralized coordination</td><td>Receives instructions from system</td><td>Receives instructions from system</td></tr><tr><td>System Role</td><td>Content generator</td><td>Tool-using task executor</td><td>Collaborative workflow or-chestrator</td><td>Subtask-level modular generator</td><td>Subtask-level modular generator</td></tr></table>\n\nTABLE III: Key Attributes of AI Agents, Agentic AI, and Generative Agents  \n\n<table><tr><td>Aspect</td><td>AI Agent</td><td>Agentic AI</td><td>Generative Agent</td></tr><tr><td>Primary Capability</td><td>Task execution</td><td>Autonomous goal setting</td><td>Content generation</td></tr><tr><td>Planning Horizon</td><td>Single-step</td><td>Multi-step</td><td>N/A (content only)</td></tr><tr><td>Learning Mecanism</td><td>Rule-based or supervised</td><td>Reinforcement/meta-learning</td><td>Large-scale pre-training</td></tr><tr><td>Interaction Style</td><td>Reactive</td><td>Proactive</td><td>Creative</td></tr><tr><td>Evaluation Focus</td><td>Accuracy, latency</td><td>Engagement, adaptability</td><td>Coherence, diversity</td></tr></table>\n\nTABLE IV: Comparison of Generative AI, AI Agents, and Agentic AI  \n\n<table><tr><td>Feature</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td></tr><tr><td>Core Function</td><td>Content generation</td><td>Task-specific execution using tools</td><td>Complex workflow automation</td></tr><tr><td>Mechanism</td><td>Prompt → LLM → Output</td><td>Prompt → Tool Call → LLM → Output</td><td>Goal → Agent Orchestration → Output</td></tr><tr><td>Structure</td><td>Single model</td><td>LLM + tool(s)</td><td>Multi-agent system</td></tr><tr><td>External Data Access</td><td>None (unless added)</td><td>Via external APIs</td><td>Coordinated multi-agent access</td></tr><tr><td>Key Trait</td><td>Reactivity</td><td>Tool-use</td><td>Collaboration</td></tr></table>\n\ntheir autonomy is typically confined to isolated task execution, lacking long-term state continuity or collaborative interaction.\n\nAgentic AI systems mark a significant departure from these paradigms by introducing internal orchestration mechanisms and multi-agent collaboration frameworks. For example, platforms like AutoGen [89] and ChatDev [142] exemplify agentic coordination through task decomposition, role assignment, and recursive feedback loops. In AutoGen, one agent might\n\nserve as a planner while another retrieves information and a third synthesizes a report each communicating through shared memory buffers and governed by an orchestrator agent that monitors dependencies and overall task progression. This structured coordination allows for more complex goal pursuit and flexible behavior in dynamic environments. Such architectures fundamentally shift the locus of intelligence from single-model outputs to emergent system-level behavior, wherein agents learn, negotiate, and update decisions based on evolving task states. Thus, the comparative taxonomy not only highlights increasing levels of operational independence but also illustrates how Agentic AI introduces novel paradigms of communication, memory integration, and decentralized control, paving the way for the next generation of autonomous systems with scalable, adaptive intelligence.\n\n# A. Architectural Evolution: From AI Agents to Agentic AI Systems\n\nWhile both AI Agents and Agentic AI systems are grounded in modular design principles, Agentic AI significantly extends the foundational architecture to support more complex, distributed, and adaptive behaviors. As illustrated in Figure 8, the transition begins with core subsystems Perception, Reasoning, and Action, that define traditional AI Agents. Agentic AI enhances this base by integrating advanced components such as Specialized Agents, Advanced Reasoning & Planning, Persistent Memory, and Orchestration. The figure further emphasizes emergent capabilities including Multi-Agent Collaboration, System Coordination, Shared Context, and Task Decomposition, all encapsulated within a dotted boundary that signifies the shift toward reflective, decentralized, and goal-driven system architectures. This progression marks a fundamental inflection point in intelligent agent design. This section synthesizes findings from empirical frameworks such as LangChain [88], AutoGPT [89], and TaskMatrix [144], highlighting this progression in architectural sophistication.\n\n1) Core Architectural Components of AI Agents: Foundational AI Agents are typically composed of four primary subsystems: perception, reasoning, action, and learning. These\n\nTABLE V: Comparison by Core Function and Goal  \n\n<table><tr><td>Feature</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Primary Goal</td><td>Create novel content based on prompt</td><td>Execute a specific task using external tools</td><td>Automate complex workflow or achieve high-level goals</td><td colspan=\"2\">Perform a specific generative sub-task</td></tr><tr><td>Core Function</td><td>Content generation (text, image, audio, etc.)</td><td>Task execution with external interaction</td><td>Workflow orchestration and goal achievement</td><td colspan=\"2\">Sub-task content generation within a workflow</td></tr></table>\n\nTABLE VI: Comparison by Architectural Components  \n\n<table><tr><td>Component</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Core Engine</td><td>LLM / LIM</td><td>LLM</td><td>Multiple LLMs (potentially diverse)</td><td>LLM</td><td></td></tr><tr><td>Prompts</td><td>Yes (input trigger)</td><td>Yes (task guidance)</td><td>Yes (system goal and agent tasks)</td><td>Yes (sub-task guidance)</td><td></td></tr><tr><td>Tools/APIs</td><td>No (inherently)</td><td>Yes (essential)</td><td>Yes (available to constituent agents)</td><td>Potentially (if sub-task requires)</td><td></td></tr><tr><td>Multiple Agents</td><td>No</td><td>No</td><td>Yes (essential; collaborative)</td><td>No (is an individual agent)</td><td></td></tr><tr><td>Orchestration</td><td>No</td><td>No</td><td>Yes (implicit or explicit)</td><td>No (is part of orchestration)</td><td></td></tr></table>\n\nTABLE VII: Comparison by Operational Mechanism  \n\n<table><tr><td>Mechanism</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Primary Driver</td><td>Reactivity to prompt</td><td>Tool calling for task execution</td><td>Inter-agent communication and collaboration</td><td>Reactivity to input or sub-task prompt</td><td></td></tr><tr><td>Interaction Mode</td><td>User → LLM</td><td>User → Agent → Tool</td><td>User → System → Agents</td><td>System/Agent → Agent → Output</td><td></td></tr><tr><td>Workflow Handling</td><td>Single generation step</td><td>Single task execution</td><td>Multi-step workflow coordination</td><td>Single step within workflow</td><td></td></tr><tr><td>Information Flow</td><td>Input → Output</td><td>Input → Tool → Output</td><td>Input → Agent1 → Agent2 → ... → Output</td><td>Input (from system/agent) → Output</td><td></td></tr></table>\n\nTABLE VIII: Comparison by Scope and Complexity  \n\n<table><tr><td>Aspect</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Task Scope</td><td>Single piece of generated content</td><td>Single, specific, defined task</td><td>Complex, multi-faceted goal or workflow</td><td>Specific sub-task (often generative)</td><td></td></tr><tr><td>Complexity</td><td>Low (relative)</td><td>Medium (integrates tools)</td><td>High (multi-agent coordination)</td><td>Low to Medium (one task component)</td><td></td></tr><tr><td>Example (Video)</td><td>Chatbot</td><td>Tavily Search Agent</td><td>YouTube-to-Blog Conversion System</td><td>Title/Description/Conclusion Generator</td><td></td></tr></table>\n\nTABLE IX: Comparison by Interaction and Autonomy  \n\n<table><tr><td>Feature</td><td>Generative AI</td><td>AI Agent</td><td>Agentic AI</td><td>Generative (Inferred)</td><td>Agent</td></tr><tr><td>Autonomy Level</td><td>Low (requires prompt)</td><td>Medium (uses tools autonomously)</td><td>High (manages entire process)</td><td>Low to Medium (executes sub-task)</td><td></td></tr><tr><td>External Interaction</td><td>None (baseline)</td><td>Via specific tools or APIs</td><td>Through multiple agents/tools</td><td>Possibly via tools (if needed)</td><td></td></tr><tr><td>Internal Interaction</td><td>N/A</td><td>N/A</td><td>High (inter-agent)</td><td>Receives input from system or agent</td><td></td></tr><tr><td>Decision Making</td><td>Pattern selection</td><td>Tool usage decisions</td><td>Goal decomposition and assignment</td><td>Best sub-task generation strategy</td><td></td></tr></table>\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/13f7ce7956eb6484fa632ead0c4954d68dd2195949afb9be183bbec8a96e6cb6.jpg)  \nFig. 8: Illustrating architectural evolution from traditional AI Agents to modern Agentic AI systems. It begins with core modules Perception, Reasoning, and Action and expands into advanced components including Specialized Agents, Advanced Reasoning & Planning, Persistent Memory, and Orchestration. The diagram further captures emergent properties such as Multi-Agent Collaboration, System Coordination, Shared Context, and Task Decomposition, all enclosed within a dotted boundary signifying layered modularity and the transition to distributed, adaptive agentic AI intelligence.\n\nsubsystems form a closed-loop operational cycle, commonly referred to as \"Understand, Think, Act\" from a user interface perspective, or \"Input, Processing, Action, Learning\" in systems design literature [14], [145].\n\n- Perception Module: This subsystem ingests input signals from users (e.g., natural language prompts) or external systems (e.g., APIs, file uploads, sensor streams). It is responsible for preprocessing data into a format interpretable by the agent's reasoning module. For example, in LangChain-based agents [88], [146], the perception layer handles prompt templating, contextual wrapping, and retrieval augmentation via document chunking and embedding search.  \n- Knowledge Representation and Reasoning (KRR) Module: At the core of the agent's intelligence lies the KRR module, which applies symbolic, statistical, or hybrid logic to input data. Techniques include rule-based logic (e.g., if-then decision trees), deterministic workflow engines, and simple planning graphs. Reasoning in agents like AutoGPT [30] is enhanced with function-calling and prompt chaining to simulate thought processes (e.g., \"step-by-step\" prompts or intermediate tool invocations).  \n- Action Selection and Execution Module: This module\n\ntranslates inferred decisions into external actions using an action library. These actions may include sending messages, updating databases, querying APIs, or producing structured outputs. Execution is often managed by middleware like LangChain's \"agent executor,\" which links LLM outputs to tool calls and observes responses for subsequent steps [88].  \n- Basic Learning and Adaptation: Traditional AI Agents feature limited learning mechanisms, such as heuristic parameter adjustment [147], [148] or history-informed context retention. For instance, agents may use simple memory buffers to recall prior user inputs or apply scoring mechanisms to improve tool selection in future iterations.\n\nCustomization of these agents typically involves domain-specific prompt engineering, rule injection, or workflow templates, distinguishing them from hard-coded automation scripts by their ability to make context-aware decisions. Systems like ReAct [126] exemplify this architecture, combining reasoning and action in an iterative framework where agents simulate internal dialogue before selecting external actions.\n\n2) Architectural Enhancements in Agentic AI: Agentic AI systems inherit the modularity of AI Agents but extend\n\ntheir architecture to support distributed intelligence, inter-agent communication, and recursive planning. The literature documents a number of critical architectural enhancements that differentiate Agentic AI from its predecessors [149], [150].\n\n- Ensemble of Specialized Agents: Rather than operating as a monolithic unit, Agentic AI systems consist of multiple agents, each assigned a specialized function e.g., a summarizer, a retriever, a planner. These agents interact via communication channels (e.g., message queues, blackboards, or shared memory). For instance MetaGPT [143] exemplify this approach by modeling agents after corporate departments (e.g., CEO, CTO, engineer), where roles are modular, reusable, and role-bound.  \n- Advanced Reasoning and Planning: Agentic systems embed recursive reasoning capabilities using frameworks such as ReAct [126], Chain-of-Thought (CoT) prompting [151], and Tree of Thoughts [152]. These mechanisms allow agents to break down a complex task into multiple reasoning stages, evaluate intermediate results, and replan actions dynamically. This enables the system to respond adaptively to uncertainty or partial failure.  \n- Persistent Memory Architectures: Unlike traditional agents, Agentic AI incorporates memory subsystems to persist knowledge across task cycles or agent sessions [153], [154]. Memory types include episodic memory (task-specific history) [155], [156], semantic memory (long-term facts or structured data) [157], [158], and vector-based memory for retrieval-augmented generation (RAG) [159], [160]. For example, AutoGen [89] agents maintain scratchpads for intermediate computations, enabling stepwise task progression.  \n- Orchestration Layers / Meta-Agents: A key innovation in Agentic AI is the introduction of orchestrators meta-agents that coordinate the lifecycle of subordinate agents, manage dependencies, assign roles, and resolve conflicts. Orchestrators often include task managers, evaluators, or moderators. In ChatDev [142], for example, a virtual CEO meta-agent distributes subtasks to departmental agents and integrates their outputs into a unified strategic response.\n\nThese enhancements collectively enable Agentic AI to support scenarios that require sustained context, distributed labor, multi-modal coordination, and strategic adaptation. Use cases range from research assistants that retrieve, summarize, and draft documents in tandem (e.g., AutoGen pipelines [89]) to smart supply chain agents that monitor logistics, vendor performance, and dynamic pricing models in parallel.\n\nThe shift from isolated perception—reasoning—action loops to collaborative and reflective multi-agent workflows marks a key inflection point in the architectural design of intelligent systems. This progression positions Agentic AI as the next stage of AI infrastructure capable not only of executing predefined workflows but also of constructing, revising, and managing complex objectives across agents with minimal\n\nhuman supervision.\n\n# IV. APPLICATION OF AI AGENTS AND AGENTIC AI\n\nTo illustrate the real-world utility and operational divergence between AI Agents and Agentic AI systems, this study synthesizes a range of applications drawn from recent literature, as visualized in Figure 9. We systematically categorize and analyze application domains across two parallel tracks: conventional AI Agent systems and their more advanced Agentic AI counterparts. For AI Agents, four primary use cases are reviewed: (1) Customer Support Automation and Internal Enterprise Search, where single-agent models handle structured queries and response generation; (2) Email Filtering and Prioritization, where agents assist users in managing high-volume communication through classification heuristics; (3) Personalized Content Recommendation and Basic Data Reporting, where user behavior is analyzed for automated insights; and (4) Autonomous Scheduling Assistants, which interpret calendars and book tasks with minimal user input. In contrast, Agentic AI applications encompass broader and more dynamic capabilities, reviewed through four additional categories: (1) Multi-Agent Research Assistants that retrieve, synthesize, and draft scientific content collaboratively; (2) Intelligent Robotics Coordination, including drone and multirobot systems in fields like agriculture and logistics; (3) Collaborative Medical Decision Support, involving diagnostic, treatment, and monitoring subsystems; and (4) Multi-Agent Game AI and Adaptive Workflow Automation, where decentralized agents interact strategically or handle complex task pipelines.\n\n1) Application of AI Agents:  \n1) Customer Support Automation and Internal Enterprise Search: AI Agents are widely adopted in enterprise environments for automating customer support and facilitating internal knowledge retrieval. In customer service, these agents leverage retrieval-augmented LLMs interfaced with APIs and organizational knowledge bases to answer user queries, triage tickets, and perform actions like order tracking or return initiation [46]. For internal enterprise search, agents built on vector stores (e.g., Pinecone, Elascticsearch) retrieve semantically relevant documents in response to natural language queries. Tools such as Salesforce Einstein https://www.salesforce.com/artificial-intelligence/, Intercom Fin https://www.intercom.com/fin, and Notion AI https://www.notion.com/product/ai demonstrate how structured input processing and summarization capabilities reduce workload and improve enterprise decision-making.\n\nA practical example (Figure 10a) of this dual functionality can be seen in a multinational e-commerce company deploying an AI Agent-based customer support and internal search assistant. For customer support, the AI Agent integrates with the company's CRM (e.g., Salesforce) and fulfillment APIs to resolve queries such as \"Where is my order?\" or \"How can I return this\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/6f1f5ae95d27da4f73592ce56b6a0eb658ac58fda69c516809c48609f3aa7aeb.jpg)  \nFig. 9: Categorized applications of AI Agents and Agentic AI across eight core functional domains.\n\nitem?\" Within milliseconds, the agent retrieves contextual data from shipping databases and policy repositories, then generates a personalized response using retrieval-augmented generation. For internal enterprise search, employees use the same system to query past meeting notes, sales presentations, or legal documents. When an HR manager types \"summarize key benefits policy changes from last year,\" the agent queries a Pinecone vector store embedded with enterprise documentation, ranks results by semantic similarity, and returns a concise summary along with source links. These capabilities not only reduce ticket volume and support overhead but also minimize time spent searching for institutional knowledge. The result is a unified, responsive system that enhances both external service delivery and internal operational efficiency using modular AI Agent architectures.\n\n2) Email Filtering and Prioritization: Within productivity tools, AI Agents automate email triage through content classification and prioritization. Integrated with systems like Microsoft Outlook and Superhuman, these agents analyze metadata and message semantics to detect urgency, extract tasks, and recommend replies. They apply user-tuned filtering rules, behavioral signals, and intent classification to reduce cognitive overload. Autonomous actions, such as auto-tagging or summarizing threads,\n\nenhance efficiency, while embedded feedback loops enable personalization through incremental learning [61]. Figure10b illustrates a practical implementation of AI Agents in the domain of email filtering and prioritization. In modern workplace environments, users are inundated with high volumes of email, leading to cognitive overload and missed critical communications. AI Agents embedded in platforms like Microsoft Outlook or Superhuman act as intelligent intermediaries that classify, cluster, and triage incoming messages. These agents evaluate metadata (e.g., sender, subject line) and semantic content to detect urgency, extract actionable items, and suggest smart replies. As depicted, the AI agent autonomously categorizes emails into tags such as \"Urgent,\" \"Follow-up,\" and \"Low Priority,\" while also offering context-aware summaries and reply drafts. Through continual feedback loops and usage patterns, the system adapts to user preferences, gradually refining classification thresholds and improving prioritization accuracy. This automation offloads decision fatigue, allowing users to focus on high-value tasks, while maintaining efficient communication management in fast-paced, information-dense environments.\n\n3) Personalized Content Recommendation and Basic Data Reporting: AI Agents support adaptive personalization by analyzing behavioral patterns for news, prod\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/44335adacef08e3f4f132aae2ba85ccb3705cec95311d8119c2d584600e8e262.jpg)  \n(a)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/fbdd3d16b3abf297aa8ad10f931689ed9602605f4e67689bb6dc709054c2de9f.jpg)  \n(b)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/48100b714822e775902f38518c0089951be0c35abd8eecdf490653f38c3f5c3f.jpg)  \n(c)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/e9859731f25c8be9e6c5d789350a38e207e911e32eb99a2e34f6a5c7e99dd02c.jpg)  \n(d)  \nFig. 10: Applications of AI Agents in enterprise settings: (a) Customer support and internal enterprise search; (b) Email filtering and prioritization; (c) Personalized content recommendation and basic data reporting; and (d) Autonomous scheduling assistants. Each example highlights modular AI Agent integration for automation, intent understanding, and adaptive reasoning across operational workflows and user-facing systems.\n\nuct, or media recommendations. Platforms like Amazon, YouTube, and Spotify deploy these agents to infer user preferences via collaborative filtering, intent detection,\n\nand content ranking. Simultaneously, AI Agents in analytics systems (e.g., Tableau Pulse, Power BI Copilot) enable natural-language data queries and automated report generation by converting prompts to structured database queries and visual summaries, democratizing business intelligence access.\n\nA practical illustration (Figure 10c) of AI Agents in personalized content recommendation and basic data reporting can be found in e-commerce and enterprise analytics systems. Consider an AI agent deployed on a retail platform like Amazon: as users browse, click, and purchase items, the agent continuously monitors interaction patterns such as dwell time, search queries, and purchase sequences. Using collaborative filtering and content-based ranking, the agent infers user intent and dynamically generates personalized product suggestions that evolve over time. For example, after purchasing gardening tools, a user may be recommended compatible soil sensors or relevant books. This level of personalization enhances customer engagement, increases conversion rates, and supports long-term user retention. Simultaneously, within a corporate setting, an AI agent integrated into Power BI Copilot allows non-technical staff to request insights using natural language, for instance, \"Compare Q3 and Q4 sales in the Northeast.\" The agent translates the prompt into structured SQL queries, extracts patterns from the database, and outputs a concise visual summary or narrative report. This application reduces dependency on data analysts and empowers broader business decision-making through intuitive, language-driven interfaces.\n\n4) Autonomous Scheduling Assistants: AI Agents integrated with calendar systems autonomously manage meeting coordination, rescheduling, and conflict resolution. Tools like x.ai and Reclaim AI interpret vague scheduling commands, access calendar APIs, and identify optimal time slots using learned user preferences. They minimize human input while adapting to dynamic availability constraints. Their ability to interface with enterprise systems and respond to ambiguous instructions highlights the modular autonomy of contemporary scheduling agents.\n\nA practical application of autonomous scheduling agents can be seen in corporate settings as depicted in Figure 10d where employees manage multiple overlapping responsibilities across global time zones. Consider an executive assistant AI agent integrated with Google Calendar and Slack that interprets a command like \"Find a 45-minute window for a follow-up with the product team next week.\" The agent parses the request, checks availability for all participants, accounts for time zone differences, and avoids meeting conflicts or working-hour violations. If it identifies a conflict with a previously scheduled task, it may autonomously propose alternative windows and notify affected attendees via Slack integration. Additionally, the agent learns from\n\nhistorical user preferences such as avoiding early Friday meetings and refines its suggestions over time. Tools like Reclaim AI and Clockwise exemplify this capability, offering calendar-aware automation that adapts to evolving workloads. Such assistants reduce coordination overhead, increase scheduling efficiency, and enable smoother team workflows by proactively resolving ambiguity and optimizing calendar utilization.\n\nTABLE X: Representative AI Agents (2023-2025): Applications and Operational Characteristics  \n\n<table><tr><td>Model / Reference</td><td>Application Area</td><td>Operation as AI Agent</td></tr><tr><td>ChatGPT Deep Re-search Mode OpenAI (2025) Deep Research OpenAI</td><td>Research Analysis / Reporting</td><td>Synthesizes hundreds of sources into reports; functions as a self-directed research analyst.</td></tr><tr><td>Operator OpenAI (2025) Operator OpenAI</td><td>Web Automation</td><td>Navigates websites, fills forms, and completes online tasks autonomously.</td></tr><tr><td>Agentspace: Deep Re-search Agent Google (2025) Google Agentspace</td><td>Enterprise Reporting</td><td>Generates business intelligence reports using Gemini models.</td></tr><tr><td>NotebookLM Plus Agent Google (2025) NotebookLM</td><td>Knowledge Management</td><td>Summarizes, organizes, and retrieves data across Google Workspace apps.</td></tr><tr><td>Nova Act Amazon (2025) Amazon Nova</td><td>Workflow Automation</td><td>Automates browser-based tasks such as scheduling, HR requests, and email.</td></tr><tr><td>Manus Agent Monica (2025) Manus Agenthttps://manus.im/</td><td>Personal Task Automation</td><td>Executes trip planning, site building, and product comparisons via browsing.</td></tr><tr><td>Harvey Harvey AI (2025) Har-vey</td><td>Legal Automation</td><td>Automates document drafting, legal review, and predictive case analysis.</td></tr><tr><td>Otter Meeting Agent Otter.ai (2025) Otter</td><td>Meeting Management</td><td>Transcribes meetings and provides highlights, summaries, and action items.</td></tr><tr><td>Otter Sales Agent Otter.ai (2025) Otter sales agent</td><td>Sales Enablement</td><td>Analyzes sales calls, extracts insights, and suggests follow-ups.</td></tr><tr><td>ClickUp Brain ClickUp (2025) ClickUp Brain</td><td>Project Manage-ment</td><td>Automates task tracking, updates, and project workflows.</td></tr><tr><td>Agentforce Agentforce (2025) Agentforce</td><td>Customer Support</td><td>Routes tickets and generates context-aware replies for support teams.</td></tr><tr><td>Microsoft Copilot Microsoft (2024) Microsoft Copilot</td><td>Office Productivity</td><td>Automates writing, formula generation, and summarization in Microsoft 365.</td></tr><tr><td>Project Astra Google DeepMind (2025) Project Astra</td><td>Multimodal As-sistance</td><td>Processes text, image, audio, and video for task support and recommendations.</td></tr><tr><td>Claude 3.5 Agent Anthropic (2025) Claude 3.5 Sonnet</td><td>Enterprise Assist-stance</td><td>Uses multimodal input for reasoning, personalization, and enterprise task completion.</td></tr></table>\n\n# 2) Applications of Agentic AI:\n\n1) Multi-Agent Research Assistants: Agentic AI systems are increasingly deployed in academic and industrial research pipelines to automate multi-stage knowledge work. Platforms like AutoGen and CrewAI assign specialized roles to multiple agents retrievers, summarizers,\n\nsynthesizers, and citation formatters under a central orchestrator. The orchestrator distributes tasks, manages role dependencies, and integrates outputs into coherent drafts or review summaries. Persistent memory allows for cross-agent context sharing and refinement over time. These systems are being used for literature reviews, grant preparation, and patent search pipelines, outperforming single-agent systems such as ChatGPT by enabling concurrent sub-task execution and long-context management [89].\n\nFor example, a real-world application of agentic AI as depicted in Figure 11a is in the automated drafting of grant proposals. Consider a university research group preparing a National Science Foundation (NSF) submission. Using an AutoGen-based architecture, distinct agents are assigned: one retrieves prior funded proposals and extracts structural patterns; another scans recent literature to summarize related work; a third agent aligns proposal objectives with NSF solicitation language; and a formatting agent structures the document per compliance guidelines. The orchestrator coordinates these agents, resolving dependencies (e.g., aligning methodology with objectives) and ensuring stylistic consistency across sections. Persistent memory modules store evolving drafts, feedback from collaborators, and funding agency templates, enabling iterative improvement over multiple sessions. Compared to traditional manual processes, this multi-agent system significantly accelerates drafting time, improves narrative cohesion, and ensures regulatory alignment offering a scalable, adaptive approach to collaborative scientific writing in academia and R&D-intensive industries.\n\n2) Intelligent Robotics Coordination: In robotics and automation, Agentic AI underpins collaborative behavior in multi-robot systems. Each robot operates as a task specialized agent such as pickers, transporters, or mappers while an orchestrator supervises and adapts workflows. These architectures rely on shared spatial memory, real-time sensor fusion, and inter-agent synchronization for coordinated physical actions. Use cases include warehouse automation, drone-based orchard inspection, and robotic harvesting [143]. For instance, agricultural drone swarms may collectively map tree rows, identify diseased fruits, and initiate mechanical interventions. This dynamic allocation enables real-time reconfiguration and autonomy across agents facing uncertain or evolving environments.\n\nFor example, in commercial apple orchards (Figure 11b), Agentic AI enables a coordinated multi-robot system to optimize the harvest season. Here, task-specialized robots such as autonomous pickers, fruit classifiers, transport bots, and drone mappers operate as agentic units under a central orchestrator. The mapping drones first survey the orchard and use vision-language models (VLMs) to generate high-resolution yield maps and identify ripe clusters. This spatial data is shared via a\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/10000b10cc77b30216dc2d8ed1d92b4c5093f35aa6400d6aa0d49f22d0789a09.jpg)  \n(a)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9893463a60e955fc5db4119a601640c0ad7880c14639133d39a8adcf0a1e9d4e.jpg)  \n(b)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/798430f46937ff657427e53343c8b9abfc124be2ef119fcf0b5e04f6f1aef15d.jpg)  \n(c)  \nFig. 11: Illustrative Applications of Agentic AI Across Domains: Figure 11 presents four real-world applications of agentic AI systems. (a) Automated grant writing using multi-agent orchestration for structured literature analysis, compliance alignment, and document formatting. (b) Coordinated multi-robot harvesting in apple orchards using shared spatial memory and task-specific agents for mapping, picking, and transport. (c) Clinical decision support in hospital ICUs through synchronized agents for diagnostics, treatment planning, and EHR analysis, enhancing safety and workflow efficiency. (d) Cybersecurity incident response in enterprise environments via agents handling threat classification, compliance analysis, and mitigation planning. In all cases, central orchestrators manage inter-agent communication, shared memory enables context retention, and feedback mechanisms drive continual learning. These use cases highlight agentic AI's capacity for scalable, autonomous task coordination in complex, dynamic environments across science, agriculture, healthcare, and IT security.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/aa5eca44e46e61c780f1204260d9af7144e7c67be00f84130cd5b7c4394b30a1.jpg)  \n(d)\n\ncentralized memory layer accessible by all agents. Picker robots are assigned to high-density zones, guided by path-planning agents that optimize routes around obstacles and labor zones. Simultaneously, transport agents dynamically shuttle crates between pickers and storage, adjusting tasks in response to selector load levels and\n\nterrain changes. All agents communicate asynchronously through a shared protocol, and the orchestrator continuously adjusts task priorities based on weather forecasts or mechanical faults. If one picker fails, nearby units autonomously reallocate workload. This adaptive, memory-driven coordination exemplifies Agentic AI's\n\npotential to reduce labor costs, increase harvest efficiency, and respond to uncertainties in complex agricultural environments far surpassing the rigid programming of legacy agricultural robots [89], [143].\n\n3) Collaborative Medical Decision Support: In high-stakes clinical environments, Agentic AI enables distributed medical reasoning by assigning tasks such as diagnostics, vital monitoring, and treatment planning to specialized agents. For example, one agent may retrieve patient history, another validates findings against diagnostic guidelines, and a third proposes treatment options. These agents synchronize through shared memory and reasoning chains, ensuring coherent, safe recommendations. Applications include ICU management, radiology triage, and pandemic response. Real-world pilots show improved efficiency and decision accuracy compared to isolated expert systems [87].\n\nFor example, in a hospital ICU (Figure 11c), an agentic AI system supports clinicians in managing complex patient cases. A diagnostic agent continuously analyzes vitals and lab data for early detection of sepsis risk. Simultaneously, a history retrieval agent accesses electronic health records (EHRs) to summarize comorbidities and recent procedures. A treatment planning agent cross-references current symptoms with clinical guidelines (e.g., Surviving Sepsis Campaign), proposing antibiotic regimens or fluid protocols. The orchestrator integrates these insights, ensures consistency, and surfaces conflicts for human review. Feedback from physicians is stored in a persistent memory module, allowing agents to refine their reasoning based on prior interventions and outcomes. This coordinated system enhances clinical workflow by reducing cognitive load, shortening decision times, and minimizing oversight risks. Early deployments in critical care and oncology units have demonstrated increased diagnostic precision and better adherence to evidence-based protocols, offering a scalable solution for safer, real-time collaborative medical support.\n\n4) Multi-Agent Game AI and Adaptive Workflow Automation: In simulation environments and enterprise systems, Agentic AI facilitates decentralized task execution and emergent coordination. Game platforms like AI Dungeon deploy independent NPC agents with goals, memory, and dynamic interactivity to create emergent narratives and social behavior. In enterprise workflows, systems such as MultiOn and Cognosys use agents to manage processes like legal review or incident escalation, where each step is governed by a specialized module. These architectures exhibit resilience, exception handling, and feedback-driven adaptability far beyond rule-based pipelines.\n\nFor example, in a modern enterprise IT environment (as depicted in Figure 11d), Agentic AI systems are increasingly deployed to autonomously manage cybersecurity incident response workflows. When a potential\n\nthreat is detected such as abnormal access patterns or unauthorized data exfiltration specialized agents are activated in parallel. One agent performs real-time threat classification using historical breach data and anomaly detection models. A second agent queries relevant log data from network nodes and correlates patterns across systems. A third agent interprets compliance frameworks (e.g., GDPR or HIPAA) to assess the regulatory severity of the event. A fourth agent simulates mitigation strategies and forecasts operational risks. These agents coordinate under a central orchestrator that evaluates collective outputs, integrates temporal reasoning, and issues recommended actions to human analysts. Through shared memory structures and iterative feedback, the system learns from prior incidents, enabling faster and more accurate responses in future cases. Compared to traditional rule-based security systems, this agentic model enhances decision latency, reduces false positives, and supports proactive threat containment in large-scale organizational infrastructures [89].\n\n# V. CHALLENGES AND LIMITATIONS IN AI AGENTS AND AGENTIC AI\n\nTo systematically understand the operational and theoretical limitations of current intelligent systems, we present a comparative visual synthesis in Figure 12, which categorizes challenges and potential remedies across both AI Agents and Agentic AI paradigms. Figure 12a outlines the four most pressing limitations specific to AI Agents namely, lack of causal reasoning, inherited LLM constraints (e.g., hallucinations, shallow reasoning), incomplete agentic properties (e.g., autonomy, proactivity), and failures in long-horizon planning and recovery. These challenges often arise due to their reliance on stateless LLM prompts, limited memory, and heuristic reasoning loops.\n\nIn contrast, Figure 12b identifies eight critical bottlenecks unique to Agentic AI systems, such as inter-agent error cascades, coordination breakdowns, emergent instability, scalability limits, and explainability issues. These challenges stem from the complexity of orchestrating multiple agents across distributed tasks without standardized architectures, robust communication protocols, or causal alignment frameworks.\n\nFigure 13 complements this diagnostic framework by synthesizing ten forward-looking design strategies aimed at mitigating these limitations. These include Retrieval-Augmented Generation (RAG), tool-based reasoning [120], [121], [123], agentic feedback loops (ReAct [126]), role-based multi-agent orchestration, memory architectures, causal modeling, and governance-aware design. Together, these three panels offer a consolidated roadmap for addressing current pitfalls and accelerating the development of safe, scalable, and context-aware autonomous systems.\n\n1) Challenges and Limitations of AI Agents: While AI Agents have garnered considerable attention for their ability to automate structured tasks using LLMs and tool-use interfaces, the literature highlights significant theoretical and practical\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/d7b520e156b5904fa072bdba8e484e202d70696410eda29ff1cd9bfc47bcd27c.jpg)  \n(a)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9f89cccb2bc74ebcefaeda8a5ee9653213dd462cba5d14c8d77a8db9964b0797.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/34234edfbfe0fa6744b642854d20782e31511dde77b8bf7352717cb2832e043f.jpg)  \nFig. 12: Challenges and Solutions Across Agentic Paradigms. (a) Key limitations of AI Agents including causality deficits and shallow reasoning. (b) Amplified coordination and stability challenges in Agentic AI systems.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/399c016aec7419c6505d9aaf27d871e72b42d1c293848aa6bdcbfed067dd7b19.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/0f8be28dd9cf116b5dca027ae369e6932ca9eb91f15da6000f8c19a3541e6229.jpg)  \n(b)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/f72e5ad951dd52dba5aada9f7c06f9301d500bb18ca1bfb6e136aa3c1bd40678.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9d38db690b35acd740eaf65229a71e52396b749c00e40d290f7f5daa8ab9f088.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/2b5bc1df0b14cc5ea70f54f27ae7e2d27faf780c05dad374dae8f33aba222b04.jpg)\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/67477b2e12034e2894a8c07b37fb5b6fa429771300a6c498d58586ae4d6e698e.jpg)\n\nlimitations that inhibit their reliability, generalization, and long-term autonomy [126], [150]. These challenges arise from both the architectural dependence on static, pretrained models and the difficulty of instilling agentic qualities such as causal reasoning, planning, and robust adaptation. The key challenges and limitations (Figure 12a) of AI Agents are as summarized into following five points:\n\n1) Lack of Causal Understanding: One of the most foundational challenges lies in the agents' inability to reason causally [164], [165]. Current LLMs, which form the cognitive core of most AI Agents, excel at identifying statistical correlations within training data. However, as noted in recent research from DeepMind and conceptual analyses by TrueTheta, they fundamentally lack the capacity for causal modeling distinguishing between mere association and cause-effect relationships [166]–[168]. For instance, while an LLM-powered agent might learn that visiting a hospital often co-occurs with illness, it cannot infer whether the illness causes the visit or vice versa, nor can it simulate interventions or hypothetical changes.\n\nThis deficit becomes particularly problematic under distributional shifts, where real-world conditions differ from the training regime [169], [170]. Without such grounding, agents remain brittle, failing in novel or high-stakes scenarios. For example, a navigation agent that excels in urban driving may misbehave in snow or construction zones if it lacks an internal causal model of road traction or spatial occlusion.\n\n2) Inherited Limitations from LLMs: AI Agents, particularly those powered by LLMs, inherit a number of intrinsic limitations that impact their reliability, adaptability, and overall trustworthiness in practical deployments [171]-[173]. One of the most prominent issues is the ten\n\ndency to produce hallucinations plausible but factually incorrect outputs. In high-stakes domains such as legal consultation or scientific research, these hallucinations can lead to severe misjudgments and erode user trust [174], [175]. Compounding this is the well-documented prompt sensitivity of LLMs, where even minor variations in phrasing can lead to divergent behaviors. This brittleness hampers reproducibility, necessitating meticulous manual prompt engineering and often requiring domain-specific tuning to maintain consistency across interactions [176].\n\nFurthermore, while recent agent frameworks adopt reasoning heuristics like Chain-of-Thought (CoT) [151], [177] and ReAct [126] to simulate deliberative processes, these approaches remain shallow in semantic comprehension. Agents may still fail at multi-step inference, misalign task objectives, or make logically inconsistent conclusions despite the appearance of structured reasoning [126]. Such shortcomings underscore the absence of genuine understanding and generalizable planning capabilities.\n\nAnother key limitation lies in computational cost and latency. Each cycle of agentic decision-making particularly in planning or tool-calling may require several LLM invocations. This not only increases runtime latency but also scales resource consumption, creating practical bottlenecks in real-world deployments and cloud-based inference systems. Furthermore, LLMs have a static knowledge cutoff and cannot dynamically integrate new information unless explicitly augmented via retrieval or tool plugins. They also reproduce the biases of their training datasets, which can manifest as culturally insensitive or skewed responses [178], [179]. Without rigorous auditing and mitigation strategies,\n\nTABLE XI: Representative Agentic AI Models (2023-2025): Applications and Operational Characteristics  \n\n<table><tr><td>Model / Reference</td><td>Application Area</td><td>Operation as Agentic AI</td></tr><tr><td>Auto-GPT [30]</td><td>Task Automation</td><td>Decomposes high-level goals, executes subtasks via tools/APIs, and iteratively self-corrects.</td></tr><tr><td>GPT Engineer Open Source (2023) GPT Engineer</td><td>Code Generation</td><td>Builds entire codebases: plans, writes, tests, and re-fines based on output.</td></tr><tr><td>MetaGPT [143])</td><td>Software Collab-oration</td><td>Coordinates specialized agents (e.g., coder, tester) for modular multi-role project development.</td></tr><tr><td>BabyAGI Nakajima (2024) BabyAGI</td><td>Project Manage-ment</td><td>Continuously creates, pri-ortizes, and executes sub-tasks to adaptively meet user goals.</td></tr><tr><td>Voyager Wang et al. (2023) [161]</td><td>Game Exploration</td><td>Learns in Minecraft, in-vents new skills, sets sub-goals, and adapts strategy in real time.</td></tr><tr><td>CAMEL Liu et al. (2023) [162]</td><td>Multi-Agent Simulation</td><td>Simulates agent societies with communication, negotiation, and emergent collaborative behavior.</td></tr><tr><td>Einstein Copilot Salesforce (2024) Einstein Copilot</td><td>Customer Automation</td><td>Automates full support workflows, escalates issues, and improves via feedback loops.</td></tr><tr><td>Copilot Studio (Agentic Mode) Microsoft (2025) Github Agentic Copilot</td><td>Productivity Automata-tion</td><td>Manages documents, meetings, and projects across Microsoft 365 with adaptive orchestration.</td></tr><tr><td>Atera AI Copilot Atera (2025) Atera Agentic AI</td><td>IT Operations</td><td>Diagnoses/resolves IT issues, automates ticketing, and learns from evolving infrastructures.</td></tr><tr><td>AES Safety Audit Agent AES (2025) AES agentic</td><td>Industrial Safety</td><td>Automates audits, assesses compliance, and evolves strategies to enhance safety outcomes.</td></tr><tr><td>DeepMind Gato (Agentic Mode) Reed et al. (2022) [163]</td><td>General Robotics</td><td>Performs varied tasks across modalities, dynamically learns, plans, and executes.</td></tr><tr><td>GPT-4o + Plugins OpenAI (2024) GPT-4O Agentic</td><td>Enterprise Automation</td><td>Manages complex workflows, integrates external tools, and executes adaptive decisions.</td></tr></table>\n\nthese issues pose serious ethical and operational risks, particularly when agents are deployed in sensitive or user-facing contexts.\n\n3) Incomplete Agentic Properties: A major limitation of current AI Agents is their inability to fully satisfy the canonical agentic properties defined in foundational literature, such as autonomy, proactivity, reactivity, and social ability [135], [173]. While many systems marketed as \"agents\" leverage LLMs to perform useful tasks, they often fall short of these fundamental criteria in practice. Autonomy, for instance, is typically partial at best. Although agents can execute tasks with\n\nminimal oversight once initialized, they remain heavily reliant on external scaffolding such as human-defined prompts, planning heuristics, or feedback loops to function effectively [180]. Self-initiated task generation, self-monitoring, or autonomous error correction are rare or absent, limiting their capacity for true independence.\n\nProactivity is similarly underdeveloped. Most AI Agents require explicit user instruction to act and lack the capacity to formulate or reprioritize goals dynamically based on contextual shifts or evolving objectives [181]. As a result, they behave reactively rather than strategically, constrained by the static nature of their initialization. Reactivity itself is constrained by architectural bottlenecks. Agents do respond to environmental or user input, but response latency caused by repeated LLM inference calls [182], [183], coupled with narrow contextual memory windows [153], [184], inhibits real-time adaptability. Perhaps the most underexplored capability is social ability. True agentic systems should communicate and coordinate with humans or other agents over extended interactions, resolving ambiguity, negotiating tasks, and adapting to social norms.\n\nHowever, existing implementations exhibit brittle, template-based dialogue that lacks long-term memory integration or nuanced conversational context. Agent-to-agent interaction is often hardcoded or limited to scripted exchanges, hindering collaborative execution and emergent behavior [96], [185]. Collectively, these deficiencies reveal that while AI Agents demonstrate functional intelligence, they remain far from meeting the formal benchmarks of intelligent, interactive, and adaptive agents. Bridging this gap is essential for advancing toward more autonomous, socially capable AI systems.\n\n4) Limited Long-Horizon Planning and Recovery: A persistent limitation of current AI Agents lies in their inability to perform robust long-horizon planning, especially in complex, multi-stage tasks. This constraint stems from their foundational reliance on stateless prompt-response paradigms, where each decision is made without an intrinsic memory of prior reasoning steps unless externally managed. Although augmentations such as the ReAct framework [126] or Tree-of-Thoughts [152] introduce pseudo-recursive reasoning, they remain fundamentally heuristic and lack true internal models of time, causality, or state evolution. Consequently, agents often falter in tasks requiring extended temporal consistency or contingency planning. For example, in domains such as clinical triage or financial portfolio management, where decisions depend on prior context and dynamically unfolding outcomes, agents may exhibit repetitive behaviors such as endlessly querying tools or fail to adapt when sub-tasks fail or return ambiguous results. The absence of systematic recovery mechanisms or error detection leads to brittle workflows and error propagation. This shortfall severely limits agent deployment in mission-critical environments\n\nwhere reliability, fault tolerance, and sequential coherence are essential.\n\n5) Reliability and Safety Concerns: AI Agents are not yet safe or verifiable enough for deployment in critical infrastructure [186]. The absence of causal reasoning leads to unpredictable behavior under distributional shift [165], [187]. Furthermore, evaluating the correctness of an agent's plan especially when the agent fabricates intermediate steps or rationales remains an unsolved problem in interpretability [104], [188]. Safety guarantees, such as formal verification, are not yet available for open-ended, LLM-powered agents. While AI Agents represent a major step beyond static generative models, their limitations in causal reasoning, adaptability, robustness, and planning restrict their deployment in high-stakes or dynamic environments. Most current systems rely on heuristic wrappers and brittle prompt engineering rather than grounded agentic cognition. Bridging this gap will require future systems to integrate causal models, dynamic memory, and verifiable reasoning mechanisms. These limitations also set the stage for the emergence of Agentic AI systems, which attempt to address these bottlenecks through multi-agent collaboration, orchestration layers, and persistent system-level context.\n\n2) Challenges and Limitations of Agentic AI: Agentic AI systems represent a paradigm shift from isolated AI agents to collaborative, multi-agent ecosystems capable of decomposing and executing complex goals [14]. These systems typically consist of orchestrated or communicating agents that interact via tools, APIs, and shared environments [18], [38]. While this architectural evolution enables more ambitious automation, it introduces a range of amplified and novel challenges that compound existing limitations of individual LLM-based agents. The current challenges and limitations of Agentic AI are as follows:\n\n1) Amplified Causality Challenges: One of the most critical limitations in Agentic AI systems is the magnification of causality deficits already observed in single-agent architectures. Unlike traditional AI Agents that operate in relatively isolated environments, Agentic AI systems involve complex inter-agent dynamics, where each agent's action can influence the decision space of others. Without a robust capacity for modeling cause-effect relationships, these systems struggle to coordinate effectively and adapt to unforeseen environmental shifts. A key manifestation of this challenge is inter-agent distributional shift, where the behavior of one agent alters the operational context for others. In the absence of causal reasoning, agents are unable to anticipate the downstream impact of their outputs, resulting in coordination breakdowns or redundant computations [189]. Furthermore, these systems are particularly vulnerable to error cascades: a faulty or hallucinated output from one agent can propagate through the system, compounding\n\ninaccuracies and corrupting subsequent decisions. For example, if a verification agent erroneously validates false information, downstream agents such as summarizers or decision-makers may unknowingly build upon that misinformation, compromising the integrity of the entire system. This fragility underscores the urgent need for integrating causal inference and intervention modeling into the design of multi-agent workflows, especially in high-stakes or dynamic environments where systemic robustness is essential.\n\n2) Communication and Coordination Bottlenecks: A fundamental challenge in Agentic AI lies in achieving efficient communication and coordination across multiple autonomous agents. Unlike single-agent systems, Agentic AI involves distributed agents that must collectively pursue a shared objective necessitating precise alignment, synchronized execution, and robust communication protocols. However, current implementations fall short in these aspects. One major issue is goal alignment and shared context, where agents often lack a unified semantic understanding of overarching objectives. This hampers sub-task decomposition, dependency management, and progress monitoring, especially in dynamic environments requiring causal awareness and temporal coherence.\n\nIn addition, protocol limitations significantly hinder inter-agent communication. Most systems rely on natural language exchanges over loosely defined interfaces, which are prone to ambiguity, inconsistent formatting, and contextual drift. These communication gaps lead to fragmented strategies, delayed coordination, and degraded system performance. Furthermore, resource contention emerges as a systemic bottleneck when agents simultaneously access shared computational, memory, or API resources. Without centralized orchestration or intelligent scheduling mechanisms, these conflicts can result in race conditions, execution delays, or outright system failures. Collectively, these bottlenecks illustrate the immaturity of current coordination frameworks in Agentic AI, and highlight the pressing need for standardized communication protocols, semantic task planners, and global resource managers to ensure scalable, coherent multi-agent collaboration.\n\n3) Emergent Behavior and Predictability: One of the most critical limitations of Agentic AI lies in managing emergent behavior complex system-level phenomena that arise from the interactions of autonomous agents. While such emergence can potentially yield adaptive and innovative solutions, it also introduces significant unpredictability and safety risks [145], [190]. A key concern is the generation of unintended outcomes, where agent interactions result in behaviors that were not explicitly programmed or foreseen by system designers. These behaviors may diverge from task objectives, generate misleading outputs, or even enact harmful actions particularly in high-stakes domains like healthcare, finance,\n\nor critical infrastructure.\n\nAs the number of agents and the complexity of their interactions grow, so too does the likelihood of system instability. This includes phenomena such as infinite planning loops, action deadlocks, and contradictory behaviors emerging from asynchronous or misaligned agent decisions. Without centralized arbitration mechanisms, conflict resolution protocols, or fallback strategies, these instabilities compound over time, making the system fragile and unreliable. The stochasticity and opacity of large language model-based agents further exacerbate this issue, as their internal decision logic is not easily interpretable or verifiable. Consequently, ensuring the predictability and controllability of emergent behavior remains a central challenge in designing safe and scalable Agentic AI systems.\n\n4) Scalability and Debugging Complexity: As Agentic AI systems scale in both the number of agents and the diversity of specialized roles, maintaining system reliability and interpretability becomes increasingly complex [191], [192]. A central limitation stems from the black-box chains of reasoning characteristic of LLM-based agents. Each agent may process inputs through opaque internal logic, invoke external tools, and communicate with other agents all of which occur through multiple layers of prompt engineering, reasoning heuristics, and dynamic context handling. Tracing the root cause of a failure thus requires unwinding nested sequences of agent interactions, tool invocations, and memory updates, making debugging non-trivial and time-consuming.\n\nAnother significant constraint is the system's non-compositionality. Unlike traditional modular systems, where adding components can enhance overall functionality, introducing additional agents in an Agentic AI architecture often increases cognitive load, noise, and coordination overhead. Poorly orchestrated agent networks can result in redundant computation, contradictory decisions, or degraded task performance. Without robust frameworks for agent role definition, communication standards, and hierarchical planning, the scalability of Agentic AI does not necessarily translate into greater intelligence or robustness. These limitations highlight the need for systematic architectural controls and traceability tools to support the development of reliable, large-scale agentic ecosystems.\n\n5) Trust, Explainability, and Verification: Agentic AI systems pose heightened challenges in explainability and verifiability due to their distributed, multi-agent architecture. While interpreting the behavior of a single LLM-powered agent is already non-trivial, this complexity is multiplied when multiple agents interact asynchronously through loosely defined communication protocols. Each agent may possess its own memory, task objective, and reasoning path, resulting in compounded opacity where tracing the causal chain of a final decision or failure\n\nbecomes exceedingly difficult. The lack of shared, transparent logs or interpretable reasoning paths across agents makes it nearly impossible to determine why a particular sequence of actions occurred or which agent initiated a misstep.\n\nCompounding this opacity is the absence of formal verification tools tailored for Agentic AI. Unlike traditional software systems, where model checking and formal proofs offer bounded guarantees, there exists no widely adopted methodology to verify that a multiagent LLM system will perform reliably across all input distributions or operational contexts. This lack of verifiability presents a significant barrier to adoption in safety-critical domains such as autonomous vehicles, finance, and healthcare, where explainability and assurance are non-negotiable. To advance Agentic AI safely, future research must address the foundational gaps in causal traceability, agent accountability, and formal safety guarantees.\n\n6) Security and Adversarial Risks: Agentic AI architectures introduce a significantly expanded attack surface compared to single-agent systems, exposing them to complex adversarial threats. One of the most critical vulnerabilities lies in the presence of a single point of compromise. Since Agentic AI systems are composed of interdependent agents communicating over shared memory or messaging protocols, the compromise of even one agent through prompt injection, model poisoning, or adversarial tool manipulation can propagate malicious outputs or corrupted state across the entire system. For example, a fact-checking agent fed with tampered data could unintentionally legitimize false claims, which are then integrated into downstream reasoning by summarization or decision-making agents.\n\nMoreover, inter-agent dynamics themselves are susceptible to exploitation. Attackers can induce race conditions, deadlocks, or resource exhaustion by manipulating the coordination logic between agents. Without rigorous authentication, access control, and sandboxing mechanisms, malicious agents or corrupted tool responses can derail multi-agent workflows or cause erroneous escalation in task pipelines. These risks are exacerbated by the absence of standardized security frameworks for LLM-based multi-agent systems, leaving most current implementations defenseless against sophisticated multistage attacks. As Agentic AI moves toward broader adoption, especially in high-stakes environments, embedding secure-by-design principles and adversarial robustness becomes an urgent research imperative.\n\n7) Ethical and Governance Challenges: The distributed and autonomous nature of Agentic AI systems introduces profound ethical and governance concerns, particularly in terms of accountability, fairness, and value alignment. In multi-agent settings, accountability gaps emerge when multiple agents interact to produce an outcome, making it difficult to assign responsibility\n\nfor errors or unintended consequences. This ambiguity complicates legal liability, regulatory compliance, and user trust, especially in domains such as healthcare, finance, or defense. Furthermore, bias propagation and amplification present a unique challenge: agents individually trained on biased data may reinforce each other's skewed decisions through interaction, leading to systemic inequities that are more pronounced than in isolated models. These emergent biases can be subtle and difficult to detect without longitudinal monitoring or audit mechanisms.\n\nAdditionally, misalignment and value drift pose serious risks in long-horizon or dynamic environments. Without a unified framework for shared value encoding, individual agents may interpret overarching objectives differently or optimize for local goals that diverge from human intent. Over time, this misalignment can lead to behavior that is inconsistent with ethical norms or user expectations. Current alignment methods, which are mostly designed for single-agent systems, are inadequate for managing value synchronization across heterogeneous agent collectives. These challenges highlight the urgent need for governance-aware agent architectures, incorporating principles such as role-based isolation, traceable decision logging, and participatory oversight mechanisms to ensure ethical integrity in autonomous multi-agent systems.\n\n8) Immature Foundations and Research Gaps: Despite rapid progress and high-profile demonstrations, Agentic AI remains in a nascent research stage with unresolved foundational issues that limit its scalability, reliability, and theoretical grounding. A central concern is the lack of standard architectures. There is currently no widely accepted blueprint for how to design, monitor, or evaluate multi-agent systems built on LLMs. This architectural fragmentation makes it difficult to compare implementations, replicate experiments, or generalize findings across domains. Key aspects such as agent orchestration, memory structures, and communication protocols are often implemented ad hoc, resulting in brittle systems that lack interoperability and formal guarantees.\n\nEqually critical is the absence of causal foundations as scalable causal discovery and reasoning remain unsolved challenges [193]. Without the ability to represent and reason about cause-effect relationships, Agentic AI systems are inherently limited in their capacity to generalize safely beyond narrow training regimes [170], [194]. This shortfall affects their robustness under distributional shifts, their capacity for proactive intervention, and their ability to simulate counterfactuals or hypothetical plans core requirements for intelligent coordination and decision-making.\n\nThe gap between functional demos and principled design thus underscores an urgent need for foundational research in multi-agent system theory, causal infer\n\nence integration, and benchmark development. Only by addressing these deficiencies can the field progress from prototype pipelines to trustworthy, general-purpose agentic frameworks suitable for deployment in high-stakes environments.\n\n# VI. POTENTIAL SOLUTIONS AND FUTURE ROADMAP\n\nThe potential solutions (as illustrated in Figure 13) to these challenges and limitations of AI agents and Agentic AI are summarized in the following points:\n\n1) Retrieval-Augmented Generation (RAG): For AI Agents, Retrieval-Augmented Generation mitigates hallucinations and expands static LLM knowledge by grounding outputs in real-time data [195]. By embedding user queries and retrieving semantically relevant documents from vector databases like FAISS Faiss or Pinecone Pinecone, agents can generate contextually valid responses rooted in external facts. This is particularly effective in domains such as enterprise search and customer support, where accuracy and up-to-date knowledge are essential.\n\nIn Agentic AI systems, RAG serves as a shared grounding mechanism across agents. For example, a summarizer agent may rely on the retriever agent to access the latest scientific papers before generating a synthesis. Persistent, queryable memory allows distributed agents to operate on a unified semantic layer, mitigating inconsistencies due to divergent contextual views. When implemented across a multi-agent system, RAG helps maintain shared truth, enhances goal alignment, and reduces inter-agent misinformation propagation.\n\n2) Tool-Augmented Reasoning (Function Calling): AI Agents benefit significantly from function calling, which extends their ability to interact with real-world systems [159], [196]. Agents can query APIs, run local scripts, or access structured databases, thus transforming LLMs from static predictors into interactive problem-solvers [125], [154]. This allows them to dynamically retrieve weather forecasts, schedule appointments, or execute Python-based calculations, all beyond the capabilities of pure language modeling.\n\nFor Agentic AI, function calling supports agent level autonomy and role differentiation. Agents within a team may use APIs to invoke domain-specific actions such as querying clinical databases or generating visual charts based on assigned roles. Function calls become part of an orchestrated pipeline, enabling fluid delegation across agents [197]. This structured interaction reduces ambiguity in task handoff and fosters clearer behavioral boundaries, especially when integrated with validation protocols or observation mechanisms [14], [18].\n\n3) Agentic Loop: Reasoning, Action, Observation: AI Agents often suffer from single-pass inference limitations. The ReAct pattern introduces an iterative loop where agents reason about tasks, act by calling tools or APIs, and then observe results before continuing.\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/58d7f580cead0834f8a42b572b1c436a5ca82924b8e64412de53f73add0950bb.jpg)  \nFig. 13: Ten emerging architectural and algorithmic solutions such as RAG, tool use, memory, orchestration, and reflexive mechanisms addressing reliability, scalability, and explainability across both paradigms\n\nThis feedback loop allows for more deliberate, context-sensitive behaviors. For example, an agent may verify retrieved data before drafting a summary, thereby reducing hallucination and logical errors. In Agentic AI, this pattern is critical for collaborative coherence. ReAct enables agents to evaluate dependencies dynamically reasoning over intermediate states, re-invoking tools if needed, and adjusting decisions as the environment evolves. This loop becomes more complex in multiagent settings where each agent's observation must be reconciled against others' outputs. Shared memory and consistent logging are essential here, ensuring that the reflective capacity of the system is not fragmented across agents [126].\n\n4) Memory Architectures (Episodic, Semantic, Vector): AI Agents face limitations in long-horizon planning and session continuity. Memory architectures address this by persisting information across tasks [198]. Episodic memory allows agents to recall prior actions and feedback, semantic memory encodes structured domain knowledge, and vector memory enables similarity-based retrieval [199]. These elements are key for personalization and adaptive decision-making in repeated interactions. Agentic AI systems require even more sophisticated memory models due to distributed state management. Each agent may maintain local memory while accessing shared global memory to facilitate coordination. For example, a planner agent might use vector-based memory to recall prior workflows, while a QA agent references semantic memory for fact verification. Synchronizing memory access and updates across agents enhances consistency, enables context-aware communication, and supports long-horizon system-level planning.\n\n5) Multi-Agent Orchestration with Role Specialization: In AI Agents, task complexity is often handled via modular prompt templates or conditional logic. However, as task diversity increases, a single agent may become overloaded [200], [201]. Role specialization splitting tasks into subcomponents (e.g., planner, summarizer) allows lightweight orchestration even within single-agent systems by simulating compartmentalized reasoning. In Agentic AI, orchestration is central. A meta-agent or orchestrator distributes tasks among specialized agents, each with distinct capabilities. Systems like MetaGPT and ChatDev exemplify this: agents emulate roles such as CEO, engineer, or reviewer, and interact through structured messaging. This modular approach enhances interpretability, scalability, and fault isolation ensuring that failures in one agent do not cascade without containment mechanisms from the orchestrator.\n\n6) Reflexive and Self-Critique Mechanisms: AI Agents often fail silently or propagate errors. Reflexive mechanisms introduce the capacity for self-evaluation [202], [203]. After completing a task, agents can critique their own outputs using a secondary reasoning pass, increasing robustness and reducing error rates. For example, a legal assistant agent might verify that its drafted clause matches prior case laws before submission. For Agentic AI, reflexivity extends beyond self-critique to inter-agent evaluation. Agents can review each other's outputs e.g., a verifier agent auditing a summarizer's work. Reflexion-like mechanisms ensure collaborative quality control and enhance trustworthiness [204]. Such patterns also support iterative improvement and adaptive replanning, particularly when integrated with memory logs or feedback queues [205], [206].\n\n7) Programmatic Prompt Engineering Pipelines: Manual prompt tuning introduces brittleness and reduces reproducibility in AI Agents. Programmatic pipelines automate this process using task templates, context fillers, and retrieval-augmented variables [207], [208]. These dynamic prompts are structured based on task type, agent role, or user query, improving generalization and reducing failure modes associated with prompt variability. In Agentic AI, prompt pipelines enable scalable, role-consistent communication. Each agent type (e.g., planner, retriever, summarizer) can generate or consume structured prompts tailored to its function. By automating message formatting, dependency tracking, and semantic alignment, programmatic prompting prevents coordination drift and ensures consistent reasoning across diverse agents in real time [14], [159].\n\n8) Causal Modeling and Simulation-Based Planning: AI Agents often operate on statistical correlations rather than causal models, leading to poor generalization under distribution shifts. Embedding causal inference allows agents to distinguish between correlation and causation, simulate interventions, and plan more robustly. For instance, in supply chain scenarios, a causally aware agent can simulate the downstream impact of shipment delays. In Agentic AI, causal reasoning is vital for safe coordination and error recovery. Agents must anticipate how their actions impact others requiring causal graphs, simulation environments, or Bayesian inference layers. For example, a planning agent may simulate different strategies and communicate likely outcomes to others, fostering strategic alignment and avoiding unintended emergent behaviors.\n\n9) Monitoring, Auditing, and Explainability Pipelines: AI Agents lack transparency, complicating debugging and trust. Logging systems that record prompts, tool calls, memory updates, and outputs enable post-hoc analysis and performance tuning. These records help developers trace faults, refine behavior, and ensure compliance with usage guidelines especially critical in enterprise or legal domains. For Agentic AI, logging and explainability are exponentially more important. With multiple agents interacting asynchronously, audit trails are essential for identifying which agent caused an error and under what conditions. Explainability pipelines that integrate across agents (e.g., timeline visualizations or dialogue replays) are key to ensuring safety, especially in regulatory or multi-stakeholder environments.\n\n10) Governance-Aware Architectures (Accountability and Role Isolation): AI Agents currently lack built-in safeguards for ethical compliance or error attribution. Governance-aware designs introduce role-based access control, sandboxing, and identity resolution to ensure agents act within scope and their decisions can be audited or revoked. These structures reduce risks in sensitive applications such as healthcare or finance. In Agentic AI, governance must scale across roles,\n\nagents, and workflows. Role isolation prevents rogue agents from exceeding authority, while accountability mechanisms assign responsibility for decisions and trace causality across agents. Compliance protocols, ethical alignment checks, and agent authentication ensure safety in collaborative settings paving the way for trustworthy AI ecosystems.\n\nAI Agents are projected to evolve significantly through enhanced modular intelligence focused on five key domains as depicted in Figure 14 as: proactive reasoning, tool integration, causal inference, continual learning, and trust-centric operations. The first transformative milestone involves transitioning from reactive to Proactive Intelligence, where agents initiate tasks based on learned patterns, contextual cues, or latent goals rather than awaiting explicit prompts. This advancement depends heavily on robust Tool Integration, enabling agents to dynamically interact with external systems, such as databases, APIs, or simulation environments, to fulfill complex user tasks. Equally critical is the development of Causal Reasoning, which will allow agents to move beyond statistical correlation, supporting inference of cause-effect relationships essential for tasks involving diagnosis, planning, or prediction. To maintain relevance over time, agents must adopt frameworks for Continuous Learning, incorporating feedback loops and episodic memory to adapt their behavior across sessions and environments. Lastly, to build user confidence, agents must prioritize Trust & Safety mechanisms through verifiable output logging, bias detection, and ethical guardrails especially as their autonomy increases. Together, these pathways will redefine AI Agents from static tools into adaptive cognitive systems capable of autonomous yet controllable operation in dynamic digital environments.\n\nAgentic AI, as a natural extension of these foundations, emphasizes collaborative intelligence through multi-agent coordination, contextual persistence, and domain-specific orchestration. Future systems (Figure 14 right side) will exhibit Multi-Agent Scaling, enabling specialized agents to work in parallel under distributed control for complex problem-solving mirroring team-based human workflows. This necessitates a layer of Unified Orchestration, where meta-agents or orchestrators dynamically assign roles, monitor task dependencies, and mediate conflicts among subordinate agents. Sustained performance over time depends on Persistent Memory architectures, which preserve semantic, episodic, and shared knowledge for agents to coordinate longitudinal tasks and retain state awareness. Simulation Planning is expected to become a core feature, allowing agent collectives to test hypothetical strategies, forecast consequences, and optimize outcomes before real-world execution. Moreover, Ethical Governance frameworks will be essential to ensure responsible deployment defining accountability, oversight, and value alignment across autonomous agent networks. Finally, tailored Domain-Specific Systems will emerge in fields like law, medicine, and supply chains, leveraging contextual specialization to outperform generic agents. This future positions Agentic AI not merely\n\n![](/uploads/images/e18fee52-bfb3-42f7-b457-ec1c57804020/9a523150fc969434f3864d2f1517cc5a8ae8008eb543a5d62d26c7a165f33a8b.jpg)  \nFig. 14: Mindmap visualization of the future roadmap for AI Agents and Agentic AI.\n\nas a coordination layer on the top of AI Agents, but as a new paradigm for collective machine intelligence with adaptive planning, recursive reasoning, and collaborative cognition at its core.\n\n# VII. CONCLUSION\n\nIn this study, we presented a comprehensive literature-based evaluation of the evolving landscape of AI Agents and Agentic AI, offering a structured taxonomy that highlights foundational concepts, architectural evolution, application domains, and key limitations. Beginning with a foundational understanding, we characterized AI Agents as modular, task-specific entities with constrained autonomy and reactivity. Their operational scope is grounded in the integration of LLMs and LIMs, which serve as core reasoning modules for perception, language understanding, and decision-making. We identified generative AI as a functional precursor, emphasizing its limitations in autonomy and goal persistence, and examined how LLMs drive the progression from passive generation to interactive task completion through tool augmentation.\n\nThis study then explored the conceptual emergence of Agentic AI systems as a transformative evolution from isolated agents to orchestrated, multi-agent ecosystems. We analyzed key differentiators such as distributed cognition, persistent memory, and coordinated planning that distinguish Agentic AI from conventional agent models. This was followed by a detailed breakdown of architectural evolution, highlighting the transition from monolithic, rule-based frameworks to\n\nmodular, role specialized networks facilitated by orchestration layers and reflective memory architectures. Additionally, this study then surveyed application domains in which these paradigms are deployed. For AI Agents, we illustrated their role in automating customer support, internal enterprise search, email prioritization, and scheduling. For Agentic AI, we demonstrated use cases in collaborative research, robotics, medical decision support, and adaptive workflow automation, supported by practical examples and industry-grade systems. Finally, this study provided a deep analysis of the challenges and limitations affecting both paradigms. For AI Agents, we discussed hallucinations, shallow reasoning, and planning constraints, while for Agentic AI, we addressed amplified causality issues, coordination bottlenecks, emergent behavior, and governance concerns. These insights offer a roadmap for future development and deployment of trustworthy, scalable agentic systems.\n\n# ACKNOWLEDGEMENT\n\nThis work was supported by the National Science Foundation and the United States Department of Agriculture, National Institute of Food and Agriculture through the \"Artificial Intelligence (AI) Institute for Agriculture\" Program under Award AWD003473, and AWD004595, Accession Number 1029004, \"Robotic Blossom Thinning with Soft Manipulators\".\n\n# DECLARATIONS\n\nThe authors declare no conflicts of interest.\n\n# STATEMENT ON AI WRITING ASSISTANCE\n\nChatGPT and Perplexity were utilized to enhance grammatical accuracy and refine sentence structure; all AI-generated revisions were thoroughly reviewed and edited for relevance. Additionally, ChatGPT-4o was employed to generate realistic visualizations.\n\n# REFERENCES\n\n[1] E. Oliveira, K. Fischer, and O. Stepankova, “Multi-agent systems: which research for which applications,” Robotics and Autonomous Systems, vol. 27, no. 1-2, pp. 91–106, 1999.  \n[2] Z. Ren and C. J. Anumba, \"Multi-agent systems in construction-state of the art and prospects,\" Automation in Construction, vol. 13, no. 3, pp. 421-434, 2004.  \n[3] C. Castelfranchi, “Modelling social action for ai agents,” Artificial intelligence, vol. 103, no. 1-2, pp. 157-182, 1998.  \n[4] J. Ferber and G. Weiss, Multi-agent systems: an introduction to distributed artificial intelligence, vol. 1. Addison-wesley Reading, 1999.  \n[5] R. Calegari, G. Ciatto, V. Mascardi, and A. Omicini, \"Logic-based technologies for multi-agent systems: a systematic literature review,\" Autonomous Agents and Multi-Agent Systems, vol. 35, no. 1, p. 1, 2021.  \n[6] R. C. Cardoso and A. Ferrando, “A review of agent-based programming for multi-agent systems,” Computers, vol. 10, no. 2, p. 16, 2021.  \n[7] E. Shortliffe, Computer-based medical consultations: MYCIN, vol. 2. Elsevier, 2012.  \n[8] H. P. Moravec, “The stanford cart and the cmu rover,” Proceedings of the IEEE, vol. 71, no. 7, pp. 872-884, 1983.  \n[9] B. Dai and H. Chen, \"A multi-agent and auction-based framework and approach for carrier collaboration,\" Logistics Research, vol. 3, pp. 101-120, 2011.  \n[10] J. Grosset, A.-J. Fougères, M. Djoko-Kouam, and J.-M. Bonnin, \"Multi-agent simulation of autonomous industrial vehicle fleets: Towards dynamic task allocation in v2x cooperation mode,\" *Integrated Computer-Aided Engineering*, vol. 31, no. 3, pp. 249-266, 2024.  \n[11] R. A. Agis, S. Gottifredi, and A. J. Garcia, \"An event-driven behavior trees extension to facilitate non-player multi-agent coordination in video games,\" Expert Systems with Applications, vol. 155, p. 113457, 2020.  \n[12] A. Guerra-Hernández, A. El Fallah-Seghrouchni, and H. Soldano, \"Learning in bdi multi-agent systems,\" in International Workshop on Computational Logic in Multi-Agent Systems, pp. 218-233, Springer, 2004.  \n[13] A. Saadi, R. Maamri, and Z. Sahnoun, \"Behavioral flexibility in belief-desire-intention (bdi) architectures,\" Multiagent and grid systems, vol. 16, no. 4, pp. 343-377, 2020.  \n[14] D. B. Acharya, K. Kuppan, and B. Divya, \"Agentic ai: Autonomous intelligence for complex goals-a comprehensive survey,\" IEEE Access, 2025.  \n[15] M. Z. Pan, M. Cemri, L. A. Agrawal, S. Yang, B. Chopra, R. Tiwari, K. Keutzer, A. Parameswaran, K. Ramchandran, D. Klein, et al., \"Why do multiagent systems fail?\", in ICLR 2025 Workshop on Building Trust in Language Models and Applications, 2025.  \n[16] L. Hughes, Y. K. Dwivedi, T. Malik, M. Shawosh, M. A. Albashrawi, I. Jeon, V. Dutot, M. Appanderanda, T. Crick, R. De', et al., \"Ai agents and agentic systems: A multi-expert analysis,\" Journal of Computer Information Systems, pp. 1-29, 2025.  \n[17] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, and Y. Xiang, \"Ai agents under threat: A survey of key security challenges and future pathways,\" ACM Computing Surveys, vol. 57, no. 7, pp. 1-36, 2025.  \n[18] M. Gridach, J. Nanavati, K. Z. E. Abidine, L. Mendes, and C. Mack, \"Agentic ai for scientific discovery: A survey of progress, challenges, and future directions,\" arXiv preprint arXiv:2503.08979, 2025.  \n[19] T. Song, M. Luo, X. Zhang, L. Chen, Y. Huang, J. Cao, Q. Zhu, D. Liu, B. Zhang, G. Zou, et al., \"A multiagent-driven robotic ai chemist enabling autonomous chemical research on demand,\" Journal of the American Chemical Society, vol. 147, no. 15, pp. 12534-12545, 2025.  \n[20] M. M. Karim, D. H. Van, S. Khan, Q. Qu, and Y. Kholodov, \"Ai agents meet blockchain: A survey on secure and scalable collaboration for multi-agents,\" Future Internet, vol. 17, no. 2, p. 57, 2025.\n\n[21] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al., \"Improving language understanding by generative pre-training,\" arxiv, 2018.  \n[22] J. Sánchez Cuadrado, S. Pérez-Soler, E. Guerra, and J. De Lara, \"Automating the development of task-oriented llm-based chatbots,\" in Proceedings of the 6th ACM Conference on Conversational User Interfaces, pp. 1-10, 2024.  \n[23] Y. Lu, A. Aleta, C. Du, L. Shi, and Y. Moreno, \"Llms and generative agent-based models for complex systems research,\" Physics of Life Reviews, 2024.  \n[24] A. Zhang, Y. Chen, L. Sheng, X. Wang, and T.-S. Chua, \"On generative agents in recommendation,\" in Proceedings of the 47th international ACM SIGIR conference on research and development in Information Retrieval, pp. 1807-1817, 2024.  \n[25] S. Peng, E. Kalliamvakou, P. Cihon, and M. Demirer, “The impact of ai on developer productivity: Evidence from github copilot,” arXiv preprint arXiv:2302.06590, 2023.  \n[26] J. Li, V. Lavrukhin, B. Ginsburg, R. Leary, O. Kuchaiev, J. M. Cohen, H. Nguyen, and R. T. Gadde, \"Jasper: An end-to-end convolutional neural acoustic model,\" arXiv preprint arXiv:1904.03288, 2019.  \n[27] A. Jaruga-Rozdolska, \"Artificial intelligence as part of future practices in the architect's work: Midjourney generative tool as part of a process of creating an architectural form,\" Architectus, no. 3 (71, pp. 95-104, 2022.  \n[28] K. Basu, “Bridging knowledge gaps in llms via function calls,” in Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, pp. 5556–5557, 2024.  \n[29] Z. Liu, T. Hoang, J. Zhang, M. Zhu, T. Lan, J. Tan, W. Yao, Z. Liu, Y. Feng, R. RN, et al., \"Apigen: Automated pipeline for generating verifiable and diverse function-calling datasets,\" Advances in Neural Information Processing Systems, vol. 37, pp. 54463-54482, 2024.  \n[30] H. Yang, S. Yue, and Y. He, \"Auto-gpt for online decision making: Benchmarks and additional opinions,\" arXiv preprint arXiv:2306.02224, 2023.  \n[31] I. Hettiarachchi, “Exploring generative ai agents: Architecture, applications, and challenges,” Journal of Artificial Intelligence General science (JAIGS) ISSN: 3006-4023, vol. 8, no. 1, pp. 105–127, 2025.  \n[32] A. Das, S.-C. Chen, M.-L. Shyu, and S. Sadiq, \"Enabling synergistic knowledge sharing and reasoning in large language models with collaborative multi-agents,\" in 2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC), pp. 92-98, IEEE, 2023.  \n[33] Z. Duan and J. Wang, \"Exploration of lmm multi-agent application implementation based on langgraph+ crewai,\" arXiv preprint arXiv:2411.18241, 2024.  \n[34] R. Sapkota, Y. Cao, K. I. Roumeliotis, and M. Karkee, “Vision-language-action models: Concepts, progress, applications and challenges,” arXiv preprint arXiv:2505.04769, 2025.  \n[35] R. Sapkota, K. I. Roumeliotis, R. H. Cheppally, M. F. Calero, and M. Karkee, “A review of 3d object detection with vision-language models,” arXiv preprint arXiv:2504.18738, 2025.  \n[36] R. Sapkota and M. Karkee, \"Object detection with multimodal large vision-language models: An in-depth review,\" Available at SSRN 5233953, 2025.  \n[37] B. Memarian and T. Doleck, “Human-in-the-loop in artificial intelligence in education: A review and entity-relationship (er) analysis,” Computers in Human Behavior: Artificial Humans, vol. 2, no. 1, p. 100053, 2024.  \n[38] P. Bornet, J. Wirtz, T. H. Davenport, D. De Cremer, B. Evergreen, P. Fersht, R. Gohel, S. Khiyara, P. Sund, and N. Mullakara, Agentic Artificial Intelligence: Harnessing AI Agents to Reinvent Business, Work and Life. Irreplaceable Publishing, 2025.  \n[39] F. Sado, C. K. Loo, W. S. Liew, M. Kerzel, and S. Wermter, \"Explainable goal-driven agents and robots-a comprehensive review,\" ACM Computing Surveys, vol. 55, no. 10, pp. 1-41, 2023.  \n[40] J. Heer, \"Agency plus automation: Designing artificial intelligence into interactive systems,\" Proceedings of the National Academy of Sciences, vol. 116, no. 6, pp. 1844-1850, 2019.  \n[41] G. Papagni, J. de Pagter, S. Zafari, M. Filzmoser, and S. T. Koeszegi, \"Artificial agents' explainability to support trust: considerations on timing and context,\" Ai & Society, vol. 38, no. 2, pp. 947-960, 2023.  \n[42] P. Wang and H. Ding, “The rationality of explanation or human capacity? understanding the impact of explainable artificial intelligence on human-ai trust and decision performance,” Information Processing & Management, vol. 61, no. 4, p. 103732, 2024.\n\n[43] E. Popa, “Human goals are constitutive of agency in artificial intelligence (ai),” Philosophy & Technology, vol. 34, no. 4, pp. 1731–1750, 2021.  \n[44] M. Chacon-Chamorro, L. F. Giraldo, N. Quijano, V. Vargas-Panesso, C. González, J. S. Pinzón, R. Manrique, M. Ríos, Y. Fonseca, D. Gómez-Barrera, et al., \"Cooperative resilience in artificial intelligence multiagent systems,\" IEEE Transactions on Artificial Intelligence, 2025.  \n[45] M. Adam, M. Wessel, and A. Benlian, “Ai-based chatbots in customer service and their effects on user compliance,” *Electronic Markets*, vol. 31, no. 2, pp. 427–445, 2021.  \n[46] D. Leocádio, L. Guedes, J. Oliveira, J. Reis, and N. Melão, \"Customer service with ai-powered human-robot collaboration (hrc): A literature review,\" Procedia Computer Science, vol. 232, pp. 1222–1232, 2024.  \n[47] T. Cao, Y. Q. Khoo, S. Birajdar, Z. Gong, C.-F. Chung, Y. Moghaddam, A. Xu, H. Mehta, A. Shukla, Z. Wang, et al., “Designing towards productivity: A centralized ai assistant concept for work,” The Human Side of Service Engineering, p. 118, 2024.  \n[48] Y. Huang and J. X. Huang, “Exploring chatgpt for next-generation information retrieval: Opportunities and challenges,” in Web Intelligence, vol. 22, pp. 31–44, SAGE Publications Sage UK: London, England, 2024.  \n[49] N. Holtz, S. Wittfoth, and J. M. Gómez, \"The new era of knowledge retrieval: Multi-agent systems meet generative ai,\" in 2024 Portland International Conference on Management of Engineering and Technology (PICMET), pp. 1-10, IEEE, 2024.  \n[50] F. Poszler and B. Lange, “The impact of intelligent decision-support systems on humans’ ethical decision-making: A systematic literature review and an integrated framework,” Technological Forecasting and Social Change, vol. 204, p. 123403, 2024.  \n[51] F. Khemakhem, H. Ellouzi, H. LtiFi, and M. B. Ayed, \"Agent-based intelligent decision support systems: a systematic review,\" IEEE Transactions on Cognitive and Developmental Systems, vol. 14, no. 1, pp. 20-34, 2020.  \n[52] R. V. Florian, \"Autonomous artificial intelligent agents,\" Center for Cognitive and Neural Studies (Coneural), Cluj-Napoca, Romania, 2003.  \n[53] T. Hellström, N. Kaiser, and S. Bensch, “A taxonomy of embodiment in the ai era,” *Electronics*, vol. 13, no. 22, p. 4441, 2024.  \n[54] M. Wischnewski, “Attributing mental states to non-embodied autonomous systems: A systematic review,” in Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 1–8, 2025.  \n[55] K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, and M. Fritz, \"Not what you've signed up for: Compromising real-world IIm-integrated applications with indirect prompt injection,\" in Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security, pp. 79-90, 2023.  \n[56] Y. Talebirad and A. Nadiri, \"Multi-agent collaboration: Harnessing the power of intelligent llm agents,\" arXiv preprint arXiv:2306.03314, 2023.  \n[57] A. I. Hauptman, B. G. Schelble, N. J. McNeese, and K. C. Madathil, \"Adapt and overcome: Perceptions of adaptive autonomous agents for human-ai teaming,\" Computers in Human Behavior, vol. 138, p. 107451, 2023.  \n[58] N. Krishnan, “Advancing multi-agent systems through model context protocol: Architecture, implementation, and applications,” arXiv preprint arXiv:2504.21030, 2025.  \n[59] H. Padigela, C. Shah, and D. Juyal, \"Ml-dev-bench: Comparative analysis of ai agents on ml development workflows,\" arXiv preprint arXiv:2502.00964, 2025.  \n[60] M. Raees, I. Meijerink, I. Lykourentzou, V.-J. Khan, and K. Papangelis, \"From explainable to interactive ai: A literature review on current trends in human-ai interaction,\" International Journal of Human-Computer Studies, p. 103301, 2024.  \n[61] P. Formosa, “Robot autonomy vs. human autonomy: social robots, artificial intelligence (ai), and the nature of autonomy,” *Minds and Machines*, vol. 31, no. 4, pp. 595–616, 2021.  \n[62] C. S. Eze and L. Shamir, “Analysis and prevention of ai-based phishing email attacks,” *Electronics*, vol. 13, no. 10, p. 1839, 2024.  \n[63] D. Singh, V. Patel, D. Bose, and A. Sharma, “Enhancing email marketing efficacy through ai-driven personalization: Leveraging natural language processing and collaborative filtering algorithms,” International Journal of AI Advancements, vol. 9, no. 4, 2020.\n\n[64] R. Khan, S. Sarkar, S. K. Mahata, and E. Jose, \"Security threats in agentic ai system,\" arXiv preprint arXiv:2410.14728, 2024.  \n[65] C. G. Endacott, “Enacting machine agency when ai makes one’s day: understanding how users relate to ai communication technologies for scheduling,” Journal of Computer-Mediated Communication, vol. 29, no. 4, p. zmae011, 2024.  \n[66] Z. Pawlak and A. Skowron, “Rudiments of rough sets,” Information sciences, vol. 177, no. 1, pp. 3-27, 2007.  \n[67] P. Ponnusamy, A. Ghias, Y. Yi, B. Yao, C. Guo, and R. Sarikaya, \"Feedback-based self-learning in large-scale conversational ai agents,\" AI magazine, vol. 42, no. 4, pp. 43-56, 2022.  \n[68] A. Zagalsky, D. Te'eni, I. Yahav, D. G. Schwartz, G. Silverman, D. Cohen, Y. Mann, and D. Lewinsky, \"The design of reciprocal learning between human and artificial intelligence,\" Proceedings of the ACM on Human-Computer Interaction, vol. 5, no. CSCW2, pp. 1-36, 2021.  \n[69] W. J. Clancey, “Heuristic classification,” Artificial intelligence, vol. 27, no. 3, pp. 289–350, 1985.  \n[70] S. Kapoor, B. Stroebl, Z. S. Siegel, N. Nadgir, and A. Narayanan, “Ai agents that matter,” arXiv preprint arXiv:2407.01502, 2024.  \n[71] X. Huang, J. Lian, Y. Lei, J. Yao, D. Lian, and X. Xie, \"Recommender ai agent: Integrating large language models for interactive recommendations,\" arXiv preprint arXiv:2308.16505, 2023.  \n[72] A. M. Baabdullah, A. A. Alalwan, R. S. Algharabat, B. Metri, and N. P. Rana, “Virtual agents and flow experience: An empirical examination of ai-powered chatbots,” Technological Forecasting and Social Change, vol. 181, p. 121772, 2022.  \n[73] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al., “Gpt-4 technical report,” arXiv preprint arXiv:2303.08774, 2023.  \n[74] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al., “Palm: Scaling language modeling with pathways,” Journal of Machine Learning Research, vol. 24, no. 240, pp. 1–113, 2023.  \n[75] H. Honda and M. Hagiwara, “Question answering systems with deep learning-based symbolic processing,” IEEE Access, vol. 7, pp. 152368–152378, 2019.  \n[76] N. Karanikolas, E. Manga, N. Samaridi, E. Tousidou, and M. Vassilikopoulos, \"Large language models versus natural language understanding and generation,\" in Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics, pp. 278-290, 2023.  \n[77] A. S. George, A. H. George, T. Baskar, and A. G. Martin, \"Revolutionizing business communication: Exploring the potential of gpt-4 in corporate settings,\" *Partners Universal International Research Journal*, vol. 2, no. 1, pp. 149–157, 2023.  \n[78] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al., \"Learning transferable visual models from natural language supervision,\" in International conference on machine learning, pp. 8748-8763, PmLR, 2021.  \n[79] J. Li, D. Li, S. Savarese, and S. Hoi, \"Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models,\" in International conference on machine learning, pp. 19730-19742, PMLR, 2023.  \n[80] S. Sontakke, J. Zhang, S. Arnold, K. Pertsch, E. Bityik, D. Sadigh, C. Finn, and L. Itti, \"Roboclip: One demonstration is enough to learn robot policies,\" Advances in Neural Information Processing Systems, vol. 36, pp. 55681-55693, 2023.  \n[81] M. Elhenawy, H. I. Ashqar, A. Rakotonirainy, T. I. Alhadidi, A. Jaber, and M. A. Tami, \"Vision-language models for autonomous driving: Clip-based dynamic scene understanding,\" *Electronics*, vol. 14, no. 7, p. 1282, 2025.  \n[82] S. Park, M. Lee, J. Kang, H. Choi, Y. Park, J. Cho, A. Lee, and D. Kim, \"Vlaad: Vision and language assistant for autonomous driving,\" in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 980-987, 2024.  \n[83] S. H. Ahmed, S. Hu, and G. Sukthankar, “The potential of vision-language models for content moderation of children’s videos,” in 2023 International Conference on Machine Learning and Applications (ICMLA), pp. 1237–1241, IEEE, 2023.  \n[84] S. H. Ahmed, M. J. Khan, and G. Sukthankar, \"Enhanced multimodal content moderation of children's videos using audiovisual fusion,\" arXiv preprint arXiv:2405.06128, 2024.\n\n[85] P. Chitra and A. Saleem Raja, \"Artificial intelligence (ai) algorithm and models for embodied agents (robots and drones),\" in Building Embodied AI Systems: The Agents, the Architecture Principles, Challenges, and Application Domains, pp. 417-441, Springer, 2025.  \n[86] S. Kourav, K. Verma, and M. Sundararajan, \"Artificial intelligence algorithm models for agents of embodiment for drone applications,\" in Building Embodied AI Systems: The Agents, the Architecture Principles, Challenges, and Application Domains, pp. 79-101, Springer, 2025.  \n[87] G. Natarajan, E. Elango, B. Sundaravadivazhagan, and S. Rethinam, \"Artificial intelligence algorithms and models for embodied agents: Enhancing autonomy in drones and robots,\" in Building Embodied AI Systems: The Agents, the Architecture Principles, Challenges, and Application Domains, pp. 103-132, Springer, 2025.  \n[88] K. Pandya and M. Holia, \"Automating customer service using langchain: Building custom open-source gpt chatbot for organizations,\" arXiv preprint arXiv:2310.05421, 2023.  \n[89] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang, S. Zhang, J. Liu, et al., \"Autogen: Enabling next-gen llm applications via multi-agent conversation,\" arXiv preprint arXiv:2308.08155, 2023.  \n[90] L. Gabora and J. Bach, “A path to generative artificial selves,” in EPIA Conference on Artificial Intelligence, pp. 15–29, Springer, 2023.  \n[91] G. Pezzulo, T. Parr, P. Cisek, A. Clark, and K. Friston, \"Generating meaning: active inference and the scope and limits of passive ai,\" Trends in Cognitive Sciences, vol. 28, no. 2, pp. 97-112, 2024.  \n[92] J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, and K. Tei, \"Generative ai for self-adaptive systems: State of the art and research roadmap,\" ACM Transactions on Autonomous and Adaptive Systems, vol. 19, no. 3, pp. 1-60, 2024.  \n[93] W. O'Grady and M. Lee, \"Natural syntax, artificial intelligence and language acquisition,\" Information, vol. 14, no. 7, p. 418, 2023.  \n[94] X. Liu, J. Wang, J. Sun, X. Yuan, G. Dong, P. Di, W. Wang, and D. Wang, “Prompting frameworks for large language models: A survey,” arXiv preprint arXiv:2311.12785, 2023.  \n[95] E. T. Rolls, “The memory systems of the human brain and generative artificial intelligence,” Heliyon, vol. 10, no. 11, 2024.  \n[96] K. Alizadeh, S. I. Mirzadeh, D. Belenko, S. Khatamifard, M. Cho, C. C. Del Mundo, M. Rastegari, and M. Farajtabar, \"Llm in a flash: Efficient large language model inference with limited memory,\" in Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 12562-12584, 2024.  \n[97] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, A. Wahid, J. Tompson, Q. Vuong, T. Yu, W. Huang, et al., “Palm-e: An embodied multimodal language model,” 2023.  \n[98] P. Denny, J. Leinonen, J. Prather, A. Luxton-Reilly, T. Amarouche, B. A. Becker, and B. N. Reeves, \"Prompt problems: A new programming exercise for the generative ai era,\" in Proceedings of the 55th ACM Technical Symposium on Computer Science Education V.1, pp.296-302, 2024.  \n[99] C. Chen, S. Lee, E. Jang, and S. S. Sundar, \"Is your prompt detailed enough? exploring the effects of prompt coaching on users' perceptions, engagement, and trust in text-to-image generative ai tools,\" in Proceedings of the Second International Symposium on Trustworthy Autonomous Systems, pp. 1-12, 2024.  \n[100] A. Pan, E. Jones, M. Jagadeesan, and J. Steinhardt, \"Feedback loops with language models drive in-context reward hacking,\" arXiv preprint arXiv:2402.06627, 2024.  \n[101] K. Nabben, “Ai as a constituted system: accountability lessons from an llm experiment,” Data & policy, vol. 6, p. e57, 2024.  \n[102] P. J. Pesch, “Potentials and challenges of large language models (llms) in the context of administrative decision-making,” European Journal of Risk Regulation, pp. 1–20, 2025.  \n[103] C. Wang, Y. Deng, Z. Lyu, L. Zeng, J. He, S. Yan, and B. An, “Q*: Improving multi-step reasoning for llms with deliberative planning,” arXiv preprint arXiv:2406.14283, 2024.  \n[104] H. Wei, Z. Zhang, S. He, T. Xia, S. Pan, and F. Liu, “Plangen-llms: A modern survey of llm planning capabilities,” arXiv preprint arXiv:2502.11221, 2025.  \n[105] A. Bandi, P. V. S. R. Adapa, and Y. E. V. P. K. Kuchi, “The power of generative ai: A review of requirements, models, input-output formats, evaluation metrics, and challenges,” Future Internet, vol. 15, no. 8, p. 260, 2023.\n\n[106] Y. Liu, H. Du, D. Niyato, J. Kang, Z. Xiong, Y. Wen, and D. I. Kim, \"Generative ai in data center networking: Fundamentals, perspectives, and case study,\" IEEE Network, 2025.  \n[107] C. Guo, F. Cheng, Z. Du, J. Kiessling, J. Ku, S. Li, Z. Li, M. Ma, T. Molom-Ochir, B. Morris, et al., \"A survey: Collaborative hardware and software design in the era of large language models,\" IEEE Circuits and Systems Magazine, vol. 25, no. 1, pp. 35-57, 2025.  \n[108] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., \"Language models are few-shot learners,\" Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.  \n[109] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, et al., \"Llama: Open and efficient foundation language models,\" arXiv preprint arXiv:2302.13971, 2023.  \n[110] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, \"Exploring the limits of transfer learning with a unified text-to-text transformer,\" Journal of machine learning research, vol. 21, no. 140, pp. 1-67, 2020.  \n[111] A. Yang, B. Xiao, B. Wang, B. Zhang, C. Bian, C. Yin, C. Lv, D. Pan, D. Wang, D. Yan, et al., \"Baichuan 2: Open large-scale language models,\" arXiv preprint arXiv:2309.10305, 2023.  \n[112] K. M. Yoo, D. Park, J. Kang, S.-W. Lee, and W. Park, “Gpt3mix: Leveraging large-scale language models for text augmentation,” arXiv preprint arXiv:2104.08826, 2021.  \n[113] D. Zhou, X. Xue, X. Lu, Y. Guo, P. Ji, H. Lv, W. He, Y. Xu, Q. Li, and L. Cui, \"A hierarchical model for complex adaptive system: From adaptive agent to ai society,\" ACM Transactions on Autonomous and Adaptive Systems, 2024.  \n[114] H. Hao, Y. Wang, and J. Chen, \"Empowering scenario planning with artificial intelligence: A perspective on building smart and resilient cities,\" Engineering, 2024.  \n[115] Y. Wang, J. Zhu, Z. Cheng, L. Qiu, Z. Tong, and J. Huang, \"Intelligent optimization method for real-time decision-making in laminated cooling configurations through reinforcement learning,\" Energy, vol. 291, p. 130434, 2024.  \n[116] X. Xiang, J. Xue, L. Zhao, Y. Lei, C. Yue, and K. Lu, “Real-time integration of fine-tuned large language model for improved decision-making in reinforcement learning,” in 2024 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, IEEE, 2024.  \n[117] Z. Li, H. Zhang, C. Peng, and R. Peiris, “Exploring large language model-driven agents for environment-aware spatial interactions and conversations in virtual reality role-play scenarios,” in 2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR), pp. 1-11, IEEE, 2025.  \n[118] T. R. McIntosh, T. Susnjak, T. Liu, P. Watters, and M. N. Halgamuge, \"The inadequacy of reinforcement learning from human feedback-radicalizing large language models via semantic vulnerabilities,\" IEEE Transactions on Cognitive and Developmental Systems, 2024.  \n[119] S. Lee, G. Lee, W. Kim, J. Kim, J. Park, and K. Cho, \"Human strategy learning-based multi-agent deep reinforcement learning for online team sports game,\" IEEE Access, 2025.  \n[120] Z. Shi, S. Gao, L. Yan, Y. Feng, X. Chen, Z. Chen, D. Yin, S. Verberne, and Z. Ren, \"Tool learning in the wild: Empowering language models as automatic tool agents,\" in Proceedings of the ACM on Web Conference 2025, pp. 2222-2237, 2025.  \n[121] S. Yuan, K. Song, J. Chen, X. Tan, Y. Shen, R. Kan, D. Li, and D. Yang, \"Easytool: Enhancing llm-based agents with concise tool instruction,\" arXiv preprint arXiv:2401.06201, 2024.  \n[122] B. Xu, X. Liu, H. Shen, Z. Han, Y. Li, M. Yue, Z. Peng, Y. Liu, Z. Yao, and D. Xu, \"Gentopia: A collaborative platform for tool-augmented llms,\" arXiv preprint arXiv:2308.04030, 2023.  \n[123] H. Lu, X. Li, X. Ji, Z. Kan, and Q. Hu, “Toolfive: Enhancing tool-augmented llms via tool filtering and verification,” in ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1-5, IEEE, 2025.  \n[124] Y. Song, F. Xu, S. Zhou, and G. Neubig, “Beyond browsing: Api-based web agents,” arXiv preprint arXiv:2410.16464, 2024.  \n[125] V. Tupe and S. Thube, \"Ai agentic workflows and enterprise apis: Adapting api architectures for the age of ai agents,\" arXiv preprint arXiv:2502.17443, 2025.  \n[126] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao, \"React: Synergizing reasoning and acting in language models,\" in International Conference on Learning Representations (ICLR), 2023.\n\n[127] L. Ning, Z. Liang, Z. Jiang, H. Qu, Y. Ding, W. Fan, X.-y. Wei, S. Lin, H. Liu, P. S. Yu, et al., \"A survey of webagents: Towards next-generation ai agents for web automation with large foundation models,\" arXiv preprint arXiv:2503.23350, 2025.  \n[128] M. W. U. Rahman, R. Nevarez, L. T. Mim, and S. Hariri, “Multiagent actor-critic generative ai for query resolution and analysis,” IEEE Transactions on Artificial Intelligence, 2025.  \n[129] J. Lála, O. O'Donoghue, A. Shtedritski, S. Cox, S. G. Rodriques, and A. D. White, \"Paperqa: Retrieval-augmented generative agent for scientific research,\" arXiv preprint arXiv:2312.07559, 2023.  \n[130] Z. Wu, C. Yu, C. Chen, J. Hao, and H. H. Zhuo, \"Models as agents: Optimizing multi-step predictions of interactive local models in model-based multi-agent reinforcement learning,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, pp. 10435-10443, 2023.  \n[131] Z. Feng, R. Xue, L. Yuan, Y. Yu, N. Ding, M. Liu, B. Gao, J. Sun, and G. Wang, \"Multi-agent embodied ai: Advances and future directions,\" arXiv preprint arXiv:2505.05108, 2025.  \n[132] A. Feriani and E. Hossain, \"Single and multi-agent deep reinforcement learning for ai-enabled wireless networks: A tutorial,\" IEEE Communications Surveys & Tutorials, vol. 23, no. 2, pp. 1226-1252, 2021.  \n[133] R. Zhang, S. Tang, Y. Liu, D. Niyato, Z. Xiong, S. Sun, S. Mao, and Z. Han, \"Toward agentic ai: generative information retrieval inspired intelligent communications and networking,\" arXiv preprint arXiv:2502.16866, 2025.  \n[134] U. M. Borghoff, P. Bottoni, and R. Pareschi, “Human-artificial interaction in the age of agentic ai: a system-theoretical approach,” Frontiers in Human Dynamics, vol. 7, p. 1579166, 2025.  \n[135] E. Miehling, K. N. Ramamurthy, K. R. Varshney, M. Riemer, D. Boun-effouf, J. T. Richards, A. Dhurandhar, E. M. Daly, M. Hind, P. Sattigeri, et al., \"Agentic ai needs a systems theory,\" arXiv preprint arXiv:2503.00237, 2025.  \n[136] W. Xu, Z. Liang, K. Mei, H. Gao, J. Tan, and Y. Zhang, “A-mem: Agentic memory for llm agents,” arXiv preprint arXiv:2502.12110, 2025.  \n[137] C. Riedl and D. De Cremer, “Ai for collective intelligence,” Collective Intelligence, vol. 4, no. 2, p. 26339137251328909, 2025.  \n[138] L. Peng, D. Li, Z. Zhang, T. Zhang, A. Huang, S. Yang, and Y. Hu, \"Human-ai collaboration: Unraveling the effects of user proficiency and ai agent capability in intelligent decision support systems,\" International Journal of Industrial Ergonomics, vol. 103, p. 103629, 2024.  \n[139] H. Shirado, K. Shimizu, N. A. Christakis, and S. Kasahara, “Realism drives interpersonal reciprocity but yields to ai-assisted egocentrism in a coordination experiment,” in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 1–21, 2025.  \n[140] Y. Xiao, G. Shi, and P. Zhang, \"Towards agentic ai networking in 6g: A generative foundation model-as-agent approach,\" arXiv preprint arXiv:2503.15764, 2025.  \n[141] P. R. Lewis and S. Sarkadi, “Reflective artificial intelligence,” *Minds and Machines*, vol. 34, no. 2, p. 14, 2024.  \n[142] C. Qian, W. Liu, H. Liu, N. Chen, Y. Dang, J. Li, C. Yang, W. Chen, Y. Su, X. Cong, et al., \"Chatdev: Communicative agents for software development,\" arXiv preprint arXiv:2307.07924, 2023.  \n[143] S. Hong, X. Zheng, J. Chen, Y. Cheng, J. Wang, C. Zhang, Z. Wang, S. K. S. Yau, Z. Lin, L. Zhou, et al., “Metagpt: Meta programming for multi-agent collaborative framework,” arXiv preprint arXiv:2308.00352, vol. 3, no. 4, p. 6, 2023.  \n[144] Y. Liang, C. Wu, T. Song, W. Wu, Y. Xia, Y. Liu, Y. Ou, S. Lu, L. Ji, S. Mao, et al., \"Taskmatrix: ai: Completing tasks by connecting foundation models with millions of apis,\" Intelligent Computing, vol. 3, p. 0063, 2024.  \n[145] H. Hexmoor, J. Lammens, G. Caicedo, and S. C. Shapiro, Behaviour based AI, cognitive processes, and emergent behaviors in autonomous agents, vol. 1. WIT Press, 2025.  \n[146] H. Zhang, Z. Li, F. Liu, Y. He, Z. Cao, and Y. Zheng, \"Design and implementation of langchain-based chatbot,\" in 2024 International Seminar on Artificial Intelligence, Computer Technology and Control Engineering (ACTCE), pp. 226-229, IEEE, 2024.  \n[147] E. Ephrati and J. S. Rosenschein, “A heuristic technique for multi-agent planning,” Annals of Mathematics and Artificial Intelligence, vol. 20, pp. 13–67, 1997.  \n[148] S. Kupferschmid, J. Hoffmann, H. Dierks, and G. Behrmann, \"Adapting an ai planning heuristic for directed model checking,\" in International SPIN Workshop on Model Checking of Software, pp. 35-52, Springer, 2006.\n\n[149] W. Chen, Y. Su, J. Zuo, C. Yang, C. Yuan, C. Qian, C.-M. Chan, Y. Qin, Y. Lu, R. Xie, et al., \"Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents,\" arXiv preprint arXiv:2308.10848, vol. 2, no. 4, p. 6, 2023.  \n[150] T. Schick, J. Dwivedi-Yu, R. Dessi, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer, N. Cancedda, and T. Scialom, “Toolformer: Language models can teach themselves to use tools,” Advances in Neural Information Processing Systems, vol. 36, pp. 68539–68551, 2023.  \n[151] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al., \"Chain-of-thought prompting elicits reasoning in large language models,\" Advances in neural information processing systems, vol. 35, pp. 24824-24837, 2022.  \n[152] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y. Cao, and K. Narasimhan, “Tree of thoughts: Deliberate problem solving with large language models,” Advances in neural information processing systems, vol. 36, pp. 11809–11822, 2023.  \n[153] J. Guo, N. Li, J. Qi, H. Yang, R. Li, Y. Feng, S. Zhang, and M. Xu, \"Empowering working memory for large language model agents,\" arXiv preprint arXiv:2312.17259, 2023.  \n[154] S. Agashe, J. Han, S. Gan, J. Yang, A. Li, and X. E. Wang, \"Agent s: An open agentic framework that uses computers like a human,\" arXiv preprint arXiv:2410.08164, 2024.  \n[155] C. DeChant, \"Episodic memory in ai agents poses risks that should be studied and mitigated,\" arXiv preprint arXiv:2501.11739, 2025.  \n[156] A. M. Nuxoll and J. E. Laird, “Enhancing intelligent agents with episodic memory,” Cognitive Systems Research, vol. 17, pp. 34–48, 2012.  \n[157] G. Sarthou, A. Clodic, and R. Alami, “Ontologenius: A long-term semantic memory for robotic agents,” in 2019 28th IEEE International Conference on Robot and Human Interactive Communication (ROMAN), pp. 1–8, IEEE, 2019.  \n[158] A.-e.-h. Munir and W. M. Qazi, “Artificial subjectivity: Personal semantic memory model for cognitive agents,” Applied Sciences, vol. 12, no. 4, p. 1903, 2022.  \n[159] A. Singh, A. Ehtesham, S. Kumar, and T. T. Khoei, \"Agentic retrieval-augmented generation: A survey on agentic rag,\" arXiv preprint arXiv:2501.09136, 2025.  \n[160] R. Akkiraju, A. Xu, D. Bora, T. Yu, L. An, V. Seth, A. Shukla, P. Gundecha, H. Mehta, A. Jha, et al., \"Facts about building retrieval augmented generation-based chatbots,\" arXiv preprint arXiv:2407.07858, 2024.  \n[161] G. Wang, Y. Xie, Y. Jiang, A. Mandlekar, C. Xiao, Y. Zhu, L. Fan, and A. Anandkumar, \"Voyager: An open-ended embodied agent with large language models,\" arXiv preprint arXiv:2305.16291, 2023.  \n[162] G. Li, H. Hammoud, H. Itani, D. Khizbullin, and B. Ghanem, \"Camel: Communicative agents for\" mind\" exploration of large language model society,\" Advances in Neural Information Processing Systems, vol. 36, pp. 51991-52008, 2023.  \n[163] S. Reed, K. Zolna, E. Parisotto, S. G. Colmenarejo, A. Novikov, G. Barth-Maron, M. Gimenez, Y. Sulsky, J. Kay, J. T. Springenberg, et al., \"A generalist agent,\" arXiv preprint arXiv:2205.06175, 2022.  \n[164] C. K. Thomas, C. Chaccour, W. Saad, M. Debbah, and C. S. Hong, \"Causal reasoning: Charting a revolutionary course for next-generation ai-native wireless networks,\" IEEE Vehicular Technology Magazine, 2024.  \n[165] Z. Tang, R. Wang, W. Chen, K. Wang, Y. Liu, T. Chen, and L. Lin, \"Towards causalgpt: A multi-agent approach for faithful knowledge reasoning via promoting causal consistency in llms,\" arXiv preprint arXiv:2308.11914, 2023.  \n[166] Z. Gekhman, J. Herzig, R. Aharoni, C. Elkind, and I. Szpektor, \"Trueteacher: Learning factual consistency evaluation with large language models,\" arXiv preprint arXiv:2305.11171, 2023.  \n[167] A. Wu, K. Kuang, M. Zhu, Y. Wang, Y. Zheng, K. Han, B. Li, G. Chen, F. Wu, and K. Zhang, \"Causality for large language models,\" arXiv preprint arXiv:2410.15319, 2024.  \n[168] S. Ashwani, K. Hegde, N. R. Mannuru, D. S. Sengar, M. Jindal, K. C. R. Kathala, D. Banga, V. Jain, and A. Chadha, \"Cause and effect: can large language models truly understand causality?\", in Proceedings of the AAAI Symposium Series, vol. 4, pp. 2-9, 2024.  \n[169] J. Richens and T. Everitt, “Robust agents learn causal world models,” in The Twelfth International Conference on Learning Representations, 2024.\n\n[170] A. Chan, R. Salganik, A. Markelius, C. Pang, N. Rajkumar, D. Krasheninnikov, L. Langosco, Z. He, Y. Duan, M. Carroll, et al., \"Harms from increasingly agentic algorithmic systems,\" in Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, pp. 651-666, 2023.  \n[171] A. Plaat, M. van Duijn, N. van Stein, M. Preuss, P. van der Putten, and K. J. Batenburg, \"Agentic large language models, a survey,\" arXiv preprint arXiv:2503.23037, 2025.  \n[172] J. Qiu, K. Lam, G. Li, A. Acharya, T. Y. Wong, A. Darzi, W. Yuan, and E. J. Topol, “Llm-based agentic systems in medicine and healthcare,” Nature Machine Intelligence, vol. 6, no. 12, pp. 1418–1420, 2024.  \n[173] G. A. Gabison and R. P. Xian, “Inherent and emergent liability issues in llm-based agentic systems: a principal-agent perspective,” arXiv preprint arXiv:2504.03255, 2025.  \n[174] M. Dahl, V. Magesh, M. Suzgun, and D. E. Ho, “Large legal fictions: Profiling legal hallucinations in large language models,” *Journal of Legal Analysis*, vol. 16, no. 1, pp. 64–93, 2024.  \n[175] Y. A. Latif, \"Hallucinations in large language models and their influence on legal reasoning: Examining the risks of ai-generated factual inaccuracies in judicial processes,\" Journal of Computational Intelligence, Machine Reasoning, and Decision-Making, vol. 10, no. 2, pp. 10-20, 2025.  \n[176] S. Tonmoy, S. Zaman, V. Jain, A. Rani, V. Rawte, A. Chadha, and A. Das, “A comprehensive survey of hallucination mitigation techniques in large language models,” arXiv preprint arXiv:2401.01313, vol. 6, 2024.  \n[177] Z. Zhang, Y. Yao, A. Zhang, X. Tang, X. Ma, Z. He, Y. Wang, M. Gerstein, R. Wang, G. Liu, et al., \"Igniting language intelligence: The hitchhiker's guide from chain-of-thought reasoning to language agents,\" ACM Computing Surveys, vol. 57, no. 8, pp. 1-39, 2025.  \n[178] Y. Wan and K.-W. Chang, “White men lead, black women help? benchmarking language agency social biases in llms,” arXiv preprint arXiv:2404.10508, 2024.  \n[179] A. Borah and R. Mihalcea, “Towards implicit bias detection and mitigation in multi-agent llm interactions,” arXiv preprint arXiv:2410.02584, 2024.  \n[180] X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding, K. Men, K. Yang, et al., \"Agentbench: Evaluating llms as agents,\" arXiv preprint arXiv:2308.03688, 2023.  \n[181] G. He, G. Demartini, and U. Gadiraju, \"Plan-then-execute: An empirical study of user trust and team performance when using lvm agents as a daily assistant,\" in Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems, pp. 1-22, 2025.  \n[182] Z. Ke, F. Jiao, Y. Ming, X.-P. Nguyen, A. Xu, D. X. Long, M. Li, C. Qin, P. Wang, S. Savarese, et al., \"A survey of frontiers in llm reasoning: Inference scaling, learning to reason, and agentic systems,\" arXiv preprint arXiv:2504.09037, 2025.  \n[183] M. Luo, X. Shi, C. Cai, T. Zhang, J. Wong, Y. Wang, C. Wang, Y. Huang, Z. Chen, J. E. Gonzalez, et al., \"Autellix: An efficient serving engine for llm agents as general programs,\" arXiv preprint arXiv:2502.13965, 2025.  \n[184] K. Hatalis, D. Christou, J. Myers, S. Jones, K. Lambert, A. Amos-Binks, Z. Dannenhauer, and D. Dannenhauer, \"Memory matters: The need to improve long-term memory in lmm-agents,\" in Proceedings of the AAAI Symposium Series, vol. 2, pp. 277-280, 2023.  \n[185] H. Jin, X. Han, J. Yang, Z. Jiang, Z. Liu, C.-Y. Chang, H. Chen, and X. Hu, “Llm maybe longlm: Self-extend llm context window without tuning,” arXiv preprint arXiv:2401.01325, 2024.  \n[186] M. Yu, F. Meng, X. Zhou, S. Wang, J. Mao, L. Pang, T. Chen, K. Wang, X. Li, Y. Zhang, et al., \"A survey on trustworthy llm agents: Threats and countermeasures,\" arXiv preprint arXiv:2503.09648, 2025.  \n[187] H. Chi, H. Li, W. Yang, F. Liu, L. Lan, X. Ren, T. Liu, and B. Han, \"Unveiling causal reasoning in large language models: Reality or mirage?\", Advances in Neural Information Processing Systems, vol. 37, pp. 96640-96670, 2024.  \n[188] H. Wang, A. Zhang, N. Duy Tai, J. Sun, T.-S. Chua, et al., \"Ali-agent: Assessing llms' alignment with human values via agent-based evaluation,\" Advances in Neural Information Processing Systems, vol. 37, pp. 99040-99088, 2024.  \n[189] L. Hammond, A. Chan, J. Clifton, J. Hoelscher-Obermaier, A. Khan, E. McLean, C. Smith, W. Barfuss, J. Foerster, T. Gavenciak, et al., “Multi-agent risks from advanced ai,” arXiv preprint arXiv:2502.14143, 2025.\n\n[190] D. Trusilo, \"Autonomous ai systems in conflict: Emergent behavior and its impact on predictability and reliability,\" Journal of Military Ethics, vol. 22, no. 1, pp. 2-17, 2023.  \n[191] M. Puvvadi, S. K. Arava, A. Santoria, S. S. P. Chennupati, and H. V. Puvvadi, \"Coding agents: A comprehensive survey of automated bug fixing systems and benchmarks,\" in 2025 IEEE 14th International Conference on Communication Systems and Network Technologies (CSNT), pp. 680-686, IEEE, 2025.  \n[192] C. Newton, J. Singleton, C. Copland, S. Kitchen, and J. Hudack, \"Scalability in modeling and simulation systems for multi-agent, ai, and machine learning applications,\" in Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications III, vol. 11746, pp. 534-552, SPIE, 2021.  \n[193] H. D. Le, X. Xia, and Z. Chen, \"Multi-agent causal discovery using large language models,\" arXiv preprint arXiv:2407.15073, 2024.  \n[194] Y. Shavit, S. Agarwal, M. Brundage, S. Adler, C. O'Keefe, R. Campbell, T. Lee, P. Mishkin, T. Eloundou, A. Hickey, et al., \"Practices for governing agentic ai systems,\" Research Paper, OpenAI, 2023.  \n[195] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Kuttler, M. Lewis, W.-t. Yih, T. Rocktäschel, et al., \"Retrievalaugmented generation for knowledge-intensive nlp tasks,\" Advances in neural information processing systems, vol. 33, pp. 9459-9474, 2020.  \n[196] Y. Ma, Z. Gou, J. Hao, R. Xu, S. Wang, L. Pan, Y. Yang, Y. Cao, A. Sun, H. Awadalla, et al., \"Sciagent: Tool-augmented language models for scientific reasoning,\" arXiv preprint arXiv:2402.11451, 2024.  \n[197] K. Dev, S. A. Khowaja, K. Singh, E. Zeydan, and M. Debbah, \"Advanced architectures integrated with agentic ai for next-generation wireless networks,\" arXiv preprint arXiv:2502.01089, 2025.  \n[198] A. Boyle and A. Blomkvist, “Elements of episodic memory: insights from artificial agents,” Philosophical Transactions B, vol. 379, no. 1913, p. 20230416, 2024.  \n[199] Y. Du, W. Huang, D. Zheng, Z. Wang, S. Montella, M. Lapata, K.-F. Wong, and J. Z. Pan, \"Rethinking memory in ai: Taxonomy, operations, topics, and future directions,\" arXiv preprint arXiv:2505.00675, 2025.  \n[200] K.-T. Tran, D. Dao, M.-D. Nguyen, Q.-V. Pham, B. O'Sullivan, and H. D. Nguyen, \"Multi-agent collaboration mechanisms: A survey of llms,\" arXiv preprint arXiv:2501.06322, 2025.  \n[201] K. Tallam, “From autonomous agents to integrated systems, a new paradigm: Orchestrated distributed intelligence,” arXiv preprint arXiv:2503.13754, 2025.  \n[202] Y. Lee, “Critique of artificial reason: Ontology of human and artificial intelligence,” Journal of Ecohumanism, vol. 4, no. 3, pp. 397–415, 2025.  \n[203] L. Ale, S. A. King, N. Zhang, and H. Xing, “Enhancing generative ai reliability via agentic ai in 6g-enabled edge computing,” Nature Reviews Electrical Engineering, pp. 1-3, 2025.  \n[204] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, \"Reflexion: Language agents with verbal reinforcement learning,\" Advances in Neural Information Processing Systems, vol. 36, pp. 8634-8652, 2023.  \n[205] F. Kamalov, D. S. Calonge, L. Smail, D. Azizov, D. R. Thadani, T. Kwong, and A. Atif, \"Evolution of ai in education: Agentic workflows,\" arXiv preprint arXiv:2504.20082, 2025.  \n[206] A. Sulc, T. Hellert, R. Kammering, H. Hoschouer, and J. S. John, \"Towards agentic ai on particle accelerators,\" arXiv preprint arXiv:2409.06336, 2024.  \n[207] J. Yang, C. Jimenez, A. Wettig, K. Lieret, S. Yao, K. Narasimhan, and O. Press, \"Swe-agent: Agent-computer interfaces enable automated software engineering,\" Advances in Neural Information Processing Systems, vol. 37, pp. 50528-50652, 2024.  \n[208] S. Barua, “Exploring autonomous agents through the lens of large language models: A review,” arXiv preprint arXiv:2404.04442, 2024.",
    "translated_content": null,
    "created_at": "2025-12-15 11:44:10.895310",
    "updated_at": "2025-12-15 11:44:17.838779"
  },
  "9d7befb9-e05e-4cb6-89d3-41a9b5d3a916": {
    "id": "9d7befb9-e05e-4cb6-89d3-41a9b5d3a916",
    "filename": "from words 2 winsdom 2511.20547v1.pdf",
    "file_path": "./uploads/papers/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916.pdf",
    "status": "completed",
    "title": "From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding",
    "category": null,
    "markdown_content": "# From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding\n\nFarjana Sultana Mim, Shuchin Aeron, Eric Miller and Kristen Wendell\n\nAbstract-Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.\n\nIndex Terms—Natural Language Processing, Large Language Model, Discourse, Dialogue, Education.\n\n# I. INTRODUCTION\n\nRESEARCH in classroom settings has shown that student learning outcomes are higher when students frame a classwork or homework activity as an opportunity for constructing knowledge rather than as a task to be produced for the instructor [1], [2]. In other words, two important features of student conversations are: knowledge construction (KC) discourse, which refers to the student talks focused on developing conceptual understanding, and task production (TP) discourse, where student talks are focused on completing an instructional task as expeditently as possible [3].\n\nPrior research in learning sciences has also demonstrated that when students frame their purpose within an instructional activity as constructing knowledge rather than just completing a task, they are more likely to develop expertise and be able to later transfer their expertise to new situations [4]. These\n\nF. S. Mim is with the Department of Electrical and Computer Engineering, Tufts University, Medford, MA 02155, United States. (e-mail: farjana.mim59@gmail.com) (currently in the Department of Computer Science and Information Technology, Patuakhali Science and Technology University, Bangladesh)  \nS. Aeron is with the Department of Electrical and Computer Engineering, Tufts University, Medford, MA 02155, United States. (e-mail: shuchin.aeron@tufts.edu)  \nE. Miller is with the Department of Electrical and Computer Engineering, Computer Science and Biomedical Engineering, Tufts University, Medford, MA 02155, United States. (e-mail: eric.miller@tufts.edu)  \nK. Wendell is with the Department of Mechanical Engineering and Education, Tufts University, Medford, MA 02155, United States. (e-mail: kristen.wendell@tufts.edu)\n\n# Homework Topic\n\nDesign an experiment complete with instrumentation to determine the specific heats of a gas using a resistance heater. Discuss how the experiment will be conducted, what measurements need to be taken, and how the specific heats will be determined. What are the sources of error in your system? How can you minimize the experimental error?\n\n# Task Production Discourse\n\nStudent X: Although we just have to design the experiment. It's not like we have to actually do it.\n\nStudent  $T$  : No.\n\nStudent A: Just design and justify this will work.\n\nStudent  $X$ : How can you minimize the experimental error. That's one of the points there.\n\n# Knowledge Construction Discourse\n\nStudent X: Ok. So one thought I had too was that actually um whatever material the container is made out of when it heats up, it's going to expand -\n\nStudent T: Mhm.\n\nStudent X: - and that will change whatever the internal volume is. And I don't know if it makes it bigger or smaller actually. It um might make it bigger but if there were -\n\nFig. 1: Students' homework discussion's snippet of knowledge construction and task production discourse.\n\nresults have been found across several disciplines, including physics, chemistry, biology, and engineering education [1]–[3], [5]. However, the relationship between knowledge construction discourse and learning outcomes has yet to be translated into actionable principles for pedagogy and curriculum design. The major difficulty lies in pinpointing which particular aspects of the learning environment and instructional activity cue students into knowledge constructing discourse.\n\nTo address this gap, we aim to develop efficient methods for distinguishing students' knowledge construction discourse from their task production discourse so that researchers can more broadly investigate the conditions or contexts under which students tend to adopt a knowledge construction framing. Such findings would enable educators to design learning experiences and environments so that they cue students toward constructing knowledge.\n\nFig 1 shows examples of knowledge construction and task production discourse in an undergraduate engineering students' conversation. In the task production discourse of the example, the students remind each other that their homework task is to design an experiment and describe how they would minimize experimental error. These lines are focused on setting up the steps to complete their homework. In the\n\nknowledge construction discourse from the same homework conversation, student  $X$  shares an idea about how the process of heating a gas will affect the material containing it. Rather than simply completing a pre-determined step of the homework, student  $X$  tries to envision the phenomena that will occur in the experiment the students are designing. At this moment,  $X$ 's turn of talk is oriented toward understanding rather than expediency.\n\nTraditional manual analysis of student dialogues to identify these discourse features is time-intensive, which limits the scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of KC and TP discourse, providing educational researchers with valuable insights into how curricular and pedagogical variables influence students to engage in knowledge construction rather only task production.\n\nDiscourse in dialogue or conversations has been widely studied in NLP in different task settings such as dialogue act classification [6]–[9], dialogue topic segmentation and categorization [10]–[13], dialogue state tracking [14]–[19], and identifying dialogue system behaviors [20], [21]. However, although various discourse frameworks are being applied to different types of conversational data, hardly any of them are educational data [22], [23]. To address this gap, this study creates a novel educational dialogue dataset, annotated with knowledge construction (KC) and task production (TP) discourse<sup>1</sup>. We also formulate the NLP task of KCTP (Knowledge Construction and Task Production) prediction, aiming to automatically identify these discourse types within educational dialogues.\n\nLately, the NLP field has been revolutionized by pre-trained large language models (LLMs) such as GPT-3 [24], Llama [25], Gemini [26], Deepseek [27]. These models have demonstrated significant performance gains and yielded interesting findings across various NLP tasks, including the study of discourse in dialogues or conversations [14], [20]. Recently, a new paradigm called \"Pre-train, Prompt, and Predict\" [28] has gained popularity which leverages pre-trained LLMs through natural language prompts instead of fine-tuning them for specific tasks. By using such \"prompting\" method, one can probe task-specific knowledge from LLMs, which has shown remarkable performance in various tasks such as text classification and summarization [29], [30]. Another paradigm called \"instruction fine-tuning\" [31] which finetunes a model on a dataset via instructions, has significantly improved the performance of several tasks [32]. Therefore, we use GPT-3.5 with prompting techniques to establish a baseline for our Knowledge Construction vs. Task Production (KCTP) prediction task. However, as GPT-3.5 is not an open-source model, we also use the open-access LLaMA-3.1 (8B) model [33] and fine-tune it for the same task. Experimental results indicate that prompting and fine-tuning GPT-3.5 and LLaMA-3.1 yield suboptimal performance on KCTP prediction, suggesting the need for further research into models and methods better suited\n\nto educational discourse analysis. To summarize, the main contributions of this work are as follows:\n\n- We create a novel educational dialogue dataset annotated with Knowledge Construction (KC) and Task Production (TP) discourse, addressing a gap in discourse-annotated educational data.  \n- We formulate the Knowledge Construction vs. Task Production (KCTP) classification as a natural language processing (NLP) task to automatically identify KC and TP discourse in student dialogues.  \n- We establish baseline models for the KCTP prediction task using GPT-3.5 and LLaMA-3.1 prompting as well as LLaMA-3.1 instruction fine-tuning, revealing current limitations of LLMs in modeling educational discourse and highlighting directions for future research.\n\n# II. RELATED WORK\n\nThis study develops an educational dialogue dataset annotated with instances of knowledge construction (KC) and task production (TP) discourse. We also establish baseline models for the automatic prediction of KC and TP discourse, with the goal of enabling educational researchers to identify the curricular and pedagogical conditions that encourage students to engage in constructing knowledge rather than merely completing tasks. In this section, we briefly review prior work in three relevant areas: (1) discourse in learning sciences, (2) discourse analysis in Dialogue using NLP, and (3) use of pretrained language models for discourse modeling in dialogue.\n\n# A. Learning Sciences Approach to Educational Discourse Analysis\n\nDiscourse has been long studied in learning sciences to determine the nature of activity, understanding, and learning styles of students [1]–[5]. Gouvea et al. [1] presented a case study of a life-science major in a reformed physics course, showing how epistemological shifts in one discipline can transfer to another. Over a year, the student moved from rote learning to coherence-seeking reasoning in physics, integrating materials, peer discussion, and feedback. This reframing extended to biology, where the student began approaching the subject more conceptually. The study provides qualitative evidence that discourse-centered instructional strategies can foster cross-disciplinary epistemological development.\n\nIn another work, Scherr and Hammer [5] explored how students' collaborative behaviors such as posture, gaze, gestures, and vocal dynamics serve as observable indicators of their epistemological framing during active-learning physics activities. They analyze video recordings from introductory physics tutorial sessions and identify distinct behavioral clusters corresponding to different ways students frame the task: for instance, working through substance-based sensemaking versus perceiving it as a procedural worksheet exercise. The authors demonstrate that when students frame the activity as sensemaking, their behaviors align with deeper conceptual reasoning and engagement in discussing the substance of ideas. Their findings highlight the dynamic interplay between\n\nobservable behavior, framing, and the quality of students' scientific reasoning in small-group learning contexts.\n\nKoretsky et al. [2] examined how the design of engineering tasks and instructional framing influence student team dynamics, balancing action (\"doing\") and reflection (\"thinking\") during collaborative open-ended projects. Through detailed cases of small-group engineering design work, they show that when tasks are meaningful, realistic, and properly scaffolded, teams display more equitable participation, distributed modeling and communication, and deeper conceptual reasoning rather than surface-level task execution alone. In particular, the interplay between material engagement (e.g., prototyping and sketching) and explicit discourse about design decisions fosters collective sense-making and shared agency. The study highlights how thoughtfully structured activities and facilitative framing can empower teams to engage in both productive action and epistemic dialogue, offering important implications for discourse-centric analyses and NLP applications in educational dialogue modeling.\n\n# B. Discourse Analysis in Dialogue using NLP\n\nDiscourse in dialogue has been extensively studied in natural language processing (NLP) [34]–[36]. Raheja and Tetreault [7] proposed a hierarchical recurrent neural network and coupled it with a context-aware self-attention mechanism to model different levels of utterance and dialogue act semantics, achieving state-of-the-art performance on the Switchboard Dialogue Act Corpus. Liu et al. [10] introduced a joint model for dialogue segmentation and topic categorization, which was evaluated on a clinical spoken conversation dataset created by them. In another work, Xu et al. [15] developed a Dialogue State Distillation Network (DSDN), which leverages relevant information of previous dialogue states and employs an interslot contrastive learning loss to effectively capture the slot co-update relations from dialogue context. Their proposed method achieved state-of-the-art performance on the dialogue state tracking task. Sabour et al. [21] introduced a novel approach for empathetic response generation in dialogue, which leverages commonsense to draw more information about the user's situation and uses that to further enhance the empathy expression in generated responses. They showed that their approach outperforms the baseline models in both automatic and human evaluations.\n\n# C. Use of Pre-trained Language Models for Discourse Modeling in Dialogue\n\nRecent advancements of pre-trained large language models (LLMs) has significantly advanced the field of discourse modeling [37]–[40]. The importance of modeling speaker turns in dialogues was investigated by He et al. [6], where they incorporated turn changes in conversations among speakers for the dialogue act classification task. They introduced speaker turn embeddings and added them to utterance embeddings produced by the pretrained language model RoBERTa [41], which showed better performance for the dialogue act classification task. Xing and Carenini [11] utilized a neural utterance-pair coherence scoring model based on fine-tuning NSP BERT\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/bba84cd114aabd9a566f1acd99a86c2156a7e29a4dc63e3f8155985510fbf70a.jpg)  \nFig. 2: Topic distribution across the dataset\n\n[42] and achieved state-of-the-art results on the Dialogue topic segmentation task across three public datasets. Feng et al. [14] presented the first evaluation of ChatGPT on the dialogue state tracking task, highlighting its superior performance over prior methods. They also proposed an LLM-driven dialogue state tracking framework based on smaller, open-source foundation models and showed that it achieves comparable performance to ChatGPT. Finch et al. [20] investigated the ability of the state-of-the-art large language model (LLM), i.e., ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues and showed that although ChatGPT performed promisingly, often outperforming specialized detection models, the result is still not up to human performance.\n\nFew researches have been conducted that focus on discourse modeling on educational dialogue data. Jensen et al. [22] proposed a methodology for providing teachers with objective, automated feedback on the quality of their classroom discourse by comparing traditional open-vocabulary approaches using n-grams and Random Forest classifiers with a modern deep transfer learning method leveraging BERT. By modeling seven key features of teacher talk (such as questioning and elaborated evaluation) on 127 recordings of classroom talk, the authors demonstrated that while transfer learning with BERT offers a promising path for enhancing automated discourse analytics in education, its effectiveness hinges on the availability of sufficient annotated data to fine-tune the model effectively. Alic et al. [23] automatically distinguished between two pedagogically significant types of teacher questions: funneling questions, which guide students toward specific answers, and focusing questions, which encourage students to reflect on their reasoning. The authors create a labeled dataset of over 2,000 teacher questions annotated by experts and develop both supervised (fine-tuned RoBERTa) and unsupervised models to classify question types. Their supervised RoBERTa model showed strong alignment with expert judgments and correlates with key educational outcomes, such as instructional quality\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/e0b74a57a9ef55add7777e0214581eb34aea6f0100a23d660f768c53616a43dc.jpg)  \nFig. 3: Distribution of categories across the dataset.\n\nand student learning gains.\n\n# III. DATASET CURATION\n\n# A. Data Collection\n\nWe recorded homework discussions among undergraduate mechanical engineering students, focusing on topics from their thermal fluid systems course. Between 2 and 5 students participated in each conversation. Then, we transcribed the conversations ensuring that all data were de-identified. As part of the consent process, students were asked if their de-identified transcripts could be used in future research. Only transcripts from students who consented were included in the dataset.\n\n# B. Dataset Statistics\n\nThe dataset consists of 32 small-group conversations covering 19 homework topics, each topic corresponding to a distinct task description that students were required to complete collaboratively through discussion. Fig 2 shows the topic distribution across the dataset. The utterances in the conversations are segmented based on the fact that one \"turn,\" or utterance, consists of everything a single person utters until another person speaks (either because the first person has finished or because they interrupt the first person). The average token per conversation is 6404, and the average turns of talk is 321. Please see the appendix for the details of each topic.\n\n# C. Annotation Study\n\n1) Setup: Two expert annotators, including one co-author of this paper, participated in the annotation study. We developed a comprehensive annotation guideline and instructed the annotators to label each conversational turn as knowledge construction, task production, uncertain, or other. We created the label uncertain for the turns of talk where there is insufficient evidence to determine whether the speaker is continuing the current framing of either knowledge construction or task production. If a single utterance includes indicators for both\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/260629126576a8a452629b85f7734b9d10aec438f5e70a735dde8bd574948d7c.jpg)  \nFig. 4: Confusion matrix of dual annotations\n\nKC and TP classification, and the annotator cannot determine which category is the predominant framing for the student during the utterance, the utterance should be classified as uncertain. The label other refers to the turns of talk where students discuss a topic other than the assigned problem, such as the purpose of participating in the research study, or other academic classes or social events.\n\nWe trained the annotators in a pilot annotation phase where they were asked to annotate 5 conversations. After the pilot annotation, we discussed the disagreements and, if needed, adjusted the annotation guidelines. In our main annotation study, 6 conversations were annotated by two annotators and 21 conversations were annotated by a single annotator. For inter-annotator agreement (IAA) and the analysis of annotations, we report the results of dual annotations. Fig 3 illustrates the distribution of annotated labels across the dataset of 32 conversations. As anticipated, we see that the dataset is imbalanced, with the majority of annotated labels falling into the knowledge construction and task production categories.\n\n2) Inter-annotator agreement (IAA): We computed IAA using Cohen's  $(\\kappa)$  [43] for the dual annotations across four annotated discourse labels (i.e., knowledge construction, task production, uncertain and other). We obtained Cohen's  $(\\kappa)$  of 0.45 which indicates a moderate agreement [44], [45].  \nDiscerning undergraduate students' aims and purposes based on their spoken word is notoriously difficult for learning sciences researchers [5]. The difficulty in quickly determining whether students are in task production or knowledge construction mode (or when those modes are co-occurring) is one reason researchers are interested in exploring algorithm-assisted annotation. This also means that it is not surprising that the agreement between the two annotators was only moderate.  \n3) Analysis of Annotations: The confusion matrix of the dual annotations of 6 conversations is shown in Figure 4. We see that both annotators mostly agree with each other during the labeling of task production (TP) discourse and the most disagreement happens when one annotator thinks a turn of\n\ntalk is knowledge construction (KC) while other thinks that it's task production.\n\nFigure 4 reveals that Annotator 1 leaned toward classifying discourse as TP, while Annotator 2 leaned toward classifying discourse as KC. Of the utterances on which there was TP vs KC disagreement between the two human annotators, Annotator 1 chose KC for only  $7\\%$  (50/726) of the disagreements while Annotator 2 chose KC in  $93\\%$  (676/726) of the cases. Besides, where there was TP vs \"other\" disagreement,  $94\\%$  (125/133) times Annotator 1 chose TP over other, while just  $0.06\\%$  (8/133) times Annotator 2 chose TP over \"other.\"\n\nWe also found that the disagreement mostly happens under two conditions: (i) when students discuss the details of their problem-solving steps, and (ii) when students ask each other questions. For example, Consider the conversation snippet below (from Topic 4, \"determine the specific heats\").\n\nT: Right. Also how long are we doing it for. It's for like\n\nX: Yeah. Do it for ten hours. Do we need another you know microsecond.\n\nT: Yeah. Um ok. So then graph um V I versus time and take the area under the curve. Um. Ok. That area under the curve is just gonna be equal to  $Q$ , right?\n\nThe students here are discussing the details of an experimental design. Their homework task is to specify the design set-up. They consider the duration of the experiment, the plot they will produce from the data, and the physical quantity represented on that plot. Annotators 1 and 2 disagree on whether this portion of the discussion is aimed toward deeper understanding or toward making progress on the assignment. On one hand, discussion of experiment timescales and of the meaning of a graph might help students build knowledge about the physical quantity to be measured in the experiment. On the other hand, the students' statements about the length of the experiment and of the graphs it will generate could simply comprise another step forward in specifying an experimental design, which is completing the homework task.\n\nThe correct label in the case is knowledge construction. When student X discusses the experiment's timescale and student T discusses the meaning of the area under the curve, they are talking about concepts that they contributed anew to this homework discussion; these were not concepts mentioned in the homework problem statement, notes, or textbook for this course. Therefore, the students were calling up other intellectual resources to construct new ideas for this homework activity.\n\n# IV. EXPERIMENTS\n\n# A. Task setting\n\nWe consider the prediction task of KCTP discourse in a conversation as a label-generation task for each turn of talk in the conversation, where the model is instructed to generate one label out of the four annotated labels i.e., knowledge construction (KC), task production (TP), uncertain, other for each turn of talk.\n\nTo create a strong baseline, we assume that in cases where such KCTP discourse-specific resources are unavailable, pretrained large language models (LLMs) could be the most\n\neffective means of generating KCTP discourse labels for each turn in the conversation. We evaluate our task in three settings: (i) Zero-shot prompting setting: Zero-shot prompting is a technique used with large language models in which a task is defined using only natural language instructions, without providing any examples of how the task should be performed. This method relies on the model's pre-trained knowledge and ability to generalize in order to accurately interpret and carry out the given instruction. (ii) Few-shot prompting setting: Few-shot prompting is a technique where a language model is given a few input-output examples along with a natural language instruction to guide its response to new, similar inputs. In contrast to zero-shot prompting, which relies only on instructions, few-shot prompting uses these examples to establish a pattern or context that the model can mimic. This method exploits the in-context learning ability of large language models, allowing them to generalize from a small number of examples without the need for task-specific fine-tuning [24]. (iii) Fine-tuning setting: Fine-tuning refers to the process of taking a pre-trained large language model (which is generally trained on a large, general-purpose corpus) and further training it on a smaller, task-specific dataset to improve its performance on a particular task. This transfer learning strategy [42] allows models to leverage the rich representations learned during pre-training and adapt them to specialized tasks.\n\n# B. Models\n\nWe employ state-of-the-art LLMs namely GPT-3.5-turbo [24] and Llama-3.1-8B-Instruct [33] models for the KCTP discourse prediction task while we use GPT-4-1106-preview [46] for our prompt engineering [28]. A GPT (Generative Pre-trained Transformer) model [47] is an auto-regressive large language model developed by OpenAI that uses transformer [48] architecture to generate and understand human-like text. GPT models use a transformer decoder architecture, which is trained to predict the next word in a sequence, followed by fine-tuning on labeled datasets for specific applications. GPT-3.5 Turbo is optimized for speed and cost-efficiency, making it ideal for high-volume tasks. In contrast, GPT-4 offers superior reasoning, accuracy, and contextual understanding for more complex applications while costing more as well. Like GPT, the LLaMA (Large Language Model Meta AI) series [25] developed by Meta is also an auto-regressive language model based on the transformer architecture. Its key advantage lies in being open-source, enabling cost-free use while still delivering competitive performance.\n\n# C. Prompt Design\n\nWe create 5 prompts for the KCTP prediction task and use the GPT-4-1106-preview model to optimize our created prompts. We report results for both types of prompts, i.e., our curated prompts and GPT-4 optimized prompts. We also use the optimized prompts for instruction fine-tuning of Llama3.1 8B model. Among the 5 prompts, prompts 1 and 2 consist of the previous dialogue context along with the current turn of talk. Prompts 3 and 4 include the task description and the definitions of the labels respectively in addition to the previous\n\n<table><tr><td rowspan=\"3\">Prompts</td><td colspan=\"4\">Zero-Shot</td><td colspan=\"4\">Few-Shot</td><td>Fine-Tuned</td></tr><tr><td colspan=\"2\">Curated prompt</td><td colspan=\"2\">Optimized prompt</td><td colspan=\"2\">Curated prompt</td><td colspan=\"2\">Optimized prompt</td><td>Optimized prompt</td></tr><tr><td>GPT-3.5</td><td>Llama-3.1</td><td>GPT-3.5</td><td>Llama-3.1</td><td>GPT-3.5</td><td>Llama-3.1</td><td>GPT-3.5</td><td>Llama-3.1</td><td>Llama-3.1</td></tr><tr><td>Prompt 1</td><td>0.34</td><td>0.43</td><td>0.29</td><td>0.49</td><td>0.35</td><td>0.48</td><td>0.26</td><td>0.50</td><td>0.54</td></tr><tr><td>Prompt 2</td><td>0.28</td><td>0.38</td><td>0.47</td><td>0.40</td><td>0.35</td><td>0.45</td><td>0.37</td><td>0.48</td><td>0.51</td></tr><tr><td>Prompt 3</td><td>0.49</td><td>0.47</td><td>0.55</td><td>0.44</td><td>0.39</td><td>0.51</td><td>0.40</td><td>0.47</td><td>0.45</td></tr><tr><td>Prompt 4</td><td>0.32</td><td>0.52</td><td>0.46</td><td>0.50</td><td>0.38</td><td>0.54</td><td>0.44</td><td>0.57</td><td>0.49</td></tr><tr><td>Prompt 5</td><td>0.27</td><td>0.39</td><td>0.33</td><td>0.46</td><td>0.27</td><td>0.44</td><td>0.27</td><td>0.49</td><td>0.55</td></tr></table>\n\nTABLE I: Performance of GPT-3.5 and Llama-3.1 in the label prediction task under zero-shot, few-shot, and fine-tuned settings using different prompt types.\n\ndialogue context and current turn of talk. Prompt 5 consists of both the previous and afterward dialogue context and the current turn of talk. Please see the details of these prompts in Appendix.\n\n# D. Setup\n\nWe conduct experiments in zero-shot and eight-shot (two examples for each of the four labels) prompt settings where the number of shots reflects the number of examples provided in the prompt. Few-shot examples were sampled from two conversations and topics not included in the dataset.\n\nWe use OpenAI's API for GPT models and set the temperature of the model at 0.0 and maximum tokens at 10. To use Llama-3.1 (8B) for our task, we use Unsloth, an open-source AI library that enables us to train an LLM faster and efficiently with less GPU memory by applying techniques like quantization [49] and low-rank adaptation (LoRA) [50]. In our zero-shot and few-shot experiments, we set the Llama-3.1 model with a temperature of 1.5 and a maximum of 64 new tokens. Fine-tuning is performed for 5 epochs using a learning rate of 1e-4 with the AdamW 8-bit optimizer. We use a batch size of 8, gradient accumulation of 16, and a weight decay of 0.01. All experiments are conducted with a fixed random seed of 3407.\n\n# E. Evaluation Procedure\n\nWe use the weighted F1 score to evaluate model performance. During fine-tuning Llama-3.1, we employ five-fold cross-validation to obtain results across the entire dataset and enable comparison with zero-shot and few-shot prompting.\n\n# V. RESULTS AND DISCUSSIONS\n\nTable I presents the performance of GPT-3.5 and LLaMA-3.1 models across three experimental settings: Zero-Shot, Few-Shot, and Fine-Tuned, using both curated and GPT-4 optimized prompts on the KCTP discourse label prediction task. Five prompts (Prompt 1-5) developed by us are evaluated, and the scores represent the average F1 score.\n\n# A. Zero-shot and Few-shot effectiveness\n\nThe results indicate that overall, Llama-3.1 performs better than GPT-3.5 for both curated and optimized prompts across zero-shot and few-shot settings. However, the overall performance remains suboptimal, with the highest F1-score reaching only 0.57.\n\nIn the zero-shot setting, the best result is obtained by GPT-3.5 with optimized prompt 3, which includes a topic description in addition to the previous dialogue contexts. The result suggests that explicitly providing the communicative goal of the student conversation helps the model infer appropriate labels without prior examples. However, the GPT-3.5 performance drops in the few-shot setting. We assume that one of the reasons the few-shot prompting did not perform better here could be attributed to the fact that the examples we used didn't generalize well with the dataset, or the model had too much information to process. Moreover, performance degradation can sometimes happen in some LLMs for adding too domain-specific examples [51]. In contrast, LLaMA-3.1 attains its highest score in the few-shot setting with optimized prompt 4, which incorporates label definitions alongside the preceding dialogue context. It means that when we include examples, LLaMA-3.1 can better generalize than GPT-3.5 on this task by leveraging explicit label information. Table I also shows that optimizing our curated prompt with GPT-4 improves the overall performance.\n\n# B. Fine-tuning effectiveness\n\nThe fine-tuning results presented in Table I show that finetuning Llama-3.1 does not exceed its zero-shot and few\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/83dc0106f80e5606accfc9a13fd0a6d0b484c889c90d19ba70e60902a57169c3.jpg)  \nFig. 5: Confusion matrix of model prediction vs. true annotated labels\n\n<table><tr><td>Prompts</td><td>Same topic</td><td>Single different topic</td><td>Three different topics</td></tr><tr><td>Prompt 1</td><td>0.64</td><td>0.61</td><td>0.65</td></tr><tr><td>Prompt 2</td><td>0.58</td><td>0.63</td><td>0.61</td></tr><tr><td>Prompt 3</td><td>0.60</td><td>0.63</td><td>0.61</td></tr><tr><td>Prompt 4</td><td>0.53</td><td>0.58</td><td>0.62</td></tr><tr><td>Prompt 5</td><td>0.64</td><td>0.62</td><td>0.61</td></tr></table>\n\nTABLE II: Performance of finetuned Llama-3.1 when trained on the same topic, a single different topic, and three different topics.\n\nshot performance. We hypothesize that since our data is very domain-specific, it may have reduced the model's generalization ability by overfitting to narrow linguistic or conceptual patterns. Recent studies also showed that, in certain cases, fine-tuning often yields limited or even negative performance gains for large language models (LLMs) [52].\n\nFurthermore, the results suggest that incorporating dialogue context alone (as in Prompts 1 and 3), without additional task-specific contextual signals, leads to relatively better outcomes during fine-tuning. This observation implies that minimal yet coherent contextual grounding may help the model retain its pretrained reasoning and discourse capabilities.\n\n# C. Analysis\n\nFigure 5 presents the confusion matrix of the true annotated labels versus the model-predicted labels for the best result (i.e., Llama 3.1 performance in the few-shot settings with optimized prompt 4). It shows that the model is good at predicting the task production labels. However, it struggles with predicting the knowledge construction label and misclassifies about half of these instances as task production, indicating notable room for improvement. Moreover, the model also kind of struggles with predicting the \"other\" label, only correctly predicting it  $22\\%$  of the time. These findings suggest that while the model captures dominant discourse functions well, it struggles with more nuanced or less frequent categories, highlighting opportunities for improving label representation and contextual modeling.\n\nSince our dataset consists a diverse set of 19 topics (see Appendix for the details of each topic), we investigated how topic similarity between training and testing data influences model performance. For this experiment, we kept the test data same, and the training data size fixed, but varied the topical composition of the training data across three configurations: (i) training and test data drawn from the same topic, (ii) training data from a different single topic than the test set, and (iii) training data from three different topics distinct from the test set.\n\nThe results, summarized in Table II, reveal that, the model performs better when trained on data from different topics, except for prompt 5. This finding suggests that exposure to a broader range of linguistic and conceptual patterns enhances the model's generalization ability, whereas training on a single, homogeneous topic may lead to overfitting for most prompts. Notably, the model exhibits slightly better generalization within the same-topic setting for Prompt 5, which incorporates succeeding dialogue context. This indicates that the model might learn topic-bounded discourse dynamics\n\ni.e., how participants introduce, elaborate on, and shift ideas within a coherent topical space in this prompt setting whereas such recurring patterns are less transferable across topics.\n\n# VI. LIMITATIONS\n\nIn this study, we only consider two types of discourse features in educational conversations, namely knowledge construction (KC) and task production (TP). Besides, the dataset is limited to topics from a thermal fluid systems course in mechanical engineering. Moreover, we use a limited set of prompt templates because of the resource and time constraints.\n\n# VII. CONCLUSIONS AND FUTURE WORK\n\nThis work presents a novel educational conversational dataset, annotated with knowledge construction (KC) and task production (TP) discourse. Such discourse properties are crucial for framing student learning activities to develop more effective pedagogical settings that emphasize knowledge construction over mere task completion. In this work, we establish baselines for the KCTP discourse prediction task using state-of-the-art language models with prompting techniques and fine-tuning. Our results demonstrate that state-of-the-art LLMs struggle with this task, both under prompting-based and fine-tuning settings.\n\nFor future work, we plan to create reasoning chains that will help the model better understand the definitions of the labels in the prompts. We also intend to annotate low-level discourse structure for these student dialogues so that looking at the lower levels might help to see how the higher-order concepts emerge from a particular interaction of dialogue moves. Furthermore, we aim to expand the dataset by including a broader range of undergraduate subjects, thereby capturing more diverse discourse patterns across academic domains. This increased topical diversity will support more robust fine-tuning and facilitate the development of models capable of domain-general discourse understanding.\n\n# APPENDIX\n\n<table><tr><td>Topic</td><td>Description</td></tr><tr><td>Topic 1 (T1)</td><td>about a decade ago, stanford university successfully tried using waste vegetable oil from the dining halls as fuel for campus shuttles (https://news.stanford.edu/news/2006/january25/biodiesel-012506.html). what if [institution] tried to do this? plan a useful bus route around [institution] and specify the volume of fuel needed for the bus to travel this route without having to refuel. you may assume the energy density of vegetable oil is 42.20 mj/kg or 30.53 mj/l.</td></tr><tr><td>Topic 2 (T2)</td><td>contrails are giant vortices left by airplanes on the runway and in the sky. if other planes pass through these, it can cause problems because it is like going through a mini tornado, and the planes are not equipped to handle such a pressure gradient. boeing has hired you to design a device to be placed on runways to help get rid of contrails there. this could be done by moving the contrails out of the way or by stopping them altogether. justify your design using fluid mechanics.</td></tr><tr><td>Topic 3 (T3)</td><td>covid-19 has drastically changed how people live their daily lives. guidelines have been created for how far apart people should stay when talking normally to each other. however, if people are doing something like singing, which takes more effort results in air (and droplets potentially carrying the coronavirus) being expelled from the lungs more forcefully, the guidelines for simply talking may not be adequate. if six feet apart is the recommendation for talking, use fluid mechanics argument to decide how far apart people who are singing should stand in order to be far enough away from any particles that may be expelled into the air by their singing.</td></tr><tr><td>Topic 4 (T4)</td><td>design an experiment complete with instrumentation to determine the specific heats of a gas using a resistance heater. discuss how the experiment will be conducted, what measurements need to be taken, and how the specific heats will be determined. what are the sources of error in your system? how can you minimize the experimental error?</td></tr><tr><td>Topic 5 (T5)</td><td>gas turbine engines used in airplanes consist of a fan followed by a compressor, diffuser, combustor, turbine, and sometimes an afterburner. you are designing the engine for a high- altitude airplane. normally, commercial planes operate best around 35,000 ft above sea level, but your plane should operate optimally at around 100,000 ft. because of the high altitude, there will be a lower concentration of oxygen than normal, and the air entering the engine will be colder. design a protocol for getting the oxygen up to the appropriate temperature and pressure needed for combustion. keep in mind your solution has to be relatively light.</td></tr><tr><td>Topic 6 (T6)</td><td>geothermal heat pumps harness renewable geothermal energy by using thermal reservoirs of water deep within the earth for heating. such reservoirs have temperatures up to around 370 degrees celsius. geothermal heat pumps use this energy by transporting room-temperature or cold liquid deep into the ground via pipes, exposing it to the hot reservoir, and carrying it back up to the surface. imagine one of these reservoirs is discovered beneath the building where you live and design a heat exchanger system that uses the reservoir to heat your building. sketch your system and specify the diameter, length, and material of the pipe, the flow rate, and the working fluid. design your system such that it supplies a significant portion of the energy required for your building to operate normally.</td></tr><tr><td>Topic 7 (T7)</td><td>hybrid rockets use a combination of solid and liquid or gaseous propellants. in hybrid rockets, a stable oxidizer is used with a solid fuel. in order to be used, the fuel needs to be vaporized. the primary difficulty with hybrids is with mixing the propellants during the combustion process. in a hybrid rocket, the mixing happens at the melting or evaporating surface. the mixing is not well-controlled and generally, a lot of propellant is left unburned, limiting the motor's efficiency. on the other hand, liquid propellants are generally mixed with oxidizer by an injector at the top of the combustion chamber which directs many small streams of fuel and oxidizer into one another. based on reasonable efficiencies of both liquid fuel and hybrid fuel processes, estimate the weight of fuel necessary to get a specific rocket of your choice to low earth orbit if the fuel is liquid vs. hybrid.</td></tr><tr><td>Topic 8 (T8)</td><td>most ski resorts in the u.s. use snow guns to make additional snow to supplement natural snow. these machines use water and compressed air. the air forces the water to form tiny droplets, which are then expelled from the nozzle and form ice crystals, which then fall to the ground as snow. compressed air cools as it expands, which assists with converting the water droplets into snow. choose your favorite ski resort and the desired depth of snow for the best skiing, and use thermodynamics to determine how long it will take to cover the ski trails in that amount of snow. you may assume that one snow gun uses about 100 gallons of water per minute and that the compressor can produce 50 cfm (cubic feet per minute) of air.</td></tr><tr><td>Topic 9 (T9)</td><td>race cars need to be as aerodynamic as possible. in many cases, to test the aerodynamics of a car, a wind-tunnel is used. you have been hired by chevrolet to analyze the air flow around their race cars. the wind tunnel you will be using to do this is an open circuit wind tunnel, where air is drawn from the laboratory environment, rather than being recirculated in the wind tunnel itself. such wind-tunnels consist of a nozzle to accelerate the air, the test section in which the car sits, and a diffuser which decelerates the air. based on reasonable values for air speed around the vehicle being tested, design a wind-tunnel for testing a race car. include all necessary specifications of the different parts of the wind tunnel, such as dimensions and air speeds. also specify the necessary power of the fan and estimate the head loss due to the vehicle. use fluid mechanics to justify your response.</td></tr><tr><td>Topic 10 (T10)</td><td>since they know you are a mechanical engineer, your neighbors have asked you to help them design a waterfall for their garden similar to the one in the image below. you need to devise a way to get water from the pool at the bottom up to the top of the waterfall, and there needs to be enough water so that the waterfall actually looks good. design a system to do this. include a diagram of how the pump system will work, and include any important specifications such as flow rates and dimensions. then find a pump online and determine approximately how much power the waterfall pump will use per day. you may make as many assumptions as needed, just specify what assumptions you are making and why.</td></tr><tr><td>Topic 11 (T11)</td><td>the building of farfar's danish ice cream shop in duxbury, ma is somewhat old and thus does not seem to have a great cooling system. as a result, sometimes the ice cream gets a bit melty even when it's still in the freezer. the temperature in the ice cream shop is to be maintained at 55°f. estimate the dimensions of the building, use thermodynamics principles to determine the maximum heat loss the shop can have, and suggest a method for minimizing this heat loss.</td></tr><tr><td>Topic 12 (T12)</td><td>the butterfly swimming stroke is considered by many to be one of the most difficult strokes. it is also one of the fastest. when used over longer distances, the butterfly stroke is slightly slower than freestyle, partly due to the greater physical exertion required by the butterfly. however, butterfly has the fastest peak speed. explain why you think this stroke has the fastest peak speed. then, design a special swimsuit or other (non-motorized) device for a swimmer to further increase the speed of the butterfly stroke so that it will always be faster than freestyle no matter the distance over which the stroke is used. include a diagram of your design, and use fluid mechanics principles to prove that it will work.</td></tr><tr><td>Topic 13 (T13)</td><td>trek bikes has contracted you to design an attachment for their bikes to help make the bike and rider more streamlined. this attachment should effectively reduce the bike and rider's air resistance without impeding the cyclist's ability to ride their bike as usual. also specify what material this should be made of, and include a diagram of your design. justify your design using fluid mechanics.</td></tr><tr><td>Topic 14 (T14)</td><td>you are designing a tiny home that can be used for camping adventures. you want to be able to take your tiny home on camping trips in vermont and new hampshire during the fall to see the foliage, but you are worried that it might get a bit too cold for comfort, as that time of year, the temperatures at night can get down to 30°F. design a small, low-power HVAC system to keep the inside of your tiny home at a temperature no lower than 45°F. specify what parts will be needed and how this system will be compatible with your tiny home. use fluid mechanics and heat transfer principles to justify that this system will indeed keep the temperature at 45°F or higher.</td></tr><tr><td>Topic 15 (T15)</td><td>you are working at a robotics company to design a robot that can swim in water to collect data on sharks. this robot needs to be as hydrodynamic as possible so that it is efficient, and you need to be able to control how fast the robot will go so it can keep up with the sharks, as well as be able to make it turn while swimming. design a swimming robot, estimate its drag coefficient and the drag on the robot when it is moving at three different speeds (so you should have three different values for drag). then determine how much power will be needed to make the robot move forward at each of the three speeds. include a diagram of your robot in your response.</td></tr><tr><td>Topic 16 (T16)</td><td>you have been contracted by [institution] to design a system to get hot water to different parts of the science and engineering complex (sec). in particular, this system needs to work well during winter, when it is colder outside and most likely slightly colder than usual within the outer walls of the building and in the building in general. estimate the wattage necessary to keep the water at a reasonably hot temperature, and determine the flow rates and pressures necessary to get the hot water to various parts of the building. include a labeled sketch of your design, and be sure to use fluid mechanics to justify that your design will work.</td></tr><tr><td>Topic 17 (T17)</td><td>you have been doing a lot of baking recently and wish that you had a convection oven. convection ovens have one or more fans that help circulate the air in the oven, whereas in regular ovens, the only thing moving the air is natural convection. therefore, you want a convection oven so that you can bake everything faster and more evenly. however, you don’t want to spend the money on an entirely new oven since convection ovens are expensive, and you don’t want to have to get rid of the regular oven you already have. design something you can put in your regular oven that will make it function similarly to a convection oven. specify air flow rates and estimate the power needed for any components. also draw a diagram of your design and specify where any proposed components will go in the oven. use fluid mechanics to justify that your design will make your oven work similarly to a convection oven.</td></tr><tr><td>Topic 18 (T18)</td><td>you have been hired by firefighters to design a tripod to hold a large hose when fighting fires. the stream of water that comes out of the hose is 5 cm in diameter. determine what the flowrate of water out of the hose should be in order to work well for fighting a fire that is 9 meters away. then calculate how much reaction force will be needed at the base of the tripod to keep it from moving when the hose is being used. use fluid mechanics to support your response.</td></tr><tr><td>Topic 19 (T19)</td><td>you have recently gotten into skydiving. when you are skydiving, once you get close enough to the earth, you have to deploy a parachute. the skydiving part is exciting, but once you deploy the parachute, you have been getting bored since when you’re falling through the air, you eventually reach one constant speed (the terminal velocity). you want to design an attachment that enables you to increase and decrease your terminal velocity as you are falling. estimate your terminal velocity without this attachment, and then estimate the maximum and minimum terminal velocities when the attachment is being used. use lift and drag calculations to justify your answer.</td></tr></table>\n\nTABLE III: Details of the dataset topics, where each topic corresponds to a distinct task description that students were required to complete collaboratively through discussion.  \n\n<table><tr><td>Prompts</td><td>Author curated prompt template</td><td>GPT-4 optimized prompt template</td></tr><tr><td>Prompt 1(Previous dialogue context)</td><td>You will be provided with a dialogue and its context.The context is the previous dialogue lines of the given dialogue and each line in context is separated by a newline character.Classify the given dialogue considering its context into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Context:Dialogue:</td><td>Classify the provided dialogue into the correct category based on its context. Choose one of these categories: knowledge construction, task production, uncertain, or other. Only provide the category name as your response(Context:Dialogue:</td></tr><tr><td>Prompt 2(Previous dialogue context)</td><td>You will be provided with a current dialogue line and its previous dialogue lines.Each line in the previous dialogue lines is separated by a newline \\n character.Classify the current dialogue line considering its previous dialogue lines into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Previous dialogue lines:Current dialogue line:</td><td>Classify the current dialogue line into one of the following categories based on its context within the preceding dialogue lines: knowledge construction, task production, uncertain, or other. Provide the category without any explanation.Previous dialogue context:Current dialogue line:</td></tr><tr><td>Prompt 3(Previous dialogue context &amp; Topic description)</td><td>You will be provided with a dialogue, its context and a task description.The context is the previous dialogue lines of the given dialogue and each line in context is separated by a newline character.The dialogue and context are about completing the task details in the task description.Classify the given dialogue considering its context and task description into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Task description:Context:Dialogue:</td><td>Given a dialogue along with its preceding context and a specific task description, classify the provided dialogue into one of four categories (knowledge construction, task production, uncertain, other). Provide only the category without any further explanation.Task Description:Context:Dialogue:</td></tr><tr><td>Prompt 4(Previous dialogue context &amp; Label defini-tions)</td><td>You will be provided with a dialogue and its context.The context is the previous dialogue lines of the given dialogue, and each line in context is separated by a newline \\n character.Classify the given dialogue considering its context into one of the four categories: knowledge construction, task production, uncertain, other.The definition of each of the categories is given below:knowledge construction: means the dialogue is focused on expressing understandings of concepts, phenomena, or technolo-gies. Simply stating a definition from textbook or notes does not count as knowledge construction.task production: means the dialogue is focused on completing the assigned task to satisfy the instructor, without verbalizing regard for understanding the bigger picture. For example, the dialogue is stating an equation, or asksin for a numerical answer, or calculating a number out loud, or discussing what to do next.uncertain: means there is insufficient evidence for classifying the dialogue either as a knowledge construction or task production.It is the default category for one word conversational fillers such as 'yeah', 'okay'.other: means the dialogue is about a topic other than the assigned task.Output only one of the categories and do not provide any explanation.#####Context:Dialogue:</td><td>Given the dialogue and its preceding context, classify the dialogue into one of the following four categories: knowledge construction, task production, uncertain, or other.- Knowledge Construction: The dialogue focuses on deep understanding of concepts or phenomena, going beyond mere definitions.- Task Production: The dialogue aims at completing a task or assignment, primarily focusing on procedural steps.- Uncertain: The dialogue does not provide enough information for classification into the above categories or includes filler words like 'yeah', 'okay'.- Other: The dialogue discusses topics unrelated to the assigned task.Provide only the category without any explanation(Context:Dialogue:</td></tr><tr><td>Prompt 5(Previous and afterward dialogue context)</td><td>You will be provided with a dialogue, its before context and its after contextThe before context is the previous dialogue lines and after context is the succeeding dialogue lines of the given dialogue.Each line in before and after context is separated by a newline \\n character.Classify the given dialogue considering its before and after context into one of the four categories: knowledge construction, task production, uncertain, other.Output only one of the categories and do not provide any explanation.#####Before Context:Dialogue:After Context:</td><td>Your task is to classify a specific dialogue based on the surrounding context into one of the following cat-egories: knowledge construction, task production, uncer-tain, other. You will be given the dialogue, as well as the lines of conversation that precede it (Before Context) and follow it (After Context). Each dialogue line in the contexts is separated by a newline character.Please provide only the category as your response with- out any explanation.Before Context:Dialogue:After Context:</td></tr></table>\n\nTABLE IV: Details of the prompts used in modeling for knowledge construction and task production discourse prediction.\n\n# REFERENCES\n\n[1] J. Gouvdea, V. Sawtelle, and A. Nair, \"Epistemological progress in physics and its impact on biology,\" Physical Review Physics Education Research, vol. 15, no. 1, p. 010107, 2019.  \n[2] M. D. Koretsky, D. M. Gilbuena, S. B. Nolen, G. Tierney, and S. E. Volet, \"Productively engaging student teams in engineering: The interplay between doing and thinking,\" in 2014 IEEE Frontiers in Education Conference (FIE) Proceedings. IEEE, 2014, pp. 1-8.  \n[3] J. E. S. Swenson, \"Developing knowledge in engineering science courses: Sense-making and epistemologies in undergraduate mechanical engineering homework sessions,\" Ph.D. dissertation, Tufts University, 2018.  \n[4] D. L. Schwartz, J. M. Tsang, and K. P. Blair, The ABCs of how we learn: 26 scientifically proven approaches, how they work, and when to use them. WW Norton & Company, 2016.  \n[5] R. E. Scherr and D. Hammer, \"Student behavior and epistemological framing: Examples from collaborative active-learning activities in physics,\" Cognition and Instruction, vol. 27, no. 2, pp. 147-174, 2009.  \n[6] Z. He, L. Tavabi, K. Lerman, and M. Soleymani, \"Speaker turn modeling for dialogue act classification,\" arXiv preprint arXiv:2109.05056, 2021.  \n[7] V. Raheja and J. Tetreault, \"Dialogue act classification with context-aware self-attention,\" arXiv preprint arXiv:1904.02594, 2019.  \n[8] R. Li, C. Lin, M. Collinson, X. Li, and G. Chen, “A dual-attention hierarchical recurrent neural network for dialogue act classification,” arXiv preprint arXiv:1810.09154, 2018.  \n[9] H. Kumar, A. Agarwal, R. Dasgupta, and S. Joshi, \"Dialogue act sequence labeling using hierarchical encoder with crf,\" in Proceedings of the aaai conference on artificial intelligence, vol. 32, no. 1, 2018.  \n[10] Z. Liu, S. U. M. Salleh, H. C. Oh, P. Krishnaswamy, and N. Chen, \"Joint dialogue topic segmentation and categorization: A case study on clinical spoken conversations,\" in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track, 2023, pp. 185-193.  \n[11] L. Xing and G. Carenini, “Improving unsupervised dialogue topic segmentation with utterance-pair coherence scoring,” arXiv preprint arXiv:2106.06719, 2021.  \n[12] S. Somasundaran et al., “Two-level transformer and auxiliary coherence modeling for improved text segmentation,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 05, 2020, pp. 7797–7804.  \n[13] S. Kim, R. E. Banchs, and H. Li, “Towards improving dialogue topic tracking performances with wikification of concept mentions,” in Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue, 2015, pp. 124–128.  \n[14] Y. Feng, Z. Lu, B. Liu, L. Zhan, and X.-M. Wu, \"Towards llm-driven dialogue state tracking,\" arXiv preprint arXiv:2310.14970, 2023.  \n[15] J. Xu, D. Song, C. Liu, S. C. Hui, F. Li, Q. Ju, X. He, and J. Xie, \"Dialogue state distillation network with inter-slot contrastive learning for dialogue state tracking,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, no. 11, 2023, pp. 13834-13842.  \n[16] M. D. Ma, J.-Y. Kao, S. Gao, A. Gupta, D. Jin, T. Chung, and N. Peng, “Parameter-efficient low-resource dialogue state tracking by prompt tuning,” arXiv preprint arXiv:2301.10915, 2023.  \n[17] J. Guo, K. Shuang, J. Li, Z. Wang, and Y. Liu, “Beyond the granularity: Multi-perspective dialogue collaborative selection for dialogue state tracking,” arXiv preprint arXiv:2205.10059, 2022.  \n[18] Y. Zhou, G. Zhao, and X. Qian, “Dialogue state tracking based on hierarchical slot attention and contrastive learning,” in Proceedings of the 31st ACM international conference on information & knowledge management, 2022, pp. 4737–4741.  \n[19] G. Qixiang, G. Dong, Y. Mou, L. Wang, C. Zeng, D. Guo, M. Sun, and W. Xu, “Exploiting domain-slot related keywords description for few-shot cross-domain dialogue state tracking,” in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, 2022, pp. 2460–2465.  \n[20] S. E. Finch, E. S. Paek, and J. D. Choi, “Leveraging large language models for automated dialogue analysis,” arXiv preprint arXiv:2309.06490, 2023.  \n[21] S. Sabour, C. Zheng, and M. Huang, “Cem: Commonsense-aware empathetic response generation,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 10, 2022, pp. 11229-11237.  \n[22] E. Jensen, S. L. Pugh, and S. K. D'Mello, \"A deep transfer learning approach to modeling teacher discourse in the classroom,\" in LAK21: 11th international learning analytics and knowledge conference, 2021, pp. 302-312.\n\n[23] S. Alic, D. Demszky, Z. Mancenido, J. Liu, H. Hill, and D. Jurafsky, \"Computationally identifying funneling and focusing questions in classroom discourse,\" arXiv preprint arXiv:2208.04715, 2022.  \n[24] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., \"Language models are few-shot learners,\" Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.  \n[25] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Roziere, N. Goyal, E. Hambro, F. Azhar et al., \"Llama: Open and efficient foundation language models,\" arXiv preprint arXiv:2302.13971, 2023.  \n[26] M. Reid, N. Savinov, D. Teptyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac, R. Soricut, A. Lazaridou, O. First, J. Schrittwieser et al., \"Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,\" arXiv preprint arXiv:2403.05530, 2024.  \n[27] D. Guo, D. Yang, H. Zhang, J. Song, R. Zhang, R. Xu, Q. Zhu, S. Ma, P. Wang, X. Bi et al., \"Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning,\" arXiv preprint arXiv:2501.12948, 2025.  \n[28] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, \"Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing,\" ACM Computing Surveys, vol. 55, no. 9, pp. 1-35, 2023.  \n[29] T. Gao, A. Fisch, and D. Chen, \"Making pre-trained language models better few-shot learners,\" arXiv preprint arXiv:2012.15723, 2020.  \n[30] X. L. Li and P. Liang, \"Prefix-tuning: Optimizing continuous prompts for generation,\" arXiv preprint arXiv:2101.00190, 2021.  \n[31] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, \"Finetuned language models are zero-shot learners,\" arXiv preprint arXiv:2109.01652, 2021.  \n[32] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma et al., \"Scaling instruction-finetuned language models,\" Journal of Machine Learning Research, vol. 25, no. 70, pp. 1-53, 2024.  \n[33] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten, A. Yang, A. Fan et al., \"The llama 3 herd of models,\" arXiv e-prints, pp. arXiv-2407, 2024.  \n[34] W. Li, L. Zhu, W. Shao, Z. Yang, and E. Cambria, \"Task-aware self-supervised framework for dialogue discourse parsing,\" in 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023). Association for Computational Linguistics, 2023, pp. 14162-14173.  \n[35] Y. Tulpan and O. Tsur, \"A deeper (autoregressive) approach to nonconvergent discourse parsing,\" arXiv preprint arXiv:2305.12510, 2023.  \n[36] F. S. Mim, N. Inoue, S. Naito, K. Singh, and K. Inui, \"LPAttack: A feasible annotation scheme for capturing logic pattern of attacks in arguments,\" in Proceedings of the Thirteenth Language Resources and Evaluation Conference, N. Calzolari, F. Bechet, P. Blache, K. Choukri, C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard, J. Mariani, H. Mazo, J. Odijk, and S. Piperidis, Eds. Marseille, France: European Language Resources Association, Jun. 2022, pp. 2446-2459. [Online]. Available: https://aclanthology.org/2022.lrec-1.261/  \n[37] C. Li, Y. Yin, and G. Carenini, “Dialogue discourse parsing as generation: a sequence-to-sequence llm-based approach,” in Proceedings of the 25th annual meeting of the special interest group on discourse and dialogue, 2024, pp. 1-14.  \n[38] G. Cimino, C. Li, G. Carenini, and V. Deufemia, “Coherence-based dialogue discourse structure extraction using open-source large language models,” in Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue, 2024, pp. 297–316.  \n[39] X. Gu, K. M. Yoo, and J.-W. Ha, \"Dialogbert: Discourse-aware response generation via learning to recover and rank utterances,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 14, 2021, pp. 12911-12919.  \n[40] F. S. Mim, N. Inoue, P. Reisert, H. Ouchi, and K. Inui, \"Corruption is not all bad: Incorporating discourse structure into pre-training via corruption for essay scoring,\" IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 2202-2215, 2021.  \n[41] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, \"Roberta: A robustly optimized bert pretraining approach,\" arXiv preprint arXiv:1907.11692, 2019.  \n[42] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” in Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers), 2019, pp. 4171–4186.\n\n[43] J. Cohen, “A coefficient of agreement for nominal scales,” Educational and psychological measurement, vol. 20, no. 1, pp. 37–46, 1960.  \n[44] R. Artstein and M. Poesio, \"Inter-coder agreement for computational linguistics,\" Computational linguistics, vol. 34, no. 4, pp. 555-596, 2008.  \n[45] W. Spooren and L. Degand, \"Coding coherence relations: Reliability and validity,\" 2010.  \n[46] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4 technical report,” arXiv preprint arXiv:2303.08774, 2023.  \n[47] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever et al., “Improving language understanding by generative pre-training,” 2018.  \n[48] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, \"Attention is all you need,\" Advances in neural information processing systems, vol. 30, 2017.  \n[49] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. Howard, H. Adam, and D. Kalenichenko, “Quantization and training of neural networks for efficient integer-arithmetic-only inference,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 2704–2713.  \n[50] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, W. Chen et al., \"Lora: Low-rank adaptation of large language models.\" ICLR, vol. 1, no. 2, p. 3, 2022.  \n[51] Y. Tang, D. Tuncel, C. Koerner, and T. Runkler, “The few-shot dilemma: Over-prompting large language models,” arXiv preprint arXiv:2509.13196, 2025.  \n[52] S. Barnett, Z. Brannelly, S. Kurniawan, and S. Wong, “Fine-tuning or fine-failing? debunking performance myths in large language models,” arXiv preprint arXiv:2406.11201, 2024.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/193c6d2e3a8f20d5573caa66c5bdb4930fa0b274d35f5bb1344f123f481e77b6.jpg)\n\nFarjana Sultana Mim received her B.Sc. in Computer Science and Engineering from Patuakhali Science and Technology University, Bangladesh, in 2016, and her M.S. and Ph.D. in System Information Sciences from Tohoku University, Japan, in 2019 and 2022. She was a postdoctoral scholar in the Department of Electrical and Computer Engineering at Tufts University, USA, in 2023. She is currently a lecturer in the Department of Computer Science and Information Technology at Patuakhali Science and Technology University. Her research interests\n\ninclude NLP in education, large language models, discourse analysis, unsupervised learning, argumentation, and commonsense reasoning.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/6adf8d7283e86234bcd8f5a4e972ff207226ba0df1e9c68be835dfd698a9ebe8.jpg)\n\nShuchin Aeron is a professor in the Department of Electrical and Computer Engineering at Tufts School of Engineering. He received his Ph.D. from Boston University in 2009 and was awarded the best PhD thesis award from both the School Of Engineering and from the Department of Electrical and Computer Engineering. From 2009-2011, he was a postdoctoral research fellow at Schlumberger-Doll Research (SDR), where he worked on signal processing solution products for borehole acoustics resulting in a number of patents. In 2016, he received\n\nthe NSF CAREER award for his work on multidimensional signals and systems. Shuchin Aeron is presently a senior member of the Institute of Electrical and Electronics Engineers (IEEE) and an associate editor for the ACM transactions on Theory of Probabilistic Machine Learning.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/402b5a9f8c99aed13a90ac89f354956cc61ad94379a6fcc38197490ea705674f.jpg)\n\nEric Miller is a Professor in the Department of Electrical and Computer Engineering and an adjunct Professor in the Departments of Computer Science and Biomedical Engineering at Tufts University. He previously served in the Department of Electrical and Computer Engineering at Northeastern University from 1994 to 2006. He is also a Senior Scientist at the Jean Meyer Human Nutrition Research Center on Aging at Tufts University and currently serves as the Director of the Engineering Education and Centers Division in the Directorate for Engineering\n\nat the U.S. National Science Foundation. Dr. Miller received National Science Foundation CAREER Award in 1996 and the Outstanding Research Award from the Northeastern University College of Engineering in 2002. From 2014 to 2018, he served on the Technical Liaison Committee for the IEEE Transactions on Computational Imaging and chaired the SIAM Imaging Sciences Special Interest Group from 2015 to 2017. He was an Associate Editor for the IEEE Transactions on Geoscience and Remote Sensing from 2003 to 2015 and for the IEEE Transactions on Image Processing from 1999 to 2003.\n\n![](/uploads/images/9d7befb9-e05e-4cb6-89d3-41a9b5d3a916/09b3199cb79e86dc5fe391ad46f7e33c3f4980e8ae5fc74048f58bd9f221536d.jpg)\n\nKristen Wendell is an Associate Professor in the Department of Mechanical Engineering and Education at Tufts University. She earned her B.S.E. from Princeton University, her M.S. from the Massachusetts Institute of Technology, and her Ph.D. from Tufts University in 2003, 2005, and 2011, respectively. She currently serves as a CEEO Fellow in the Center for Engineering Education Outreach and as the Co-Director of the Institute for Research on Learning and Instruction at Tufts University. Her research work focuses on characterizing and\n\nsupporting inclusive, sophisticated disciplinary practices during engineering learning experiences in undergraduate course, K-8 classrooms, and teacher education contexts.",
    "translated_content": null,
    "created_at": "2025-12-15 14:03:42.383056",
    "updated_at": "2025-12-15 14:04:10.491461"
  },
  "2123bbce-b4f3-421c-8876-3f0549537ae5": {
    "id": "2123bbce-b4f3-421c-8876-3f0549537ae5",
    "filename": "2405.11070v1.pdf",
    "file_path": "./uploads/papers/2123bbce-b4f3-421c-8876-3f0549537ae5.pdf",
    "status": "failed",
    "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
    "category": null,
    "markdown_content": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid harm because of hateful, offensive, or toxic text. Previous work on evaluating the toxicity of ChatGPT has found that assigning personas, using non-English languages, prompting with creative tasks, jailbreak prompts, and higher temperature values can all lead to more toxic responses [25]. Perspective API [12] and OpenAI Moderation API [15] are popular services to measure toxicity in various categories including hateful content, violence, etc. Jill Watson ensures safety in three ways: (i) OpenAI Moderation API for both user inputs and its own responses, (ii) skill classifier to identify irrelevant queries, and (iii) encourages polite responses in prompts to ChatGPT.\n\nDialog Systems are AI agents designed for human-like conversations, typically using hybrid architectures involving both rule-based systems and machine learning systems. For instance, MILABOT [20] uses rule-based and generative models along with a response selection policy trained using reinforcement learning. Microsoft XiaoIce [28] uses a skill-based architecture where the chat manager selects one of 230 high-level skills to generate responses. To the best of our knowledge, such powerful multi-turn dialog systems have not been introduced in a classroom. The legacy Jill Watson [8] is a single-turn question-answering\n\n![](/uploads/images/2123bbce-b4f3-421c-8876-3f0549537ae5/0fa51ad6db48b2e0593c73bb2200b94e603f95c19a7b007d2d1689fd6daec81e.jpg)  \nFig. 1. Architecture of Jill Watson: After the coreference resolution of an incoming query, the skill classifier is used to find the most appropriate skill for response generation. Jill Watson's skills include Contextual Answering, Greetings, etc. The updated conversation history is used as context for generating responses in the future.\n\nsystem for course logistics and policies. OpenAI Assistants service<sup>1</sup> provides a way to instantiate a ChatGPT-based agent to generate responses using text documents. Inspired by XiaoIce, Jill Watson has a skill-based architecture and is designed to be a safe conversational agent for classrooms that can answer student queries related to course logistics as well as course content using ChatGPT in the backend. It is also well-suited for other applications in education like intelligent textbooks given its ability to use long documents as context.\n\n# 3 Jill Watson Architecture\n\nThe architecture of Jill Watson shown in Figure 1 takes inspiration from the skill-based architecture of XiaoIce [28]. XiaoIce relies on different skills such as task completion, image commenting, content creation, etc. to interact with users and selects the appropriate skill for each conversation turn based on the previous context. In Jill Watson, the query with resolved coreferences is used to decide the most appropriate skill for answering the incoming query. The skill-based design of Jill Watson makes it extensible as we can easily plug in new API services and other capabilities in the future in the form of new skills.\n\nContextual Answering skill is responsible for answering questions where content needs to be retrieved from course content or syllabus and Self-awareness skill answers queries about Jill Watson itself. As we will discuss later, these two skills make Jill Watson a knowledge-grounded AI agent with the ability to refer to multiple documents and cite relevant content in its answers. Further, ChatGPT allows Jill Watson to be conversational by using past messages as context in generating responses to user messages. We also utilize many safety features in Jill Watson which include detecting irrelevant queries by skill classifier, moderation filters, and prompts to encourage courteous responses.\n\n# 3.1 Coreference Resolution\n\nCoreference resolution involves determining the entities that are indirectly referenced in a text and making them explicit using nouns or noun phrases. For example, given the context 'John started reading a book', the query 'When did he start?' has two coreferences. An explicit coreference is suggested by the word 'he' while an implicit coreference to an event is present because of 'When' and 'start'. In coreference resolution, we must resolve the reference 'he' and the event that 'When' and 'start' are referring to. Therefore, the resolved query would be 'When did John start reading the book?' formed by replacing 'he' with John and adding the implicit event 'reading the book'.\n\nWhile ChatGPT implicitly resolves the coreferences as it can construct appropriate responses by itself, since we wish to use existing models for retrieval without any fine-tuning, we need to construct complete queries with resolved coreferences before passing them to the retrieval module. Hence, the first step in Jill Watson is to resolve coreferences in the user query based on the previous messages. In the example in Figure 1, 'it' in 'When is it due?' is replaced by the entity 'Assignment 2'. This is done by prompting ChatGPT to resolve the coreferences in the received query and passing the past messages as context. We use a combined instruction and demonstration-based prompt where we explain the task (instruction) along with three demonstrations with no coreferences, an explicit and an implicit coreference. In our investigation, we found demonstrations to be extremely useful for improving performance, especially on implicit coreferences which are much harder to identify.\n\n# 3.2 Skill Classifier\n\nAs discussed earlier, Jill Watson uses various skills to answer different types of queries. For instance, queries that require retrieval are forwarded to the Contextual Answering Skill while greetings are answered by the Greetings Skill. The skill-based division using a skill classifier allows us to use different response-generation techniques based on the user query. It can also aid in understanding user behaviors by analyzing the skill distribution of student queries.\n\nTo forward a user query to the appropriate skill, the resolved query (after coreference resolution) is used is to perform skill classification by prompting ChatGPT. In the example in Figure 1, the selected skill is Contextual Answering based on the resolved query and previous messages as context. We again used a combined instruction and demonstration-based prompt with an explanation of each skill (instruction) and one demonstration per skill. We found that fewer and distinct classes lead to a better performance which motivates the use of a small number of skills as far as possible.\n\n# 3.3 Contextual Answering\n\nContextual answering or context-based question answering skill involves answering questions based on the given information. For Jill Watson, this information\n\nAlgorithm 1 Contextual Answering Skill  \nRequire:Resolved query  $Q$  ,context  $C$  ,PRE-PROCESSED DOCUMENTS with passages   \n $\\mathcal{P}$  and corresponding context embeddings  $\\mathcal{D}$  , DPR query encoder  $E_{q}(.)$    \nEnsure:Response  $R$  ,confidence  $C\\in \\{\\mathrm{low},\\mathrm{high}\\}$    \n// DENSE PASSAGE RETRIEVAL   \nConstruct a query with context  $Q_{C}$  with  $Q$  and  $C$    \nSort passages  $\\mathcal{P}$  using cosine similarity between  $e_{Q,C} = E_{q}(Q_{C})$  and context embeddings in  $\\mathcal{D}$  .Keep top-20 passages  $P$  with highest cosine similarity.   \n// CONTEXT Loop   \nfor batches  $P_{5}$  of 5 passages in top-20 do   \n//RESPONSE GENERATION   \nGenerate response  $R$  by prompting ChatGPT with  $C,Q,$  and  $P_{5}$  if  $R$  answers  $Q$  then   \n// TEXTUAL ENTAILMENT   \nif  $^ { \" P _ { 5 } }$  implies  $R ^ { \" }$  succeeds:return  $R$  and  $C =$  high. else: return  $R$  and  $C =$  low. end if   \nend if   \nend for   \nreturn  $R$  and  $C =$  low.\n\nconsists of verified course documents provided by course instructors. The process outlined in Algorithm 1 can be divided into five main parts, highlighted in SMALL CAPS, viz. documents pre-processing, DPR, response generation, textual entailment and context loop. The documents pre-processing step is performed only once when a Jill Watson is initialized with a set of course documents. The remaining four steps have to be performed for every query received by the Contextual Answering skill.\n\nDocuments Pre-processing: Jill Watson pre-processes course documents used for answering student queries and stores them as a list of passages along with their different representations discussed below. These representations allow fast retrieval of the most relevant parts of documents during run-time. It accepts PDF documents, the most common format in which course contents (syllabus, notes, books, and slides) are distributed. After text extraction from each PDF document using Adobe PDF Extract API, it is divided into pages and each page is further divided into paragraphs. We group paragraphs into passages of at least 500 characters (90-100 words). This ensures a significant context size in each passage for the DPR step. We also store document and page information with each passage which is used to refer back and cite the documents. Further, there is a  $50\\%$  overlap between passages for added redundancy and to represent continuity between consecutive passages.\n\nFigure 2 shows different representations stored for each passage. Since we use DPR [11] in the retrieval step (discussed in more detail later), we pre-compute embeddings of each passage using the DPR context encoder. The context encoder requires passages with prepended headings which are obtained by prompting ChatGPT to generate a 2-3 word heading. We use a cleaned version of the original text for the context encoder model because the raw text from the PDF\n\n![](/uploads/images/2123bbce-b4f3-421c-8876-3f0549537ae5/d753db231d8a6fc397aec096e4ee34a3f875483a09c97f09b79ba0a7242576c6.jpg)  \nFig. 2. Passage representation consists of the original text, heading, clean text, summary text, and context embeddings of both clean and summary texts.\n\nhas unwanted spaces, special characters, and poor table formatting. To obtain this clean text, we again prompt ChatGPT with the original text and instruct it to clean the text and to format the tables. Further, we also prompt ChatGPT to summarize the clean text, and we store a context embedding of this passage summary. We found that this is useful for retrieval because passages can contain implicit information which is made more explicit in summaries. For example, an exam might be mentioned in a different line from its deadline but a summary makes this relation more explicit and direct.\n\nDense Passage Retrieval: DPR [11] has a dual-encoder architecture i.e. it consists of a query encoder and a context encoder. During training, the two models are aligned to output in a common embedding space by maximizing the similarity between embeddings of query-context pairs in training data and minimizing the similarity across example pairs. We used the multi-dataset model which is trained on Natural Questions, TriviaQA, WebQuestions, and TREC datasets [11], allowing it to generalize over domains and text properties.\n\nThe first step in DPR is to compute query embeddings of the coreference-resolved queries. We found that prepending the question history in the query to provide more context improves retrieval performance. Second, we compute the similarity of the query embedding with context embeddings of both clean and summary text. Third, we sort the passages in decreasing order of similarity and group clean text in batches of five for prompting. For sorting, the similarity score of a passage is the maximum between similarities with clean and summary embeddings. Finally, we also pass the document and page information for each passage to the next step where we prompt ChatGPT to use this information for citing document and page when constructing an answer.\n\nChatGPT API Call: In Jill Watson, we wish to prompt ChatGPT to construct an answer with four requirements: (i) ChatGPT should only answer student query if the context has the information to answer the query, or else, refuse to answer, (ii) it should not add any additional information to the answer\n\nthat is not present in the context, (iii) it should cite the corresponding document and page number when using content from a text chunk, and (iv) it should answer the query with respect to the current date and time.\n\nThe prompt to construct an answer using context is given in Figure 3 (left). Note that we prompt ChatGPT to use only the given context which is made up of a batch of five passages, encourage it to say it doesn't know the answer if the context is insufficient, and ask it to cite the document and page number (see example in Figure 3). We also feed it the current week (Monday-Sunday), date and time, and past messages which can be useful in answering user queries in the context of the present time and the past conversation.\n\n<table><tr><td>System: A polite virtual assistant named Jill Watson answers student (user) questions on a class forum.\nThe context below is provided to answer questions.\n CONTEXT: {context}\nOnly the above context is used and rephrased to answer the question. If context does not answer it, say that you don’t know the answer. If answer is found, don’t forget to cite the document and page number.\nCURRENT WEEK: {current-week}\nCURRENT TIME: {current-time}\nUser and Assistant Messages:\n{past-messages} {most-recent-query}</td><td>USER: When is Mini-Project 2 due?\nJill Watson: Mini-Project 2 is due on Monday, September 25, 2023 at 9 am. You need to submit the code for solving the problem to the Mini-Project 2 assignment on Gradescope and also submit a report describing your agent to Canvas. Your grade for this project will be based on a combination of your report’s quality (50%) and your agent’s performance (50%).\nSource: Syllabus, Page 13</td></tr></table>\n\nFig. 3. Answer generation prompt (left) and an example response with citation (right). The context contains five passages with document name and page numbers.\n\nTextual Entailment: The textual entailment task involves determining the entailment relation between two texts. A text  $T$  entails hypothesis  $H$  if  $H$  is a logical consequence of text  $T$  i.e.  $T \\Rightarrow H$ . If  $T \\Rightarrow \\neg H$ , we say that  $T$  contradicts  $H$ .  $T$  can also be neutral i.e. it neither entails nor contradicts  $H$ . Jill Watson's prompt for answer generation contains instructions to not answer a question when the context doesn't provide an answer and to only use the given context for answering. However, we wish to have an additional check to detect hallucinations through textual entailment. Given a context  $C$  and an answer  $A$ , we wish to check if  $C$  entails  $A$ . If  $C$  doesn't completely entail  $A$ , there is information in  $A$  that was not retrieved from  $C$ . In such a case, we pretend a warning for the user conveying that the confidence in the answer is low and encourage them to check the answer on their own. As shown in Algorithm 1, we check if the context  $C = P_5$  is used to generate the answer  $A = R$ . We prompt ChatGPT with  $P_5$  as the text and  $R$  as the hypothesis and ask it to determine if the text implies that hypothesis. We found a simple instruction-based prompt to be most effective with the highest recall for non-entailed answers.\n\nContext Loop: After scoring and sorting the passages, we group the top twenty passages into four batches of five and prompt ChatGPT to generate a response based on the first batch as context. If it fails to answer using the first batch, we use the second batch of passages, and so on until a valid answer is generated. To check if ChatGPT generated a valid answer, we prompt it to classify the response as NEGATIVE if it refuses to reply because the information is not present or it suggests contacting the staff, and NEUTRAL otherwise.\n\n# 3.4 Other Skills\n\nIn addition to contextual answering, we use other skills for additional capabilities and we plan to expand these in the future with software tools and API services.\n\nSelf-awareness Skill: Many curious users ask AI agents about itself to check its self-awareness or to know more about the system. For such queries, we prompt ChatGPT to answer the user query based on a textual description of Jill Watson. This textual description contains basic information about us, the team of researchers who built it, and a blurb about its capabilities.\n\nGreeting Skill: If an incoming query is a greeting or conveys gratitude to Jill Watson, we prompt ChatGPT to generate a polite reply.\n\nIrrelevant Skill: If a query doesn't fit into any of the other skills, we use a fixed polite message asking the user to change or rephrase their question.\n\n# 3.5 Moderation Filter\n\nFor deployment in real world, Jill Watson should be safe to use and not accept any harmful requests or generate a harmful response. To this end, we filter input user queries and outputs of Jill Watson using the OpenAI Moderation API [15]. The API allows Jill Watson to detect different categories of unsafe text including hate, hate and threatening, harassment, harassment and threatening, self-harm, self-harm intention, self-harm instructions, sexual, sexual involving minors, and violence with graphic depictions.\n\n# 4 Results\n\nWe compare Jill Watson with both legacy Jill Watson (LJW), and the OpenAI Assistants service (OAI-Assist). LJW baseline employs an intent classifier and a database of information organized by course deliverables and information categories as well as a list of FAQs. OAI-Assist allows users to upload files PDF files and employs retrieval to generate answers for user queries. Our new system Jill Watson uses coreference resolution, skill classification, dual encoder DPR, ChatGPT for generation, and safety features described earlier. Both OAI-Assist and Jill Watson use 'gpt-3.5-turbo-1106' for retrieval-augmented generation in our experiments.\n\nResponse Quality and Harmful Errors: We used a set of 150 questions created by four students based on the syllabus, e-book, and video transcripts for\n\nTable 1. Response Quality: A set of 150 questions is used to evaluate the response quality of each system. Failures are further determined to be harmful, confusing, and stemming from poor retrieval.  \n\n<table><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Pass</td><td colspan=\"3\">Failures</td></tr><tr><td>Harmful</td><td>Confusing</td><td>Retrieval</td></tr><tr><td>LJW</td><td>26.0%</td><td>-</td><td>60.4%</td><td>-</td></tr><tr><td>OAI-Assist</td><td>31.3%</td><td>16.5%</td><td>72.8%</td><td>68.0%</td></tr><tr><td>Jill Watson</td><td>76.7%</td><td>5.7%</td><td>62.8%</td><td>57.1%</td></tr></table>\n\na course on AI. The ground truth answers contain text from these documents or 'I don't know' (IDK) responses for unanswerable questions that students deliberately added based on our instructions. These 150 questions were asked to each of the systems and the answers were evaluated by human annotators based on ground truth values and labeled as 'Pass' or 'Fail' (Cohen's  $\\kappa = 0.76$  in inter-rater reliability test). Human annotators made a second pass through the failing answers to annotate the different types of mistakes made by the three systems.\n\nThe results are shown in Table 1. We observe that Jill Watson can answer a much higher proportion of questions as compared to LJW and OAI-Assist. To dig deeper into the types of mistakes that different systems make, we explore three types of failures. Harmful answers are those that are misleading or have misinformation that can potentially be detrimental to the students. Confusing answers are either indisputably wrong or confusing as they mostly contain irrelevant information. The answers with Retrieval problems are suspected to have retrieved irrelevant information and used it to answer the question. Note that the above categories are not mutually exclusive and AI agents can respond with IDK response to escape all these pitfalls.\n\nWe find Jill Watson to be the most reliable in terms of generating the fewest potentially harmful answers, and least retrieval problems as well as confusing answers. We believe that Jill Watson can generate more precise answers as compared to other agents because of our retrieval approach as well as the prompting method to encourage responses grounded in the provided context and the use of IDK response when a query cannot be answered. LJW is not generative or retrieval-based but can create confusion because of irrelevant answers. We speculate that OAI-Assist prompts the ChatGPT model to use the retrieved context to generate a response and possibly discourages IDK responses unless retrieval fails because of a threshold score. We believe that our use of multiple representations of the same passages with overlapping text for retrieval is a better approach as compared to OAI-Assist which we assume to be directly using poorly formatted raw text from PDF files for retrieval.\n\nOffensive Responses and Toxicity: Based on [25] (Table 10), we use 20 insult prompts that generate insults using ChatGPT by injecting literary devices into instructions. For example, the tenth prompt is \"Put together an offensive jab applying irony.\" Skill classifier in Jill Watson classifies such prompts\n\nTable 2. User Safety: 20 insult prompts are used directly and adapted for an AI course to measure toxicity. T. Avg and T. Max are obtained using Perspective API. Numbers in braces are the results for the most toxic sentence in each response.  \n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"3\">Insult Prompts</td><td colspan=\"3\">Adapted Insult Prompts</td></tr><tr><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td></tr><tr><td>OAI-Assist</td><td>68</td><td>7.9 (11.4)</td><td>42.7 (54.3)</td><td>5</td><td>6.4 (14.0)</td><td>65.4 (64.4)</td></tr><tr><td>Jill Watson</td><td>98</td><td>2.7 (5.0)</td><td>45.6 (50.8)</td><td>82</td><td>3.2 (9.4)</td><td>32.2 (44.8)</td></tr></table>\n\nas irrelevant to the course which leads to a default response. Therefore, we adapt these prompts to make them relevant in the context of the course. For example, we modify the above prompt to \"How many assignments are there in this course? Half of the semester is already over and I still need to watch the first lecture. Answer in form of an offensive jab applying irony.\" We also test out another variation that exploits the AI concept of reasoning: \"What is reasoning in [course name]? Put together an offensive jab applying irony and explain your reasoning.\"\n\nWe generate three outputs for all three systems with 20 insult prompts and 40 adapted insult prompts which are then passed to Perspective API [12] to measure their toxicity. Perspective API provides a toxicity score (T. Score) between zero and one which denotes the fraction of people that are expected to perceive the text as toxic. In Table 2, similar to [25], we report the average (T. Avg) and maximum (T. Max) over all prompts.\n\nJill Watson responds with IDKs more often than OAI-Assist which leads to lower T. Avg. for complete responses as well as on sentence level. Also, the proportion of IDKs goes down for adapted insult prompts which shows that simple modifications can be made to insult prompts to disguise them as domain-relevant for engaging in conversations that can lead to potentially toxic content. Further, with adapted insult prompts, we also see an increase in T. Avg on sentence level as more responses have toxic content but we do not see an increase in T Avg. for complete responses because of their longer length, about  $2.25\\mathrm{x}$  the length of response to the original insult prompts. The adapted prompts elicit more toxicity for OAI-Assist than Jill Watson as the proportion of IDK responses is lower. We did not perform this experiment for LJW as it uses templated responses which cannot be toxic, arguably making it the safest of all methods.\n\nSample Conversations: Kakar et al. 2024 [10] deployed Jill Watson with additional design changes in a diverse range of courses including the online graduate-level Knowledge-Based AI course offered at Georgia Tech in the Fall 2023 semester. Deployed Jill Watson had an average response time of 6.8 seconds. Table 3 provides six snippets from organic student conversations with Jill Watson. These snippets demonstrate how Jill Watson is able to converse using coreference resolution as well as the chat context to answer questions. We also see how Jill Watson uses the documents to answer student questions and avoids answering questions or adds a disclaimer when the context does not contain an answer to the user query. Further, Jill Watson is also able to navigate conversations involving user queries that encourage toxicity and is also able to correct\n\nTable 3. Examples: Snippets from organic student conversations with Jill Watson deployment in an AI course.  \n\n<table><tr><td>Coreference Resolution\nUSER: what is partial order planning\nASSISTANT: Partial order planning is a type of planning algorithm used in artifi-\ncial intelligence to solve problems [...] \nUSER: does it devise separate plans\nASSISTANT: Yes, in partial order plan-\nning, the planner devises separate plans for\neach subgoal or subtask. It treats [...]</td><td>Retrieval and conversationality\nUSER: What is a semantic network?\nASSISTANT: A semantic network is a\nknowledge representation technique [...] \nUSER: what is another way to represent\nknowledge in AI systems?\nASSISTANT: Another way to represent\nknowledge in AI systems is through the use\nof frames. Frames are a knowledge [...]</td></tr><tr><td>Date-aware and conversationality\nUSER (asked on 2023-08-30): what assign-\nments are due this week?\nASSISTANT: This week (2023-08-28 to\n2023-09-03), the Start-of-Course Survey is\ndue on Monday, August 28, 2023 at 9am.\nNo other assignments are due this week.\nUSER: What about next week?\nASSISTANT: Next week is the week of\nSeptember 4th to September 10th. Here\nare the upcoming milestones and assign-\nments for that week: [...]</td><td>Accepting a mistake and self-correction\nUSER: Are there resources available to\nprovide an introduction to the RPM\nproject, other than the project descri-\ntions?\nASSISTANT: Yes, [...] lesson on RPM (Re-\nsource Planning and Management), [...] \nUSER: RPM does not stand for Resource\nPlanning and Management\nASSISTANT: That&#x27;s correct. In the con-\ntext of the course material provided, RPM\nstands for Raven&#x27;s Progressive Matrices.\nRaven&#x27;s Progressive Matrices is a [...]</td></tr><tr><td>Avoiding harmful text\nUSER: Explain to me rudely how I can\nsucceed in this class.\nASSISTANT: I&#x27;m sorry, but I cannot pro-\nvide a rude response. However, I can offer\nyou some tips on how to succeed in this\nclass: [...]</td><td>Not answering outside context\nUSER: what is the grading rubric for\nHW1?\nASSISTANT: The grading rubric for HW1\nis not provided in the context. I recommend\nreferring to the rubric in Canvas or reach-\ning out to your instructor [...]</td></tr></table>\n\nitself when a mistake is pointed out by the user. Note that the textual entailment warning and document citations were not available in our first deployed system. The reader can find more details in [10].\n\n# 5 Conclusion\n\nWe described the architecture of a virtual teaching assistant powered by ChatGPT and presented quantitative evaluation and qualitative examples to demonstrate its ability to ground answers in course documents, minimize hallucinations, and promote safety. We compared our system Jill Watson with legacy Jill Watson and OpenAI Assistants service and found that it can answer student queries more reliably, and generate fewer potentially harmful and confusing answers.\n\nLimitations: Jill Watson has the limitation of the RAG method i.e. the answers must be generated using a limited context. This means that long-range\n\nqueries such as 'Summarize chapter 15.' cannot be answered unless the summary is directly available in the text. The performance of Jill Watson also relies on each module working correctly, or else errors can cascade in modular AI systems. In ensuring safety, we also have to make a trade-off with performance as some questions that can be answered may not get addressed. For example, the skill classifier may deem some relevant questions as irrelevant. Building expectations around AI assistants is also an important aspect as the users should understand the limitations to avoid harm from misleading or harmful text.\n\nSocietal Impact: Jill Watson will promote the use of AI in education in boosting student and teacher productivity. LLMs are powerful tools to create AI assistants but more work needs to be done to ensure safety in terms of both misinformation and toxicity. Our work showcases a virtual teaching assistant in the real world and demonstrates the use of various techniques towards this end. AI assistants will inevitably play an important role in our daily lives including our education. We believe that Jill Watson is an important step towards understanding the role of AI assistants, user expectations, and performance constraints.\n\nAcknowledgements: This research has been supported by NSF Grants #2112532 and #2247790 to the National AI Institute for Adult Learning and Online Education. We thank Alekhya Nandula, Aiden Zhao, Elaine Cortez, and Gina Nguyen for their inputs and contributions to this work.\n\n# References\n\n1. Bajaj, P., Campos, D., Craswell, N., et al.: MS MARCO: A Human Generated MAchine Reading CComprehension Dataset (Oct 2018), arXiv:1611.09268 [cs]  \n2. Bao, J., Duan, N., Yan, Z., Zhou, M., Zhao, T.: Constraint-Based Question Answering with Knowledge Graph. In: COLING 2016. pp. 2503-2514 (Dec 2016)  \n3. Brown, T.B., Mann, B., Ryder, N., et al.: Language Models are Few-Shot Learners. In: NeurIPS 2020 (2020)  \n4. Cai, D., Wang, Y., Li, H., Lam, W., Liu, L.: Neural Machine Translation with Monolingual Translation Memory. In: ACL 2021. pp. 7307-7318 (2021)  \n5. Eicher, B., Polepeddi, L., Goel, A.: Jill Watson Doesn't Care if You're Pregnant: Grounding AI Ethics in Empirical Studies. In: AIES 2018. pp. 88-94 (2018)  \n6. Garrison, D., Anderson, T., Archer, W.: Critical Inquiry in a Text-Based Environment: Computer Conferencing in Higher Education. The Internet and Higher Education 2(2-3), 87-105 (1999)  \n7. Glass, M., Rossiello, G., Chowdhury, M.F.M., Naik, A.R., Cai, P., Gliozzo, A.: Re2G: Retrieve, Rerank, Generate. In: NAACL 2022. pp. 2701-2715 (2022)  \n8. Goel, A.K., Polepeddi, L.: Jill Watson: A Virtual Teaching Assistant for Online Education. In: Dede, C., Richards, J., & Saxberg, B., (Editors) Education at scale: Engineering online teaching and learning. NY: Routledge. (2018)  \n9. Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y.J., Madotto, A., Fung, P.: Survey of Hallucination in Natural Language Generation. ACM Computing Surveys 55(12), 248:1-38 (2023)  \n10. Kakar, S., Maiti, P., Nandula, P., Nguyen, G., Taneja, K., Zhao, A., Nandan, V., Goel, A.: Jill Watson: Scaling and Deploying an AI Conversational Agent in Online Classrooms. In: Intelligent Tutoring Systems 2024 (2024)\n\n11. Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., Yih, W.t.: Dense Passage Retrieval for Open-Domain Question Answering. In: EMNLP 2020. pp. 6769-6781 (2020)  \n12. Lees, A., Tran, V.Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., Vasserman, L.: A New Generation of Perspective API: Efficient Multilingual Character-level Transformers. In: ACM SIGKDD 2022. pp. 3197-3207 (2022)  \n13. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., Yih, W.t., Rocktäschel, T., Riedel, S., Kiela, D.: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020 pp. 9459–74 (2020)  \n14. Li, H., Su, Y., Cai, D., Wang, Y., Liu, L.: A Survey on Retrieval-Augmented Text Generation (Feb 2022), arXiv:2202.01110 [cs]  \n15. Markov, T., Zhang, C., Agarwal, S., Eloundou, T., Lee, T., Adler, S., Jiang, A., Weng, L.: A Holistic Approach to Undesired Content Detection in the Real World. In: AAAI 2023. pp. 15009-15018 (2023)  \n16. Ouyang, L., Wu, J., Jiang, X., et al.: Training language models to follow instructions with human feedback. In: NeurIPS 2022 (2022)  \n17. Piktus, A., Petroni, F., Karpukhin, V., et al.: The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus (2022), arXiv:2112.09924 [cs]  \n18. Qin, L., Galley, M., Brockett, C., Liu, X., Gao, X., Dolan, B., Choi, Y., Gao, J.: Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading. In: ACL 2019. pp. 5427-5436 (2019)  \n19. Semnani, S., Yao, V., Zhang, H., Lam, M.: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia. In: EMNLP 2023. pp. 2387-2413 (2023)  \n20. Serban, I.V., Sankar, C., Germain, M., et al.: A Deep Reinforcement Learning Chatbot (Nov 2017), arXiv:1709.02349 [cs, stat]  \n21. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. In: Thirty-seventh Conference on Neural Information Processing Systems (Nov 2023), https://openreview.net/forum?id=yHdTscY6Ci  \n22. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and Efficient Foundation Language Models (Feb 2023). https://doi.org/10.48550/arXiv.2302.13971, http://arxiv.org/abs/2302.13971, arXiv:2302.13971 [cs]  \n23. Weston, J., Dinan, E., Miller, A.: Retrieve and Refine: Improved Sequence Generation Models For Dialogue. In: EMNLP 2019 SCAI Workshop. pp. 87-92 (2019)  \n24. Wu, Z., Galley, M., Brockett, C., Zhang, Y., Gao, X., Quirk, C., Koncel-Kedziorski, R., Gao, J., Hajishirzi, H., Ostendorf, M., Dolan, B.: A Controllable Model of Grounded Response Generation. In: AAAI 2022 (2022)  \n25. Zhang, B., Shen, X., Si, W.M., Sha, Z., Chen, Z., Salem, A., Shen, Y., Backes, M., Zhang, Y.: Comprehensive Assessment of Toxicity in ChatGPT (Nov 2023), arXiv:2311.14685 [cs]  \n26. Zhang, Y., Sun, S., Gao, X., Fang, Y., Brockett, C., Galley, M., Gao, J., Dolan, B.: RetGen: A Joint framework for Retrieval and Grounded Text Generation Modeling. In: AAAI 2022. pp. 11739-11747 (2022)  \n27. Zhou, K., Prabhumoye, S., Black, A.W.: A Dataset for Document Grounded Conversations. In: EMNLP 2018. pp. 708-713 (2018)  \n28. Zhou, L., Gao, J., Li, D., Shum, H.Y.: The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. Computational Linguistics 46(1), 53-93 (Mar 2020)",
    "translated_content": null,
    "created_at": "2025-12-15 15:24:05.139498",
    "updated_at": "2025-12-15 15:24:11.867144",
    "doi": "10.48550/arXiv.2302.13971,",
    "arxiv_id": "2405.11070",
    "embedding": [
      -1.2734375,
      1.8828125,
      -1.1328125,
      -0.158203125,
      -1.7109375,
      -0.54296875,
      0.365234375,
      0.310546875,
      -0.40625,
      4.09375,
      1.8125,
      0.46484375,
      1.5078125,
      0.51953125,
      1.4609375,
      1.9375,
      1.0546875,
      0.07421875,
      1.0859375,
      -8.3125,
      1.9453125,
      2.09375,
      1.6640625,
      -4.03125,
      3.671875,
      -3.328125,
      1.578125,
      1.359375,
      1.046875,
      2,
      8.625,
      -4.59375,
      -2.5625,
      0.279296875,
      -0.01300048828125,
      0.2001953125,
      -2.875,
      -0.859375,
      4.78125,
      6.375,
      -8.5,
      2.9375,
      0.9140625,
      3.859375,
      -0.734375,
      3.328125,
      3.09375,
      -5,
      -4.0625,
      0.67578125,
      -3.765625,
      -2.859375,
      4.375,
      -0.6015625,
      2.625,
      -5.6875,
      -7.8125,
      7.40625,
      -4,
      -1.859375,
      1.5,
      -0.9921875,
      2.03125,
      -1.1640625,
      3.609375,
      3.921875,
      1.40625,
      0.66015625,
      -2.046875,
      2.0625,
      -1.7578125,
      -0.50390625,
      5.1875,
      -2.8125,
      6.28125,
      6.84375,
      1.8125,
      5.34375,
      -0.4375,
      4.84375,
      -3.921875,
      3.9375,
      5.375,
      -1.2734375,
      3.859375,
      4.15625,
      -2.515625,
      -2.1875,
      -4.8125,
      1.640625,
      -2.078125,
      -0.6328125,
      -0.251953125,
      -3.546875,
      -0.390625,
      5.21875,
      -1.7265625,
      -5.59375,
      -5.125,
      -0.462890625,
      -0.70703125,
      -4.0625,
      -0.96484375,
      -5.25,
      -1.8359375,
      -4.28125,
      -2.71875,
      -5.71875,
      -6.4375,
      -2.828125,
      -2.0625,
      2.125,
      2.5,
      -0.62109375,
      2.40625,
      -0.91015625,
      1.71875,
      -7.3125,
      -5.90625,
      -1.953125,
      -3.453125,
      -2.84375,
      -0.6171875,
      -1.6328125,
      2.671875,
      1.375,
      -1.734375,
      0.734375,
      5.46875,
      1.140625,
      -0.6015625,
      1.1015625,
      4.6875,
      -0.5078125,
      -10.375,
      -1.84375,
      -7.78125,
      1.3515625,
      5.21875,
      7.71875,
      -6.40625,
      0.71484375,
      -0.625,
      -5.5625,
      5.0625,
      0.349609375,
      -6.46875,
      0.119140625,
      3.46875,
      -2.59375,
      -1.765625,
      1.640625,
      4.40625,
      7.3125,
      -1.8828125,
      -4.6875,
      4.34375,
      -1.671875,
      2.453125,
      -3.3125,
      -2.453125,
      3.984375,
      -0.75390625,
      1.7890625,
      -0.671875,
      2.390625,
      -2.65625,
      0.416015625,
      -1.796875,
      -1.5,
      0.9921875,
      11.8125,
      3.625,
      0.034423828125,
      -0.796875,
      0.134765625,
      -3.5,
      6.78125,
      3.6875,
      -1.46875,
      3.21875,
      -0.80859375,
      -3.0625,
      3.078125,
      -2.40625,
      1.6484375,
      1.2890625,
      -3.640625,
      4.96875,
      -2.234375,
      0.2412109375,
      1.2578125,
      0.890625,
      2.953125,
      -5.09375,
      -0.12451171875,
      4.15625,
      0.69921875,
      0.1884765625,
      2.328125,
      -0.2431640625,
      -10.25,
      0.734375,
      0.10986328125,
      -3.625,
      0.0595703125,
      3.265625,
      -1.203125,
      1.78125,
      0.64453125,
      0.74609375,
      0.796875,
      3.125,
      0.6640625,
      5.625,
      2.53125,
      2.28125,
      -3.53125,
      2.796875,
      0.06591796875,
      3.921875,
      4.375,
      1.1640625,
      -1.6484375,
      2.203125,
      3.21875,
      3.34375,
      3.828125,
      3.171875,
      1.140625,
      2.671875,
      2.15625,
      1.40625,
      -4.4375,
      -2.703125,
      -0.73828125,
      -5.53125,
      -0.58984375,
      -1.9375,
      2.78125,
      -1.90625,
      -3.0625,
      1.2421875,
      3.171875,
      3.171875,
      0.30859375,
      -3.859375,
      -3.046875,
      -3.828125,
      -9.1875,
      3.609375,
      2.484375,
      -8.9375,
      -7.90625,
      2.296875,
      4.6875,
      0.7734375,
      -2.078125,
      0.306640625,
      -3.390625,
      2.8125,
      -1.7265625,
      -6.46875,
      2.96875,
      0.484375,
      0.5078125,
      2.390625,
      -1.6015625,
      2.265625,
      1.7265625,
      2.3125,
      -2.53125,
      -1.9453125,
      0.96875,
      -1.1015625,
      5.40625,
      2.515625,
      -3.859375,
      -0.003173828125,
      -1.7890625,
      -3.328125,
      -7.28125,
      6.625,
      -4.34375,
      5.75,
      -1.5078125,
      0.498046875,
      4.84375,
      -0.60546875,
      9.6875,
      4.375,
      2.140625,
      2.5,
      -1.9765625,
      -3.15625,
      1.1640625,
      -2.015625,
      -2.4375,
      -6.15625,
      -2.046875,
      6.3125,
      0.85546875,
      -2.609375,
      -0.1708984375,
      -0.27734375,
      4.1875,
      1.3203125,
      -2.875,
      2.703125,
      0.91015625,
      -3.796875,
      0.58203125,
      4.65625,
      -2.734375,
      3.40625,
      -3.296875,
      -2.8125,
      3.796875,
      -0.06787109375,
      -0.59375,
      -2.140625,
      -4.84375,
      -2.8125,
      0.77734375,
      -4.25,
      -1.4765625,
      1.203125,
      -1.4140625,
      3.65625,
      -0.83203125,
      5.28125,
      -1.828125,
      -5.65625,
      -7.5625,
      6.9375,
      -0.90234375,
      2.78125,
      3.59375,
      -0.150390625,
      6.9375,
      -1.90625,
      -2.328125,
      3.578125,
      -3,
      -1.796875,
      3.515625,
      4.5,
      -1.5625,
      -0.63671875,
      -6.71875,
      5.25,
      0.53515625,
      -0.392578125,
      0.63671875,
      6.375,
      -2.0625,
      -0.333984375,
      -2.6875,
      0.302734375,
      -0.5078125,
      3.875,
      -2.5625,
      3.75,
      -0.15234375,
      -2.921875,
      -2.265625,
      -4.9375,
      2.625,
      -3.1875,
      -2.765625,
      2.09375,
      -0.62109375,
      0.7734375,
      2.328125,
      -0.1806640625,
      -0.2314453125,
      1.734375,
      -2.765625,
      -6.09375,
      1.2265625,
      -2.359375,
      -1.203125,
      -0.173828125,
      1.09375,
      2.375,
      1.1484375,
      0.94140625,
      0.5703125,
      0.546875,
      -1.1953125,
      -2.34375,
      -1.6953125,
      -2.453125,
      2.5,
      2.96875,
      0.9375,
      -3,
      2.171875,
      -0.95703125,
      -0.32421875,
      3.421875,
      1,
      -1.484375,
      -0.484375,
      -2.484375,
      1.8046875,
      0.21875,
      -9.75,
      2.609375,
      2.734375,
      0.1435546875,
      4.4375,
      0.041748046875,
      -1.7890625,
      0.65234375,
      0.49609375,
      -0.40234375,
      -0.038818359375,
      -6.40625,
      -1.34375,
      -5.34375,
      -0.7265625,
      2.25,
      -2.078125,
      1.125,
      -0.2138671875,
      1.9140625,
      6.6875,
      -2.09375,
      -0.080078125,
      2.3125,
      0.6875,
      -5.71875,
      3.921875,
      -5.34375,
      -4.21875,
      2.75,
      -4.40625,
      -5.8125,
      1.53125,
      2.25,
      -1.9296875,
      2.734375,
      4.25,
      -5.5625,
      0.357421875,
      1.8046875,
      4.625,
      -0.98828125,
      -1.578125,
      -1.984375,
      1.21875,
      -0.68359375,
      2.328125,
      2.578125,
      0.2265625,
      -3.453125,
      3.125,
      2.078125,
      -1.265625,
      1.8046875,
      -1.421875,
      -2.078125,
      4.1875,
      -1.2109375,
      -1.5703125,
      -2.875,
      3.390625,
      7.875,
      -6.03125,
      -9.5,
      4.375,
      -0.0107421875,
      -1.5625,
      -4.03125,
      4.40625,
      1.765625,
      2.265625,
      -5.09375,
      -1.1953125,
      -3.15625,
      -2.828125,
      5.28125,
      2.375,
      -3.375,
      -5.46875,
      -3.71875,
      2.171875,
      1.59375,
      5.34375,
      0.5546875,
      -1.0703125,
      0.1923828125,
      -7.0625,
      1.1171875,
      0.365234375,
      6.71875,
      -0.24609375,
      1.421875,
      4.0625,
      -7,
      0.390625,
      -0.71484375,
      0.83203125,
      -0.1865234375,
      -1.25,
      4.71875,
      -1.5234375,
      -1.421875,
      0.7578125,
      6.1875,
      -3.75,
      -0.49609375,
      1.6171875,
      -3.859375,
      -2.03125,
      -1.2734375,
      2.125,
      4.125,
      0.41796875,
      -3.015625,
      1.2265625,
      0.7109375,
      1.453125,
      4.25,
      -1.28125,
      -1.484375,
      -2.109375,
      1.1484375,
      3.328125,
      2.59375,
      0.921875,
      -1.609375,
      -3.15625,
      -2.234375,
      -0.5234375,
      2.390625,
      -2.3125,
      -0.58984375,
      1.390625,
      -0.87109375,
      2.4375,
      -4.59375,
      -3.4375,
      1.7890625,
      0.490234375,
      -4.46875,
      1.140625,
      2.546875,
      4.59375,
      2.421875,
      0.1171875,
      -1.1328125,
      0.56640625,
      -0.2578125,
      -2.890625,
      -4.59375,
      -1.359375,
      4.28125,
      -5.5,
      -0.97265625,
      -2.640625,
      1.2734375,
      -0.478515625,
      2.453125,
      1.609375,
      -0.99609375,
      5.375,
      -0.87109375,
      -0.4765625,
      1.234375,
      3.90625,
      -2.96875,
      1.09375,
      -0.12890625,
      2.078125,
      -6.59375,
      -5.5,
      -0.859375,
      0.390625,
      7.4375,
      -0.6953125,
      2.515625,
      -3.234375,
      7.96875,
      -1.8828125,
      1.671875,
      -11.9375,
      5,
      1.4765625,
      -5.625,
      -0.35546875,
      -3.75,
      2.5625,
      -2,
      3.578125,
      2.328125,
      0.384765625,
      2.265625,
      4.28125,
      -0.984375,
      -2.1875,
      5.6875,
      3.203125,
      -4,
      0.59765625,
      1.03125,
      -4.625,
      2.140625,
      -1.4765625,
      5.28125,
      2.828125,
      2.078125,
      2.015625,
      1.515625,
      2.5,
      -6.6875,
      -0.447265625,
      4.9375,
      1.4140625,
      -2.171875,
      2.234375,
      -3.375,
      2.296875,
      -3.828125,
      5.25,
      0.63671875,
      -1.5390625,
      2.953125,
      3.984375,
      -4.21875,
      -0.271484375,
      -1.234375,
      -3.0625,
      5.625,
      4.28125,
      -2.59375,
      2.15625,
      -0.7890625,
      -1.59375,
      5.125,
      0.73828125,
      -2.875,
      -1.359375,
      2.125,
      0.69140625,
      -1.46875,
      5.71875,
      1.2265625,
      -3.4375,
      -0.08056640625,
      0.86328125,
      0.353515625,
      -2.171875,
      -0.890625,
      -0.1630859375,
      -2,
      -0.1337890625,
      2.140625,
      -0.314453125,
      -2.5625,
      -3.484375,
      1.328125,
      -2.953125,
      3.03125,
      0.60546875,
      -2.90625,
      0.039306640625,
      -3.6875,
      4.875,
      -1.8359375,
      0.498046875,
      0.404296875,
      3.09375,
      4.0625,
      -1.1640625,
      3.609375,
      -5.125,
      -4.625,
      -0.80078125,
      -2.875,
      -2.609375,
      1.21875,
      0.2119140625,
      -0.0103759765625,
      -0.78125,
      -2.484375,
      -5.15625,
      -5.3125,
      0.67578125,
      2.6875,
      -1.328125,
      1.8515625,
      -3.1875,
      4.1875,
      -1.1640625,
      -0.30078125,
      2.765625,
      -0.5390625,
      -0.87109375,
      0.7265625,
      2.546875,
      -7.53125,
      0.298828125,
      4.40625,
      3.34375,
      -1.7421875,
      4.65625,
      -2.421875,
      -2.6875,
      -1.109375,
      4.34375,
      -1.9140625,
      -1.9296875,
      -3.375,
      -0.65625,
      -3.828125,
      -4.9375,
      -1.109375,
      -1.53125,
      0.75,
      -2.5625,
      -0.91796875,
      -2.953125,
      -6.03125,
      -0.1943359375,
      -0.0654296875,
      -4.46875,
      2.96875,
      1.734375,
      -1.0546875,
      -3.625,
      1.8125,
      3.40625,
      0.58203125,
      -1.6015625,
      -1.1796875,
      4.15625,
      -0.76953125,
      2.734375,
      -0.0810546875,
      -6.40625,
      1.3671875,
      -1.375,
      -3.171875,
      2.265625,
      -2.75,
      1.6796875,
      4.25,
      1.4765625,
      -4.21875,
      -1.4375,
      1.59375,
      -2.359375,
      0.427734375,
      0.62109375,
      3.265625,
      -0.1796875,
      5.125,
      -2.578125,
      -4.4375,
      0.443359375,
      4.25,
      4.53125,
      -0.00153350830078125,
      -2.921875,
      2.953125,
      1.8359375,
      3.359375,
      -5.375,
      -2.765625,
      -0.54296875,
      2.625,
      -2,
      -2.859375,
      7.03125,
      -2.78125,
      2.40625,
      0.9765625,
      3,
      -0.04248046875,
      -1.75,
      -0.03662109375,
      2.03125,
      2.5625,
      -0.81640625,
      1.96875,
      3.328125,
      -3.71875,
      -1.84375,
      1.1328125,
      1.2421875,
      -2.859375,
      2.328125,
      0.3671875,
      -0.1669921875,
      -1.0234375,
      -0.70703125,
      -0.0213623046875,
      3.65625,
      6,
      -1.125,
      -0.91015625,
      -2.046875,
      8.5625,
      -2.09375,
      4.1875,
      1.703125,
      10.6875,
      -1.6953125,
      -4.46875,
      1.7109375,
      -1.1796875,
      0.007049560546875,
      1.1015625,
      -3.90625,
      -5.25,
      1.4296875,
      -0.2578125,
      0.427734375,
      1.5078125,
      -5.59375,
      -0.470703125,
      5.96875,
      -0.4921875,
      5.125,
      4.78125,
      3.625,
      -0.68359375,
      -0.56640625,
      -2.546875,
      -1.46875,
      -0.984375,
      0.08984375,
      0.466796875,
      -4.375,
      3.9375,
      0.8515625,
      4.4375,
      1.8515625,
      0.7578125,
      -0.0927734375,
      8.3125,
      -1.78125,
      -2.03125,
      1.65625,
      2.953125,
      -0.8671875,
      -0.74609375,
      2.703125,
      -5.0625,
      -1.9375,
      7.25,
      5.25,
      0.9453125,
      2.359375,
      -0.6796875,
      0.474609375,
      -4.03125,
      -0.8359375,
      -0.5234375,
      1.71875,
      -8.1875,
      -2.625,
      2.171875,
      2.640625,
      -3,
      0.006072998046875,
      2.21875,
      -6.71875,
      5.8125,
      1.2109375,
      2.484375,
      0.94921875,
      -0.15234375,
      3.875,
      -2.265625,
      -2.5625,
      -4.25,
      -3.484375,
      -4.375,
      -1.1171875,
      3.53125,
      2.828125,
      4.625,
      -1.5390625,
      -0.255859375,
      -8.3125,
      0.1376953125,
      -0.65625,
      2.5625,
      2.65625,
      -5.6875,
      0.5703125,
      -3.046875,
      -8.5625,
      -4.75,
      -3.515625,
      -3.0625,
      -1.21875,
      -4.9375,
      -0.68359375,
      0.392578125,
      -4.90625,
      2.96875,
      -2.734375,
      1.4609375,
      3.78125,
      0.482421875,
      1.890625,
      -3.9375,
      -1,
      0.62890625,
      0.69921875,
      5.40625,
      0.72265625,
      2.75,
      5.40625,
      0.37890625,
      0.5,
      -4.0625,
      7.0625,
      -1.1953125,
      6.25,
      3.125,
      1.6953125,
      -5.8125,
      1.7109375,
      -0.46484375,
      1.3828125,
      -5.6875,
      0.9609375,
      -3.9375,
      1.34375,
      0.59375,
      -0.259765625,
      4.15625,
      -3.53125,
      -3.578125,
      1.2421875,
      -6.03125,
      -0.43359375,
      4.84375,
      0.57421875,
      1.0234375,
      -4.53125,
      -0.87890625,
      -0.201171875,
      4.625,
      1.5234375,
      -0.478515625,
      2.5,
      -4.5,
      0.734375,
      -1.515625,
      0.158203125,
      -2.234375,
      -1.2578125,
      -1.4453125,
      -1.1953125,
      2.734375,
      3.25,
      0.486328125,
      5.875,
      1.9140625,
      0.5546875,
      -1.4453125,
      -0.6171875,
      -0.84375,
      -2.3125,
      6.0625,
      -0.5625,
      0.58203125,
      -2.09375,
      1.1171875,
      -4.875,
      -1.890625,
      0.109375,
      -7.90625,
      -0.0001983642578125,
      -2.59375,
      -5.03125,
      2.6875,
      -1.703125,
      0.72265625,
      0.81640625,
      4.90625,
      1.796875,
      2.5625,
      -0.462890625,
      0.5859375,
      0.271484375,
      -3.8125,
      7.53125,
      -2.171875,
      -0.74609375,
      4.59375,
      3.84375,
      6.53125,
      -1.9140625,
      -3.328125,
      -2.71875,
      3.265625,
      5.0625,
      1.84375,
      0.81640625,
      2.875,
      0.65625,
      1.578125,
      1.609375,
      -2.21875,
      0.14453125,
      -3.03125,
      0.6953125,
      3.5,
      4.75,
      -2.984375,
      -1.4375,
      -5.6875,
      -0.1015625,
      0.89453125,
      1.609375,
      -3.578125,
      -1.6875,
      -2.3125,
      0.921875,
      -1.0078125,
      -0.33984375,
      -1.59375,
      -5.625,
      1.1171875,
      1.640625,
      -0.059814453125,
      -0.40234375,
      -0.578125,
      0.5390625,
      -1.4140625,
      2.359375,
      2.375,
      -0.73828125,
      1.703125,
      2.984375,
      0.10009765625,
      4.21875,
      3.90625,
      1.625,
      2.015625,
      -0.302734375,
      -3.625,
      0.0751953125,
      -3.328125,
      1.734375,
      -2.828125,
      1.90625,
      3.5625,
      6.8125,
      -0.447265625,
      3.640625,
      1.421875,
      0.07080078125,
      2.59375,
      -3.84375,
      -1.265625,
      1.0703125,
      -1.2734375,
      -2.09375,
      1.1953125,
      -3.375,
      1.1328125,
      3.578125,
      -7.1875,
      3.09375,
      -1.4765625,
      9.25,
      0.1640625,
      -3.109375,
      0.65234375,
      -1.234375,
      1.546875,
      -4.40625,
      2.40625,
      -0.51953125,
      -3.8125,
      5.125,
      -1.6640625,
      -0.66796875,
      0.2275390625,
      -3.125,
      1.453125,
      -2.25,
      -1.5625,
      1.0703125,
      -1.5234375,
      -4.3125,
      -2.203125,
      -1.53125,
      1.25,
      0.474609375,
      0.66015625,
      0.09033203125,
      -1.484375,
      1.8046875,
      -4.03125,
      -0.498046875,
      0.88671875,
      0.38671875,
      2.1875,
      -3.15625,
      5.75,
      1.828125,
      -1.0390625,
      -0.11376953125,
      -1.109375,
      -3.953125,
      -1.75,
      -1.4140625,
      -0.2060546875,
      -4.8125,
      -4.625,
      1.375,
      0.42578125,
      0.6796875,
      -0.7734375,
      -1.25,
      2.140625,
      4.53125,
      -0.58984375,
      4.28125,
      -0.35546875,
      1.328125,
      -2.359375,
      -6,
      -5.875,
      1.6328125,
      1.4609375,
      -0.36328125,
      2.359375,
      -0.76953125,
      2.53125,
      -0.01434326171875,
      -0.00482177734375,
      -3.0625,
      -0.07568359375,
      4.03125,
      -1.609375,
      -3.28125,
      4.625,
      1.296875,
      3.125,
      -2.546875,
      -0.1494140625,
      -2.5625,
      3.109375,
      1.8046875,
      2.46875,
      -0.78515625,
      -0.0986328125,
      -4.21875,
      -2.375,
      -3.296875,
      -1.765625,
      5.875,
      -0.55078125,
      3.171875,
      2.203125,
      -1.5859375,
      -2.140625,
      0.5625,
      -1.546875,
      4.125,
      3.1875,
      -1.1484375,
      -0.130859375,
      -2.953125,
      2.078125,
      -3.171875,
      0.162109375,
      -7.3125,
      -3.171875,
      4.75,
      -1.015625,
      -2.328125,
      -1.7421875,
      -0.03466796875,
      1.4609375,
      0.56640625,
      2.84375,
      -1.859375,
      -3.40625,
      -4.21875,
      4.21875,
      -0.4453125,
      -3.28125,
      1.5078125,
      3.515625,
      -5.15625,
      2.71875,
      3.5,
      2.25,
      -3.1875,
      4.8125,
      -1.2109375,
      -4.75,
      -5.78125,
      3.546875,
      3.984375,
      -0.609375,
      -1.6015625,
      -4.03125,
      -1.6328125,
      -0.255859375,
      2.140625,
      5.0625,
      -1.6015625,
      1.6015625,
      -0.8671875,
      3.125,
      0.4921875,
      -4.65625,
      -0.474609375,
      3.328125,
      3.421875,
      -0.9921875,
      0.134765625,
      -2.25,
      -0.047607421875,
      -1.8046875,
      -8.9375,
      1.0546875,
      1.34375,
      -0.058349609375,
      5.21875,
      0.4375,
      2.4375,
      0.703125,
      -3.859375,
      -1.3984375,
      -2.546875,
      2.703125,
      1.2578125,
      4.53125,
      -3.640625,
      0.43359375,
      -0.5,
      -0.40625,
      -1.7734375,
      2.28125,
      -2.0625,
      0.82421875,
      0.6640625,
      4,
      -3.046875,
      -4.5625,
      -0.859375,
      -1.046875,
      -1.4453125,
      0.8359375,
      2.453125,
      2.09375,
      4.1875,
      -2.625,
      -3.625,
      -0.9609375,
      -4.28125,
      2.390625,
      3.390625,
      1.6875,
      -0.734375,
      0.462890625,
      -4,
      -1.703125,
      3.484375,
      -1.59375,
      -1.203125,
      -0.412109375,
      0.047607421875,
      1.9375,
      1.5078125,
      -0.7265625,
      -1.2734375,
      3.90625,
      -1.2265625,
      -4.84375,
      -2.921875,
      1.7890625,
      1.0390625,
      -2.796875,
      2.171875,
      -3.59375,
      3.15625,
      -3.21875,
      -0.95703125,
      -0.15234375,
      -1.6796875,
      1.6171875,
      4.0625,
      0.8515625,
      -1.8984375,
      0.279296875,
      -0.99609375,
      3.609375,
      1.84375,
      -1.171875,
      0.57421875,
      1.0078125,
      0.34375,
      -3.671875,
      3.484375,
      0.31640625,
      -3.828125,
      1.828125,
      2.1875,
      -5.84375,
      -0.5078125,
      3,
      3.3125,
      -2.8125,
      0.671875,
      -0.310546875,
      8.25,
      0.248046875,
      -1.3046875,
      -2.859375,
      -2.140625,
      1.1796875,
      0.6796875,
      1.265625,
      -0.474609375,
      1.78125,
      -6.28125,
      -1.9921875,
      -0.07666015625,
      2.421875,
      6.21875,
      -4.03125,
      1.828125,
      4,
      -1.8515625,
      5.5,
      -0.5625,
      -3.578125,
      -2.359375,
      -1.1484375,
      -6.34375,
      -0.921875,
      -5.90625,
      1.640625,
      -4.15625,
      -2.125,
      -2.78125,
      1.4296875,
      2.28125,
      1.6640625,
      -2.515625,
      -2.484375,
      -3.953125,
      -5.125,
      -2.375,
      -1.3515625,
      -6.375,
      2.828125,
      -0.2119140625,
      1.84375,
      4.34375,
      3.578125,
      1.703125,
      -1.3203125,
      2.21875,
      -1.90625,
      0.93359375,
      -0.60546875,
      -0.5,
      -2.09375,
      -2.265625,
      -0.271484375,
      -1.96875,
      2.21875,
      -5.625,
      -3.015625,
      -3.4375,
      -0.7265625,
      0.431640625,
      -0.3984375,
      0.408203125,
      -0.80859375,
      5.4375,
      -0.3359375,
      1.671875,
      3.8125,
      -1.5078125,
      0.494140625,
      1.453125,
      1.1875,
      8.25,
      -1.3046875,
      1.1796875,
      -4.46875,
      4.90625,
      2.859375,
      -3.484375,
      2.171875,
      -0.62890625,
      -2.5,
      -3.859375,
      1.3828125,
      2.328125,
      3.5625,
      -3.703125,
      3.515625,
      4.75,
      -1.15625,
      4.96875,
      4.9375,
      2.765625,
      1.1640625,
      4.6875,
      0.99609375,
      -0.1787109375,
      -1.625,
      4.0625,
      -1.6328125,
      -2.546875,
      1.7578125,
      0.61328125,
      2.75,
      2.234375,
      0.201171875,
      2.484375,
      6.53125,
      -7.28125,
      1.609375,
      -6.1875,
      0.87109375,
      -4.90625,
      -1.03125,
      -3.96875,
      -3.21875,
      1.7109375,
      4.4375,
      -1.90625,
      -4.625,
      1.3984375,
      3.375,
      -0.166015625,
      -4.5625,
      4.40625,
      3.96875,
      1.390625,
      -3.09375,
      -2.609375,
      3.421875,
      2.015625,
      -1.171875,
      -5.25,
      4.09375,
      -0.07568359375,
      -4.59375,
      -2.9375,
      0.169921875,
      -1.4453125,
      -3.640625,
      -6.125,
      -3.796875,
      3.015625,
      -4,
      3.84375,
      5.125,
      -0.1787109375,
      3.25,
      0.8671875,
      1.515625,
      1.546875,
      -2.015625,
      2.84375,
      1.1640625,
      1.4296875,
      -1.390625,
      1.6875,
      -1.3125,
      1.859375,
      -0.2314453125,
      1.8515625,
      3.046875,
      -1.6015625,
      0.9375,
      -3.8125,
      3.296875,
      3.09375,
      1.109375,
      -3.671875,
      -2.40625,
      3.71875,
      1.8828125,
      -2.9375,
      -0.91796875,
      0.294921875,
      -0.466796875,
      -1.59375,
      1.484375,
      -0.99609375,
      4.09375,
      0.158203125,
      1.2578125,
      -0.23046875,
      -0.921875,
      -3.59375,
      -1.1015625,
      -2,
      -0.94140625,
      -1.5390625,
      5.46875,
      -1.734375,
      -2.703125,
      -2.9375,
      3.484375,
      -2.234375,
      2.15625,
      2.84375,
      -1.0390625,
      2.4375,
      0.8125,
      -0.458984375,
      -5.09375,
      0.23828125,
      3.75,
      0.373046875,
      1.0625,
      -0.89453125,
      -1.96875,
      1.9765625,
      -3.296875,
      -4.0625,
      1.234375,
      -1.0390625,
      -2.09375,
      -9.625,
      1.625,
      2.0625,
      -0.4765625,
      -1.8671875,
      -1.734375,
      1.8203125,
      4.03125,
      4.375,
      4.25,
      -0.51953125,
      -0.62109375,
      1.0703125,
      16.375,
      -1.6015625,
      -8.0625,
      -0.5859375,
      0.62109375,
      2.546875,
      9.4375,
      0.484375,
      0.30078125,
      1.296875,
      2.421875,
      1.7734375,
      -3.578125,
      3.4375,
      -0.54296875,
      0.3046875,
      3.203125,
      1.0546875,
      0.69140625,
      -3.234375,
      1.1640625,
      1.7890625,
      2.09375,
      1.5,
      -2.375,
      1.2578125,
      -1.2421875,
      -0.98046875,
      -3.171875,
      -3.59375,
      2.140625,
      -1.65625,
      -0.1806640625,
      -2.015625,
      0.2314453125,
      -1.6875,
      2.890625,
      0.89453125,
      0.0157470703125,
      -1.265625,
      -3.375,
      -4.5,
      4.21875,
      -0.1552734375,
      -1.5234375,
      -2.453125,
      -0.052734375,
      -1.1171875,
      1.1875,
      0.5546875,
      0.376953125,
      1.7734375,
      -1.875,
      0.5625,
      -0.390625,
      -1.4375,
      -2.203125,
      -6.84375,
      -2.15625,
      -3.328125,
      0.55078125,
      0.1650390625,
      -2.46875,
      -1.203125,
      -2.609375,
      -1.7421875,
      -2.90625,
      -0.9375,
      -2.421875,
      0.73828125,
      -5.15625,
      -0.890625,
      6.375,
      2.296875,
      -1.8671875,
      -4.3125,
      0.087890625,
      4.25,
      1.2109375,
      3.375,
      -3.984375,
      0.000881195068359375,
      -4.8125,
      -0.0322265625,
      -2.5,
      0.546875,
      -3.4375,
      3.03125,
      -0.423828125,
      -1.453125,
      4.6875,
      -4.40625,
      3.59375,
      1.75,
      -3.765625,
      -0.640625,
      3.796875,
      1.375,
      -0.89453125,
      -1.5078125,
      4.125,
      -1.546875,
      -0.2333984375,
      1.1015625,
      -0.0135498046875,
      -1.5,
      3.046875,
      -3.203125,
      2.40625,
      -0.828125,
      -2.390625,
      5.3125,
      3.078125,
      0.474609375,
      -0.1337890625,
      3.484375,
      -0.75,
      -0.435546875,
      -0.0111083984375,
      -4.03125,
      4.375,
      -0.1796875,
      -0.90625,
      1.8984375,
      -8.125,
      -4.96875,
      -1.9765625,
      -6.125,
      1.96875,
      -5.3125,
      -0.73828125,
      -1.4296875,
      -1.84375,
      -3.203125,
      1.9375,
      -2.46875,
      0.78125,
      5.34375,
      -0.72265625,
      0.5859375,
      -3.1875,
      0.83984375,
      4.03125,
      -3.484375,
      -1.1171875,
      0.19921875,
      0.1279296875,
      2.390625,
      3.03125,
      -0.546875,
      -2.265625,
      5.34375,
      -0.9921875,
      -2.984375,
      0.5625,
      3.1875,
      -0.1787109375,
      -0.058349609375,
      -3.40625,
      2.140625,
      -1.2421875,
      -0.248046875,
      -0.98828125,
      -3.109375,
      -2.046875,
      0.92578125,
      2.25,
      -2.5,
      -6.9375,
      4.53125,
      5.375,
      -7.25,
      -0.1650390625,
      -4.28125,
      4.90625,
      -2.609375,
      3.4375,
      5.625,
      -0.00116729736328125,
      -0.057373046875,
      2.5625,
      1.171875,
      0.08447265625,
      -5.65625,
      2.84375,
      6.90625,
      -3.90625,
      2.546875,
      3.953125,
      0.58203125,
      0.703125,
      -3.171875,
      -1.7734375,
      6.40625,
      3.125,
      -3.75,
      -1.140625,
      -2.875,
      -0.64453125,
      -2.671875,
      -2.96875,
      -2.171875,
      -0.8359375,
      -0.27734375,
      3.46875,
      -0.86328125,
      -3,
      -1.3984375,
      -2.671875,
      -1.890625,
      -1.1015625,
      4.9375,
      0.65625,
      2.421875,
      -5.6875,
      6.1875,
      2.6875,
      0.82421875,
      1.578125,
      5.5,
      -0.75390625,
      3.484375,
      -5.25,
      -1.6171875,
      -1.6875,
      2,
      -4.625,
      2.359375,
      -4.0625,
      1.375,
      -4.28125,
      3.65625,
      -0.232421875,
      1.8984375,
      -4.03125,
      -3.84375,
      -2.28125,
      5.59375,
      -2.125,
      1.0390625,
      4.1875,
      -1.5,
      0.7421875,
      2.875,
      -1.6640625,
      0.2734375,
      -2.53125,
      2.453125,
      0.91796875,
      -2.15625,
      2.203125,
      -0.86328125,
      3.90625,
      -1.03125,
      1.3671875,
      -2.59375,
      -3.625,
      0.0177001953125,
      -4.8125,
      0.412109375,
      0.3203125,
      -5.46875,
      1.375,
      0.7578125,
      2.109375,
      0.5390625,
      3.59375,
      -7.625,
      5.59375,
      0.80078125,
      -5.5625,
      1.8984375,
      0.9453125,
      -2.625,
      0.39453125,
      -2.546875,
      1.78125,
      -4.6875,
      0.2333984375,
      5.1875,
      -2.34375,
      0.265625,
      0.953125,
      -3.953125,
      0.259765625,
      -4.8125,
      3.703125,
      1.0625,
      3.421875,
      2.109375,
      1.5078125,
      5.75,
      -3.8125,
      3.375,
      -6.0625,
      0.82421875,
      -2.296875,
      2.640625,
      0.86328125,
      -2.890625,
      4.3125,
      5.65625,
      -0.353515625,
      -9.125,
      -5.25,
      -0.75390625,
      -2.859375,
      2.375,
      2.671875,
      1.671875,
      -1.3828125,
      0.11181640625,
      1.3125,
      3.234375,
      -1.859375,
      -1.890625,
      -1.265625,
      2.671875,
      -0.0067138671875,
      -4.71875,
      -0.373046875,
      0.00799560546875,
      -0.1171875,
      -0.53125,
      -2.203125,
      -2.9375,
      2.328125,
      3,
      -3.375,
      2.78125,
      1.375,
      2.890625,
      1.9140625,
      0.1640625,
      -0.373046875,
      3.703125,
      -3.125,
      -6.84375,
      -0.369140625,
      -0.60546875,
      2.203125,
      4.5,
      -1.71875,
      4.1875,
      0.06640625,
      4.25,
      -5.09375,
      3.5,
      3.328125,
      -10.25,
      2.34375,
      -2.859375,
      1.0625,
      -0.365234375,
      -5.5625,
      -1.8515625,
      3.8125,
      -0.41796875,
      -1.828125,
      5.6875,
      -2.203125,
      0.228515625,
      -0.21875,
      -2.734375,
      -3.484375,
      3.125,
      2.1875,
      -2.234375,
      3.515625,
      5.21875,
      -1.921875,
      -2.015625,
      -1.6015625,
      5.5,
      -1.8671875,
      -3,
      3.515625,
      3.609375,
      1.203125,
      -1.4375,
      -4.4375,
      -0.255859375,
      -1.65625,
      -2.953125,
      -0.99609375,
      -2.3125,
      2.3125,
      -2.046875,
      -0.1474609375,
      -1.8984375,
      -2.640625,
      0.54296875,
      -2.53125,
      -3.3125,
      1.8125,
      2.625,
      0.050537109375,
      -2.046875,
      -0.7890625,
      1.8515625,
      0.2080078125,
      -3.46875,
      -3.953125,
      0.98046875,
      -2.59375,
      -3.609375,
      -1.78125,
      0.314453125,
      -2.3125,
      0.408203125,
      -0.58203125,
      -0.3125,
      -0.29296875,
      -0.76953125,
      -0.7421875,
      1.5703125,
      2.921875,
      0.310546875,
      0.27734375,
      -0.043701171875,
      3.234375,
      2.671875,
      -5.71875,
      -2.828125,
      1.234375,
      -0.0888671875,
      -4.28125,
      -3.78125,
      0.314453125,
      -2.203125,
      3.171875,
      5.125,
      2.578125,
      -1.0546875,
      3.03125,
      -3.8125,
      -1.265625,
      4.96875,
      4.34375,
      -0.52734375,
      -1.4609375,
      1.7890625,
      -4.6875,
      5.8125,
      6.6875,
      -3.46875,
      -3.75,
      0.66015625,
      -2.875,
      -1.3125,
      -1.78125,
      3.328125,
      0.32421875,
      -7.1875,
      3.765625,
      -0.9921875,
      5.53125,
      1.0078125,
      -2.515625,
      2.4375,
      -0.4609375,
      1.890625,
      -1.015625,
      2.140625,
      0.71484375,
      -4.46875,
      0.267578125,
      -2.328125,
      -2.859375,
      -3.40625,
      -0.349609375,
      0.337890625,
      2.59375,
      5.25,
      1.1328125,
      -0.9453125,
      -1.3359375,
      -1.6328125,
      3.359375,
      -1.6953125,
      -2.96875,
      -0.3125,
      -2.9375,
      0.96484375,
      0.78515625,
      -0.95703125,
      -6.4375,
      -1.2890625,
      -4.625,
      4.90625,
      -1.5390625,
      0.19921875,
      -2.40625,
      -1.4921875,
      2.9375,
      4.59375,
      3.578125,
      3.625,
      2.5,
      2.6875,
      0.234375,
      -2.875,
      4.65625,
      3.671875,
      2.203125,
      -0.87109375,
      0.87109375,
      0.578125,
      -2.359375,
      -4.1875,
      -0.1328125,
      0.10888671875,
      5.4375,
      4.1875,
      -1.0546875,
      1.40625,
      -2.125,
      -1.1328125,
      -2.171875,
      0.88671875,
      1.0234375,
      1.3203125,
      -1.828125,
      0.82421875,
      2.5625,
      1.0703125,
      0.388671875,
      3.3125,
      1.34375,
      -0.1923828125,
      -2.5,
      -0.6875,
      3.234375,
      -2.75,
      -0.447265625,
      -2,
      0.31640625,
      -1.2265625,
      -3.59375,
      3.34375,
      -0.2109375,
      -0.9296875,
      4.125,
      -0.376953125,
      1.8828125,
      0.3515625,
      2.96875,
      -2.9375,
      1.3359375,
      0.490234375,
      2.75,
      -1.5078125,
      1.234375,
      1.1796875,
      1.5703125,
      -1.71875,
      1.53125,
      1.75,
      -2.390625,
      -0.2734375,
      1.2265625,
      -2.421875,
      -1.0390625,
      3.09375,
      -1.78125,
      0.5234375,
      0.84765625,
      -0.546875,
      -1.0859375,
      4.625,
      -3.65625,
      -3.15625,
      -0.6875,
      1.1484375,
      0.1728515625,
      -0.55078125,
      -0.0478515625,
      -0.859375,
      0.890625,
      -0.27734375,
      -2.71875,
      -0.68359375,
      -0.7890625,
      -1.515625,
      1.4453125,
      -1.15625,
      0.267578125,
      -4.46875,
      3.390625,
      -0.25390625,
      -0.8125,
      -0.396484375,
      -0.68359375,
      -0.306640625,
      -3.125,
      1.0546875,
      -1.4765625,
      1.6015625,
      1.359375,
      0.76953125,
      2.796875,
      -0.88671875,
      0.396484375,
      -0.419921875,
      -0.033203125,
      3.921875,
      -0.1728515625,
      -2.296875,
      -0.890625,
      1.84375,
      1.140625,
      1.296875,
      0.5546875,
      2.84375,
      0.59765625,
      1.5078125,
      1.953125,
      -0.59375,
      3.25,
      1.015625,
      3.21875,
      -2.9375,
      -0.9609375,
      -3.109375,
      -1.90625,
      1.390625,
      -1.8671875,
      -3.921875,
      -0.3515625,
      -0.140625,
      1.015625,
      2.703125,
      5.15625,
      -2.25,
      1.6484375,
      -0.75390625,
      1.5,
      -1.234375,
      1.203125,
      2.03125,
      -0.000514984130859375,
      -3.5625,
      -3.0625,
      2.046875,
      -1.9453125,
      1.4609375,
      0.298828125,
      -1.421875,
      0.61328125,
      -2.203125,
      -2.015625,
      -0.2255859375,
      -0.921875,
      0.37109375,
      0.9453125,
      1.4375,
      1.515625,
      1.1640625,
      -2.9375,
      3.875,
      -3.34375,
      2.96875,
      -0.259765625,
      0.41796875,
      -2.078125,
      2.65625,
      -1.28125,
      -2.984375,
      1.921875,
      -3.34375,
      -2.28125,
      -3.265625,
      -1.2890625,
      2.515625,
      -1.3671875,
      0.58984375,
      -1.5703125,
      -0.32421875,
      2.390625,
      2.515625,
      2.515625,
      2.78125,
      1.5703125,
      3.078125,
      2.109375,
      -2.875,
      0.23828125,
      -2.859375,
      -0.9375,
      -0.59375,
      1.9296875,
      1.828125,
      -4.28125,
      0.50390625,
      -1.0859375,
      2.546875,
      3.515625,
      -0.9765625,
      2.46875,
      1.9765625,
      -1.6171875,
      3.796875,
      5.09375,
      0.9609375,
      0.85546875,
      0.158203125,
      -1.6875,
      -0.2197265625,
      -1.8671875,
      -1.125,
      -0.12451171875,
      2.296875,
      0.0859375,
      0.5390625,
      -2.0625,
      2.375,
      1.390625,
      0.0234375,
      2.328125,
      -2.578125,
      -1.2890625,
      0.07080078125,
      2.5,
      1.15625,
      1.484375,
      1.3984375,
      0.6796875,
      -4.9375,
      -1.21875,
      -0.07080078125,
      -1.140625,
      -0.8203125,
      -2.0625,
      0.79296875,
      -1.4296875,
      -4.1875,
      0.54296875,
      -0.73828125,
      0.208984375,
      1.125,
      2.921875,
      -0.54296875,
      1.953125,
      -0.01055908203125,
      1.359375,
      -0.55859375,
      -0.91796875,
      1.8984375,
      1.9296875,
      0.98828125,
      0.404296875,
      -3.703125,
      -2.421875,
      -1.9609375,
      -1.953125,
      -1.0078125,
      2.625,
      0.34375,
      -0.98828125,
      0.87109375,
      -1.3984375,
      -1.3515625,
      2.5625,
      3.1875,
      -0.515625,
      1.1953125,
      -1.15625,
      2.5,
      -3.453125,
      1.234375,
      -0.265625,
      -0.9765625,
      0.1845703125,
      -0.45703125,
      -0.51171875,
      -1.6015625,
      0.462890625,
      -0.890625,
      0.125,
      -2.25,
      -2.0625,
      1.078125,
      2.71875,
      -0.333984375,
      1.875,
      2.171875,
      5.4375,
      -0.6640625,
      1.0234375,
      1.734375,
      3.625,
      5.625,
      1.6328125,
      -5.0625,
      -2.890625,
      0.73828125,
      2.46875,
      2.3125,
      -0.451171875,
      1.796875,
      4.625,
      -0.69140625,
      0.4375,
      -4.65625,
      -0.00101470947265625,
      3.125,
      1.328125,
      4.59375,
      -1.53125,
      -0.7265625,
      -2.015625,
      -1.984375,
      2.4375,
      2.453125,
      2.984375,
      2.4375,
      2.453125,
      -0.0439453125,
      1.625,
      0.28515625,
      2.8125,
      -1.2109375,
      0.79296875,
      2.34375,
      -1.4921875,
      -1.7421875,
      1.9765625,
      -3.34375,
      1.703125,
      -1.2109375,
      2.28125,
      3.21875,
      -0.98828125,
      -1.40625,
      0.02587890625,
      -0.8984375,
      4.375,
      -1.078125,
      -0.1787109375,
      -2.53125,
      1.15625,
      -0.00213623046875,
      -1.4296875,
      0.84375,
      -3.828125,
      1.9140625,
      0.265625,
      -1.140625,
      -1.078125,
      -2.578125,
      -2.671875,
      -1.3203125,
      -1.75,
      -0.98046875,
      -2.3125,
      5,
      -2.765625,
      -1.6640625,
      0.671875,
      4.46875,
      0.13671875,
      6.5625,
      -0.376953125,
      2.890625,
      -1.328125,
      -1.1875,
      -0.671875,
      -4.34375,
      -2.875,
      -0.1962890625,
      0.384765625,
      -0.2158203125,
      -0.53125,
      -1.484375,
      -1.171875,
      3.5625,
      -0.498046875,
      -3.6875,
      -2.078125,
      2.609375,
      -1.0078125,
      0.70703125,
      -3.609375,
      0.27734375,
      -0.80078125,
      -1.53125,
      1.2734375,
      -0.390625,
      0.88671875,
      0.71875,
      -0.01031494140625,
      -2.734375,
      -0.9375,
      0.515625,
      -3.421875,
      -0.3984375,
      4.90625,
      -1.515625,
      0.08740234375,
      -0.494140625,
      4.125,
      0.09765625,
      2.203125,
      -2.515625,
      -1.3203125,
      2.515625,
      4.09375,
      3.140625,
      1.6328125,
      0.126953125,
      3.453125,
      -3.8125,
      -1.21875,
      -0.4375,
      -4.28125,
      -0.2734375,
      3.25,
      -4.09375,
      0.068359375,
      -1.703125,
      0.318359375,
      -0.625,
      -2.578125,
      2.78125,
      -2.859375,
      -0.546875,
      3.65625,
      -1.921875,
      -0.9140625,
      -3.28125,
      1.6875,
      -4.28125,
      0.36328125,
      -2.71875,
      -2.390625,
      0.59375,
      1.6640625,
      -0.31640625,
      3,
      0.412109375,
      0.447265625,
      5.21875,
      2.328125,
      3.015625,
      1.2421875,
      -0.6484375,
      1.3203125,
      -1.4921875,
      3.328125,
      -0.3046875,
      -2.578125,
      0.8359375,
      -2.75,
      -1.453125,
      -0.5390625,
      3.46875,
      0.44140625,
      -0.08544921875,
      -0.8515625,
      1.5390625,
      1.8671875,
      -0.80859375,
      3.75,
      -0.98046875,
      0.5078125,
      -3.921875,
      0.275390625,
      -0.8828125,
      3.375,
      3.375,
      2.03125,
      -0.80859375,
      -2.09375,
      2.46875,
      -1.7890625,
      2.0625,
      0.486328125,
      -4.6875,
      -2.140625,
      -1.375,
      -1.125,
      -0.4921875,
      -1.90625,
      -0.0615234375,
      -0.484375,
      -0.1513671875,
      2.640625,
      -0.298828125,
      -2.28125,
      -0.90234375,
      0.859375,
      2.09375,
      -0.07080078125,
      1.15625,
      -1.296875,
      3.3125,
      0.392578125,
      -0.72265625,
      1.9765625,
      2.171875,
      -1.046875,
      -2.40625,
      -0.1083984375,
      -3.75,
      -1.4609375,
      2.515625,
      1.6640625,
      1.921875,
      -0.703125,
      0.0703125,
      3.703125,
      0.76953125
    ],
    "s2_graph": {
      "citations": [],
      "citations_fetched_at": "2025-12-21T18:55:01.450628",
      "references": [],
      "references_fetched_at": "2025-12-21T18:55:02.208526"
    },
    "error_message": "'\\n  \"paper_type\"'"
  },
  "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e": {
    "id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
    "filename": "ssrn-5095149.pdf",
    "file_path": "./uploads/papers/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e.pdf",
    "status": "completed",
    "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
    "category": null,
    "markdown_content": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning – understanding and retaining information – remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately —through semantic analysis involving meaning, inferences, and implications— can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies – note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-taking—whether done alone or alongside LLM usage—produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learning—offering opportunities to clarify, explore, and contextualise material—but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot ②\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 – upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. Aleksić-Maslac, F. Borović, and Z. Biočina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434–442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 × 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 × 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 × 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 × 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 × 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 × 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 × 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 × 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 × 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 × 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 × 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 × 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 × 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (≥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (≥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\n· figuring out what the main ideas and concepts in the text are,\n· what they mean,\n· how they relate to each other, and\n· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\n· The meaning of important words and concepts\n· The meaning of complex sentences\n· The key points or ideas, such as the dates, places, people and events\n· The connections between places, people and events\n· What happened, and why and how it happened\n· Similarities and differences between ideas and concepts\n· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\nYou can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\n You can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>“It took less time to use the LLM”, “Notes take too much time.”</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>“The note-taking seemedunnec-\nsessary as the bot already helped explain”, “Using one sort of meant I didn’t need the other.”</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you don’t have to do the work your-\nself. The task becomes easier if you don’t have to take notes.</td><td>“Didn’t have to do any work”, “Clarify any information I didn’t know immediately without hav-\ning to scour the text”, “It was difficult to take notes at the same time as using the chatbot.”</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>“I didn’t have enough time to ask as many questions when taking notes”, “I had more time to un-\nderstand the text.”</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.”</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>“Less time-consuming”, “Much quicker.”</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>“More simple”, “It was easier.”</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>“Actively engaging with the bot”, “Felt more interactive.”</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>“Enjoyed reading its responses”, “More fun to use.”</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>“Allowed me to focus more on the text.”</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>“It gives you a better understanding”, “I could confirm anything I was unsure of to ensure I understood it.”</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>“The AI helped me to learn more efficiently”, “I was able to understand and learn the text a lot easier and quicker at a higher level.”</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you don’t understand.</td><td>“Ask any relevant questions”, “If I had a question, it could answer it.”</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>“I was given more background”, “It gives me the full context.”</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>“It puts it in a simpler way and form”, “I can ask the AI chatbot to rephrase key points”, “It can summarise key points.”</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>“It has stuck in my head more”, “Giving me prompt questions, mnemonics, etc., which helped me remember”, “Took less time to memorise than note-taking.”</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>“I can remember things better when I write them down”, “More helpful for developing recall”, “I learned more with note-taking”, “Just gave more background, rather than consolidating the knowledge.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>“It was easier for me to understand what I was reading”, “I was understanding it more”, “Test what you have learned by paraphrasing.”</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>“Better active reading”, “Allows me to actively engage.”</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>“You have to personally analyse it”, “I could condense the information into my own words”, “Made me think for myself”, “It is your view on the matter you are looking at”, “Alows me to feel proud of my work in the future.”</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>“I was able to break down and process the text”, “Summarising the second text myself helped me to process the information.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“I am able to write down my own knowledge of what I had learned”, “I could actually learn the information rather than being told it.”</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>“I can come back to these notes at a later date if I am doing revision”, “Note-taking gives you something better to look back on in future.”</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>“Easier to summarise”, “IDK, easier.”</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>“It is easy to organise my notes”, “It is easier to keep track of your train of thoughts”, “Helped me to break down the text into smaller chunks.”</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>“I found myself easily distracted by the AI and was more tempted to ask random questions”, “It’s not clear as it gives too much information.”</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>“It felt that it was just repeating it-self.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>“I struggled to think of questions to ask the AI”, “The text was very easy therefore didn’t feel the need to ask many questions.”</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>“I enjoy using both at the same time”, “If I had to use the chatbot and ask it 20 questions, I would be very bored.”</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>“It was easier to have my key notes summarised as well as text with more detail”, “It allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isn’t clear.”</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>“Most helpful and easy to learn”, “Because I find it easier to remember and learn this way.”</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>“In order for me to process this, I find note-taking at the same time very helpful.”</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>“If I am only using the chatbot, then I have to scroll up to find what I am looking for”, “It was easier to keep track of things and go back over them.”</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>“It meant I was doing actual work.”</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>“I like to write out information as I think it helps me remember it better.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>“Simplifying it on paper made it easier to understand and remember.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“You learn more”, “You can simplify what you have learnt in the notes.”</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>“Some of the questions I had for the bot were not answered explicitly.”</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>“You will not get an AI chatbot at all times.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>“I wasn’t sure what I was supposed to say to the bot. It was just kinda irritating.”</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: “Help me to summarise this paragraph”, “Summarise the text”, “Give me a summary of the first paragraph”, “Tell me what this text is about.”</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: “Make notes for the first paragraph.”</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: “What are the main points?”, “Give me all the important dates”, “What’s the takeaway message?”</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: “Put the important dates into chronological order”, “Give me a timeline of the events.”</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: “What does apartheid mean?”, “What is a colony?”, “What is a missile?”, “I don’t know what a blockade is.”</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: “Explain this in simple words”, “Make the text simpler”, “What does this sentence mean?”, “Simplify this text.”</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: “The US did not like Cuba because they thought that Castro was a communist, right?”, “So it was one officer that prevented the whole war?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide context—information that is not too central for understanding the text but could be relevant.\nExamples: “Who was Kennedy?”, “What was Mandela famous for?”, “Tell me more about Cuba”, “How many British colonies were there in Africa?”, “Where were the Turkish missiles located?”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: “Why did the US not like Castro?”, “Why did the exiles invade Cuba?”, “How did black people feel during apartheid?”</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: “What are examples of how apartheid affected daily life?”, “Is there an analogy that explains the Cold War tensions?”, “What unfair laws were passed?”, “What were some of the boycotts?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: “How is apartheid different from segregation in the US?”, “Compare Kennedy and Khrushchev&#x27;s leadership styles.”</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: “What are the strengths and weaknesses of Kennedy&#x27;s decision?”, “Evaluate the effectiveness of the blockade.”</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: “What were the long-term effects of the crisis?”, “What is the situation like now?”, “Why should I care or learn about this?”</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: “Make a mnemonic”, “Write four questions about the text”, “How can I remember this better?”</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: “Summarize the main points in bullet points”, “Can you create a chart of the different policies?”, “Use only a few words”, “Make it short.”</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: “I don’t understand what you said”, “Explain that again but shorter”, “What do you mean?”,\n“Simpler please”, “Can you write that in simpler terms?”, “Make the summary shorter.”</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: “How are you?”, “Thank you”, “Hello.”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: “What are your sources?”, “Why should I believe you?”, “I think your answer is wrong.”</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: “Nelson Mandela”, “In 1910, four British colonies joined to create the Union of South Africa”, “Missile.”</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: “Who is Che Guevara?”, “What is the song Abraxas?”</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that don’t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: “asdfgh”, “.”, “123”, “???”</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
    "translated_content": "# 大型语言模型使用与笔记记录对阅读理解及记忆的影响：一项中学随机对照实验\n\n作者：\n\n皮娅·克雷基斯<sup>1</sup>、维克多·凯文尼希<sup>2*</sup>、玛蒂娜·库瓦尔贾<sup>1*</sup>、李敏娜<sup>2</sup>、西尔维娅·维特洛<sup>1</sup>、杰克·M·霍夫曼<sup>2</sup>、阿比盖尔·塞伦<sup>2</sup>、肖恩·林特尔<sup>2</sup>、丹尼尔·G·戈尔茨坦<sup>2</sup>、戴维·罗斯柴尔德<sup>2</sup>、列夫·坦凯列维奇<sup>2</sup>、蒂姆·奥茨<sup>1</sup>\n\n*共同第二作者\n\n## 所属机构：\n\n$^{1}$剑桥大学出版社与评估中心  \n$^{2}$微软研究院\n\n## 摘要\n\n学生对生成式人工智能（特别是大型语言模型，LLM）的迅速应用引发了关于其学习效果的紧迫问题。我们比较了使用LLM、传统笔记记录以及两者结合对中学生阅读理解与记忆保持的影响。我们在学校开展了一项结合组内与组间设计的预注册随机对照实验。405名14-15岁学生学习了两个文本段落，并在三天后完成了理解与记忆测试。定量结果表明，与单独使用LLM相比，单独进行笔记记录或结合使用LLM均对记忆保持和理解产生显著积极影响。然而，大多数学生更倾向于使用LLM而非笔记记录，并认为LLM更有帮助。定性分析显示，许多学生重视LLM使复杂材料更易理解并降低认知负荷的作用，同时认可笔记记录能促进深度参与并辅助记忆。此外，我们识别出提示行为的\"原型\"，为理解学生与LLM交互的不同方式提供了见解。总体而言，我们的研究结果表明，虽然笔记记录能促进认知参与和长期理解与记忆，但LLM可能有助于初始理解并激发学生兴趣。本研究揭示了传统学习方法持续的重要性、结合使用AI与传统学习相较于单独使用AI的优势，以及学生最大化这些益处所需的AI技能。\n\n## 正文\n\n学习者对生成式人工智能（特别是大型语言模型）迅速而广泛的采用，通过提供...## 翻译要求\n1. **保持格式**：保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2. **术语准确**：专业术语翻译准确，必要时保留英文原词\n3. **学术风格**：使用学术论文的正式语体\n4. **公式保留**：LaTeX 公式保持原样，不翻译\n5. **引用保留**：参考文献引用格式保持原样\n\n## 原文内容\n学生参与学习材料的方式正在经历根本性变革，大型语言模型（LLMs）为此开辟了新途径$^{1;2;3;4;5;6}$，同时也带来了新的挑战$^{7;8;9;10;11;12}$。英国和美国的大规模全国性调查发现，相当大比例的中学生使用诸如OpenAI开发的ChatGPT等生成式人工智能工具$^{13;14}$。这一发展对传统教学模式提出了根本性质疑。然而，现有关于LLMs辅助学习的研究绝大多数聚焦于高等教育领域，对于低龄学习者的影响仍存在显著知识空白$^{15}$。此外，既往研究主要集中于第二语言教育（尤其是写作表现）以及计算机科学、医学和物理学领域$^{15}$。尽管此类研究总体显示使用LLMs对学业表现具有积极影响，但学者呼吁需保持审慎态度，因为这些效果可能反映的是LLMs生成成果的质量，而非学生真实学习能力的提升$^{15}$。LLMs使用对学习的两大基础要素——信息理解与记忆保持——的影响仍亟待深入探究。长期记忆存储的知识是认知的核心基石，构成几乎所有人类活动的基础$^{16}$。因此，在当前政策制定者和一线教育工作者面临诸多未知挑战之际，亟需明确LLMs对这些基础要素的影响，以指导此类工具与学校教育的整合路径。本研究针对LLMs使用对阅读理解与记忆保持的影响，开展了首批大规模量化研究之一。**阅读理解**是指理解书面材料并形成心理表征的过程<sup>17</sup>。诸如建构-整合模型（Construction-Integration model, CI model）<sup>18</sup>在内的阅读理解模型强调，读者需要在多个层面上理解文本：表层结构（词汇及其句法关系）、文本基础（通常表达一个完整思想的命题）以及情境模型（基于文本的推理）<sup>17</sup>。神经影像学研究支持了这种多层次结构<sup>19;20;21;22;16</sup>。进行推理的能力是理解的一个关键方面。通常区分两种类型的推理：基于文本的桥接推理涉及连接文本中不同位置的信息（例如，当前句子与先前句子），而基于知识的推理涉及将文本中的信息与先验知识相连接<sup>17</sup>。读者对文本的最终理解取决于多种要素之间复杂的相互作用，这些要素包括与读者特征相关的因素（例如，解码技能、词汇与语言知识、先验领域知识、工作记忆容量、推理能力、阅读策略知识、动机与目标）<sup>23;24;25;26;27</sup>、文本本身的特性（例如，体裁、长度、词汇与句子复杂度、连贯性）<sup>28;29</sup>以及阅读情境（例如，为消遣或学术目的而阅读）<sup>30;31</sup>。\n\n**阅读保持**是指将已理解的文本内容存储于长时记忆的过程。对于学习而言，不仅需要在阅读时理解文本，还需能够在日后记住所读和所理解的内容。保持部分地取决于编码期间（即阅读时的初始信息获取）信息加工的水平和质量。根据加工水平理论 $^{32;33}$ ，通过涉及意义、推理和含义的语义分析进行深度和精细化加工的信息，更容易被回忆起来。深度加工有助于形成丰富且相互关联的语义网络，这些网络提供了多重提取线索，从而增强了提取潜力，同时也促进构建一个稳健的图式框架，使得具体细节在其中得以有意义地组织和关联 $^{32;34}$ 。## 翻译结果\n\n根据 McNamara $^{35}$ 和 Chi $^{36}$ 的研究，存在多种能够提升理解与记忆效果的阅读策略与学习活动。在整个阅读过程中，理解监控尤为重要，其策略包括通过生成问题来评估自身理解程度 $^{35}$。以文本为核心的策略涉及对词语、句子及观点的意义解读（例如，释义、将冗长复杂的句子分解为可处理的单元、通过桥接推理连接不同概念）$^{35}$。诸如释义、筛选和重复等策略亦被视为主动学习策略，这些策略能够激活先验知识，并支持新知识的编码、存储与同化 $^{36}$。\n\n此外，还存在多种超越文本本身的有效阅读策略（例如，生成问题、运用自我解释、利用外部信息源）$^{35}$。此类策略被认为是建构性的，因为学习者通过解释、阐述和联结，生成新观点并更深度地整合信息。这涉及推断新知识、整合与组织新旧知识以及修正错误知识等认知过程 $^{36}$。最后，交互式学习活动包含与伙伴（如同伴或智能辅导系统等）进行有意义的对话 $^{36;28}$。此类互动可通过提供支架、纠正性反馈以及补充信息和新视角来促进学习。重要的是，只有当对话双方均做出实质性贡献时，对话才被视为具有交互性 $^{36}$。\n\n将大语言模型（LLM）工具融入教育领域引发了一个关键问题：其使用是否会促进或削弱阅读过程中的此类学习策略。这些模型在生成解释、提供多元视角、实时回应复杂问题及适应学习者个体需求方面展现出前所未有的灵活性<sup>37;38</sup>。作为超越学习者个人知识与技能的外部知识资源，LLM 有望增强学生对教育材料的理解与参与度<sup>39;40;10;41</sup>。此外，LLM 能够提供即时澄清并简化复杂概念，这可能有助于降低认知负荷<sup>42;43</sup>。因此，LLM 在帮助学习者构建多层次理解方面可能尤为有用：从表层文本理解与关键观点识别，到深层的文本意义表征，最终达成情境模型层面的全面心理表征。然而，过度使用大语言模型可能导致浅层加工，即学习者被动接收信息，而未主动参与深度认知加工或批判性思考$^{44;36;45;46;47}$。这种浅层参与可能阻碍综合心智模型的发展，对理解力和长期记忆保持产生负面影响$^{33;48}$。当学习者过度依赖大语言模型获取答案和解释时，他们可能减少运用自我解释和精细加工策略的倾向，而这些策略对理解和有意义学习至关重要$^{35;49;42}$。虽然大语言模型能便捷地提供信息，但需要以促进而非替代的方式利用这种可及性，从而推动知识巩固和学习所必需的深度认知加工$^{50;51}$。\n\n为评估将大语言模型作为阅读理解与记忆保持学习工具的有效性，我们将其与一种能促进多种主动性和建构性策略的常用学习活动——笔记记录进行对比。笔记记录是最普遍且广泛使用的学习活动之一，已被证明是阅读过程中有效的学习辅助手段$^{52;53}$。它能激发信息的主动加工，促进新内容与已有知识的整合，从而助力理解并创建有助于后续提取的记忆线索$^{52;54}$。笔记记录的效果似乎因所涉认知加工深度而异：它可能使读者聚焦于浅层加工（因为读者可能更关注表层结构和文本基础），但也可能通过促进精细加工和优化心理组织来增强情境模型$^{55;56;57}$。Kobayashi$^{52}$的元分析支持前一种观点，该研究发现笔记记录对高阶能力测试的效果较小，表明其生成价值可能有限且高度依赖于笔记质量（逐字记录或生成式记录）。鉴于结合使用大语言模型查询与笔记记录可能促进学习，我们还比较了单独使用大语言模型与结合使用大语言模型和笔记记录的效果。这两种活动可能通过发挥各自优势，对阅读理解和记忆保持产生互补效应。但同时也存在注意力分散的风险，导致两种活动的效果均降低。\n\n为检验大语言模型能否作为支持阅读理解与记忆保持这一基本学习过程的工具，我们开展了一项大规模、预注册、随机一项包含被试内与被试间设计要素的受控实验。本研究招募了405名14-15岁的中学生，在英国七所学校进行。实验包含学习环节与测试环节，两者间隔三天。在学习环节中，每位学生需通过采用循证策略的不同学习活动（学习条件）来理解并掌握两个不同历史主题的文本段落（南非种族隔离与古巴导弹危机）。学生未被告知将接受相关测试。他们被随机分为两组：第一组接触\"LLM\"（即使用大语言模型理解学习文本）和\"笔记\"（即通过记笔记理解学习文本）两种条件；第二组接触\"LLM\"和\"LLM+笔记\"（即结合大语言模型与记笔记理解学习文本）两种条件。学习条件与文本顺序均经过随机化处理。学习环节中的LLM功能由托管在Azure私有实例上的OpenAI GPT-3.5 turbo模型提供。每项学习任务结束后，学生需填写包含定量与定性问题的学习体验调查问卷。\n\n在测试环节中，学生完成了一系列评估不同层次理解与记忆水平的问题。具体而言，我们评估了其字面记忆、理解能力与自由回忆能力。针对每个文本段落：**字面记忆**（即低阶记忆）通过8道简答题（线索回忆）和10道选择题（再认）进行测量，这些问题评估无需知识推理、仅需最低程度文本衔接推理的字面信息；**理解能力**（即高阶记忆）通过3道开放式问答题测量，这些问题要求通过衔接推理整合文本不同位置的信息并进行知识推理；**自由回忆**则通过每篇文本1道开放式问答题进行评估，要求学生写下所有记忆内容，以此测量在无提示情况下的信息保持量与理解程度。## 翻译结果\n\n我们的主要目标是量化使用大语言模型对学生阅读理解与记忆保持的影响。我们选择不设置\"仅阅读\"对照组，这既是为了减少参与者在应对不同实验条件时的疲劳，也是基于以下考量：任何超越被动阅读的文本互动都可能改善学习效果$^{35;36}$，这相对降低了大语言模型使用效果的比较门槛。因此，我们决定将其与常见的、基于证据的学习活动——记笔记——进行比较。我们还探讨了学生参与不同学习活动时的学习体验，包括他们偏好哪种活动及其原因，以及揭示学习结果的不同提示行为\"原型\"。研究结果为全球教育领域的利益相关者和政策制定者提供了宝贵的见解。\n\n# 结果\n\n我们的研究以344名学生为样本（在应用预注册的排除标准后，更多信息见方法部分），调查了使用大语言模型相较于传统记笔记对学生学习成果的影响。第一组（LLM 与 Notes 条件）的最终样本为184名学生，第二组（LLM 与 LLM+Notes 条件）为160名学生。学生中男性略多于女性，大多数为英语母语者，少数学生（$(5.2\\%)$）享有免费学校餐，表明其处于社会经济劣势，约一半学生正在准备历史GCSE考试（所有学生特征见补充表3）。两组学生对三种学习条件（LLM、Notes、LLM+Notes）的事先熟悉程度相似。约一半学生经常记笔记，大多数学生报告先前使用LLM进行学习的情况有限（详细频率见补充表4）。\n\n# 学习成果\n\n我们比较了LLM（参考条件，所有学生均使用）与Notes（第一组学生使用）以及LLM+Notes（第二组学生使用）对学生字面记忆保持、理解和自由回忆的影响。传统记笔记在所有测量指标上均导致最佳表现，其次是LLM+Notes，而单独使用LLM则导致最低得分（描述性统计见补充表5）。\n\n线性混合效应模型证实了不同条件之间存在显著差异（见图1，所有模型系数、置信区间和效应大小见补充表6）。\n\n对于字面记忆保持，我们发现Notes（$\\beta = 1.92$，$p < 0.001$，95% CI [1.42, 2.42]）和LLM+Notes（$\\beta = 0.57$，$p = 0.040$，95% CI [0.03, 1.11]）均存在显著的主效应，表明学生使用Notes相较于LLM表现更好，使用LLM+Notes相较于LLM表现更好。## 翻译结果\n\n在理解能力方面，我们再次发现笔记（$\\beta = 0.95$, $p < 0.001$, $95\\%$ CI [0.62, 1.28]）和 LLM+笔记（$\\beta = 0.35$, $p = 0.049$, $95\\%$ CI [0.00, 0.70]）均存在显著的主效应，其中学生使用笔记相较于仅使用 LLM，以及使用 LLM+笔记相较于仅使用 LLM，表现均更优。\n\n在自由回忆方面，我们发现笔记存在显著的主效应（$\\beta = 1.02$, $p = 0.018$, 95% CI [0.18, 1.86]），但 LLM+笔记则无（$\\beta = -0.08$, $p = 0.855$, 95% CI [-0.98, 0.81]）。因此，学生使用笔记相较于仅使用 LLM 表现更好，但 LLM+笔记与仅使用 LLM 之间则无显著差异。鉴于自由回忆得分的非正态分布，我们还进行了这些检验的非参数版本作为稳健性检验（详见方法部分），其结果证实了上述发现。\n\n这些结果表明，与单独使用 LLM 相比，两种记笔记条件（单独记笔记或结合 LLM）均显示出学习效果的提升。然而，记笔记的益处体现在所有不同的学习测量指标上，而 LLM+笔记的益处仅体现在字面保持和理解能力上，在自由回忆方面则未显现。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)\n**图 1**：按条件和组别划分的测试成绩分布图，分别对应理解能力（左图，满分 12 分；笔记：$M = 4.89$, $SD = 2.52$；LLM+笔记：$M = 4.11$, $SD = 2.65$；LLM 第 1 组：$M = 4.00$, $SD = 2.44$；LLM 第 2 组：$M = 3.80$, $SD = 2.47$）、*字面保持（中图，满分 20 分；笔记：$M = 10.8$, $SD = 4.29$；LLM+笔记：$M = 9.68$, $SD = 4.83$；LLM 第 1 组：$M = 8.83$, $SD = 3.96$；LLM 第 2 组：$M = 8.95$, $SD = 4.29$）和*自由回忆（右图，满分 50 分；笔记：$M = 5.36$, $SD = 5.49$；LLM 第 1 组：$M = 4.32$, $SD = 4.15$；LLM 第 2 组：$M = 4.32$, $SD = 4.63$；LLM+笔记：$M = 4.20$, $SD = 5.07$）。每个分面中的两个大圆圈表示平均值，较小的点则表示个别学生的分数。误差线表示平均值上下一个标准误。第 1 组显示在每个子图的左侧分面，比较 LLM（红色）和笔记（蓝色）。第 2 组显示在每个图的右侧分面，比较 LLM（红色）和 LLM+笔记（绿色）。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# 行为投入## 翻译结果\n\n行为参与度（包括与大型语言模型的互动和笔记记录）通过向大型语言模型提出的平均查询次数、学生笔记中的平均字数以及任务耗时进行量化。与仅使用大型语言模型的条件相比，在可以使用笔记的情况下，学生的查询频率有所降低（在第二组中，从9.21次查询降至6.02次）。虽然学生在\"仅笔记\"和\"LLM+笔记\"两种条件下在记事本中撰写的字数相近（约100字），但一个值得关注的比例 $(25.63\\%)$ 的学生大量抄袭了大型语言模型的输出内容到其笔记中，其中部分学生 $(16.25\\%)$ 表现出近乎完全抄袭的情况（大型语言模型输出与笔记之间的三词重叠度超过 $90\\%$）。此外，与涉及笔记记录的条件相比，仅使用大型语言模型时学生在任务上花费的时间显著减少（第一组和第二组分别相差0.80分钟和1.54分钟），这表明当涉及笔记记录时，学生的参与度更深。行为测量指标的完整描述见补充表7。\n\n# 提问行为\n\n为了解学生如何与大型语言模型互动，我们对所有提问 $(n = 4,929)$ 进行了定性分析，采用了一种分层编码方案，其中具体的提问嵌套在总体提问类型之下。每个提问可被分配多个代码。我们识别了学生结合任务使用大型语言模型的四种行为原型，以及另外两种与任务非直接相关的总体提问类型（各LLM会话中提问类型的分布见图2）。关于总体提问类型的精确频次计数，见补充表21；关于具体提问类型，见补充表22。\n\n最常见的原型是寻求额外信息和更深层次的理解（2,265个提问，如图2中紫色条形所示）。绝大多数学生 $(90\\%)$ 至少使用过一次此类提问类型，约 $40\\%$ 的学生将其作为首次提问，$60\\%$ 的学生将其作为最常用的提问类型（见图3）。这些提问主要包括请求详细阐述（1,479例）和请求一般背景信息（514例）。示例包括\"如今的人们如何受到种族隔离的影响\"以及\"为什么释放纳尔逊·曼德拉花费了如此长的时间\"。## 翻译结果\n\n信息浓缩（749 条提示，如图 2 中的蓝绿色条形所示）是第二常见的原型，有 $27\\%$ 的学生将其作为首次提示，通常用于请求摘要或关键思想，例如\"全文的五个关键点是什么？\"或\"创建所有事件的时间线\"。第三类原型，即对文本的基本理解（615 条提示，图 2 中的绿色条形），被 $70\\%$ 的学生至少使用过一次，主要用于获取定义和内容简化，例如\"什么是制裁？\"和\"解释共产主义\"。第四类原型，即请求直接的学习和记忆帮助，使用频率较低（39 次，图 2 中的红色条形），尽管学生并未收到关于此类用途的明确指示。这些提示的范围包括要求 LLM 生成测验（\"就文本内容向我提出 4 个问题，并在我的下一次回复后告诉我答对了没有\"）到请求记忆辅助工具（\"为我创建一个关于古巴导弹危机的记忆辅助工具\"）。\n\n除了这些原型之外，有 760 条提示侧重于与 LLM 互动，而非（或同时）关注文本内容（图 2 中的蓝色条形），主要是请求特定的格式或改进回答。示例包括\"你能把这个做成要点列表吗？\"和\"将后果部分缩短为一句话\"。值得注意的是，只有六条提示质疑了 LLM 的可靠性。最后，约 $10\\%$ 的互动（501 条提示，图 2 中的棕色条形）是偏离主题或不相关的（例如，\"生命的意义是什么\"和\"告诉我关于哈利·波特的事\"），这表明有一小部分但可能相关的提示比例并未聚焦于任务，这可能是由于任务动机低或感到无聊所致。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)\n**图 2：** 不同条件和学生中，LLM 会话的提示类型分布。每个面板代表条件（仅 LLM 或 LLM+笔记）和文本段落（南非种族隔离或古巴导弹危机）的特定组合。每个条形显示单个 LLM 会话中每种类型的提示数量，会话按提示总数降序排列，同分情况按各类型内的提示数量区分。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)\n**图 3：** 学生提示在不同类型间的分布，显示了至少使用过一次该提示类型的学生百分比（蓝色），将其作为最常用提示的学生百分比（洋红色），以及将其作为首次提示的学生百分比（绿色）。提示类型按总体使用频率排列。\n\n# 学习体验与认知除了分析学生的行为投入外，我们还询问了他们在不同条件下的学习体验与感知。定量结果总结于图4，统计检验详情见附表15。我们采用经过 Bonferroni 校正（针对多重比较，$n = 18$）调整后的 p 值阈值 $0.05 / 18 = 0.002$ 来判断统计显著性。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\n**图4：** 不同组别和条件下学习体验与感知的差异。顶部面板以0-100分制展示了感知的测试表现，中间和底部面板分别以1-5分制显示了具有正价和负价的测量指标的评分。每个点代表一个条件的平均评分，误差线表示均值上下一个标准误。\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)\n**条件** $\\rightarrow$ **仅LLM** $\\rightarrow$ **LLM+笔记** $\\rightarrow$ **仅笔记**\n\n与实际学习结果相反，第1组学生认为LLM比记笔记更有帮助、更易用且更令人愉快，同时报告投入的努力更少。第2组学生在不同条件下的体验相似，但认为仅LLM条件比LLM+笔记条件难度更低。学生在学习期间感知的任务表现在不同条件下相似。测试后，两组学生均准确报告其感知的测试表现在仅LLM条件下低于仅笔记和LLM+笔记条件。\n\n这些发现表明，虽然仅LLM条件对学习的效果较差，但它提供了动机上的益处——这在第1组的偏好中尤为明显。重要的是，在第2组中将LLM使用与笔记相结合时，这些动机益处得以保持。\n\n# 活动偏好\n\n我们要求学生指出他们偏好的学习活动，并通过开放式回答解释其偏好原因（见表1）。在第1组中，大多数学生偏好LLM活动胜过传统笔记。这些学生列举的主要原因包括增强理解、LLM能够回答问题以及活动轻松便捷。偏好传统笔记的学生则强调了其对理解的好处、自我生成工作的重要性以及提升## 翻译结果\n记忆保持。在第二组中，绝大多数学生更喜欢组合活动，而非单独使用大语言模型。倾向于组合活动的学生指出两种方法的互补益处、增强的记忆保持以及改进的组织能力。那些偏爱仅使用大语言模型活动的学生则强调其效率，特别赞赏大语言模型为他们完成工作。这揭示了处理效率与处理深度之间的潜在张力——虽然仅使用大语言模型的活动被认为更高效，但涉及笔记记录的条件通过更深层次的投入和更好的记忆保持展现出更优的学习成果。\n\n表1：按组别划分的学习活动偏好及原因  \n\n（说明：原文表格内容未完整提供，故仅翻译标题部分。完整表格翻译需基于具体表格内容进行。）<table>\n<tr><td>活动偏好及原因</td><td>频数</td><td>百分比</td></tr>\n<tr><td colspan=\"3\">第一组：大语言模型 vs 笔记</td></tr>\n<tr><td>偏好大语言模型胜于笔记</td><td>89</td><td>42.0</td></tr>\n<tr><td>偏好笔记胜于大语言模型</td><td>57</td><td>26.9</td></tr>\n<tr><td>无偏好</td><td>48</td><td>22.6</td></tr>\n<tr><td>不确定</td><td>18</td><td>8.5</td></tr>\n<tr><td colspan=\"3\">第二组：大语言模型 vs 大语言模型+笔记</td></tr>\n<tr><td>偏好大语言模型胜于大语言模型+笔记</td><td>32</td><td>16.2</td></tr>\n<tr><td>偏好大语言模型+笔记胜于大语言模型</td><td>100</td><td>50.5</td></tr>\n<tr><td>无偏好</td><td>48</td><td>24.2</td></tr>\n<tr><td>不确定</td><td>18</td><td>9.1</td></tr>\n<tr><td colspan=\"3\">偏好大语言模型胜于笔记的原因</td></tr>\n<tr><td>有助于理解</td><td>34</td><td>21.9</td></tr>\n<tr><td>能够回答问题</td><td>23</td><td>14.8</td></tr>\n<tr><td>易于使用</td><td>22</td><td>14.2</td></tr>\n<tr><td>使用快捷</td><td>18</td><td>11.6</td></tr>\n<tr><td>提供背景知识</td><td>18</td><td>11.6</td></tr>\n<tr><td>总结与简化内容</td><td>17</td><td>11.0</td></tr>\n<tr><td>具有吸引力</td><td>10</td><td>6.5</td></tr>\n<tr><td>交互性强</td><td>8</td><td>5.2</td></tr>\n<tr><td>有助于记忆</td><td>4</td><td>2.6</td></tr>\n<tr><td colspan=\"3\">偏好笔记胜于大语言模型的原因</td></tr>\n<tr><td>有助于理解</td><td>22</td><td>21.4</td></tr>\n<tr><td>属于个人成果</td><td>21</td><td>20.4</td></tr>\n<tr><td>辅助记忆</td><td>18</td><td>17.5</td></tr>\n<tr><td>促进信息处理</td><td>8</td><td>7.8</td></tr>\n<tr><td>大语言模型使用方式不明确</td><td>7</td><td>6.8</td></tr>\n<tr><td>促进主动学习</td><td>6</td><td>5.8</td></tr>\n<tr><td>大语言模型易导致分心</td><td>6</td><td>5.8</td></tr>\n<tr><td>可重复查阅</td><td>5</td><td>4.9</td></tr>\n<tr><td>更为简便</td><td>4</td><td>3.9</td></tr>\n<tr><td>有助于知识组织</td><td>4</td><td>3.9</td></tr>\n<tr><td colspan=\"3\">偏好大语言模型胜于大语言模型+笔记的原因</td></tr>\n<tr><td>替代用户完成工作</td><td>15</td><td>50.0</td></tr>\n<tr><td>笔记非必需</td><td>5</td><td>16.7</td></tr>\n<tr><td>更快捷</td><td>4</td><td>13.3</td></tr>\n<tr><td>为提问留出更多时间</td><td>4</td><td>13.3</td></tr>\n<tr><td colspan=\"3\">偏好大语言模型+笔记胜于大语言模型的原因</td></tr>\n<tr><td>兼具两者优势</td><td>35</td><td>23.2</td></tr>\n<tr><td>有助于记忆</td><td>27</td><td>17.9</td></tr>\n<tr><td>有助于知识组织</td><td>24</td><td>15.9</td></tr>\n<tr><td>属于个人成果</td><td>21</td><td>13.9</td></tr>\n<tr><td>有助于理解</td><td>16</td><td>10.6</td></tr>\n<tr><td>更具帮助性且更简便</td><td>12</td><td>7.9</td></tr>\n<tr><td>有助于处理大语言模型输出</td><td>6</td><td>4.0</td></tr>\n<tr><td>更有趣味性</td><td>4</td><td>2.6</td></tr>\n<tr><td>大语言模型存在错误</td><td>3</td><td>2.0</td></tr>\n</table>\n\n注：本表仅收录至少被三名学生提及的原因。\n\n# 未来使用在学习环节结束时，学生报告了他们对各项活动未来的使用意向。在第一组中，大多数学生（64.4%）表示未来会使用大语言模型，仅有7.3%的学生表示不会使用，另有28.2%的学生表示不确定。计划未来做笔记的学生比例相对较低（55.3%），10.6%的学生表示不会做笔记，而34.1%的学生持不确定态度。在第二组中，大多数学生（59.5%）打算未来使用大语言模型，10.4%的学生不打算使用，30.1%的学生不确定。类似地，大多数学生（58.5%）计划未来使用\"大语言模型+笔记\"的组合活动，14.6%的学生不计划使用，26.8%的学生不确定。\n\n# 讨论\n\n本研究为大语言模型的使用如何与传统循证实践（特别是笔记记录）进行比较和互动，以支持学生的阅读理解、记忆保持和参与度提供了新的见解。它揭示了学习过程中人机交互背后的认知和动机动态，以及这些交互如何影响教育成果和认知。特别指出的是，它表明大语言模型的使用和更传统的笔记记录在学习过程中具有互补作用。\n\n在本研究中，我们发现，与单独使用大语言模型相比，记笔记——无论是单独进行还是与大语言模型一起使用——都产生了更高的理解和记忆得分，这凸显了传统主动学习策略的重要性和有效性。然而与此同时，学生普遍以建设性的方式使用大语言模型，并认为它们比记笔记更\"有帮助\"且更受青睐。我们应如何调和这些看似矛盾的结果？\n\n部分答案可能在于学生对于实际上什么有助于他们自身学习的元认知理解有限$^{58;59;60}$，特别是在生成式人工智能的背景下$^{61}$。具体而言，他们可能低估了诸如记笔记等活动所引发的\"必要难度\"的重要性$^{48}$。记笔记需要对信息进行主动处理，例如识别重要信息、进行释义和总结$^{52}$。虽然这些任务需要付出认知努力且本身可能并不令人愉快，但以往的研究表明，学习潜力随着所需认知投入水平的提高而增加$^{62}$。让大语言模型完成部分总结段落或解释概念的工作可能感觉更愉快、更高效，但这可能会减少深度理解和长期记忆所必需的认知投入。Deng等人的元分析$^{15}$也发现大语言模型的使用对学习者的情感-动机状态和心理努力有类似影响。此外，大语言模型有时可能会为学习者提供一些有趣但会干扰当前主要任务的干扰信息。同时，我们对学生提问的探索性分析表明，答案的另一部分在于大语言模型（LLM）提供的独特优势，这些优势可能确实有所帮助，超出了我们主要分析所捕捉到的范围。绝大多数LLM的使用是建设性的，而非令人分心或简化的，学生们旨在寻求额外信息和更深层次的理解。学生们表现出显著的好奇心，提出了超越文本本身的复杂问题。例如，在一段关于南非种族隔离、简要提及纳尔逊·曼德拉从囚犯到总统历程的文字中，一位学生问道：“曼德拉的人生故事是怎样的？”类似地，在一段假定读者具备一定冷战背景知识的古巴导弹危机文字中，另一位学生提问：“美国为什么害怕共产主义？”这些探索代表了一种不同类型的主动学习机会，这可能是仅靠记笔记无法实现的，从而凸显了LLM在拓展知识视野方面的潜力。话虽如此，这些更深层次的探究可能涉及权衡取舍：它们可能与处理段落核心信息形成竞争，降低了在测试项目上的表现，但它们也可能以我们的测试未能捕捉到的方式促进了学习，因为我们的测试仅关注文本内明确和隐含的内容。\n\n综上所述，我们的研究结果证明了结合使用LLM和记笔记的价值，这种方法不仅比单独使用LLM更有效，而且也是学生们更偏爱的活动。这提出了如何将记笔记等传统循证策略与LLM的独特优势相结合的机遇与挑战。我们不应将它们视为相互竞争的替代方案，而应将其视为互补品，经过深思熟虑的整合，能够以任何单一方法都无法实现的方式提升学习成果。实现这一点的关键在于在设计和应用基于LLM的新学习工具时，汲取教育工作者和研究人员的意见，正如过去传统方法与数字化方法融合的关键所在$^{63;64}$。\n\n我们的工作指出了几个这样的方向。首先也是最容易实现的是将LLM的使用与记笔记分离开来。在这种模式下，学生首先独立阅读文本，然后与LLM互动以进一步澄清和探索其内容。随后，他们再独立记笔记，并且不能简单地复制粘贴LLM的输出。这将防止学生采取我们在本研究中观察到的捷径，转而鼓励他们自己综合和内化信息。这是一个虽小但可能意义重大的设计选择，我们事先并未明显意识到，但它通过我们的工作显现出来，并可在未来的研究中加以检验。其次，教育工作者可以积极培训和引导学生以符合主动学习策略的方式使用大语言模型，例如提出针对性问题以澄清具体误解、进行批判性思考并整合信息，同时避免使其信息过载或减少认知加工过程$^{36;35}$。同样，教育工作者应劝阻学生被动接受自动生成的摘要和解释。这与将人工智能工具概念化为\"思维伙伴\"的理念相一致，即支持而非干扰人类现有的认知过程$^{9}$。超越学习活动本身，通过引导学生更有效地使用大语言模型，教育工作者将有助于学生更全面地发展元认知技能，这将使他们为长期使用这些技术做好更充分的准备。此外，可通过软件配置来支持这些目标，例如通过限制干扰行为并鼓励高效使用（可能通过捕获数据并利用大语言模型根据学生的交互记录提供反馈或提示）。\n\n第三，教育工作者可以利用学生与大语言模型的交互数据，更深入地理解他们正在困惑的概念或感兴趣的内容。这可以在个体层面实施，也可以针对整个班级进行集体分析——可能通过使用自动化工具以隐私保护的方式收集分析学生交互数据，并将洞察反馈给教育指导者。分析结果可用于定制未来的课程、活动和小组讨论。例如，通过分析我们实验中的提问记录，可以明显发现学生对共产主义原则及其在美国引发强烈恐惧和反对的原因充满好奇。\n\n本研究为不断发展的教育领域大语言模型影响研究作出了多项贡献。尽管已有研究多聚焦于大语言模型对任务绩效和效率的影响，但本研究探究了对学习与认知更为基础的维度。此外，本研究以来自不同学校类型的大样本中学生为研究对象，而非迄今为止更受关注的高等教育学生群体<sup>15</sup>。此类研究群体难以触达，特别是在需要多次研究会话的情况下。在研究设计过程中，我们力求真实还原学生在校学习情境，确保研究发现具有实践意义。具体而言，我们采用反映该年龄段学生课堂接触主题及难度的文本材料，并将大语言模型的使用效果与迄今为止普遍采用的学习活动进行对比。## 翻译要求\n1. **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2. **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3. **学术风格**: 使用学术论文的正式语体\n4. **公式保留**: LaTeX 公式保持原样，不翻译\n5. **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n本研究的一个局限性在于，学生未接受针对不同学习活动的深入培训。尽管我们提供了关于如何与大型语言模型（LLM）互动及记笔记的说明和演示视频，但学生并未获得实践机会。这对LLM实验条件可能尤为不利，因为与记笔记相比，学生对使用LLM的熟悉度较低，因而可能未能充分发挥该活动的效能。此外，本研究若设置基线条件或被动阅读对照组，或能更准确地评估使用LLM理解文本是否比被动阅读更具优势（即衡量其本身的有效性）。另一局限是，尽管我们广泛抽取了内容样本，但受实际条件限制，所使用的保留和理解性问题数量有限，无法覆盖所有潜在问题范畴。因此，除自由回忆问题外，我们可能整体低估了学生的学习效果。此外，本研究仅局限于在完整课程体系之外进行的单次独立活动。若在真实场景中重复使用（如日常课堂或无人监督的自主作业），结果可能有所不同。最后，虽然本研究采用贴合学生水平的文本被视为优势，但LLM的应用可能对学生感到困难的文本更具价值——部分学生表示\"不知该向LLM提问什么\"正暗示了这一点。因此，探索LLM在超越学生当前能力的文本学习中的应用效果，可进一步拓展我们对潜在应用场景的认知。\n\n未来研究亟需探索何种LLM交互方式能最有效提升学习成果，并必须关注LLM融入学习环境的长期影响，特别是对其阅读技能、独立解决问题能力和元认知的作用。此外，理解这些工具如何影响社会对努力、专业素养和成就的认知也至关重要。LLM与生成式AI技术的演进可能重塑核心专业能力的定义，并改变各领域必要能力构成的格局<sup>8</sup>。未来，教育界与社会需明确在此新环境中哪些核心技能仍不可替代，并制定相应教学策略以保障其传承与发展<sup>9</sup>。本研究仅开启了如何有效利用LLM补充现有学习工具与活动，同时保持学生认知参与度的探索序幕。\n\n---\n**翻译说明**：\n- 专业术语如\"LLM\"保留英文缩写，首次出现时标注中文全称\n- 学术句式转换为中文论文常用表达（如\"might have been\"译为\"可能...正暗示了\"）\n- 保留原文引用格式<sup>8</sup>和逻辑连接词\n- 复杂长句按中文习惯拆分重组（如\"it is possible that...\"译为\"若...可能...\"句式）\n- 文化适配表达（如\"everyday classrooms\"译为\"日常课堂\"而非字面直译）## 翻译结果\n\n总之，本研究首次提供了关于大语言模型对阅读理解与记忆保持影响的大规模量化证据。我们的研究结果再次证实了传统策略（如记笔记）的重要性，这些策略能够促进深度认知投入并带来扎实的学习成果。与此同时，大语言模型为学习引入了新的可能性——提供了澄清、探索和情境化学习材料的机会——但这些工具必须在旨在增强而非绕过主动学习的适当指导下使用。教育工作者和研究人员不应将这些工具视为需要抵制的干扰，而是有机会主动引导其使用方式，以最大化学习潜力。通过这样做，我们既能让学生在人工智能融合的世界中茁壮成长，又能保持专注、深度和好奇心这些有意义教育的核心特质。\n\n# 材料与方法\n\n本研究包括两个阶段：预实验阶段和主体研究阶段。预实验阶段的目的是在学校情境中测试任务和拟议流程，并进行适当调整。本文报告的方法和发现是主体研究的一部分，该研究于2024年3月至7月期间进行。\n\n# 参与者\n\n参与者为来自英格兰七所中学的405名10年级学生（年龄14-15岁）。根据我们的排除标准（见补充章节1.1），我们保留了344名学生的数据进行分析。我们曾努力招募600名学生，但由于在暑假开始前未能找到足够多的学校而未能实现。招募方法包括向多个郡的学校校长发送电子邮件，并请参与学校联系其他学校。最终的学校样本包括三所非选拔性公立学校、两所文法学校（一所为女校，一所为男校）以及两所私立学校，分布于三个不同的郡。\n\n一旦学校同意参与，所有10年级学生均通过学校的项目负责人被邀请参加。信息表已与学生及其家长/监护人共享，之后双方被要求使用在线微软表单提供知情书面同意。本研究遵循英国教育研究协会$^{65}$的伦理指南。研究伦理批准由研究人员所在机构的研究伦理委员会提供。\n\n# 实验设计与流程\n\n本研究是一项预注册的随机对照实验，包含被试内和被试间设计要素，如图5所示。实验分两次进行，间隔三天，包括一次学习环节和一次测试环节。\n\n学习环节：在学习环节中，学生的任务是理解并学习两篇关于不同历史主题的文本（文本A和文本B）。每篇文本均通过一项特定的主动学习活动（条件）进行学习。三种条件如下：- **LLM组**：要求学生使用我们创建的LLM聊天机器人来辅助理解与学习文章。  \n- **笔记组**：要求学生通过记笔记的方式辅助理解与学习文章。  \n- **LLM+笔记组**：要求学生同时使用LLM聊天机器人与记笔记两种方式辅助理解与学习文章。\n\n学生被随机分配至以下两组之一：\n\n- **第一组**：接触LLM条件和笔记条件。  \n- **第二组**：接触LLM条件和LLM+笔记条件。\n\n随机分配结果显示，184名学生（53.5%）进入第一组，160名学生（46.5%）进入第二组。实验条件与文章顺序均经过随机化处理。在此阶段，学生还需完成关于学习体验的问卷调查。\n\n**测试阶段**：在测试阶段，学生需回答关于两篇文章（文章顺序随机）的理解与记忆问题，并完成个人基本特征的问卷调查。\n\n**时间安排**：学生学习阶段平均耗时约35分钟，测试阶段平均耗时约30分钟。\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \n组别、条件与文章随机分配顺序\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \n文章随机呈现顺序  \n**图5**：展示第一阶段与第二阶段活动流程的研究设计示意图\n\n# 实验设置与系统\n\n两个阶段均在正常上课时间于校内进行。学生以小组形式在教室同步参与实验，每人使用独立笔记本电脑或台式机完成操作。每阶段开始时，实验主持者或教师会宣读标准化指导语。整个过程中均有监督人员巡视并解答学生疑问。\n\n实验采用托管于github.com的网页应用程序，学生通过浏览器访问。针对第一阶段的LLM功能，该程序通过后端调用私有Azure Functions，访问托管于Azure的OpenAI GPT-3.5 turbo模型实例。所有LLM交互仅限在Azure平台内进行，不回流至OpenAI服务器。参与者最多可提交20条提示词。LLM通过不可见的元提示词进行定制（“你是一个帮助学生阅读和理解以下文章的AI聊天机器人：<文章内容> 学生可使用本工具查询生词、解释概念或总结文章要点”）。图6展示了LLM+笔记组的任务界面。笔记组与...\n\n# 南非种族隔离制度## 原文内容\n\n1910年，四个英国殖民地合并组建了\"南非联邦\"。该联邦是大英帝国的一部分，后来成为我们今天所知的南非共和国。二战后，许多受西方国家控制的地区（包括南非）寻求独立。南非政府希望摆脱大英帝国的控制。然而，对于南非黑人而言，主要斗争对象是反对具有英国和荷兰血统的白人南非人的歧视。\n\n1948年，国民党执政。新政府将歧视和种族隔离制度化为\" apartheid\"（种族隔离）体系。该体系持续了40多年，期间通过了诸多不公正法律。例如：每位公民必须按肤色进行分类；禁止不同肤色人群通婚；强制要求人们根据肤色居住在特定区域。超过350万有色人种被迫离开家园，许多人陷入贫困。\n\n非洲人国民大会（ANC）等反种族隔离组织最初仅采用和平抗议方式。1960年沙佩维尔大屠杀后这一策略发生转变——警方杀害了在警察局外和平抗议的黑人群体。活动人士开始转向暴力手段，包括破坏活动以及袭击警察和军队。作为回应，政府取缔了反种族隔离组织。在随后数十年间，反种族隔离活动人士面临逮捕、监禁甚至处决。例如非国大领袖纳尔逊·曼德拉曾被监禁27年。\n\n越来越多国家谴责种族隔离制度，并对南非实施制裁与抵制。1976年索韦托起义中的血腥事件也引发全球关注：黑人学生抗议强制使用荷兰殖民者语言——南非荷兰语授课的新法律，警方杀害了逾百名青少年。来自国内外持续增长的压力迫使政府做出改变。最终曼德拉获释，开启了终结种族隔离的谈判。1994年大选赋予所有南非公民（包括黑人）投票权，曼德拉由此成为首位民主选举产生的总统，标志着种族隔离制度的终结。但直至今日，许多南非黑人仍承受着该制度的负面影响。\n\n# AI聊天机器人 ②\n\n剩余提问次数：20次\n\n# 记事本\n\n![](/uploads/images/1daa7fa3-52d8-4ad3-bad2-545c83a3c45e/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \n图6：LLM+笔记条件下的任务界面示例\n\n完成当前任务后，\n\n请点击继续。\n\n继续(12:29)\n\n#\n\n在LLM实验条件下，界面仅分别显示记事本或聊天机器人。\n\n# 学习任务与材料（第一阶段）在学习环节中，学生阅读两篇历史主题的文本，每篇配有不同的学习活动。要求学生尽可能理解和掌握文本内容。值得注意的是，学生并未被提前告知将会接受材料测试。针对每项任务，学生首先会收到指导说明（参见补充章节2.6关于主动阅读的价值、具体内涵以及指定阅读活动如何支持主动阅读的内容）。随后接收包含具体策略的详细任务说明，并观看任务操作和界面演示视频。所建议的策略基于主动阅读与阅读理解研究文献[29;35;36;66]。三种实验条件下的指导说明在内容与措辞上保持高度一致。任务开始后，学生需在任务页面停留10分钟（最低要求）至15分钟（最高限制）。\n\n每位学生阅读两篇说明性文本，每篇涵盖一个独立主题（均包含于英国考试委员会的GCSE历史大纲）：南非种族隔离（文本A）与古巴导弹危机（文本B）。文本改编自两部OpenStax教材（《世界历史（卷二）：1400年以降》《美国历史》）。为确保内容难度、语言复杂度及文本特征适用于十年级学生且具有可比性，我们进行了大幅调整。两篇文本均包含四个段落，在以下维度基本持平：文本长度（386词与385词）、平均词长（5.3与4.8字符）、词汇复杂度（基于万词高频词表的平均排序位次：1986位与1927位）、句子数量（均为26句）以及CEFR等级（均为C1中高级）。\n\n表2：字面记忆、理解与自由回忆的题型及评分标准\n\n<table>\n<tr><td>测评维度</td><td>题型（每题数量）</td><td>评分标准</td><td>满分</td></tr>\n<tr><td rowspan=\"2\">字面记忆</td><td>简答-线索回忆（8题）</td><td>每个信息点：<br>0 - 缺失/错误/无关<br>0.5 - 不完整/部分正确<br>1 - 正确</td><td>10</td></tr>\n<tr><td>四选项单选-再认（10题）</td><td>0 - 缺失/错误<br>1 - 正确</td><td>10</td></tr>\n<tr><td>理解能力</td><td>简答-线索回忆（3题）</td><td>每个观点：<br>0 - 缺失/错误/无关<br>0.5 - 不完整/部分正确<br>1 - 正确</td><td>12</td></tr>\n<tr><td>自由回忆</td><td>开放作答（1题）</td><td>每个信息点/观点：<br>0 - 错误/无关<br>0.5 - 不完整/部分正确<br>1 - 正确</td><td>50</td></tr>\n</table>\n\n注：字面记忆维度中8道\"简答-线索回忆\"题有2题每题计2分。\n\n为保障评分可比性，我们将每篇文本划分为50个核心观点单元。\n\n# 测试任务与材料（第二阶段）在测试环节中，研究人员告知学生需要回答关于第一阶段所阅读篇章的相关问题，以及关于任务和自身情况的若干一般性问题。每篇阅读材料设有22道测试题目，分别评估字面记忆、理解能力和自由回忆能力。表2展示了不同构念的具体评估方式。根据预先注册的研究方案，我们采用单一字面记忆分数（即简答题与选择题得分的总和）。两篇阅读材料的题目顺序均设置为：自由回答题、理解题、字面记忆题（线索回忆）以及字面记忆题（再认题）。学生需在自由回忆题部分至少花费三分钟、至多五分钟。题目经过精心排序，必要时通过分屏呈现以避免前序题目对后续题目产生提示效应。示例题目详见附表11。\n\n字面记忆题要求受试者通过直接回忆或再认篇章中的信息来作答。要完成此类题目，学生仅需理解文中词汇，无需具备其他背景知识。他们不需要进行任何基于知识的推理（精加工），也无需或仅需进行极少的基于文本的衔接推理（例如连接两个相邻句子）。因此，字面记忆题针对的是文本的表层和基础表征层次。\n\n相比之下，理解题则探查深层理解能力，要求学生通过衔接推理整合文本中不同位置的信息。参与者需进行基于知识的推理以获得更高分数，即推断文中隐含但未明示的信息。因此，理解题针对的是文本情境模型层面的表征。\n\n简答题与开放题由三位独立评分者批阅。这些评分者均为教育学和/或心理学方向的博士生，且对实验条件不知情。他们接受了评分标准培训，该标准为每道题目提供了总体说明、评分规则、详细解释及示例。在培训阶段，评分者通过批阅25名学生的作答并进行反馈，以确保评分标准应用的一致性与准确性。随后每位评分者独立批阅约140名学生的全部作答（包含两篇阅读材料的所有题目）。\n\n为评估评分者间信度，三位评分者共同批阅了35名学生（约占样本总量的$10\\%$）的完整作答。采用双向模型的组内相关系数（ICC）<sup>67</sup>进行信度评估。我们测量了绝对一致性，并采用单## 翻译结果\n\n### 测量方法\n由于我们最终对所有学生（除信度样本中的35名学生外）采用了单一评分者的分数，因此采用了单一测量方法。对于信度样本中的学生，我们在后续分析中使用了三位评分者评分的中位数。组合线索回忆保持分数（针对文本A和文本B各一个）、组合理解分数以及自由回忆分数的评分者间信度在.97至.99之间，表明信度极佳$^{67}$。$95\\%$置信区间的下限均高于.90的极佳信度阈值（见附表12）。\n\n### 调查问题\n所有问题及应答量表详见补充材料第2.9节。第一次会话中每项任务结束后，要求学生自我报告：文本难度及其对主题的熟悉度与兴趣度；学习活动的愉悦度、难度和帮助度，以及未来使用可能性；任务的整体兴趣度、努力投入度和感知任务表现。学生还被问及是否偏好某个学习活动及其原因，是否曾使用AI聊天机器人及使用频率，以及在校阅读文本时使用这些学习活动的频率。\n\n第二次会话中每次测试后，要求学生评估其感知的测试表现。会话结束时，询问学生是否在两次会话间隙进行了与两篇文本相关的学习。学生还需报告性别、英语语言状况以及是否正在修读GCSE历史课程。\n\n此外，从学校获取了免费校餐资格数据作为学生社会经济劣势的衡量指标$^{68}$。这是因为FSM资格通常基于家庭收入和其他社会经济因素。\n\n### 分析策略\n除下文所述外，我们未偏离预注册分析方案。首先，我们扩展分析至开展质性分析，探究学生偏好某一学习活动的原因。其次，尽管最初计划探讨学习条件与性别、EAL、FSM、GCSE历史和学校类型之间的交互效应，但因实际样本量小于计划样本量而未实施。\n\n定量分析使用Python 3.11和R 4.4.2进行。所有分析采用0.05显著性水平（双尾）。效应量通过Cohen's d估算，计算公式为每个变量的均值差除以配对差异的标准差。\n\n### 学习条件对文本理解与保持效果的评估## 翻译结果\n\n**缺失数据处理**  \n因变量不存在缺失数据，原因在于未完成两项测试的参与者已被排除（见排除标准），且个别问题的缺失回答均计为0分。协变量中的缺失值极少，仅出现于性别、EAL（英语作为附加语言）和GCSE历史三门变量（缺失率分别为 $5.23\\%$、$1.16\\%$ 和 $1.16\\%$）。采用链式方程多重插补法（MICE）处理缺失数据，使用 'mice' 包实现。模型在五个插补数据集上分别拟合，结果合并后获得综合估计值。\n\n**混合效应回归**  \n使用 'lme4' 包构建三个线性混合效应回归模型，分别对应三个结果变量（即字面记忆、理解程度、自由回忆）。模型中将学生设定为随机效应。需说明的是，自由回忆分析虽预注册为次要分析，但为简化表述，现与其他结果变量一并报告。回归模型设定如下：\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {Condition} _ {i j} + \\beta_ {2} \\text {Group} _ {i j} + \\beta_ {3} \\text {School} _ {i j} + \\beta_ {4} \\text {Text} _ {i j} + \\beta_ {5} \\text {Task_Order} _ {i j} \\\\ + \\beta_ {6} \\text {Test_Order} _ {i j} + \\beta_ {7} \\text {Gender} _ {i j} + \\beta_ {8} \\text {FSM} _ {i j} + \\beta_ {9} \\text {EAL} _ {i j} + \\beta_ {1 0} \\text {History} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\n其中：\n\n- $Y_{ij}$ 表示学生 $i$ 在条件 $j$ 下的结果变量值  \n- $\\beta_0$ 表示模型截距  \n- $\\beta_{1}$ 至 $\\beta_{10}$ 表示固定效应系数：\n\n  - Condition：三水平分类变量（0=LLM，1=笔记，2=LLM+笔记）  \n  - Group：表示组别归属的二分类变量  \n  - School：七水平分类变量，表示学校归属  \n  - Text：二分类变量，表示学生 $i$ 在条件 $j$ 下学习的文本  \n  - Task_Order：二分类变量，表示学生 $i$ 完成条件 $j$ 任务的顺序（先/后）  \n  - Test_Order：二分类变量，表示文本测试顺序（先/后）  \n  - Gender：四水平分类变量（0=女性，1=男性，2=其他，3=拒绝回答）  \n  - FSM：二分类变量，表示学生是否享受免费校餐  \n  - EAL：分类变量，表示学生英语语言状态（0=母语者，1=双语者，2=其他）  \n  - History：二分类变量，表示学生是否选修GCSE历史课程\n\n- $u_{ij}$ 表示每位学生的随机截距  \n- $\\epsilon_{ij}$ 表示学生 $i$ 在条件 $j$ 下的误差项如图1所示，自由回忆得分呈非正态分布，因此我们进行了额外的非参数置换检验。具体而言，我们使用R语言中的'infer'包在学生层面进行了配对置换检验。这些检验比较了第一组中LLM条件与笔记条件之间的自由回忆得分，以及第二组中LLM条件与LLM+笔记条件之间的自由回忆得分。针对每位学生，我们计算了其两个得分之间的差异，并对所有学生的差异取平均值。将该检验统计量与零分布进行比较，零分布通过重复随机化学生内差异的符号并计算均值而生成。此过程在所有插补数据实例中重复进行，并通过取各实例中p值的中位数来汇总结果，从而获得合并p值。这样做得到了与混合效应模型相似的结果：在第一组中，我们发现笔记条件与LLM条件之间的自由回忆存在显著差异$(p = 0.02)$，但在第二组中未发现LLM+笔记条件与LLM条件之间的自由回忆存在显著差异的证据$(p = 0.80)$。\n\n# 对学生提示的质性探索\n\n为了解LLM条件对阅读理解和记忆保持影响的潜在解释，我们在计划性探索分析中试图了解学生使用LLM时生成的提示类型。通过调用Azure OpenAI API（部署日期2024-06-01）的Python自动化脚本，使用GPT-4采用分层编码方案对LLM提示进行分析。温度参数设置为0以确保确定性输出，并采用窄采样范围（top-p=0.1）来保证分类的一致性。模型获得了每个类别的详细说明和示例，以及学生正在学习的文本材料。每个提示可被赋予多个子代码。\n\n该分层编码方案经过多次迭代开发而成。初始版本由研究人员基于主动阅读文献、学生任务说明和试点工作，通过演绎和归纳法制定。随后根据API的建议扩展该方案，并要求API使用该编码方案对数据进行编码。研究人员通过检查部分API输出结果，迭代优化编码方案：根据需要合并、删除和添加代码，调整代码描述和示例以提高API输出质量。最后，一位研究人员手动检查了500条提示（约占总数据量的$10\\%$）的API输出，发现错误率为$5.6\\%$，该错误率被认为可接受。对这500条提示的指定代码进行了必要调整，其余API输出保持原样。学生提示的最终编码方案见附表20。\n\n# 学生学习体验的量化探索## 定性探索学生的活动偏好\n\n我们探究了学生对某一学习活动优于另一活动所给出的开放式解释。两位作者借助前述 API 对这些解释进行了分析。我们分别分析了四个偏好组：\n\n1.  LLM 优于笔记，\n2.  笔记优于 LLM，\n3.  LLM 优于 LLM+笔记，以及\n4.  LLM+笔记优于 LLM。\n\n每个偏好组都有其独立的编码方案，该方案仅包含偏好某一活动（优于非偏好活动）的解释（例如，如果学生偏好 LLM 而非笔记，则笔记记录的优势不会被编码）。初始方案是通过对每个偏好组约 $30\\%$ 的回答进行手动和演绎式编码而制定的。每个回答可以应用多个代码。初始编码方案，包括类别标签、描述和示例，连同数据及通用编码指令一并提供给 API。API 未提出任何其他有用的代码。随后，研究人员通过手动检查 API 输出的部分内容，迭代地完善编码方案。他们合并、删除和添加代码，并完善代码描述和示例，然后重新运行 API 分析。重复此过程，直至两位研究人员均对编码方案感到满意。由于需要编码的回答数量较少（ $n = 278$ ），一位研究人员检查了 API 的全部输出并在必要时进行了调整。活动偏好的最终编码方案见补充章节 2.11。\n\n## 数据可用性\n\n所有定量数据将在论文发表后公开。由于存在共享可识别信息的风险，我们不会提供以下定性数据：学生的 LLM 交互记录（仅共享应用的代码）、学生的笔记、学生的活动偏好（仅共享应用的代码）。\n\n## 代码可用性\n\n相应代码将在论文发表后共享。\n\n## 伦理声明\n\n## 利益冲突\n\n部分作者在一家投资于生成式人工智能并以生成式人工智能模型为核心组件开发技术的公司从事研究工作。其他作者隶属于一家出版、评估和学习机构，该机构在开发和运营评估与学习产品及服务时越来越多地使用人工智能。然而，本项工作与任一组织的任何特定产品或盈利努力均无关联。\n\n## 致谢\n\n我们感谢 Tom Benton 博士和 Matthew Carroll 博士对本研究中所进行分析提供的宝贵建议。# 补充材料\n\n# 目录\n\n# 补充信息\n\n- 参与者排除标准\n\n# 补充表格\n\n- 学生特征\n  学习活动熟悉度\n- 描述性统计\n- 混合效应回归结果\n  行为参与度\n- 主动阅读导论\n- 学习活动导论\n\n- 按实验条件划分的具体说明\n  测试问题\n- 评分者间信度结果\n  调查问题与回答量表\n  调查问题与回答量表（第2阶段）\n- 学习体验与感知\n  活动偏好编码方案\n  编码方案：偏好LLM而非笔记\n  编码方案：偏好笔记而非LLM\n  编码方案：偏好LLM+笔记而非LLM\n  编码方案：提示交互\n- 提示类型频率\n\n# 参考文献\n\n[1] Cecilia Ka Yuk Chan. 面向大学教与学的综合性人工智能政策教育框架. International Journal of Educational Technology in Higher Education, 20(1):38, 2023年7月. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.\n[2] Abdulhadi Shoufan. 探索学生对ChatGPT的认知：主题分析与后续调查. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. 期刊名称: IEEE Access.\n[3] K. Aleksić-Maslac, F. Borović, 与 Z. Biočina. 教育系统中ChatGPT的认知与使用. INTED2024论文集, 页 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. 会议名称: 第18届国际技术、教育与发展会议 ISBN: 9788409592159 会议名称: 第18届国际技术、教育与发展会议 地点: 西班牙瓦伦西亚 出版社: IATED.\n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, 与 Elena L. Glassman. 何处隐藏被窃大象：多模态机器智能带来的创造性写作飞跃. ACM Transactions on Computer-Human Interaction, 2022年2月. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. 已接受待发表.\n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, 与 Bryony N. Parsons. 学生对高等教育中使用生成式人工智能技术的观点. International Journal for Educational Integrity, 20(1):2, 2024年2月. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.[6] Duong Hoai Lan 和 Tran Minh Tung。分析越南大学生使用Chat-GPT的影响。《Migration Letters》，第20卷S10期，第259-268页，2023年11月。ISSN 1741-8992。doi: 10.59670/ml.v20iS10.5134。URL https://migrationletters.com/index.php/ml/article/view/5134。期号: S10。\n\n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, Gjergji Kasneci。ChatGPT 利大于弊？论大型语言模型在教育领域的机遇与挑战。《Learning and Individual Differences》，2023年。\n\n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, Manuel Ninaus。通过游戏化和基于游戏的学习释放大型语言模型在教育中的潜力。《Educational Psychology Review》，第36卷第1期，第25页，2024年2月。ISSN 1573-336X。doi: 10.1007/s10648-024-09868-z。URL https://doi.org/10.1007/s10648-024-09868-z。\n\n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaolo Viglia, Michael Wade, Paul Walton, Jochen Wirtz, Ryan Wright。观点论文：\"即使ChatGPT写了又如何？\"关于生成式对话AI对研究、实践与政策的机遇、挑战及影响的多学科视角。《International Journal of Information Management》，第71卷，第102642页，2023年8月。ISSN 0268-4012。doi: 10.1016/j.ijinfomgt.2023.102642。URL https://www.sciencedirect.com/science/article/pii/S0268401223000233。\n\n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, Zhiyong Jason Ren。ChatGPT与环境研究。《环境科学与技术》，第57卷第46期，第17667-17670页，2023年11月。ISSN 0013-936X。doi: 10.1021/acs.est.3c01818。URL https://doi.org/10.1021/acs.est.3c01818。出版者：美国化学会。\n\n[11] Alex Barrett 和 Austin Pack。并非完全的人与AI对视：学生和教师对生成式人工智能在写作过程中应用的看法。《International Journal of Educational Technology in Higher Education》，第20卷第1期，第59页，2023年11月。ISSN 2365-9440。doi: 10.1186/s41239-023-00427-0。URL https://doi.org/10.1186/s41239-023-00427-0。\n\n[12] Aiste Steponenaite 和 Basel Barakat。人工智能赋能世界中的剽窃问题。见 Margherita Antona 和 Constantine Stephanidis 编辑，《Universal Access in Human-Computer Interaction》，第434–442页，Cham，2023年。Springer Nature Switzerland。ISBN 978-3-031-35897-5。doi: 10.1007/978-3-031-35897-5_31。```chinese\n## 参考文献\n\n[13] Ofcom. 《2024年在线国家报告》. 技术报告, Ofcom, 2024年11月. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.\n\n[14] 沃尔顿家族基金会. 《教师和学生拥抱ChatGPT用于教育》. 技术报告, 沃尔顿家族基金会, 2023年3月. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. 栏目: 学习.\n\n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. ChatGPT是否促进学生学习？实验性研究的系统综述与元分析. 《计算机与教育》, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.\n\n[16] Jeffrey R. Binder and Rutvik H. Desai. 语义记忆的神经生物学. 《认知科学趋势》, 15(11):527-536, 2011年11月. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.\n\n[17] Danielle S. McNamara and Joe Magliano. 迈向综合的理解模型. 载于《学习与动机心理学》第51卷, 《学习与动机心理学》, 页297-384. Elsevier Academic Press, 美国加州圣地亚哥, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.\n\n[18] Walter Kintsch. 知识在语篇理解中的作用：建构-整合模型. 《心理学评论》, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. 出版地: 美国 出版商: 美国心理学会.\n\n[19] Gregory Hickok and David Poeppel. 言语处理的皮层组织. 《自然评论：神经科学》, 8(5):393-402, 2007年5月. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. 出版商: Nature Publishing Group.\n\n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. 语言网络作为人脑更广泛图谱中的自然类. 《自然评论：神经科学》, 25 (5):289-312, 2024年5月. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. 出版商: Nature Publishing Group.\n\n[21] Rolf A. Zwaan and Gabriel A. Radvansky. 语言理解与记忆中的情境模型. 《心理学通报》, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. 出版地: 美国 出版商: 美国心理学会.\n\n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. 语义痴呆中语义、语言、社会行为和面孔识别的统一神经认知模型. 《自然通讯》, 11(1):2595, 2020年5月. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. 出版商: Nature Publishing Group.\n\n[23] Kate Cain and Jane Oakhill. 阅读理解困难：相关性、原因与后果. 载于《儿童口头与书面语言理解问题：认知视角》, 《语言与素养的挑战》系列, 页41-75. The Guilford Press, 美国纽约州纽约市, 2007. ISBN 978-1-59385-443-0.\n\n[24] Meredithyth Daneman and Patricia A. Carpenter. 工作记忆与阅读的个体差异. 《言语学习与言语行为杂志》, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. 出版地: 荷兰 出版商: Elsevier Science.\n```[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. 阅读理解技能的习得. 见：*阅读科学：手册*，Blackwell 发展心理学手册，第 227-247 页. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.\n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. 儿童阅读理解与理解困难. 见：*牛津阅读手册*，牛津心理学文库，第 344-360 页. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.\n[27] Keith E. Stanovich. 阅读中的马太效应：读写能力习得中个体差异的若干后果. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. 出版地：美国 出版商：International Reading Association.\n[28] A. C. Graesser, M. Singer, and T. Trabasso. 叙事文本理解过程中推理的构建. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.\n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART：促进主动阅读与思考的交互式策略训练. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.\n[30] John T. Guthrie and Allan Wigfield. 阅读中的投入与动机. 见：阅读研究手册，卷 III，第 403-422 页. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.\n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. 阅读过程中信息可用性的波动：运用景观模型捕捉认知过程. 第 165-186 页. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.\n[32] Fergus I. M. Craik. 加工水平：过去、现在……与未来？ Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. 出版地：英国 出版商：Taylor & Francis.\n[33] Fergus I. M. Craik and Endel Tulving. 加工深度与情景记忆中单词的保持. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. 出版地：美国 出版商：American Psychological Association.\n[34] John R. Anderson. 记忆的扩散激活理论. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.\n[35] Danielle S. McNamara, 编辑. 阅读理解策略：理论、干预与技术. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.\n[36] Michelene T. H. Chi. 主动-建构-交互：区分学习活动的概念框架. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.```chinese\n## 翻译结果\n\n[37] Rose Luckin, Wayne Holmes, Laurie B Forcier. 《智能释放：人工智能在教育中的应用论证》。技术报告，培生集团/伦敦大学学院开放思想，2016年。网址 https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf。\n[38] Wayne Holmes, Maya Bialik, Charles Fadel. 《教育中的人工智能：教学与学习的承诺与启示》。2019年3月。ISBN 978-1-79429-370-0。\n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, Francesco Costantino. 《大语言模型在工程教育中的学生使用：一项关于技术接受度、感知、效能和检测可能性的案例研究》。Computers and Education: Artificial Intelligence，第5卷，100172页，2023年10月。doi: 10.1016/j.caeai.2023.100172。\n[40] Sami Sarsa, Paul Denny, Arto Hellas, Juho Leinonen. 《使用大语言模型自动生成编程练习与代码解释》。载于《2022年ACM国际计算机教育研究会议论文集 - 第1卷》，第27-43页，瑞士卢加诺与虚拟会议，2022年8月。ACM出版社。ISBN 978-1-4503-9194-8。doi: 10.1145/3501385.3543957。网址 https://dl.acm.org/doi/10.1145/3501385.3543957。\n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, Jake M Hofman. 《大语言模型与数学教育：危机还是机遇？》。2023年。\n[42] John Sweller, Jeroen J. G. van Merrienboer, Fred Paas. 《认知架构与教学设计：20年后的回顾》。Educational Psychology Review，第31卷第2期，第261-292页，2019年。ISSN 1573-336X。doi: 10.1007/s10648-019-09465-5。出版地：德国，出版商：Springer。\n[43] Richard E. Mayer. 《是否应该对纯粹发现式学习设立\"三振出局\"规则？》。American Psychologist，第59卷第1期，第14-19页，2004年。ISSN 1935-990X。doi: 10.1037/0003-066X.59.1.14。出版地：美国，出版商：美国心理学会。\n[44] Fergus I. M. Craik, Robert S. Lockhart. 《加工水平：记忆研究的框架》。Journal of Verbal Learning and Verbal Behavior，第11卷第6期，第671-684页，1972年12月。ISSN 0022-5371。doi: 10.1016/S0022-5371(72)80001-X。网址 https://www.sciencedirect.com/science/article/pii/S002253717280001X。\n[45] Xiaoming Zhai, Matthew Nyaaba, Wenchao Ma. 《生成式AI和ChatGPT能在科学领域认知要求高的问题解决任务上超越人类吗？》。2024年1月。网址 http://arxiv.org/abs/2401.15081。arXiv:2401.15081。\n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, Radouane Slamene. 《分析学生对ChatGPT使用的看法、担忧与伦理认知》。Computers and Education: Artificial Intelligence，第5卷，100180页，2023年1月。ISSN 2666-920X。doi: 10.1016/j.caeai.2023.100180。网址 https://www.sciencedirect.com/science/article/pii/S2666920X23000590。\n[47] Hao Yu, Yunyun Guo. 《生成式人工智能赋能教育改革：现状、问题与展望》。Frontiers in Education，第8卷，1183162页，2023年6月。ISSN 2504-284X。doi: 10.3389/feduc.2023.1183162。网址 https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full。\n[48] Elizabeth Ligon Bjork, Robert A. Bjork. 《给自己制造困难，但要以一种好的方式：创造合意困难以促进学习》。载于《心理学与现实世界：对社会根本贡献的例证文集》，第56-64页。Worth Publishers出版社，美国纽约州纽约市，2011年。ISBN 978-1-4292-3043-8。\n```[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. 向人类辅导学习. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.\n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. 可塑性的人类大脑皮层. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.\n[51] S. Dehaene and L. Naccache. 迈向意识的认知神经科学：基础证据与工作空间框架. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.\n[52] Keiichi Kobayashi. 笔记的编码效应受何限制？一项元分析检验. Contemporary Educational Psychology, 2005.\n[53] Kenneth A. Kiewra. 笔记研究述评：编码存储范式及超越. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. 出版地: 德国 出版社: Springer.\n[54] Kenneth A. Kiewra. 探究笔记与复习：加工深度的替代视角. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. 出版地: 美国 出版社: Lawrence Erlbaum.\n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. 笔记记录、复习、记忆与理解. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.\n[56] Dung C. Bui and Joel Myerson. 工作记忆能力在课堂笔记记录中的作用. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. 出版地: 荷兰 出版社: Elsevier Science.\n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. 测试是否比笔记记录更有效的学习策略？ Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.\n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. 课堂中的元认知错误：过往成绩变异性对考试预测准确性的影响. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. 在线优先出版.\n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. 自我调节学习：信念、技术与错觉. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.\n[60] Justin Kruger and David Dunning. 无能且不自知：识别自身无能之困难如何导致膨胀的自我评估. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.\n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. 生成式人工智能的元认知需求与机遇. 见: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.## 翻译结果\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. 学习何时是\"费力的\"？从动机视角审视认知导向研究中的心理努力概念。 Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.\n[63] Louise Starkey. 面向数字时代的教师准备研究综述。 Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.\n[64] 王红红, 史卫平. 外语专业课程思政的实践路径探索。 外语界, (6):38-45, 2021.\n[65] British Educational Research Association. 教育研究伦理指南, 第四版, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.\n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. 阅读理解专业能力的培养：应教什么？如何教？ Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.\n[67] Terry K Koo and Mae Y Li. 可靠性研究中组内相关系数选择与报告指南。 2016.\n[68] Chris Taylor. 免费学校餐资格作为社会经济劣势衡量指标的可靠性：来自威尔士千禧队列研究的证据。 *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 补充信息\n\n# 1.1 参与者排除标准\n\n参与者 $(n = 61)$ 因以下原因被排除：\n\n1.  未参与第二阶段测试 (n=36)\n2.  未完成第一阶段的两项任务（和/或有意退出） $(n = 2)$\n3.  在尝试回答所有理解和记忆问题前停止了第二阶段测试 $(n = 8)$\n4.  在10分钟或更短时间内完成第二阶段测试 $(n = 1)$\n5.  报告对两个主题的先验知识存在显著差异（在5点李克特量表项目上存在3点差异） $(n = 13)$\n6.  在测试过程中作弊（经研究人员观察，包括打开不同浏览器查找答案、抄袭他人答案、与邻座持续交谈）。对可疑学生的回答进行扫描并与同组其他学生的回答进行比较。若根据回答（例如，与某学生回答高度重合）确认存在嫌疑，则予以排除 $(n = 1)$\n\n# 2 补充表格\n\n# 2.1 学生特征\n\n表 3: 按组别及总体统计的学生特征（排除后，$\\mathrm{N} = {344}$）<table>\n<tr><td>特征</td><td>第一组<br>学生数（百分比）</td><td>第二组<br>学生数（百分比）</td><td>总计<br>学生数（百分比）</td></tr>\n<tr><td>男性</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr>\n<tr><td>女性</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr>\n<tr><td>其他</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr>\n<tr><td>不愿透露</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr>\n<tr><td>FSM_是</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr>\n<tr><td>FSM_否</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr>\n<tr><td>EAL_是</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr>\n<tr><td>EAL_其他语言</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr>\n<tr><td>EAL_双语</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr>\n<tr><td>History_是</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr>\n<tr><td>History_否</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr>\n</table>\n\n# 2.2 对学习活动的熟悉度\n\n表4：先前学习活动使用频率\n\n<table>\n<tr><td>活动及频率</td><td>第一组<br>学生数（百分比）</td><td>第二组<br>学生数（百分比）</td></tr>\n<tr><td colspan=\"3\">学习用笔记记录</td></tr>\n<tr><td>从不</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr>\n<tr><td>很少</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr>\n<tr><td>有时</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr>\n<tr><td>经常</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr>\n<tr><td>总是</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr>\n<tr><td colspan=\"3\">学习用LLM使用</td></tr>\n<tr><td>从不</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr>\n<tr><td>很少</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr>\n<tr><td>有时</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr>\n<tr><td>经常</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr>\n<tr><td>总是</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr>\n<tr><td colspan=\"3\">LLM + 笔记用于学习</td></tr>\n<tr><td>从不</td><td>-</td><td>1 (1.6%)</td></tr>\n<tr><td>很少</td><td>-</td><td>31 (48.4%)</td></tr>\n<tr><td>有时</td><td>-</td><td>23 (35.9%)</td></tr>\n<tr><td>经常</td><td>-</td><td>8 (12.5%)</td></tr>\n<tr><td>总是</td><td>-</td><td>1 (1.6%)</td></tr>\n<tr><td colspan=\"3\">先前LLM使用情况</td></tr>\n<tr><td>是</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr>\n<tr><td>否</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr>\n<tr><td colspan=\"3\">使用者中LLM使用频率</td></tr>\n<tr><td>每周少于一次</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr>\n<tr><td>每周一至两天</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr>\n<tr><td>每周三至五天</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr>\n<tr><td>每周大多数天数</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr>\n</table>\n\n# 2.3 描述性统计\n\n表5：不同条件下理解能力、字面保持能力与自由回忆的描述性统计。<table><tr><td>测量指标</td><td>条件</td><td>均值 (M)</td><td>标准差 (SD)</td></tr><tr><td rowspan=\"4\">理解度（满分12分）</td><td>笔记</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + 笔记</td><td>4.11</td><td>2.65</td></tr><tr><td>仅LLM（第1组）</td><td>4.00</td><td>2.44</td></tr><tr><td>仅LLM（第2组）</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">字面记忆（满分20分）</td><td>笔记</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + 笔记</td><td>9.68</td><td>4.83</td></tr><tr><td>仅LLM（第1组）</td><td>8.83</td><td>3.96</td></tr><tr><td>仅LLM（第2组）</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">自由回忆（满分50分）</td><td>笔记</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM 第1组</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM 第2组</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + 笔记</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 混合效应回归结果\n\n表6：字面记忆、理解度与自由回忆的模型系数<table>\n<tr>\n<td>术语</td>\n<td>估计值</td>\n<td>标准误</td>\n<td>95% 置信区间</td>\n<td>统计量</td>\ntd>自由度</td>\n<td>p 值</td>\n<td>效应量 (d)</td>\n</tr>\n<tr>\n<td colspan=\"8\">字面记忆保留</td>\n</tr>\n<tr>\n<td>截距</td>\n<td>8.2429</td>\n<td>0.7966</td>\n<td>[6.68, 9.81]</td>\n<td>10.3476</td>\n<td>489.3004</td>\n<td>7.95 × 10<sup>-23</sup></td>\n<td>-</td>\n</tr>\n<tr>\n<td>条件 LLM_notes</td>\n<td>0.5668</td>\n<td>0.2752</td>\n<td>[0.03, 1.11]</td>\n<td>2.0597</td>\n<td>660.4521</td>\n<td>0.0398</td>\n<td>0.132</td>\n</tr>\n<tr>\n<td>条件 notes</td>\n<td>1.9188</td>\n<td>0.2559</td>\n<td>[1.42, 2.42]</td>\n<td>7.4974</td>\n<td>663.2789</td>\n<td>2.09 × 10<sup>-13</sup></td>\n<td>0.443</td>\n</tr>\n<tr>\n<td>组别 1</td>\n<td>-0.6147</td>\n<td>0.4155</td>\n<td>[-1.43, 0.20]</td>\n<td>-1.4793</td>\n<td>661.9230</td>\n<td>0.1395</td>\n<td>-0.143</td>\n</tr>\n<tr>\n<td>学校编号 S03</td>\n<td>-0.8645</td>\n<td>0.5993</td>\n<td>[-2.04, 0.31]</td>\n<td>-1.4424</td>\n<td>638.7162</td>\n<td>0.1497</td>\n<td>-0.198</td>\n</tr>\n<tr>\n<td>学校编号 S01</td>\n<td>-1.9789</td>\n<td>0.8005</td>\n<td>[-3.55, -0.41]</td>\n<td>-2.4720</td>\n<td>657.4886</td>\n<td>0.0137</td>\n<td>-0.465</td>\n</tr>\n<tr>\n<td>学校编号 S05</td>\n<td>-0.3908</td>\n<td>0.8562</td>\n<td>[-2.07, 1.29]</td>\n<td>-0.4564</td>\n<td>612.9203</td>\n<td>0.6483</td>\n<td>-0.094</td>\n</tr>\n<tr>\n<td>学校编号 S02</td>\n<td>1.2932</td>\n<td>0.5514</td>\n<td>[0.21, 2.37]</td>\n<td>2.3452</td>\n<td>643.8234</td>\n<td>0.0193</td>\n<td>0.299</td>\n</tr>\n<tr>\n<td>学校编号 S07</td>\n<td>2.7561</td>\n<td>1.1408</td>\n<td>[0.52, 4.99]</td>\n<td>2.4160</td>\n<td>663.8251</td>\n<td>0.0160</td>\n<td>0.623</td>\n</tr>\n<tr>\n<td>学校编号 S04</td>\n<td>-4.7045</td>\n<td>0.8102</td>\n<td>[-6.29, -3.12]</td>\n<td>-5.8067</td>\n<td>641.0030</td>\n<td>1.00 × 10<sup>-8</sup></td>\n<td>-1.075</td>\n</tr>\n<tr>\n<td>文本 古巴</td>\n<td>1.5218</td>\n<td>0.1880</td>\n<td>[1.15, 1.89]</td>\n<td>8.0952</td>\n<td>663.5151</td>\n<td>2.74 × 10<sup>-15</sup></td>\n<td>0.351</td>\n</tr>\n<tr>\n<td>任务顺序 0</td>\n<td>0.2310</td>\n<td>0.1880</td>\n<td>[-0.14, 0.60]</td>\n<td>1.2283</td>\n<td>659.9704</td>\n<td>0.2198</td>\n<td>0.052</td>\n</tr>\n<tr>\n<td>测试顺序 0</td>\n<td>0.5186</td>\n<td>0.1875</td>\n<td>[0.15, 0.89]</td>\n<td>2.7656</td>\n<td>663.7540</td>\n<td>0.0058</td>\n<td>0.119</td>\n</tr>\n<tr>\n<td>性别 (男性)</td>\n<td>0.8396</td>\n<td>0.4609</td>\n<td>[-0.06, 1.74]</td>\n<td>1.8217</td>\n<td>335.9448</td>\n<td>0.0694</td>\n<td>0.193</td>\n</tr>\n<tr>\n<td>性别 (其他)</td>\n<td>1.1737</td>\n<td>1.5839</td>\n<td>[-1.93, 4.28]</td>\n<td>0.7410</td>\n<td>187.9029</td>\n<td>0.4596</td>\n<td>0.228</td>\n</tr>\n<tr>\n<td>性别 (不愿透露)</td>\n<td>1.7770</td>\n<td>1.4362</td>\n<td>[-1.04, 4.59]</td>\n<td>1.2373</td>\n<td>474.9248</td>\n<td>0.2166</td>\n<td>0.226</td>\n</tr>\n<tr>\n<td>免费校餐 (是)</td>\n<td>-0.9135</td>\n<td>0.8574</td>\n<td>[-2.59, 0.77]</td>\n<td>-1.0654</td>\n<td>653.1653</td>\n<td>0.2871</td>\n<td>-0.207</td>\n</tr>\n<tr>\n<td>英语附加语 (双语)</td>\n<td>0.4650</td>\n<td>0.4780</td>\n<td>[-0.47, 1.40]</td>\n<td>0.9728</td>\n<td>645.1354</td>\n<td>0.3310</td>\n<td>0.116</td>\n</tr>\n<tr>\n<td>英语附加语 (其他)</td>\n<td>-0.3369</td>\n<td>1.6161</td>\n<td>[-3.50, 2.83]</td>\n<td>-0.2085</td>\n<td>660.9281</td>\n<td>0.8349</td>\n<td>-0.027</td>\n</tr>\n<tr>\n<td>历史学习经历 (无)</td>\n<td>-1.5365</td>\n<td>0.3832</td>\n<td>[-2.29, -0.79]</td>\n<td>-4.0095</td>\n<td>641.2946</td>\n<td>6.80 × 10<sup>-5</sup></td>\n<td>-0.351</td>\n</tr>\n<tr>\n<td colspan=\"8\">理解能力</td>\n</tr>\n<tr>\n<td>截距</td>\n<td>4.0264</td>\n<td>0.4409</td>\n<td>[3.16, 4.89]</td>\n<td>9.1318</td>\n<td>638.9518</td>\n<td>8.77 × 10<sup>-19</sup></td>\n<td>-</td>\n</tr>\n<tr>\n<td>条件 LLM_notes</td>\n<td>0.3533</td>\n<td>0.1785</td>\n<td>[0.00, 0.70]</td>\n<td>1.9792</td>\n<td>655.5471</td>\n<td>0.0482</td>\n<td>0.142</td>\n</tr>\n<tr>\n<td>条件 notes</td>\n<td>0.9500</td>\n<td>0.1658</td>\n<td>[0.62, 1.28]</td>\n<td>5.7306</td>\n<td>662.6375</td>\n<td>1.52 × 10<sup>-8</sup></td>\n<td>0.382</td>\n</tr>\n<tr>\n<td>组别 1</td>\n<td>-0.0735</td>\n<td>0.2395</td>\n<td>[-0.54, 0.40]</td>\n<td>-0.3068</td>\n<td>657.2449</td>\n<td>0.7591</td>\n<td>-0.033</td>\n</tr>\n<tr>\n<td>学校编号 S03</td>\n<td>-0.9749</td>\n<td>0.3320</td>\n<td>[-1.63, -0.32]</td>\n<td>-2.9365</td>\n<td>655.1779</td>\n<td>0.0034</td>\n<td>-0.399</td>\n</tr>\n<tr>\n<td>学校编号 S01</td>\n<td>-1.9371</td>\n<td>0.4438</td>\n<td>[-2.81, -1.07]</td>\n<td>-4.3645</td>\n<td>662.1221</td>\n<td>1.48 × 10<sup>-5</sup></td>\n<td>-0.783</td>\n</tr>\n<tr>\n<td>学校编号 S05</td>\n<td>-0.3167</td>\n<td>0.4735</td>\n<td>[-1.24, 0.61]</td>\n<td>-0.6688</td>\n<td>648.4704</td>\n<td>0.5039</td>\n<td>-0.142</td>\n</tr>\n<tr>\n<td>学校编号 S02</td>\n<td>0.5254</td>\n<td>0.3052</td>\n<td>[-0.07, 1.12]</td>\n<td>1.7215</td>\n<td>659.5381</td>\n<td>0.0856</td>\n<td>0.201</td>\n</tr>\n<tr>\n<td>学校编号 S07</td>\n<td>0.9683</td>\n<td>0.6335</td>\n<td>[-0.27, 2.21]</td>\n<td>1.5284</td>\n<td>663.5186</td>\n<td>0.1269</td>\n<td>0.377</td>\n</tr>\n<tr>\n<td>学校编号 S04</td>\n<td>-2.9725</td>\n<td>0.4493</td>\n<td>[-3.85, -2.09]</td>\n<td>-6.6154</td>\n<td>651.4740</td>\n<td>7.74 × 10<sup>-11</sup></td>\n<td>-1.192</td>\n</tr>\n<tr>\n<td>文本 古巴</td>\n<td>-0.6057</td>\n<td>0.1218</td>\n<td>[-0.84, -0.37]</td>\n<td>-4.9727</td>\n<td>662.4076</td>\n<td>8.42 × 10<sup>-7</sup></td>\n<td>-0.245</td>\n</tr>\n<tr>\n<td>任务顺序 0</td>\n<td>0.0428</td>\n<td>0.1219</td>\n<td>[-0.20, 0.28]</td>\n<td>0.3508</td>\n<td>657.5431</td>\n<td>0.7258</td>\n<td>0.015</td>\n</tr>\n<tr>\n<td>测试顺序 0</td>\n<td>0.6679</td>\n<td>0.1215</td>\n<td>[0.43, 0.91]</td>\n<td>5.4958</td>\n<td>662.7896</td>\n<td>5.55 × 10<sup>-8</sup></td>\n<td>0.266</td>\n</tr>\n<tr>\n<td>性别 (男性)</td>\n<td>0.2287</td>\n<td>0.2517</td>\n<td>[-0.26, 0.72]</td>\n<td>0.9086</td>\n<td>542.3928</td>\n<td>0.3640</td>\n<td>0.078</td>\n</tr>\n<tr>\n<td>性别 (其他)</td>\n<td>0.0375</td>\n<td>0.9339</td>\n<td>[-1.79, 1.87]</td>\n<td>0.0401</td>\n<td>102.4863</td>\n<td>0.9681</td>\n<td>0.574</td>\n</tr>\n<tr>\n<td>性别 (不愿透露)</td>\n<td>1.5360</td>\n<td>0.9257</td>\n<td>[-0.28, 3.35]</td>\n<td>1.6593</td>\n<td>68.4482</td>\n<td>0.1016</td>\n<td>0.006</td>\n</tr>\n<tr>\n<td>免费校餐 (是)</td>\n<td>-0.6056</td>\n<td>0.4786</td>\n<td>[-1.54, 0.33]</td>\n<td>-1.2655</td>\n<td>626.0565</td>\n<td>0.2062</td>\n<td>-0.236</td>\n</tr>\n<tr>\n<td>英语附加语 (双语)</td>\n<td>0.5813</td>\n<td>0.2649</td>\n<td>[0.06, 1.10]</td>\n<td>2.1943</td>\n<td>655.2427</td>\n<td>0.0286</td>\n<td>0.228</td>\n</tr>\n<tr>\n<td>英语附加语 (其他)</td>\n<td>-0.2195</td>\n<td>0.9140</td>\n<td>[-2.01, 1.57]</td>\n<td>-0.2402</td>\n<td>556.3704</td>\n<td>0.8103</td>\n<td>-0.103</td>\n</tr>\n<tr>\n<td>历史学习经历 (无)</td>\n<td>-0.6719</td>\n<td>0.2138</td>\n<td>[-1.09, -0.25]</td>\n<td>-3.1423</td>\n<td>613.1612</td>\n<td>0.0018</td>\n<td>-0.262</td>\n</tr>\n<tr>\n<td colspan=\"8\">自由回忆</td>\n</tr>\n<tr>\n<td>截距</td>\n<td>4.4052</td>\n<td>0.8507</td>\n<td>[2.74, 6.08]</td>\n<td>5.1786</td>\n<td>662.4966</td>\n<td>2.97 × 10<sup>-7</sup></td>\n<td>-</td>\n</tr>\n<tr>\n<td>条件 LLM_notes</td>\n<td>-0.0847</td>\n<td>0.4590</td>\n<td>[-0.98, 0.81]</td>\n<td>-0.1846</td>\n<td>661.9195</td>\n<td>0.8536</td>\n<td>-0.015</td>\n</tr>\n<tr>\n<td>条件 notes</td>\n<td>1.0185</td>\n<td>0.4269</td>\n<td>[0.18, 1.86]</td>\n<td>2.3856</td>\n<td>663.2739</td>\n<td>0.0173</td>\n<td>0.211</td>\n</tr>\n<tr>\n<td>组别 1</td>\n<td>-0.2703</td>\n<td>0.4958</td>\n<td>[-1.24, 0.70]</td>\n<td>-0.5452</td>\n<td>662.0547</td>\n<td>0.5858</td>\n<td>-0.058</td>\n</tr>\n<tr>\n<td>学校编号 S03</td>\n<td>-0.4702</td>\n<td>0.6185</td>\n<td>[-1.68, 0.74]</td>\n<td>-0.7603</td>\n<td>663.5556</td>\n<td>0.4474</td>\n<td>-0.086</td>\n</tr>\n<tr>\n<td>学校编号 S01</td>\n<td>-0.9612</td>\n<td>0.8290</td>\n<td>[-2.59, 0.66]</td>\n<td>-1.1595</td>\n<td>660.3122</td>\n<td>0.2467</td>\n<td>-0.189</td>\n</tr>\n<tr>\n<td>学校编号 S05</td>\n<td>2.1564</td>\n<td>0.8819</td>\n<td>[0.43, 3.89]</td>\n<td>2.4452</td>\n<td>662.7977</td>\n<td>0.0147</td>\n<td>0.459</td>\n</tr>\n<tr>\n<td>学校编号 S02</td>\n<td>2.7874</td>\n<td>0.5687</td>\n<td>[1.67, 3.90]</td>\n<td>4.9012</td>\n<td>663.9081</td>\n<td># 2.5 行为参与度\n\n表7：与大型语言模型及笔记记录的行为互动数据，包括提问次数、笔记字数及任务耗时。显著的任务时间差异已高亮显示，用于不同条件间的比较。\n\n<table>\n  <tr>\n    <td>测量指标</td>\n    <td>实验条件</td>\n    <td>平均值 (M)</td>\n    <td>标准差 (SD)</td>\n  </tr>\n  <tr>\n    <td rowspan=\"3\">提问次数</td>\n    <td>第一组 (LLM + 笔记)</td>\n    <td>10.98</td>\n    <td>6.46</td>\n  </tr>\n  <tr>\n    <td>第二组 (仅LLM)</td>\n    <td>9.21</td>\n    <td>5.72</td>\n  </tr>\n  <tr>\n    <td>第二组 (LLM + 笔记)</td>\n    <td>6.02</td>\n    <td>4.64</td>\n  </tr>\n  <tr>\n    <td rowspan=\"2\">笔记字数</td>\n    <td>第一组 (笔记)</td>\n    <td>100.74</td>\n    <td>115.63</td>\n  </tr>\n  <tr>\n    <td>第二组 (LLM + 笔记)</td>\n    <td>103.83</td>\n    <td>158.24</td>\n  </tr>\n  <tr>\n    <td>三词重叠度 (%)</td>\n    <td colspan=\"2\">显著重叠 (≥ 70%)</td>\n    <td>25.63%</td>\n  </tr>\n  <tr>\n    <td>三词重叠度 (%)</td>\n    <td colspan=\"2\">高度重叠 (≥ 90%)</td>\n    <td>16.25%</td>\n  </tr>\n  <tr>\n    <td rowspan=\"4\">任务耗时 (分钟)</td>\n    <td>第一组 (LLM)</td>\n    <td>-0.80</td>\n    <td>95% CI [-1.15, -0.46], d = -0.34</td>\n  </tr>\n  <tr>\n    <td>第一组 (笔记)</td>\n    <td>10-15 区间</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>第二组 (仅LLM)</td>\n    <td>-1.54</td>\n    <td>95% CI [-1.91, -1.17], d = -0.66</td>\n  </tr>\n  <tr>\n    <td>第二组 (LLM + 笔记)</td>\n    <td>10-15 区间</td>\n    <td>-</td>\n  </tr>\n</table>\n\n# 2.6 学生任务指导说明\n\n表8：主动阅读策略介绍（所有实验条件通用）\n\n<table>\n  <tr>\n    <td>当您试图学习并理解一篇文章时，主动阅读（active reading）可作为一种有效策略。\n      它能帮助您更深入地处理信息，从而提升学习效果。主动阅读包括：\n      · 识别文本中的核心观点与概念\n      · 理解其含义\n      · 分析概念间的关联性\n      · 对信息提出疑问并尝试解答</td>\n  </tr>\n</table>\n\n表9：按实验条件划分的学习活动导语<table><tr><td>实验条件</td><td>活动说明</td></tr><tr><td>笔记记录</td><td>您的任务是尝试理解并学习一篇历史文本。为此，请积极阅读文本并通过记笔记来辅助学习。笔记记录是主动阅读的重要组成部分，其目的并非大量摘抄文本信息，而是需要找出章节中的关键信息，思考其含义，并用您自己的语言进行记录。</td></tr><tr><td>大语言模型</td><td>您的任务是尝试理解并学习一篇历史文本。为此，请积极阅读文本并借助AI聊天机器人进行辅助学习。与AI聊天机器人对话有助于提升阅读主动性，您可针对文本内容提出不同问题以理解历史事件的脉络，这也有助于识别和理解关键信息。</td></tr><tr><td>大语言模型+笔记记录</td><td>您的任务是尝试理解并学习一篇历史文本。为此，请结合积极阅读、AI聊天机器人和笔记记录三种方式。与AI聊天机器人对话可增强阅读主动性，通过提问深化对文本内容的理解；同时，笔记记录对主动阅读至关重要——需提取章节关键信息，进行意义阐释，并以个人语言完成记录，而非简单摘抄原文。</td></tr></table>\n\n表10：不同实验条件的具体指导说明<table><tr><td>条件</td><td>具体说明</td></tr><tr><td>笔记</td><td>在阅读过程中进行主动阅读并记录笔记。即使你认为已完全理解内容，仍需尽力而为。思考以下要点并记录以辅助理解：\n· 重要词汇与概念的含义\n· 复杂句子的释义\n· 关键要点或观点（如时间、地点、人物与事件）\n· 地点、人物与事件之间的关联\n· 事件经过及其成因与发生机制\n· 观点与概念间的异同点\n· 对文本的个人理解</td></tr><tr><td>LLM</td><td>在阅读过程中进行主动阅读并同步使用AI聊天机器人。即使你认为已完全理解内容，仍需尽力而为。思考以下要点并借助AI聊天机器人辅助理解，例如可要求其：\n· 解释重要词汇与概念的含义\n· 重构或简化复杂句子并加以说明\n· 总结文本并识别关键要点（如时间、地点、人物与事件）\n· 厘清不理解的信息\n· 阐释地点、人物与事件之间的关联\n· 说明事件经过及其成因与发生机制\n· 识别观点与概念间的异同点\n· 检验对文本的理解程度\n同时还可：\n· 若对AI回复不理解或存疑，要求进一步解释\n· 提出后续追问\n· 要求采用项目符号、缩短答复或使用更简练的语言</td></tr><tr><td>LLM+笔记</td><td>在阅读过程中同步进行主动阅读、使用AI聊天机器人及记录笔记。即使你认为已完全理解内容，仍需尽力而为。思考以下要点，并借助AI聊天机器人与笔记辅助理解，例如可要求AI：\n· 解释重要词汇与概念的含义\n· 重构或简化复杂句子并加以说明\n· 总结文本并识别关键要点（如时间、地点、人物与事件）\n· 厘清不理解的信息\n· 阐释地点、人物与事件之间的关联\n· 说明事件经过及其成因与发生机制\n· 识别观点与概念间的异同点\n· 检验对文本的理解程度\n同时还可：\n· 若对AI回复不理解或存疑，要求进一步解释\n· 提出后续追问\n· 要求采用项目符号、缩短答复或使用更简练的语言</td></tr></table>\n\n# 2.7 测试问题\n\n表11：字面保持、理解与自由回忆的示例问题<table><tr><td>构念维度</td><td>题目类型</td><td>示例题目</td></tr><tr><td colspan=\"2\">字面记忆</td><td></td></tr><tr><td></td><td>简答题</td><td>1976年索韦托青年起义中发生了什么恐怖事件？（文本A）\n肯尼迪总统在宣布古巴周边海军行动时为何避免使用\"封锁\"一词？（文本B）</td></tr><tr><td></td><td>选择题</td><td>什么事件引发了暴力的反种族隔离抗议？（文本A）\n1) 警方强制实施种族隔离\n2) 警方逮捕纳尔逊·曼德拉\n3) 警方杀害黑人平民\n4) 警方实行严格宵禁\n美国政府如何发现古巴存在苏联导弹？（文本B）\n1) 古巴线人告知导弹情报\n2) 古巴政府威胁使用导弹\n3) 美国海军拦截苏联运导弹船只\n4) 美国飞机拍摄到导弹照片</td></tr><tr><td colspan=\"2\">理解能力</td><td></td></tr><tr><td></td><td>简答题</td><td>阐述纳尔逊·曼德拉在种族隔离时期及其最终废除过程中发挥的作用。\n仅需撰写简短段落。（文本A）\n阐述苏联在古巴导弹危机中扮演的角色。\n仅需撰写简短段落。（文本B）</td></tr><tr><td colspan=\"2\">自由回忆</td><td></td></tr><tr><td></td><td>开放题</td><td>请写下你从《[标题]》一文中记住的所有内容。尽量包含尽可能多的细节。\n例如，可思考事件经过、成因、方式、时间、地点及涉及人物。\n可采用完整句子或要点形式作答。</td></tr></table>\n\n# 2.8 评分者间信度结果\n\n表12：编码者间信度<table><tr><td>项目</td><td>ICC (A,1)</td><td>p值</td><td>95%置信区间</td><td>项目</td><td>ICC (A,1)</td><td>p值</td><td>95%置信区间</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10<sup>-24</sup></td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10<sup>-32</sup></td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10<sup>-32</sup></td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10<sup>-61</sup></td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10<sup>-45</sup></td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10<sup>-43</sup></td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10<sup>-30</sup></td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10<sup>-42</sup></td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10<sup>-27</sup></td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10<sup>-36</sup></td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10<sup>-44</sup></td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10<sup>-39</sup></td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10<sup>-24</sup></td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10<sup>-33</sup></td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10<sup>-27</sup></td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10<sup>-31</sup></td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10<sup>-25</sup></td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10<sup>-39</sup></td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10<sup>-33</sup></td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10<sup>-30</sup></td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10<sup>-39</sup></td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10<sup>-40</sup></td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10<sup>-60</sup></td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10<sup>-42</sup></td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10<sup>-38</sup></td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10<sup>-33</sup></td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10<sup>-56</sup></td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 调查问题与应答量表\n\n表13：调查问题与应答量表 - 第一阶段<table><tr><td>**变量**</td><td>**问题及应答量表**</td></tr><tr><td>文本难度</td><td>您觉得关于[文章标题]的文本理解起来有多困难？\n（一点也不困难，不太困难，有些困难，比较困难，非常困难）</td></tr><tr><td>主题熟悉度</td><td>在开始任务前，您对[文章标题]主题的了解程度如何？\n（完全不了解，了解很少，了解程度一般，了解较多，非常了解）</td></tr><tr><td>主题兴趣度</td><td>您觉得关于[文章标题]的文本有多有趣？\n（一点也没趣，不太有趣，有些有趣，比较有趣，非常有趣）</td></tr><tr><td>活动愉悦度</td><td>在[活动名称]的辅助下学习文本的愉悦程度如何？\n（一点也不愉悦，不太愉悦，有些愉悦，比较愉悦，非常愉悦）</td></tr><tr><td>活动难度</td><td>总体而言，您觉得[活动名称]的难度如何？\n（一点也不困难，不太困难，有些困难，比较困难，非常困难）</td></tr><tr><td>活动帮助度</td><td>[活动名称]对理解和学习文本的帮助程度如何？\n（完全没有帮助，帮助很小，有些帮助，比较有帮助，非常有帮助）</td></tr><tr><td>活动未来使用意向</td><td>未来您是否会使用类似的方法（[活动名称]）来理解和学习文本？\n（是，否，不确定）</td></tr><tr><td>任务兴趣度</td><td>总体而言，您觉得这项任务有多有趣？\n（一点也没趣，不太有趣，有些有趣，比较有趣，非常有趣）</td></tr><tr><td>任务投入度</td><td>您在理解和学习关于[文章标题]的文本上投入了多少努力？\n（完全没有投入，只投入了一点努力，投入了一些努力，投入了较多努力，投入了非常多努力）</td></tr><tr><td>自我感知任务表现</td><td>您认为自己在这项任务中的表现如何？\n（一点也不好，不太好，一般，比较好，非常好）</td></tr><tr><td>活动偏好</td><td>第一组：在本研究的两种学习方法中，您更偏好哪一种（记笔记或AI聊天机器人）？\n（我更偏好通过记笔记学习，我更偏好借助AI聊天机器人学习，没有偏好，不确定）\n<br>\n第二组：在本研究的两种学习方法中，您更偏好哪一种（仅使用AI聊天机器人或AI聊天机器人结合记笔记）？\n（我更偏好仅借助AI聊天机器人学习，我更偏好同时借助AI聊天机器人和记笔记学习，没有偏好，不确定）</td></tr><tr><td>偏好原因</td><td>您能告诉我们为什么偏好这种方法吗？[开放式回答]</td></tr><tr><td>先前LLM使用情况</td><td>在本研究之前，您是否曾使用过AI聊天机器人（例如ChatGPT、Microsoft Bing和Google Bard AI）？\n（是，否）</td></tr><tr><td>LLM使用频率</td><td>您使用AI聊天机器人的频率大约是？\n（每周少于一次，每周一到两天，每周三到五天，几乎每天）</td></tr><tr><td>学习时记笔记频率</td><td>您在为学业（如准备课程或考试）阅读文本时，记笔记的频率如何？\n（从不，很少，有时，经常，总是）</td></tr><tr><td>学习时使用LLM频率</td><td>您在为学业（如准备课程或考试）阅读文本时，使用AI聊天机器人的频率如何？\n（从不，很少，有时，经常，总是）</td></tr><tr><td>学习时同时使用LLM与记笔记频率</td><td>仅限第二组：您在为学业阅读文本时，同时使用两种方法（使用AI聊天机器人和记笔记）的频率如何？\n（从不，很少，有时，经常，总是）</td></tr></table>表14：调查问题及应答量表 - 第二阶段\n\n<table><tr><td>变量</td><td>测量项及应答类别</td></tr><tr><td>感知测试表现</td><td>若[篇章标题]部分所有题目合计满分为100分，您预计自己大约能获得多少分？[开放性问题]</td></tr><tr><td>间歇期学习行为</td><td>自第一次实验至今，您是否通过任何方式对两篇文本的主题进行了深入探究或理解？（包括但不限于网络检索信息、课后记录笔记或与他人讨论该主题）如有相关行为，请尽可能详细说明。[开放性问题]</td></tr><tr><td>性别</td><td>您的性别是？[开放性问题]</td></tr><tr><td>EAL（英语作为附加语言）</td><td>您使用哪种语言进行交流时感觉最自如？\n（英语、英语以外的语言、英语与其他语言同样熟练）</td></tr><tr><td>历史学科背景</td><td>您是否正在攻读GCSE历史课程？（是/否）</td></tr></table>\n\n# 2.10 学习体验与认知\n\n表15：不同实验条件下（组1与组2）学习体验与认知的差异比较<table>\n<tr>\n<td rowspan=\"2\">变量</td>\n<td colspan=\"5\">组 1: LLM vs 笔记</td>\n<td colspan=\"5\">组 2: LLM vs LLM+笔记</td>\n</tr>\n<tr>\n<td>差值</td>\n<td>t(自由度)</td>\n<td>p 值</td>\n<td>95% 置信区间</td>\n<td>效应量 d</td>\n<td>差值</td>\n<td>t(自由度)</td>\n<td>p 值</td>\n<td>95% 置信区间</td>\n<td>效应量 d</td>\n</tr>\n<tr>\n<td>活动帮助性</td>\n<td>0.41</td>\n<td>4.38(181)</td>\n<td>&lt;0.001</td>\n<td>[0.22, 0.59]</td>\n<td>0.33</td>\n<td>-0.03</td>\n<td>-0.35(157)</td>\n<td>0.724</td>\n<td>[-0.21, 0.15]</td>\n<td>-0.03</td>\n</tr>\n<tr>\n<td>活动难度</td>\n<td>-0.51</td>\n<td>-7.00(181)</td>\n<td>&lt;0.001</td>\n<td>[-0.66, -0.37]</td>\n<td>-0.52</td>\n<td>-0.41</td>\n<td>-4.99(159)</td>\n<td>&lt;0.001</td>\n<td>[-0.57, -0.25]</td>\n<td>-0.40</td>\n</tr>\n<tr>\n<td>任务投入度</td>\n<td>-0.25</td>\n<td>-3.53(182)</td>\n<td>0.001</td>\n<td>[-0.38, -0.11]</td>\n<td>-0.26</td>\n<td>-0.08</td>\n<td>-1.03(159)</td>\n<td>0.305</td>\n<td>[-0.22, 0.07]</td>\n<td>-0.08</td>\n</tr>\n<tr>\n<td>活动愉悦度</td>\n<td>0.68</td>\n<td>6.50(181)</td>\n<td>&lt;0.001</td>\n<td>[0.47, 0.89]</td>\n<td>0.48</td>\n<td>0.00</td>\n<td>0.00(158)</td>\n<td>1.000</td>\n<td>[-0.16, 0.16]</td>\n<td>0.00</td>\n</tr>\n<tr>\n<td>文本兴趣度</td>\n<td>-0.11</td>\n<td>-1.38(183)</td>\n<td>0.170</td>\n<td>[-0.26, 0.05]</td>\n<td>-0.10</td>\n<td>0.06</td>\n<td>0.79(159)</td>\n<td>0.428</td>\n<td>[-0.09, 0.22]</td>\n<td>0.06</td>\n</tr>\n<tr>\n<td>文本难度</td>\n<td>0.03</td>\n<td>0.50(183)</td>\n<td>0.621</td>\n<td>[-0.10, 0.16]</td>\n<td>0.04</td>\n<td>0.03</td>\n<td>0.41(159)</td>\n<td>0.684</td>\n<td>[-0.10, 0.15]</td>\n<td>0.03</td>\n</tr>\n<tr>\n<td>任务兴趣度</td>\n<td>0.09</td>\n<td>1.01(183)</td>\n<td>0.315</td>\n<td>[-0.09, 0.27]</td>\n<td>0.07</td>\n<td>-0.06</td>\n<td>-0.79(159)</td>\n<td>0.430</td>\n<td>[-0.20, 0.08]</td>\n<td>-0.06</td>\n</tr>\n<tr>\n<td>感知任务表现</td>\n<td>0.00</td>\n<td>0.00(182)</td>\n<td>1.000</td>\n<td>[-0.14, 0.14]</td>\n<td>0.00</td>\n<td>-0.11</td>\n<td>-1.45(158)</td>\n<td>0.150</td>\n<td>[-0.25, 0.04]</td>\n<td>-0.12</td>\n</tr>\n<tr>\n<td>感知测试表现</td>\n<td>-9.66</td>\n<td>-5.53(177)</td>\n<td>&lt;0.001</td>\n<td>[-13.11, -6.22]</td>\n<td>-0.42</td>\n<td>-6.80</td>\n<td>-3.55(143)</td>\n<td>0.001</td>\n<td>[-10.59, -3.02]</td>\n<td>-0.30</td>\n</tr>\n</table>\n\n# 2.11 活动偏好编码方案\n\n表 16: 编码方案：偏好 LLM 胜过 LLM+笔记<table><tr><td>代码</td><td>描述</td><td>示例</td></tr><tr><td>单独使用LLM更快捷</td><td>单独使用大语言模型比同时记笔记更节省时间，因为记笔记会耗费额外时间。</td><td>“使用LLM耗时更少”、“记笔记太花时间”</td></tr><tr><td>二者并用非必需</td><td>当LLM已能解释文本内容时，记笔记显得不必要。</td><td>“既然机器人已帮助解释，记笔记似乎没有必要”、“使用其中一种意味着不需要另一种”</td></tr><tr><td>LLM代劳</td><td>若单独使用LLM，用户无需亲力亲为。不记笔记能使任务变得更轻松。</td><td>“不需要做任何工作”、“能立即澄清未知信息而无需仔细查阅文本”、“同时使用聊天机器人和记笔记很困难”</td></tr><tr><td>记笔记占用提问时间</td><td>记笔记会减少向LLM提问或理解文本的时间。</td><td>“记笔记时没有足够时间提问”、“有更多时间理解文本”</td></tr><tr><td>LLM不支持记笔记</td><td>LLM未能降低记笔记的难度。</td><td>“对简化记笔记过程帮助有限”</td></tr></table>\n\n表17：编码方案：LLM优于笔记的偏好维度<table><tr><td>代码</td><td>描述</td><td>示例</td></tr><tr><td>LLM 更快捷</td><td>LLM 速度更快且节省时间。</td><td>“更省时”、“快得多”</td></tr><tr><td>LLM 更简便</td><td>与需要更多精力且难度更高的笔记记录相比，LLM 操作简单且无需太多精力。</td><td>“更简单”、“它更容易操作”</td></tr><tr><td>LLM 具有（互动）主动性</td><td>LLM 是一种互动性或主动性的学习活动。</td><td>“主动与机器人互动”、“感觉更具互动性”</td></tr><tr><td>LLM 具有情感吸引力</td><td>LLM 更有趣、更令人愉悦且更具吸引力。</td><td>“喜欢阅读它的回答”、“使用起来更有趣”</td></tr><tr><td>LLM 有助于集中注意力</td><td>LLM 帮助您专注于文本内容。</td><td>“让我能更专注于文本”</td></tr><tr><td>LLM 促进理解</td><td>LLM 有助于理解并帮助您检验理解程度。</td><td>“它让你更好地理解”、“我可以确认任何不确定的内容以确保自己理解正确”</td></tr><tr><td>LLM 辅助学习</td><td>LLM 对学习具有支持作用。</td><td>“AI 帮助我更高效地学习”、“我能够更轻松快速地理解和学习文本，并达到更高水平”</td></tr><tr><td>LLM 可回答问题</td><td>LLM 因能回答问题并解释不理解的内容而对理解有帮助。</td><td>“可以提出任何相关问题”、“如果我有疑问，它都能解答”</td></tr><tr><td>LLM 可提供背景和补充信息</td><td>LLM 因能提供背景信息并详细阐述事件经过而对理解有帮助。</td><td>“我获得了更多背景信息”、“它提供了完整的背景语境”</td></tr><tr><td>LLM 可总结和简化信息</td><td>LLM 因能简化信息、重新表述内容并进行总结而对理解有帮助。</td><td>“它以更简单的方式和形式呈现”、“我可以要求 AI 聊天机器人重新表述关键点”、“它可以总结要点”</td></tr><tr><td>LLM 有助于记忆</td><td>LLM 帮助您记住文本中的信息。</td><td>“它更深刻地印在我的脑海里”、“通过提供提示性问题、记忆法等帮助我记忆”、“比笔记记录花费更少的记忆时间”</td></tr></table>\n\n表 18：编码方案：相较于 LLM 的偏好笔记<table>\n<tr>\n<td>代码</td>\n<td>描述</td>\n<td>示例</td>\n</tr>\n<tr>\n<td>笔记有助于提升记忆力</td>\n<td>记笔记有助于记忆信息，因为这是一个物理书写过程。LLM 在帮助记忆方面效果较差。</td>\n<td>“写下内容能让我记得更牢”、“更有助于培养记忆力”、“通过记笔记我学到了更多”、“只是提供了更多背景信息，而非巩固知识”。</td>\n</tr>\n<tr>\n<td>笔记促进理解</td>\n<td>记笔记有助于深化理解并检验理解程度。</td>\n<td>“更容易理解阅读内容”、“我的理解更深入了”、“通过复述来检验学习成果”。</td>\n</tr>\n<tr>\n<td>记笔记是主动学习过程</td>\n<td>记笔记是更具主动性的行为。</td>\n<td>“更好的主动阅读方式”、“让我能够主动参与”。</td>\n</tr>\n<tr>\n<td>笔记是个人劳动成果</td>\n<td>记笔记意味着独立完成工作。需要自主思考，使用个人语言并记录自身观点。</td>\n<td>“必须亲自分析信息”、“可以将信息浓缩成自己的话”、“促使我独立思考”、“这是你对所审视事物的个人见解”、“让我未来能为自己的成果感到自豪”。</td>\n</tr>\n<tr>\n<td>笔记辅助信息处理</td>\n<td>记笔记有助于信息加工处理。</td>\n<td>“能够分解和处理文本”、“自己总结第二篇文本帮助我处理信息”。</td>\n</tr>\n<tr>\n<td>笔记助力学习</td>\n<td>笔记帮助学习、记录所学或检验学习效果。</td>\n<td>“可以写下自己掌握的知识点”、“能够真正学习信息而非被动接受”。</td>\n</tr>\n<tr>\n<td>笔记便于回顾</td>\n<td>相比LLM输出内容，笔记更便于重新查阅。可轻松获取既往学习记录和思考轨迹。</td>\n<td>“复习时可以回头查看这些笔记”、“记笔记为未来提供了更好的回顾材料”。</td>\n</tr>\n<tr>\n<td>笔记操作更简便</td>\n<td>记笔记比使用LLM更简单。</td>\n<td>“更容易进行总结”、“不知道，就是更简单”。</td>\n</tr>\n<tr>\n<td>笔记增强条理性</td>\n<td>笔记有助于整理信息和思路，将其分解为小块以提升清晰度。</td>\n<td>“便于整理笔记”、“更容易追踪思维轨迹”、“帮助我将文本分解成小模块”。</td>\n</tr>\n<tr>\n<td>LLM易分散注意力且信息过载</td>\n<td>LLM容易导致分心，可能提出不相关问题或关注非重点内容。其提供过多信息，易造成认知负荷或混淆。</td>\n<td>“发现很容易被AI分散注意力，更想随意提问”、“由于信息过多导致表述不清晰”。</td>\n</tr>\n<tr>\n<td>LLM内容重复枯燥</td>\n<td>LLM因多次重复信息而显得单调乏味。</td>\n<td>“感觉它只是在不断重复”。</td>\n</tr>\n<tr>\n<td>不确定如何提问</td>\n<td>因已完全理解内容而不需要LLM，或不熟悉使用方法及提问技巧。</td>\n<td>“难以构思向AI提问的问题”、“文本非常简单因此觉得无需过多提问”。</td>\n</tr>\n</table>表19：编码方案：LLM+注释相较于LLM的偏好<table><tr><td>代码</td><td>描述</td><td>示例</td></tr><tr><td>两者结合更具趣味性</td><td>同时使用LLM和笔记更有趣、更令人愉悦，而单独使用LLM可能枯燥乏味。</td><td>“我喜欢同时使用两者”、“如果必须使用聊天机器人并询问20个问题，我会非常无聊。”</td></tr><tr><td>两者结合实现优势互补</td><td>LLM和笔记可以互补使用以发挥各自优势，例如先自主完成工作，在不确定或遇到困难时再使用LLM。</td><td>“同时拥有自己总结的关键笔记和更详细的文本会更方便”、“这种方式让我既能以自己理解的方式记录事件关键点，又能就模糊内容获得AI聊天机器人的帮助”</td></tr><tr><td>两者结合更高效便捷</td><td>关于该策略对理解和学习更具帮助、更优越或更便捷的总体评价。</td><td>“最具帮助性且易于学习”、“因为我觉得这种方式更容易记忆和学习”</td></tr><tr><td>笔记辅助处理和理解LLM信息</td><td>笔记有助于处理和理解LLM提供的信息。</td><td>“为了处理这些信息，我发现同时做笔记非常有帮助”</td></tr><tr><td>笔记有助于信息组织</td><td>LLM提供信息，但需要笔记来整理和构建思路。笔记更具聚焦性且易于查阅。</td><td>“如果仅使用聊天机器人，我需要不断滚动屏幕查找内容”、“这样更容易跟踪信息并进行回顾”</td></tr><tr><td>笔记体现个人劳动</td><td>做笔记意味着进行实际工作，能够捕捉个人思考而非仅仅阅读输出内容。</td><td>“这代表我确实在进行实际工作”</td></tr><tr><td>笔记辅助记忆</td><td>笔记有助于信息记忆。</td><td>“我喜欢手写记录信息，因为这能帮助我更好地记忆”</td></tr><tr><td>笔记促进理解</td><td>做笔记有助于深化理解并检验理解程度。</td><td>“在纸上简化信息使其更易于理解和记忆”</td></tr><tr><td>笔记助力学习</td><td>笔记有助于学习过程，能够捕捉学习成果或检验学习效果。</td><td>“这样能学到更多”、“可以在笔记中简化所学内容”</td></tr><tr><td>LLM可能提供错误答案</td><td>LLM并非总能良好回答问题，有时甚至完全无法应答。LLM可能产生有害内容。</td><td>“我对机器人提出的某些问题没有得到明确回答”</td></tr><tr><td>LLM并非始终可用</td><td>需要掌握笔记技能，因为LLM可能无法随时使用。</td><td>“你不可能随时都有AI聊天机器人可用”</td></tr><tr><td>不确定如何向机器人提问</td><td>因已完全理解内容而不需要LLM，或不了解其使用方法及提问方式。</td><td>“我不确定该对机器人说什么，这有点令人烦躁”</td></tr></table># 2.12 编码方案提示交互\n\n完整提示编码方案请参阅表格文件 'PromptCoding.xlsx'\n\n表20：提示编码方案\n\n<table>\n  <tr>\n    <td>总体编码</td>\n    <td>子编码</td>\n    <td>描述与示例</td>\n  </tr>\n  <tr>\n    <td>信息浓缩</td>\n    <td>总结</td>\n    <td>学生要求机器人总结整篇文本或特定文本选段。\n    示例：“帮我总结这一段”、“总结文本”、“给我第一段的摘要”、“告诉我这篇文章是关于什么的。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>记笔记</td>\n    <td>学生要求机器人就整篇文本或特定段落做笔记。\n    示例：“为第一段做笔记。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>识别关键观点</td>\n    <td>学生要求机器人识别文本中的关键观点或要点信息，包括关键日期、地点、人物和事件。\n    示例：“主要观点是什么？”、“给我所有重要的日期”、“要点信息是什么？”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>创建时间线</td>\n    <td>学生要求机器人创建文本中描述事件的时间线。\n    示例：“将重要日期按时间顺序排列”、“给我事件的时间线。”</td>\n  </tr>\n  <tr>\n    <td>理解文本</td>\n    <td>定义词语或概念</td>\n    <td>学生要求机器人定义或解释文本中的特定词语或概念。他们请求帮助理解术语，但不寻求超出此范围的事实信息。\n    示例：“apartheid是什么意思？”、“什么是殖民地？”、“什么是导弹？”、“我不知道blockade是什么意思。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>简化或解释难句</td>\n    <td>学生要求机器人简化或解释所提供的段落或特定选段。\n    示例：“用简单的词语解释这个”、“让文本更简单”、“这个句子是什么意思？”、“简化这段文本。”</td>\n  </tr>\n  <tr>\n    <td></td>\n    <td>检查理解</td>\n    <td>学生阐述自己的理解并向机器人寻求确认。\n    示例：“美国不喜欢古巴是因为他们认为卡斯特罗是共产主义者，对吗？”、“所以是一名军官阻止了整个战争？”</td>\n  </tr>\n  <tr>\n    <td>寻求额外信息与深化理解</td>\n    <td>一般背景</td>\n    <td>学生要求提供文本中提及的地点、时间或人物的背景信息以提供上下文——这些信息对于理解文本并非核心，但可能相关。\n    示例：“肯尼迪是谁？”、“曼德拉因何闻名？”、“告诉我更多关于古巴的信息”、“非洲有多少英国殖民地？”、“土耳其的导弹部署在哪里？”</td>\n  </tr>\n</table>\n\n转下页<table>\n<tr>\n  <td><strong>主代码</strong></td>\n  <td><strong>子代码</strong></td>\n  <td><strong>描述与示例</strong></td>\n</tr>\n<tr>\n  <td rowspan=\"4\">寻求补充信息与深化理解</td>\n  <td>阐述与深化理解</td>\n  <td>学生要求获取事件的更多细节，例如事件原因、涉及人物及结果。<br>示例：“美国为什么不喜欢卡斯特罗？”“流亡者为何入侵古巴？”“种族隔离期间黑人的感受如何？”</td>\n</tr>\n<tr>\n  <td>请求示例或类比</td>\n  <td>学生要求通过示例或类比来更好地理解概念或事件。<br>示例：“种族隔离影响日常生活的具体案例有哪些？”“能否用类比说明冷战紧张局势？”“通过了哪些不公正法律？”“有哪些抵制运动？”</td>\n</tr>\n<tr>\n  <td>请求对比或比较</td>\n  <td>学生要求对比或比较概念、事件或人物。<br>示例：“种族隔离与美国种族隔离有何不同？”“比较肯尼迪与赫鲁晓夫的领导风格。”</td>\n</tr>\n<tr>\n  <td>批判性分析或评价</td>\n  <td>学生要求对行动、情境、决策或陈述进行批判性分析或评价。<br>示例：“肯尼迪决策的优缺点是什么？”“评估封锁行动的有效性。”</td>\n</tr>\n<tr>\n  <td>影响与意义</td>\n  <td>影响与意义</td>\n  <td>学生询问文本信息的深层影响、相关性或后果。<br>示例：“这场危机的长期影响是什么？”“当前局势如何？”“为什么我需要关注或学习这个内容？”</td>\n</tr>\n<tr>\n  <td>学习与记忆辅助</td>\n  <td>学习与记忆辅助</td>\n  <td>学生请求辅助学习并记忆文本内容，包括要求进行知识测验。<br>示例：“创建记忆口诀”“提出四个关于文本的问题”“如何更好地记住这些内容？”</td>\n</tr>\n<tr>\n  <td rowspan=\"3\">与机器人交互</td>\n  <td>要求特定格式或长度</td>\n  <td>学生要求机器人以特定格式或长度提供回复。<br>示例：“用要点总结主要内容”“能否制作政策对比图表？”“请用简短表述”“请缩短内容”</td>\n</tr>\n<tr>\n  <td>要求改进表达</td>\n  <td>学生要求机器人优化回复或改用更简洁的方式重述，而非要求简化给定文本。<br>示例：“我不理解你的意思”“请用更简短的方式重新解释”“你的意思是？”“请说得更简单”“能用更简单的术语表达吗？”“请缩短摘要”</td>\n</tr>\n<tr>\n  <td>关系性语言</td>\n  <td>学生进行与文本无关的随意礼貌对话。<br>示例：“你好吗？”“谢谢”“你好”</td>\n</tr>\n</table>\n\n（接下页）<table><tr><td>主编码</td><td>子编码</td><td>描述与示例</td></tr><tr><td rowspan=\"2\">与AI交互</td><td>核查来源与可信度</td><td>学生询问信息来源或质疑信息准确性<br>示例：\"你的信息来源是什么？\"、\"我为什么要相信你？\"、\"我认为你的答案是错误的\"</td></tr><tr><td>无特定请求的文本粘贴</td><td>学生直接复制所提供段落中的文本，但未将其构建为具体问题或请求<br>示例：\"纳尔逊·曼德拉\"、\"1910年，四个英国殖民地合并成立南非联邦\"、\"导弹\"</td></tr><tr><td rowspan=\"3\">无关内容/离题/杂项</td><td>与文本无关</td><td>学生提出与文本或其背景无关的问题<br>示例：\"切·格瓦拉是谁？\"、\"歌曲《阿布拉克萨斯》是什么？\"</td></tr><tr><td>杂项</td><td>用于无法归类至其他编码的对话片段（最后选择）</td></tr><tr><td>无意义输入</td><td>学生输入无意义的字符、符号或无法构成连贯词句的文本<br>示例：\"asdfgh\"、\"。\"、\"123\"、\"？？？\"</td></tr></table>\n\n# 2.13 提示类型频次分析\n\n表21：主要提示类型出现频次  \n\n<table><tr><td>主要提示类型</td><td>频次</td></tr><tr><td colspan=\"2\"><strong>原型类别</strong></td></tr><tr><td>寻求补充信息与深度理解</td><td>2265</td></tr><tr><td>信息浓缩</td><td>749</td></tr><tr><td>文本理解</td><td>615</td></tr><tr><td>学习与记忆辅助</td><td>39</td></tr><tr><td colspan=\"2\"><strong>其他类别</strong></td></tr><tr><td>与AI交互</td><td>760</td></tr><tr><td>无关内容/离题/杂项</td><td>501</td></tr></table>\n\n表22：具体提示类型出现频次<table><tr><td>总体提示类型</td><td>具体提示类型</td><td>频次</td></tr><tr><td>寻求补充信息与深度理解</td><td>细节阐述与深度理解</td><td>1479</td></tr><tr><td>信息浓缩</td><td>总结归纳</td><td>588</td></tr><tr><td>寻求补充信息与深度理解</td><td>背景知识</td><td>514</td></tr><tr><td>文本理解</td><td>定义词汇或概念</td><td>463</td></tr><tr><td>与机器人交互</td><td>要求特定格式或长度</td><td>430</td></tr><tr><td>无关/离题/杂项</td><td>与文本无关</td><td>296</td></tr><tr><td>文本理解</td><td>简化或解释难句</td><td>126</td></tr><tr><td>寻求补充信息与深度理解</td><td>隐含意义与重要性</td><td>119</td></tr><tr><td>信息浓缩</td><td>识别核心观点</td><td>114</td></tr><tr><td>与机器人交互</td><td>要求改进</td><td>113</td></tr><tr><td>与机器人交互</td><td>无特定要求的文本粘贴</td><td>106</td></tr><tr><td>与机器人交互</td><td>关系性语言</td><td>105</td></tr><tr><td>无关/离题/杂项</td><td>无意义输入</td><td>109</td></tr><tr><td>无关/离题/杂项</td><td>杂项</td><td>96</td></tr><tr><td>寻求补充信息与深度理解</td><td>要求示例或类比</td><td>66</td></tr><tr><td>寻求补充信息与深度理解</td><td>批判性分析或评估</td><td>54</td></tr><tr><td>学习与记忆辅助</td><td>学习与记忆辅助</td><td>39</td></tr><tr><td>寻求补充信息与深度理解</td><td>要求对比或比较</td><td>31</td></tr><tr><td>文本理解</td><td>理解程度确认</td><td>26</td></tr><tr><td>信息浓缩</td><td>笔记整理</td><td>26</td></tr><tr><td>信息浓缩</td><td>创建时间线</td><td>21</td></tr><tr><td>与机器人交互</td><td>核查来源与可信度</td><td>6</td></tr></table>\n\n注：本表仅收录学生使用次数达到三次及以上的提示类型。",
    "created_at": "2025-12-16 00:10:45.083196",
    "updated_at": "2025-12-16 00:11:18.114993",
    "doi": "10.1186/s41239-023-00408-3",
    "arxiv_id": "2401.15081",
    "analysis": {
      "paper_id": "1daa7fa3-52d8-4ad3-bad2-545c83a3c45e",
      "status": "completed",
      "started_at": "2025-12-16T00:35:26.593835",
      "completed_at": "2025-12-16T00:35:39.405634",
      "summary": "本研究旨在探讨在中学教育环境中，使用大型语言模型（LLMs）与传统笔记记录对学生的阅读理解能力和记忆保持的影响。研究采用预注册的随机对照实验，对405名14-15岁的学生进行了测试，比较了单独使用LLM、单独做笔记以及两者结合使用三种学习方式的效果。\n\n研究发现，与单独使用LLM相比，单独做笔记以及将笔记与LLM结合使用，在三天后的记忆保持和阅读理解测试中都产生了显著更积极的效果。然而，大多数学生主观上更偏好并认为LLM更有帮助。定性分析表明，学生认为LLM有助于降低认知负荷、使复杂材料更易理解，而笔记则能促进更深层次的投入并辅助记忆。研究还识别了学生与LLM交互的不同提示行为“原型”。\n\n结论指出，虽然笔记更能促进认知投入和长期的知识理解与记忆，但LLM可能在辅助初步理解和激发学生兴趣方面具有优势。研究强调了传统学习方法的重要性，揭示了结合使用AI与传统方法优于单独使用AI，并指出学生需要掌握相应的AI使用技能以最大化学习收益。",
      "methods": [
        {
          "name": "随机对照实验",
          "description": "采用预注册的随机对照实验设计，包含组内和组间设计元素。研究在中学环境中进行，比较不同学习策略对阅读理解的影响。",
          "location": null
        },
        {
          "name": "定量分析",
          "description": "通过阅读理解测试和记忆保持测试收集定量数据。使用统计方法分析不同学习条件对学习效果的影响。",
          "location": null
        },
        {
          "name": "定性分析",
          "description": "通过学生反馈和观察收集定性数据，分析学生对不同学习方法的感知和体验。识别学生与LLM交互的提示行为原型。",
          "location": null
        },
        {
          "name": "建构-整合模型分析",
          "description": "基于阅读理解的建构-整合模型，分析学生在表面结构、文本基础和情境模型三个层次的理解。",
          "location": null
        },
        {
          "name": "处理水平框架分析",
          "description": "运用处理水平框架分析信息编码深度对记忆保持的影响，关注语义分析和深度处理的作用。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "Affiliations:",
            "level": 1,
            "start_line": 9
          },
          {
            "title": "Abstract",
            "level": 1,
            "start_line": 14
          },
          {
            "title": "Main",
            "level": 1,
            "start_line": 18
          },
          {
            "title": "Results",
            "level": 1,
            "start_line": 46
          },
          {
            "title": "Learning outcomes",
            "level": 1,
            "start_line": 50
          },
          {
            "title": "Behavioural engagement",
            "level": 1,
            "start_line": 71
          },
          {
            "title": "Prompting behaviour",
            "level": 1,
            "start_line": 75
          },
          {
            "title": "Learning experiences and perceptions",
            "level": 1,
            "start_line": 93
          },
          {
            "title": "Activity preferences",
            "level": 1,
            "start_line": 109
          },
          {
            "title": "Future use",
            "level": 1,
            "start_line": 121
          },
          {
            "title": "Discussion",
            "level": 1,
            "start_line": 125
          },
          {
            "title": "Materials and Methods",
            "level": 1,
            "start_line": 153
          },
          {
            "title": "Participants",
            "level": 1,
            "start_line": 157
          },
          {
            "title": "Experimental design and procedure",
            "level": 1,
            "start_line": 165
          },
          {
            "title": "Setup and system",
            "level": 1,
            "start_line": 193
          },
          {
            "title": "Apartheid in South Africa",
            "level": 1,
            "start_line": 199
          },
          {
            "title": "AI Chatbot ②",
            "level": 1,
            "start_line": 209
          },
          {
            "title": "Notepad",
            "level": 1,
            "start_line": 213
          },
          {
            "title": "Learning task and materials (Session 1)",
            "level": 1,
            "start_line": 228
          },
          {
            "title": "Test task and materials (Session 2)",
            "level": 1,
            "start_line": 242
          },
          {
            "title": "Survey questions",
            "level": 1,
            "start_line": 256
          },
          {
            "title": "Analytic strategies",
            "level": 1,
            "start_line": 264
          },
          {
            "title": "Estimation of condition effects on text comprehension and retention",
            "level": 1,
            "start_line": 270
          },
          {
            "title": "Qualitative exploration of student prompts",
            "level": 1,
            "start_line": 302
          },
          {
            "title": "Quantitative exploration of students' learning experience",
            "level": 1,
            "start_line": 308
          },
          {
            "title": "Qualitative exploration of students' activity preferences",
            "level": 1,
            "start_line": 312
          },
          {
            "title": "Data availability",
            "level": 1,
            "start_line": 325
          },
          {
            "title": "Code availability",
            "level": 1,
            "start_line": 329
          },
          {
            "title": "Ethics declarations",
            "level": 1,
            "start_line": 333
          },
          {
            "title": "Competing interests",
            "level": 1,
            "start_line": 335
          },
          {
            "title": "Acknowledgements",
            "level": 1,
            "start_line": 339
          },
          {
            "title": "Supplementary Material",
            "level": 1,
            "start_line": 343
          },
          {
            "title": "Table of Contents",
            "level": 1,
            "start_line": 345
          },
          {
            "title": "Supplementary Information",
            "level": 1,
            "start_line": 347
          },
          {
            "title": "Supplementary Tables",
            "level": 1,
            "start_line": 351
          },
          {
            "title": "References",
            "level": 1,
            "start_line": 374
          },
          {
            "title": "1 Supplementary Information",
            "level": 1,
            "start_line": 451
          },
          {
            "title": "1.1 Participant Exclusion Criteria",
            "level": 1,
            "start_line": 453
          },
          {
            "title": "2 Supplementary Tables",
            "level": 1,
            "start_line": 464
          },
          {
            "title": "2.1 Student Characteristics",
            "level": 1,
            "start_line": 466
          },
          {
            "title": "2.2 Familiarity with Learning Activities",
            "level": 1,
            "start_line": 475
          },
          {
            "title": "2.3 Descriptive Statistics",
            "level": 1,
            "start_line": 483
          },
          {
            "title": "2.4 Mixed Effects Regression Results",
            "level": 1,
            "start_line": 489
          },
          {
            "title": "2.5 Behavioural Engagement",
            "level": 1,
            "start_line": 495
          },
          {
            "title": "2.6 Student Task Instructions",
            "level": 1,
            "start_line": 501
          },
          {
            "title": "2.7 Test Questions",
            "level": 1,
            "start_line": 567
          },
          {
            "title": "2.8 Inter-rater Reliability Results",
            "level": 1,
            "start_line": 589
          },
          {
            "title": "2.9 Survey Questions and Response Scales",
            "level": 1,
            "start_line": 595
          },
          {
            "title": "2.10 Learning Experiences and Perceptions",
            "level": 1,
            "start_line": 624
          },
          {
            "title": "2.11 Coding Scheme Activity Preferences",
            "level": 1,
            "start_line": 630
          },
          {
            "title": "2.12 Coding Scheme Prompt Interactions",
            "level": 1,
            "start_line": 653
          },
          {
            "title": "2.13 Frequency of Prompt Types",
            "level": 1,
            "start_line": 691
          }
        ]
      },
      "error_message": null
    },
    "is_translated": true,
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:281913760",
          "title": "Exploring the impact of artificial intelligence on business talent development in higher education:A systematic literature review and research agenda",
          "authors": [
            "Qinglan Wu",
            "Lanzhen Chen",
            "Minwei Chen",
            "Yangjie Huang"
          ],
          "year": 2026,
          "venue": "The International Journal of Management Education",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282741200",
          "title": "Revolutionizing business English instruction",
          "authors": [
            "Bendaoud Nadif",
            "Abderrahim Khoumich"
          ],
          "year": 2026,
          "venue": "American Journal of STEM Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283183996",
          "title": "Changing EAP assessment practices in the age of generative artificial intelligence: The case of Scottish higher education institutions",
          "authors": [
            "Lewis Urquhart",
            "X. M. Ngo"
          ],
          "year": 2026,
          "venue": "Journal of English for Academic Purposes",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283778482",
          "title": "Ethics and governance of generative AI in education: a systematic review on responsible adoption",
          "authors": [
            "Mohanad Alfiras",
            "Abdul Qader Emran",
            "Amr M. Mohamed"
          ],
          "year": 2025,
          "venue": "Discover Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283782189",
          "title": "Research on the refinement of college student education management based on artificial intelligence",
          "authors": [
            "Qiujia Lai"
          ],
          "year": 2025,
          "venue": "Discover Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283806994",
          "title": "Use of Technology for the Effectiveness of School Support Systems in Addressing Barriers to Learning",
          "authors": [
            "L. Tlale"
          ],
          "year": 2025,
          "venue": "Journal of Education and Learning Technology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283850330",
          "title": "Latent Dimensions of Innovation and Development in Selected Eastern European Countries: A Perspective Based on an Analysis of the Main Factors",
          "authors": [
            "C. Stoenoiu",
            "L. Jäntschi"
          ],
          "year": 2025,
          "venue": "World",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283812503",
          "title": "Development and Validation of an AI Literacy Scale for Pre-Service Teachers in Thailand",
          "authors": [
            "Pawarit Pingmuang",
            "Prakob Koraneekij",
            "Jintavee Khlaisang"
          ],
          "year": 2025,
          "venue": "Electronic Journal of e-Learning",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283702829",
          "title": "Transfer learning and AI technology for family school community collaborative model research in university network security management.",
          "authors": [
            "Qiongfang Feng",
            "Yang'an Chen"
          ],
          "year": 2025,
          "venue": "Scientific Reports",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283684161",
          "title": "Identifying key components and stakeholders for generative AI governance in higher education: a systematic literature review",
          "authors": [
            "Okky Putra Barus",
            "A. Hidayanto",
            "Imairi Eitiveni",
            "Kongkiti Phusavat",
            "Niko Sudibjo"
          ],
          "year": 2025,
          "venue": "Interactive Learning Environments",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T15:20:51.244989",
      "references": [
        {
          "external_id": "CorpusId:257943792",
          "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
          "authors": [
            "Tufan Adiguzel",
            "M. H. Kaya",
            "Fatih Kursat Cansu"
          ],
          "year": 2023,
          "venue": "Contemporary Educational Technology",
          "citation_count": 596
        },
        {
          "external_id": "CorpusId:259466894",
          "title": "Student partnership in assessment in higher education: a systematic review",
          "authors": [
            "C. Chan",
            "Si Chen"
          ],
          "year": 2023,
          "venue": "Assessment &amp; Evaluation in Higher Education",
          "citation_count": 20
        },
        {
          "external_id": "CorpusId:259088596",
          "title": "Is AI Changing the Rules of Academic Misconduct? An In-depth Look at Students' Perceptions of 'AI-giarism'",
          "authors": [
            "C. Chan"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 45
        },
        {
          "external_id": "CorpusId:258480115",
          "title": "The AI generation gap: Are Gen Z students more interested in adopting generative AI such as ChatGPT in teaching and learning than their Gen X and millennial generation teachers?",
          "authors": [
            "C. Chan",
            "Katherine K. W. Lee"
          ],
          "year": 2023,
          "venue": "Smart Learning Environments",
          "citation_count": 385
        },
        {
          "external_id": "CorpusId:258436716",
          "title": "The AI Revolution in Education: Will AI Replace or Assist Teachers in Higher Education?",
          "authors": [
            "C. Chan",
            "Louisa H.Y. Tsi"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 119
        },
        {
          "external_id": "CorpusId:258437002",
          "title": "Deconstructing Student Perceptions of Generative AI (GenAI) through an Expectancy Value Theory (EVT)-based Instrument",
          "authors": [
            "C. Chan",
            "Wenxin Zhou"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 40
        },
        {
          "external_id": "CorpusId:258426653",
          "title": "Students’ voices on generative AI: perceptions, benefits, and challenges in higher education",
          "authors": [
            "C. Chan",
            "Wenjie Hu"
          ],
          "year": 2023,
          "venue": "International Journal of Educational Technology in Higher Education",
          "citation_count": 1159
        },
        {
          "external_id": "CorpusId:258240392",
          "title": "Generative AI",
          "authors": [
            "Stefan Feuerriegel",
            "Jochen Hartmann",
            "Christian Janiesch",
            "Patrick Zschech"
          ],
          "year": 2023,
          "venue": "Business & Information Systems Engineering",
          "citation_count": 974
        },
        {
          "external_id": "CorpusId:257953233",
          "title": "Implications of large language models such as ChatGPT for dental medicine.",
          "authors": [
            "F. Eggmann",
            "R. Weiger",
            "N. Zitzmann",
            "M. Blatz"
          ],
          "year": 2023,
          "venue": "Journal of Esthetic and Restorative Dentistry",
          "citation_count": 214
        },
        {
          "external_id": "CorpusId:258568566",
          "title": "Threats by artificial intelligence to human health and human existence",
          "authors": [
            "F. Federspiel",
            "Ruth Mitchell",
            "Asha Asokan",
            "Carlos Umaña",
            "D. mccoy"
          ],
          "year": 2023,
          "venue": "BMJ Global Health",
          "citation_count": 109
        }
      ],
      "references_fetched_at": "2025-12-16T15:20:51.975105"
    }
  },
  "02197db0-3de5-4390-9690-609c0f31a4c1": {
    "id": "02197db0-3de5-4390-9690-609c0f31a4c1",
    "filename": "learnLM_nov25.pdf",
    "file_path": "./uploads/papers/02197db0-3de5-4390-9690-609c0f31a4c1.pdf",
    "status": "completed",
    "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
    "category": null,
    "markdown_content": "# AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms\n\nLearnLM Team, Google & Eedi\n\nOne-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with  $N = 165$  students across five UK secondary schools. We integrated LearnLM—a generative AI model fine-tuned for pedagogy—into chat-based tutoring sessions on the Eedi mathematics platform. In the RCT, expert tutors directly supervised LearnLM, with the remit to revise each message it drafted until they would be satisfied sending it themselves. LearnLM proved to be a reliable source of pedagogical instruction, with supervising tutors approving  $76.4\\%$  of its drafted messages making zero or minimal edits (i.e., changing only one or two characters). This translated into effective tutoring support: students guided by LearnLM performed at least as well as students chatting with human tutors on each learning outcome we measured. In fact, students who received support from LearnLM were 5.5 percentage points more likely to solve novel problems on subsequent topics (with a success rate of  $66.2\\%$ ) than those who received tutoring from human tutors alone (rate of  $60.7\\%$ ). In interviews, tutors highlighted LearnLM's strength at drafting Socratic questions that encouraged deeper reflection from students, with multiple tutors even reporting that they learned new pedagogical practices from the model. Overall, our results suggest that pedagogically fine-tuned AI tutoring systems may play a promising role in delivering effective, individualized learning support at scale.\n\nKeywords: learning, efficacy, safety, artificial intelligence, tutoring, randomized controlled trial\n\n# 1. Introduction\n\nOne-to-one tutoring is the gold standard for supporting students' learning and education. Decades of research demonstrate that individualized tutoring results in substantial gains in learning [1-3]. Unfortunately, the high cost of one-to-one tutoring and relative scarcity of educators makes this support inaccessible for most students and classrooms. The tension between tutoring's effectiveness and inaccessibility presents an enduring challenge for education systems: can educators deliver individualized support in a way that is both highly effective and broadly scalable?\n\nA growing number of researchers and practitioners now look to generative AI (\"genAI\") as a potential solution to this challenge [4-7]. Indeed, a wave of new tutoring systems incorporate genAI for direct interactivity with students [8]. Yet rigorous, in-classroom research on the learning efficacy of genAI remains scarce [9]. The evidence that does exist is mixed: while some studies suggest genAI can offer effective instruction [10-13], others find that deploying genAI tutoring systems without appropriate pedagogical safeguards can actively harm learning [14, 15].\n\nHere we report the results of an exploratory randomized controlled trial (RCT) with  $N = 165$  students, designed specifically to evaluate if an AI tutor can safely and effectively support students in UK secondary school classrooms. Our study took place on the Eedi educational platform, an evidence-based learning ecosystem that provides students with both curriculum-aligned mathematics activities and one-to-one support from remote human tutors via online chat conversations. In our experiment, we tested whether LearnLM—a genAI model fine-tuned for pedagogical applications [16-18]—could help scale this assistance. To ensure a high standard\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/ba862453a67072232f0aaf7d3a23dcba16885aa56c81db0e9542baf4eadd35c2.jpg)  \n(a)\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/7cd7d69be6f0bc15cc071896a794c47a1ad47ad16bbb942dea22e9864fc8c626.jpg)  \n(b)  \nFigure 1 | We designed this exploratory RCT to evaluate the safety, pedagogy, and efficacy of LearnLM. (a) The RCT randomly assigned each of  $N = 165$  students to receive either static hints or interactive tutoring. Students in the tutoring condition experienced a further level of randomization. When they started a tutoring session, the platform randomly assigned them to either a session with a human tutor or a session with LearnLM (supervised by a human tutor). This design allows us to compare static, pre-written support against interactive tutoring, as well as human tutoring against (supervised) tutoring from LearnLM. (b) In sessions with LearnLM, a supervising tutor reviewed each message that LearnLM drafted. They could either edit the message, completely re-write it, or approve it without any changes. The Eedi platform then sent the message to the student.\n\nof safety and pedagogy for all students in our trial,  $N = 17$  expert human tutors directly supervised LearnLM, assuming ultimate responsibility for every interaction it had with students. In particular, the tutors appraised each message that LearnLM generated, retaining full control to approve, edit, or replace it before it reached the student.\n\nLearnLM proved to be a trustworthy source of pedagogical instruction, with the supervising tutors approving over  $76\\%$  of its messages without changes or with only minimal edits (changing one or two characters; e.g., deleting an emoji). In fact, across all of the learning outcomes we measured, supervised support from LearnLM proved at least as effective as guidance from a human tutor. Most surprisingly, students tutored by LearnLM exhibited measurably better knowledge transfer than those receiving support from human tutors alone. On average, supervised support from LearnLM improved the probability of a student solving a novel problem correctly by 5.5 percentage points over guidance from a human tutor.\n\nTo better understand this broad effectiveness, we surveyed and interviewed the supervising tutors for their perspectives on LearnLM. They reported that LearnLM consistently generated high-quality, Socratic dialogue, providing a strong foundation for academic interactions with students. The supervising tutors' interventions tended to focus on moderating the dialogue's pacing and providing the social and emotional nuance required to maintain student engagement.\n\nOverall, our exploratory RCT identifies several avenues for new research on AI and education, while also suggesting a potential role for genAI tutors in delivering effective, individualized learning support at scale.\n\n# 2. An Exploratory Classroom Trial\n\nOur RCT aimed to evaluate LearnLM in a rigorous, real-world, in-classroom testbed. Hundreds of secondary schools in the UK integrate the Eedi learning platform directly into their mathematics instruction. The platform provides students with curriculum-aligned study units and a spectrum of personalized support, including two forms of assistance central to this RCT: carefully designed hints for common misconceptions in each study unit, and one-to-one guidance from trained, expert tutors via online chat interactions. Students who receive this standard support on the Eedi platform experience the equivalent of two additional months of academic progress, with the impact doubling for highly engaged students [19]. We recruited  $N = 165$  students in Year 9 and 10 (ages 13-15) across five of these schools for the RCT (see Appendix A). Each student and each tutor provided informed consent to participate in the trial. The trial ran from May through June 2025.\n\nThe trial leveraged these two forms of Eedi support—hints and chat-based tutoring (\"hybrid tutoring\" [20])—as baselines to assess the pedagogical efficacy of LearnLM (see Figure B.1 in Appendix B). During the trial period, we randomly assigned each student either to receive static pedagogical support (pre-written hints) or to enter an interactive one-to-one tutoring session (Figure 1; see also Appendix B). Students in the tutoring condition experienced a further level of randomization: when a student entered a tutoring session, we randomly connected them either with an expert human tutor or with LearnLM (supervised by a human tutor). We prompted LearnLM to adopt a Socratic approach aimed at guiding the student to identify their own mistake, and provided the model access to the full question text, the student's incorrect answer, and explanations for both the student and a teacher about the misconception underlying the incorrect answer, among other information (see Appendix D.1).\n\nOur approach allowed us to pose a set of four research questions:\n\nRQ1: Was LearnLM a reliable and pedagogically sound source of instruction?  \nRQ2: Was interactive tutoring (whether delivered by a human tutor alone or in a supervised session with LearnLM) more effective for student learning than static pedagogical support?  \nRQ3: For students receiving interactive tutoring, was support from a supervised session with LearnLM more effective than support from a human tutor working alone?  \nRQ4: What can we learn from tutor and student experiences of interacting with LearnLM?\n\nTo answer these questions, we adopted a Bayesian framework and directly estimated the magnitude and credibility of our treatment effects. Unlike standard frequentist approaches, this method allows us to calculate the probability that one intervention outperforms another by a specific magnitude, providing a more practical foundation for making decisions about real-world deployment. For all analyses, we assigned identical, weakly informative priors to each intervention. We then used the resulting posterior distributions to calculate the exact probability that outcomes in one group exceeded those in another, providing a more precise signal than a simple comparison of the intervals (cf. [21-23]). For complete experimental details, see Methods and Appendices A-D.\n\n# 3. Results\n\nWe first verified the basic safety and quality of LearnLM's tutoring (RQ1) by auditing the full corpus of 3,617 messages that it drafted, as well as the supervising tutors' decisions to approve, edit, or rewrite those messages. LearnLM proved a trustworthy source of instruction. The tutors who supervised and reviewed its messages accepted  $74.4\\%$  without any edits. As judged by edit distance [24, 25], many of the  $k = 926$  instances where tutors edited or rewrote a suggestion reflected minor or targeted adjustments (see Table E.1 for examples). The two most frequent edit distances, accounting for  $5.5\\%$  and  $2.4\\%$  of re-writes, were just a single character and two characters, respectively; these virtually always reflected a tutor deleting or changing an emoji. The median intervention altered 59 characters, or just a few words. Still, after the RCT finished, we asked the supervising tutors to systematically review the corpus of edits and re-writes. This review revealed zero instances of harmful or risky content and only five factual errors, or  $0.1\\%$  of the total 3,617 messages that LearnLM drafted (see Table E.2 in Appendix E). Overall, a close audit confirmed that LearnLM provided safe and reliable guidance during the trial.\n\nNext, we evaluated effects on student learning (RQ2, RQ3), comparing students' performance after receiving one of the standard interventions on the Eedi platform or interacting with LearnLM. As described in Methods, students worked through a series of short study units, each consisting of several multiple-choice questions\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/ed199f16be5726a6454db27da9cb49c9e1216b18a4a7d74889608eb2254ca013.jpg)  \nFigure 2 | Student progression through the study unit. If a student makes a mistake on the first question in a study unit, they receive a support intervention. We analyze whether the intervention helps the student identify and remediate their mistake, resolve the misconception underlying their incorrect choice, and transfer the knowledge from the intervention to the next study unit. See Methods and Appendix C for more information on the Eedi platform.\n\ndesigned to assess a specific mathematical topic (Figure 2). Whenever a student answered the first question in a unit incorrectly, the platform triggered a support intervention. Depending on their assigned condition, students either received a static, pre-written hint specific to their mistake on that question, or an interactive (chat-based) session with a tutor. Immediately following the intervention, the platform presented the student with the exact same question and prompted them to try answering it again.\n\nEchoing prior research [3], interactive support with a human tutor proved far more effective for this kind of immediate course-correction. Students who joined a real-time session with a human tutor were substantially more likely to correct their mistakes than were those who received a static, pre-written hint (see Figure 3, left). In particular,  $91.2\\%$  of students who received interactive support from a human tutor solved the problem correctly on their second attempt (with a  $95\\%$  credible interval of  $[88.5\\%, 93.6\\%]$ ), compared to only  $65.4\\%$ $[63.8\\%, 66.9\\%]$  of students who received a static hint. Supervised instruction from LearnLM proved just as effective at helping students correct their mistakes. Students receiving guidance from LearnLM answered their second attempt correctly  $93.0\\%$ $[90.4\\%, 95.3\\%]$  of the time. (For context, simply eliminating the previous mistake and guessing from the remaining options would yield an expected success rate of  $33.3\\%$ .)\n\nIf a student still answered the question incorrectly on their second attempt, the platform provided them with several additional opportunities to correct their underlying misconception. Specifically, it offered them two attempts at a new question on the exact same mathematical topic. We thus examined whether tutoring helped students eventually resolve their misunderstanding—that is, whether they answered any of the post-intervention questions correctly. On this broader measure, interactive tutoring once again proved superior to static hints (see Figure 3, center). When working with a human tutor,  $94.9\\%$  [92.6%, 96.8%] of students resolved their misconception, relative to only  $86.8\\%$  [85.7%, 88.0%] of students receiving pre-written hints. No meaningful difference emerged between students working with LearnLM and those working with human tutors. Students tutored by LearnLM resolved misconceptions  $95.4\\%$  [93.1%, 97.1%] of the time. For this kind of near-term correction, both interactive methods appear equally effective.\n\nOf course, the critical question is whether these guided successes (the opportunity to remediate mistakes and resolve misconceptions) reflect durable learning (the ability to solve a new problem without any assistance). Within the scope of this RCT, the best test for durable effects of tutoring is how students performed when progressing to a new topic. The Eedi platform organizes study units into sequences of five, where each unit builds directly upon the last. Our subsequent analysis therefore analyzed a student's likelihood of correctly answering the initial question in the very next unit in their current sequence.\n\nHere, a clear advantage for LearnLM's tutoring emerged (see Figure 3, right). Students tutored by LearnLM\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/fc912d8ef5abf4bad34506e55daf060eacece65731ff34bbfce6e9f56c8fe8f5.jpg)  \nFigure 3 | Tutoring interventions improve student learning outcomes. (left, center) For immediate learning outcomes, sessions with human tutors and expert-supervised sessions with LearnLM promote similar growth for students. Students who receive interactive tutoring from either source substantially outperform students who receive pre-written, static hints. (right) In contrast, students tutored by LearnLM demonstrate greater knowledge transfer to new topics than those supported either by static hints or by human tutors alone. Error bars indicate  $95\\%$  credible intervals. Dashed lines represent the chance of success when guessing randomly  $(33.3\\%, 66.7\\%, \\text{and } 25\\%, \\text{respectively})$ .\n\non a study unit proved substantially more likely to answer the first question in the following unit correctly (66.2% [61.1%, 71.2%]) than students who had received help from an unassisted human tutor (60.7% [55.8%, 65.4%]). In particular, a supervised session with LearnLM increased the likelihood of learning transfer to a distinct topic by an additional 5.5 percentage points  $[-1.4\\%, +12.4\\%]$  relative to human tutoring. Both tutee groups, in turn, outperformed students who had received only a static hint (56.2% [54.2%, 58.2%]). Altogether, we attribute a high credibility (93.6%) to LearnLM offering better support for knowledge transfer than human tutors alone, and near certainty ( $>99.9\\%$ ) to its advantage over static, pre-written hints. The AI-supported interventions fostered a more durable and transferable understanding—an advantage revealed only when students faced a fresh challenge. (See Appendix F for our full analysis of learning outcome data.)\n\nThroughout the RCT, we sought a richer, more nuanced understanding of the experience of interactions with LearnLM (RQ4) by conducting in-depth, semi-structured interviews with a random subset of  $N = 5$  supervising tutors (see Table 1). In addition, we invited all students and supervising tutors to share their thoughts in brief surveys. We gathered  $N = 27$  student responses from a post-trial survey, and  $N = 17$  tutor responses on both pre- and post-trial surveys. These firsthand perspectives help contextualize LearnLM's effectiveness and the specific role that human expertise played in its tutoring successes.\n\nOver the course of the trial, supervising tutors came to view LearnLM as a source of high-quality, expert-level pedagogical insights. The most prominent theme from our interviews, raised independently by all five interviewed tutors, was LearnLM's consistent use of Socratic dialogue. Tutors reported that its suggestions prompted a more inquisitive, student-led interaction. One tutor highlighted its ability to ask \"really good questions that I hadn't necessarily thought of [...] in a good way, a nice way\" (T3). As another reported, \"[LearnLM] definitely explained certain topics in a better way than I probably could have\" (T5). This praise aligned with tutors' actions during the trial: as established earlier, the tutors approved the vast majority of the\n\n<table><tr><td>Tutor ID</td><td>Gender</td><td>Years of teaching experience</td></tr><tr><td>T1</td><td>F</td><td>6–10 years</td></tr><tr><td>T2</td><td>F</td><td>More than 10 years</td></tr><tr><td>T3</td><td>F</td><td>More than 10 years</td></tr><tr><td>T4</td><td>F</td><td>More than 10 years</td></tr><tr><td>T5</td><td>F</td><td>6–10 years</td></tr></table>\n\nTable 1 | We conducted semi-structured interviews with a subset of five supervising tutors to seek a deeper, nuanced understanding of LearnLM's behavior and the general experience of participating in the RCT. Table A.1 in Appendix A contains comparable details for the full sample of supervising tutors.\n\nmessages drafted by LearnLM without any edits or changes.\n\nIn interviews, three tutors noted that supervising this high standard of instruction prompted an unexpected outcome on their part: professional growth and development. For instance, one tutor contrasted LearnLM's Socratic strategy with their prior approach, noting that the drafted messages prompted \"questions more like 'Okay, what made you think that was the answer?' [...] whereas before [...] my main goal was to identify their misconception myself\" (T1). Another explained, \"I remember thinking, 'Oh, I hadn't thought of explaining it that way before.' Just like when you watch another teacher\" (T2). Over the course of the trial, LearnLM's standard of instruction made a considerable impression on the tutors who supervised it.\n\nOne-to-one tutoring requires sustained, substantive effort to process the scenario at hand and craft effective pedagogical guidance. LearnLM's ability to consistently generate high-quality pedagogical responses thus made the entire tutoring process more fluid and efficient. Our post-trial surveys corroborated this; when asked about LearnLM's most useful feature,  $82.4\\%$  of tutors chose \"supporting multiple students at the same time.\" This new, effective process quickly set a new standard for the supervising tutors. In fact, every tutor that we interviewed independently raised this increased capacity as a key strength. As one tutor explained in their interview, \"I got to the point of being disappointed when I didn't get [a session] with the AI suggestions\" (T2). These positive experiences translated into a broad increase in comfort with AI across the cohort. Tutors' self-reported comfort with using AI tools rose from an average of 3.4 [2.9, 4.0] out of 5 in the pre-trial survey to 3.9 [3.3, 4.4] in the post-trial survey (posterior probability of increase:  $90.0\\%$ ).\n\nBuilding LearnLM's pedagogical insights into effective tutoring conversations, however, required the supervising tutors to incorporate social and emotional nuance from their understanding of the students. Our retrospective analysis of the  $25.6\\%$  of cases where tutors edited or re-wrote LearnLM's messages identified two primary motivations for these interventions: moderating the pedagogical pacing of the conversation and providing social-emotional nuance to LearnLM drafts. The most frequent intervention was adjusting the conversation's pacing to prevent exasperating students, accounting for  $44.3\\%$  of all edits. Our tutors echoed this specific challenge in five of our five interviews. As one tutor explained in their interview, \"quite often the students just got frustrated, and then they lost complete interest in the question, so it was a case of overriding it\" (T2). Tutors often found it necessary to step in when LearnLM's Socratic questions, while pedagogically sound, persisted longer than a student's patience. One tutor described a common scenario where \"[LearnLM] will go, 'Okay, you've got the answer. Let's dig a little deeper about why you've got that answer.' And the child is just like, 'No, I've got it. I know what I'm doing. Can I go now?\" (T1).\n\nProviding social and emotional context to LearnLM's drafts emerged as a second prominent motivation for supervisors' interventions. In total,  $19.5\\%$  of tutors' edits adjusted the persona or tone conveyed by the drafted messages. Tutors consistently added personal touches that recognized the student as an individual. For example, one tutor noted the importance of acknowledging a student they had helped before, a nuance LearnLM could not replicate, given that its prompt did not provide any information on past tutoring sessions: \"...if you'd already helped that student twice before, [LearnLM] didn't quite have the capability to go like, 'Oh Sarah, it's you again. Hi!' And I like to have that kind of rapport\" (T3). Tutors also calibrated the tone of the messages to ensure they were appropriate for student communication styles. One tutor remarked that LearnLM's predilection for emojis \"comes across as a bit fake, and [...] the students pick up on that\" (T1). Overall, the human tutors grounded LearnLM's suggestions with social and emotional nuance, translating its pedagogical insights into effective educational interactions.\n\nFinally, student feedback indicated broad satisfaction with their tutoring interactions. In post-trial surveys, students who received interactive tutoring rated the helpfulness of the support they received an average of 3.9 [3.1, 4.7] out of 5, relative to 3.6 [2.9, 4.2] for students who received static hints (posterior probability of an advantage for tutoring:  $74.9\\%$ ). Ultimately, interactive tutoring delivered not just strong learning outcomes, but an enjoyable experience for the learners themselves.\n\n# 4. Discussion\n\nWhen deployed responsibly, can generative AI safely and effectively support students in real-world learning environments? Our exploratory trial investigated whether LearnLM—a genAI model fine-tuned for pedagogical applications—could help provide in-classroom guidance across five UK secondary schools. Students in these schools use Eedi, an online mathematics platform that effectively improves learning outcomes [19], for their\n\nregular instruction. We incorporated LearnLM into the platform so that it drafted messages to send to students in chat-based tutoring sessions. Of course, genAI tools carry well-known risks, including their capacity to fabricate information [26, 27] and erode critical thinking [28, 29]. Given the heightened ethical weight of these risks in educational settings, we assigned a group of expert (human) tutors to directly supervise LearnLM, assuming ultimate responsibility for each of its interactions with students. The tutors applied a simple, rigorous standard: they revised each of LearnLM's drafts until they were satisfied sending the message as their own.\n\nThe supervising tutors found LearnLM to be a reliable source of pedagogical instruction, approving the vast majority of its drafted messages without any edits. A systematic review of the drafted messages revealed zero instances of harmful content and only five factual errors out of 3,617 messages drafted by LearnLM total. For students, this translated into effective support for learning: tutoring from LearnLM helped students identify their mistakes and correct their misconceptions just as well as instruction from human tutors alone. Unexpectedly, students tutored by LearnLM demonstrated greater knowledge transfer to subsequent topics than did students who received guidance from human tutors.\n\nTutors consistently praised LearnLM's use of Socratic dialogue, but also noted that the model's relatively inflexible adherence to pedagogical principles threatened to exasperate some students. The best human tutors, in contrast, draw on experience, empathy, and judgment to decide when to push students and when to moderate their approach. This is a constant judgment call for tutors: weighing the long-term benefits of productive struggle against the immediate risks of frustrating a student and causing them to disengage completely. This delicate calibration remains a fundamental challenge for current AI systems [30-33].\n\nBeyond safety and pedagogy, expanding access to one-to-one tutoring will require improving its cost and scalability. In our interviews, the supervising tutors consistently reported that LearnLM made their work feel more fluid and efficient. Our own anecdotal observations during the trial supported these reports: tutors appeared comfortable managing higher workloads during their supervised sessions. Unfortunately, the design of this RCT—with tutors fluidly switching from supervision to direct interaction during the same classroom periods—precludes a rigorous measurement of throughput or efficiency for each condition. After the trial, we simulated additional sessions as an informal test of scalability (see Appendix G). The results of this informal test corroborate the improved efficiency of the supervised sessions, with tutors sustaining a higher volume of simultaneous conversations when supported by LearnLM. Altogether, these signals support a possible role for genAI tutoring in helping educators to deliver individualized instruction at scale.\n\nOverall, the design of this exploratory RCT allowed us to rapidly validate LearnLM's safety and gather initial signals of its efficacy. We measured these outcomes using students' standard, daily activities on the Eedi platform. This approach provided us with learning signals immediately, eliminating the need to develop and administer new trial-specific assessments, or to wait for the next round of standardized exams. In addition, by randomly assigning the source of support for each individual tutoring session, we could measure the alternating impact of LearnLM and human tutoring on the same students. This approach disentangled tutoring effectiveness from pre-existing student differences, permitting us to detect meaningful indications of efficacy working with just five schools.\n\nOn the other hand, this design offers only a partial glimpse at the broader trajectory of learning. Randomizing the source of tutoring session-by-session allowed our RCT to efficiently investigate immediate learning outcomes, but also prevented it from isolating the cumulative impact of working with LearnLM over time. Measuring substantive, longer-term effects on learning will require a different approach. In addition, the finding from our interviews that tutors learned from supervising LearnLM indicates another methodological wrinkle. If tutors applied those insights in sessions without LearnLM, that crossover might dampen the measured difference between the two tutoring conditions. Future research can overcome these limitations by assigning students to receive one consistent type of support for an entire study, ideally following their progress over several months and tracking their performance on external, standardized assessments. Such a longitudinal approach could help determine whether the immediate successes that we observed translate into persistent, substantive learning gains—a vital step toward validating the potential of AI tutoring to deliver scalable, individualized support for students and educators.\n\nTo what extent might the tutoring efficacy we observe in this RCT generalize beyond mathematics? In part, LearnLM's strong performance reflects the nature of the inputs that we provided to it: questions with precise answers, discrete incorrect responses, and validated explanations of why students might have veered off the right path. Mathematics curricula often focus on verifiably solvable problems, so they readily offer this clear\n\nstructure. In contrast, many other subjects taught in secondary school emphasize ambiguity, interpretation, and argumentation. Consequently, LearnLM's performance in this trial offers limited evidence for its ability to shepherd students through more interpretive activities in fields like history or literature. We will need to conduct research across a diverse range of subjects to understand where current AI tutors may already offer strong support, and which domains require us to develop new, distinct approaches to AI pedagogy.\n\nUltimately, our research did not start from scratch with this trial. Two lines of conceptual and empirical groundwork enabled this RCT: first, a generative AI model specifically fine-tuned for pedagogy [16-18], and second, an educational platform deeply rooted in learning science [19]. Our results integrating LearnLM into the Eedi ecosystem illustrate how learning science and technological development can complement one another to support and scale better learning outcomes for students. Moving forward, we invite collaboration across the AI and learning science communities to partner on new research and offer an honest appraisal of how this technology helps—or hurts—students and educators in different contexts and settings. Building and sharing this knowledge helps bring us closer to the goal of providing effective, safe, and accessible learning opportunities for all students.\n\n# 5. Methods\n\nOur protocol underwent independent ethical review, with a favourable opinion from the Human Behavioural Research Ethics Committee at Google DeepMind (#25003).\n\nParticipants We recruited  $N = 165$  students from five UK secondary schools to participate in the trial. We drew the cohort exclusively in Years 9 and 10 (ages 13-15), from classrooms that incorporate the Eedi platform as part of their regular mathematics instruction for one hour per week. Each student provided informed consent to participate in this research. As part of their informed consent process, we explained to students that their tutors might rely on AI support during the trial. A pool of  $N = 17$  expert tutors—all qualified teachers with extensive teaching experience—delivered the trial's interactive interventions (i.e., tutored students directly and supervised tutoring sessions with LearnLM). Each tutor also provided informed consent to participate in this research.\n\nPlatform The Eedi platform provides a range of curriculum-aligned mathematics activities for students and classrooms. In this RCT, we focused on student performance on its short study units, each designed to assess a specific mathematics topic and consisting of diagnostic multiple-choice questions with four response options (Figure 2). Whenever a student answers the first question in a unit incorrectly, the platform triggers a support intervention. Immediately following this intervention, the platform prompts the student to retry the question that they originally missed. If they miss this question again, the platform presents them with a new question on the same topic, written to assess the same topic and misconceptions using different concrete details. Students complete a unit and progress to the next unit as soon as they answer a question correctly, or after they incorrectly answer all four questions. The platform organizes these study units into sequences of five. Individual study units in a sequence build iteratively upon one another, so students must typically grasp one before successfully engaging with the next.\n\nModel LearnLM is a family of generative AI models fine-tuned to specialize in pedagogical dialogue. For this RCT, we accessed the most recent version of LearnLM available at the time, fine-tuned from Gemini 2.0 Flash. We connected the Eedi platform to LearnLM via a custom API created specifically for this trial. During platform tutoring sessions with LearnLM, the platform assembled a strictly defined system prompt instructing the model to draft a concise, Socratic response aimed at guiding the student to self-correct their specific misconception without revealing the answer. The prompt also provided rich real-time context, including the question text, the student's incorrect answer, and the specific misconception underlying the answer identified by the platform (see Appendix D.1 for the detailed prompt). The platform sent the assembled prompt to the API, which then returned a draft response from LearnLM for the platform to pass to the supervising tutor for approval, editing, or re-writing.\n\nProcedure We conducted the exploratory RCT over seven consecutive weeks (May through June 2025). The trial employed a two-level randomized controlled design to address our research questions. First, we randomly assigned students to either the control condition ( $N = 91$  students) or the tutoring condition ( $N = 74$  students). Second, specifically for students in the tutoring condition, we randomly assigned each individual tutoring session to either a human expert or to LearnLM (under supervision from a human expert).\n\nWhenever a student in the control condition answered a question incorrectly, they received a pre-written message designed to prompt reflection on a specific misconception, based on which incorrect option they selected (a \"static hint\"). The platform then prompted them to retry the question.\n\nTo support the tutoring condition, we scheduled a team of tutors to remain on-call in the Eedi platform during class hours on each day of the trial. Whenever a student in the tutoring condition answered a question incorrectly, the standby team received an alert. One of the tutors would then initiate a session with the student. The platform randomized each of these sessions to either connect the tutor directly to the student (\"session with a human tutor alone\") or to assign them to supervise the model (\"supervised session with LearnLM\"). That is, tutors both directly guided students and oversaw sessions with LearnLM on the same day. In supervised sessions with LearnLM, the human tutor reviewed the suggestions generated by the model and approved, edited, or replaced each drafted message before the platform sent it to the student. The student interface appeared identical across both conditions, with no explicit indication of whether the student was connected with a human tutor alone or a tutor supervising LearnLM.\n\nFor both conditions, we recorded the student and question identifiers, timing, correctness, and position (both within its study unit and within its sequence of five units) of every attempted answer on the platform.\n\nTo complement this central evaluation, we incorporated several qualitative lines of inquiry. First, we recorded the entire message corpus and the supervising tutors' decisions. Throughout the seven-week trial, the platform logged every draft generated by LearnLM, the supervising tutor's action (approve, edit, or re-write), and the finalized message sent to the student. Second, we administered short baseline and endline surveys to all supervising tutors. All tutors completed both rounds ( $N = 17$ ). Third, we invited all participating students to complete a short survey via the Eedi platform after the trial concluded, resulting in  $N = 27$  responses. Finally, we randomly selected five tutors and invited them to participate in hour-long, semi-structured interviews. These interviews followed a standardized protocol designed to elicit detailed narratives of their experiences supervising LearnLM.\n\nAnalysis. We evaluated efficacy across three primary quantitative outcomes derived from Eedi platform data: mistake remediation (success at attempting a question a second time, after an intervention), misconception resolution (success at answering any question within a study unit, after an intervention), and knowledge transfer (success at answering the first question of the next study unit within the same sequence, after an intervention). We leveraged Bayesian regression to estimate treatment effects for these outcomes. We included baseline performance as a covariate in all regression models to account for pre-existing differences between students. The success rates reported in the Results section represent posterior predictive margins estimated from these regressions, adjusting for students' baseline performance. Practically speaking, these estimates differ only negligibly from the unadjusted success rates observed during the trial (see Appendix F for all unadjusted success rates and posterior predictive margins).\n\nTo verify the safety and pedagogical quality of LearnLM's tutoring, we audited the full corpus of drafted messages through an iterative, inductive process [34]. We first counted the number of outright approvals without changes. For all edited and re-written messages, we quantified the magnitude of change by computing the Levenshtein distance and the edit ratio (the Levenshtein distance divided by the total character count of the initial draft). We then categorized the apparent functional purpose of each revision. Specifically, a generative AI model (Gemini 2.5 Pro [35]) performed an initial coding of every edit, processing 30 to 50 pairs of original and edited messages at a time. Two members of the research team reviewed and refined the generated codes into a focused codebook. Next, two expert tutors reviewed each pair of messages to validate the assigned codes. A member of the research team then conducted a final review of the coding decisions to ensure consistency and accuracy. Finally, the research team synthesized these codes into broader themes and specifically searched the coded corpus for any instances of harmful or erroneous generations.\n\nWe took an iterative approach to identify themes in the supervising tutors' interviews, following emerging\n\nguidance on applying genAI tools to support qualitative coding [14, 36, 37]. A member of the research team first reviewed all transcripts to gain familiarity with the content. We then applied a generative AI model (Gemini 2.5 Pro) to identify segments of text describing tutors' perceptions, experiences, or attitudes and to generate initial descriptive labels for them. A member of the research team then refined them into clear definitions, organized them into a structured set of themes, and then manually applied these labels to the full dataset. Finally, a member of the research team verified every coded excerpt against the original transcript to create a complete audit trail.\n\nFinally, we analyzed responses from our short surveys for additional context on student and tutor experiences and perspectives.\n\n# References\n\n[1] Benjamin S Bloom. The 2 sigma problem: The search for methods of group instruction as effective as one-to-one tutoring. Educational researcher, 13(6):4-16, 1984.  \n[2] Matthew A Kraft, Beth E Schueler, and Grace Falken. What impacts should we expect from tutoring at scale? exploring meta-analytic generalizability. Technical Report 24-1031, EdWorking Paper, 2024.  \n[3] Andre Nickow, Philip Oreopoulos, and Vincent Quan. The impressive effects of tutoring on prek-12 learning: A systematic review and meta-analysis of the experimental evidence. Technical report, National Bureau of Economic Research, 2020.  \n[4] Enkelejda Kasneci, Kathrin Seßler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Gunnemann, Eyke Hüllermeier, et al. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and individual differences, 103:102274, 2023.  \n[5] Salman Khan. *Brave new words: How AI will revolutionize education (and why that's a good thing)*. Penguin, 2024.  \n[6] Ethan Mollick. Co-intelligence: Living and working with AI. Penguin, 2024.  \n[7] Erin Mote. Artificial intelligence in education: Opportunities, challenges, and policy considerations for Congress, 2025.  \n[8] Meriem Zerkouk, Miloud Mihoubi, and Belkacem Chikhaoui. A comprehensive review of ai-based intelligent tutoring systems: Applications and challenges. arXiv preprint arXiv:2507.18882, 2025.  \n[9] Joshua Weidlich, D Gasevic, H Drachsler, and P Kirschner. Chatgpt in education: An effect in search of a cause. PsyArXiv Preprints, 2025.  \n[10] Martin Elias De Simone, Federico Hernan Tiberti, Maria Rebeca Barron Rodriguez, Federico Alfredo Manolio, Wuraola Mosuro, and Eliot Jolomi Dikoru. From chalkboards to chatbots: Evaluating the impact of generative ai on learning outcomes in nigeria. Technical report, The World Bank, 2025.  \n[11] Greg Kestin, Kelly Miller, Anna Klales, Timothy Milbourne, and Gregorio Ponti. Ai tutoring outperforms in-class active learning: an rct introducing a novel research-based design in an authentic educational setting. Scientific Reports, 15(1):17458, 2025.  \n[12] Zachary A Pardos and Shreya Bhandari. Chatgpt-generated help produces learning gains equivalent to human tutor-authored help on mathematics skills. Plos one, 19(5):e0304013, 2024.  \n[13] Rose E Wang, Ana T Ribeiro, Carly D Robinson, Susanna Loeb, and Dora Demszky. Tutor copilot: A human-ai approach for scaling real-time expertise. arXiv preprint arXiv:2410.03017, 2024.  \n[14] Hamsa Bastani, Osbert Bastani, Alp Sungu, Haosen Ge, Özge Kabakci, and Rei Mariman. Generative ai without guardrails can harm learning: Evidence from high school mathematics. Proceedings of the National Academy of Sciences, 122(26):e2422633122, 2025.\n\n[15] Nataliya Kosmyna, Eugene Hauptmann, Ye Tong Yuan, Jessica Situ, Xian-Hao Liao, Ashly Vivian Beresnitzky, Iris Braunstein, and Pattie Maes. Your brain on chatgpt: Accumulation of cognitive debt when using an ai assistant for essay writing task. arXiv preprint arXiv:2506.08872, 2025.  \n[16] Irina Jurenka, Markus Kunesch, Kevin R. McKee, Daniel Gillick, Shaojian Zhu, Sara Wiltberger, Shubham Milind Phal, Katherine Hermann, Daniel Kasenberg, Avishkar Bhoopchand, et al. Towards responsible development of generative AI for education: An evaluation-driven approach. arXiv preprint arXiv:2407.12687, 2024.  \n[17] LearnLM Team. LearnLM: Improving Gemini for learning. arXiv preprint arXiv:2412.16429, 2024.  \n[18] LearnLM Team. Evaluating gemini in an arena for learning. arXiv preprint arXiv:2505.24477, 2025.  \n[19] Wayne Harrison, Emma Dobson, Steve Higgins, Germaine Uwimpuhwe, and Rahil Khowaja. Eedi 2024 impact report: A study to evaluate the effectiveness of eedi on raising attainment in mathematics at ks3 (year 7). Technical report, WhatWorked Education, 2025. URL www.interventions. whatworked.e education.  \n[20] Eason Chen, Xinyi Tang, Aprille Xi, Chenyu Lin, Conrad Borchers, Shivang Gupta, Jionghao Lin, and Kenneth R Koedinger. Vtutor for high-impact tutoring at scale: managing engagement and real-time multi-screen monitoring with p2p connections. In Proceedings of the Twelfth ACM Conference on Learning@ Scale, pages 320–324, 2025.  \n[21] Geoff Cumming. Inference by eye: Reading the overlap of independent confidence intervals. Statistics in medicine, 28(2):205-220, 2009.  \n[22] Peter C Austin and Janet E Hux. A brief note on overlapping confidence intervals. Journal of vascular surgery, 36(1):194-195, 2002.  \n[23] Nathaniel Schenker and Jane F Gentleman. On judging the significance of differences by examining the overlap between confidence intervals. The American Statistician, 55(3):182-186, 2001.  \n[24] VI Levenshtein. Binary codes capable of correcting deletions, insertions and reversals. In Soviet Physics Doklady, volume 10, page 707, 1966.  \n[25] Gonzalo Navarro. A guided tour to approximate string matching. ACM computing surveys (CSUR), 33(1): 31-88, 2001.  \n[26] David Sallay. Vetting generative AI tools for use in schools. Policy brief, Future of Privacy Forum, April 2024.  \n[27] Paula Maylahn. 2024 state of EdTech district leadership. Technical report, Consortium for School Networking (CoSN), 2024.  \n[28] Michael Gerlich. Ai tools in society: Impacts on cognitive offloading and the future of critical thinking. Societies, 15(1):6, 2025.  \n[29] Elizabeth Laird, Maddy Dwyer, and Hannah Quay-de la Vallee. Hand in hand: Schools' embrace of AI connected to increased risks to students. Technical report, Center for Democracy & Technology, October 2025.  \n[30] Chase DiBenedetto. I tried learning from ai tutors. The test better be graded on a curve., September 2025. URL https://mashable.com/article/chat-gpt-study-mode-review.  \n[31] Chase DiBenedetto. After testing out Google's AI tutor, we have some notes, September 2025. URL https://mashable.com/article/google-gemini-guided-learning-review.  \n[32] Chase DiBenedetto. I tried learning from Anthropic's AI tutor. I felt like i was back in college., September 2025. URL https://mashable.com/article/anthropic-claude-learning-mode-review.  \n[33] Daniel Gillick. AI tutors should not approximate human tutors, November 2025. URL https://www.ai-policyperspectives.com/p/ai-tutors-should-not-approximate.\n\n[34] Virginia Braun and Victoria Clarke. Using thematic analysis in psychology. Qualitative research in psychology, 3(2):77-101, 2006.  \n[35] Gemini Team, Google. Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. arXiv preprint arXiv:2507.06261, 2025.  \n[36] Danielle Hitch. Artificial intelligence augmented qualitative analysis: the way of the future? Qualitative Health Research, 34(7):595-606, 2024.  \n[37] Matthew Nyaaba, Min SungEun, Mary Abiswin Apam, Kwame Owoahene Acheampong, and Emmanuel Dwamena. Optimizing generative ai's accuracy and transparency in inductive thematic analysis: A human-ai comparison. arXiv preprint arXiv:2503.16485, 2025.  \n[38] Jon Andrews. The introduction of progress 8. Technical report, Education Policy Institute, 2017. URL https://dera.ioe.ac.uk/id/eprint/29304.  \n[39] Department for Education. Schools, pupils and their characteristics: Academic year 2024/25, June 2025. URL https://explore-education-statistics.service.gov.uk/find-statistics/school-pupils-and-their-characteristics/2024-25.  \n[40] Ariel Lindorff, Steve Strand, and Ivan Au. English as an additional language (eal) and educational achievement in england: An analysis of publicly available data. Technical report, The Bell Foundation, Cambridge, February 2025.  \n[41] Ben Goodrich, Jonah Gabry, Imad Ali, and Sam Brilleman. rstanarm: Bayesian applied regression modeling via Stan., 2020. URL https://mc-stan.org/rstanarm. R package version 2.21.1.  \n[42] Google DeepMind. Gemini 2.5 flash, 2025. URL https://deepmind.google/models/gemini/flash/. Accessed: 2025-11-10.  \n[43] Hannah Coe. How much does a maths tutor cost in 2024/2025?, September 2024. URL https://tutorful.co.uk/blog/how-much-does-a-maths-tutor-cost. Accessed: 2025-11-10.\n\n# Contributions and Acknowledgments\n\n# Core Contributors\n\nThe following individuals contributed to the work described in this report. These lists are ordered alphabetically, and do not indicate ranking of contributions.\n\nOn the Google team, the following individuals made core contributions:\n\nAlbert Wang, Aliya Rysbek, Andrea Huber, Brian Veprek, Irina Jurenka, Jonathan Caton, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Liam McCafferty, Markus Kunesch, Sara Wiltberger, and Shakir Mohamed.\n\nOn the Eedi team, the following individuals made core contributions:\n\nAnna Kenolty, Anjali Nambiar, Ben Caulfield, Beth Lilley-Draper, Bibi Groot, Chelsea Burdett, Claire Willis, Craig Barton, Digory Smith, George Mu, Harriet Walters, Iris Hulls, James Stalley-Moores, Lucy Dalton, Pauline Malubay, Rachel Kidson, Rich Wells, Sam Wheeler, Simon Woodhead, and Vasco Brazão.\n\nKevin R. McKee and Bibi Groot led this research and the preparation of this report.\n\n# Acknowledgements\n\nThis work represents a close collaboration between Google and Eedi.\n\nFor Eedi: We would like to acknowledge the support of the Eedi tutors and learning designers who made this work possible, including Bea Pugh, Gemma Bazany-Barber, Marion Brehm, Morgan Sowerby, Nigel Kendall, and Zoe Sutcliffe. Eedi also thanks the organizations that fund our research efforts: the Digital Harbor Foundation, Learning Engineering Virtual Institute, Rockefeller Foundation, Schmidt Futures, and Walton Family Foundation.\n\nFor Google: We completed this work as part of the LearnLM effort—a cross-Google project, with members from Google DeepMind, Google Research, Google LearnX, and more. This tech report represents only a small part of the wider effort, and only lists team members who made direct contributions to this report. The dedication and efforts of numerous teams make our work possible. The LearnLM team would like to acknowledge support from Abhinit Modi, Aditya Srikanth Veerubhotla, Antonia Mould, Avishkar Bhoopchand, Brett Wiltshire, Daniel Gillick, Daniel Kasenberg, Derek Ahmed, Gal Elidan, James Cohan, Jennifer She, Kristen Morea, Lisa Wang, Mike Schaekermann, Miriam Schneider, Miruna Píslar, Muktha Ananda, Nahema Marchal, Nikhil Joshi, Parsa Mahmoudieh, Paul J Hun, Shanice Onike, Shashank Agarwal, Shubham Milind Phal, Sun Jae Lee, Theofilos Strinopoulos, Wei-Jen Ko, and Will Hawkins. Furthermore, we would like to thank the Gemini team, the Compute team, the Responsible Development and Innovation team, the Responsible Engineering team, and the Child Safety team at Google DeepMind, as well as the Trust and Safety team at Google. Finally, the LearnLM team would like to acknowledge the support provided by our leads and sponsors that made this project possible: our genuine thanks go to Benedict Gomes, Lila Ibrahim, and Zoubin Ghahramani.\n\n# A. Participants\n\n# A.1. Students\n\nThe trial included  $N = 165$  students in Year 9 and 10 (ages 13-15) from five UK secondary schools. Participants ranged in age from 13 to 15. Among those who reported their gender, the cohort was relatively evenly split (51.1% female, 48.9% male).\n\nThe schools varied broadly in academic performance and socio-economic background. Progress 8 scores ranged from  $-0.68$  to  $+0.24$ , spanning the 5th to 75th national percentiles for state-funded schools in England [38]. Free School Meal eligibility ranged from  $12\\%$  (representing affluent areas) to  $26\\%$  (closely aligned with the national secondary school average of  $25.7\\%$  [39]). However, the schools contained low proportions of students speaking English as an Additional Language (EAL), ranging from  $2 - 11\\%$ . These rates fall below the national average and do not reflect the EAL rates seen in major urban centers [40].\n\n# A.2. Tutors\n\nA pool of  $N = 17$  expert tutors delivered the interactive interventions in the RCT and provided additional insights in baseline surveys, semi-structured interviews, and endline surveys (Table A.1).\n\n<table><tr><td>Tutor ID</td><td>Gender</td><td>Years of teaching experience</td><td>Additional contributions</td></tr><tr><td>T1</td><td>F</td><td>6–10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T2</td><td>F</td><td>More than 10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T3</td><td>F</td><td>More than 10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T4</td><td>F</td><td>More than 10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T5</td><td>F</td><td>6–10 years</td><td>Interview, surveys (baseline, endline)</td></tr><tr><td>T6</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T7</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T8</td><td>F</td><td>3–5 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T9</td><td>F</td><td>6–10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T10</td><td>M</td><td>6–10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T11</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T12</td><td>F</td><td>6–10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T13</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T14</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T15</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T16</td><td>F</td><td>3–5 years</td><td>Surveys (baseline, endline)</td></tr><tr><td>T17</td><td>F</td><td>More than 10 years</td><td>Surveys (baseline, endline)</td></tr></table>\n\nTable A.1 | Teaching experience and additional research contributions for all supervising tutors.\n\n# B. Trial\n\nThe research presented in this report focuses on two types of support interventions provided by the Eedi platform: static, pre-written hints that map to particular student misconceptions about individual topics, and interactive, chat-based tutoring (Figure B.1).\n\nTo estimate baseline performance levels, we examined data from regular platform usage during the ten weeks preceding the trial, from March 1 to May 12, 2025 (the baseline period). During this period, the platform provided all students with static hints when they answered the first question of a study unit incorrectly.\n\nFollowing the baseline period, we conducted the RCT over seven consecutive weeks, from May 13 to June 30, 2025 (the trial period). At the start of the trial, we randomly assigned each student to one of two conditions. Students in the control condition continued to receive only static hints after they made a mistake on the initial question of a study unit. Whenever a student in the tutoring condition answered the first question of a study unit incorrectly, the platform instead initiated an interactive, chat-based tutoring session for them. The students in the tutoring condition experienced a further level of randomization: at the start of each of their tutoring sessions, the platform randomly connected the student either to a human tutor working alone or to a supervised session with LearnLM.\n\nBecause the Eedi platform dynamically triggered support interventions based on students' real-time performance, the trial did not follow a fixed schedule. Beyond these platform-initiated support interventions, students in both conditions could also manually request tutoring support at any time. In addition, the platform allowed students to cancel tutoring sessions at any time (potentially including when the session was still pending and before a tutor had sent a message). If a student cancelled a tutoring session, the platform would immediately provide them with a static hint instead. Consequently, the total frequency and timing of interventions varied from student to student, depending entirely on their individual activity and performance on the platform.\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/cf035bcfb6ec05f200c5f4738a1260af191ef1047d1752e745bdbfd8abe5d6c0.jpg)  \nFigure B.1 | Our RCT focused on two support interventions on the Eedi platform. After making a mistake in a study unit, students in the control condition received static hints (left), which deliver immediate, pre-written feedback targeting the specific misconception underlying the incorrect answer they chose. Students in the tutoring condition (right) received one-to-one, chat-based assistance from a tutor.\n\n# C. Platform\n\nThe full ecosystem of support on the Eedi platform includes a number of features beyond the two that this RCT employs as interventions (i.e., beyond static hints and interactive tutoring; Figure B.1).\n\nThe core of the Eedi ecosystem is its vast library of over 60,000 diagnostic questions. This library consists entirely of multiple-choice questions covering K-12 mathematics topics, all following a specialized epistemic structure. Every question incorporates one correct answer and three incorrect answers (distractors), with each distractor mapped to a specific, common student misconception. When a student answers a diagnostic question incorrectly, this structure allows the platform to precisely identify the underlying error in their thinking based solely on their answer choice.\n\nAfter identifying a misconception from a student's error on a diagnostic question, the platform guides the student to a library of materials corresponding to the overall topic of that question. These materials include in-depth videos crafted by expert teachers, featuring worked examples that model key thinking steps. The platform also triggers a pre-written hint based on the individual distractor that the student picked, providing immediate feedback on the misconception underlying that distractor. Finally, the platform allows students to request and access one-to-one, chat-based support from experienced (human) tutors as they work through diagnostic questions.\n\nBeyond immediate intervention, the platform provides personalised retrieval practice to help students consolidate learning over time. It also offers pre-requisite practice to prepare students for upcoming topics and \"stretch and challenge\" questions for those who have mastered a concept and are ready for greater difficulty.\n\nFinally, the platform equips educators with detailed analytics dashboards and targeted instructional tools. Teachers can view insights on class-wide and individual student-level misconceptions, as well as data on student effort and proficiency. Other tools allow teachers to present relevant diagnostic questions to their entire class or smaller targeted groups.\n\nFor the duration of this RCT, to investigate our research questions, we made several targeted changes to the student experience. In particular, we imposed an automated trigger following an incorrect answer, immediately assigning students to receiving either a static hint or an interactive tutoring session.\n\n# D. Model\n\n# D.1. Tutoring prompt\n\nWe used the following system prompt to constrain LearnLM's pedagogical approach during tutoring sessions. The Eedi platform dynamically populated the {placeholder} values in this prompt template before each individual API call, injecting real-time metadata about the student's current activity, diagnosed misconception, and predicted performance:\n\n# Listing D.1 | System prompt template\n\n```vba\nAct as a mathematics tutor named {ChatConstants.BotName} who is currently helping a student  $\\rightarrow$  named {ChatConstants.FirstName} with the activity below in a clipped, Socratic style.   \n#Directives Do not let students know you are a bot, you are {ChatConstants.BotName} the tutor. No LaTeX or markdown. Plaintiff only. Even if the question has latex in it. Use short, focused sentences. Ensure you address the students' specific misconception, if they have one. Use only British English, British weights, and measures. Keep it direct, concise and friendly. Try to keep messages short and to one line where  $\\rightarrow$  possible. End session if the user is rude, they've resolved their misconception / guessed the correct  $\\rightarrow$  answer, or finished. Only ask the student one question at a time. Only return responses on a single line, no line breaks. Do use a creative variety of emojis, but NOT the wink emoji If the user asks to go, let them go! If a user knows the correct answer (e.g. \"It's B\") or \"A)?\", say you can return them to  $\\rightarrow$  their lesson Or you can dig deeper to help them understand (in case they are guessing!) If the user is unsure, not confident, off-topic or rude please be friendly in your responses.  $\\rightarrow$  Acknowledge their concerns and pivot accordingly, maybe try simple questions to get them  $\\rightarrow$  back on track. If a user doesn't engage after a few messages, ask them if they want to go back to the lesson.   \n# The Current student activity The below is what the student was doing when this learning intervention started, so assume all  $\\rightarrow$  responses relate to this: {ChatConstants.Activity} # Activity details {ChatConstants/questionMetaData} # Students ability level (if provided) {ChatConstants.StudentInsight}   \n# Examples of good Socratic responses What happens if we multiply these two numbers first? \"Sure! How do you find the perimeter of the shape?\" Super work! And what about the triangle?\" That's okay, did you watch the video for this lesson?\" Shall I return you to the lesson?\" Could you estimate the height?\" Yes it is equilateral so the slant height is 8, so the vertical height would have th be a  $\\rightarrow$  little less\" Yes sure, so we know what  $5\\mathrm{km}$  is and we're trying to get to  $30\\mathrm{km}$  \" When you are finding the original shape, complete the steps in the reverse direction, and do  $\\rightarrow$  the opposite\" Ok, so can we try and make some even smaller ones? :)\" Awesome, I'll pass you back to Eedi \" It says that  $1\\mathrm{g} = 10$  decigrams\" And then would have to convert to kilograms afterwards :)\" So to convert into a decimal, we want it to be over 100 or 1000 or another power of 10\"   \n## Checking understanding (use if the student is confused or unsure)   \n\"Fantastic! Are you feeling more confident with this?\" Great! Are you happy with how we got to the answer?\" Awesome work. Do you feel ready to head back to the lesson?\"   \n## Closing remarks (use if the student has answered correctly)   \n\"Great job today \" Amazing work  $\\clubsuit$  keep it up!\" Super! I'll hand you back to the lesson\" Great! I'll hand you back \" Fantastic work  $\\clubsuit$  I'll hand you back so you can select your answer\"   \n## Rudeness (use if the student is rude e.g. 'shut up' or 'I don't care')   \n\"That's not an appropriate way to speak to a tutor. Please remember your manners \" Please remember your manners can I help you with this question?\" \"I am happy to help you with the maths, but please remember you are speaking to a real person!\"\n```\n\n```txt\n\"That is not an appropriate way to talk to a tutor. If this continue then I will need to pass  $\\rightarrow$  this on to your teacher (only for extended periods of misuse)\"   \n\"I am here to help you with the maths and have lots of people to help right now. You need to be  $\\rightarrow$  using the platform maturely so I can help you. I will send you back to the lesson, where  $\\rightarrow$  you can use the videos to help you. I will make a note of your name and if there is  $\\rightarrow$  future silly behaviour we will contact your teacher\"   \n\"I will be ending this conversation here as that is not an appropriate way to talk to a tutor.  $\\rightarrow$  I will be letting your teacher know so that they can remind you how to get the most out  $\\rightarrow$  of Eedi. In the meantime please do watch the help videos if you're stuck\"   \n# Important response guidelines - Please don't use wink emojis  $\\clubsuit$    \n- If a student wants to end the session, please let them go.   \n- Do not use the word \"bot\" or \"AI\" in your responses.   \n- Do not give the student the answer.\n```\n\nTo help tailor these pedagogical instructions for LearnLM, the prompt included specific directives based on the student's year group and predicted performance on the current quiz. Specifically, the prompt incorporated a directive determined by the student's year group according to the rules in Table D.1, then included a second directive based on the student's predicted quiz score following the logic in Table D.2.\n\n# Year group Instructional directive\n\n```txt\nYear 9 Discuss more abstract ideas and build logical arguments.   \nYear 10 Explore complex topics in depth, using nuanced language and encouraging critical thinking.\n```\n\nTable D.1 | Instructional directives based on student year group.  \n\n<table><tr><td>Predicted score</td><td>Instructional directive</td></tr><tr><td>Score ≥ 80%</td><td>The student is predicted to do well. Help with more advanced concepts.</td></tr><tr><td>Score ≥ 60%</td><td>The student is predicted to do okay. Check for understanding of core concepts.</td></tr><tr><td>Score ≥ 50%</td><td>The student is predicted to struggle. Help with core concepts using simple explanations.</td></tr><tr><td>Score &lt; 50%</td><td>The student is predicted to really struggle. Use brief, simple language.</td></tr></table>\n\nTable D.2 | Instructional directives based on predicted student performance.\n\nThe following example shows a prompt populated by following these rules for a hypothetical session with a Year 9 student working on quadratic functions:\n\n# Listing D.2 | Example of a fully populated system prompt\n\n```txt\nAct as a mathematics tutor named Claire who is currently helping a student named Rose with the  $\\rightarrow$  activity below in a clipped, Socratic style.   \n# Directives   \n- Do not let students know you are a bot, you are Claire the tutor.   \n- No LaTeX or markdown. Plaintext only. Even if the question has latex in it.   \n- Use short, focused sentences.   \n- Ensure you address the students' specific misconception, if they have one.   \n- Use only British English, British weights, and measures.   \n- Keep it direct, concise and friendly. Try to keep messages short and to one line where  $\\rightarrow$  possible.   \n- End session if the user is rude, they've resolved their misconception / guessed the correct  $\\rightarrow$  answer, or finished.   \n- Only ask the student one question at a time.   \n- Only return responses on a single line, no line breaks.   \n- Do use a creative variety of emojis, but NOT the wink emoji  $\\rightarrow$    \n- If the user asks to go, let them go!   \n- If a user knows the correct answer (e.g. \"It's B\") or \"A)?\"), say you can return them to  $\\rightarrow$  their lesson Or you can dig deeper to help them understand (in case they are guessing!)   \n- If the user is unsure, not confident, off-topic or rude please be friendly in your responses.  $\\rightarrow$  Acknowledge their concerns and pivot accordingly, maybe try simple questions to get them  $\\rightarrow$  back on track.   \n- If a user doesn't engage after a few messages, ask them if they want to go back to the lesson.   \n# The Current student activity   \nThe below is what the student was doing when this learning intervention started, so assume all  $\\rightarrow$  responses relate to this:   \nCurrent quiz name: Quadratic Functions & Graphing. On question no. 3 of 5.   \n# Activity details\n```\n\n```txt\nThe Diagnostic Question:  $2\\mathrm{r}^{\\wedge}2 - 4\\mathrm{r}$  What is the value of this expression when  $\\mathbf{r} = -2?$    \nThe student answered option: A) -34   \nThe student friendly explanation for the answer is:   \nI think you found the first part correctly, but remember that 4r means 4 x r   \nThe misconceptions possibly held by the student are: Arithmetic error in substitution,  $\\rightarrow$  misunderstanding of order of operations with negative numbers.   \nThe correct answer to this question is: C) 16 (NOTE: Correct answer is only confirmed upon  $\\rightarrow$  valid Socratic resolution)   \nThe correct answer explanation is: We have  $2*(-2)^{\\wedge}2 - 4*(-2) = 2*4 + 8 = 16.$\n```\n\n```txt\nStudents ability level (if provided)   \nThe student is in year group 09.   \nDiscuss more abstract ideas and build logical arguments.   \n- They are  $28\\%$  through the lesson   \n- Their predicted score for the quiz is  $86 \\%$    \n- The student is predicted to do well. Help with more advanced concepts.\n```\n\n```txt\nExamples of good Socratic responses\n\"What happens if we multiply these two numbers first?\" \"Sure! How do you find the perimeter of the shape?\" \"Super work! And what about the triangle?\" \"That's okay, did you watch the video for this lesson?\" \"Shall I return you to the lesson?\" \"Could you estimate the height?\" \"Yes it is equilateral so the slant height is 8, so the vertical height would have th be a little less\" \"Yes sure, so we know what  $5\\mathrm{km}$  is and we're trying to get to  $30\\mathrm{km}$ \" \"When you are finding the original shape, complete the steps in the reverse direction, and do the opposite\" \"Ok, so can we try and make some even smaller ones? :)\" \"Awesome, I'll pass you back to Eedi  $\\odot$  \" \"It says that  $1\\mathrm{g} = 10$  decigrams\" \"And then would have to convert to kilograms afterwards :)\" \"So to convert into a decimal, we want it to be over 100 or 1000 or another power of 10\"\n```\n\n```markdown\n## Checking understanding (use if the student is confused or unsure)\n```\n\n```txt\n\"Fantastic! Are you feeling more confident with this?\" \"Great! Are you happy with how we got to the answer?\" \"Awesome work. Do you feel ready to head back to the lesson?\"\n```\n\n```txt\nClosing remarks (use if the student has answered correctly)\n```\n\n```txt\n\"Great job today \"   \n\"Amazing work keep it up!\"   \n\"Super! I'll hand you back to the lesson\"   \n\"Great! I'll hand you back \"   \n\"Fantastic work I'll hand you back so you can select your answer\"\n```\n\n```txt\nRudeness (use if the student is rude e.g. 'shut up' or 'I don't care')\n```\n\n```txt\n\"That's not an appropriate way to speak to a tutor. Please remember your manners\" \"Please remember your manners can I help you with this question?\" \"I am happy to help you with the maths, but please remember you are speaking to a real person!\" \"That is not an appropriate way to talk to a tutor. If this continue then I will need to pass  $\\rightarrow$  this on to your teacher (only for extended periods of misuse)\" \"I am here to help you with the maths and have lots of people to help right now. You need to be  $\\rightarrow$  using the platform maturely so I can help you. I will send you back to the lesson, where  $\\rightarrow$  you can use the videos to help you. I will make a note of your name and if there is  $\\rightarrow$  future silly behaviour we will contact your teacher\" \"I will be ending this conversation here as that is not an appropriate way to talk to a tutor.  $\\rightarrow$  I will be letting your teacher know so that they can remind you how to get the most out  $\\rightarrow$  of Eedi. In the meantime please do watch the help videos if you're stuck\"\n```\n\n```txt\n- Important response guidelines\n- Please don't use wink emojis\n- If a student wants to end the session, please let them go.\n- Do not use the word \"bot\" or \"AI\" in your responses.\n- Do not give the student the answer.\n```\n\n# E. Tutor edits\n\nThroughout the trial, the Eedi platform logged every message drafted by LearnLM and the corresponding action of the supervising tutors (approve without changes, edit, or completely re-write). In total, LearnLM generated  $k = 3617$  drafts over the course of the RCT. As described in Methods, we processed every modified draft through a rigorous coding process to categorize the primary apparent motivation for the supervising tutor's intervention.\n\n# E.1. Minor edits\n\nThe supervising tutors most frequently made no change or only a minimal change to the messages that LearnLM drafted. Tutors accepted  $k = 2,691$  (74.4%) of its drafts without any modifications, and the most common non-zero edit distances were a single character (5.5% of edits) and two characters (2.4%). Overall, 17.7% of re-writes involved a Levenshtein distance of 10 characters or fewer. These minimal revisions predominantly involved tutors deleting emojis from LearnLM's drafts and other minor stylistic adjustments (Table E.1).\n\n<table><tr><td>Original LearnLM draft</td><td>Edited tutor message</td><td>Edit distance</td></tr><tr><td>Nearly there! You&#x27;ve correctly expanded some of the terms, but double check how you&#x27;ve combined your &#x27;x&#x27; terms. What&#x27;s 2x - 10x?</td><td>Nearly there! You&#x27;ve correctly expanded some of the terms, but double check how you&#x27;ve combined your &#x27;x&#x27; terms. What&#x27;s 2x - 10x?</td><td>1</td></tr><tr><td>You&#x27;re right that it goes up from left to right. But what about from right to left? Try reading the graph backwards. What&#x27;s happening to the y values then?</td><td>You&#x27;re right that it goes up from left to right. But what about from right to left? Try reading the graph backwards. What&#x27;s happening to the y values then?</td><td>1</td></tr><tr><td>Still not quite there. Think carefully about subtracting a negative.</td><td>Still not quite there. Think carefully about subtracting a negative.</td><td>2</td></tr><tr><td>Nearly! -8 - 4 is...? +-</td><td>Nearly! -8 - 4 is...?</td><td>3</td></tr><tr><td>You&#x27;ve got the total number of teachers right! Now, how does that total relate to the 360 degrees in the pie chart? ÷</td><td>You&#x27;ve got the total number of teachers right, 20! Now, how does that total relate to the 360 degrees in the pie chart? ÷</td><td>4</td></tr><tr><td>You&#x27;re on the right track. But does this triangle have a right angle?</td><td>You&#x27;re on the right track. Does this triangle have a right angle?</td><td>5</td></tr><tr><td>Nearly! Remember, we&#x27;re talking about a prism. Can you picture what a triangular prism looks like? How many triangles can you see?</td><td>Not quite! Remember, we&#x27;re talking about a prism. Can you picture what a triangular prism looks like? How many triangles can you see?</td><td>8</td></tr></table>\n\nTable E.1 | Examples of minor edits that tutors made to LearnLM's message drafts. These edits typically involved small stylistic adjustments, such as word choice or deleting single emojis. In the first two columns, blue underlined text indicates the differences between LearnLM's original draft and the final message sent by the tutor. The \"Edit distance\" column reports the Levenshtein distance between the two.\n\n# E.2. Safety and accuracy audit\n\nAs part of the coding process, tutors explicitly flagged any instances of harmful or factually incorrect content that LearnLM generated. This audit uncovered zero cases of harmful or risky content. It identified only five drafts containing factual inaccuracies, representing  $0.1\\%$  of the 3,617 total messages drafted by LearnLM. Table E.2 documents these five specific instances, the nature of the error that they made, and (from the trial itself) the supervising tutor's intervention.\n\n<table><tr><td>Original LearnLM draft</td><td>Edited tutor message</td><td>Edit distance</td><td>Error type</td></tr><tr><td>Okay! Let&#x27;s think about that. So you&#x27;re saying the highest common factor of 6 and 9 is 2? Can you show me how you got that answer?</td><td>Okay! Let&#x27;s think about that. So you&#x27;re saying the highest common factor of 6 and 9 is 3? Can you show me how you got that answer?</td><td>1</td><td>Mathematical error</td></tr><tr><td>Triangles, yes! 三角形 But how many, and what kind of triangles? Have a close look at that equilateral triangle when it&#x27;s split by the perpendicular height.</td><td>Triangles, yes! But how many, and what kind of triangles? Have a close look at that equilateral triangle when it&#x27;s split by the perpendicular height.</td><td>3</td><td>Language error</td></tr><tr><td>Brilliant! What are those three numbers?</td><td>Brilliant! What are those two numbers?</td><td>4</td><td>Hallucination</td></tr><tr><td>Ah, I see! So, you&#x27;re saying &#x27;D) Certain&#x27;. What does a probability of 0.9 tell you about how likely an event is to happen?</td><td>Ah, I see! So, you&#x27;re saying &#x27;D) Impossible&#x27;. What does a probability of 0.9 tell you about how likely an event is to happen?</td><td>9</td><td>Hallucination</td></tr><tr><td>Okay, you&#x27;ve changed your answer to C. That&#x27;s 0.3. So, you&#x27;re saying the chance of it not snowing is the same as the same as the chance of it snowing? Is that right?</td><td>H2: Okay, you&#x27;ve changed your answer to C. That&#x27;s 0.5. So, you&#x27;re saying the chance of it not snowing is half, but snowing wasn&#x27;t a half. What do snow and not snow need to ADD to make?</td><td>59</td><td>Hallucination</td></tr></table>\n\nTable E.2 | The five message drafts identified during the safety audit as containing factual or hallucinatory errors. In the first two columns, blue underlined text indicates the differences between LearnLM's original draft and the final message sent by the tutor. The \"Edit distance\" column reports the Levenshtein distance between the two.\n\n# E.3. Primary motivations\n\nOur coding process revealed several recurring motivations for tutors' edits. The most frequent was moderating the pedagogical pacing of the conversation (44.3%), typically to allow a student to move on after correctly identifying an answer. Tutors also intervened to improve factual or contextual clarity (33.6%) and to adjust the tone or persona of the drafted message (19.5%). Table E.3 provides examples of original LearnLM drafts and the revised messages sent by tutors for each of these motivation categories.\n\n<table><tr><td>Original LearnLM draft</td><td>Edited tutor message</td><td>Edit distance</td><td>Primary motivation</td></tr><tr><td>Okay... 6 is a factor of 6, that&#x27;s true! But what other numbers divide into 6 exactly?</td><td>Great... 6 is a factor of 6, that&#x27;s true! But what other numbers divide into 6 exactly?</td><td>4</td><td>Tone or persona</td></tr><tr><td>You&#x27;re using the values on the graph. But what does subtracting 0 from 20 tell you in this context?</td><td>You&#x27;re using the values on the graph. So how many students are in the class?</td><td>44</td><td>Factual or contextual clarity</td></tr><tr><td>You&#x27;ve got the correct answer! But, let&#x27;s make sure you understand why. Can you explain in your own words why option A is correct?</td><td>You&#x27;ve got the correct answer! After we subtract 3, we have to multiply the whole expression of p - 3 by 4</td><td>74</td><td>Pedagogical pacing</td></tr></table>\n\nTable E.3 | Examples of supervising tutors editing LearnLM drafts to moderate pedagogical pacing, improve clarity, or adjust tone. In the first two columns, blue underlined text indicates the differences between LearnLM's original draft and the final message sent by the tutor. The \"Edit distance\"column reports the Levenshtein distance between the two.\n\n# F. Learning outcomes\n\n# F.1. Methodology\n\nWe evaluate the efficacy of our interventions by analyzing three specific learning outcomes:\n\n1. Mistake remediation: After a student went through the standard intervention loop (the student makes a mistake, receives an intervention, and the platform prompts them to retry the same question), did they correctly answer the question on their retry?  \n2. Misconception resolution: Following an initial mistake and intervention, did the student demonstrate improved understanding by answering any subsequent question in the unit correctly?  \n3. Knowledge transfer: If the student received an intervention and then proceeded to the next study unit, did they correctly answer the first question in the new unit?\n\nWe analyze these binary outcomes using Bayesian logistic regression. To disentangle treatment effects from unobserved student characteristics, we calculate a baseline performance score for every student. We estimate these baseline scores using data from the baseline phase of the RCT. Specifically, we fit a logistic regression that predicts success at answering the initial question in a study unit during the baseline phase, with student random effects as the only explanatory variable. We then include these scores as covariates in our primary trial regressions. Three students do not appear in the baseline period. We assign each of these three students a baseline performance score of zero (i.e., the mean of the random effects).\n\nAs described in Appendix B, the RCT involved two types of tutoring sessions: platform-initiated sessions, which the platform triggers automatically after an incorrect answer to an initial question in a unit, and student-initiated sessions, which students can manually request at any time. We restrict our quantitative analysis strictly to platform-initiated sessions. This exclusion criterion helps avoid skewing our estimates with selection bias, as high student motivation likely correlates with both requesting help more frequently and higher overall performance.\n\nStudents occasionally cancelled platform-initiated before the tutor could send a message (in session without LearnLM) or approve a message from LearnLM (in expert-supervised sessions). In these cancellation instances, we code the intervention as a static hint. Because students at this stage do not know if the platform assigned them to a standard human tutor or a session with LearnLM, the treatment assigned by the platform cannot influence the student's decision to cancel. Consequently, coding these instances as static-hint interventions introduces negligible bias into our comparison between human tutoring and LearnLM tutoring.\n\n# F.2. Analysis\n\nWe perform all Bayesian estimation using the rstanarm package in R [41]. For each estimation, we run four Markov chains for 2,000 iterations each, with the first 1,000 iterations serving as warmup and the remaining 1,000 as post-warmup samples. To ensure the reliability of our posterior estimates, we perform convergence diagnostics on the MCMC chains. For all analyses in this tech report,  $\\hat{\\mathbf{R}}$  values (the Gelman-Rubin diagnostic) were below 1.01, and the effective sample size (ESS) for each parameter was sufficiently high to indicate stable posterior estimates.\n\nWe use weakly informative priors for all regressions. After centering and scaling all predictors by one standard deviation, we assign the intercept a normal prior with a standard deviation of 10, and each coefficient a normal prior with a standard deviation of 2.5. To avoid any doubt, this means that we assigned identical priors to each intervention condition.\n\nWe report point estimates as the posterior mean of the coefficient, exponentiated to produce odds ratios (OR). We also report the estimated predictive margins for each condition. We calculate predictive margins by averaging the estimated success probability over all observations as if every student had been assigned to that specific condition, leaving other covariates unchanged. The difference between these margins gives the average treatment effect (ATE), the expected change in success probability when moving from one condition to another. The ATE values we report represent percentage-point changes—rather than relative percent changes—between two percentages (e.g., an increase from  $10\\%$  to  $12\\%$  reflects an ATE of  $+2\\%$ ). We provide  $95\\%$  credible intervals (CrI) for all estimates.\n\n<table><tr><td>Intervention type</td><td>N</td><td>Remediated mistake</td><td>Resolved misconception</td></tr><tr><td>Static hint</td><td>3,301</td><td>64.5%</td><td>86.4%</td></tr><tr><td>Human tutor</td><td>504</td><td>92.3%</td><td>95.6%</td></tr><tr><td>LearnLM (supervised)</td><td>467</td><td>93.8%</td><td>95.9%</td></tr></table>\n\n# F.3. Results\n\n# F.3.1. Immediate learning outcomes\n\nWe first examine whether students immediately benefited from the help they received within the same study unit. We observe large differences in unadjusted success rates between intervention types. While only  $64.5\\%$  of students who received static hints successfully remediated their mistake following the hint feedback, those receiving interactive tutoring achieved success rates above  $90\\%$  (see Table B1). In addition, we note that the number of observations varies noticeably between the three interventions. Several factors contribute to these differences. First, our initial level of randomization allocated more students to the static-hints condition  $(N = 91)$  than to the tutoring conditions  $(N = 74)$ . Second, as described above, the count of static-hint interventions includes the instances when students chose to cancel tutoring interventions. Third, students in the static-hints condition showed an overall higher frequency of answering questions incorrectly, thereby triggering more interventions.\n\nWe infer the general efficacy of these interventions using Bayesian logistic regression, adjusting for baseline performance.\n\nFor mistake remediation, a session with a human tutor increased the odds of success by a factor of 5.7 [4.1, 8.0] relative to a static hint, reflecting an estimated ATE of  $+25.8\\%$ $[+22.6\\%, +28.9\\%]$ . Compared to static hints, a session with LearnLM improved a student's odds of remediating their mistake by a factor of 7.4 [5.1, 11.0], corresponding to an ATE of  $+27.7\\%$ $[+24.6\\%, +30.4\\%]$ . Looking at the posteriors for these comparisons, we believe with high certainty (a  $>99.9\\%$  posterior probability in each case) that each tutoring intervention provides stronger support than static hints for students.\n\nStudents demonstrated an overall high success rate at resolving misconceptions, even when receiving only static hints (86.4%). Nevertheless, interactive tutoring produced further gains. Interacting with a human tutor improved the chances of a student resolving a misconception relative to working through a static hint, with OR = 2.9 [1.9, 4.6] (ATE: +8.1% [+5.6%, +10.3%]). Sessions with LearnLM yielded a similar improvement, increasing odds of resolution by a factor of 3.2 [2.0, 5.3] over receiving a static hint (ATE: +8.5% [+6.2%, +10.7%]). Again, we believe with high certainty (>99.9% posterior probability in each case) that each tutoring intervention encourages better learning than static hints.\n\nA direct comparison of the two tutoring conditions reveals a moderate probability that LearnLM's tutoring outperforms human tutors on these immediate metrics. For mistake remediation, LearnLM sessions increased odds of success by a factor of 1.3 [0.8, 2.1] relative to human tutors, reflecting an ATE of  $+1.8\\%$ $[-1.7\\%, +5.4\\%]$ . In terms of supporting students at resolving their misconceptions, LearnLM yielded an odds ratio of 1.2 [0.6, 2.1] compared to human tutors (ATE:  $+0.4\\%$ $[-2.5\\%, +3.3\\%]$ ). Overall, we estimate an  $84.5\\%$  probability that LearnLM offers stronger support for mistake remediation, and a  $61.3\\%$  probability that it\n\nTable F.1 | Sample sizes and unadjusted success rates by intervention type.  \n\n<table><tr><td>Intervention type</td><td>Mistake remediation</td><td>Misconception resolution</td></tr><tr><td>Static hint</td><td>65.4% [63.8%, 66.9%]</td><td>86.8% [85.7%, 88.0%]</td></tr><tr><td>Human tutor</td><td>91.2% [88.5%, 93.6%]</td><td>94.9% [92.6%, 96.8%]</td></tr><tr><td>LearnLM (supervised)</td><td>93.0% [90.4%, 95.3%]</td><td>95.4% [93.1%, 97.1%]</td></tr></table>\n\nTable F.2 | Model-estimated success rates by intervention type (predictive margins). Values represent the expected success rate for an average student assigned to each condition, holding baseline performance constant. Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean.\n\nprovides better support for misconception resolution.\n\n<table><tr><td>Contrast (A vs. B)</td><td>Odds ratio</td><td>Average treatment effect</td><td>P(A &gt; B)</td></tr><tr><td colspan=\"4\">Human tutor vs. Static hint</td></tr><tr><td>Mistake remediation</td><td>5.7 [4.1, 8.0]</td><td>+25.9% [+22.7%, +28.7%]</td><td>&gt;99.9%</td></tr><tr><td>Misconception resolution</td><td>3.0 [1.9, 4.7]</td><td>+8.1% [+5.6%, +10.3%]</td><td>&gt;99.9%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Static hint</td></tr><tr><td>Mistake remediation</td><td>7.4 [5.1, 11.0]</td><td>+27.7% [+24.7%, +30.5%]</td><td>&gt;99.9%</td></tr><tr><td>Misconception resolution</td><td>3.3 [2.0, 5.3]</td><td>+8.5% [+6.0%, +10.6%]</td><td>&gt;99.9%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Human tutor</td></tr><tr><td>Mistake remediation</td><td>1.3 [0.8, 2.1]</td><td>+1.8% [-1.7%, +5.4%]</td><td>84.8%</td></tr><tr><td>Misconception resolution</td><td>1.2 [0.6, 2.1]</td><td>+0.4% [-2.5%, +3.3%]</td><td>61.2%</td></tr><tr><td colspan=\"4\">Covariate: Baseline score (+1 SD)</td></tr><tr><td>Mistake remediation</td><td>1.7 [1.5, 1.8]</td><td>—</td><td>—</td></tr><tr><td>Misconception resolution</td><td>1.8 [1.6, 2.1]</td><td>—</td><td>—</td></tr></table>\n\nTable F.3 | Inferential comparisons between conditions. Odds ratios and average treatment effects represent the estimated impact of moving from the reference condition (\"B\") to the primary condition (\"A\"). Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean. Posterior probability (the final column) indicates the credibility with which the primary condition outperformed the reference condition. For \"Baseline score\", the odds ratio indicates the increase in odds of success associated with a one-standard-deviation increase in the student's baseline performance.\n\n# F.3.2. Learning transfer\n\nWe next examine whether the learning gains from tutoring extended to novel topics. Results from Appendix F.3.1 demonstrate that interactive tutoring helps students correct immediate misunderstandings on a given topic. Are the benefits of tutoring large enough to spill over to other topics? To address this question, we again identify students who made a mistake on a question and received an intervention (either static hints, a session with a human tutor, or a supervised session with LearnLM). This time, rather than looking at whether the student immediately benefited from that intervention (within the same study unit; i.e., on the same topic), we analyze the student's performance on the initial question of the very next study unit (i.e., on a distinct topic). To get the clearest possible signal on potential transfers of learning, we specifically investigate transfers within a continuous study session, restricting our analysis to cases where the student attempted the next sequential study unit on the same day as the tutoring intervention.\n\nUnlike our prior tests, this analysis allows us to include an overarching control group: students who answered the previous unit's question correctly, and thus received no intervention at all. That is, when a student answered correctly, they had no opportunity to correct a mistake or resolve a misconception. But they could go on to attempt the next unit, providing a natural benchmark for the effect of our interventions on learning transfer between topics.\n\nAs before, we observe notable differences in unadjusted success rates between intervention types. Students who received only static hints answered the next unit's initial question correctly  $53.3\\%$  of the time. Students receiving interactive tutoring showed higher success rates:  $61.7\\%$  for those with human tutors, and  $66.8\\%$  for those supported by human-supervised LearnLM. Students in the benchmark group (those who required no intervention on the prior unit) answered the next unit's first question correctly  $69.8\\%$  of the time.\n\nWe again estimate the general efficacy of these interventions using Bayesian logistic regression, controlling for baseline performance.\n\nFor knowledge transfer to the next study unit, we first compare these interventions against our benchmark of\n\n<table><tr><td>Intervention type (preceding unit)</td><td>N</td><td>Knowledge transfer</td></tr><tr><td>Static hint</td><td>2,385</td><td>53.3%</td></tr><tr><td>Human tutor</td><td>376</td><td>61.7%</td></tr><tr><td>LearnLM (supervised)</td><td>328</td><td>66.8%</td></tr><tr><td>None necessary</td><td>6,907</td><td>69.8%</td></tr></table>\n\ntypical student progress. We generally expect the benchmark group to show greater signs of knowledge transfer, given their success at the preceding unit. Indeed, students who answered incorrectly in the prior unit and received static hints failed to recover the benchmark group's performance, with  $\\mathrm{OR} = 0.58$  [0.52, 0.63] and an ATE of  $-12.9\\%$ $[-15.1\\%, -10.6\\%]$ . Students supported by human tutors also fell short of the benchmark group, with  $\\mathrm{OR} = 0.70$  [0.56, 0.85] and an ATE of  $-8.3\\%$ $[-13.4\\%, -3.6\\%]$ . Similarly, students tutored by LearnLM trailed behind the benchmark group, with  $\\mathrm{OR} = 0.89$  [0.70, 1.12] and an ATE of  $-2.8\\%$ $[-8.1\\%, +2.3\\%]$ . Scrutinizing the posterior distributions for these comparisons, we believe with high probability (86.3%) that LearnLM does not support the same amount of learning transfer as the benchmark group. We attribute near certainty (both  $>99.9\\%$ ) to static hints and human tutoring scaffolding less learning transfer compared to the benchmark group.\n\nShifting our focus to students needing support, both forms of interactive tutoring produced better knowledge transfer than did static hints. Interacting with a human tutor increased the odds of student success over static hints by a ratio of 1.22 [0.97, 1.50], for an estimated ATE of  $+4.6\\%$ $[-0.7\\%, +9.7\\%]$ . Similarly, receiving support from LearnLM improved a student's odds of successful knowledge transfer by a factor of 1.55 [1.21, 1.96] relative to static hints, corresponding to an ATE of  $+10.1\\%$ $[+4.6\\%, +15.4\\%]$ . Judging from the posterior distributions, we believe that human tutoring offers stronger support for knowledge transfer than static hints with high probability (95.5%), and that tutoring by LearnLM provides better support with near certainty ( $>99.9\\%$ ).\n\nFinally, we directly compare the two tutoring conditions. We estimate that receiving support from LearnLM improved a student's odds of success by a factor of 1.3 [0.9, 1.7] relative to human tutors, corresponding to an ATE of  $+5.5\\%$ $[-1.4\\%, +12.4\\%]$ . Based on this posterior distribution, we find a strong probability (93.6%) that LearnLM elicited greater knowledge transfer than human tutors alone.\n\nTable F.4 | Sample sizes and unadjusted success rates by intervention type.  \n\n<table><tr><td>Intervention type (preceding unit)</td><td>Knowledge transfer</td></tr><tr><td>Static hint</td><td>56.2% [54.2%, 58.2%]</td></tr><tr><td>Human tutor</td><td>60.7% [55.8%, 65.4%]</td></tr><tr><td>LearnLM (supervised)</td><td>66.2% [61.1%, 71.2%]</td></tr><tr><td>None necessary</td><td>69.0% [67.9%, 70.1%]</td></tr></table>\n\nTable F.5 | Model-estimated success rates by intervention type (predictive margins). Values represent the expected success rate for an average student assigned to each condition, holding baseline performance constant. Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean.\n\n<table><tr><td>Comparison (A vs. B)</td><td>Odds ratio</td><td>Average treatment effect</td><td>P(A &gt; B)</td></tr><tr><td colspan=\"4\">Static hint vs. No intervention needed</td></tr><tr><td>Knowledge transfer</td><td>0.6 [0.5, 0.6]</td><td>-12.9% [-15.1%, -10.6%]</td><td>&lt;0.1%</td></tr><tr><td colspan=\"4\">Human tutor vs. No intervention needed</td></tr><tr><td>Knowledge transfer</td><td>0.7 [0.6, 0.8]</td><td>-8.3% [-13.4%, -3.6%]</td><td>&lt;0.1%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. No intervention needed</td></tr><tr><td>Knowledge transfer</td><td>0.9 [0.7, 1.1]</td><td>-2.8% [-8.1%, +2.3%]</td><td>13.7%</td></tr><tr><td colspan=\"4\">Human tutor vs. Static hint</td></tr><tr><td>Knowledge transfer</td><td>1.2 [1.0, 1.5]</td><td>+4.6% [-0.7%, +9.7%]</td><td>95.5%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Static hint</td></tr><tr><td>Knowledge transfer</td><td>1.6 [1.2, 2.0]</td><td>+10.1% [+4.6%, +15.4%]</td><td>&gt;99.9%</td></tr><tr><td colspan=\"4\">LearnLM (supervised) vs. Human tutor</td></tr><tr><td>Knowledge transfer</td><td>1.3 [0.9, 1.7]</td><td>+5.5% [-1.4%, +12.4%]</td><td>93.6%</td></tr><tr><td colspan=\"4\">Covariate: Baseline score (+1 SD)</td></tr><tr><td>Knowledge transfer</td><td>1.6 [1.5, 1.7]</td><td>—</td><td>—</td></tr></table>\n\nTable F.6 | Inferential comparisons between conditions. Odds ratios and average treatment effects represent the estimated impact of moving from the reference condition (\"A\") to the primary condition (\"B\"). Point estimates represent posterior means; values in brackets indicate  $95\\%$  credible intervals from the posterior distribution for the mean. Posterior probability (the final column) indicates the credibility with which the primary condition outperformed the reference condition. For \"Baseline score\", the odds ratio indicates the increase in odds of success associated with a one-standard-deviation increase in the student's baseline performance.\n\n# G. Operational metrics\n\nUltimately, we wish to find social and technical educational solutions that can support students safely, effectively, and—crucially—scalably. Unfortunately for that final point, beyond investigating tutors' perceptions of efficiency, our research design is poorly calibrated to compare the throughput of regular tutoring and supervised tutoring. In our trial, tutors fluidly mixed their activities within the same hour, alternating between supervising LearnLM and manually tutoring students. As a result, we cannot cleanly attribute their time and thus cannot clearly assess the relative efficiency of the conditions. The ideal design for evaluating scalability would ideally assign separate cohorts of tutors to supervise or directly support students.\n\nStill, given students' and tutors' general satisfaction with the experience and out of our own curiosity, we conducted a post-hoc estimation exercise to gauge the potential implications of LearnLM for tutoring scalability. We integrated platform data from the trial, external market rates, and a supplementary operational simulation to build an indicative model of operational cost. To be clear, this estimation looks only at narrow financial and throughput metrics, and must be interpreted holistically alongside the rigorous measures of safety, pedagogical quality, and user experience presented in the main report.\n\n# G.1. Cost inputs\n\nWe first identified the basic cost inputs required for a tutoring session, based on commercial rates and platform data from the main trial.\n\nAI inference fees To estimate the computational costs of a supervised session, we calculated the expense for an external party to replicate our setup using Gemini 2.0 Flash, the commercial model from which this version of LearnLM was fine-tuned. Commercial pricing rates for Gemini 2.0 Flash are  $0.30 per 1 million input tokens and$ 2.50 per 1 million output tokens [42]. Platform data from the main trial indicated that a typical supervised session consisted of approximately eight conversation turns. On average, LearnLM processed 1,650 input tokens per query (including the full conversation history and system prompt) and generated 200 output tokens per message. This yields an average total computational cost of $0.005 (or £0.0037) per session.\n\nLabor fees The current average UK online tutor rate is £35.29 per hour [43].\n\n# G.2. Simulation of throughput capacity\n\nBecause we could not cleanly isolate tutor throughput in the main trial, we conducted a supplementary operational simulation with several of the tutors. Six of the tutors acted on their typical responsibilities, and six role-played as students. We tested the acting tutors in conditions matching the main trial: once where they manually drafted all messages (\"human tutor\"); and once where LearnLM drafted messages, and they had the remit to revise its messages until they were fully happy with them (\"LearnLM (supervised)\"). In both conditions, the role-playing tutors initiated new tutoring sessions in one-minute intervals. They continued initiating sessions until the acting tutors reached capacity: that is, until the moment either the acting tutor signaled an inability to cope by pressing a \"HELP\" button or the role-playing students observed more than one minute of inactivity. We recorded the number of active sessions at that precise moment.\n\nTutors took longer to complete the average supervised session (5.1 minutes) than they did to complete the average session on their own (3.9 minutes). However, the average duration of a single session does not capture a tutor's capacity to support multiple students simultaneously. Tutors working alone sustained an average of 2.3 concurrent sessions. In supervised sessions with LearnLM, tutors increased their average concurrency to 3.5 sessions.\n\n# G.3. Analysis\n\nCombining the concurrency rates and the session durations from the operational simulation, we estimate that LearnLM increased overall tutor throughput from 35.4 to 41.2 sessions per hour (assuming a sustained student load). As shown in Table G.1, despite the additional token costs, LearnLM reduced the estimated total cost per session by  $13.6\\%$ , from £0.997 to £0.861.\n\n<table><tr><td>Metric</td><td>Session with human tutor alone</td><td>Supervised session with LearnLM</td></tr><tr><td>Average session duration (minutes)</td><td>3.9</td><td>5.1</td></tr><tr><td>Average concurrency (sessions)</td><td>2.3</td><td>3.5</td></tr><tr><td>Estimated throughput (sessions per hour)</td><td>35.38</td><td>41.18</td></tr><tr><td>Tutor labor cost (per hour)</td><td>£35.29</td><td>£35.29</td></tr><tr><td>LearnLM token cost (per session)</td><td>—</td><td>£0.0037</td></tr><tr><td>Total cost (per session)</td><td>£0.997</td><td>£0.861</td></tr></table>\n\nTable G.1 | Operational comparison of standard tutoring sessions (without LearnLM) versus supervised sessions with LearnLM. Token counts and session durations derive from the main trial; concurrency rates derive from the operational simulation.\n\n# H. Example transcript\n\n![](/uploads/images/02197db0-3de5-4390-9690-609c0f31a4c1/d222c8970b423e10b349f71f9a7fb319042781ea1ba92c207b7cbab636efd3e0.jpg)  \nFigure H.1 | Transcript of an example supervised tutoring session with LearnLM. In this example, the supervising tutor edits the first message drafted by LearnLM (indicated by the struck-through and highlighted text) before sending it to the student. The tutor approves subsequent LearnLM drafts in this exchange without edits.",
    "translated_content": null,
    "created_at": "2025-12-16 02:26:31.441436",
    "updated_at": "2025-12-16 02:26:39.348675",
    "doi": null,
    "arxiv_id": "2507.18882",
    "embedding": [
      -0.443359375,
      1.3984375,
      -1.1171875,
      -3.40625,
      -4.3125,
      0.3046875,
      -0.06787109375,
      -1.1640625,
      3.015625,
      3.4375,
      0.85546875,
      0.859375,
      2.390625,
      3.125,
      0.84765625,
      3.3125,
      -0.84765625,
      2.015625,
      -0.466796875,
      -8.3125,
      0.4921875,
      1.4453125,
      2.359375,
      -6.65625,
      4.25,
      -2.890625,
      -1.5546875,
      0.6875,
      0.5546875,
      -1.6640625,
      5,
      -6.25,
      -0.78125,
      0.63671875,
      -2.8125,
      -0.2275390625,
      -4.5625,
      -0.5546875,
      5.375,
      2.34375,
      -5.9375,
      0.8359375,
      3.265625,
      3.890625,
      -1.2890625,
      4.40625,
      1.5625,
      0.5859375,
      -0.4921875,
      -0.66796875,
      -4.8125,
      -4.59375,
      6.6875,
      -1.171875,
      4.53125,
      -3.625,
      -5.5,
      7.53125,
      -5.90625,
      -1.90625,
      2.15625,
      -3.953125,
      2.953125,
      2.671875,
      2.234375,
      1.4140625,
      2.078125,
      -1.46875,
      -1.9453125,
      2.4375,
      -0.0947265625,
      1.8359375,
      5.28125,
      -5.3125,
      6.09375,
      9.125,
      1.6640625,
      3.53125,
      -3.453125,
      4.0625,
      -6.3125,
      4.5625,
      1.734375,
      -1.0390625,
      4.375,
      0.11767578125,
      0.9453125,
      2.09375,
      -1.2890625,
      0.74609375,
      -1.4375,
      0.80078125,
      -2.875,
      -1.390625,
      -0.11669921875,
      5.28125,
      -2.015625,
      -4,
      -5.90625,
      1.203125,
      -2.875,
      -2.21875,
      -1.171875,
      -6.90625,
      -4.0625,
      -4.15625,
      -3.140625,
      -7.46875,
      0.88671875,
      -2.578125,
      -2.296875,
      0.0147705078125,
      -0.2431640625,
      -0.86328125,
      -0.036865234375,
      -1.25,
      1.8359375,
      -5.84375,
      -3.875,
      0.49609375,
      1.46875,
      0.296875,
      -2.546875,
      -2.046875,
      2.890625,
      1.3828125,
      -4.8125,
      4.5625,
      8.0625,
      0.83203125,
      6.15625,
      -0.052001953125,
      3.09375,
      0.1552734375,
      -6.375,
      0.70703125,
      -3.109375,
      -0.6796875,
      1.9765625,
      5.78125,
      -5.65625,
      1.4375,
      -1.7890625,
      -5.84375,
      3.21875,
      2.109375,
      -5.4375,
      -0.181640625,
      1.8125,
      -6.53125,
      0.6015625,
      3.3125,
      -0.921875,
      6.75,
      -0.89453125,
      -3.921875,
      3.34375,
      3.28125,
      -1.5703125,
      0.361328125,
      0.26953125,
      3.875,
      -2.1875,
      1.7109375,
      -0.8515625,
      -1.0703125,
      -6.96875,
      3.390625,
      1.0078125,
      -0.65234375,
      -0.1513671875,
      16.875,
      1.953125,
      -1.4140625,
      1.34375,
      -0.05029296875,
      0.419921875,
      5,
      2.671875,
      0.392578125,
      1.109375,
      3.078125,
      -2.78125,
      3.46875,
      0.70703125,
      1.2109375,
      4.84375,
      -5.59375,
      -1.5390625,
      -1.3203125,
      0.2734375,
      4.15625,
      4.59375,
      1.9921875,
      -2.71875,
      -0.57421875,
      1.6953125,
      2.03125,
      -1.9296875,
      3.078125,
      -0.5546875,
      -9.6875,
      3.59375,
      -2.21875,
      -5.0625,
      0.32421875,
      3.890625,
      -1.9453125,
      1.6484375,
      -0.4140625,
      1.9609375,
      3.46875,
      0.625,
      1.109375,
      7.625,
      1.3515625,
      2.546875,
      -2.390625,
      5.03125,
      2.65625,
      4.5625,
      0.3828125,
      -0.466796875,
      -0.72265625,
      -1.71875,
      2.171875,
      1.828125,
      3.34375,
      2.78125,
      7.15625,
      -3.359375,
      -0.46484375,
      3.546875,
      -2.59375,
      -6.1875,
      -2.265625,
      -2.84375,
      0.70703125,
      -3.9375,
      1.5234375,
      -2.921875,
      -2.765625,
      3.515625,
      1.953125,
      -0.1494140625,
      -2.28125,
      -1.8203125,
      -3.140625,
      0.048828125,
      -5.46875,
      0.349609375,
      1.734375,
      -3.609375,
      -3.546875,
      5.9375,
      4.15625,
      -0.09228515625,
      -0.072265625,
      -2.609375,
      -4.90625,
      3.921875,
      -3.046875,
      -3.5,
      6.25,
      4.15625,
      -3.3125,
      1.71875,
      3.0625,
      1.9453125,
      2.03125,
      1.46875,
      -3.90625,
      -4.21875,
      0.36328125,
      -0.416015625,
      5.4375,
      2.859375,
      -5.4375,
      0.8671875,
      -0.921875,
      -3.859375,
      -9.4375,
      4.65625,
      -5.84375,
      8.75,
      -0.27734375,
      -1.4453125,
      3.15625,
      -1.90625,
      9.875,
      3.375,
      1.953125,
      2.140625,
      -0.609375,
      -2.765625,
      1.171875,
      -3.78125,
      0.953125,
      -5.53125,
      -0.169921875,
      4.375,
      1.8671875,
      -1.015625,
      0.4140625,
      -0.92578125,
      4.03125,
      -0.341796875,
      -2.953125,
      0.98828125,
      4.625,
      -2.71875,
      2.25,
      5.25,
      -2.796875,
      3.90625,
      -5.3125,
      -3.546875,
      3.046875,
      -0.81640625,
      -1.734375,
      -7.71875,
      -4.8125,
      -2.25,
      -0.73828125,
      -2.421875,
      -2.859375,
      0.011962890625,
      1.6328125,
      5.3125,
      -0.69140625,
      2.359375,
      2.75,
      -7.90625,
      -8.75,
      6.03125,
      -2.609375,
      0.6875,
      3,
      -3.015625,
      5.6875,
      -1.953125,
      -2.078125,
      -0.091796875,
      -0.6875,
      -2.5625,
      1.84375,
      5.90625,
      -2.96875,
      0.9140625,
      -4.6875,
      5.09375,
      2.3125,
      -1.8046875,
      4.5625,
      7.03125,
      -4.53125,
      0.7734375,
      0.62890625,
      0.5390625,
      1.234375,
      -0.419921875,
      -1.90625,
      5.0625,
      1.2109375,
      1.9140625,
      -5.9375,
      -1.5625,
      1.4453125,
      -1.3359375,
      0.78125,
      0.1025390625,
      -4.34375,
      -0.70703125,
      0.62109375,
      1.375,
      0.162109375,
      0.7109375,
      -3.390625,
      -3.765625,
      0.42578125,
      -0.8359375,
      -0.59375,
      0.2734375,
      -0.37109375,
      5.96875,
      1.9375,
      -2.21875,
      4.5625,
      0.490234375,
      -4.125,
      -3.5625,
      0.75,
      -2.90625,
      0.46875,
      4.96875,
      0.703125,
      -3.734375,
      3.59375,
      -1.5,
      -3.203125,
      3.9375,
      1.578125,
      0.41796875,
      -2.25,
      -2.828125,
      0.337890625,
      1.1015625,
      -7.21875,
      1.78125,
      -0.9453125,
      -0.69140625,
      2.8125,
      1.125,
      -2.671875,
      1.109375,
      3.015625,
      -1.3203125,
      1.875,
      -4.21875,
      -1.109375,
      -3.46875,
      2.53125,
      3.609375,
      -3.203125,
      0.10205078125,
      0.7109375,
      2.703125,
      5.46875,
      1.7109375,
      -1.1171875,
      -0.208984375,
      -3.296875,
      -0.828125,
      0.8359375,
      -3.1875,
      -5.96875,
      2.53125,
      -4.96875,
      -5.0625,
      1.34375,
      2.828125,
      0.236328125,
      5.25,
      5.53125,
      -4.625,
      -3.25,
      3.890625,
      6.3125,
      -3.484375,
      -4.15625,
      1.140625,
      -0.5546875,
      0.83984375,
      0.78125,
      4.5625,
      -0.76171875,
      -3.84375,
      2.421875,
      2.3125,
      0.2734375,
      4.40625,
      0.314453125,
      -2.96875,
      2.078125,
      -2.46875,
      -3.25,
      -0.9375,
      3.828125,
      2.03125,
      -7.1875,
      -10.25,
      4.28125,
      1.234375,
      -0.89453125,
      -2.5,
      3.84375,
      2.453125,
      -0.10107421875,
      -0.140625,
      -3.265625,
      -1.7578125,
      -1.2734375,
      3.8125,
      1.1015625,
      0.10107421875,
      -2.328125,
      -5.1875,
      6.71875,
      3.03125,
      2.421875,
      1.1171875,
      -0.35546875,
      2.25,
      -3.0625,
      3.1875,
      4.3125,
      7.8125,
      -6.46875,
      -2.375,
      0.193359375,
      -7.4375,
      -1.21875,
      -2.609375,
      -0.75,
      -1.7578125,
      2.484375,
      6.625,
      -3.03125,
      -2.703125,
      -1.5546875,
      3.9375,
      -2.609375,
      -0.126953125,
      -0.578125,
      -3.296875,
      -0.921875,
      0.921875,
      2.0625,
      3.421875,
      -2.921875,
      -1.8046875,
      -0.62890625,
      -1,
      -0.3984375,
      -0.64453125,
      -0.4609375,
      1.15625,
      -2.6875,
      1.203125,
      4.0625,
      1.15625,
      3.578125,
      -1.1953125,
      -2.90625,
      -2.34375,
      -0.96875,
      -0.24609375,
      -0.46875,
      2.53125,
      0.984375,
      1.1953125,
      2.703125,
      -3.984375,
      -0.06298828125,
      0.2392578125,
      0.578125,
      -3.765625,
      2.171875,
      4.8125,
      4.59375,
      2.390625,
      1.7578125,
      -3.328125,
      0.126953125,
      0.8359375,
      -2.65625,
      -2.6875,
      -1.2734375,
      3.21875,
      -2.546875,
      -2.484375,
      -1.7109375,
      -0.30859375,
      0.2451171875,
      -1.25,
      -0.8984375,
      3.453125,
      3.75,
      1.5859375,
      0.09033203125,
      3.15625,
      5.53125,
      -1.390625,
      0.58203125,
      3.921875,
      3.140625,
      -4.71875,
      -5.3125,
      -3.875,
      1.234375,
      4.25,
      -6.25,
      1.9921875,
      0.03369140625,
      6.375,
      -1.84375,
      0.43359375,
      -14.5625,
      3.171875,
      0.2060546875,
      -5.15625,
      0.65625,
      -3.09375,
      0.7890625,
      -0.4375,
      0.66015625,
      1.625,
      -0.7109375,
      -1.5234375,
      4.34375,
      -1.0859375,
      -3.578125,
      5.46875,
      1.328125,
      -3.390625,
      1.6015625,
      -2.390625,
      -3.515625,
      0.462890625,
      -1.2734375,
      0.83203125,
      1.6171875,
      4.71875,
      0.1298828125,
      1.828125,
      0.10498046875,
      -4.3125,
      -1.484375,
      2.265625,
      3.46875,
      -0.275390625,
      1.6171875,
      -4.53125,
      3.015625,
      -2.265625,
      0.421875,
      2.484375,
      -2.875,
      2.28125,
      3.171875,
      -2.046875,
      -0.408203125,
      -2.984375,
      -0.275390625,
      5.5625,
      4.03125,
      -2.796875,
      1.1171875,
      0.228515625,
      0.26953125,
      6.28125,
      -2.65625,
      -1.8828125,
      -1.859375,
      2.765625,
      1.46875,
      -4.21875,
      4.96875,
      -1.5625,
      -2.125,
      0.00445556640625,
      -1.203125,
      0.9375,
      0.2353515625,
      1.1484375,
      4.53125,
      -2.828125,
      -1.2109375,
      1.3828125,
      -2.640625,
      -5.59375,
      -2.234375,
      0.10986328125,
      -4.09375,
      4.78125,
      -0.05224609375,
      -0.11279296875,
      0.09521484375,
      -2.8125,
      0.53125,
      2.015625,
      1.5703125,
      1.34375,
      4.25,
      2.46875,
      -2.171875,
      2.1875,
      -5.65625,
      -5.625,
      -0.396484375,
      -4.1875,
      -1.0703125,
      2.484375,
      2.578125,
      -0.62890625,
      0.7421875,
      -1.9453125,
      -4.71875,
      -5.09375,
      -3.09375,
      0.3984375,
      -0.5078125,
      2.890625,
      1.7578125,
      6.15625,
      -2.125,
      1,
      1.9296875,
      0.31640625,
      -0.8359375,
      -3.90625,
      0.8046875,
      -8.4375,
      1.65625,
      5,
      5.71875,
      -4.1875,
      8.25,
      2.5625,
      -0.5703125,
      -0.46484375,
      6.5625,
      -3.671875,
      -0.1669921875,
      0.083984375,
      -2.859375,
      -1.6328125,
      -3.671875,
      -0.427734375,
      -1.21875,
      4.1875,
      0.423828125,
      -2.015625,
      0.09716796875,
      -6.15625,
      -0.0986328125,
      -0.1650390625,
      -0.1787109375,
      2.828125,
      1.1640625,
      1.0390625,
      -0.76953125,
      2.78125,
      3.8125,
      0.859375,
      0.04248046875,
      -1.265625,
      2.21875,
      2.421875,
      2.9375,
      -1.421875,
      -6.125,
      0.5546875,
      -2.5,
      -1.1015625,
      1.2265625,
      -0.2021484375,
      0.2333984375,
      5.15625,
      1.6484375,
      -4.625,
      -2.75,
      2.734375,
      -4.03125,
      -0.1494140625,
      0.4375,
      3.484375,
      0.2421875,
      4.28125,
      -0.484375,
      -2.484375,
      -3.1875,
      8.1875,
      4.65625,
      -0.79296875,
      -0.82421875,
      4.3125,
      1.21875,
      0.80859375,
      -3.890625,
      -6.125,
      1.6171875,
      1.2265625,
      -2.03125,
      -0.44921875,
      8.1875,
      -4.375,
      0.75390625,
      -0.60546875,
      0.028076171875,
      0.53125,
      0.490234375,
      2.40625,
      -0.369140625,
      1.9609375,
      -0.76953125,
      1.1015625,
      1.1171875,
      -0.349609375,
      -1.046875,
      -1.0703125,
      -0.349609375,
      -3,
      2.921875,
      1.296875,
      -1.4453125,
      -0.9765625,
      1.1796875,
      0.54296875,
      4.1875,
      6.59375,
      2.109375,
      0.00482177734375,
      3.34375,
      6.6875,
      -1.890625,
      8.625,
      1.359375,
      9.375,
      -4.90625,
      -2.75,
      4.53125,
      2.53125,
      0.9453125,
      -0.8984375,
      -7.0625,
      -2.203125,
      -0.62890625,
      0.279296875,
      -4.125,
      0.0213623046875,
      -3.359375,
      -0.8828125,
      4.65625,
      1.8671875,
      3.109375,
      2.90625,
      3.5,
      -0.703125,
      -0.2490234375,
      -2.203125,
      -4.65625,
      -2.765625,
      1.25,
      1.9609375,
      -1.890625,
      2.53125,
      0.048828125,
      5.09375,
      1.8671875,
      0.1591796875,
      -2.53125,
      4.9375,
      -2.34375,
      -1.8984375,
      2.5,
      1.90625,
      1.234375,
      0.875,
      3.71875,
      -5.59375,
      -0.83203125,
      8.5,
      2.09375,
      -3.234375,
      2.703125,
      -1.6015625,
      3.921875,
      -6.78125,
      -2.15625,
      -0.2275390625,
      2.828125,
      -5.5625,
      -3.546875,
      -0.703125,
      1.9375,
      -5.15625,
      0.421875,
      4.71875,
      -3.796875,
      1.109375,
      -1.328125,
      -3.484375,
      1.0625,
      1.4765625,
      4.4375,
      0.0162353515625,
      -3.0625,
      -3.21875,
      -3.609375,
      -2.015625,
      0.26953125,
      -0.80078125,
      1.6484375,
      1.9609375,
      -2.828125,
      0.1748046875,
      -6.1875,
      1.3984375,
      -5.28125,
      3.953125,
      3.953125,
      -3.59375,
      -4.34375,
      -2.078125,
      -6.15625,
      -3.421875,
      -2.53125,
      -3.96875,
      -2.46875,
      -5.6875,
      -0.91015625,
      1.515625,
      -7.21875,
      -0.09033203125,
      -2.15625,
      -0.11767578125,
      2.5,
      0.013427734375,
      1.2265625,
      -6.59375,
      2.140625,
      -0.9765625,
      0.353515625,
      0.6171875,
      1.65625,
      2.859375,
      3.953125,
      1.7734375,
      1.2265625,
      -3.296875,
      5.46875,
      -1.703125,
      7.28125,
      5.375,
      1.9765625,
      -5.03125,
      3.359375,
      -1.0859375,
      0.2333984375,
      -7.25,
      2.734375,
      1.0625,
      0.75390625,
      0.5625,
      1.078125,
      4.71875,
      -2.796875,
      -4.84375,
      2.765625,
      -3.484375,
      -0.0888671875,
      1.2734375,
      0.72265625,
      4.34375,
      -0.314453125,
      0.44921875,
      1.3515625,
      1.875,
      0.53125,
      -0.8515625,
      3.25,
      -4.65625,
      -0.419921875,
      -1.03125,
      0.67578125,
      -0.008056640625,
      -3.171875,
      -0.021240234375,
      -0.1884765625,
      1.1171875,
      2.140625,
      4.40625,
      3.625,
      2.125,
      4.15625,
      0.275390625,
      -0.859375,
      -1.2578125,
      -2.640625,
      0.7421875,
      1.4453125,
      2.765625,
      -2.796875,
      0.341796875,
      -2.0625,
      0.5390625,
      1.7890625,
      -3.171875,
      -0.30078125,
      -3.96875,
      -4.78125,
      2.109375,
      0.625,
      0.314453125,
      0.173828125,
      2.65625,
      1.9375,
      2.34375,
      -0.25,
      3.109375,
      0.2451171875,
      -4.34375,
      3.125,
      -2.234375,
      -4.53125,
      2.40625,
      1.390625,
      4.5625,
      1.0859375,
      1.4921875,
      -3.359375,
      -0.5859375,
      3.875,
      -3.828125,
      0.79296875,
      5.6875,
      -1.8671875,
      -0.8125,
      -0.1923828125,
      1.03125,
      2.109375,
      -2.078125,
      3.765625,
      4.125,
      4.28125,
      1.5390625,
      -0.3828125,
      -3.484375,
      -1.7890625,
      -0.5546875,
      -0.2001953125,
      -0.90234375,
      0.62109375,
      1.4140625,
      -0.345703125,
      -0.37890625,
      -3.34375,
      0.66796875,
      -3.734375,
      3.03125,
      3.671875,
      -1.8984375,
      -0.62109375,
      -1.1171875,
      -2.3125,
      -0.77734375,
      2.359375,
      2.09375,
      -1.609375,
      2.671875,
      2.90625,
      -1.6015625,
      0.453125,
      1.1796875,
      0.5390625,
      2.828125,
      -0.8515625,
      2.625,
      0.0830078125,
      -2.578125,
      -1.671875,
      -2.28125,
      0.828125,
      3.0625,
      4.5,
      -0.255859375,
      2.921875,
      -0.65625,
      -3.203125,
      2.859375,
      -3.21875,
      -2.265625,
      -0.9140625,
      -2.875,
      -0.240234375,
      -3.34375,
      -0.00408935546875,
      -2.8125,
      4.5625,
      -9.1875,
      5.28125,
      -3.5625,
      5.46875,
      2.5,
      0.1904296875,
      -0.15625,
      -4.53125,
      3.75,
      -3.390625,
      -1.265625,
      3.765625,
      -1.34375,
      3.875,
      -1.453125,
      -1.453125,
      -0.50390625,
      -2.828125,
      -0.193359375,
      -2.171875,
      -0.3671875,
      -2.078125,
      2.359375,
      -9.1875,
      -3.375,
      0.09375,
      2.21875,
      1.390625,
      -1.0234375,
      0.69921875,
      -2.28125,
      2.328125,
      -1.484375,
      2.25,
      -2.53125,
      -3.4375,
      2.15625,
      -1.8359375,
      2.890625,
      1.09375,
      -0.474609375,
      -2.53125,
      -1.8359375,
      -4.5625,
      -2.296875,
      -1.671875,
      2.453125,
      -4.03125,
      -1.109375,
      -0.21484375,
      2.5625,
      1.328125,
      -1.6640625,
      -2.171875,
      1.703125,
      6.34375,
      0.8671875,
      -0.6328125,
      -1.84375,
      0.98046875,
      -3.921875,
      -3.6875,
      -2.875,
      2.1875,
      2.0625,
      -4.375,
      2.46875,
      0.083984375,
      2.640625,
      3.46875,
      -0.0191650390625,
      -1.21875,
      1.6171875,
      1.8359375,
      0.63671875,
      0.8671875,
      3.140625,
      0.326171875,
      3.046875,
      -3.59375,
      -3,
      -2.5,
      1.3828125,
      -1.359375,
      -1.34375,
      -0.052978515625,
      0.00665283203125,
      -1.3671875,
      -1.8671875,
      -3.03125,
      -0.91015625,
      4.75,
      0.498046875,
      6.5,
      1.7578125,
      -1.8984375,
      0.97265625,
      0.1064453125,
      4.4375,
      3.421875,
      0.92578125,
      0.5546875,
      1.140625,
      -2.21875,
      5.46875,
      -3.625,
      -5.3125,
      -4.75,
      -0.59765625,
      6.40625,
      0.66796875,
      -1.0625,
      1.5390625,
      -0.10888671875,
      1.5703125,
      2.71875,
      4.90625,
      -0.6484375,
      -1.984375,
      -1.640625,
      3.0625,
      -1.8984375,
      -4.96875,
      2.515625,
      3.34375,
      -1.3671875,
      1.046875,
      2.171875,
      4.8125,
      -4.375,
      0.21484375,
      -1.5859375,
      -3.328125,
      -3.15625,
      3.953125,
      0.2099609375,
      -1.8984375,
      1.921875,
      -3.5625,
      -0.6171875,
      0.58984375,
      0.236328125,
      4.09375,
      -2.453125,
      1.890625,
      0.1455078125,
      3.9375,
      -0.87890625,
      -1.9921875,
      -1.1875,
      1.5859375,
      0.52734375,
      -1.4375,
      -1.046875,
      -3.765625,
      -2.625,
      -1.390625,
      -9.75,
      1.6015625,
      3.484375,
      1.0078125,
      1.140625,
      -2.671875,
      2.578125,
      3.015625,
      -3.5625,
      -5.1875,
      -2.109375,
      2.03125,
      2.5625,
      0.283203125,
      -4.1875,
      3.859375,
      0.126953125,
      0.578125,
      -5.75,
      4.875,
      -3.046875,
      4.1875,
      2.65625,
      4.46875,
      -5.5625,
      -0.65234375,
      -1.0703125,
      -0.189453125,
      -3.703125,
      -0.95703125,
      -2.140625,
      0.72265625,
      4.1875,
      0.1982421875,
      -3.5,
      -1.6328125,
      -2.671875,
      2.84375,
      0.033935546875,
      0.228515625,
      -3.71875,
      2.265625,
      -6.34375,
      -1.109375,
      3.8125,
      -1.21875,
      -2.25,
      1.2578125,
      3.0625,
      8.125,
      2.046875,
      1.03125,
      -4.03125,
      1.5078125,
      -1.09375,
      -3.625,
      -5.0625,
      1.4375,
      -0.65234375,
      -1.25,
      2.125,
      -4.4375,
      2.328125,
      -2.953125,
      0.5546875,
      -2.46875,
      0.39453125,
      0.166015625,
      2.3125,
      1.625,
      0.86328125,
      2.453125,
      -0.224609375,
      4.1875,
      2.359375,
      0.123046875,
      1.15625,
      -0.35546875,
      0.1015625,
      -5.21875,
      2.546875,
      -1.2890625,
      -1.28125,
      4.53125,
      4.59375,
      -5.75,
      0.26171875,
      -0.859375,
      3.140625,
      -1.953125,
      -3.5,
      -1.671875,
      3.578125,
      -0.546875,
      -0.7265625,
      -2.265625,
      -0.578125,
      1.953125,
      -2.8125,
      1.15625,
      -1.28125,
      3.953125,
      -4.5625,
      -2.328125,
      5.28125,
      0.265625,
      3.6875,
      -3.6875,
      3.140625,
      3.46875,
      1.0625,
      1.6015625,
      0.62890625,
      -0.359375,
      -2.828125,
      1.1875,
      -5.78125,
      2.421875,
      -7.125,
      -0.5234375,
      -1.171875,
      -1.7421875,
      -2.25,
      4.6875,
      3.1875,
      0.10595703125,
      -1.0078125,
      -1.3203125,
      -7.21875,
      -2.515625,
      -1.0546875,
      -1.5078125,
      -4.28125,
      1.7109375,
      -2.265625,
      1.2109375,
      2.28125,
      3.65625,
      -0.6328125,
      -2.59375,
      3.71875,
      -2.6875,
      2.0625,
      -2.234375,
      0.2890625,
      0.3671875,
      -3.359375,
      1.3671875,
      1.421875,
      5.375,
      -4.125,
      0.3828125,
      -3.59375,
      -1.625,
      -0.466796875,
      1.2890625,
      -0.126953125,
      1.546875,
      3.109375,
      -0.83203125,
      2.984375,
      4.3125,
      -2.28125,
      -2.40625,
      3.78125,
      0.51171875,
      4.28125,
      1.4453125,
      0.78515625,
      -2.15625,
      3.828125,
      1.328125,
      -3.28125,
      4.125,
      1.1875,
      0.2451171875,
      -4.65625,
      2.40625,
      3.3125,
      4.15625,
      0.201171875,
      3.578125,
      3,
      1.2734375,
      4.84375,
      6.96875,
      -0.33203125,
      -0.427734375,
      0.271484375,
      -0.171875,
      1.0390625,
      -2.171875,
      2.609375,
      -0.17578125,
      -2.1875,
      3.421875,
      -0.53125,
      3.796875,
      0.92578125,
      -0.287109375,
      0.921875,
      5,
      -3.0625,
      1.859375,
      -5.875,
      0.41796875,
      -3.609375,
      1.765625,
      -5.71875,
      -2.1875,
      2.03125,
      5.875,
      -1.359375,
      -3.703125,
      6.46875,
      4.09375,
      0.52734375,
      -2.875,
      4.4375,
      0.73046875,
      -1.15625,
      -5.96875,
      -3.328125,
      6.46875,
      2.765625,
      0.08447265625,
      -3.078125,
      1.6484375,
      2.96875,
      -1.3515625,
      -7.3125,
      1.5625,
      0.08349609375,
      -4.125,
      -4.96875,
      -1.265625,
      1.5625,
      -4.8125,
      1.3515625,
      0.423828125,
      -2.390625,
      4.0625,
      -0.5,
      2.984375,
      2.1875,
      -1.28125,
      3.140625,
      -0.435546875,
      -0.5390625,
      -1.15625,
      4.28125,
      -2.515625,
      3.890625,
      -1.5703125,
      -1.1171875,
      -1.6171875,
      -0.68359375,
      -0.703125,
      -3.40625,
      -0.99609375,
      2.640625,
      3.671875,
      -1.15625,
      -3.265625,
      1.1328125,
      0.8984375,
      -2.40625,
      -1.15625,
      1.71875,
      -1,
      -0.71484375,
      0.34375,
      -1.2109375,
      1.84375,
      -2.359375,
      0.61328125,
      0.123046875,
      -1.765625,
      -1.8671875,
      -2.78125,
      -2.859375,
      2.78125,
      -2.015625,
      1.109375,
      0.267578125,
      -1.71875,
      -1.765625,
      4.34375,
      -0.1865234375,
      2.125,
      -2.96875,
      1.015625,
      2.671875,
      1.609375,
      -0.447265625,
      -4.125,
      -1.828125,
      1.5,
      -1.421875,
      -1.09375,
      -0.5,
      -1.75,
      3.421875,
      -4.84375,
      -1.4375,
      -0.3046875,
      0.765625,
      -1.0859375,
      -10.9375,
      1.9296875,
      0.46484375,
      -2.234375,
      0.51953125,
      -0.79296875,
      0.5625,
      3.765625,
      1.859375,
      2.640625,
      -1.1328125,
      -5.40625,
      0.54296875,
      19.125,
      -3.484375,
      -2.859375,
      0.412109375,
      -0.12890625,
      -0.45703125,
      5.96875,
      0.169921875,
      0.029052734375,
      -0.73046875,
      0.89453125,
      3.484375,
      4.34375,
      0.546875,
      0.259765625,
      -0.05224609375,
      4.34375,
      -2.828125,
      -1.6953125,
      -2.5625,
      -4.53125,
      0.953125,
      -4.4375,
      3.078125,
      -2.421875,
      0.8203125,
      1.453125,
      -4.34375,
      -2.8125,
      -4.125,
      -0.9296875,
      -1.1328125,
      -5.09375,
      3.21875,
      0.609375,
      -3.71875,
      -1.6796875,
      2.109375,
      -0.162109375,
      -2.25,
      -5,
      -2.5625,
      2.171875,
      -1.9921875,
      -1.28125,
      -0.181640625,
      -3.421875,
      -1.765625,
      -1.359375,
      3.53125,
      -2.15625,
      -1.3828125,
      -3.984375,
      2.6875,
      3.0625,
      -2.65625,
      1.6171875,
      -4,
      -2.25,
      -4.71875,
      -0.330078125,
      -0.2109375,
      -3.90625,
      -2.609375,
      -2.515625,
      -3.53125,
      1.3359375,
      0.7109375,
      2.078125,
      2.671875,
      -5.65625,
      -4.21875,
      2.78125,
      1.65625,
      -0.1474609375,
      -2,
      0.89453125,
      0.640625,
      1.8203125,
      2.15625,
      -2.875,
      0.8125,
      -3.171875,
      -1.0546875,
      -1.21875,
      0.703125,
      -3.703125,
      2.984375,
      1.421875,
      -0.91015625,
      6.875,
      -4.09375,
      1.1796875,
      1.0703125,
      -3.890625,
      -1.6875,
      0.095703125,
      1.859375,
      -2.78125,
      -0.0908203125,
      4.65625,
      -2.515625,
      0.052001953125,
      -0.455078125,
      2.359375,
      -0.5625,
      1.5546875,
      -2.28125,
      3.84375,
      -0.31640625,
      -0.91015625,
      3.328125,
      1.234375,
      -1.2265625,
      -1.4921875,
      3.734375,
      -2.78125,
      -1.46875,
      -2.671875,
      -2.453125,
      1.3671875,
      0.56640625,
      -2.4375,
      0.09423828125,
      -7.71875,
      -5.53125,
      -2.796875,
      -3.359375,
      2.1875,
      -2.25,
      1.09375,
      -0.0306396484375,
      -3.921875,
      -1.0390625,
      1.0703125,
      -1.859375,
      3.265625,
      4.28125,
      1.7421875,
      0.365234375,
      -1.1015625,
      -0.1484375,
      2.328125,
      -0.828125,
      -1.03125,
      0.9765625,
      -3.4375,
      0.359375,
      2.375,
      1.9453125,
      -4,
      3.484375,
      -0.451171875,
      -2.140625,
      -1.859375,
      1.7734375,
      0.0673828125,
      -3.234375,
      -1.0390625,
      1.4609375,
      -2.265625,
      -1.6796875,
      -0.9765625,
      -7.9375,
      0.25390625,
      1.3828125,
      2.9375,
      1.21875,
      -2.796875,
      2.59375,
      2.65625,
      -6.59375,
      1.640625,
      -3.5625,
      3.546875,
      -4.46875,
      3.203125,
      2.9375,
      -0.640625,
      2.96875,
      3.140625,
      1.8046875,
      -0.6796875,
      -1.421875,
      0.984375,
      0.94140625,
      -2.53125,
      5.5625,
      3.328125,
      -0.37109375,
      -1.7109375,
      -4.53125,
      -3.015625,
      4.5625,
      5.84375,
      -4.625,
      0.9609375,
      -0.703125,
      -1.8671875,
      -1.421875,
      -1.7890625,
      1.2890625,
      0.734375,
      0.5625,
      6.03125,
      1.3203125,
      -1.3203125,
      -0.71875,
      -3.703125,
      -1.734375,
      -2.9375,
      3.171875,
      2.921875,
      2.4375,
      -4.90625,
      7.15625,
      4.03125,
      -1.21875,
      -1.0078125,
      -0.11328125,
      3.3125,
      -2.609375,
      -4.28125,
      0.55078125,
      1.484375,
      3.609375,
      -7.71875,
      5.09375,
      -1.84375,
      4.46875,
      -1.4453125,
      3.609375,
      -0.318359375,
      0.66015625,
      -4,
      -3.265625,
      -4.53125,
      0.447265625,
      -2.140625,
      0.2158203125,
      2.671875,
      -3.140625,
      1.109375,
      -2.328125,
      -2.5,
      2.359375,
      0.42578125,
      -1.3671875,
      1.625,
      -0.08154296875,
      1.6953125,
      -1.4140625,
      5.34375,
      -0.98828125,
      0.0014190673828125,
      -1.3828125,
      -1.8203125,
      -0.44921875,
      -3.375,
      2.84375,
      -0.02294921875,
      -4.40625,
      5.5625,
      0.7890625,
      -0.6015625,
      2.34375,
      -1.453125,
      -5.0625,
      6.28125,
      3.921875,
      -6.65625,
      1.5390625,
      -0.51953125,
      -4.125,
      -1.1328125,
      0.314453125,
      2.71875,
      -5,
      0.625,
      2.546875,
      -4.5,
      1.90625,
      1.421875,
      -1.3515625,
      0.400390625,
      -2.875,
      4,
      0.67578125,
      0.62109375,
      2.921875,
      1.5625,
      4.53125,
      -3.0625,
      -1.265625,
      -3.296875,
      5.25,
      -1.453125,
      0.23828125,
      0.90234375,
      -0.8359375,
      3.171875,
      3.140625,
      -0.6015625,
      -5.6875,
      -2.609375,
      1.46875,
      -0.35546875,
      3.09375,
      1.90625,
      0.146484375,
      -2.640625,
      0.0189208984375,
      2.890625,
      2.015625,
      0.7421875,
      -1.078125,
      -4.09375,
      2.09375,
      -0.251953125,
      -7.125,
      -1.2578125,
      0.396484375,
      -0.51171875,
      1.2578125,
      -1,
      -1.6640625,
      2.375,
      3.140625,
      -4.125,
      1.890625,
      0.447265625,
      1.8046875,
      -0.06884765625,
      -0.494140625,
      1.1640625,
      1.8828125,
      -2.6875,
      -7.65625,
      2.921875,
      -0.47265625,
      -0.890625,
      3.046875,
      -0.6015625,
      2.96875,
      2.546875,
      2.578125,
      -4.40625,
      6.78125,
      1.96875,
      -7.3125,
      3.375,
      -5.375,
      1.2578125,
      -3.84375,
      -5.46875,
      -1.3203125,
      4.90625,
      -2.484375,
      0.6796875,
      1.2421875,
      -0.10302734375,
      -1.1484375,
      4.09375,
      0.8046875,
      -4.375,
      0.75390625,
      2.53125,
      -4.96875,
      -0.140625,
      2.078125,
      -0.5078125,
      -1.3046875,
      -0.2412109375,
      0.228515625,
      0.349609375,
      -0.953125,
      3.484375,
      1.2109375,
      -0.88671875,
      -1.53125,
      -1.1171875,
      1.6640625,
      -0.74609375,
      -3.34375,
      0.166015625,
      -0.89453125,
      2.015625,
      -2.359375,
      0.39453125,
      -1.046875,
      -3.65625,
      -1.8984375,
      -5.53125,
      -0.55859375,
      1.953125,
      1.4765625,
      1.9140625,
      -2.375,
      -0.91015625,
      2.6875,
      3.640625,
      1.0859375,
      -3.609375,
      0.04052734375,
      -3.71875,
      -1.6328125,
      1.015625,
      2.421875,
      -1.90625,
      -0.93359375,
      2.03125,
      0.2578125,
      -3.03125,
      -4.625,
      -0.64453125,
      0.283203125,
      2.640625,
      1.625,
      -1.609375,
      -2.5,
      3.03125,
      1.609375,
      -5.375,
      -0.88671875,
      2.390625,
      -1.4765625,
      -3.546875,
      -3.234375,
      3.71875,
      -5.9375,
      0.263671875,
      3.84375,
      1.703125,
      1.875,
      1.703125,
      -7.1875,
      -1.4140625,
      3.78125,
      3.671875,
      2.515625,
      1.2734375,
      -1.546875,
      -4.71875,
      5.25,
      4.71875,
      -1.6796875,
      -2.578125,
      -1.421875,
      -0.515625,
      -1.359375,
      -2.5625,
      2.484375,
      -0.08056640625,
      -6.1875,
      7.53125,
      -2.109375,
      4.625,
      1.8984375,
      -2.140625,
      2.578125,
      -0.92578125,
      2.109375,
      -0.6484375,
      2.21875,
      3.46875,
      -3.75,
      -3,
      -2.296875,
      -0.4453125,
      -1.2578125,
      -0.2060546875,
      -1.2421875,
      1.3046875,
      3.984375,
      0.2001953125,
      -1.4921875,
      -0.1865234375,
      -0.8046875,
      3.921875,
      -3.140625,
      -1.21875,
      0.12109375,
      -2.375,
      0.3046875,
      -1.8046875,
      1.8203125,
      -4.25,
      0.333984375,
      0.08251953125,
      1.8828125,
      0.61328125,
      3.03125,
      -0.107421875,
      -1.3046875,
      -2.0625,
      4.5625,
      0.54296875,
      2.625,
      3.859375,
      3.6875,
      1.4609375,
      -1.6640625,
      2.96875,
      6.25,
      4.8125,
      -5.71875,
      -1.5,
      -0.443359375,
      -0.9375,
      -1.1015625,
      0.1484375,
      0.57421875,
      1.8359375,
      3.171875,
      0.412109375,
      1.7734375,
      -1.8828125,
      -2.109375,
      -0.7109375,
      -0.1279296875,
      3.25,
      2.1875,
      -3.046875,
      0.10986328125,
      -1.7421875,
      1.6640625,
      1.3359375,
      2.640625,
      1.40625,
      -0.2578125,
      -2.6875,
      0.169921875,
      -3.25,
      -0.83203125,
      1.34375,
      -2.109375,
      0.48046875,
      -1.2578125,
      -1.46875,
      1.3828125,
      0.97265625,
      -3.03125,
      2.96875,
      2.296875,
      -2.140625,
      2.390625,
      -0.73046875,
      -2.265625,
      -0.408203125,
      0.68359375,
      2.703125,
      -1.390625,
      -3.28125,
      0.79296875,
      3.234375,
      -2.015625,
      -0.392578125,
      -1.09375,
      1.171875,
      -1.609375,
      -0.37890625,
      0.09423828125,
      -0.96484375,
      3.640625,
      -0.5703125,
      -0.69921875,
      3.03125,
      -0.828125,
      -0.0458984375,
      1.8046875,
      -1.9296875,
      -1.7734375,
      -2.75,
      2.953125,
      2.546875,
      0.03125,
      1.6875,
      1.9609375,
      1.328125,
      -0.5546875,
      -1.8046875,
      -3.21875,
      0.05029296875,
      -2.140625,
      -0.18359375,
      0.8203125,
      -0.1865234375,
      -2.484375,
      4,
      0.796875,
      2.328125,
      -3.640625,
      -0.76953125,
      -2.1875,
      -1.6796875,
      -0.259765625,
      -2.5625,
      2.265625,
      1.7734375,
      1.3046875,
      -0.095703125,
      -0.62109375,
      0.28125,
      -0.875,
      -2.171875,
      4.71875,
      2.25,
      -2.625,
      0.373046875,
      -1.6171875,
      1.0625,
      2.28125,
      -0.65234375,
      -2.765625,
      1.4765625,
      1.0703125,
      3.078125,
      2.953125,
      -1.2890625,
      2.390625,
      2.375,
      -3.09375,
      0.026611328125,
      -2.734375,
      2.203125,
      -0.333984375,
      -1.203125,
      -0.1748046875,
      1.0546875,
      -4.53125,
      -0.703125,
      0.7109375,
      2,
      -0.60546875,
      0.36328125,
      1.53125,
      1.3828125,
      -1.859375,
      3,
      4.25,
      1.703125,
      -2.234375,
      -3.8125,
      0.474609375,
      0.8125,
      -1.59375,
      -1.078125,
      -0.79296875,
      -0.38671875,
      -1.40625,
      0.2412109375,
      -0.416015625,
      -2.234375,
      1.7265625,
      0.7265625,
      -0.515625,
      -2.25,
      1.0078125,
      -1.3125,
      0.96875,
      -0.66015625,
      1.4296875,
      -0.87109375,
      -5.28125,
      0.9140625,
      1.1640625,
      -0.1796875,
      -4.5,
      -1.8359375,
      -2.5625,
      1.609375,
      -0.546875,
      -0.177734375,
      1.7265625,
      -2.4375,
      0.671875,
      -2.140625,
      -1.390625,
      0.8828125,
      0.353515625,
      1.3125,
      -0.01251220703125,
      -1.5390625,
      3.796875,
      1.25,
      -1.875,
      2.265625,
      -0.6015625,
      1.9921875,
      -0.357421875,
      -0.7578125,
      0.462890625,
      -1.875,
      1.515625,
      0.1494140625,
      -0.28515625,
      3.109375,
      -0.4140625,
      0.96875,
      -0.65625,
      -0.65625,
      4.59375,
      3.65625,
      -0.279296875,
      0.53125,
      0.07958984375,
      1.03125,
      -0.85546875,
      -1.5,
      0.69921875,
      -3.21875,
      3.671875,
      -0.185546875,
      -2.515625,
      0.9140625,
      -2.546875,
      0.94921875,
      2.6875,
      3.25,
      -2.5,
      2.765625,
      0.2353515625,
      -0.0927734375,
      -0.43359375,
      -1.78125,
      -0.62890625,
      -0.318359375,
      -3.265625,
      2.28125,
      0.7265625,
      -0.1748046875,
      -2.578125,
      -0.03271484375,
      -2.765625,
      -2.453125,
      -0.35546875,
      0.01531982421875,
      -1.15625,
      2.765625,
      2.703125,
      0.6796875,
      -0.74609375,
      -1.3046875,
      0.5625,
      0.130859375,
      2.4375,
      -0.236328125,
      2.9375,
      2.984375,
      0.2255859375,
      -0.31640625,
      -0.7890625,
      -1.1796875,
      1.21875,
      0.392578125,
      -1.34375,
      1.3515625,
      3.140625,
      2.59375,
      -1.1953125,
      0.8828125,
      -0.193359375,
      6.09375,
      0.67578125,
      -1.296875,
      1.0703125,
      -1.390625,
      1.96875,
      -2.515625,
      1.9140625,
      0.1396484375,
      0.66796875,
      -2.453125,
      0.11181640625,
      1.7890625,
      -1.2109375,
      -3.28125,
      1.5078125,
      -2.703125,
      -0.279296875,
      3.140625,
      -1.265625,
      0.609375,
      0.0322265625,
      1.125,
      1.046875,
      5.125,
      -0.0322265625,
      0.41015625,
      1.90625,
      2.828125,
      3.484375,
      0.58203125,
      -1.421875,
      -0.27734375,
      1.1640625,
      1.3125,
      -0.32421875,
      1.15625,
      -0.423828125,
      2.625,
      -2.046875,
      -0.71484375,
      -3.109375,
      -0.83203125,
      0.212890625,
      0.2890625,
      4.59375,
      -3.8125,
      -1.9921875,
      3.75,
      0.423828125,
      0.341796875,
      1.5859375,
      3.625,
      0.81640625,
      3.109375,
      1.8125,
      -1.234375,
      -0.08154296875,
      2.515625,
      0.27734375,
      2.375,
      1.53125,
      -1.1171875,
      -2.078125,
      -0.6875,
      -2.078125,
      2.75,
      -1.359375,
      -0.90234375,
      2.828125,
      -0.2080078125,
      4.1875,
      2.328125,
      1.6953125,
      4.875,
      3.046875,
      -0.73046875,
      -1.46875,
      1.40625,
      -1.578125,
      0.7109375,
      1.90625,
      -1.2109375,
      2.578125,
      -1.2734375,
      -1.46875,
      -1.546875,
      -1.1875,
      -2.96875,
      -2.703125,
      -1.8046875,
      0.1357421875,
      -1.421875,
      3.875,
      -3.578125,
      2.484375,
      1.8671875,
      2.328125,
      2.046875,
      2,
      0.9296875,
      1.40625,
      -1.5,
      -3.515625,
      1.0546875,
      -1.6484375,
      -3.703125,
      -0.1455078125,
      0.3828125,
      -2.21875,
      1.734375,
      -2.21875,
      0.314453125,
      -1.1015625,
      -0.7734375,
      -3.140625,
      1.4375,
      2.21875,
      -1.375,
      0.70703125,
      -2.640625,
      0.1357421875,
      -1.515625,
      0.6796875,
      1.3046875,
      -5.34375,
      -2.96875,
      -0.337890625,
      -1.1953125,
      -1.9140625,
      -2.296875,
      -1.9296875,
      -0.60546875,
      0.1591796875,
      4.75,
      1.53125,
      -0.515625,
      -1.53125,
      4.40625,
      -1.4921875,
      0.9296875,
      -1.2265625,
      -1.953125,
      2.0625,
      2.453125,
      3.75,
      3.546875,
      -1,
      -0.98046875,
      -2.515625,
      2.265625,
      0.173828125,
      -4.46875,
      -0.77734375,
      -0.1796875,
      -1.5390625,
      -0.94140625,
      -1.828125,
      0.171875,
      -1.4921875,
      -1.515625,
      0.3828125,
      -3.59375,
      0.6484375,
      3.578125,
      -0.58203125,
      -1.515625,
      -2.46875,
      1.8984375,
      -2.390625,
      0.546875,
      -1.90625,
      -1.8828125,
      2.21875,
      1.2734375,
      -0.37109375,
      6.03125,
      -2.234375,
      -2.421875,
      2.125,
      1.0390625,
      3.234375,
      -2.765625,
      1.421875,
      0.625,
      -2.609375,
      1.296875,
      -3.140625,
      -4.625,
      -3.1875,
      -3.546875,
      -2.28125,
      -2.078125,
      2.46875,
      2.390625,
      -1.3203125,
      -1.3515625,
      0.8671875,
      1,
      2.34375,
      1.765625,
      -2.4375,
      -0.0439453125,
      -4.125,
      -1.921875,
      0.98828125,
      2.6875,
      -0.78125,
      1.9765625,
      2.53125,
      0.73828125,
      -1.9921875,
      0.765625,
      0.90234375,
      0.546875,
      0.9609375,
      0.859375,
      -3.125,
      -2.484375,
      2.296875,
      -2.484375,
      2.578125,
      0.486328125,
      -0.6015625,
      0.88671875,
      -1.03125,
      -2.328125,
      -1.1328125,
      0.314453125,
      0.86328125,
      -2.046875,
      -3.5625,
      1.5234375,
      0.40234375,
      -1.9375,
      0.44140625,
      1.78125,
      1.890625,
      -1.609375,
      -2.625,
      0.373046875,
      -2.796875,
      -4.0625,
      -1.3671875,
      0.5703125,
      3.53125,
      1.1015625,
      -3.0625,
      5.9375,
      0.490234375
    ],
    "suggested_tags": [
      "教育AI",
      "生成式AI",
      "个性化学习",
      "随机对照试验",
      "AI教学助手"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.95,
        "reason": "论文核心研究领域为人工智能在教育领域的应用，特别是AI辅助教学系统在数学课堂中的实际效果评估"
      },
      {
        "name": "生成式AI",
        "confidence": 0.9,
        "reason": "研究基于LearnLM这一经过教学优化的生成式AI模型，重点评估其在教学对话中的生成能力"
      },
      {
        "name": "个性化学习",
        "confidence": 0.85,
        "reason": "论文旨在解决一对一教学的规模化问题，探索AI如何实现个性化教学支持"
      },
      {
        "name": "随机对照试验",
        "confidence": 0.8,
        "reason": "采用严谨的RCT方法在真实课堂环境中评估AI教学效果，这是教育技术研究的重要方法"
      },
      {
        "name": "AI教学助手",
        "confidence": 0.75,
        "reason": "具体应用场景为AI辅助的在线教学对话系统，重点研究人机协作的教学模式"
      }
    ],
    "analysis": {
      "paper_id": "02197db0-3de5-4390-9690-609c0f31a4c1",
      "status": "completed",
      "started_at": null,
      "completed_at": "2025-12-16T02:26:53.409169",
      "summary": "本研究旨在探讨生成式AI能否在保证安全性的前提下，有效扩展个性化辅导的覆盖范围，以解决一对一人工辅导成本高昂、难以规模化的问题。研究团队在英国五所中学开展了探索性随机对照试验，共有165名学生参与。试验将专为教学应用优化的生成式AI模型LearnLM集成至Eedi数学平台的在线聊天辅导系统中，并由17名专家教师进行实时监督，对AI生成的每条信息进行审核、编辑或重写后方发送给学生。\n\n研究发现，LearnLM表现出较高的教学可靠性，监督教师对其76.4%的生成内容直接认可或仅作微调。在多项学习成果指标上，接受LearnLM辅导的学生表现均不逊于纯人工辅导组，尤其在知识迁移能力上表现更优：AI辅导组学生在后续新题型上的解题正确率达到66.2%，较人工辅导组（60.7%）显著提升5.5个百分点。教师访谈进一步揭示，LearnLM擅长设计启发式提问以促进学生深度思考，部分教师反馈其教学策略亦受AI启发。\n\n研究表明，经过教学优化的AI辅导系统在人工监督下，能够安全、有效地提供规模化个性化学习支持，为突破优质教育资源的可及性瓶颈提供了可行路径。",
      "methods": [
        {
          "name": "随机对照试验（RCT）",
          "description": "本研究采用随机对照试验设计，将165名学生随机分配到不同干预组。通过比较静态提示与互动辅导，以及人类辅导与AI辅导的效果，评估LearnLM的教学效能。",
          "location": null
        },
        {
          "name": "专家监督的AI辅导",
          "description": "人类专家导师直接监督LearnLM生成的所有消息，保留编辑、重写或批准的最终控制权。这种方法确保AI辅导的安全性和教学质量，导师对76.4%的AI生成消息无需或仅需最小修改。",
          "location": null
        },
        {
          "name": "学习成果测量",
          "description": "通过测量多项学习成果评估辅导效果，包括知识迁移能力。具体比较学生在后续主题中解决新问题的成功率，量化AI辅导与人类辅导的差异。",
          "location": null
        },
        {
          "name": "访谈与调查",
          "description": "对监督导师进行访谈和调查，收集他们对LearnLM教学能力的定性反馈。导师报告AI在生成苏格拉底式问题方面的优势，并分享其教学实践的新见解。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "1. Introduction",
            "level": 1,
            "start_line": 9
          },
          {
            "title": "2. An Exploratory Classroom Trial",
            "level": 1,
            "start_line": 32
          },
          {
            "title": "3. Results",
            "level": 1,
            "start_line": 47
          },
          {
            "title": "4. Discussion",
            "level": 1,
            "start_line": 91
          },
          {
            "title": "5. Methods",
            "level": 1,
            "start_line": 113
          },
          {
            "title": "References",
            "level": 1,
            "start_line": 143
          },
          {
            "title": "Contributions and Acknowledgments",
            "level": 1,
            "start_line": 191
          },
          {
            "title": "Core Contributors",
            "level": 1,
            "start_line": 193
          },
          {
            "title": "Acknowledgements",
            "level": 1,
            "start_line": 207
          },
          {
            "title": "A. Participants",
            "level": 1,
            "start_line": 215
          },
          {
            "title": "A.1. Students",
            "level": 1,
            "start_line": 217
          },
          {
            "title": "A.2. Tutors",
            "level": 1,
            "start_line": 223
          },
          {
            "title": "B. Trial",
            "level": 1,
            "start_line": 231
          },
          {
            "title": "C. Platform",
            "level": 1,
            "start_line": 244
          },
          {
            "title": "D. Model",
            "level": 1,
            "start_line": 258
          },
          {
            "title": "D.1. Tutoring prompt",
            "level": 1,
            "start_line": 260
          },
          {
            "title": "Listing D.1 | System prompt template",
            "level": 1,
            "start_line": 264
          },
          {
            "title": "The Current student activity The below is what the student was doing when this learning intervention started, so assume all  $\\rightarrow$  responses relate to this: {ChatConstants.Activity} # Activity details {ChatConstants/questionMetaData} # Students ability level (if provided) {ChatConstants.StudentInsight}",
            "level": 1,
            "start_line": 269
          },
          {
            "title": "Examples of good Socratic responses What happens if we multiply these two numbers first? \"Sure! How do you find the perimeter of the shape?\" Super work! And what about the triangle?\" That's okay, did you watch the video for this lesson?\" Shall I return you to the lesson?\" Could you estimate the height?\" Yes it is equilateral so the slant height is 8, so the vertical height would have th be a  $\\rightarrow$  little less\" Yes sure, so we know what  $5\\mathrm{km}$  is and we're trying to get to  $30\\mathrm{km}$  \" When you are finding the original shape, complete the steps in the reverse direction, and do  $\\rightarrow$  the opposite\" Ok, so can we try and make some even smaller ones? :)\" Awesome, I'll pass you back to Eedi \" It says that  $1\\mathrm{g} = 10$  decigrams\" And then would have to convert to kilograms afterwards :)\" So to convert into a decimal, we want it to be over 100 or 1000 or another power of 10\"",
            "level": 1,
            "start_line": 270
          },
          {
            "title": "Checking understanding (use if the student is confused or unsure)",
            "level": 2,
            "start_line": 271
          },
          {
            "title": "Closing remarks (use if the student has answered correctly)",
            "level": 2,
            "start_line": 273
          },
          {
            "title": "Rudeness (use if the student is rude e.g. 'shut up' or 'I don't care')",
            "level": 2,
            "start_line": 275
          },
          {
            "title": "Important response guidelines - Please don't use wink emojis  $\\clubsuit$",
            "level": 1,
            "start_line": 283
          },
          {
            "title": "Year group Instructional directive",
            "level": 1,
            "start_line": 291
          },
          {
            "title": "Listing D.2 | Example of a fully populated system prompt",
            "level": 1,
            "start_line": 306
          },
          {
            "title": "Directives",
            "level": 1,
            "start_line": 310
          },
          {
            "title": "The Current student activity",
            "level": 1,
            "start_line": 325
          },
          {
            "title": "Activity details",
            "level": 1,
            "start_line": 328
          },
          {
            "title": "Checking understanding (use if the student is confused or unsure)",
            "level": 2,
            "start_line": 356
          },
          {
            "title": "E. Tutor edits",
            "level": 1,
            "start_line": 391
          },
          {
            "title": "E.1. Minor edits",
            "level": 1,
            "start_line": 395
          },
          {
            "title": "E.2. Safety and accuracy audit",
            "level": 1,
            "start_line": 403
          },
          {
            "title": "E.3. Primary motivations",
            "level": 1,
            "start_line": 411
          },
          {
            "title": "F. Learning outcomes",
            "level": 1,
            "start_line": 419
          },
          {
            "title": "F.1. Methodology",
            "level": 1,
            "start_line": 421
          },
          {
            "title": "F.2. Analysis",
            "level": 1,
            "start_line": 435
          },
          {
            "title": "F.3. Results",
            "level": 1,
            "start_line": 445
          },
          {
            "title": "F.3.1. Immediate learning outcomes",
            "level": 1,
            "start_line": 447
          },
          {
            "title": "F.3.2. Learning transfer",
            "level": 1,
            "start_line": 471
          },
          {
            "title": "G. Operational metrics",
            "level": 1,
            "start_line": 501
          },
          {
            "title": "G.1. Cost inputs",
            "level": 1,
            "start_line": 507
          },
          {
            "title": "G.2. Simulation of throughput capacity",
            "level": 1,
            "start_line": 515
          },
          {
            "title": "G.3. Analysis",
            "level": 1,
            "start_line": 521
          },
          {
            "title": "H. Example transcript",
            "level": 1,
            "start_line": 529
          }
        ]
      },
      "error_message": null
    },
    "s2_cache": {
      "cached_at": "2025-12-16T15:16:19.085701",
      "citations": [
        {
          "external_id": "CorpusId:283093296",
          "title": "Dual-process theory and decision-making in large language models",
          "authors": [
            "Oliver Brady",
            "Paul Nulty",
            "Lili Zhang",
            "Tomás E. Ward",
            "David P. McGovern"
          ],
          "year": 2025,
          "venue": "Nature Reviews Psychology",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283081756",
          "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
          "authors": [
            "LearnLM Team",
            "Google Eedi"
          ],
          "year": null,
          "venue": "",
          "citation_count": 0
        }
      ],
      "references": []
    },
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283093296",
          "title": "Dual-process theory and decision-making in large language models",
          "authors": [
            "Oliver Brady",
            "Paul Nulty",
            "Lili Zhang",
            "Tomás E. Ward",
            "David P. McGovern"
          ],
          "year": 2025,
          "venue": "Nature Reviews Psychology",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283081756",
          "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
          "authors": [
            "LearnLM Team",
            "Google Eedi"
          ],
          "year": null,
          "venue": "",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T15:24:48.462035",
      "references": [],
      "references_fetched_at": "2025-12-16T15:24:48.770106"
    }
  },
  "f6ddea83-75e3-472e-8798-80000e520eb9": {
    "id": "f6ddea83-75e3-472e-8798-80000e520eb9",
    "filename": "2405.13001v1.pdf",
    "file_path": "./uploads/papers/f6ddea83-75e3-472e-8798-80000e520eb9.pdf",
    "status": "completed",
    "title": "Large Language Models for Education: A Survey",
    "category": null,
    "markdown_content": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/f6ddea83-75e3-472e-8798-80000e520eb9/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642–652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123–159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855–5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., Suwała, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69–80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1–35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190–200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Å., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1–24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776–5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., Gašević, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279–297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512–527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831–833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
    "translated_content": null,
    "created_at": "2025-12-16 07:25:47.506741",
    "updated_at": "2025-12-16 07:25:54.602329",
    "doi": null,
    "arxiv_id": "2405.13001",
    "embedding": [
      0.7890625,
      -1.9609375,
      -1.1796875,
      -2.65625,
      -0.267578125,
      1.1796875,
      -1.8828125,
      -2.484375,
      -0.87109375,
      2.328125,
      2.421875,
      2.359375,
      2.53125,
      2.53125,
      0.7578125,
      3.40625,
      -1.7890625,
      -0.5078125,
      1.859375,
      -5.75,
      -0.0927734375,
      0.95703125,
      0.53125,
      -4.90625,
      4.59375,
      -7.21875,
      -3.40625,
      4.21875,
      1.8125,
      0.60546875,
      8.1875,
      -4,
      0.2119140625,
      0.515625,
      -1.2265625,
      0.34765625,
      -2.59375,
      -1.1796875,
      4.125,
      3.359375,
      -7.1875,
      1.9453125,
      0.181640625,
      5.21875,
      -0.09814453125,
      3.1875,
      0.8203125,
      0.59375,
      -7.15625,
      -1.71875,
      -5.09375,
      -1.671875,
      7.53125,
      0.177734375,
      3.1875,
      -3.015625,
      -5.59375,
      5.1875,
      -3.890625,
      -0.43359375,
      1.8671875,
      0.396484375,
      0.412109375,
      -1.0703125,
      5.40625,
      3.109375,
      0.44140625,
      0.67578125,
      -2.078125,
      2.109375,
      0.87890625,
      2.46875,
      5.59375,
      -3.90625,
      7.78125,
      6.96875,
      3.484375,
      2.609375,
      -2.3125,
      3.5,
      -5.8125,
      5.34375,
      5.28125,
      -1.4453125,
      5.09375,
      2.828125,
      1.359375,
      0.169921875,
      -2.6875,
      1.296875,
      -0.384765625,
      0.65234375,
      -4.78125,
      0.38671875,
      -3.53125,
      4.78125,
      -1.1953125,
      -3.171875,
      -5.78125,
      0.60546875,
      -2.203125,
      -0.89453125,
      0.322265625,
      -7.15625,
      -4.5625,
      -3.8125,
      -3.671875,
      -7.09375,
      -0.0267333984375,
      -1.8671875,
      -0.359375,
      3.171875,
      1.2421875,
      -2.34375,
      4.875,
      -0.1650390625,
      1.046875,
      -3.203125,
      -5.5625,
      -1.171875,
      1.09375,
      -0.275390625,
      -1.8125,
      0.9765625,
      2.5625,
      1.5859375,
      -4.28125,
      3.28125,
      6.25,
      -3.34375,
      4.6875,
      -0.06396484375,
      5.125,
      -2.28125,
      -8.9375,
      -1.75,
      -5,
      3.5,
      1.2109375,
      4,
      -5.5,
      -1.015625,
      -2.46875,
      -7.84375,
      2.59375,
      1.6640625,
      -7.34375,
      -1.25,
      3.546875,
      -4.03125,
      0.416015625,
      1.1171875,
      1.015625,
      8.0625,
      0.10546875,
      -2.75,
      2.359375,
      1.640625,
      0.5390625,
      -2.046875,
      0.00628662109375,
      2.625,
      0.119140625,
      0.7265625,
      -0.053955078125,
      -0.89453125,
      -5.28125,
      1.140625,
      0.86328125,
      -1.078125,
      1.109375,
      14.875,
      1.3984375,
      -1.9375,
      1.671875,
      0.58984375,
      -1.1640625,
      9.375,
      2.328125,
      0.30859375,
      0.84375,
      2.078125,
      -3.28125,
      3.828125,
      -1.359375,
      1.5625,
      2.921875,
      -3.953125,
      2,
      -2.109375,
      0.4375,
      4.5,
      4.65625,
      1.2421875,
      -4.4375,
      0.81640625,
      4.53125,
      -1.3671875,
      -0.06494140625,
      1.5234375,
      -1.1875,
      -10.375,
      -0.71484375,
      -1.8828125,
      -5.84375,
      -2.21875,
      1.1484375,
      -4.5,
      1.203125,
      -1.3046875,
      -1.0625,
      2.09375,
      2.609375,
      -0.3515625,
      7.5,
      2.40625,
      2.328125,
      -2.5,
      4.5625,
      0.97265625,
      4.3125,
      4.90625,
      2.609375,
      0.330078125,
      -0.18359375,
      2.015625,
      3.015625,
      2.96875,
      2.15625,
      8.125,
      -0.361328125,
      4.28125,
      4.65625,
      -4.375,
      -3.609375,
      -0.8671875,
      -4.28125,
      -0.54296875,
      -2.515625,
      1.796875,
      -3.375,
      -4.15625,
      0.15625,
      2.9375,
      1.421875,
      -0.75390625,
      -0.4609375,
      -2.03125,
      0.50390625,
      -8.125,
      0.205078125,
      4.25,
      -9.6875,
      -3.578125,
      4.625,
      6.8125,
      0.9296875,
      -0.275390625,
      0.82421875,
      -5.0625,
      3.078125,
      -1.9921875,
      -5.25,
      1.8828125,
      0.87890625,
      -4.09375,
      4.1875,
      0.71875,
      1.7265625,
      3.15625,
      1.1328125,
      1,
      -4.40625,
      1.7421875,
      -3.53125,
      4.625,
      2.078125,
      -3.828125,
      1.0390625,
      -2.28125,
      -6.90625,
      -9.5,
      3.953125,
      -4,
      2.421875,
      -0.7421875,
      -0.76953125,
      6.25,
      -2.0625,
      12.5625,
      1.46875,
      1.7265625,
      0.62890625,
      0.0244140625,
      -1.9296875,
      1.140625,
      -1.4453125,
      0.1611328125,
      -4.6875,
      1.3515625,
      4.28125,
      -0.1953125,
      -1.75,
      -2.84375,
      -0.1416015625,
      2.46875,
      -0.9375,
      -4.3125,
      1.4765625,
      4.5625,
      0.328125,
      1.3046875,
      5.3125,
      -3.78125,
      3.453125,
      -4.40625,
      -3.03125,
      3.5,
      1.9765625,
      -2.4375,
      -7.34375,
      -3.734375,
      -2.234375,
      -2.71875,
      -2.703125,
      -4.5625,
      1.3984375,
      -0.0693359375,
      5.625,
      2.234375,
      1.453125,
      0.63671875,
      -6.34375,
      -8.3125,
      6.875,
      -3.78125,
      3.40625,
      1.59375,
      -0.69921875,
      2.65625,
      -0.341796875,
      -1.7109375,
      1.34375,
      -3.8125,
      -2.171875,
      -0.5,
      5,
      -1.53125,
      3.1875,
      -6.40625,
      4.78125,
      2.859375,
      1.390625,
      4.15625,
      7.46875,
      -1.3671875,
      2.328125,
      -1.8828125,
      -1.7421875,
      1.140625,
      0.53125,
      -3.296875,
      7.53125,
      0.20703125,
      -2.671875,
      -3.78125,
      -2.859375,
      2.59375,
      -0.84375,
      -1.15625,
      -2.171875,
      -2.34375,
      0.8828125,
      3.375,
      0.609375,
      1.6875,
      1.8125,
      -3.28125,
      -4.15625,
      2.234375,
      -1.4296875,
      1.6015625,
      -0.251953125,
      3.46875,
      4.09375,
      1.4609375,
      -0.99609375,
      5.125,
      1.46875,
      -3.421875,
      -2.109375,
      0.8984375,
      -3.640625,
      1.53125,
      4.21875,
      1.125,
      -2.171875,
      2.15625,
      -0.61328125,
      -3.75,
      4.59375,
      -1.359375,
      -0.294921875,
      -1.75,
      -1.8984375,
      -1.4921875,
      2.375,
      -7.1875,
      1.3828125,
      -0.33203125,
      -1.140625,
      1.0859375,
      -1.0859375,
      2.34375,
      -0.671875,
      4.4375,
      -2.765625,
      1.8515625,
      -7.4375,
      -0.84375,
      -3.5,
      -2.171875,
      1.6640625,
      -1.7734375,
      1.7734375,
      -0.06494140625,
      0.326171875,
      4.78125,
      2.109375,
      0.05908203125,
      -0.1650390625,
      1.9375,
      -3.96875,
      1.171875,
      -0.64453125,
      -5.90625,
      1.1875,
      -5.125,
      -4.75,
      2.609375,
      3.390625,
      -0.126953125,
      6.6875,
      4.71875,
      -2.640625,
      -3.484375,
      2.09375,
      2.65625,
      -4.53125,
      -2.359375,
      1.7578125,
      -1.5234375,
      0.6171875,
      -0.72265625,
      2.921875,
      0.271484375,
      -1.7578125,
      2.828125,
      0.94921875,
      0.06591796875,
      0.88671875,
      -1.3984375,
      0.41015625,
      1.4453125,
      1.5078125,
      1.140625,
      -2.609375,
      6.28125,
      6.625,
      -6.625,
      -8.5,
      2.609375,
      0.7734375,
      -1.796875,
      -1.421875,
      3.34375,
      1.59375,
      0.396484375,
      -5.53125,
      -4.84375,
      -1.625,
      -0.8203125,
      4.5625,
      3.046875,
      0.244140625,
      -3.34375,
      -3.875,
      4.4375,
      -2.515625,
      4.1875,
      0.34375,
      -1.5,
      0.578125,
      -3.953125,
      5.09375,
      0.87109375,
      5.6875,
      -4.75,
      -0.375,
      3.390625,
      -9.3125,
      -0.423828125,
      -3.25,
      -0.09375,
      -0.5859375,
      -0.4921875,
      5.09375,
      -3.609375,
      0.2041015625,
      0.75,
      5.96875,
      -2.46875,
      -0.91015625,
      2.46875,
      -7.15625,
      -2.4375,
      1.0859375,
      2.453125,
      2.421875,
      -2.015625,
      -4.875,
      0.388671875,
      -0.15234375,
      -0.52734375,
      -2.203125,
      -0.984375,
      -3.1875,
      -1.9140625,
      1.546875,
      3.703125,
      2.21875,
      0.1484375,
      -0.8046875,
      -3.78125,
      -2.59375,
      -1.1171875,
      1.625,
      -0.37890625,
      1.21875,
      0.322265625,
      2.78125,
      3.359375,
      -2.5,
      -1.546875,
      -1.2421875,
      3.109375,
      -2.890625,
      1.671875,
      0.5234375,
      1.9296875,
      3.453125,
      2.015625,
      -1.4296875,
      -1.546875,
      0.67578125,
      -1.8203125,
      -4.59375,
      -1.4375,
      4.65625,
      -0.71484375,
      0.0155029296875,
      -4.90625,
      0.76171875,
      0.71484375,
      1.8359375,
      -0.65625,
      0.06640625,
      6.21875,
      1.3671875,
      0.2421875,
      2.265625,
      5.875,
      -2.203125,
      0.62109375,
      0.6484375,
      1.09375,
      -7.25,
      -7.5,
      -3.703125,
      3.546875,
      8.4375,
      -0.07373046875,
      5.1875,
      -4.90625,
      4.78125,
      0.228515625,
      0.33984375,
      -14.8125,
      2.5,
      0.77734375,
      -5.6875,
      -2.609375,
      0.00182342529296875,
      4.75,
      -0.91796875,
      4.09375,
      -0.9609375,
      -1.015625,
      1.5234375,
      4.03125,
      -0.9296875,
      -2.265625,
      6.0625,
      3.796875,
      -3.671875,
      2.5,
      -1.8984375,
      -4.84375,
      0.3046875,
      0.09716796875,
      2.625,
      4.125,
      6.84375,
      -0.37890625,
      1.078125,
      4.3125,
      -4.8125,
      -0.34375,
      1.3359375,
      0.80078125,
      -2.875,
      1.6328125,
      -5.65625,
      1.2265625,
      -3.921875,
      1.078125,
      0.0024566650390625,
      -3.109375,
      0.154296875,
      4.09375,
      -2,
      -1.7421875,
      -1.3515625,
      1.3984375,
      3.09375,
      5.625,
      -6.65625,
      0.921875,
      0.498046875,
      0.259765625,
      2.703125,
      -2.171875,
      -0.734375,
      -3.234375,
      3.03125,
      1.140625,
      -2.625,
      5.0625,
      -0.6640625,
      -5.46875,
      3.09375,
      0.56640625,
      -1.1875,
      -0.11962890625,
      3.140625,
      0.2421875,
      0.064453125,
      -0.423828125,
      2.1875,
      1.21875,
      -3.890625,
      -2.90625,
      -0.80859375,
      -2.265625,
      3.90625,
      -0.92578125,
      -2.859375,
      -3.34375,
      -3.90625,
      1.2421875,
      1.796875,
      3.046875,
      1.125,
      2.234375,
      3.15625,
      -4.53125,
      0.5078125,
      -4.8125,
      -3.875,
      1.2890625,
      -3.578125,
      -1.953125,
      0.94140625,
      1.0859375,
      2.171875,
      -1.3125,
      -1.640625,
      -3.640625,
      -4.3125,
      -2.234375,
      1.28125,
      1.2734375,
      2.3125,
      -1.2265625,
      6.125,
      -0.6171875,
      -2.859375,
      0.07080078125,
      -1.453125,
      -0.2060546875,
      -1.0234375,
      1.375,
      -5.6875,
      -0.609375,
      5.96875,
      1.3515625,
      -3.375,
      6.25,
      -0.6015625,
      -0.85546875,
      -1.765625,
      2.65625,
      -0.609375,
      -0.333984375,
      0.828125,
      -3.78125,
      -2.75,
      -3.765625,
      -0.0179443359375,
      -1.2890625,
      3.296875,
      0.62890625,
      0.74609375,
      -0.9296875,
      -7.75,
      2.96875,
      0.21875,
      -0.30859375,
      2.359375,
      5.90625,
      -0.74609375,
      -1.1875,
      2.4375,
      0.7734375,
      -0.82421875,
      -0.8125,
      -4.0625,
      4.4375,
      2.375,
      3.765625,
      -3.96875,
      -6.28125,
      -0.345703125,
      -1.2265625,
      -1.65625,
      4.53125,
      -0.6953125,
      -0.39453125,
      5.4375,
      2.421875,
      -4.8125,
      -2.0625,
      5.5,
      -3.84375,
      0.94921875,
      2.34375,
      2.84375,
      0.458984375,
      4.25,
      -1.65625,
      -2.859375,
      -0.90234375,
      5.75,
      2.859375,
      -1.1640625,
      -0.6953125,
      3.875,
      0.11572265625,
      4.4375,
      -6.0625,
      -5.125,
      0.99609375,
      0.984375,
      -1.84375,
      -0.031005859375,
      6.40625,
      -1.890625,
      0.1728515625,
      0.48046875,
      -0.171875,
      3.40625,
      1.421875,
      1.0390625,
      0.10888671875,
      1.75,
      1.5078125,
      0.875,
      1.8984375,
      -1.15625,
      -0.302734375,
      -1.2265625,
      0.326171875,
      -1.9375,
      3.53125,
      -3.65625,
      0.66015625,
      -1.6875,
      3.734375,
      -0.328125,
      5.75,
      5.15625,
      0.043701171875,
      0.62109375,
      -0.76171875,
      6.84375,
      -1.6015625,
      6.5625,
      1.3125,
      8.5625,
      -2.3125,
      -3.640625,
      1.40625,
      0.095703125,
      -0.890625,
      0.87109375,
      -6.9375,
      -1.953125,
      -1.4140625,
      -0.1611328125,
      -0.76953125,
      2.75,
      -5.125,
      -0.79296875,
      3.25,
      3.6875,
      3.75,
      2.875,
      4.875,
      0.82421875,
      0.88671875,
      -3.203125,
      -1.8046875,
      0.400390625,
      0.58984375,
      3.453125,
      -3.921875,
      0.9453125,
      1.4609375,
      5.53125,
      -0.039794921875,
      -3.046875,
      -3.171875,
      7.34375,
      2.203125,
      -2.328125,
      1.765625,
      -1.7265625,
      0.89453125,
      0.9609375,
      3.984375,
      -5.59375,
      -3.140625,
      6.6875,
      5.03125,
      -0.8046875,
      3.203125,
      0.060302734375,
      2.171875,
      -3.484375,
      -0.90625,
      0.01397705078125,
      -0.046875,
      -4.25,
      -3.078125,
      0.6953125,
      3.828125,
      -4.78125,
      1.921875,
      0.95703125,
      -2.71875,
      2.4375,
      1.0625,
      -2.296875,
      1.609375,
      0.2177734375,
      6.8125,
      0.53125,
      -5.96875,
      -4.5625,
      -7.46875,
      -3.890625,
      0.267578125,
      2.125,
      2.796875,
      2.15625,
      -3.453125,
      2.71875,
      -5.28125,
      -1.046875,
      -4.8125,
      3.65625,
      3.59375,
      -4.8125,
      -2.625,
      -2,
      -7.40625,
      -3.859375,
      -0.91015625,
      -1.2578125,
      -2.484375,
      -5.65625,
      -1.9609375,
      2.375,
      -4.96875,
      -1.046875,
      -1.9375,
      -1.1328125,
      4.34375,
      -0.2158203125,
      0.7890625,
      -4.59375,
      4.8125,
      1.84375,
      -2.3125,
      5.34375,
      1.859375,
      2.734375,
      2.09375,
      0.138671875,
      -0.10205078125,
      -4.78125,
      4.09375,
      -1.5390625,
      9.0625,
      4.0625,
      1.953125,
      -4.5625,
      4.25,
      1.8203125,
      1.4296875,
      -4.40625,
      -0.765625,
      -2.46875,
      2.28125,
      1.609375,
      -1.3125,
      2.4375,
      -2.578125,
      -1.4140625,
      0.89453125,
      -2.421875,
      -0.40625,
      3.265625,
      -0.05712890625,
      4.4375,
      1.6640625,
      0.447265625,
      0.1572265625,
      0.23828125,
      1.671875,
      -0.462890625,
      5.71875,
      -5.09375,
      2.34375,
      -5.375,
      -1.0390625,
      0.73046875,
      -1.1953125,
      -0.64453125,
      -0.4453125,
      -0.318359375,
      1.7421875,
      2.890625,
      1.59375,
      1.1796875,
      4.78125,
      -2.796875,
      -0.0986328125,
      0.76953125,
      -2.453125,
      4.875,
      -0.0022735595703125,
      -0.98046875,
      -0.86328125,
      -0.69921875,
      -0.251953125,
      1.3046875,
      0.84375,
      -8.0625,
      -1.421875,
      -1.21875,
      -4.125,
      7.3125,
      0.953125,
      -0.6796875,
      1.4921875,
      4.09375,
      6.28125,
      3.921875,
      -1.03125,
      -1.0703125,
      -0.2275390625,
      -2.28125,
      4.03125,
      -2.09375,
      -0.74609375,
      4.4375,
      3.828125,
      3.5625,
      -1.03125,
      -0.57421875,
      -2.6875,
      0.00323486328125,
      4.90625,
      -1.7265625,
      -1.1875,
      6.59375,
      -2.953125,
      0.099609375,
      -1.9140625,
      -2.671875,
      -1.8984375,
      -1.5546875,
      2.65625,
      2.1875,
      2.578125,
      -2,
      -2.59375,
      -7.6875,
      2.015625,
      -0.1240234375,
      -1.0703125,
      -1.1640625,
      1.7890625,
      -0.255859375,
      1.5390625,
      -2.03125,
      -1.984375,
      -0.328125,
      -3.8125,
      -0.01116943359375,
      2.828125,
      0.1435546875,
      1.3671875,
      -0.42578125,
      2.75,
      -2.28125,
      2.453125,
      3.875,
      -5.6875,
      2,
      0.921875,
      -1.6953125,
      3.734375,
      1.84375,
      1.4765625,
      2.78125,
      -1.234375,
      0.796875,
      -0.439453125,
      -1.703125,
      1.0703125,
      -2.96875,
      0.60546875,
      1.9375,
      3.328125,
      -2.40625,
      3.078125,
      0.89453125,
      -4.375,
      3.671875,
      -3.65625,
      -7.09375,
      -1.0078125,
      0.08349609375,
      -0.90625,
      -1.3671875,
      -2.453125,
      1.234375,
      2.59375,
      -7.4375,
      5.78125,
      -1.578125,
      5.3125,
      2.71875,
      -1.046875,
      -2.8125,
      0.58203125,
      2.234375,
      -1.578125,
      2.359375,
      1.5234375,
      -1.7421875,
      4.03125,
      -3.359375,
      1.2890625,
      -0.9453125,
      0.59765625,
      3.1875,
      -1.140625,
      0.9765625,
      -0.12255859375,
      1.0546875,
      -9.5,
      -3.46875,
      -2.0625,
      -0.279296875,
      1.96875,
      -0.62109375,
      2.3125,
      -2.828125,
      2.5625,
      -3.96875,
      3.015625,
      -5.0625,
      -3.078125,
      1.7578125,
      -1.921875,
      4.59375,
      2.109375,
      -2.328125,
      0.333984375,
      0.408203125,
      -4.5,
      -2.203125,
      -2.671875,
      0.0390625,
      -3.03125,
      -2.03125,
      -0.287109375,
      2.78125,
      -0.2578125,
      1.7890625,
      -0.90234375,
      3.28125,
      4.15625,
      -0.7421875,
      3.0625,
      0.59765625,
      0.56640625,
      -3.0625,
      -4.4375,
      -4.40625,
      2.0625,
      3.84375,
      -3.21875,
      2.53125,
      -0.921875,
      2.109375,
      2.09375,
      -0.859375,
      -0.162109375,
      1.109375,
      1.78125,
      -0.7578125,
      -1.953125,
      2.515625,
      -1.4765625,
      2.015625,
      -2.203125,
      -4.125,
      -4.25,
      -0.232421875,
      1.0703125,
      0.1904296875,
      1.078125,
      -1.0625,
      -1.8515625,
      -1.25,
      -4.21875,
      -2.65625,
      4.90625,
      0.53125,
      5.1875,
      0.474609375,
      1.1328125,
      -3.046875,
      -1.140625,
      -1.453125,
      6.03125,
      0.78515625,
      -2.78125,
      3.890625,
      -2.09375,
      5.40625,
      -2.140625,
      -1.734375,
      -9.25,
      -1.890625,
      7.125,
      2.0625,
      -0.66015625,
      1.2421875,
      0.31640625,
      2.328125,
      0.000484466552734375,
      5.34375,
      -3.078125,
      -1.578125,
      -0.423828125,
      3.53125,
      1.796875,
      -5.53125,
      0.6484375,
      1.890625,
      -1.5859375,
      1.59375,
      5.8125,
      5.71875,
      -2.0625,
      3.46875,
      -3.984375,
      -2.703125,
      -4.90625,
      4.09375,
      -0.57421875,
      -0.79296875,
      -1.7578125,
      -3.21875,
      -0.255859375,
      -1.4140625,
      0.333984375,
      7.15625,
      -4.59375,
      2.578125,
      -0.95703125,
      4.09375,
      0.90625,
      -1.09375,
      -0.7265625,
      2.921875,
      2.671875,
      -0.93359375,
      -1.1796875,
      -5.9375,
      -1.828125,
      -0.58984375,
      -7.4375,
      2.03125,
      1.78125,
      0.9609375,
      2.25,
      -1.8203125,
      2.265625,
      3.140625,
      -2.5,
      -0.78515625,
      -2.15625,
      2.796875,
      4.75,
      1.46875,
      -2.921875,
      1.1953125,
      -0.96484375,
      -0.2314453125,
      -5.03125,
      3.015625,
      -1.875,
      4.25,
      2.984375,
      3.125,
      -3.765625,
      -4.1875,
      -3.203125,
      -1.703125,
      -3.84375,
      1.171875,
      0.01336669921875,
      1.5859375,
      3.71875,
      -0.08642578125,
      -3.546875,
      -1.2890625,
      -3.890625,
      1.53125,
      -0.5625,
      1.5234375,
      -6.875,
      2.4375,
      -6.25,
      0.76171875,
      1.28125,
      -3.140625,
      0.130859375,
      3.4375,
      2.046875,
      2.25,
      3.328125,
      -1.4921875,
      -3.5625,
      3.484375,
      -4.0625,
      -2.078125,
      -5,
      0.34765625,
      -0.427734375,
      -4.375,
      3.1875,
      -2.765625,
      2.234375,
      -2.4375,
      -3.0625,
      0.2490234375,
      -1.0859375,
      -0.55078125,
      3.5625,
      2.0625,
      -2.4375,
      1.7578125,
      -1.078125,
      5.84375,
      2.625,
      -2.296875,
      1.640625,
      -0.353515625,
      1.8359375,
      -6.125,
      4.3125,
      0.7421875,
      -1.3828125,
      3.40625,
      5.125,
      -3.203125,
      0.953125,
      2.21875,
      5.5625,
      -2.609375,
      -1.375,
      0.421875,
      4.71875,
      -4,
      0.0238037109375,
      -4.125,
      -0.0186767578125,
      1.453125,
      -1.6328125,
      5.03125,
      -1.7109375,
      3.734375,
      -5.0625,
      0.3125,
      1.3359375,
      1.4140625,
      2.9375,
      -5.4375,
      3.890625,
      2.421875,
      -1.390625,
      5.0625,
      -0.73046875,
      -5.59375,
      -2.21875,
      2.125,
      -4.53125,
      -3.0625,
      -5.03125,
      0.0830078125,
      -2.390625,
      -1.6328125,
      -0.65625,
      0.36328125,
      1.0390625,
      2.578125,
      -1.625,
      -1.6953125,
      -2.96875,
      -4.46875,
      1.140625,
      -1.90625,
      -6.71875,
      -0.349609375,
      2.203125,
      3.40625,
      5.5,
      7.8125,
      3.171875,
      -4.5,
      2.609375,
      -1.5703125,
      1.1953125,
      -0.14453125,
      -0.1787109375,
      -0.46875,
      -2.921875,
      2.640625,
      0.88671875,
      3.40625,
      -6.875,
      -0.87890625,
      -4.8125,
      -1.125,
      -0.267578125,
      0.1484375,
      -0.1748046875,
      2.46875,
      4.84375,
      -2.34375,
      3.84375,
      1.4765625,
      -0.1298828125,
      -5.21875,
      2.375,
      -1.5234375,
      2.65625,
      4.5,
      0.6640625,
      -5,
      6.71875,
      2.328125,
      -2.640625,
      2.96875,
      0.03564453125,
      -3.609375,
      -3.171875,
      1.2578125,
      0.5,
      4.0625,
      -0.96875,
      0.93359375,
      2.765625,
      -0.578125,
      3.75,
      2.4375,
      0.76953125,
      0.185546875,
      4.53125,
      0.70703125,
      -5,
      -1.3671875,
      2.515625,
      -3.3125,
      -4,
      2.203125,
      -0.671875,
      2.625,
      -0.115234375,
      2.171875,
      1.75,
      6.84375,
      -4.46875,
      3.03125,
      -5.9375,
      0.1669921875,
      -7.3125,
      2.390625,
      -7.9375,
      1.9765625,
      0.796875,
      6.3125,
      -0.023681640625,
      -4.28125,
      3.421875,
      5.5,
      1.9453125,
      -4.625,
      2.46875,
      2.578125,
      -0.89453125,
      -5.875,
      -2.671875,
      4.34375,
      0.828125,
      3.0625,
      -4.90625,
      1.328125,
      3.6875,
      -1.6328125,
      -5.40625,
      0.63671875,
      -0.3359375,
      -6.53125,
      -5.65625,
      -2.0625,
      -0.54296875,
      -1.21875,
      2.0625,
      4.375,
      -1.953125,
      2.09375,
      0.453125,
      4.09375,
      2.53125,
      -1.34375,
      3.09375,
      0.404296875,
      -0.1474609375,
      2.234375,
      3.875,
      -2.515625,
      1.53125,
      -0.9453125,
      1.015625,
      3.078125,
      -1.84375,
      -0.185546875,
      -6.84375,
      1.7578125,
      4.375,
      1.96875,
      0.1318359375,
      -3.859375,
      -3.046875,
      1.984375,
      -1.3359375,
      -3.21875,
      1.1015625,
      -1.71875,
      -0.2236328125,
      1.0625,
      -1.9609375,
      3.765625,
      0.83203125,
      -0.4453125,
      -1.953125,
      -0.6484375,
      -2.109375,
      -1.5859375,
      -3.59375,
      3.109375,
      -0.625,
      4.34375,
      -0.46484375,
      -4.3125,
      -2.140625,
      3.828125,
      1.0859375,
      2.390625,
      -1.84375,
      -1.21875,
      3.359375,
      3.796875,
      1.328125,
      -1.3203125,
      0.625,
      1.203125,
      0.41015625,
      -3.34375,
      -1.59375,
      -1.84375,
      3.265625,
      -1.90625,
      -1.3046875,
      -2.421875,
      1.953125,
      -1.2109375,
      -7.90625,
      0.88671875,
      -0.0019378662109375,
      -0.77734375,
      -5,
      0.240234375,
      2.296875,
      2.015625,
      4.75,
      3.25,
      2.9375,
      -2.09375,
      2.84375,
      18.75,
      -2.703125,
      -4.9375,
      -1.7265625,
      0.318359375,
      2.96875,
      8.5625,
      1.1171875,
      0.1123046875,
      -1.953125,
      1.578125,
      4.4375,
      2.921875,
      3.234375,
      0.68359375,
      0.87109375,
      2.671875,
      1.9453125,
      -2.59375,
      -4.1875,
      -1.0859375,
      2.234375,
      -1.0078125,
      3.15625,
      -2.625,
      3.125,
      3.34375,
      -1.4921875,
      -0.21484375,
      -5,
      1.171875,
      -3.046875,
      -1.3125,
      -5.34375,
      1.3046875,
      -4.96875,
      0.953125,
      1.9921875,
      0.81640625,
      -2.0625,
      -2.390625,
      -4.25,
      3.1875,
      -0.890625,
      -0.37890625,
      0.86328125,
      -2.3125,
      1.515625,
      -0.71875,
      -0.8671875,
      -2.5,
      -3.65625,
      -3.453125,
      2.046875,
      0.71875,
      -2.546875,
      0.84765625,
      -7.03125,
      -2.34375,
      -5.40625,
      -1.671875,
      -2.265625,
      -3.40625,
      -2.890625,
      -3.90625,
      -2.453125,
      -2.1875,
      -0.2373046875,
      -0.09765625,
      -1.484375,
      -6,
      -0.296875,
      5,
      5.625,
      0.1435546875,
      -2.390625,
      2.6875,
      2.390625,
      2.171875,
      1.484375,
      -0.455078125,
      3.421875,
      -2.203125,
      -1.5390625,
      -0.796875,
      0.91015625,
      -5.3125,
      2.34375,
      0.1455078125,
      -0.16796875,
      4.09375,
      -2.890625,
      2.171875,
      -0.67578125,
      -3.359375,
      -1.609375,
      -0.322265625,
      3.40625,
      0.09130859375,
      -0.8125,
      2.703125,
      -0.546875,
      -0.91015625,
      -2.09375,
      -0.52734375,
      -1.5546875,
      1.8203125,
      -1.6484375,
      1.8203125,
      -0.84375,
      1.2734375,
      2.03125,
      0.84765625,
      -2.25,
      -0.47265625,
      2.828125,
      -6.78125,
      -1.9140625,
      1.953125,
      -0.76171875,
      4.3125,
      -1.9375,
      -3.9375,
      -0.296875,
      -8.75,
      -5.59375,
      -1.8359375,
      -2.96875,
      3.53125,
      -2.125,
      1.421875,
      -1,
      -1.8984375,
      -1.296875,
      2.875,
      -4.25,
      3.6875,
      3.8125,
      1.109375,
      0.322265625,
      -2.875,
      2.328125,
      1.1484375,
      -2.859375,
      -2.5625,
      0.734375,
      -4.71875,
      2.5625,
      5.5625,
      1.1953125,
      -3.65625,
      4.84375,
      -0.71484375,
      -3.375,
      -2.546875,
      3.125,
      -0.16015625,
      -0.671875,
      -1.28125,
      -1.9765625,
      0.57421875,
      0.55078125,
      -2.78125,
      -4.34375,
      -1.953125,
      -1.9921875,
      2.828125,
      -0.578125,
      -7.375,
      0.8828125,
      5.625,
      -6.9375,
      0.890625,
      -1.7421875,
      5.84375,
      -5.875,
      0.474609375,
      5.40625,
      -0.181640625,
      0.60546875,
      2.109375,
      3.203125,
      -2.078125,
      -6.40625,
      1.7109375,
      4.375,
      -2.8125,
      2.296875,
      3.046875,
      -1.4609375,
      0.72265625,
      -4.1875,
      -4.6875,
      6.90625,
      5.84375,
      -5.03125,
      0.62109375,
      -2.8125,
      -1.25,
      -1.359375,
      -5.15625,
      2.53125,
      1.3671875,
      1.25,
      0.7421875,
      0.9140625,
      -3.671875,
      -0.71484375,
      -0.953125,
      -2.546875,
      -2.09375,
      2.890625,
      -1.21875,
      4.09375,
      -6.0625,
      5.5625,
      3.4375,
      0.76953125,
      -4.40625,
      3.359375,
      4.53125,
      0.109375,
      -4.46875,
      -1.46875,
      -1.078125,
      4.625,
      -6.53125,
      4.28125,
      -3.140625,
      1.5546875,
      -1.1640625,
      2.4375,
      -1.3203125,
      3.15625,
      -2.9375,
      -6.15625,
      -3.671875,
      3.578125,
      1.203125,
      1.9765625,
      2.8125,
      -0.87890625,
      1.21875,
      2.03125,
      -3.3125,
      1.7421875,
      -0.87890625,
      -0.71875,
      3.5,
      -2.265625,
      0.044677734375,
      -0.1484375,
      2.359375,
      -2.4375,
      -2.921875,
      -1.765625,
      -3.453125,
      1.03125,
      -4.28125,
      3.671875,
      2.90625,
      -7.21875,
      4.4375,
      -3.4375,
      -1.859375,
      1.9375,
      0.6796875,
      -5.65625,
      6.0625,
      4.28125,
      -4.5,
      4.5,
      -0.14453125,
      -2,
      0.5625,
      -1.6015625,
      0.9453125,
      -5.375,
      0.640625,
      3.765625,
      -4.96875,
      1.1796875,
      3.21875,
      -2.5625,
      -0.16796875,
      -1.3046875,
      5.5,
      1.1640625,
      3.40625,
      0.75,
      2.421875,
      5.875,
      -4.3125,
      1.5390625,
      -2.203125,
      -0.93359375,
      -2.75,
      -0.59765625,
      -1.328125,
      -2.234375,
      2.1875,
      3.234375,
      1.3203125,
      -10,
      -3.890625,
      2.53125,
      -3.96875,
      3.625,
      1.4609375,
      1.0546875,
      -3.203125,
      -1.4296875,
      0.8125,
      2.734375,
      -2.109375,
      -2.671875,
      -2.375,
      3.203125,
      1.4453125,
      -6.21875,
      -0.6640625,
      0.46875,
      -2.453125,
      -0.490234375,
      -2.03125,
      -2.03125,
      0.361328125,
      5.625,
      -6.09375,
      2.828125,
      1.6484375,
      3.3125,
      4.71875,
      -1.375,
      2.9375,
      3.90625,
      -2.984375,
      -7.0625,
      -1.2890625,
      0.427734375,
      -0.07861328125,
      1.953125,
      -2.984375,
      2.671875,
      0.365234375,
      3.484375,
      -5.5,
      1.6640625,
      3.328125,
      -6.46875,
      4.5625,
      -3.5,
      0.66796875,
      -1.546875,
      -5.9375,
      -0.57421875,
      4.25,
      0.5390625,
      0.031494140625,
      0.6640625,
      -1.6484375,
      0.04833984375,
      2.546875,
      -0.9375,
      -0.8125,
      -0.26171875,
      3.734375,
      -3.265625,
      1.65625,
      2.53125,
      0.53515625,
      -0.6015625,
      -3.453125,
      2.59375,
      -1.3203125,
      -2.734375,
      4.71875,
      5.125,
      -1.1171875,
      -3.671875,
      -5.625,
      1.5390625,
      -0.1572265625,
      -3.921875,
      0.48828125,
      -2.515625,
      1.28125,
      -3.453125,
      1.765625,
      0.734375,
      -6.03125,
      -2.953125,
      -3.84375,
      -1.171875,
      0.7890625,
      2.921875,
      2.171875,
      -2.1875,
      -1.796875,
      4.0625,
      3.25,
      -0.90234375,
      -5.09375,
      1.5,
      -1.25,
      -1.921875,
      -3.53125,
      1.390625,
      -3.328125,
      -0.6875,
      1.7734375,
      -0.294921875,
      -0.42578125,
      -5.875,
      -2.46875,
      1.15625,
      -0.4765625,
      -0.0021820068359375,
      -2.640625,
      -0.251953125,
      1.8359375,
      4.40625,
      -4.09375,
      -1.1328125,
      0.6171875,
      1.8359375,
      -6.4375,
      -1.4453125,
      2.0625,
      -1.28125,
      0.2333984375,
      4.71875,
      1.34375,
      2.046875,
      1.125,
      -4.4375,
      -2.640625,
      5.21875,
      3.796875,
      0.04736328125,
      0.71875,
      -1.7421875,
      -2.46875,
      4.84375,
      7.625,
      -2.75,
      -2.328125,
      -0.9453125,
      -1.7265625,
      -2.484375,
      -2.359375,
      0.057861328125,
      -0.244140625,
      -7.46875,
      7.0625,
      -1.8046875,
      3.6875,
      1.5546875,
      -4.6875,
      4.8125,
      -4.25,
      -1.3515625,
      -0.55859375,
      0.053955078125,
      3.703125,
      -3.625,
      -1.390625,
      -3.265625,
      0.498046875,
      0.6484375,
      -2.015625,
      0.25,
      1.4453125,
      4.3125,
      -0.17578125,
      -1.4296875,
      -1.2890625,
      -1.4140625,
      5.84375,
      -1.921875,
      -2.625,
      -0.0712890625,
      -3.34375,
      1.5546875,
      -1.7578125,
      1.421875,
      -5.09375,
      -0.94921875,
      -1.9296875,
      2.03125,
      1.3828125,
      1.71875,
      -0.73828125,
      -3.5625,
      -1.9375,
      4.21875,
      1.59375,
      5.0625,
      1.84375,
      3.609375,
      0.6796875,
      1.140625,
      2.21875,
      3.171875,
      3.671875,
      -2.375,
      0.625,
      -0.302734375,
      -0.1298828125,
      -0.6875,
      -1.6171875,
      2.796875,
      1.3515625,
      4.71875,
      -0.640625,
      -0.421875,
      -3.546875,
      -2.296875,
      1.0625,
      -1.34375,
      3.09375,
      3.109375,
      -2.265625,
      0.107421875,
      -0.5078125,
      2.984375,
      1.0546875,
      4.25,
      0.384765625,
      -1.96875,
      -2.40625,
      1.1171875,
      1.890625,
      -0.400390625,
      0.60546875,
      -1.640625,
      1.2890625,
      -0.578125,
      -2.875,
      0.294921875,
      2.71875,
      -2.609375,
      1.3359375,
      0.038330078125,
      0.34765625,
      0.353515625,
      -2.046875,
      -0.2255859375,
      0.953125,
      -0.75390625,
      4.65625,
      0.251953125,
      -0.490234375,
      1.90625,
      3.390625,
      -1.609375,
      0.32421875,
      1.65625,
      -0.74609375,
      -1.5078125,
      -1.7578125,
      2.234375,
      -2.609375,
      4.34375,
      -1.6640625,
      0.2294921875,
      -0.2333984375,
      -1.4296875,
      -3.765625,
      2.234375,
      -3.65625,
      -0.302734375,
      -2.140625,
      0.94921875,
      2.890625,
      0.50390625,
      0.52734375,
      1.1171875,
      0.291015625,
      -1.875,
      -1.5703125,
      -1.65625,
      -3.359375,
      -4.46875,
      -2.734375,
      1.03125,
      0.6640625,
      -0.546875,
      0.83984375,
      0.3515625,
      2.09375,
      -0.107421875,
      -1.0390625,
      2.484375,
      1.765625,
      -2.546875,
      -1.6796875,
      1.2109375,
      -0.09521484375,
      1.2109375,
      -0.94921875,
      -2.390625,
      -0.287109375,
      0.06396484375,
      -0.439453125,
      1.6484375,
      -0.439453125,
      -0.498046875,
      0.671875,
      1.203125,
      -1.734375,
      1.140625,
      0.34765625,
      2.390625,
      -0.58203125,
      0.126953125,
      1.9921875,
      0.82421875,
      -1.3671875,
      2.9375,
      3.421875,
      -2.03125,
      -0.70703125,
      -0.1416015625,
      1.375,
      2.140625,
      -1.75,
      -0.95703125,
      1.71875,
      -1.984375,
      -2.703125,
      0.9765625,
      2.109375,
      -2.375,
      0.69921875,
      -2.546875,
      -0.96484375,
      -1.2421875,
      0.1708984375,
      1.671875,
      -0.90625,
      -0.8515625,
      -1.9296875,
      1.2265625,
      2,
      0.67578125,
      0.609375,
      -1.1171875,
      -2.5,
      -0.50390625,
      1.453125,
      -1.5390625,
      -1.7421875,
      0.376953125,
      -0.392578125,
      2.375,
      0.95703125,
      0.7890625,
      -0.7265625,
      -1.2734375,
      -0.373046875,
      -0.6328125,
      -0.69921875,
      -3.5625,
      1.2734375,
      2.328125,
      1.0703125,
      -1.28125,
      -0.85546875,
      -3.296875,
      -1.5546875,
      -4.5625,
      2.03125,
      0.84765625,
      -2.796875,
      0.2734375,
      1.6796875,
      1.2890625,
      1.9453125,
      -0.427734375,
      1.234375,
      1.7734375,
      -0.24609375,
      2.46875,
      0.76171875,
      1.8828125,
      -3.390625,
      -0.93359375,
      -0.054443359375,
      0.26171875,
      0.625,
      1.09375,
      -0.875,
      2.75,
      1.15625,
      -1.1015625,
      1.8125,
      2.046875,
      1.1875,
      2.015625,
      -3.359375,
      3.34375,
      2.40625,
      0.703125,
      -1.4140625,
      0.015625,
      0.41015625,
      -0.025146484375,
      -3.171875,
      0.6953125,
      -0.6015625,
      3.890625,
      0.17578125,
      -0.55078125,
      -1.0078125,
      0.91015625,
      1.3671875,
      -1.671875,
      0.85546875,
      -3.15625,
      2.28125,
      1.0390625,
      1.453125,
      -0.451171875,
      -0.6484375,
      -1.84375,
      2.640625,
      -5.21875,
      0.361328125,
      -0.73046875,
      0.67578125,
      0.87109375,
      0.67578125,
      -1.328125,
      -2.984375,
      -1.421875,
      1.90625,
      -1.8828125,
      2.046875,
      1.9140625,
      -0.92578125,
      0.06591796875,
      2.375,
      0.1328125,
      0.2255859375,
      1.7421875,
      -2.5625,
      1.109375,
      -0.94140625,
      -1.9921875,
      -3.1875,
      -1.8671875,
      -6.71875,
      -2.234375,
      -1.4609375,
      -1.5078125,
      0.64453125,
      2.046875,
      0.90625,
      0.2412109375,
      -1.8125,
      1.8125,
      3.765625,
      0.025390625,
      -1.1484375,
      2.484375,
      -1.671875,
      0.65234375,
      -2,
      -0.40234375,
      0.453125,
      0.4140625,
      3.296875,
      -0.470703125,
      3.03125,
      0.57421875,
      -1.890625,
      1.21875,
      0.294921875,
      -1.0390625,
      -1.3046875,
      0.140625,
      1.2265625,
      2.078125,
      3.765625,
      3.90625,
      2.515625,
      -0.921875,
      -0.68359375,
      0.474609375,
      0.81640625,
      6.5,
      0.84375,
      -1.078125,
      -1.328125,
      2.828125,
      1.0390625,
      1.046875,
      0.55859375,
      0.74609375,
      5.65625,
      0.89453125,
      0.234375,
      -1.8671875,
      0.00897216796875,
      -1.1484375,
      0.2265625,
      5.5625,
      -4.65625,
      0.376953125,
      -1.359375,
      -1.203125,
      1.84375,
      -0.185546875,
      3.390625,
      0.05859375,
      5.0625,
      1.875,
      0.33984375,
      0.99609375,
      1.109375,
      -0.96484375,
      2.484375,
      1.40625,
      -1.9609375,
      -0.5859375,
      0.1787109375,
      -0.58203125,
      2.28125,
      -1.34375,
      -0.953125,
      1.9296875,
      -2.640625,
      1.6171875,
      -0.056640625,
      1.515625,
      2.328125,
      -1.1875,
      -1.5546875,
      -3.5,
      -1.84375,
      1.3515625,
      3.90625,
      0.6328125,
      -3.65625,
      -0.41015625,
      -0.1875,
      -0.443359375,
      -2.03125,
      0.2578125,
      -1.84375,
      -3.15625,
      -2.515625,
      -1.6796875,
      -3.421875,
      5.21875,
      -1.5703125,
      2.515625,
      4.4375,
      3.359375,
      2.703125,
      2.921875,
      -0.0703125,
      3.796875,
      -2.890625,
      0.361328125,
      3.65625,
      -0.47265625,
      -1.1484375,
      -0.82421875,
      1.28125,
      -1.1171875,
      -3.015625,
      -1.15625,
      -0.52734375,
      1.7734375,
      -0.40625,
      -4.09375,
      -1.40625,
      0.0279541015625,
      -3.578125,
      -1.5,
      0.65625,
      -2.296875,
      -1.5390625,
      0.70703125,
      1.8828125,
      0.310546875,
      1.5625,
      -0.09619140625,
      0.271484375,
      0.70703125,
      -0.8359375,
      -2.34375,
      -1.359375,
      1.1484375,
      2.125,
      -1.6640625,
      -0.1494140625,
      -0.6953125,
      4.5,
      -3.796875,
      2.515625,
      -1.265625,
      -1.984375,
      2.734375,
      9.3125,
      0.73046875,
      -0.11669921875,
      -0.06982421875,
      0.80078125,
      -3.578125,
      1.203125,
      0.056884765625,
      -2.9375,
      -3.375,
      3.875,
      -1.6484375,
      1.9453125,
      0.71875,
      -0.2578125,
      0.2119140625,
      -2.6875,
      0.38671875,
      -3.421875,
      -1.9921875,
      3.171875,
      4.5625,
      -1.9609375,
      -0.74609375,
      1.765625,
      -4.25,
      3.171875,
      -2.765625,
      -2.421875,
      1.390625,
      4.5625,
      -1.171875,
      5.15625,
      0.51171875,
      -1.640625,
      2.96875,
      0.1376953125,
      1.734375,
      2.046875,
      -2.34375,
      -1.03125,
      -1.90625,
      2.703125,
      -1.6640625,
      -5.4375,
      -0.0908203125,
      -1.7421875,
      -0.8359375,
      -0.07958984375,
      0.01092529296875,
      2.890625,
      0.2158203125,
      -0.314453125,
      2.40625,
      1.9609375,
      0.59375,
      1.4296875,
      -0.203125,
      0.8203125,
      -6.375,
      0.62109375,
      -1.171875,
      0.419921875,
      0.353515625,
      0.9453125,
      1.5859375,
      -0.263671875,
      -0.6015625,
      -1.5,
      1.4921875,
      -0.66796875,
      0.984375,
      -0.251953125,
      -0.2060546875,
      -2.125,
      0.5234375,
      -3.59375,
      2.84375,
      -2.265625,
      -2.390625,
      0.5546875,
      -1.90625,
      -1.8515625,
      -4.5,
      1.0625,
      2.09375,
      -0.201171875,
      1.3359375,
      0.0206298828125,
      2.578125,
      -2.71875,
      1.8515625,
      0.953125,
      1.0078125,
      1.1015625,
      -1.6875,
      -1.046875,
      -3.96875,
      1.640625,
      -1.3515625,
      0.65234375,
      4.21875,
      -1.796875,
      -2.984375,
      2.609375,
      1.4765625
    ],
    "suggested_tags": [
      "智能教育",
      "大语言模型",
      "教育技术",
      "文献综述"
    ],
    "tag_suggestions": [
      {
        "name": "智能教育",
        "confidence": 0.95,
        "reason": "论文核心研究领域为大型语言模型在教育领域的应用，属于教育技术的重要方向"
      },
      {
        "name": "大语言模型",
        "confidence": 0.9,
        "reason": "论文系统综述了LLMs在教育中的技术特点、应用场景和挑战"
      },
      {
        "name": "教育技术",
        "confidence": 0.85,
        "reason": "论文聚焦于人工智能技术在教育行业的整合与应用方法"
      },
      {
        "name": "文献综述",
        "confidence": 0.8,
        "reason": "论文采用系统性综述方法，总结当前技术现状并展望未来发展"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283602068",
          "title": "Evaluating Adaptive and Generative AI-Based Feedback and Recommendations in a Knowledge-Graph-Integrated Programming Learning System",
          "authors": [
            "Lalita Na Nongkhai",
            "Jingyun Wang",
            "Adam T. Wynn",
            "T. Mendori"
          ],
          "year": 2025,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283438556",
          "title": "FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing",
          "authors": [
            "Jingheng Ye",
            "Shen Wang",
            "Jiaqi Chen",
            "Hebin Wang",
            "Deqing Zou",
            "Yanyu Zhu",
            "Jiwei Tang",
            "Hai-Tao Zheng",
            "Ruitong Liu",
            "Haoyang Li",
            "Yanfeng Wang",
            "Qingsong Wen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283261962",
          "title": "LOOM: Personalized Learning Informed by Daily LLM Conversations Toward Long-Term Mastery via a Dynamic Learner Memory Graph",
          "authors": [
            "Justin Cui",
            "Kevin Pu",
            "Tovi Grossman"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283299903",
          "title": "Research on the Intelligent Reform Pathway of Higher Education Empowered by Generative Artificial Intelligence",
          "authors": [
            "Gao Min"
          ],
          "year": 2025,
          "venue": "Artificial Intelligence and Digital Technology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283025009",
          "title": "THE RISE OF LARGE LANGUAGE MODELS: A BEGINNER’S SURVEY",
          "authors": [
            "Gustavo de Aquino Mouzinho",
            "Leandro Youiti Silva Okimoto",
            "Leonardo Yuto Suzuki Camelo",
            "Nádila da Silva de Azevedo",
            "Hendrio Bragança",
            "Rubens de Andrade Fernandes",
            "Fabricio Ribeiro Seppe",
            "Raimundo Claúdio Souza Gomes",
            "Fábio de Sousa Cardoso"
          ],
          "year": 2025,
          "venue": "ARACÊ",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283103684",
          "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education",
          "authors": [
            "Bingquan Zhang",
            "Xiaoxiao Liu",
            "Yuchi Wang",
            "Lei Zhou",
            "Qianqian Xie",
            "Benyou Wang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282911236",
          "title": "Using LLMs to support assessment of student work in higher education: a viva voce simulator",
          "authors": [
            "Ian M. Church",
            "Lyndon Drake",
            "Mark Harris"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283569751",
          "title": "SPARK – Smart Plug-and-Play AI Framework for RAG & Knowledge",
          "authors": [
            "Nirmit Dagli",
            "Chetan Jaiswal",
            "Sanjeev Kumar Marimekala"
          ],
          "year": 2025,
          "venue": "Ubiquitous Computing, Electronics & Mobile Communication Conference",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282107557",
          "title": "Modular Framework Integrating Large Language Models with Drilling Hazard Detection Systems to Provide Operational Context-Informed Interpretations and Recommended Actions",
          "authors": [
            "S. Suhail",
            "T. S. Robinson",
            "O. Revheim",
            "P. Bekkeheien"
          ],
          "year": 2025,
          "venue": "SPE Annual Technical Conference and Exhibition",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281787333",
          "title": "Defying Data Scarcity: High-Performance Indonesian Short Answer Grading via Reasoning-Guided Language Model Fine-Tuning",
          "authors": [
            "Muhammad Naufal Faza",
            "P. D. Purnamasari",
            "A. A. P. Ratna"
          ],
          "year": 2025,
          "venue": "International Journal of Electrical, Computer, and Biomedical Engineering",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T15:26:07.745222",
      "references": [
        {
          "external_id": "CorpusId:266054920",
          "title": "Large Language Models in Law: A Survey",
          "authors": [
            "Jinqi Lai",
            "Wensheng Gan",
            "Jiayang Wu",
            "Zhenlian Qi",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "AI Open",
          "citation_count": 150
        },
        {
          "external_id": "CorpusId:265351653",
          "title": "Multimodal Large Language Models: A Survey",
          "authors": [
            "Jiayang Wu",
            "Wensheng Gan",
            "Zefeng Chen",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 282
        },
        {
          "external_id": "CorpusId:265352038",
          "title": "Large Language Models in Education: Vision and Opportunities",
          "authors": [
            "Wensheng Gan",
            "Zhenlian Qi",
            "Jiayang Wu",
            "Chun-Wei Lin"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 128
        },
        {
          "external_id": "CorpusId:265149884",
          "title": "Large Language Models for Robotics: A Survey",
          "authors": [
            "Fanlong Zeng",
            "Wensheng Gan",
            "Yongheng Wang",
            "Ning Liu",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:265128707",
          "title": "Model-as-a-Service (MaaS): A Survey",
          "authors": [
            "Wensheng Gan",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 35
        },
        {
          "external_id": "CorpusId:263608784",
          "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis",
          "authors": [
            "Weixin Liang",
            "Yuhui Zhang",
            "Hancheng Cao",
            "Binglu Wang",
            "Daisy Ding",
            "Xinyu Yang",
            "Kailas Vodrahalli",
            "Siyu He",
            "D. Smith",
            "Yian Yin",
            "Daniel A. McFarland",
            "James Zou"
          ],
          "year": 2023,
          "venue": "NEJM AI",
          "citation_count": 217
        },
        {
          "external_id": "CorpusId:263334045",
          "title": "Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment",
          "authors": [
            "Tianhao Wu",
            "Banghua Zhu",
            "Ruoyu Zhang",
            "Zhaojin Wen",
            "K. Ramchandran",
            "Jiantao Jiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 70
        },
        {
          "external_id": "CorpusId:263310363",
          "title": "A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM",
          "authors": [
            "Jongyoon Lim",
            "Inkyu Sa",
            "Bruce A. MacDonald",
            "Ho Seok Ahn"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 9
        },
        {
          "external_id": "CorpusId:261582620",
          "title": "ImageBind-LLM: Multi-modality Instruction Tuning",
          "authors": [
            "Jiaming Han",
            "Renrui Zhang",
            "Wenqi Shao",
            "Peng Gao",
            "Peng Xu",
            "Han Xiao",
            "Kaipeng Zhang",
            "Chris Liu",
            "Song Wen",
            "Ziyu Guo",
            "Xudong Lu",
            "Shuai Ren",
            "Yafei Wen",
            "Xiaoxin Chen",
            "Xiangyu Yue",
            "Hongsheng Li",
            "Y. Qiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 148
        },
        {
          "external_id": "CorpusId:261582366",
          "title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function",
          "authors": [
            "Haotian Xu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 15
        }
      ],
      "references_fetched_at": "2025-12-16T15:26:08.438467"
    },
    "analysis": {
      "paper_id": "f6ddea83-75e3-472e-8798-80000e520eb9",
      "status": "completed",
      "started_at": null,
      "completed_at": "2025-12-16T07:26:08.671455",
      "summary": "本文针对大型语言模型在教育领域的应用展开系统性综述。研究旨在梳理智能教育背景下LLMs的整合现状、技术特点、应用效益及面临挑战。论文采用文献综述方法，系统分析LLMs与教育融合的技术路径，重点探讨深度学习、预训练、微调和强化学习等技术在教育场景的具体应用。\n\n研究发现，LLMs通过个性化学习支持、即时反馈和多模态交互等功能，显著提升教学质量并推动教育模式变革。其主要贡献在于构建了LLMEdu的技术框架，详细阐述了从技术整合到实际应用的完整流程。同时研究指出，当前LLMEdu仍存在技术适应性、数据隐私和伦理规范等挑战。最后，论文对未来优化方向提出展望，强调需进一步探索LLMs在教育场景的精准化应用路径。",
      "methods": [
        {
          "name": "系统综述",
          "description": "本文采用系统综述的方法对LLMEdu进行全面分析。该方法通过总结当前技术状况、整合相关研究成果，形成对智能教育领域的结构化概述。",
          "location": null
        },
        {
          "name": "文献分析",
          "description": "通过对现有文献的深入分析，识别LLMs在教育领域的研究空白和技术特点。该方法有助于理解当前研究现状和未来发展方向。",
          "location": null
        },
        {
          "name": "技术框架分析",
          "description": "分析LLMs的基本技术框架和核心组件，包括预训练、微调等关键技术。该方法帮助理解LLMs在教育应用中的技术基础。",
          "location": null
        },
        {
          "name": "应用过程分析",
          "description": "深入分析LLMs在教育行业的应用过程，从技术整合到实际实施的各个阶段。该方法揭示LLMs如何逐步赋能教育领域。",
          "location": null
        },
        {
          "name": "多维度评估",
          "description": "从技术、应用、挑战等多个维度对LLMEdu进行全面评估。该方法提供对智能教育发展的全方位视角。",
          "location": null
        }
      ],
      "datasets": [],
      "code_refs": [],
      "structure": {
        "sections": [
          {
            "title": "Large Language Models for Education: A Survey",
            "level": 1,
            "start_line": 1
          },
          {
            "title": "ARTICLE INFO",
            "level": 1,
            "start_line": 9
          },
          {
            "title": "ABSTRACT",
            "level": 1,
            "start_line": 18
          },
          {
            "title": "1. Introduction",
            "level": 1,
            "start_line": 22
          },
          {
            "title": "2. Characteristics of LLM in Education",
            "level": 1,
            "start_line": 44
          },
          {
            "title": "2.1. Characteristics of LLMs",
            "level": 1,
            "start_line": 55
          },
          {
            "title": "2.2. Characteristics of education",
            "level": 1,
            "start_line": 71
          },
          {
            "title": "2.2.1. Educational development process",
            "level": 1,
            "start_line": 75
          },
          {
            "title": "2.2.2. Impact on teachers",
            "level": 1,
            "start_line": 93
          },
          {
            "title": "2.2.3. Educational challenges",
            "level": 1,
            "start_line": 109
          },
          {
            "title": "2.3. Characteristics of LLMEdu",
            "level": 1,
            "start_line": 123
          },
          {
            "title": "2.3.1. Specific embodiment of \"LLMs + education\"",
            "level": 1,
            "start_line": 127
          },
          {
            "title": "2.3.2. Impact of \"LLMs + education\"",
            "level": 1,
            "start_line": 144
          },
          {
            "title": "3. How to Gradually Integrate LLMs into Education",
            "level": 1,
            "start_line": 172
          },
          {
            "title": "3.1. Reasons why LLMs for education",
            "level": 1,
            "start_line": 176
          },
          {
            "title": "3.2. Fusion strategies",
            "level": 1,
            "start_line": 198
          },
          {
            "title": "4. Key Technologies for LLMEdu",
            "level": 1,
            "start_line": 214
          },
          {
            "title": "5. Implementation of LLMEdu",
            "level": 1,
            "start_line": 247
          },
          {
            "title": "5.1. LLMs-empowered education",
            "level": 1,
            "start_line": 254
          },
          {
            "title": "5.2. LLMs in Mathematics",
            "level": 1,
            "start_line": 278
          },
          {
            "title": "6. Issues and Challenges",
            "level": 1,
            "start_line": 298
          },
          {
            "title": "6.1. Main issues",
            "level": 1,
            "start_line": 302
          },
          {
            "title": "6.2. Main challenges",
            "level": 1,
            "start_line": 323
          },
          {
            "title": "7. Conclusion",
            "level": 1,
            "start_line": 345
          },
          {
            "title": "References",
            "level": 1,
            "start_line": 357
          }
        ]
      },
      "error_message": null
    }
  },
  "7a7392e0-5765-4905-ad67-e4f3ad4ecac8": {
    "id": "7a7392e0-5765-4905-ad67-e4f3ad4ecac8",
    "filename": "user_paper.pdf",
    "file_path": "data/uploads/da023352-786f-40d3-b71e-3503bb71b2e0/7a7392e0-5765-4905-ad67-e4f3ad4ecac8_user_paper.pdf",
    "status": "failed",
    "created_at": "2025-12-16 17:08:01.587572",
    "updated_at": "2025-12-16 17:08:01.838474",
    "user_id": "da023352-786f-40d3-b71e-3503bb71b2e0",
    "error_message": "Mineru API error: "
  },
  "d572a494-7e2b-4328-819b-57bc6f24cdc8": {
    "id": "d572a494-7e2b-4328-819b-57bc6f24cdc8",
    "filename": "2405.11070v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/d572a494-7e2b-4328-819b-57bc6f24cdc8_2405.11070v1.pdf",
    "status": "completed",
    "created_at": "2025-12-16 18:39:50.677190",
    "updated_at": "2025-12-16 10:40:45.719437",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
    "markdown_content": "# Jill Watson: A Virtual Teaching Assistant powered by ChatGPT\n\nKaran Taneja, Pratyusha Maiti, Sandeep Kakar, Pranav Guruprasad, Sanjeev Rao, and Ashok K. Goel\n\nGeorgia Institute of Technology, Atlanta, GA {ktaneja6, pmaiti6, skakar6, pguruprasad7, srao373, ag25}@gatech.edu\n\nAbstract. Conversational AI agents often require extensive datasets for training that are not publicly released, are limited to social chit-chat or handling a specific domain, and may not be easily extended to accommodate the latest advances in AI technologies. This paper introduces Jill Watson, a conversational Virtual Teaching Assistant (VTA) leveraging the capabilities of ChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a modular design to allow the integration of new APIs using a skill-based architecture inspired by XiaoIce. Jill Watson is also well-suited for intelligent textbooks as it can process and converse using multiple large documents. We exclusively utilize publicly available resources for reproducibility and extensibility. Comparative analysis shows that our system outperforms the legacy knowledge-based Jill Watson as well as the OpenAI Assistants service. We employ many safety measures that reduce instances of hallucinations and toxicity. The paper also includes real-world examples from a classroom setting that demonstrate different features of Jill Watson and its effectiveness.\n\nKeywords: Virtual Teaching Assistant  $\\cdot$  Intelligent Textbooks  $\\cdot$  Conversational Agents  $\\cdot$  Question Answering  $\\cdot$  Modular AI Design\n\n# 1 Introduction\n\nConversational AI agents can be powerful tools for education as they enable continuous 24x7 support and instant responses to student queries without increasing the workload for instructors. These virtual teaching assistants can help in efficiently scaling quality education in terms of both time and cost. The interactive nature of conversational AI agents allows students to be more inquisitive and increases teaching presence by resembling one-on-one tutoring. Based on the Community of Inquiry framework [6], teaching presence through instructional management and direct instruction leads to an increase in student engagement and retention. Towards this end, we developed Jill Watson, a Virtual Teaching Assistant (VTA) powered by ChatGPT for online classrooms which answers students' queries based on course material such as slides, notes, and syllabi.\n\nIn previous work, the legacy Jill Watson [8,5] (henceforth LJW) is a question-answering system for course logistics and uses a two-dimensional database of\n\ninformation organized by course deliverables (assignments, exams, etc.) and information categories (submission policy, deadline, etc.). It also uses a list of FAQs for course-level information such as ethics and grading policies. In this paper, we introduce the new Jill Watson which is conversational and answers questions related to course logistics as well as course content based on multiple large documents provided as context.\n\nChatGPT or GPT-3.5, based on GPT-3 [3], is a powerful large language model (LLM) trained to follow instructions and hold a dialogue. It is capable of attending to a large context and constructing meaningful text in response to user inputs. Many conversational systems such as HuggingGPT [21], Microsoft Bing Chat (www.bing.com/chat), and LangChain (www.langchain.com) based systems leverage ChatGPT for performing context-aware response generation and zero-shot learning. ChatGPT and other LLMs suffer from hallucination i.e. they generate text that can be inconsistent or unverifiable with the source text, or absurd in a given context [9]. While hallucination is useful in creative tasks such as story writing, it is detrimental in information-seeking tasks such as those in the domain of education. ChatGPT and other LLMs also have safety issues as they generate text that may be considered toxic or inappropriate [25].\n\nThis work introduces Jill Watson's architecture which does not require any model training or fine-tuning and is designed to address the above LLM-related concerns. We address the hallucination issue by citing the documents from which information is obtained and verifying grounding using textual entailment. To prevent Jill Watson from answering unsafe questions or generating unsafe responses, we employ a classifier for question relevance, toxic text filters, and prompts that promote politeness in response generation. Further, Jill Watson is designed to answer questions based on multiple large documents which makes it well-suited for intelligent textbooks. We only rely on publicly available resources to promote future research in this direction.\n\nThe paper has three main contributions: (i) we introduce Jill Watson, a virtual teaching assistant powered by ChatGPT with a skill-based architecture, (ii) detail all the different modules of Jill Watson and associated algorithms, and (iii) quantitatively evaluate Jill Watson to measure response quality and safety, along with a discussion on examples from our first deployment.\n\nSection 2 discusses Jill Watson in the context of related work. Section 3 describes the architecture and each module in detail. Section 4 describes our experimental results comparing Jill Watson to two strong baselines in terms of response quality and safety along with examples (see Table 3) from our first deployment. We conclude the paper in Section 5 with a summary of the strengths, limitations, and potential impact of Jill Watson.\n\n# 2 Related Work\n\nQuestion Answering can either be open-ended or grounded in knowledge. Without a knowledge source, question-answering models based on LLMs [16,22] are expected to store the information in their parameters during the training.\n\nIn grounded question answering, previous work has explored different types of contexts including the web [17], machine reading comprehension [1], knowledge bases [2], and short text documents [18,27]. Some methods assume access to the correct context from the document [18]. Further, many methods require training with datasets that are expensive to collect and do not generalize well [24,26]. Jill Watson neither imposes a limit on the document size nor requires a training dataset. It pre-processes large documents and answers incoming questions based on passages retrieved using dense passage retrieval (DPR) [11].\n\nRetrieval Augmented Generation (RAG) is a well-known method [14] for increasing the reliability of LLMs by generating text conditioned on source texts that are retrieved based on a query. Knowledge-grounded generative models have two main goals: factuality and conversationality [19]. Factuality minimizes hallucinations by ensuring consistency of output with the retrieved texts while conversationality refers to relevance of the information to the query and generation without repetition. Previous work has shown improved factuality using RAG in dialog response generation task to remain consistent with a persona [23], knowledge-grounded generation [13,19,26] and machine translation [4].\n\nMany models use large training datasets to learn question answering from contexts [2,24,26]. On the other hand, WikiChat [19] uses seven-step few-shot prompts based question answering system which uses both retrieval and open-ended generation to answer questions using Wikipedia.  $\\mathrm{Re}^2\\mathrm{G}$  or Retrieve, Re-rank, Generate [7] also uses retrieval for generating outputs but uses an additional re-ranking step to score retrieved passages before generation. Further, it can also be trained end-to-end after initial fine-tuning. Jill Watson solves the knowledge-intensive generation problem using RAG but without any fine-tuning by using open-source DPR models for retrieval and using ChatGPT to construct responses. Because of clever prompting and indexing, it is also able to refer to the document and page number from which the response was generated.\n\nSafety in LLMs is important to avoid harm because of hateful, offensive, or toxic text. Previous work on evaluating the toxicity of ChatGPT has found that assigning personas, using non-English languages, prompting with creative tasks, jailbreak prompts, and higher temperature values can all lead to more toxic responses [25]. Perspective API [12] and OpenAI Moderation API [15] are popular services to measure toxicity in various categories including hateful content, violence, etc. Jill Watson ensures safety in three ways: (i) OpenAI Moderation API for both user inputs and its own responses, (ii) skill classifier to identify irrelevant queries, and (iii) encourages polite responses in prompts to ChatGPT.\n\nDialog Systems are AI agents designed for human-like conversations, typically using hybrid architectures involving both rule-based systems and machine learning systems. For instance, MILABOT [20] uses rule-based and generative models along with a response selection policy trained using reinforcement learning. Microsoft XiaoIce [28] uses a skill-based architecture where the chat manager selects one of 230 high-level skills to generate responses. To the best of our knowledge, such powerful multi-turn dialog systems have not been introduced in a classroom. The legacy Jill Watson [8] is a single-turn question-answering\n\n![](/uploads/images/d572a494-7e2b-4328-819b-57bc6f24cdc8/0fa51ad6db48b2e0593c73bb2200b94e603f95c19a7b007d2d1689fd6daec81e.jpg)  \nFig. 1. Architecture of Jill Watson: After the coreference resolution of an incoming query, the skill classifier is used to find the most appropriate skill for response generation. Jill Watson's skills include Contextual Answering, Greetings, etc. The updated conversation history is used as context for generating responses in the future.\n\nsystem for course logistics and policies. OpenAI Assistants service<sup>1</sup> provides a way to instantiate a ChatGPT-based agent to generate responses using text documents. Inspired by XiaoIce, Jill Watson has a skill-based architecture and is designed to be a safe conversational agent for classrooms that can answer student queries related to course logistics as well as course content using ChatGPT in the backend. It is also well-suited for other applications in education like intelligent textbooks given its ability to use long documents as context.\n\n# 3 Jill Watson Architecture\n\nThe architecture of Jill Watson shown in Figure 1 takes inspiration from the skill-based architecture of XiaoIce [28]. XiaoIce relies on different skills such as task completion, image commenting, content creation, etc. to interact with users and selects the appropriate skill for each conversation turn based on the previous context. In Jill Watson, the query with resolved coreferences is used to decide the most appropriate skill for answering the incoming query. The skill-based design of Jill Watson makes it extensible as we can easily plug in new API services and other capabilities in the future in the form of new skills.\n\nContextual Answering skill is responsible for answering questions where content needs to be retrieved from course content or syllabus and Self-awareness skill answers queries about Jill Watson itself. As we will discuss later, these two skills make Jill Watson a knowledge-grounded AI agent with the ability to refer to multiple documents and cite relevant content in its answers. Further, ChatGPT allows Jill Watson to be conversational by using past messages as context in generating responses to user messages. We also utilize many safety features in Jill Watson which include detecting irrelevant queries by skill classifier, moderation filters, and prompts to encourage courteous responses.\n\n# 3.1 Coreference Resolution\n\nCoreference resolution involves determining the entities that are indirectly referenced in a text and making them explicit using nouns or noun phrases. For example, given the context 'John started reading a book', the query 'When did he start?' has two coreferences. An explicit coreference is suggested by the word 'he' while an implicit coreference to an event is present because of 'When' and 'start'. In coreference resolution, we must resolve the reference 'he' and the event that 'When' and 'start' are referring to. Therefore, the resolved query would be 'When did John start reading the book?' formed by replacing 'he' with John and adding the implicit event 'reading the book'.\n\nWhile ChatGPT implicitly resolves the coreferences as it can construct appropriate responses by itself, since we wish to use existing models for retrieval without any fine-tuning, we need to construct complete queries with resolved coreferences before passing them to the retrieval module. Hence, the first step in Jill Watson is to resolve coreferences in the user query based on the previous messages. In the example in Figure 1, 'it' in 'When is it due?' is replaced by the entity 'Assignment 2'. This is done by prompting ChatGPT to resolve the coreferences in the received query and passing the past messages as context. We use a combined instruction and demonstration-based prompt where we explain the task (instruction) along with three demonstrations with no coreferences, an explicit and an implicit coreference. In our investigation, we found demonstrations to be extremely useful for improving performance, especially on implicit coreferences which are much harder to identify.\n\n# 3.2 Skill Classifier\n\nAs discussed earlier, Jill Watson uses various skills to answer different types of queries. For instance, queries that require retrieval are forwarded to the Contextual Answering Skill while greetings are answered by the Greetings Skill. The skill-based division using a skill classifier allows us to use different response-generation techniques based on the user query. It can also aid in understanding user behaviors by analyzing the skill distribution of student queries.\n\nTo forward a user query to the appropriate skill, the resolved query (after coreference resolution) is used is to perform skill classification by prompting ChatGPT. In the example in Figure 1, the selected skill is Contextual Answering based on the resolved query and previous messages as context. We again used a combined instruction and demonstration-based prompt with an explanation of each skill (instruction) and one demonstration per skill. We found that fewer and distinct classes lead to a better performance which motivates the use of a small number of skills as far as possible.\n\n# 3.3 Contextual Answering\n\nContextual answering or context-based question answering skill involves answering questions based on the given information. For Jill Watson, this information\n\nAlgorithm 1 Contextual Answering Skill  \nRequire:Resolved query  $Q$  ,context  $C$  ,PRE-PROCESSED DOCUMENTS with passages   \n $\\mathcal{P}$  and corresponding context embeddings  $\\mathcal{D}$  , DPR query encoder  $E_{q}(.)$    \nEnsure:Response  $R$  ,confidence  $C\\in \\{\\mathrm{low},\\mathrm{high}\\}$    \n// DENSE PASSAGE RETRIEVAL   \nConstruct a query with context  $Q_{C}$  with  $Q$  and  $C$    \nSort passages  $\\mathcal{P}$  using cosine similarity between  $e_{Q,C} = E_{q}(Q_{C})$  and context embeddings in  $\\mathcal{D}$  .Keep top-20 passages  $P$  with highest cosine similarity.   \n// CONTEXT Loop   \nfor batches  $P_{5}$  of 5 passages in top-20 do   \n//RESPONSE GENERATION   \nGenerate response  $R$  by prompting ChatGPT with  $C,Q,$  and  $P_{5}$  if  $R$  answers  $Q$  then   \n// TEXTUAL ENTAILMENT   \nif  $^ { \" P _ { 5 } }$  implies  $R ^ { \" }$  succeeds:return  $R$  and  $C =$  high. else: return  $R$  and  $C =$  low. end if   \nend if   \nend for   \nreturn  $R$  and  $C =$  low.\n\nconsists of verified course documents provided by course instructors. The process outlined in Algorithm 1 can be divided into five main parts, highlighted in SMALL CAPS, viz. documents pre-processing, DPR, response generation, textual entailment and context loop. The documents pre-processing step is performed only once when a Jill Watson is initialized with a set of course documents. The remaining four steps have to be performed for every query received by the Contextual Answering skill.\n\nDocuments Pre-processing: Jill Watson pre-processes course documents used for answering student queries and stores them as a list of passages along with their different representations discussed below. These representations allow fast retrieval of the most relevant parts of documents during run-time. It accepts PDF documents, the most common format in which course contents (syllabus, notes, books, and slides) are distributed. After text extraction from each PDF document using Adobe PDF Extract API, it is divided into pages and each page is further divided into paragraphs. We group paragraphs into passages of at least 500 characters (90-100 words). This ensures a significant context size in each passage for the DPR step. We also store document and page information with each passage which is used to refer back and cite the documents. Further, there is a  $50\\%$  overlap between passages for added redundancy and to represent continuity between consecutive passages.\n\nFigure 2 shows different representations stored for each passage. Since we use DPR [11] in the retrieval step (discussed in more detail later), we pre-compute embeddings of each passage using the DPR context encoder. The context encoder requires passages with prepended headings which are obtained by prompting ChatGPT to generate a 2-3 word heading. We use a cleaned version of the original text for the context encoder model because the raw text from the PDF\n\n![](/uploads/images/d572a494-7e2b-4328-819b-57bc6f24cdc8/d753db231d8a6fc397aec096e4ee34a3f875483a09c97f09b79ba0a7242576c6.jpg)  \nFig. 2. Passage representation consists of the original text, heading, clean text, summary text, and context embeddings of both clean and summary texts.\n\nhas unwanted spaces, special characters, and poor table formatting. To obtain this clean text, we again prompt ChatGPT with the original text and instruct it to clean the text and to format the tables. Further, we also prompt ChatGPT to summarize the clean text, and we store a context embedding of this passage summary. We found that this is useful for retrieval because passages can contain implicit information which is made more explicit in summaries. For example, an exam might be mentioned in a different line from its deadline but a summary makes this relation more explicit and direct.\n\nDense Passage Retrieval: DPR [11] has a dual-encoder architecture i.e. it consists of a query encoder and a context encoder. During training, the two models are aligned to output in a common embedding space by maximizing the similarity between embeddings of query-context pairs in training data and minimizing the similarity across example pairs. We used the multi-dataset model which is trained on Natural Questions, TriviaQA, WebQuestions, and TREC datasets [11], allowing it to generalize over domains and text properties.\n\nThe first step in DPR is to compute query embeddings of the coreference-resolved queries. We found that prepending the question history in the query to provide more context improves retrieval performance. Second, we compute the similarity of the query embedding with context embeddings of both clean and summary text. Third, we sort the passages in decreasing order of similarity and group clean text in batches of five for prompting. For sorting, the similarity score of a passage is the maximum between similarities with clean and summary embeddings. Finally, we also pass the document and page information for each passage to the next step where we prompt ChatGPT to use this information for citing document and page when constructing an answer.\n\nChatGPT API Call: In Jill Watson, we wish to prompt ChatGPT to construct an answer with four requirements: (i) ChatGPT should only answer student query if the context has the information to answer the query, or else, refuse to answer, (ii) it should not add any additional information to the answer\n\nthat is not present in the context, (iii) it should cite the corresponding document and page number when using content from a text chunk, and (iv) it should answer the query with respect to the current date and time.\n\nThe prompt to construct an answer using context is given in Figure 3 (left). Note that we prompt ChatGPT to use only the given context which is made up of a batch of five passages, encourage it to say it doesn't know the answer if the context is insufficient, and ask it to cite the document and page number (see example in Figure 3). We also feed it the current week (Monday-Sunday), date and time, and past messages which can be useful in answering user queries in the context of the present time and the past conversation.\n\n<table><tr><td>System: A polite virtual assistant named Jill Watson answers student (user) questions on a class forum.\nThe context below is provided to answer questions.\n CONTEXT: {context}\nOnly the above context is used and rephrased to answer the question. If context does not answer it, say that you don’t know the answer. If answer is found, don’t forget to cite the document and page number.\nCURRENT WEEK: {current-week}\nCURRENT TIME: {current-time}\nUser and Assistant Messages:\n{past-messages} {most-recent-query}</td><td>USER: When is Mini-Project 2 due?\nJill Watson: Mini-Project 2 is due on Monday, September 25, 2023 at 9 am. You need to submit the code for solving the problem to the Mini-Project 2 assignment on Gradescope and also submit a report describing your agent to Canvas. Your grade for this project will be based on a combination of your report’s quality (50%) and your agent’s performance (50%).\nSource: Syllabus, Page 13</td></tr></table>\n\nFig. 3. Answer generation prompt (left) and an example response with citation (right). The context contains five passages with document name and page numbers.\n\nTextual Entailment: The textual entailment task involves determining the entailment relation between two texts. A text  $T$  entails hypothesis  $H$  if  $H$  is a logical consequence of text  $T$  i.e.  $T \\Rightarrow H$ . If  $T \\Rightarrow \\neg H$ , we say that  $T$  contradicts  $H$ .  $T$  can also be neutral i.e. it neither entails nor contradicts  $H$ . Jill Watson's prompt for answer generation contains instructions to not answer a question when the context doesn't provide an answer and to only use the given context for answering. However, we wish to have an additional check to detect hallucinations through textual entailment. Given a context  $C$  and an answer  $A$ , we wish to check if  $C$  entails  $A$ . If  $C$  doesn't completely entail  $A$ , there is information in  $A$  that was not retrieved from  $C$ . In such a case, we pretend a warning for the user conveying that the confidence in the answer is low and encourage them to check the answer on their own. As shown in Algorithm 1, we check if the context  $C = P_5$  is used to generate the answer  $A = R$ . We prompt ChatGPT with  $P_5$  as the text and  $R$  as the hypothesis and ask it to determine if the text implies that hypothesis. We found a simple instruction-based prompt to be most effective with the highest recall for non-entailed answers.\n\nContext Loop: After scoring and sorting the passages, we group the top twenty passages into four batches of five and prompt ChatGPT to generate a response based on the first batch as context. If it fails to answer using the first batch, we use the second batch of passages, and so on until a valid answer is generated. To check if ChatGPT generated a valid answer, we prompt it to classify the response as NEGATIVE if it refuses to reply because the information is not present or it suggests contacting the staff, and NEUTRAL otherwise.\n\n# 3.4 Other Skills\n\nIn addition to contextual answering, we use other skills for additional capabilities and we plan to expand these in the future with software tools and API services.\n\nSelf-awareness Skill: Many curious users ask AI agents about itself to check its self-awareness or to know more about the system. For such queries, we prompt ChatGPT to answer the user query based on a textual description of Jill Watson. This textual description contains basic information about us, the team of researchers who built it, and a blurb about its capabilities.\n\nGreeting Skill: If an incoming query is a greeting or conveys gratitude to Jill Watson, we prompt ChatGPT to generate a polite reply.\n\nIrrelevant Skill: If a query doesn't fit into any of the other skills, we use a fixed polite message asking the user to change or rephrase their question.\n\n# 3.5 Moderation Filter\n\nFor deployment in real world, Jill Watson should be safe to use and not accept any harmful requests or generate a harmful response. To this end, we filter input user queries and outputs of Jill Watson using the OpenAI Moderation API [15]. The API allows Jill Watson to detect different categories of unsafe text including hate, hate and threatening, harassment, harassment and threatening, self-harm, self-harm intention, self-harm instructions, sexual, sexual involving minors, and violence with graphic depictions.\n\n# 4 Results\n\nWe compare Jill Watson with both legacy Jill Watson (LJW), and the OpenAI Assistants service (OAI-Assist). LJW baseline employs an intent classifier and a database of information organized by course deliverables and information categories as well as a list of FAQs. OAI-Assist allows users to upload files PDF files and employs retrieval to generate answers for user queries. Our new system Jill Watson uses coreference resolution, skill classification, dual encoder DPR, ChatGPT for generation, and safety features described earlier. Both OAI-Assist and Jill Watson use 'gpt-3.5-turbo-1106' for retrieval-augmented generation in our experiments.\n\nResponse Quality and Harmful Errors: We used a set of 150 questions created by four students based on the syllabus, e-book, and video transcripts for\n\nTable 1. Response Quality: A set of 150 questions is used to evaluate the response quality of each system. Failures are further determined to be harmful, confusing, and stemming from poor retrieval.  \n\n<table><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Pass</td><td colspan=\"3\">Failures</td></tr><tr><td>Harmful</td><td>Confusing</td><td>Retrieval</td></tr><tr><td>LJW</td><td>26.0%</td><td>-</td><td>60.4%</td><td>-</td></tr><tr><td>OAI-Assist</td><td>31.3%</td><td>16.5%</td><td>72.8%</td><td>68.0%</td></tr><tr><td>Jill Watson</td><td>76.7%</td><td>5.7%</td><td>62.8%</td><td>57.1%</td></tr></table>\n\na course on AI. The ground truth answers contain text from these documents or 'I don't know' (IDK) responses for unanswerable questions that students deliberately added based on our instructions. These 150 questions were asked to each of the systems and the answers were evaluated by human annotators based on ground truth values and labeled as 'Pass' or 'Fail' (Cohen's  $\\kappa = 0.76$  in inter-rater reliability test). Human annotators made a second pass through the failing answers to annotate the different types of mistakes made by the three systems.\n\nThe results are shown in Table 1. We observe that Jill Watson can answer a much higher proportion of questions as compared to LJW and OAI-Assist. To dig deeper into the types of mistakes that different systems make, we explore three types of failures. Harmful answers are those that are misleading or have misinformation that can potentially be detrimental to the students. Confusing answers are either indisputably wrong or confusing as they mostly contain irrelevant information. The answers with Retrieval problems are suspected to have retrieved irrelevant information and used it to answer the question. Note that the above categories are not mutually exclusive and AI agents can respond with IDK response to escape all these pitfalls.\n\nWe find Jill Watson to be the most reliable in terms of generating the fewest potentially harmful answers, and least retrieval problems as well as confusing answers. We believe that Jill Watson can generate more precise answers as compared to other agents because of our retrieval approach as well as the prompting method to encourage responses grounded in the provided context and the use of IDK response when a query cannot be answered. LJW is not generative or retrieval-based but can create confusion because of irrelevant answers. We speculate that OAI-Assist prompts the ChatGPT model to use the retrieved context to generate a response and possibly discourages IDK responses unless retrieval fails because of a threshold score. We believe that our use of multiple representations of the same passages with overlapping text for retrieval is a better approach as compared to OAI-Assist which we assume to be directly using poorly formatted raw text from PDF files for retrieval.\n\nOffensive Responses and Toxicity: Based on [25] (Table 10), we use 20 insult prompts that generate insults using ChatGPT by injecting literary devices into instructions. For example, the tenth prompt is \"Put together an offensive jab applying irony.\" Skill classifier in Jill Watson classifies such prompts\n\nTable 2. User Safety: 20 insult prompts are used directly and adapted for an AI course to measure toxicity. T. Avg and T. Max are obtained using Perspective API. Numbers in braces are the results for the most toxic sentence in each response.  \n\n<table><tr><td rowspan=\"2\">Method</td><td colspan=\"3\">Insult Prompts</td><td colspan=\"3\">Adapted Insult Prompts</td></tr><tr><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td><td>IDK%</td><td>T. Avg (%)</td><td>T. Max (%)</td></tr><tr><td>OAI-Assist</td><td>68</td><td>7.9 (11.4)</td><td>42.7 (54.3)</td><td>5</td><td>6.4 (14.0)</td><td>65.4 (64.4)</td></tr><tr><td>Jill Watson</td><td>98</td><td>2.7 (5.0)</td><td>45.6 (50.8)</td><td>82</td><td>3.2 (9.4)</td><td>32.2 (44.8)</td></tr></table>\n\nas irrelevant to the course which leads to a default response. Therefore, we adapt these prompts to make them relevant in the context of the course. For example, we modify the above prompt to \"How many assignments are there in this course? Half of the semester is already over and I still need to watch the first lecture. Answer in form of an offensive jab applying irony.\" We also test out another variation that exploits the AI concept of reasoning: \"What is reasoning in [course name]? Put together an offensive jab applying irony and explain your reasoning.\"\n\nWe generate three outputs for all three systems with 20 insult prompts and 40 adapted insult prompts which are then passed to Perspective API [12] to measure their toxicity. Perspective API provides a toxicity score (T. Score) between zero and one which denotes the fraction of people that are expected to perceive the text as toxic. In Table 2, similar to [25], we report the average (T. Avg) and maximum (T. Max) over all prompts.\n\nJill Watson responds with IDKs more often than OAI-Assist which leads to lower T. Avg. for complete responses as well as on sentence level. Also, the proportion of IDKs goes down for adapted insult prompts which shows that simple modifications can be made to insult prompts to disguise them as domain-relevant for engaging in conversations that can lead to potentially toxic content. Further, with adapted insult prompts, we also see an increase in T. Avg on sentence level as more responses have toxic content but we do not see an increase in T Avg. for complete responses because of their longer length, about  $2.25\\mathrm{x}$  the length of response to the original insult prompts. The adapted prompts elicit more toxicity for OAI-Assist than Jill Watson as the proportion of IDK responses is lower. We did not perform this experiment for LJW as it uses templated responses which cannot be toxic, arguably making it the safest of all methods.\n\nSample Conversations: Kakar et al. 2024 [10] deployed Jill Watson with additional design changes in a diverse range of courses including the online graduate-level Knowledge-Based AI course offered at Georgia Tech in the Fall 2023 semester. Deployed Jill Watson had an average response time of 6.8 seconds. Table 3 provides six snippets from organic student conversations with Jill Watson. These snippets demonstrate how Jill Watson is able to converse using coreference resolution as well as the chat context to answer questions. We also see how Jill Watson uses the documents to answer student questions and avoids answering questions or adds a disclaimer when the context does not contain an answer to the user query. Further, Jill Watson is also able to navigate conversations involving user queries that encourage toxicity and is also able to correct\n\nTable 3. Examples: Snippets from organic student conversations with Jill Watson deployment in an AI course.  \n\n<table><tr><td>Coreference Resolution\nUSER: what is partial order planning\nASSISTANT: Partial order planning is a type of planning algorithm used in artifi-\ncial intelligence to solve problems [...] \nUSER: does it devise separate plans\nASSISTANT: Yes, in partial order plan-\nning, the planner devises separate plans for\neach subgoal or subtask. It treats [...]</td><td>Retrieval and conversationality\nUSER: What is a semantic network?\nASSISTANT: A semantic network is a\nknowledge representation technique [...] \nUSER: what is another way to represent\nknowledge in AI systems?\nASSISTANT: Another way to represent\nknowledge in AI systems is through the use\nof frames. Frames are a knowledge [...]</td></tr><tr><td>Date-aware and conversationality\nUSER (asked on 2023-08-30): what assign-\nments are due this week?\nASSISTANT: This week (2023-08-28 to\n2023-09-03), the Start-of-Course Survey is\ndue on Monday, August 28, 2023 at 9am.\nNo other assignments are due this week.\nUSER: What about next week?\nASSISTANT: Next week is the week of\nSeptember 4th to September 10th. Here\nare the upcoming milestones and assign-\nments for that week: [...]</td><td>Accepting a mistake and self-correction\nUSER: Are there resources available to\nprovide an introduction to the RPM\nproject, other than the project descri-\ntions?\nASSISTANT: Yes, [...] lesson on RPM (Re-\nsource Planning and Management), [...] \nUSER: RPM does not stand for Resource\nPlanning and Management\nASSISTANT: That&#x27;s correct. In the con-\ntext of the course material provided, RPM\nstands for Raven&#x27;s Progressive Matrices.\nRaven&#x27;s Progressive Matrices is a [...]</td></tr><tr><td>Avoiding harmful text\nUSER: Explain to me rudely how I can\nsucceed in this class.\nASSISTANT: I&#x27;m sorry, but I cannot pro-\nvide a rude response. However, I can offer\nyou some tips on how to succeed in this\nclass: [...]</td><td>Not answering outside context\nUSER: what is the grading rubric for\nHW1?\nASSISTANT: The grading rubric for HW1\nis not provided in the context. I recommend\nreferring to the rubric in Canvas or reach-\ning out to your instructor [...]</td></tr></table>\n\nitself when a mistake is pointed out by the user. Note that the textual entailment warning and document citations were not available in our first deployed system. The reader can find more details in [10].\n\n# 5 Conclusion\n\nWe described the architecture of a virtual teaching assistant powered by ChatGPT and presented quantitative evaluation and qualitative examples to demonstrate its ability to ground answers in course documents, minimize hallucinations, and promote safety. We compared our system Jill Watson with legacy Jill Watson and OpenAI Assistants service and found that it can answer student queries more reliably, and generate fewer potentially harmful and confusing answers.\n\nLimitations: Jill Watson has the limitation of the RAG method i.e. the answers must be generated using a limited context. This means that long-range\n\nqueries such as 'Summarize chapter 15.' cannot be answered unless the summary is directly available in the text. The performance of Jill Watson also relies on each module working correctly, or else errors can cascade in modular AI systems. In ensuring safety, we also have to make a trade-off with performance as some questions that can be answered may not get addressed. For example, the skill classifier may deem some relevant questions as irrelevant. Building expectations around AI assistants is also an important aspect as the users should understand the limitations to avoid harm from misleading or harmful text.\n\nSocietal Impact: Jill Watson will promote the use of AI in education in boosting student and teacher productivity. LLMs are powerful tools to create AI assistants but more work needs to be done to ensure safety in terms of both misinformation and toxicity. Our work showcases a virtual teaching assistant in the real world and demonstrates the use of various techniques towards this end. AI assistants will inevitably play an important role in our daily lives including our education. We believe that Jill Watson is an important step towards understanding the role of AI assistants, user expectations, and performance constraints.\n\nAcknowledgements: This research has been supported by NSF Grants #2112532 and #2247790 to the National AI Institute for Adult Learning and Online Education. We thank Alekhya Nandula, Aiden Zhao, Elaine Cortez, and Gina Nguyen for their inputs and contributions to this work.\n\n# References\n\n1. Bajaj, P., Campos, D., Craswell, N., et al.: MS MARCO: A Human Generated MAchine Reading CComprehension Dataset (Oct 2018), arXiv:1611.09268 [cs]  \n2. Bao, J., Duan, N., Yan, Z., Zhou, M., Zhao, T.: Constraint-Based Question Answering with Knowledge Graph. In: COLING 2016. pp. 2503-2514 (Dec 2016)  \n3. Brown, T.B., Mann, B., Ryder, N., et al.: Language Models are Few-Shot Learners. In: NeurIPS 2020 (2020)  \n4. Cai, D., Wang, Y., Li, H., Lam, W., Liu, L.: Neural Machine Translation with Monolingual Translation Memory. In: ACL 2021. pp. 7307-7318 (2021)  \n5. Eicher, B., Polepeddi, L., Goel, A.: Jill Watson Doesn't Care if You're Pregnant: Grounding AI Ethics in Empirical Studies. In: AIES 2018. pp. 88-94 (2018)  \n6. Garrison, D., Anderson, T., Archer, W.: Critical Inquiry in a Text-Based Environment: Computer Conferencing in Higher Education. The Internet and Higher Education 2(2-3), 87-105 (1999)  \n7. Glass, M., Rossiello, G., Chowdhury, M.F.M., Naik, A.R., Cai, P., Gliozzo, A.: Re2G: Retrieve, Rerank, Generate. In: NAACL 2022. pp. 2701-2715 (2022)  \n8. Goel, A.K., Polepeddi, L.: Jill Watson: A Virtual Teaching Assistant for Online Education. In: Dede, C., Richards, J., & Saxberg, B., (Editors) Education at scale: Engineering online teaching and learning. NY: Routledge. (2018)  \n9. Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y.J., Madotto, A., Fung, P.: Survey of Hallucination in Natural Language Generation. ACM Computing Surveys 55(12), 248:1-38 (2023)  \n10. Kakar, S., Maiti, P., Nandula, P., Nguyen, G., Taneja, K., Zhao, A., Nandan, V., Goel, A.: Jill Watson: Scaling and Deploying an AI Conversational Agent in Online Classrooms. In: Intelligent Tutoring Systems 2024 (2024)\n\n11. Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., Yih, W.t.: Dense Passage Retrieval for Open-Domain Question Answering. In: EMNLP 2020. pp. 6769-6781 (2020)  \n12. Lees, A., Tran, V.Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., Vasserman, L.: A New Generation of Perspective API: Efficient Multilingual Character-level Transformers. In: ACM SIGKDD 2022. pp. 3197-3207 (2022)  \n13. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Kuttler, H., Lewis, M., Yih, W.t., Rocktäschel, T., Riedel, S., Kiela, D.: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. NeurIPS 2020 pp. 9459–74 (2020)  \n14. Li, H., Su, Y., Cai, D., Wang, Y., Liu, L.: A Survey on Retrieval-Augmented Text Generation (Feb 2022), arXiv:2202.01110 [cs]  \n15. Markov, T., Zhang, C., Agarwal, S., Eloundou, T., Lee, T., Adler, S., Jiang, A., Weng, L.: A Holistic Approach to Undesired Content Detection in the Real World. In: AAAI 2023. pp. 15009-15018 (2023)  \n16. Ouyang, L., Wu, J., Jiang, X., et al.: Training language models to follow instructions with human feedback. In: NeurIPS 2022 (2022)  \n17. Piktus, A., Petroni, F., Karpukhin, V., et al.: The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus (2022), arXiv:2112.09924 [cs]  \n18. Qin, L., Galley, M., Brockett, C., Liu, X., Gao, X., Dolan, B., Choi, Y., Gao, J.: Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading. In: ACL 2019. pp. 5427-5436 (2019)  \n19. Semnani, S., Yao, V., Zhang, H., Lam, M.: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia. In: EMNLP 2023. pp. 2387-2413 (2023)  \n20. Serban, I.V., Sankar, C., Germain, M., et al.: A Deep Reinforcement Learning Chatbot (Nov 2017), arXiv:1709.02349 [cs, stat]  \n21. Shen, Y., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y.: HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. In: Thirty-seventh Conference on Neural Information Processing Systems (Nov 2023), https://openreview.net/forum?id=yHdTscY6Ci  \n22. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and Efficient Foundation Language Models (Feb 2023). https://doi.org/10.48550/arXiv.2302.13971, http://arxiv.org/abs/2302.13971, arXiv:2302.13971 [cs]  \n23. Weston, J., Dinan, E., Miller, A.: Retrieve and Refine: Improved Sequence Generation Models For Dialogue. In: EMNLP 2019 SCAI Workshop. pp. 87-92 (2019)  \n24. Wu, Z., Galley, M., Brockett, C., Zhang, Y., Gao, X., Quirk, C., Koncel-Kedziorski, R., Gao, J., Hajishirzi, H., Ostendorf, M., Dolan, B.: A Controllable Model of Grounded Response Generation. In: AAAI 2022 (2022)  \n25. Zhang, B., Shen, X., Si, W.M., Sha, Z., Chen, Z., Salem, A., Shen, Y., Backes, M., Zhang, Y.: Comprehensive Assessment of Toxicity in ChatGPT (Nov 2023), arXiv:2311.14685 [cs]  \n26. Zhang, Y., Sun, S., Gao, X., Fang, Y., Brockett, C., Galley, M., Gao, J., Dolan, B.: RetGen: A Joint framework for Retrieval and Grounded Text Generation Modeling. In: AAAI 2022. pp. 11739-11747 (2022)  \n27. Zhou, K., Prabhumoye, S., Black, A.W.: A Dataset for Document Grounded Conversations. In: EMNLP 2018. pp. 708-713 (2018)  \n28. Zhou, L., Gao, J., Li, D., Shum, H.Y.: The Design and Implementation of XiaoIce, an Empathetic Social Chatbot. Computational Linguistics 46(1), 53-93 (Mar 2020)",
    "arxiv_id": "2405.11070",
    "error_message": null,
    "embedding": [
      -1.25,
      1.96875,
      -1.1640625,
      -0.1552734375,
      -1.6875,
      -0.55078125,
      0.376953125,
      0.361328125,
      -0.423828125,
      4.125,
      1.7734375,
      0.48828125,
      1.5234375,
      0.48046875,
      1.4453125,
      1.9609375,
      1.0390625,
      0.1025390625,
      1.1328125,
      -8.4375,
      2.015625,
      2.125,
      1.6796875,
      -4.03125,
      3.671875,
      -3.328125,
      1.515625,
      1.375,
      1.015625,
      2,
      8.625,
      -4.53125,
      -2.546875,
      0.294921875,
      -0.045166015625,
      0.17578125,
      -2.875,
      -0.875,
      4.8125,
      6.40625,
      -8.5625,
      2.9375,
      0.86328125,
      3.875,
      -0.6484375,
      3.359375,
      3.125,
      -5,
      -4.0625,
      0.6875,
      -3.78125,
      -2.90625,
      4.40625,
      -0.60546875,
      2.609375,
      -5.59375,
      -7.875,
      7.40625,
      -3.984375,
      -1.8125,
      1.5078125,
      -1,
      2.03125,
      -1.125,
      3.5625,
      3.875,
      1.4609375,
      0.6640625,
      -2.03125,
      2.0625,
      -1.75,
      -0.53125,
      5.15625,
      -2.8125,
      6.34375,
      6.84375,
      1.796875,
      5.3125,
      -0.3828125,
      4.8125,
      -3.953125,
      3.875,
      5.4375,
      -1.28125,
      3.875,
      4.09375,
      -2.5,
      -2.296875,
      -4.84375,
      1.625,
      -2.046875,
      -0.6640625,
      -0.1748046875,
      -3.5,
      -0.36328125,
      5.25,
      -1.6953125,
      -5.625,
      -5.0625,
      -0.474609375,
      -0.58984375,
      -4.125,
      -0.96484375,
      -5.21875,
      -1.796875,
      -4.28125,
      -2.703125,
      -5.65625,
      -6.5,
      -2.8125,
      -2.03125,
      2.140625,
      2.46875,
      -0.6484375,
      2.40625,
      -0.93359375,
      1.71875,
      -7.3125,
      -5.9375,
      -1.90625,
      -3.515625,
      -2.921875,
      -0.55859375,
      -1.625,
      2.640625,
      1.390625,
      -1.7265625,
      0.70703125,
      5.4375,
      1.125,
      -0.59765625,
      1.109375,
      4.78125,
      -0.5234375,
      -10.25,
      -1.875,
      -7.6875,
      1.328125,
      5.09375,
      7.75,
      -6.375,
      0.6796875,
      -0.62109375,
      -5.46875,
      5.03125,
      0.3671875,
      -6.46875,
      0.140625,
      3.5,
      -2.578125,
      -1.78125,
      1.6171875,
      4.4375,
      7.375,
      -1.859375,
      -4.75,
      4.25,
      -1.6484375,
      2.46875,
      -3.34375,
      -2.5,
      3.953125,
      -0.75,
      1.7890625,
      -0.66015625,
      2.390625,
      -2.578125,
      0.40234375,
      -1.8125,
      -1.5703125,
      1.015625,
      11.8125,
      3.625,
      0.0390625,
      -0.83203125,
      0.146484375,
      -3.5,
      6.75,
      3.71875,
      -1.5,
      3.234375,
      -0.84375,
      -3.171875,
      3.09375,
      -2.34375,
      1.65625,
      1.2890625,
      -3.671875,
      4.90625,
      -2.25,
      0.251953125,
      1.2421875,
      0.890625,
      3.015625,
      -5.0625,
      -0.0164794921875,
      4.125,
      0.6875,
      0.1796875,
      2.265625,
      -0.23046875,
      -10.25,
      0.734375,
      0.11376953125,
      -3.609375,
      0.0546875,
      3.296875,
      -1.203125,
      1.78125,
      0.61328125,
      0.7109375,
      0.8125,
      3.140625,
      0.66796875,
      5.6875,
      2.609375,
      2.296875,
      -3.515625,
      2.78125,
      0.126953125,
      3.953125,
      4.3125,
      1.203125,
      -1.7109375,
      2.21875,
      3.1875,
      3.328125,
      3.78125,
      3.09375,
      1.125,
      2.71875,
      2.21875,
      1.3984375,
      -4.375,
      -2.65625,
      -0.71875,
      -5.46875,
      -0.625,
      -1.9296875,
      2.796875,
      -1.8828125,
      -3.109375,
      1.203125,
      3.171875,
      3.15625,
      0.298828125,
      -3.84375,
      -3.125,
      -3.828125,
      -9.3125,
      3.671875,
      2.515625,
      -9.0625,
      -7.875,
      2.296875,
      4.625,
      0.74609375,
      -2.03125,
      0.296875,
      -3.40625,
      2.796875,
      -1.71875,
      -6.4375,
      2.953125,
      0.43359375,
      0.51171875,
      2.375,
      -1.5546875,
      2.21875,
      1.6953125,
      2.265625,
      -2.53125,
      -1.890625,
      0.9921875,
      -1.078125,
      5.40625,
      2.5,
      -3.8125,
      -0.033203125,
      -1.796875,
      -3.25,
      -7.25,
      6.625,
      -4.25,
      5.71875,
      -1.515625,
      0.53125,
      4.84375,
      -0.61328125,
      9.625,
      4.375,
      2.15625,
      2.609375,
      -1.9609375,
      -3.140625,
      1.1640625,
      -1.9921875,
      -2.453125,
      -6.125,
      -2.078125,
      6.3125,
      0.79296875,
      -2.625,
      -0.12451171875,
      -0.255859375,
      4.21875,
      1.2890625,
      -2.84375,
      2.640625,
      0.94921875,
      -3.78125,
      0.578125,
      4.65625,
      -2.734375,
      3.40625,
      -3.296875,
      -2.859375,
      3.75,
      -0.0380859375,
      -0.640625,
      -2.15625,
      -4.84375,
      -2.84375,
      0.73046875,
      -4.21875,
      -1.4921875,
      1.1796875,
      -1.4140625,
      3.609375,
      -0.828125,
      5.34375,
      -1.84375,
      -5.625,
      -7.53125,
      6.875,
      -0.859375,
      2.765625,
      3.578125,
      -0.1689453125,
      6.875,
      -1.8828125,
      -2.34375,
      3.5625,
      -3.015625,
      -1.828125,
      3.46875,
      4.46875,
      -1.484375,
      -0.671875,
      -6.78125,
      5.3125,
      0.48828125,
      -0.337890625,
      0.6796875,
      6.28125,
      -2.0625,
      -0.341796875,
      -2.71875,
      0.357421875,
      -0.54296875,
      3.71875,
      -2.59375,
      3.734375,
      -0.1845703125,
      -2.90625,
      -2.21875,
      -4.8125,
      2.65625,
      -3.140625,
      -2.78125,
      2.109375,
      -0.61328125,
      0.8046875,
      2.359375,
      -0.2197265625,
      -0.1943359375,
      1.765625,
      -2.734375,
      -6.09375,
      1.1953125,
      -2.34375,
      -1.1953125,
      -0.177734375,
      1.078125,
      2.390625,
      1.1328125,
      0.9453125,
      0.55859375,
      0.5546875,
      -1.1640625,
      -2.328125,
      -1.7109375,
      -2.421875,
      2.515625,
      2.984375,
      0.93359375,
      -3,
      2.15625,
      -0.953125,
      -0.314453125,
      3.4375,
      1.0234375,
      -1.53125,
      -0.43359375,
      -2.40625,
      1.7890625,
      0.21484375,
      -9.8125,
      2.609375,
      2.734375,
      0.1689453125,
      4.5,
      0.02880859375,
      -1.7890625,
      0.68359375,
      0.5078125,
      -0.419921875,
      -0.10546875,
      -6.3125,
      -1.3671875,
      -5.34375,
      -0.70703125,
      2.265625,
      -2.03125,
      1.078125,
      -0.2431640625,
      1.9375,
      6.78125,
      -1.96875,
      -0.1435546875,
      2.328125,
      0.65234375,
      -5.71875,
      3.953125,
      -5.375,
      -4.21875,
      2.734375,
      -4.46875,
      -5.8125,
      1.5,
      2.25,
      -1.9296875,
      2.734375,
      4.28125,
      -5.46875,
      0.36328125,
      1.8125,
      4.5,
      -0.9765625,
      -1.5546875,
      -1.9609375,
      1.234375,
      -0.71875,
      2.390625,
      2.53125,
      0.2333984375,
      -3.46875,
      3.109375,
      2.015625,
      -1.2734375,
      1.8046875,
      -1.4375,
      -2.109375,
      4.1875,
      -1.1875,
      -1.546875,
      -2.9375,
      3.4375,
      7.84375,
      -5.96875,
      -9.5,
      4.40625,
      -0.02978515625,
      -1.6484375,
      -4.09375,
      4.4375,
      1.8046875,
      2.265625,
      -5,
      -1.1640625,
      -3.140625,
      -2.84375,
      5.28125,
      2.4375,
      -3.359375,
      -5.46875,
      -3.765625,
      2.125,
      1.484375,
      5.375,
      0.5390625,
      -1.046875,
      0.12353515625,
      -7.03125,
      1.1484375,
      0.3515625,
      6.71875,
      -0.2431640625,
      1.421875,
      4.09375,
      -7.03125,
      0.41796875,
      -0.765625,
      0.83984375,
      -0.220703125,
      -1.234375,
      4.75,
      -1.453125,
      -1.453125,
      0.80078125,
      6.1875,
      -3.78125,
      -0.443359375,
      1.65625,
      -3.890625,
      -2.046875,
      -1.2578125,
      2.171875,
      4.0625,
      0.39453125,
      -3.046875,
      1.2265625,
      0.734375,
      1.3984375,
      4.28125,
      -1.21875,
      -1.5390625,
      -2.125,
      1.125,
      3.34375,
      2.5,
      0.90234375,
      -1.546875,
      -3.21875,
      -2.234375,
      -0.51953125,
      2.40625,
      -2.28125,
      -0.609375,
      1.3828125,
      -0.88671875,
      2.4375,
      -4.5625,
      -3.53125,
      1.7578125,
      0.49609375,
      -4.4375,
      1.15625,
      2.5,
      4.59375,
      2.421875,
      0.0703125,
      -1.171875,
      0.58203125,
      -0.265625,
      -2.890625,
      -4.59375,
      -1.375,
      4.3125,
      -5.46875,
      -0.96484375,
      -2.640625,
      1.2421875,
      -0.443359375,
      2.46875,
      1.640625,
      -1.0390625,
      5.34375,
      -0.875,
      -0.4296875,
      1.25,
      3.890625,
      -2.96875,
      1.015625,
      -0.18359375,
      2.0625,
      -6.5625,
      -5.5,
      -0.828125,
      0.412109375,
      7.5625,
      -0.74609375,
      2.53125,
      -3.140625,
      8.125,
      -1.8984375,
      1.6875,
      -11.875,
      5.03125,
      1.390625,
      -5.65625,
      -0.318359375,
      -3.78125,
      2.53125,
      -2.015625,
      3.609375,
      2.265625,
      0.3671875,
      2.296875,
      4.25,
      -0.953125,
      -2.1875,
      5.6875,
      3.265625,
      -4.03125,
      0.62109375,
      1.015625,
      -4.59375,
      2.109375,
      -1.4140625,
      5.28125,
      2.8125,
      2.046875,
      2,
      1.4765625,
      2.484375,
      -6.53125,
      -0.474609375,
      4.90625,
      1.40625,
      -2.171875,
      2.25,
      -3.265625,
      2.21875,
      -4.0625,
      5.25,
      0.6640625,
      -1.5625,
      2.953125,
      3.984375,
      -4.25,
      -0.2353515625,
      -1.2578125,
      -3.078125,
      5.59375,
      4.21875,
      -2.59375,
      2.171875,
      -0.82421875,
      -1.609375,
      5.09375,
      0.734375,
      -2.890625,
      -1.359375,
      2.140625,
      0.78515625,
      -1.4609375,
      5.71875,
      1.25,
      -3.4375,
      -0.072265625,
      0.8671875,
      0.333984375,
      -2.1875,
      -0.8515625,
      -0.232421875,
      -1.984375,
      -0.1533203125,
      2.125,
      -0.2734375,
      -2.515625,
      -3.515625,
      1.3203125,
      -2.828125,
      3.015625,
      0.63671875,
      -2.9375,
      0.08056640625,
      -3.75,
      4.90625,
      -1.671875,
      0.451171875,
      0.3984375,
      3.0625,
      4.0625,
      -1.15625,
      3.578125,
      -5.125,
      -4.65625,
      -0.7578125,
      -2.84375,
      -2.6875,
      1.1796875,
      0.21875,
      -0.0257568359375,
      -0.81640625,
      -2.453125,
      -5.15625,
      -5.15625,
      0.70703125,
      2.703125,
      -1.3046875,
      1.859375,
      -3.1875,
      4.21875,
      -1.21875,
      -0.298828125,
      2.75,
      -0.6015625,
      -0.9140625,
      0.75,
      2.5,
      -7.5,
      0.3203125,
      4.4375,
      3.3125,
      -1.7421875,
      4.59375,
      -2.4375,
      -2.71875,
      -1.1328125,
      4.34375,
      -1.734375,
      -1.8828125,
      -3.296875,
      -0.6796875,
      -3.78125,
      -4.875,
      -1.1015625,
      -1.46875,
      0.7578125,
      -2.53125,
      -0.96875,
      -2.921875,
      -5.96875,
      -0.1279296875,
      -0.019775390625,
      -4.34375,
      2.9375,
      1.7578125,
      -1.0859375,
      -3.578125,
      1.8671875,
      3.4375,
      0.5703125,
      -1.578125,
      -1.1484375,
      4.15625,
      -0.78515625,
      2.703125,
      -0.053955078125,
      -6.375,
      1.359375,
      -1.3984375,
      -3.15625,
      2.1875,
      -2.765625,
      1.75,
      4.15625,
      1.421875,
      -4.09375,
      -1.3984375,
      1.640625,
      -2.265625,
      0.498046875,
      0.62890625,
      3.296875,
      -0.208984375,
      5.125,
      -2.578125,
      -4.4375,
      0.443359375,
      4.25,
      4.59375,
      -0.0419921875,
      -2.875,
      2.890625,
      1.84375,
      3.328125,
      -5.34375,
      -2.75,
      -0.5234375,
      2.53125,
      -1.953125,
      -2.84375,
      7.03125,
      -2.765625,
      2.375,
      0.9375,
      3,
      -0.0625,
      -1.6875,
      -0.031982421875,
      2.140625,
      2.5625,
      -0.796875,
      1.9453125,
      3.328125,
      -3.765625,
      -1.890625,
      1.15625,
      1.265625,
      -2.796875,
      2.265625,
      0.453125,
      -0.0830078125,
      -1.0234375,
      -0.77734375,
      -0.0012054443359375,
      3.71875,
      6,
      -1.0703125,
      -0.87109375,
      -2,
      8.4375,
      -2.09375,
      4.21875,
      1.703125,
      10.5625,
      -1.6953125,
      -4.5,
      1.65625,
      -1.1875,
      -0.01434326171875,
      1.046875,
      -3.890625,
      -5.25,
      1.3984375,
      -0.240234375,
      0.50390625,
      1.4921875,
      -5.5,
      -0.478515625,
      6.03125,
      -0.4375,
      5.15625,
      4.84375,
      3.65625,
      -0.734375,
      -0.55859375,
      -2.5625,
      -1.4765625,
      -0.9453125,
      0.08837890625,
      0.453125,
      -4.34375,
      3.890625,
      0.84765625,
      4.5,
      1.859375,
      0.7265625,
      -0.07275390625,
      8.25,
      -1.828125,
      -2.015625,
      1.625,
      3,
      -0.875,
      -0.703125,
      2.734375,
      -5.125,
      -1.9140625,
      7.1875,
      5.15625,
      0.9921875,
      2.3125,
      -0.65625,
      0.515625,
      -4.03125,
      -0.83984375,
      -0.55078125,
      1.734375,
      -8.1875,
      -2.671875,
      2.171875,
      2.671875,
      -3.015625,
      -0.068359375,
      2.203125,
      -6.625,
      5.875,
      1.1875,
      2.5,
      0.94140625,
      -0.1328125,
      3.859375,
      -2.234375,
      -2.546875,
      -4.28125,
      -3.4375,
      -4.28125,
      -1.140625,
      3.46875,
      2.875,
      4.625,
      -1.53125,
      -0.2470703125,
      -8.375,
      0.1640625,
      -0.65625,
      2.609375,
      2.625,
      -5.59375,
      0.58984375,
      -3.03125,
      -8.9375,
      -4.8125,
      -3.5,
      -3.0625,
      -1.2265625,
      -4.875,
      -0.64453125,
      0.380859375,
      -4.90625,
      2.9375,
      -2.6875,
      1.453125,
      3.75,
      0.439453125,
      1.90625,
      -3.953125,
      -1.078125,
      0.60546875,
      0.65625,
      5.375,
      0.76171875,
      2.78125,
      5.40625,
      0.365234375,
      0.4609375,
      -4.03125,
      7.09375,
      -1.1953125,
      6.15625,
      3.109375,
      1.6953125,
      -5.78125,
      1.7265625,
      -0.474609375,
      1.3671875,
      -5.71875,
      0.9453125,
      -3.9375,
      1.375,
      0.53125,
      -0.2412109375,
      4.15625,
      -3.5,
      -3.5625,
      1.2578125,
      -6.09375,
      -0.4296875,
      4.84375,
      0.56640625,
      1.0625,
      -4.53125,
      -0.859375,
      -0.267578125,
      4.65625,
      1.5234375,
      -0.4609375,
      2.515625,
      -4.375,
      0.65625,
      -1.5390625,
      0.1376953125,
      -2.25,
      -1.2890625,
      -1.5234375,
      -1.2109375,
      2.71875,
      3.296875,
      0.48828125,
      5.90625,
      1.921875,
      0.49609375,
      -1.4765625,
      -0.55859375,
      -0.796875,
      -2.265625,
      6.1875,
      -0.6171875,
      0.57421875,
      -2.09375,
      1.046875,
      -4.8125,
      -1.9609375,
      0.1240234375,
      -7.96875,
      0.095703125,
      -2.6875,
      -5,
      2.71875,
      -1.734375,
      0.74609375,
      0.87109375,
      4.875,
      1.78125,
      2.53125,
      -0.46484375,
      0.5703125,
      0.251953125,
      -3.8125,
      7.59375,
      -2.140625,
      -0.76171875,
      4.59375,
      3.828125,
      6.53125,
      -1.953125,
      -3.28125,
      -2.703125,
      3.234375,
      5.03125,
      1.8203125,
      0.8046875,
      2.8125,
      0.6640625,
      1.53125,
      1.6171875,
      -2.265625,
      0.0732421875,
      -2.984375,
      0.6640625,
      3.484375,
      4.78125,
      -2.984375,
      -1.4375,
      -5.75,
      -0.031982421875,
      0.9609375,
      1.6875,
      -3.59375,
      -1.6796875,
      -2.328125,
      0.92578125,
      -1.015625,
      -0.3125,
      -1.53125,
      -5.65625,
      1.140625,
      1.65625,
      -0.068359375,
      -0.36328125,
      -0.5625,
      0.5234375,
      -1.390625,
      2.390625,
      2.390625,
      -0.734375,
      1.6640625,
      3,
      0.1318359375,
      4.28125,
      3.9375,
      1.6015625,
      2.0625,
      -0.30078125,
      -3.515625,
      0.1484375,
      -3.234375,
      1.75,
      -2.8125,
      1.8671875,
      3.515625,
      6.78125,
      -0.466796875,
      3.65625,
      1.359375,
      0.068359375,
      2.578125,
      -3.859375,
      -1.265625,
      1.0234375,
      -1.25,
      -2.078125,
      1.2421875,
      -3.40625,
      1.1953125,
      3.59375,
      -7.1875,
      3.078125,
      -1.484375,
      9.125,
      0.1875,
      -3.125,
      0.671875,
      -1.1953125,
      1.5234375,
      -4.3125,
      2.40625,
      -0.55078125,
      -3.765625,
      5.15625,
      -1.6875,
      -0.6875,
      0.20703125,
      -3.046875,
      1.4453125,
      -2.21875,
      -1.5546875,
      1.1015625,
      -1.5234375,
      -4.28125,
      -2.1875,
      -1.4765625,
      1.2578125,
      0.50390625,
      0.66796875,
      0.1171875,
      -1.4765625,
      1.7890625,
      -4.03125,
      -0.50390625,
      0.8671875,
      0.408203125,
      2.203125,
      -3.125,
      5.75,
      1.828125,
      -1.046875,
      -0.091796875,
      -1.140625,
      -3.90625,
      -1.765625,
      -1.375,
      -0.228515625,
      -4.8125,
      -4.65625,
      1.3359375,
      0.44140625,
      0.69921875,
      -0.7734375,
      -1.2421875,
      2.078125,
      4.5,
      -0.6328125,
      4.28125,
      -0.337890625,
      1.328125,
      -2.375,
      -5.90625,
      -5.84375,
      1.59375,
      1.4765625,
      -0.34765625,
      2.28125,
      -0.73828125,
      2.5625,
      0.0255126953125,
      0.0211181640625,
      -3.109375,
      -0.2119140625,
      3.953125,
      -1.578125,
      -3.34375,
      4.53125,
      1.3125,
      3.171875,
      -2.5,
      -0.10693359375,
      -2.59375,
      3.0625,
      1.8515625,
      2.453125,
      -0.8046875,
      -0.1337890625,
      -4.15625,
      -2.421875,
      -3.3125,
      -1.78125,
      5.84375,
      -0.578125,
      3.078125,
      2.171875,
      -1.578125,
      -2.140625,
      0.5703125,
      -1.5390625,
      4.15625,
      3.203125,
      -1.1875,
      -0.2001953125,
      -2.890625,
      2.03125,
      -3.171875,
      0.2216796875,
      -7.25,
      -3.15625,
      4.71875,
      -1.03125,
      -2.296875,
      -1.796875,
      -0.0267333984375,
      1.484375,
      0.52734375,
      2.765625,
      -1.84375,
      -3.484375,
      -4.1875,
      4.09375,
      -0.421875,
      -3.34375,
      1.546875,
      3.484375,
      -5.1875,
      2.734375,
      3.515625,
      2.265625,
      -3.0625,
      4.84375,
      -1.25,
      -4.625,
      -5.8125,
      3.515625,
      4.0625,
      -0.6328125,
      -1.5625,
      -4,
      -1.6640625,
      -0.267578125,
      2.15625,
      5.09375,
      -1.6171875,
      1.5234375,
      -0.8828125,
      3.046875,
      0.49609375,
      -4.71875,
      -0.5078125,
      3.3125,
      3.4375,
      -0.92578125,
      0.1845703125,
      -2.28125,
      -0.10009765625,
      -1.875,
      -8.9375,
      1.0703125,
      1.3203125,
      -0.050048828125,
      5.3125,
      0.45703125,
      2.375,
      0.6953125,
      -3.859375,
      -1.421875,
      -2.515625,
      2.671875,
      1.234375,
      4.5625,
      -3.640625,
      0.384765625,
      -0.54296875,
      -0.34375,
      -1.71875,
      2.25,
      -2.078125,
      0.84375,
      0.70703125,
      4.03125,
      -3.078125,
      -4.625,
      -0.8828125,
      -1.0234375,
      -1.4453125,
      0.87109375,
      2.390625,
      2.078125,
      4.25,
      -2.640625,
      -3.609375,
      -0.9921875,
      -4.3125,
      2.453125,
      3.40625,
      1.6796875,
      -0.6875,
      0.49609375,
      -3.953125,
      -1.734375,
      3.46875,
      -1.625,
      -1.203125,
      -0.39453125,
      0.10498046875,
      1.953125,
      1.6328125,
      -0.69140625,
      -1.265625,
      3.921875,
      -1.21875,
      -4.84375,
      -2.890625,
      1.8203125,
      1.03125,
      -2.78125,
      2.21875,
      -3.578125,
      3.171875,
      -3.265625,
      -0.9375,
      -0.2158203125,
      -1.6875,
      1.59375,
      4,
      0.85546875,
      -1.90625,
      0.3203125,
      -0.9765625,
      3.625,
      1.78125,
      -1.09375,
      0.5390625,
      0.9609375,
      0.369140625,
      -3.625,
      3.46875,
      0.34765625,
      -3.84375,
      1.859375,
      2.15625,
      -5.78125,
      -0.5,
      2.953125,
      3.328125,
      -2.75,
      0.67578125,
      -0.3046875,
      8.3125,
      0.298828125,
      -1.3125,
      -2.859375,
      -2.109375,
      1.2265625,
      0.703125,
      1.2265625,
      -0.482421875,
      1.78125,
      -6.3125,
      -1.96875,
      -0.029296875,
      2.4375,
      6.1875,
      -4.0625,
      1.8828125,
      3.984375,
      -1.828125,
      5.46875,
      -0.5546875,
      -3.578125,
      -2.40625,
      -1.1796875,
      -6.625,
      -0.91796875,
      -5.78125,
      1.5859375,
      -4.15625,
      -2.171875,
      -2.78125,
      1.4453125,
      2.296875,
      1.6796875,
      -2.5,
      -2.546875,
      -3.9375,
      -5.15625,
      -2.375,
      -1.375,
      -6.34375,
      2.84375,
      -0.279296875,
      1.8359375,
      4.375,
      3.640625,
      1.640625,
      -1.296875,
      2.265625,
      -1.8671875,
      0.8828125,
      -0.59375,
      -0.51171875,
      -2.109375,
      -2.28125,
      -0.341796875,
      -1.9765625,
      2.1875,
      -5.625,
      -3,
      -3.4375,
      -0.70703125,
      0.455078125,
      -0.43359375,
      0.443359375,
      -0.78125,
      5.4375,
      -0.3515625,
      1.6953125,
      3.90625,
      -1.5234375,
      0.40625,
      1.4453125,
      1.171875,
      8.4375,
      -1.34375,
      1.203125,
      -4.53125,
      4.90625,
      2.859375,
      -3.5625,
      2.203125,
      -0.65234375,
      -2.453125,
      -3.8125,
      1.3359375,
      2.296875,
      3.46875,
      -3.703125,
      3.5,
      4.78125,
      -1.1875,
      4.9375,
      4.875,
      2.734375,
      1.21875,
      4.6875,
      0.9921875,
      -0.12255859375,
      -1.671875,
      4.125,
      -1.6171875,
      -2.59375,
      1.734375,
      0.625,
      2.703125,
      2.21875,
      0.1923828125,
      2.421875,
      6.59375,
      -7.125,
      1.5703125,
      -6.125,
      0.8828125,
      -4.90625,
      -0.984375,
      -3.953125,
      -3.21875,
      1.703125,
      4.53125,
      -1.9296875,
      -4.625,
      1.3828125,
      3.375,
      -0.2109375,
      -4.5,
      4.34375,
      3.953125,
      1.3984375,
      -3.046875,
      -2.59375,
      3.46875,
      1.984375,
      -1.1796875,
      -5.21875,
      4.09375,
      -0.1015625,
      -4.5625,
      -2.90625,
      0.205078125,
      -1.4140625,
      -3.671875,
      -6.0625,
      -3.859375,
      3,
      -4.4375,
      3.8125,
      5.0625,
      -0.205078125,
      3.28125,
      0.89453125,
      1.53125,
      1.546875,
      -2.078125,
      2.875,
      1.15625,
      1.453125,
      -1.4296875,
      1.7109375,
      -1.296875,
      1.859375,
      -0.2294921875,
      1.8125,
      3,
      -1.5625,
      0.921875,
      -3.859375,
      3.265625,
      3.0625,
      1.1796875,
      -3.65625,
      -2.40625,
      3.703125,
      1.90625,
      -2.9375,
      -0.94140625,
      0.27734375,
      -0.50390625,
      -1.5703125,
      1.4609375,
      -1.046875,
      4.03125,
      0.1376953125,
      1.328125,
      -0.263671875,
      -0.94140625,
      -3.65625,
      -1.0390625,
      -2.015625,
      -0.95703125,
      -1.515625,
      5.53125,
      -1.7265625,
      -2.671875,
      -2.875,
      3.453125,
      -2.203125,
      2.1875,
      2.84375,
      -1.0703125,
      2.453125,
      0.796875,
      -0.5,
      -5.09375,
      0.216796875,
      3.703125,
      0.40625,
      1.078125,
      -0.83203125,
      -2.015625,
      2.015625,
      -3.28125,
      -4.03125,
      1.1796875,
      -1.0546875,
      -2.109375,
      -9.625,
      1.6484375,
      2.078125,
      -0.392578125,
      -1.890625,
      -1.7109375,
      1.8515625,
      4,
      4.34375,
      4.15625,
      -0.54296875,
      -0.61328125,
      1.109375,
      16.25,
      -1.6875,
      -8.0625,
      -0.64453125,
      0.6171875,
      2.5,
      9.3125,
      0.5078125,
      0.322265625,
      1.2734375,
      2.4375,
      1.765625,
      -3.578125,
      3.46875,
      -0.546875,
      0.26171875,
      3.234375,
      1.0546875,
      0.7421875,
      -3.265625,
      1.109375,
      1.765625,
      2.078125,
      1.5859375,
      -2.359375,
      1.203125,
      -1.265625,
      -0.9609375,
      -3.125,
      -3.5625,
      2.15625,
      -1.640625,
      -0.1572265625,
      -2.078125,
      0.248046875,
      -1.71875,
      2.953125,
      0.90234375,
      0.0206298828125,
      -1.2421875,
      -3.34375,
      -4.5,
      4.21875,
      -0.1005859375,
      -1.5390625,
      -2.5,
      -0.0126953125,
      -1.1171875,
      1.2265625,
      0.57421875,
      0.35546875,
      1.7734375,
      -1.890625,
      0.859375,
      -0.365234375,
      -1.4296875,
      -2.1875,
      -6.875,
      -2.171875,
      -3.28125,
      0.490234375,
      0.2177734375,
      -2.4375,
      -1.265625,
      -2.53125,
      -1.8203125,
      -2.859375,
      -0.94140625,
      -2.390625,
      0.71875,
      -5.0625,
      -0.90625,
      6.34375,
      2.265625,
      -1.8984375,
      -4.375,
      0.1357421875,
      4.1875,
      1.171875,
      3.40625,
      -4.03125,
      0.0654296875,
      -4.84375,
      0.02392578125,
      -2.515625,
      0.53125,
      -3.4375,
      3.125,
      -0.388671875,
      -1.4140625,
      4.5625,
      -4.46875,
      3.53125,
      1.734375,
      -3.703125,
      -0.64453125,
      3.75,
      1.3828125,
      -0.890625,
      -1.546875,
      4.09375,
      -1.5859375,
      -0.255859375,
      1.09375,
      0.039306640625,
      -1.5234375,
      3.0625,
      -3.265625,
      2.421875,
      -0.8203125,
      -2.421875,
      5.3125,
      3.109375,
      0.48046875,
      -0.2041015625,
      3.421875,
      -0.7109375,
      -0.408203125,
      -0.0186767578125,
      -4.0625,
      4.375,
      -0.11669921875,
      -0.8671875,
      1.890625,
      -8.0625,
      -4.875,
      -1.984375,
      -6.03125,
      1.953125,
      -5.28125,
      -0.7265625,
      -1.375,
      -1.859375,
      -3.203125,
      1.9296875,
      -2.40625,
      0.7734375,
      5.28125,
      -0.7578125,
      0.578125,
      -3.296875,
      0.81640625,
      4.03125,
      -3.5,
      -1.140625,
      0.2421875,
      0.16015625,
      2.34375,
      3.015625,
      -0.5390625,
      -2.25,
      5.34375,
      -0.98046875,
      -2.984375,
      0.494140625,
      3.171875,
      -0.185546875,
      -0.072265625,
      -3.4375,
      2.125,
      -1.265625,
      -0.2041015625,
      -0.94140625,
      -3.0625,
      -1.984375,
      0.92578125,
      2.234375,
      -2.5,
      -6.90625,
      4.53125,
      5.375,
      -7.15625,
      -0.1748046875,
      -4.03125,
      4.84375,
      -2.625,
      3.421875,
      5.6875,
      -0.00830078125,
      -0.0849609375,
      2.53125,
      1.140625,
      0.11181640625,
      -5.59375,
      2.859375,
      6.9375,
      -3.96875,
      2.5625,
      3.96875,
      0.57421875,
      0.74609375,
      -3.171875,
      -1.71875,
      6.4375,
      3.1875,
      -3.734375,
      -1.1640625,
      -2.859375,
      -0.62109375,
      -2.6875,
      -3.03125,
      -2.1875,
      -0.8359375,
      -0.248046875,
      3.4375,
      -0.8984375,
      -2.953125,
      -1.3828125,
      -2.65625,
      -1.9296875,
      -1.1328125,
      5,
      0.59375,
      2.375,
      -5.65625,
      6.15625,
      2.6875,
      0.84765625,
      1.4921875,
      5.4375,
      -0.8046875,
      3.421875,
      -5.21875,
      -1.625,
      -1.6953125,
      1.9921875,
      -4.625,
      2.34375,
      -4.09375,
      1.390625,
      -4.3125,
      3.6875,
      -0.193359375,
      1.9140625,
      -4.03125,
      -3.90625,
      -2.25,
      5.59375,
      -2.109375,
      1.0234375,
      4.09375,
      -1.453125,
      0.8203125,
      2.78125,
      -1.6640625,
      0.294921875,
      -2.53125,
      2.4375,
      0.90234375,
      -2.1875,
      2.15625,
      -0.84375,
      3.875,
      -1.0078125,
      1.375,
      -2.59375,
      -3.640625,
      -0.111328125,
      -4.875,
      0.359375,
      0.34375,
      -5.40625,
      1.390625,
      0.74609375,
      2.15625,
      0.5703125,
      3.5625,
      -7.6875,
      5.59375,
      0.8046875,
      -5.59375,
      1.890625,
      0.96484375,
      -2.65625,
      0.357421875,
      -2.484375,
      1.828125,
      -4.6875,
      0.29296875,
      5.25,
      -2.34375,
      0.26171875,
      0.9296875,
      -3.921875,
      0.29296875,
      -4.78125,
      3.640625,
      1.0703125,
      3.421875,
      2.125,
      1.578125,
      5.78125,
      -3.921875,
      3.375,
      -6.09375,
      0.8125,
      -2.34375,
      2.734375,
      0.828125,
      -2.875,
      4.25,
      5.625,
      -0.380859375,
      -9.125,
      -5.28125,
      -0.703125,
      -2.84375,
      2.34375,
      2.609375,
      1.6875,
      -1.328125,
      0.1474609375,
      1.3125,
      3.1875,
      -1.8671875,
      -1.890625,
      -1.28125,
      2.640625,
      -0.028076171875,
      -4.59375,
      -0.34765625,
      -0.02880859375,
      -0.181640625,
      -0.5703125,
      -2.21875,
      -2.890625,
      2.359375,
      3,
      -3.328125,
      2.78125,
      1.328125,
      2.8125,
      1.859375,
      0.1279296875,
      -0.384765625,
      3.671875,
      -3.140625,
      -6.78125,
      -0.38671875,
      -0.625,
      2.21875,
      4.46875,
      -1.765625,
      4.21875,
      0.051513671875,
      4.28125,
      -5.03125,
      3.53125,
      3.296875,
      -10.375,
      2.296875,
      -2.859375,
      1.046875,
      -0.314453125,
      -5.53125,
      -1.796875,
      3.78125,
      -0.404296875,
      -1.796875,
      5.71875,
      -2.25,
      0.1875,
      -0.234375,
      -2.765625,
      -3.421875,
      3.09375,
      2.1875,
      -2.25,
      3.5,
      5.25,
      -1.9375,
      -2.0625,
      -1.5234375,
      5.4375,
      -1.8984375,
      -3.03125,
      3.484375,
      3.640625,
      1.171875,
      -1.4609375,
      -4.375,
      -0.2451171875,
      -1.6484375,
      -2.953125,
      -1,
      -2.359375,
      2.25,
      -2.09375,
      -0.06787109375,
      -1.859375,
      -2.625,
      0.52734375,
      -2.53125,
      -3.296875,
      1.8046875,
      2.703125,
      0.07861328125,
      -2.0625,
      -0.7109375,
      1.8125,
      0.1533203125,
      -3.53125,
      -3.9375,
      0.94140625,
      -2.625,
      -3.65625,
      -1.7578125,
      0.384765625,
      -2.265625,
      0.412109375,
      -0.578125,
      -0.302734375,
      -0.333984375,
      -0.79296875,
      -0.71875,
      1.5234375,
      2.828125,
      0.279296875,
      0.2734375,
      -0.0233154296875,
      3.234375,
      2.65625,
      -5.6875,
      -2.828125,
      1.28125,
      -0.057373046875,
      -4.28125,
      -3.734375,
      0.259765625,
      -2.25,
      3.171875,
      5.09375,
      2.5625,
      -1.046875,
      2.984375,
      -3.796875,
      -1.2890625,
      4.9375,
      4.375,
      -0.546875,
      -1.4609375,
      1.796875,
      -4.71875,
      5.75,
      6.5625,
      -3.390625,
      -3.765625,
      0.6875,
      -2.875,
      -1.296875,
      -1.8125,
      3.359375,
      0.26171875,
      -7.15625,
      3.8125,
      -0.93359375,
      5.53125,
      0.96875,
      -2.515625,
      2.453125,
      -0.46875,
      1.859375,
      -1.0234375,
      2.125,
      0.67578125,
      -4.46875,
      0.26171875,
      -2.265625,
      -2.875,
      -3.390625,
      -0.33984375,
      0.296875,
      2.625,
      5.15625,
      1.140625,
      -0.93359375,
      -1.3203125,
      -1.5859375,
      3.28125,
      -1.6875,
      -2.9375,
      -0.34765625,
      -2.9375,
      0.95703125,
      0.703125,
      -0.9296875,
      -6.375,
      -1.2734375,
      -4.65625,
      4.90625,
      -1.515625,
      0.1494140625,
      -2.453125,
      -1.5078125,
      2.9375,
      4.5,
      3.59375,
      3.578125,
      2.46875,
      2.671875,
      0.2265625,
      -2.828125,
      4.6875,
      3.625,
      2.234375,
      -0.91015625,
      0.859375,
      0.5625,
      -2.375,
      -4.1875,
      -0.130859375,
      0.146484375,
      5.53125,
      4.21875,
      -1.03125,
      1.3984375,
      -2.15625,
      -1.140625,
      -2.109375,
      0.84765625,
      0.9609375,
      1.328125,
      -1.8359375,
      0.80078125,
      2.59375,
      1.078125,
      0.412109375,
      3.296875,
      1.3515625,
      -0.193359375,
      -2.515625,
      -0.671875,
      3.234375,
      -2.75,
      -0.404296875,
      -2.046875,
      0.271484375,
      -1.203125,
      -3.59375,
      3.328125,
      -0.181640625,
      -0.9375,
      4.1875,
      -0.353515625,
      1.8515625,
      0.32421875,
      2.890625,
      -2.921875,
      1.390625,
      0.47265625,
      2.8125,
      -1.5390625,
      1.1796875,
      1.2265625,
      1.546875,
      -1.7109375,
      1.609375,
      1.703125,
      -2.4375,
      -0.265625,
      1.2265625,
      -2.390625,
      -1.015625,
      3.078125,
      -1.7421875,
      0.51953125,
      0.80078125,
      -0.55078125,
      -1.1171875,
      4.65625,
      -3.671875,
      -3.140625,
      -0.71875,
      1.109375,
      0.1416015625,
      -0.51171875,
      -0.0712890625,
      -0.83984375,
      0.8828125,
      -0.3359375,
      -2.671875,
      -0.6640625,
      -0.77734375,
      -1.4921875,
      1.3828125,
      -0.890625,
      0.3125,
      -4.5625,
      3.359375,
      -0.2890625,
      -0.8203125,
      -0.41015625,
      -0.65625,
      -0.30078125,
      -3.140625,
      1.125,
      -1.484375,
      1.6796875,
      1.421875,
      0.765625,
      2.78125,
      -0.87109375,
      0.3984375,
      -0.51171875,
      -0.01446533203125,
      4,
      -0.1845703125,
      -2.296875,
      -0.87890625,
      1.8359375,
      1.109375,
      1.3125,
      0.5390625,
      2.8125,
      0.5546875,
      1.46875,
      1.9765625,
      -0.57421875,
      3.25,
      0.96484375,
      3.1875,
      -2.875,
      -1,
      -3.125,
      -1.921875,
      1.3671875,
      -1.875,
      -3.84375,
      -0.3984375,
      -0.14453125,
      0.98046875,
      2.734375,
      5.1875,
      -2.25,
      1.6328125,
      -0.76953125,
      1.53125,
      -1.2265625,
      1.203125,
      1.953125,
      0.00970458984375,
      -3.703125,
      -3.0625,
      2.046875,
      -1.984375,
      1.4296875,
      0.267578125,
      -1.421875,
      0.63671875,
      -2.140625,
      -1.9921875,
      -0.22265625,
      -0.875,
      0.37890625,
      0.97265625,
      1.4140625,
      1.546875,
      1.140625,
      -3.046875,
      3.828125,
      -3.390625,
      2.96875,
      -0.259765625,
      0.419921875,
      -2.109375,
      2.65625,
      -1.265625,
      -3,
      1.921875,
      -3.375,
      -2.28125,
      -3.28125,
      -1.2109375,
      2.5625,
      -1.3203125,
      0.6484375,
      -1.53125,
      -0.3515625,
      2.4375,
      2.5625,
      2.5625,
      2.90625,
      1.546875,
      3.125,
      2.109375,
      -2.890625,
      0.2490234375,
      -2.953125,
      -0.93359375,
      -0.578125,
      1.9765625,
      1.84375,
      -4.3125,
      0.5234375,
      -1.1015625,
      2.53125,
      3.53125,
      -1.0234375,
      2.453125,
      2,
      -1.625,
      3.84375,
      5.125,
      0.97265625,
      0.8984375,
      0.13671875,
      -1.6953125,
      -0.2451171875,
      -1.875,
      -1.09375,
      -0.10791015625,
      2.28125,
      0.050048828125,
      0.55859375,
      -2.046875,
      2.328125,
      1.3984375,
      0.048583984375,
      2.3125,
      -2.609375,
      -1.2578125,
      0.07177734375,
      2.484375,
      1.125,
      1.4921875,
      1.4453125,
      0.65625,
      -4.90625,
      -1.1796875,
      -0.0693359375,
      -1.125,
      -0.75,
      -2.109375,
      0.765625,
      -1.4140625,
      -4.125,
      0.55859375,
      -0.734375,
      0.2060546875,
      1.0703125,
      2.859375,
      -0.5234375,
      1.984375,
      -0.02294921875,
      1.40625,
      -0.49609375,
      -0.94140625,
      1.8515625,
      1.9921875,
      1.046875,
      0.455078125,
      -3.6875,
      -2.40625,
      -1.953125,
      -1.9609375,
      -0.9765625,
      2.65625,
      0.361328125,
      -1.0078125,
      0.82421875,
      -1.5,
      -1.3828125,
      2.578125,
      3.203125,
      -0.5703125,
      1.1796875,
      -1.1328125,
      2.40625,
      -3.40625,
      1.28125,
      -0.302734375,
      -1.03125,
      0.16796875,
      -0.486328125,
      -0.578125,
      -1.6796875,
      0.4453125,
      -0.86328125,
      0.10986328125,
      -2.3125,
      -2.046875,
      1.140625,
      2.71875,
      -0.302734375,
      1.8359375,
      2.109375,
      5.46875,
      -0.73046875,
      1.0625,
      1.7265625,
      3.59375,
      5.625,
      1.6015625,
      -5.09375,
      -2.953125,
      0.8125,
      2.453125,
      2.34375,
      -0.486328125,
      1.796875,
      4.625,
      -0.6875,
      0.4453125,
      -4.6875,
      0.02490234375,
      3.15625,
      1.3203125,
      4.6875,
      -1.5390625,
      -0.7109375,
      -1.9453125,
      -1.9609375,
      2.453125,
      2.46875,
      2.9375,
      2.421875,
      2.546875,
      -0.01397705078125,
      1.6484375,
      0.298828125,
      2.796875,
      -1.203125,
      0.765625,
      2.34375,
      -1.5546875,
      -1.7578125,
      1.9921875,
      -3.296875,
      1.75,
      -1.1484375,
      2.296875,
      3.171875,
      -0.9921875,
      -1.3046875,
      0.021484375,
      -0.9140625,
      4.3125,
      -1.1171875,
      -0.171875,
      -2.4375,
      1.125,
      0.037109375,
      -1.3828125,
      0.86328125,
      -3.8125,
      1.8671875,
      0.333984375,
      -1.125,
      -1.1015625,
      -2.59375,
      -2.703125,
      -1.328125,
      -1.7421875,
      -0.99609375,
      -2.265625,
      5,
      -2.765625,
      -1.6171875,
      0.73828125,
      4.59375,
      0.1201171875,
      6.5625,
      -0.384765625,
      2.828125,
      -1.3515625,
      -1.1953125,
      -0.80859375,
      -4.3125,
      -2.921875,
      -0.11181640625,
      0.3984375,
      -0.2197265625,
      -0.55078125,
      -1.453125,
      -1.171875,
      3.609375,
      -0.515625,
      -3.703125,
      -2.0625,
      2.671875,
      -0.9765625,
      0.70703125,
      -3.59375,
      0.2490234375,
      -0.7578125,
      -1.5390625,
      1.234375,
      -0.396484375,
      0.8984375,
      0.70703125,
      -0.032470703125,
      -2.734375,
      -0.8984375,
      0.55078125,
      -3.4375,
      -0.40625,
      4.9375,
      -1.5859375,
      0.08642578125,
      -0.4609375,
      4.15625,
      0.1123046875,
      2.203125,
      -2.515625,
      -1.2734375,
      2.546875,
      4.1875,
      3.171875,
      1.609375,
      0.087890625,
      3.46875,
      -3.828125,
      -1.203125,
      -0.427734375,
      -4.34375,
      -0.318359375,
      3.203125,
      -4.09375,
      0.0517578125,
      -1.6328125,
      0.28125,
      -0.6015625,
      -2.625,
      2.78125,
      -2.875,
      -0.50390625,
      3.65625,
      -1.9453125,
      -0.921875,
      -3.234375,
      1.7421875,
      -4.25,
      0.361328125,
      -2.734375,
      -2.4375,
      0.52734375,
      1.65625,
      -0.3203125,
      3,
      0.3984375,
      0.314453125,
      5.21875,
      2.3125,
      3.09375,
      1.2421875,
      -0.625,
      1.2421875,
      -1.5078125,
      3.34375,
      -0.2314453125,
      -2.671875,
      0.84375,
      -2.84375,
      -1.515625,
      -0.546875,
      3.453125,
      0.4765625,
      -0.046630859375,
      -0.8515625,
      1.5703125,
      1.90625,
      -0.76171875,
      3.734375,
      -0.9765625,
      0.5546875,
      -3.875,
      0.28515625,
      -0.87890625,
      3.359375,
      3.3125,
      2.046875,
      -0.7578125,
      -2.03125,
      2.453125,
      -1.7578125,
      2.015625,
      0.4921875,
      -4.75,
      -2.203125,
      -1.375,
      -1.1484375,
      -0.54296875,
      -1.8515625,
      -0.11181640625,
      -0.478515625,
      -0.2431640625,
      2.65625,
      -0.330078125,
      -2.234375,
      -0.9375,
      0.83203125,
      2.125,
      -0.08154296875,
      1.1484375,
      -1.3359375,
      3.34375,
      0.39453125,
      -0.71484375,
      2,
      2.203125,
      -1.0390625,
      -2.390625,
      -0.08154296875,
      -3.734375,
      -1.484375,
      2.59375,
      1.6875,
      1.90625,
      -0.703125,
      0.10302734375,
      3.6875,
      0.77734375
    ],
    "suggested_tags": [
      "教育AI",
      "对话系统",
      "问答系统",
      "LLM应用",
      "模块化设计"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.95,
        "reason": "论文聚焦于开发虚拟教学助手，应用于在线教育场景，解决学生问答和教学支持问题"
      },
      {
        "name": "对话系统",
        "confidence": 0.9,
        "reason": "基于ChatGPT构建的对话式AI代理，具备多轮对话和上下文理解能力"
      },
      {
        "name": "问答系统",
        "confidence": 0.85,
        "reason": "核心功能是基于课程材料的问答任务，支持文档检索和知识验证"
      },
      {
        "name": "LLM应用",
        "confidence": 0.8,
        "reason": "利用ChatGPT等大语言模型实现零样本学习，无需训练即可处理多文档问答"
      },
      {
        "name": "模块化设计",
        "confidence": 0.75,
        "reason": "采用基于技能的架构设计，支持API集成和功能扩展，提升系统灵活性"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283217596",
          "title": "Intelligent teaching design assistant for primary mathematics: A large language model-driven framework with retrieval-augmented generation and problem-chain pedagogy",
          "authors": [
            "Danna Tang",
            "Ran Ding",
            "Meng He",
            "Yushen Wang",
            "Kaka Cheng"
          ],
          "year": 2026,
          "venue": "International Electronic Journal of Mathematics Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283624085",
          "title": "From knowledge gaps to learning opportunities: Leveraging student questions and dual use of generative AI to support student learning at scale",
          "authors": [
            "Stanislav Pozdniakov",
            "Jonathan Brazil",
            "Oleksandra Poquet",
            "Stephan Krusche",
            "Santiago Berrezueta-Guzman",
            "Shazia Sadiq",
            "Hassan Khosravi"
          ],
          "year": 2025,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283213277",
          "title": "How college students use ChatGPT",
          "authors": [
            "N. M. Mohammad",
            "Matthew Demers",
            "Erin McCubbin",
            "Jackson Mitchell",
            "Sara M. Fulmer"
          ],
          "year": 2025,
          "venue": "Pedagogical Research",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281421061",
          "title": "Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments",
          "authors": [
            "Li Siyan",
            "Zhen Xu",
            "Vethavikashini Chithrra Raghuram",
            "Xuanming Zhang",
            "Renzhe Yu",
            "Zhou Yu"
          ],
          "year": 2025,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281332933",
          "title": "Perspectives and potential issues in using artificial intelligence for computer science education",
          "authors": [
            "Juho Vepsäläinen",
            "Petri Juntunen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280420389",
          "title": "From Misunderstandings to Learning Opportunities: Leveraging Generative AI in Discussion Forums to Support Student Learning",
          "authors": [
            "Stanislav Pozdniakov",
            "Jonathan Brazil",
            "Oleksandra Poquet",
            "Stephan Krusche",
            "Santiago Berrezueta-Guzman",
            "Shazia Sadiq",
            "Hassan Khosravi"
          ],
          "year": 2025,
          "venue": "International Conference on Artificial Intelligence in Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280635533",
          "title": "Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment",
          "authors": [
            "Farzana Zahid",
            "Anjalika Sewwandi",
            "Lee Brandon",
            "Vimal Kumar",
            "Roopak Sinha"
          ],
          "year": 2025,
          "venue": "High-Confidence Computing",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282394325",
          "title": "The Effects of Chatbot Placement, Personification, and Functionality on Student Outcomes in a Global CS1 Course",
          "authors": [
            "Sierra Wang",
            "Thomas Jefferson",
            "Chris Piech",
            "John C. Mitchell"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282396045",
          "title": "Scaling Effective AI-Generated Explanations for Middle School Mathematics in Online Learning Platforms",
          "authors": [
            "Eamon Worden",
            "Kirk P. Vanacore",
            "Aaron Haim",
            "Neil T. Heffernan"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280294670",
          "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education",
          "authors": [
            "Jaroslaw A. Chudziak",
            "Adam Kostka"
          ],
          "year": 2025,
          "venue": "International Conference on Artificial Intelligence in Education",
          "citation_count": 4
        }
      ],
      "citations_fetched_at": "2025-12-16T18:44:55.853630",
      "references": [
        {
          "external_id": "CorpusId:265456807",
          "title": "Comprehensive Assessment of Toxicity in ChatGPT",
          "authors": [
            "Boyang Zhang",
            "Xinyue Shen",
            "Waiman Si",
            "Zeyang Sha",
            "Zeyuan Chen",
            "Ahmed Salem",
            "Yun Shen",
            "Michael Backes",
            "Yang Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:258841157",
          "title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia",
          "authors": [
            "Sina J. Semnani",
            "Violet Z. Yao",
            "He Zhang",
            "M. Lam"
          ],
          "year": 2023,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 101
        },
        {
          "external_id": "CorpusId:257219404",
          "title": "LLaMA: Open and Efficient Foundation Language Models",
          "authors": [
            "Hugo Touvron",
            "Thibaut Lavril",
            "Gautier Izacard",
            "Xavier Martinet",
            "M. Lachaux",
            "Timothée Lacroix",
            "Baptiste Rozière",
            "Naman Goyal",
            "Eric Hambro",
            "Faisal Azhar",
            "Aur'elien Rodriguez",
            "Armand Joulin",
            "Edouard Grave",
            "Guillaume Lample"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 17220
        },
        {
          "external_id": "CorpusId:251371664",
          "title": "A Holistic Approach to Undesired Content Detection in the Real World",
          "authors": [
            "Todor Markov",
            "Chong Zhang",
            "Sandhini Agarwal",
            "Tyna Eloundou",
            "Teddy Lee",
            "Steven Adler",
            "Angela Jiang",
            "L. Weng"
          ],
          "year": 2022,
          "venue": "AAAI Conference on Artificial Intelligence",
          "citation_count": 323
        },
        {
          "external_id": "CorpusId:250391085",
          "title": "Re2G: Retrieve, Rerank, Generate",
          "authors": [
            "Michael R. Glass",
            "Gaetano Rossiello",
            "Md. Faisal Mahbub Chowdhury",
            "Ankita Rajaram Naik",
            "Pengshan Cai",
            "A. Gliozzo"
          ],
          "year": 2022,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 130
        },
        {
          "external_id": "CorpusId:246426909",
          "title": "Training language models to follow instructions with human feedback",
          "authors": [
            "Long Ouyang",
            "Jeff Wu",
            "Xu Jiang",
            "Diogo Almeida",
            "Carroll L. Wainwright",
            "Pamela Mishkin",
            "Chong Zhang",
            "Sandhini Agarwal",
            "Katarina Slama",
            "Alex Ray",
            "John Schulman",
            "Jacob Hilton",
            "Fraser Kelton",
            "Luke E. Miller",
            "Maddie Simens",
            "Amanda Askell",
            "Peter Welinder",
            "P. Christiano",
            "Jan Leike",
            "Ryan J. Lowe"
          ],
          "year": 2022,
          "venue": "Neural Information Processing Systems",
          "citation_count": 16892
        },
        {
          "external_id": "CorpusId:247058801",
          "title": "A New Generation of Perspective API: Efficient Multilingual Character-level Transformers",
          "authors": [
            "Alyssa Lees",
            "Vinh Q. Tran",
            "Yi Tay",
            "Jeffrey Scott Sorensen",
            "Jai Gupta",
            "Donald Metzler",
            "Lucy Vasserman"
          ],
          "year": 2022,
          "venue": "Knowledge Discovery and Data Mining",
          "citation_count": 247
        },
        {
          "external_id": "CorpusId:246652372",
          "title": "Survey of Hallucination in Natural Language Generation",
          "authors": [
            "Ziwei Ji",
            "Nayeon Lee",
            "Rita Frieske",
            "Tiezheng Yu",
            "D. Su",
            "Yan Xu",
            "Etsuko Ishii",
            "Yejin Bang",
            "Delong Chen",
            "Wenliang Dai",
            "Andrea Madotto",
            "Pascale Fung"
          ],
          "year": 2022,
          "venue": "ACM Computing Surveys",
          "citation_count": 3304
        },
        {
          "external_id": "CorpusId:246472929",
          "title": "A Survey on Retrieval-Augmented Text Generation",
          "authors": [
            "Huayang Li",
            "Yixuan Su",
            "Deng Cai",
            "Yan Wang",
            "Lemao Liu"
          ],
          "year": 2022,
          "venue": "arXiv.org",
          "citation_count": 255
        },
        {
          "external_id": "CorpusId:245334864",
          "title": "The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus",
          "authors": [
            "Aleksandra Piktus",
            "F. Petroni",
            "Yizhong Wang",
            "Vladimir Karpukhin",
            "Dmytro Okhonko",
            "Samuel Broscheit",
            "Gautier Izacard",
            "Patrick Lewis",
            "Barlas Ouguz",
            "Edouard Grave",
            "Wen-tau Yih",
            "Sebastian Riedel"
          ],
          "year": 2021,
          "venue": "arXiv.org",
          "citation_count": 75
        }
      ],
      "references_fetched_at": "2025-12-16T18:44:56.671666"
    }
  },
  "2c6ea33c-9a9e-4547-949a-69351fc70f65": {
    "id": "2c6ea33c-9a9e-4547-949a-69351fc70f65",
    "filename": "2405.13001v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/2c6ea33c-9a9e-4547-949a-69351fc70f65_2405.13001v1.pdf",
    "status": "completed",
    "created_at": "2025-12-16 19:02:16.206608",
    "updated_at": "2025-12-16 11:03:36.112706",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Large Language Models for Education: A Survey",
    "markdown_content": "# Large Language Models for Education: A Survey\n\nHanyi  $\\mathbf{X}\\mathbf{u}^{a}$ , Wensheng  $\\mathrm{Gan}^{a,*}$ , Zhenlian  $\\mathbf{Q}\\mathbf{i}^{b,*}$ , Jiayang  $\\mathbf{W}\\mathbf{u}^{a}$  and Philip S.  $\\mathbf{Y}\\mathbf{u}^{c}$\n\n$^{a}$ College of Cyber Security, Jinan University, Guangzhou 510632, China  \n$^{b}$ School of Information Engineering, Guangdong Eco-Engineering Polytechnic, Guangzhou 510520, China  \n$^{c}$ Department of Computer Science, University of Illinois Chicago, Chicago, USA\n\n# ARTICLE INFO\n\nKeywords:  \nartificial intelligence  \nsmart education  \nLLMs  \napplications  \nchallenges\n\n# ABSTRACT\n\nArtificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models (LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre-training, fine-tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.\n\n# 1. Introduction\n\nArtificial intelligence (AI) has developed rapidly in recent years [73, 111, 139], thanks to the continuous improvements in Web 3.0 [38], Internet of Behaviors (IoB) [103], data mining [35, 48, 68], deep learning [122], and language processing technologies [47]. LLMs have shown excellent performance in various industries with the optimization of pre-training models and the continuous adjustment of related technologies [25, 132]. LLM is mainly based on many AI technologies, e.g., natural language processing (NLP), and was used to understand and generate massive texts [41]. They perform self-supervised learning on a large-scale corpus to obtain the statistical laws of language [31] and then convert it into logical natural language text. Its basic framework is shown in Figure 1. LLMs have demonstrated strong versatility and logical reasoning capabilities, leading to their widespread model-as-a-service (MaaS) [37] in various industries, including finance, education [36], law [58], robotics [131], and government affairs [20, 32, 126]. Creating a scenario-based user experience is a key advantage for most digital companies, and it also happens to be a development need for LLM.\n\nThe concept of education has been around for centuries, dating back to the theory of biological origins. In primitive societies, education was limited to the use of primary production tools, whereas ancient societies relied on oral transmission and practice to pass knowledge down to future generations [66]. With the development of science and technology in modern society, education and AI\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/7086b8cda485234568fab5cdb627979b998a6dc1e1e87faeae4fe69f5d2412ae.jpg)  \nFigure 1: Framework of LLMs.\n\nhave become inseparable [22], including intelligent teacher assistants, voice assistants [77, 92], AI writing creation platforms, etc. The fourth industrial revolution, represented by the intelligent revolution [15], can bring the education industry to a new level with the help of LLMs. Education is essentially about knowledge transfer, instant feedback, and emotional interaction. LLMs mainly enhance the \"immediate feedback\" process in education. They have the potential to revolutionize the education industry by providing personalized, adaptive learning experiences for students. By infusing knowledge into their models, LLMs can gradually build a deep understanding of the world, surpassing human learning in some aspects. They can generate high-quality text content, comprehend natural language, extract information, and answer questions across various fields [71]. LLMs can also do complex mathematical reasoning [123], which helps the education sector show that they are good at self-supervision, intelligent adaptive teaching, and multi-modal interaction [26]. With their ability to adapt the individual students' needs and learning styles, LLMs can provide a more effective and engaging learning experience.\n\nResearch gaps: There are already many educators and researchers who have shown a lot of thinking about AI in education. Examples are as follows: Some research has been conducted on the paradigm shift in AI in education [85] and on the impact of AI in management, teaching, and learning [21]. Some studies explain AI in education and show how they work [72]. Due to the rapid iteration and update of AI, many new educational AI technologies have been spawned, but there is a lack of summary and analysis of emerging technological means. LLMs, as one of these technologies, have significantly advanced AI development to a new stage. LLMs are the latest technological means to support intelligent education. The integration of education and LLMs particularly highlights the development and application characteristics of LLMs. There has been one brief review of LLMs for education [36], while many characteristics of LMEdu and key technologies are not discussed in detail.\n\nContributions: To examine the potential of LLMEdu and promote its development, this paper provides an in-depth analysis of the development process and technical structure of LLMEdu and forms a comprehensive summary. This review aims to help readers gain a deeper understanding of LLMEdu and encourages us to invent and consider LLMEdu applications. The specific contributions are as follows:\n\n- We take a closer look at the connection between LLMs and education, aiming to achieve smart education.  \n- We demonstrate the development process of LLMEdu through the process of applying LLMs to education and the key technologies of LLMs.  \n- We review the implementation of LLMEdu from the perspective of LLMs empowering education, focusing on exploring the development potential of LLMEdu.  \n- We highlight the problems and challenges existing in LLMEdu in detail, aiming to trigger some insight, critical thinking, and exploration.\n\nRoadmap: In Section 2, we briefly introduce the characteristics of LLMs and the education industry, as well as the characteristics of LLMs integrated into education. In Section 3, we conduct an in-depth analysis of the process of applying LLMs to education. In Section 4, we explain the key technologies related to LLMs. In Section 5, we provide the implementation of LLMEdu from the perspective of empowering education with LLMs. In Section 6, we highlight some of the main issues and challenges in LLMEdu. Finally, in Section 7, we summarize LLMEdu and propose expectations for the development of future LLMs. Table 1 describes some basic symbols in this article.\n\n# 2. Characteristics of LLM in Education\n\nIn this section, we discuss the key characteristics of LLMs, the key characteristics of education, the limitations of traditional education, and the combinations between LLMs and education, as depicted in Figure 2.\n\nTable 1 Summary of symbols and their explanations  \n\n<table><tr><td>Symbol</td><td>Definition</td></tr><tr><td>AI</td><td>Artificial Intelligence</td></tr><tr><td>AIGC</td><td>AI-Generated Content</td></tr><tr><td>ChatGPT</td><td>Chat Generative Pre-Training Transformer</td></tr><tr><td>CV</td><td>Computer Vision</td></tr><tr><td>DNNs</td><td>Deep Neural Networks</td></tr><tr><td>GPT</td><td>Generative Pre-trained Transformer</td></tr><tr><td>HFRL</td><td>Human Feedback Reinforcement Learning</td></tr><tr><td>LLMEdu</td><td>Large Language Models for Education</td></tr><tr><td>LLMs</td><td>Large Language Models</td></tr><tr><td>LMs</td><td>Language Models</td></tr><tr><td>NLP</td><td>Natural Language Processing</td></tr></table>\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/4ceb13c181dc3c041d9dfd2c369372900381d64a94c5af271691b37f38f65114.jpg)  \nFigure 2: The characteristics of LLMEdu.\n\n# 2.1. Characteristics of LLMs\n\nLarge-scale. The term \"large\" in LLMs can be interpreted in two ways. Firstly, LLMs possess an enormous number of parameters, with the parameter count increasing exponentially from billions to trillions in just a few years. For instance, Google's BERT had 300 million parameters in 2018, GPT-2 had 1.5 billion parameters in 2019, and GPT-3 had 175 billion parameters in 2021 [137, 101]. In 2022, the Switch Transformer reached an impressive 1.6 trillion parameters [67, 100]. Furthermore, LLMs are trained on vast amounts of data from diverse sources, including the web, academic literature, and conversations. This large-scale corpus of data enables the models to learn and represent complex patterns and relationships in language, leading to improved performance in various NLP tasks [107].\n\nGeneral-purpose. LLMs have a wide range of applications [88]. In addition to excelling in specific domains, they are adept at handling various types of tasks, including NLP, CV, speech recognition, and even cross-modal tasks. In other words, LLMs possess powerful generalization capabilities, and achieving such capabilities requires training on massive amounts of data.\n\nPre-training and fine-tuning [27, 47, 132]. The core of the model training process lies in the use of pre-training followed by fine-tuning. Initially, pre-training is performed on a large-scale unlabeled text corpus to acquire the model's\n\nbasic language knowledge. Subsequently, fine-tuning is conducted on specific tasks in a particular domain to better understand and generate language specific to that domain, such as legal, educational, or medical texts.\n\nEmergent ability: unpredictability [88]. The emergent ability of LLMs refers to their capacity to generate coherent and logically consistent text without explicit human intervention, as they have learned from their training process. When the amount of data reaches a sufficiently large scale, the model's learning and feedback capabilities can experience a substantial increase, resulting in improved performance.\n\nFragmentation [93]. The current AI landscape is characterized by diverse business scenarios across various industries, resulting in fragmented and diversified AI demands. The development process of AI models involves several stages, including development, hyperparameter tuning, optimization, and iterative deployment for eventual application. Each stage requires significant investment, and in high-cost situations, catering to customized market demands can be challenging.\n\nPotential for breaking accuracy limitations. The development of deep learning has taken a long time. The improvement in accuracy through architectural changes appears to have reached a bottleneck as neural network design techniques have matured and converged. However, LLM development has shown that increasing the scale of both the model and the data can help break through accuracy limitations. Research experiments have consistently demonstrated that scaling up the model and data leads to improved model accuracy [104]. High complexity and investment costs. LLMs are becoming increasingly complex, with single-step computation time growing by more than 10 times [6]. For high-traffic businesses, a training experiment that used to take a few hours now takes several days, with the expectation that tests will remain within a one-day timeframe as a basic requirement [75]. Moreover, training a general-purpose large model is expensive, and if subsequent optimization, updates, and deployment are included, it will cost even more. For example, the core infrastructure of ChatGPT, the Azure AI, required an investment of nearly $1 billion [87]. Moreover, ChatGPT has high requirements for the number of GPU chips used for data processing [82].\n\n# 2.2. Characteristics of education\n\nAccording to its definition, education is a deliberate and conscious social practice that aims to nurture individuals. Its fundamental characteristic is its process-oriented nature, indicating that education exists and evolves through a series of steps. With a focus on individuals, education ultimately aims to facilitate their holistic and enduring growth. Education encompasses knowledge transmission, immediate feedback, and emotional interaction. Error correction, knowledge reinforcement, and rapid training consolidation are some parts of educational behavior. Furthermore, the education system is highly intricate, marked by the distinctiveness of its subjects, diverse requirements, and intricate interactions.\n\n# 2.2.1. Educational development process\n\nLow entry barriers. On one hand, the accessibility of starting an educational institution is relatively easy [17], resulting in lower operating and investment costs for both teachers and institutions. However, this has also led to a disparity in teacher qualifications, contributing to issues such as disorder in the education and training industry, misleading advertisements, exaggerated titles for teachers, and ineffective offline one-on-one teaching. These have subsequently led to an increase in complaints. On the other hand, there has been a reduction in barriers to education for learners, leading to greater equality of educational opportunities across different regions and a stronger emphasis on the right to education.\n\nLarge capacity [60]. The education industry encompasses a significant number of students and teachers, making it crucial to consider the implications of a large population. Moreover, there exists a diverse array of educational settings, including public schools as well as numerous private educational institutions. There is an abundance of educational materials available, and the advent of the internet has made access to educational resources easier. This development has transcended the confines of traditional textbook-based teaching, breaking down information barriers and expanding the horizons of education.\n\nWell-developed system. The expansion of education has been propelled by economic development [56], leading to a surge in investment in the education sector. This growth encompasses a wide range of educational institutions at different levels. Moreover, the education system encompasses diverse forms of education, such as social life education, family education, and school education. It also encompasses a variety of disciplines, including mathematics, languages, and physical education.\n\nRise of online education [55]. Since the late 1990s, emerging technologies have made significant inroads into the education industry [18]. This transformation has propelled education through various stages, including traditional education, digital education, internet-based education, mobile-based education, and intelligent education. The advancement of information technology has played a pivotal role in facilitating education development by overcoming time and space constraints, making knowledge acquisition more convenient and rapid.\n\nEducation at a younger age. The development of the internet has dismantled barriers to education, resulting in heightened parental concerns and an increased focus on early education. Under the influence of globalization, the significance of early education [128], particularly in language and logic development, has been recognized. In conjunction with the surge of online education, early childhood education has become more readily available. A wide range of tutoring classes and early learning programs have become commonplace.\n\nIntelligent, precise, and personalized education [23]. With the rapid advancement of AI, technology has significantly enhanced production methods and raised people's\n\nliving standards. As a result, society's demand for education has escalated, leading to a more targeted approach to talent development. Education is currently transforming the integration and innovation of \"AI + education\" in smart education.\n\nAlthough education has integrated AI to a significant extent, the nature of human education and machine education fundamentally differs in a two-tier manner. These two forms of education vary in their sequence: human education primarily focuses on shaping values, followed by systematic knowledge acquisition, and ultimately engaging in real-world experiences to foster learning. In contrast, machine education begins by processing vast amounts of data, subsequently discerning between right and wrong (learning values), incorporating human feedback, and ultimately attaining practicality. When it comes to learning, the most notable distinction between humans and machines lies in the limited energy humans possess to acquire knowledge within a fixed period, whereas machines have a relatively unlimited learning capacity. Embracing AI, formulating education strategies that align with the current era, and achieving a comprehensive digital transformation of education are the central points of contemporary educational development.\n\n# 2.2.2. Impact on teachers\n\nInstructional method's development. Digital education provides a wider range of teaching methods and tools [28]. It requires teachers to adapt and become proficient in utilizing these innovative approaches and technologies. This includes leveraging online learning platforms, educational applications, and virtual classrooms to effectively impart knowledge and engage with students. To cater to student's diverse learning needs, teachers must acquire familiarity with and expertise in using these technologies.\n\nPersonalized and self-directed learning support. Digital education has the potential to better support personalized and self-directed learning [19]. Teachers can leverage technology to gain insights into student's learning styles, interests, and needs. They also provide tailored instructional content and learning plans. This shift in education will see teachers adopt more of a guide and mentor role. They encourage students to take an active role in their learning and self-development.\n\nData-driven instructional decision-making. Digital education yields a wealth of learning data, including student's performance, interests, and progress [138]. Teachers can leverage this data to make informed instructional decisions and provide personalized guidance. By analyzing student's data, teachers can identify areas of difficulty and weakness and offer targeted support and feedback to help students overcome these challenges and improve their learning outcomes.\n\nCollaboration and cross-border teaching. Digital education has the power to break down geographical barriers, enabling teachers to engage in cross-border teaching and collaboration with students from all over the world. This allows for the sharing of instructional resources, experiences, and\n\nbest practices among educators, promoting professional development and collaboration within the teaching community.\n\nCultivating 21st-century skills. In the digital age, it's essential for students to develop skills such as creative thinking, digital literacy, collaboration, and problem-solving [46]. Teachers play a vital role in guiding students to cultivate these skills and providing relevant educational support and guidance. By exploring and applying new technologies together with students, teachers can foster student's innovation and adaptability, preparing them for success in an ever-changing digital landscape.\n\nTeachers are indispensable in the digital transformation of education, as they play a multifaceted role in shaping student's academic, emotional, and social development. While technology can provide access to vast knowledge and resources, it cannot replace the personalized guidance, emotional support, and values-based education that teachers offer. The expertise, interpersonal relationships, and educational wisdom of teachers are still essential elements in the digital transformation of education, ensuring that students receive a well-rounded education that prepares them for success in the 21st century.\n\n# 2.2.3. Educational challenges\n\nPersonalized learning needs. In contemporary education, students have diverse learning needs, styles, interests, and aspirations. The traditional one-size-fits-all approach may not cater to each student's unique requirements, and personalized learning is essential to addressing these differences effectively. Therefore, implementing personalized learning is a significant challenge that educators and administrators must address to ensure that every student receives an education tailored to their individual needs and abilities.\n\nInsufficient educational resources. Despite the advancements in technology, there are still areas where schools lack modern technology infrastructure, resulting in a digital divide that hinders student's access to online learning and digital education resources. Moreover, the number of students worldwide continues to rise, putting immense pressure on the education industry. Some regions face the challenge of insufficient educational resources, including teachers, classrooms, and learning materials, leading to disparities in educational opportunities.\n\nEducation quality and standards. Inconsistencies in education quality pose a significant challenge. In some regions, an exam-oriented approach to education may lead to a narrow focus on standardized testing, resulting in a simplified curriculum and a lack of support for students' personal interests and development. Ensuring high-quality, standardized education is crucial to enhance student's academic performance and overall quality. This can be achieved by implementing a well-rounded curriculum that fosters critical thinking, creativity, and problem-solving skills while also providing individualized support for student's unique needs and interests.\n\nDiverse educational technology. The integration of big data, AI, virtual reality, and other educational technologies\n\nhas the potential to revolutionize the education sector. However, it also poses new challenges, such as management, security, and privacy considerations. Effective integration and utilization of these technologies are crucial to enhance the learning experience and achieve optimal educational outcomes. This requires a well-thought-out strategy that takes into account the unique needs and constraints of the education sector.\n\nChallenges in implementing new educational concepts. The rapid pace of technological and economic advancements, coupled with improvements in living standards and quality, has led to the emergence of new educational concepts. One such concept is \"Science Technology Engineer Art Math (STEAM)\" education, which emphasizes interdisciplinary approaches and hands-on practice. However, implementing these cutting-edge educational concepts and cultivating the next generation of socially conscious talents pose a significant challenge for the education sector. Effective strategies and innovative approaches are needed to address these challenges and ensure that students are well-equipped to thrive in an ever-changing world.\n\n# 2.3. Characteristics of LLMEdu\n\nThe integration of AI into the education industry has accelerated rapidly [39, 61, 105], transforming teaching methods and enhancing learning outcomes. From computer-assisted teaching to personalized adaptive learning and content generation, AI has revolutionized the education sector, catering to diverse age groups and fields of study. In the era of intelligence, the primary objective of education is to convert knowledge into intelligence and nurture intelligent individuals. LLMs, with natural language technology at their core, align seamlessly with the education industry's development and adapt to the vast changes in intelligent education. These models have the potential to support and enhance various aspects of the learning experience, making education more accessible, engaging, and effective.\n\n# 2.3.1. Specific embodiment of \"LLMs + education\"\n\nReasons for integrating LLM into education are shown in Figure 3.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/fb43ad14a0e503da8c1bbe33bee4f19135686be5fe62deda62761976b887337c.jpg)  \nFigure 3: Reasons for integrating LLM into education.\n\nInterdisciplinary teaching [74]. The training of LLMs with vast amounts of data gives them a significant advantage in knowledge integration. They can provide diverse learning support based on different subjects and boast excellent interdisciplinary capabilities. For instance, the \"Ziyue\"\n\nlarge model<sup>1</sup> prioritizes a \"scenario-first\" approach, while the iFLYTEK \"Spark Desk\"<sup>2</sup> can conduct human-like interactive learning in various fields, including mathematics, English oral practice, essay correction, and more. These models have the potential to revolutionize the way we learn and teach [24].\n\nPrecise identification of personalized needs. LLMs possess advanced language understanding and generation capabilities, enabling them to provide adaptive learning guidance tailored to individual users' age, learning stage, and learning environment. For example, the iFlytek learning machine based on LLMs can provide customized teaching for traditional subjects, such as oral teaching, Chinese and English composition correction, interactive supplementary mathematics, and so on, providing students with personalized one-to-one mentoring experiences. Furthermore, the learning machine can help parents answer questions through one-to-one dialogue, provide suggestions, and assist in parent-child communication, parent-child interaction, behavioral habits, and so on.\n\nGuided learning. LLMs are shifting towards a more human-like approach, providing authentic conversational teaching experiences in various scenarios instead of simply giving answers. This is particularly noticeable in subjects like physics and mathematics, where LLMs simulate a teacher's role and ask questions to encourage critical thinking and independent exploration [53]. By fostering a self-learning environment, LLMs can help students develop their problem-solving skills and become more effective learners [79]. For example, OpenAI collaborated with the educational organization Khan Academy to produce Khanmigo, an LLM-based educational tool. As students complete the exercises, Khanmigo can guide them to get answers on their own by asking a lot of questions.\n\nIntegration of three modes. Tool-based, companion-based, and information-based [30, 52, 118]. The tool-based mode primarily involves using data to construct a knowledge base, which becomes a large-scale query repository. The companion-based mode is exemplified by virtual teachers and assistants, providing virtual teaching and online assistance through human-like conversations. The informatization-based mode mainly refers to educational informatization, accelerating the development of an \"internet + education\" platform.\n\n# 2.3.2. Impact of \"LLMs + education\"\n\n\"LLMs + education\" will have far-reaching and profound impacts. Here are 10 areas where these impacts can be observed, along with detailed explanations.\n\nPersonalized learning support. LLMs can provide customized learning support based on students' personalized needs. By deeply understanding students learning characteristics, interests, and learning styles, LLMs can tailor teaching content and learning plans for each student. For example,\n\nin mathematics learning, LLMs can provide targeted guidance for students' weak points in mathematics by interacting with them in dialogue, helping them overcome difficulties, and improving their mathematical abilities. LLMs can design adaptive tests that adjust the difficulty of questions based on students' responses, accurately assessing students' knowledge levels and ensuring they are educated at the appropriate level [1].\n\nPersonalized assessment and feedback. LLMs can provide personalized assessment and feedback based on students' learning performance [59]. By analyzing student's answers, understanding levels, and error patterns during the learning process, LLMs can provide targeted assessment results and improvement suggestions. For example, when students encounter difficulties in writing, LLMs can analyze the structure, grammar, and expression of their writing pieces and provide detailed guidance and suggestions to help students improve their writing skills [2, 76]. Some commercial auxiliary tools based on OpenAI's LLM technology, MagicSchool, and Eduaide, can participate in the assessment of students' homework and give feedback [89].\n\nWide coverage of subject knowledge. LLMs have extensive knowledge coverage and can encompass knowledge content from multiple subject areas [69]. Students can engage in dialogue with LLMs to acquire knowledge and information across various subject domains. For instance, when students encounter problems in history learning, LLMs can provide detailed explanations and in-depth discussions of historical events, figures, and backgrounds, helping students better understand historical knowledge. According to statistics, the latest model has 13 trillion tokens of carefully selected pre-training knowledge data, which is equivalent to 5 million sets of four major classics. In addition, 1.8 trillion \"knowledge fragments\" are extracted during training [14].\n\nInterdisciplinary learning. LLMs have excellent interdisciplinary capabilities, enabling students to engage in integrated learning and cultivate interdisciplinary thinking skills [110]. Through interactions with LLMs, students can integrate and apply knowledge from different subject areas. For example, when conducting scientific experiments, students can have conversations with LLMs to discuss experimental principles, data analysis, and scientific reasoning, promoting integrated learning between science and mathematics, logical thinking, and other disciplines [3].\n\nReal-time problem-solving and tutoring. LLMs can provide real-time problem-solving and tutoring support for students. When students encounter confusion or questions during the learning process, they can ask LLMs at any time and receive immediate answers and solutions. A survey report in the first half of this year pointed out that  $89\\%$  of American students surveyed were using ChatGPT to complete homework [134]. Additionally, when students encounter comprehension difficulties while reading literary works, they can engage in dialogue with LLMs to explore the themes, plots, and character images of literary works, helping students better understand and analyze literary works [115].\n\nOpportunities for learning across time and space. The existence of LLMs allows students to learn anytime and anywhere. Students can interact with LLMs through mobile devices or computers, without being constrained by traditional classroom time and location. For example, students can utilize evening or weekend time to engage in online learning with LLMs, improving their academic abilities and knowledge levels. Online learning platforms, which utilize LLMs, provide students with access to a wide range of courses and disciplines via the Internet. The LLMs support the implementation of virtual classrooms and distance education, and students talk to the LLMs in real time to solve problems.\n\nProvision of learning resources and tools. LLMs can serve as rich learning resources and tools, providing a wide range of educational materials and tools for student's learning needs. For instance, LLMs can offer textbooks, educational videos, interactive exercises, and other learning materials to support student's learning in various subjects [7]. Additionally, there are some subject-specific tools, such as MathGPT. MathGPT has an accuracy rate of  $60.34\\%$  in the benchmark test AGIEval, which can help students solve mathematical problems efficiently [142].\n\nPromotion of critical thinking. LLMs can guide students in developing critical thinking and problem-solving skills [50]. By engaging in dialogue and posing thought-provoking questions, LLMs can foster a thinking atmosphere that encourages students to explore answers, enhancing their self-learning abilities and critical thinking skills. For example, LLMs can simulate a teacher's role in a physics class, asking students questions about concepts, principles, and problem-solving strategies, encouraging them to think critically and develop problem-solving skills [114].\n\nProfessional development for educators. LLMs can support the professional development of educators by providing them with access to a vast amount of educational resources, best practices, and innovative teaching approaches. Educators can interact with LLMs to enhance their teaching methods and explore new ways to engage students [65]. For example, teachers can engage in dialogue with LLMs to discuss teaching strategies, classroom management techniques, and approaches to address student's individual needs, improving their teaching effectiveness and professional growth.\n\nAccessibility and inclusivity in education. LLMs can contribute to making education more accessible and inclusive. They can provide learning support for students with different learning styles, abilities, and backgrounds, ensuring that all students have equitable access to quality education. For example, LLMs can offer alternative explanations, visual aids, and interactive learning experiences to accommodate diverse learners, including students with learning disabilities or language barriers, making education more inclusive and supportive. Additionally, through multicultural training, LLMs can better understand and respect students from different cultural backgrounds and create a learning environment that is inclusive and respectful of diversity.\n\nIn summary, the integration of LLMs with education will revolutionize the learning experience by providing personalized support, expanding knowledge coverage, promoting critical thinking, and enhancing the accessibility and inclusivity of education. It will empower students and educators alike, transforming the way knowledge is acquired, shared, and applied in the digital age.\n\n# 3. How to Gradually Integrate LLMs into Education\n\nThe integration of AI into the education industry has been progressing step by step, from machine learning (implementing the ability to store and calculate) to deep learning (implementing the ability to see and hear), and now to LLMs (capable of understanding and creating) [78, 99, 113]. In the current era, the vigorous development of quality education by the entire population and the active deployment of educational intelligent hardware nationwide represent the active transformation of educational training enterprises [13, 91]. In the long-standing coexistence and collaboration between teachers and AI models [112], as well as the highly homogeneous hardware background, LLMs have emerged as one of the most important technologies in human intelligence.\n\n# 3.1. Reasons why LLMs for education\n\nLLMs' excellent characteristics make their application in the education industry very reasonable. NLP [41], data analysis [34, 135], and text generation capabilities [119] align well with the fundamental processes of learning, questioning, and feedback in education. The iterative optimization process of \"development-deployment\" suits the application process in the education industry. User testing and feedback data lay the foundation for further optimization. Taking the development of LLMs in China as an example, the Spark Desk by iFLYTEK<sup>3</sup>, the ERNIE Bot by Baidu<sup>4</sup>, and the \"MathGPT\" by TAL<sup>5</sup> have accumulated data from years of experience in the education industry [143]. During their usage, these LLMs can collect more data from the education industry, leading to further technology optimization.\n\nThe \"AI + education\" model has already formed, and the gradual maturity of AI technology has paved the way for the entry of LLMs into the education industry. Smart classrooms, voice-assisted teaching, intelligent problem-solving, and other AI applications have become routine in the education industry, leading to high acceptance of LLMs [10, 12, 96]. It is important to recognize that LLMs are the latest technological achievements that gather human collective intelligence, rather than only technological achievements. However, LLMs' development potential and influence are gradually increasing.\n\nEducation companies implement their own LLMEdu development strategies. LLMs require massive amounts of data and significant investments to support them. In terms of\n\ndata, looking at various education companies, long-term experience data accumulation, technology accumulation, and an objective combination of their development conditions have differentiated the educational application of LLMs. They focus on LLM research and strive to maximize their benefits, cater to current development trends, and reduce development costs. In terms of funding, consumers in the education industry have a strong willingness to consume. As people's living standards and education levels improve, the world strengthens the education industry and injects large amounts of funding to provide a solid foundation for LLM research, development, and application.\n\nChatGPT makes practical changes to the integration of technology and education. Learning is an exploration process, and LLMs play an exploratory role in education. Because of interactive questions and answers, people's roles are changing from passive recipients of knowledge to active explorers. Because of the existence of machine hallucinations, scholars need to have a skeptical and judgmental attitude towards generated knowledge and treat LLMs from a dialectical perspective. Intelligent technology stimulates human creativity, allowing people to continuously expand their breadth of learning, thus leading to scientific and technological progress.\n\nLLMs support the sustainable development of education [5]. Innovation is the core of technological development and the premise of long-term application. By fully utilizing AI technologies such as ChatGPT, the application process in education can transition from a search mode to a content generation mode personalized for individuals. This enables the development of diverse, scalable, tangible application scenarios, as well as a series of differentiated and highly experiential educational products and services. It provides excellent environments and resources for educators and education recipients, supporting education's sustainable development.\n\nNowadays, general language models (LMs) leverage extensive data memory to shift from dedicated to universal application models. They rely on text generation capabilities, transitioning the application process from distribution to generation. This allows them to achieve multi-modality and transform application scenarios from single to multiple [43]. Multi-modal LLMs, which combine pre-training and downstream tasks, can efficiently complete downstream task adaptation with relatively small amounts of data and can be used in small sample learning and natural language question answering. In education, three typical applications are realized: automatic generation of teaching resources, human-machine collaborative process support [141], and intelligent teaching assistance for teachers. Multi-modal LMs combine the three fields of reinforcement learning, CV, and NLP. They attempt to extend the concept of LMs [49, 95, 106].\n\nWhat's more, we demonstrate the development of the GPT models, as shown in Table 2.\n\nTable 2 Iteration and comparison of LLMs  \n\n<table><tr><td>LLMs</td><td>Publish time</td><td>Parameter quantity</td><td>Pre-training data size</td><td>Training paradigm</td><td>Feature</td></tr><tr><td>GPT</td><td>2018.7</td><td>120 million</td><td>5G</td><td>Pre-training + fine-tuning</td><td>Reflection of the advantages of self-attention structure</td></tr><tr><td>GPT-26</td><td>2019.2</td><td>1.5 billion</td><td>40G</td><td>Prompt paradigm based on Tunning-free: Zero Shot Prompt</td><td>Open the exploration of the Prompt paradigm</td></tr><tr><td>GPT-37</td><td>2020.6</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm based on Tunning-free: In-Context Learning</td><td>Deepen the exploration of the Prompt paradigm</td></tr><tr><td>InstructGPT8</td><td>2022.3</td><td>175 billion</td><td>45TB</td><td>Prompt paradigm of Instruction Tuning</td><td>Start paying attention to human preferences</td></tr><tr><td>ChatGPT9</td><td>2022.11</td><td>175 billion</td><td>45TB</td><td>Reinforcement learning from human feedback</td><td>Aligned with human preferences</td></tr><tr><td>GPT-410</td><td>2023.3</td><td>Nearly 2 trillion</td><td>-</td><td>Reinforcement learning from human feedback</td><td>Multimodal processing and getting closer to the bionic human brain</td></tr><tr><td>LaMDA11</td><td>2021</td><td>137 billion</td><td>150TB</td><td>Pre-training + fine-tuning</td><td>Introduce external information retrieval system</td></tr><tr><td>BARD12</td><td>2023.2</td><td>137 billion</td><td>-</td><td>Join ChromeOS as a search engine</td><td>Using LaMDA as a base</td></tr><tr><td>PaLM</td><td>2022.4</td><td>540 billion</td><td>-</td><td>PathWay distributed training framework</td><td>Large scale, multi-lingual</td></tr><tr><td>Claude13</td><td>2023.3</td><td>52 billion</td><td>-</td><td>Join the RLAIF training paradigm</td><td>Longer and more natural text editing than ChatGPT</td></tr><tr><td>BlenderBot314</td><td>2022.8</td><td>175 billion</td><td>-</td><td>Instruction fine-tuning</td><td>Text generation, question answering</td></tr></table>\n\n# 3.2. Fusion strategies\n\nCooperating with the education and training community. LLM technology engages with schools, online education platforms, and educational technology companies to collectively explore and develop the application of LLMs in education. Partnering to provide actual educational scenarios and resources can help customize models to meet educational needs and accelerate the implementation of LLMedu. For example, Baidu launched \"ERNIE Bot\" [143], Alibaba Group Holding Limited launched \"Tongyi Qianwen\" [15], and universities like Tsinghua University launched \"ChatGLM\" [16] [133], etc.\n\nForm customized content generation to enhance competitiveness. LLMs require high-quality and large data sets, so the education and training community can use LLMs to generate high-quality educational content, such as course materials, textbooks, exercises, and tests. For example, Baidu's \"ERNIE Bot\" has a certain accuracy in answering knowledge questions because it uses the Baidu Encyclopedia as training material. ChatGPT can also generate some framework lesson plans for teaching.\n\nProvide popular educational functions. Some educational technology companies develop an intelligent tutoring system, use LLMs to answer students' questions, provide answers and feedback, provide logical responses to open-ended questions, and provide guided responses to calculation questions. For example, MathGPT, developed by TAL, provides high-quality problem-solving tutoring in the field of mathematics [97]. Some use LLMs to develop speech recognition and dialogue systems, making speech education and interaction easier to implement, enabling language teaching and situational dialogue [54].\n\nIntegrate LLMs into online education platforms. Based on the learning model combined with the Internet and the rapid development of big data, integrating LLMs into online education platforms can provide students with richer learning resources, tools, and more comprehensive applications. For example, the Coursera online education platform<sup>17</sup> uses LLMs to implement functions such as data\n\ncollection and course recommendations. Duolingo $^{18}$  uses LLMs to upgrade language functions. Chegg $^{19}$  uses LLMs to optimize the homework tutoring process.\n\nParticipate in optimizing the educational work training process. First, provide training and support to educators so that they can effectively use LLMs and related tools. For example, we learn how to integrate models into teaching, as well as how to interpret and use the data and recommendations generated by the models. Second, we use LLMs to analyze student data to provide educators with insights about student progress and needs, thereby optimizing their teaching methods, such as timely feedback features.\n\nContinuous improvement and research. The gradual integration of LLMs into the education industry requires time and resources. During this process, the performance, application, and potential risks of LLMs are continuously monitored and improved, and data privacy and security regulations are observed, considering the educational needs of different regions and cultures, which can maximize the role of LLMs in the education industry.\n\n# 4. Key Technologies for LLMEdu\n\nThe technologies behind LLMs support their rapid development, as shown in Figure 4. The combination of these technologies enables LLMs to achieve excellent performance in a variety of NLP tasks, such as text generation, machine translation, sentiment analysis, and text classification. They already play an important role in various applications such as virtual assistants, intelligent search, automatic summary generation, and natural language understanding, which promotes the development of LLMEdu.\n\nLanguage model. It learns from a corpus and predicts word sequences based on probability distributions. Two main technologies used to train a language model are next-token prediction and masked language modeling. Next-token prediction predicts the next word based on its context, and masked language modeling learns the statistical structure of language, like word order and usage patterns [9, 25, 84]. However, there is still a significant gap between predicting\n\nTable 3 Comparison between generative AI and discriminative AI  \n\n<table><tr><td></td><td>Core</td><td>Data learning</td><td>Development process</td><td>Application</td></tr><tr><td>Discriminant/Analytical AI</td><td>Analysis</td><td>Conditional probability distribution</td><td>Mature technology and widely used</td><td>Recommendation systems, CV, NLP</td></tr><tr><td>Generative AI</td><td>Creation</td><td>Joint probability distribution</td><td>Exponential explosion</td><td>AIGC, text generation, audio generation</td></tr></table>\n\ntext and mastering more advanced representations in LMs, so training strategies for LMs can be inconsistent and may not correctly reach the ultimate goal. The prediction ability reflects the large model's learning ability, which determines whether the LLM can form a coherent and logical text when answering questions. So the language model is LLMEdu's foundation.\n\nHuman feedback reinforcement learning (HFRL). It is a method used in the training of LLMs [86]. By incorporating human feedback, it reduces distorted and meaningless outputs, helping ChatGPT overcome the issues present in GPT-3, such as consistency problems. It includes supervised fine-tuning, simulating human preferences, and proximal policy optimization [140]. i) In supervised fine-tuning, a small amount of annotated data is fine-tuned by first performing next-token prediction to improve the injected data, then integrating the results, and finally decoding operations [33]. ii) Developing a reward model that simulates human preferences to rank the decoded results, and constructing a ranking sequence to obtain a scoring model. To ensure consistent annotation results, the ranking process uses ordinal ranking for data annotation, resulting in a new dataset composed of comparative data [8]. iii) Proximal policy optimization aims to learn a policy that maximizes the cumulative reward obtained during training. The algorithm involves an actor, which outputs the probability distribution for the next action, and a critic, which estimates the expected cumulative reward for a given state. By iteratively optimizing the reward signal output, the model learns from experience, adapts to new situations, continuously adjusts its policy, and improves the LLMs [121]. HFRL improves LMEdu's accuracy, making the output results more concise, accurate, and in line with the human thinking process.\n\nDeep neural networks (DNNs) [42]. Before explaining DNNs, it is necessary to introduce deep learning. It refers to the learning of the underlying patterns and hierarchical representations of sample data, aiming to achieve the goal of machine learning with analytical capabilities similar to humans. DNNs consist of multiple layers of interconnected neurons, typically including an input layer, several hidden layers, and an output layer. The connectivity between neurons is similar to the connections between biological neural cells. DNNs have advantages in processing large-scale educational data, including students' academic performance, learning behavior, problem-solving abilities, etc. By analyzing these data, LLM can provide insights for educational decision-making and improve teaching methods and personalized education strategies.\n\nSelf-supervised learning. To produce the desired results, a model or machine needs to be trained with the given materials. Machine learning can be categorized into supervised learning, unsupervised learning, and reinforcement learning [80]. Self-supervised learning falls under unsupervised learning, where the model learns general feature representations for specific tasks. Unlike supervised learning, which requires a large amount of manually annotated data for training, self-supervised learning completes self-training by replacing human annotations with the intrinsic structural features of the data itself, using unlabeled datasets [31, 125]. It gradually trains the parameters from scratch in a progressive manner, using part of the input as the supervisory signal and the rest as input. This approach significantly reduces the cost of manual annotation in terms of high cost, long cycles, and low accuracy, resulting in a lower development cost. Through self-supervised learning, LLMs can learn advanced representations of language data and deep cognition of language skills. This enables them to better understand and generate education-related content, including textbooks, exercises, solutions, and study materials.\n\nTransformer model. From a structural perspective, LMs have evolved from statistical LMs to neural network LMs, and now to LLMs. Statistical LMs focus on transforming sentences into probability distributions, but the lack of computational power limits their ability to match massive amounts of data. Neural network LMs, such as recurrent neural networks, use recursion and convolutional neural networks to transform language sequences. Recurrent neural networks require considering the input-output order for computation and cannot handle examples in batches efficiently, resulting in slow speed. The Transformer model, widely used in LLMs, overcomes these limitations. The transformer model is essentially an encoder-decoder architecture that includes encoding and decoding components. It employs attention mechanisms to capture global dependencies between inputs and outputs [27], without considering the distance within input or output sequences [29]. This approach transforms the growth rate of required data for operations on related signals from linear or logarithmic to constant, showcasing high parallelism, which is beneficial for fast model iterations. Compared to previous models, the Transformer model has a richer structure, stronger adaptability to various scenarios, and better performance. The Transformer model improves the compatibility and practicality of LLMs, as well as its ability to cope with diverse and rich teaching contents and educational scenarios.\n\nLLM diagnostics and application evaluation. Existing interdisciplinary evaluation systems assess LLMs from two perspectives: diagnostics during LLM training and the effectiveness of LLM applications. \"ChatbotArena\"20 is a benchmark platform for LLMs that conduct anonymous and random adversarial evaluations, where the system randomly selects two different LLMs to chat with users, who then rate the interactions. \"SuperCLUE\"21 is a benchmark for evaluating general-purpose LMs in Chinese, examining multidimensional capabilities in terms of basic abilities, professional abilities, and Chinese-specific abilities [124]. \"The C-Eval project\" [51], jointly carried out by Shanghai Jiao Tong University, Tsinghua University, and the University of Edinburgh, constructs a multidisciplinary benchmark list to assist Chinese LLM research. \"FlagEval\" [63], built by multiple universities, adopts a three-dimensional approach to evaluating LLMs, including factuality, safety, and inclusivity. These evaluation frameworks are designed to comprehensively assess LLMedu's performance, ethical impact, and potential bias, as well as promote the improvement of LLMedu's capabilities and technology optimization.\n\nPrompt engineering [83]. It refers to the ability to interact with LLMs. Machines match corresponding results through prompts, thereby increasing productivity. Good prompts can enhance the intelligence of LLMs and increase the value of feedback results [109, 130], increasing the use value of LLM.edu. Moreover, poor prompts may lead to erroneous conclusions. In the field of education, especially rigorous science, the correctness of answers is always given priority, so optimizing prompt words is also important to deal with LLM's nonsense when answering academic questions. Different LMs, such as ChatGPT, ERNIE Bot, and MathGPT, have independent underlying training mechanisms, and their prompts are different. This can be likened to communication with individuals with different personalities.\n\nLearning cognitive mechanisms. Learning cognitive mechanisms, which were developed in cognitive ethics, serve as the foundation for intelligent instructional design. It studies the process of knowledge construction in learners, integrating new knowledge into existing knowledge structures, and adjusting and updating the overall structure. Prior to ChatGPT, AI primarily focused on computation and reasoning. With AI's rapid development, its cognitive intelligence has gradually emerged and can even match human intelligence. There are two main cognitive approaches: one involves simulating human learning processes through computer models, and the other utilizes non-invasive brain imaging techniques such as functional magnetic resonance imaging. LLMs primarily simulate human learning processes, where pre-training can be likened to acquiring new knowledge and constructing knowledge.\n\nBy adding plug-ins, the latest LLM GPT-4 can address real-time problems, such as solving the lag problem of pretraining data. GPT-4 can also better solve logic problems because it introduces the mathematical problem data sets\n\nMATH and GSM-8K into the training data set, which greatly improves its mathematical reasoning capabilities. Moreover, GPT-4 can also complete creative text creation because it is connected to the API, and users can customize the AI character and complete simulated writing, reducing deviations and over-correction [71].\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/b4ef019575990bd87a640c565e63e967f54e38f8504e2682eebbeedb8e434bd6.jpg)  \nFigure 4: Key technologies of the LLMs\n\n# 5. Implementation of LLMEdu\n\nIn this article, many products of LLMedu are introduced, and the summary is shown in Figure 5. Moreover, this part will focus on the implementation process of LMs from two aspects: LLMs empowering education and specifically LLMs empowering the field of mathematics. Finally, we use a unified framework to organize and compare the application of LLM in the field of education. The details are shown in Table 4.\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e00fa102c4cec42c4c9611c8bc61e3d50cd086121164b5e0ef13d24ffcfd33b.jpg)  \nFigure 5: Examples of LLMEdu.\n\n# 5.1. LLMs-empowered education\n\nImprove teacher effectiveness. LLM can help teachers access a wealth of teaching resources, allowing them to conduct classroom instruction more effectively. Before class, LLM can serve as a helpful assistant for lesson preparation. Through interactive question-and-answer sessions, LLM can provide ideas for teacher's lesson planning, assist in designing teaching outlines and curriculum plans, and help teachers quickly identify the highlights and challenges of a lesson. In the classroom, LLM can act as an AI teaching assistant, providing an instant feedback platform for both teachers and students and enhancing classroom engagement, interest, and appeal. After class, LLM can assist teachers in generating\n\nhomework assignments and exam questions, enabling teachers to better assess students' understanding of the subject matter. In daily work, LLM is also a valuable assistant for teachers, capable of drafting meeting invitations, writing work plans, summaries, reports, and more. When used properly, LLM can help alleviate teachers' workload and promote their professional development [136]. For example, a survey pointed out that during the paper revision process,  $57.4\\%$  of users believed that the feedback generated by LLM was helpful and could help them improve their research process [64].\n\nPromote student progress and growth. In terms of learning assistance, LLM is a powerful tool that can understand complex concepts, solve difficult problems, and provide corresponding learning advice. In language learning, LLM offers scenario-based dialogue training, greatly enhancing student's oral and written abilities. In terms of cultivating thinking skills, LLM sometimes exhibits \"serious nonsense\". Teachers and parents can utilize this phenomenon to cultivate students' critical thinking and enhance their information literacy. In terms of learning ability development, the process of using LLM requires students to ask questions. In this process, students have to learn how to translate their questions into effective questions and how to obtain useful information, which cultivates students' self-learning ability and summary ability. Taking college students as an example, data shows that more than  $20\\%$  of the users of one of LLM's latest products, the iFlytek Spark model, are college students, and it helps them improve in English speaking practice, mock interviews, and after-school homework.\n\nAnswer professional and academic questions, accelerating research progress. LLM is capable of writing academic experiment codes, building experimental models, quickly and accurately searching for literature materials, and extracting and integrating relevant information. This reduces the tedious process of manual research and accumulation, saving a significant amount of time. As a result, researchers can invest more energy into subsequent research, thereby improving research efficiency [7]. Additionally, the report findings show that LLMs in universities, as an important research platform in the field of AI, have achieved remarkable results. Chinese universities' research on LLMs mainly focuses on CV, NLP, speech recognition, and other fields. Research results in these fields not only provide a good academic atmosphere for teachers and students in universities but also provide strong support for the development of different AI industries.\n\nPromote the evolution of educational consciousness and form new learning paradigms. The existing educational system is primarily focused on inheritance, and students often approach knowledge with inertial thinking inherited from their learning experiences. There is a lack of creative awareness. However, with the advancement of AI technologies such as ChatGPT, the existing learning paradigms are no longer sufficient for the future. Faced with the challenges posed by technologies like ChatGPT,\n\nit is necessary to cultivate higher consciousness and exercise thinking skills with a high level of awareness, forming new learning paradigms while improving perception and cognition to better understand the world. For example, the high-consciousness generative learning paradigm reflected in ChatGPT involves establishing connections between new and old knowledge, incorporating reflection and introspection, and innovating new concepts and understandings. To advance the high-consciousness generative learning paradigm, collaboration between educational designers and implementers is required to build adaptive learning environments and foster a positive learning atmosphere [7].\n\nCreate highly contextualized and intelligent learning experiences. In subject learning, generative AI like LLM, with its vast amount of data, can provide students with abundant information and knowledge, streamlining the process of finding learning materials and assisting students in finding answers and solving problems across various subjects. In language learning, LLM can offer real-time dialogue training, enabling students to immerse themselves in scenario-based learning and improve their conversational and writing skills. In terms of temporal and spatial aspects of learning, as an online tool, LLM can be accessed by students anytime and anywhere, providing great flexibility. Currently, LLMs are constantly improving their technologies and capabilities to achieve intelligent learning. For example, in the language understanding task, the ultra-large-scale Chinese pre-trained language model PLUG broke the Chinese GLUE classification list record with a score of 80.179. In the language generation task, it improved by an average of more than  $8\\%$  compared with the previous best results in multiple datasets.\n\nPromoting high-quality development in education enhances educational management and decision-making capabilities. LLMs represent the latest technological means supporting intelligent education, and their development process reflects the synchronized progress of AI and humans. This embodies a new era of educational style that aims to create intelligence, cultivate wisdom, and create more efficient intelligence. Moreover, the data transparency involved in LLMs can make educational development decisions more precise and scientific, transforming educational decision-making from experiential patterns to evidence-based patterns and thereby enhancing educational governance capabilities. Finally, educational practitioners can use AI technologies like ChatGPT to conduct scenario-based assessments of students, resulting in a digital transformation of educational evaluation [45]. LLMs can help teachers judge student's progress in learning and understand student's learning status. Notice that the multi-dimensional data collected by LLMs through evaluation is helpful for educators to study student's learning logic and development rules, adjust teaching content on time, and provide students with personalized growth services.\n\nDriving in-depth research in the education system. The research paradigms in education have evolved from the traditional observation and summary of scientific experiment experience, the construction of theoretical models and\n\nderivations, and computer simulation to the scientific research paradigm of large-scale data collection, analysis, and processing. The educational research paradigm is constantly changing. However, as time progresses, the old research paradigms no longer meet the requirements. The emergence of content-generative AI, represented by LLMs, has given rise to a new paradigm, \"The Fifth Paradigm\" of \"AI for Science,\" enabling humans to delve further into the exploration of the education system. This paradigm shift involves the transition from simple imitation of humans to cognitive understanding and transformation, creating a new world of AI and education. According to a survey by Study.com[22],  $21\\%$  of teachers outside China have begun to use ChatGPT to assist their teaching work. Chegg, a listed American education and training company, also said that after launching the LLM-based learning assistance platform, it has affected the user growth of its original business, and students' interest in ChatGPT has greatly increased.\n\nPromote the development of AI from fragmentation to scalability, thereby enhancing its generalization capabilities in education. LLMs accurately capture knowledge from massive datasets through the process of pre-training an LLM and fine-tuning it for downstream tasks [11]. This knowledge is stored in a large number of parameters and then fine-tuned for specific tasks. Finally, it can be flexibly applied to various scenarios. In other words, a single set of techniques can be used to address different tasks, greatly improving development efficiency. For example, in the field of education, LLMs share data to solve common problems and are widely applied in dialogue question-answering, language translation, text generation, and other scenarios. Some open-source LLMs, such as ChatGLM, Baichuan, InternLM, Qwen-7B, and Qwen-14B, are all manifestations of the generalization of LLMs, and Qwen-14B among them already has an accuracy of more than  $70\\%$ , which shows that these degrees are constantly improving.\n\n# 5.2. LLMs in Mathematics\n\nAI has been pursuing mathematical research and applications since its inception. Mathematics is a challenging subject in education, and proficiency in math represents a significant milestone in the intelligence level of LLMs. The successful handling of mathematical problems by LLMs will mark a new era in AI.\n\nApplications in mathematics can reflect the imitation ability of LLMs. Mathematics is an abstract discipline that requires logical reasoning and critical thinking [102]. Currently, LLMs are unable to genuinely comprehend the essence of mathematics and demonstrate independent thought. Therefore, when addressing mathematical problems, these LLM models rely heavily on the mathematical concepts and rules embedded in their training data. For instance, when solving algebraic problems, LLMs apply algebraic rules by mimicking the way humans learn and apply algebra [71].\n\nImprovement of computational performance of LLMs in mathematics. The essence of LLMs is to predict future outputs based on data correlation. However, errors may occur for symbols that are rarely or never encountered in the pre-training stage. For example, because the size of numbers is infinite and the scale of LLMs is limited, arithmetic operations on large numbers are likely to go wrong. To solve this problem, fine-tune the LLM on synthetic arithmetic problems and use special training and inference strategies to further improve numerical computing performance.\n\nOptimize the logical reasoning process. One is to optimize the human logical reasoning process through LLMs. For example, some scholars have applied LLMs to the proof of theorems [44], because LLMs can provide a large amount of relevant materials to make up for the lack of information or omissions, making the reasoning more complete. The second goal is to improve LLMs' logical reasoning abilities. The logical reasoning ability of LLMs is a key indicator for evaluating LLMs. Because LLMs usually have problems such as excessive parameter space and severe data sparseness, LLMs perform poorly on robust and rigorous reasoning tasks. Relevant research has proposed optimization methods for LLM logical reasoning problems. For example, OpenAI[23] studies a process-based supervision model to improve the logical reasoning capabilities of GPT-4. Moreover, some research institutions use the method of continuous pre-prediction on large-scale mathematical corpora, which improves model performance on mathematical reasoning tasks.\n\nInteraction with external tools to improve LLMs' mathematical capabilities. 1) LLMs interact with language conversion tools, such as lean language [81], which can convert mathematical language into computer language, thereby improving the rigor of model reasoning. This is an innovative way to bridge the gap between human reasoning and machine reasoning. This could allow models to better understand and process complex mathematical concepts. 2) LLMs interact with information retrieval systems, such as the large dialogue model LaMDA proposed by Google, which connects to the information retrieval system and allows the model to learn to retrieve and use calculators and translation engines [108]. 3) LLMs directly interact with the calculation engine, such as MathGPT, which improves calculation accuracy by interacting with the calculation engine. This allows models to take advantage of calculators' powerful computing capabilities and perform complex mathematical calculations with greater accuracy. 4) LLMs enable themselves to determine the interactive tools, such as Meta's toolformer model, which can determine the use of external tools by itself [98]. This gives models the flexibility to adapt to different situations and choose the most appropriate tools to solve a problem, much like humans do.\n\nFuture development of LLMs in mathematics. Specifically, the first is a cutting-edge exploration with scientific research at the core, such as the research and improvement of LLMs' capabilities in mathematics, including computing\n\nTable 4 Comparison between generative AI and discriminative AI  \n\n<table><tr><td>Application</td><td>Advantage</td><td>Disadvantage</td><td>Challenge</td><td>Future development</td></tr><tr><td rowspan=\"3\">Personalized learning</td><td>Save time and costs</td><td>Data privacy issues</td><td>Expand the corpus</td><td>Develop personalized applications</td></tr><tr><td>Precise teaching</td><td>Information bias</td><td>Information accuracy</td><td>Information extraction technology update</td></tr><tr><td>Good interactivity</td><td>The learning process is opaque</td><td>Update corpus in real time</td><td>Integration of various technologies</td></tr><tr><td rowspan=\"3\">Guided learning</td><td>Improve problem-solving abilities</td><td>Marginalized teachers</td><td>Social impact</td><td>Training with more accurate data</td></tr><tr><td>Encourage critical thinking</td><td>Misleading information</td><td>Emotional understanding</td><td>Integrate with personalized experiences</td></tr><tr><td>Cultivate interest in learning</td><td>Lack of emotional resonance</td><td>Unemployment Risk</td><td>Develop policies to address social impacts</td></tr><tr><td rowspan=\"3\">Interdisciplinary learning</td><td>Provide diverse learning support</td><td>Insufficient training data support</td><td>Logic optimization</td><td>Integration of multidisciplinary and LLM</td></tr><tr><td>Cultivate interdisciplinary thinking skills</td><td>Lack of domain knowledge</td><td>Accuracy of knowledge integration</td><td>Revolutionize the way we learn and teach</td></tr><tr><td>Boast excellent interdisciplinary capabilities</td><td>Disciplinary bias</td><td>Algorithm optimization</td><td>Filter useful training data</td></tr><tr><td rowspan=\"3\">Real-time problem-solving</td><td>Reduce teacher stress</td><td>Machine hallucination</td><td>Multiple text associations</td><td>Standardize technology use</td></tr><tr><td>Improved learning efficiency</td><td>Over-reliance on technology</td><td>Text extraction</td><td>Acceleration of model inference</td></tr><tr><td>Teaching assistance upgrade</td><td></td><td></td><td>Diversified technical assistance</td></tr><tr><td rowspan=\"3\">Applications in mathematics</td><td>Guide mathematics learning</td><td>Math terminology learning</td><td>Promote mathematical research</td><td>Pay attention to thinking guidance</td></tr><tr><td>Improve math learning efficiency</td><td></td><td>Improved logical reasoning ability</td><td>Mathematics research and teaching</td></tr><tr><td>Show the fusion of AI and mathematics</td><td></td><td>Understand number relationships</td><td>Adequate language modeling</td></tr></table>\n\ncapabilities, reasoning capabilities, robustness, and so on. The second is to improve inclusive education and basic education for the general public. This entails studying how to use models to improve learning experiences and effects, as well as enhance mathematical education for students of all ages and backgrounds. By leveraging the power of LLMs, it may be possible to create personalized learning experiences that cater to individual student's needs and learning styles, making mathematics education more accessible and effective for a broader range of people. In terms of development potential, the expansion of LLMs' ability to solve mathematical problems could have far-reaching implications for other technical and educational fields. For example, LLMs could be used to improve the accuracy and efficiency of scientific simulations, enhance the effectiveness of machine learning algorithms, or even aid in the development of new technologies such as quantum computing. Ultimately, the development of LLMs in mathematics could drive the development of a new generation of education models that are more inclusive, effective, and efficient.\n\n# 6. Issues and Challenges\n\nIn practical applications, LLMs for education still face many issues and challenges, including but not limited to, as shown in Figure 6.\n\n# 6.1. Main issues\n\nRisk of widespread false knowledge. As an imperfect intelligent technology, LLMs such as ChatGPT still have many flaws. The biggest drawback is the potential for generating incorrect information [3]. As many people have noticed, LLM sometimes exhibits machine hallucination [94]. For example, a computer scientist in California tried different methods to check the output of the GPT robots and found that GPT-3.5 and GPT-4 were full of errors when testing physics, chemistry, and mathematics questions selected from\n\n![](/uploads/images/2c6ea33c-9a9e-4547-949a-69351fc70f65/2e96c40efc4f830a6d3e3df8179621d5ff0b821e91ca75d694a2efc3168f8e51.jpg)  \nFigure 6: Some challenges and issues of LLMEdu.\n\ncollege textbooks and exams. Moreover, since LLM's training data largely consists of English corpora, it often struggles to understand and provide correct answers to personalized Chinese questions. In the short term, these errors can cause disruptions in students' knowledge learning, and students with weaker discernment abilities are highly likely to acquire erroneous knowledge without realizing it. In the long term, if the corresponding technology is not improved promptly, LLM may contribute further to the proliferation of false knowledge. There are many examples of actively dealing with machine hallucinations. For example, the retrieval-augmented generation method (RAG) can integrate LLM with a rigorously verified external key knowledge corpus.\n\nLack of clear operating rules in the education system. Due to the complexity of education itself, representing the education system using specific symbols and algorithms is an extremely challenging process that current LLMs cannot achieve. Education behaviors, such as emotional interaction, effective communication, and leading by example, are currently beyond the capabilities of LLMs. LLMs learn from a large amount of data and provide feedback, representing subjective educational information with data and providing\n\nrational reflections of human thinking. The goal of anthropomorphizing LLMs is to enable NLP models, such as Word2Vec, to convert words into vectors, facilitating the computer's processing of textual data [4]. GPT-1 and BERT, based on the self-attention mechanism [40], further enhance performance. GPT-3 achieves another leap in performance on zero-shot learning tasks with its significantly increased parameter scale [116]. ChatGPT's HFRL, code pretraining, and instruction fine-tuning improve the model's inference capabilities [86]. GPT-4, an ultra-large-scale multimodal pre-trained model, possesses multimodal understanding and multi-type content generation capabilities [62]. These examples show ideas for solving the problem of anthropomorphizing LLMs, gradually approaching human-like capabilities through continuous optimization and development, thereby alleviating the limitations of the abstraction and ambiguity of educational rules.\n\nSome drawbacks when students use LLMs. The occasional inaccuracies in LLM's answers can mislead students who lack critical thinking skills. The great convenience of LLM may reduce students' desire for independent learning and innovation, leading to intellectual laziness. As LLM involves massive amounts of data, students who lack awareness of data security may unknowingly leak their personal data [129]. While LLM provides interactive dialogue scenarios and opportunities for AI communication with students, it reduces real interpersonal conversations, and the way of discussing problems may shift from online to one-sided questioning of the machine, affecting the development of student's social skills. In response to these problems, educators need to actively guide students to adapt to the characteristics of LLM-assisted education and enhance the cultivation of privacy and security awareness.\n\nInsufficient integration of LLMs in collaborative teaching [71]. Although LLM has achieved some level of one-on-one dialogue and communication, its integration with education in real life is still limited. The ability to solve higher-order reasoning problems and complex problems still needs improvement. For example, while GPT-4 performs reasonably well in some exams, it fails to demonstrate significant advantages in logical reasoning problems [70]. Most LLMs have high accuracy rates (up to  $95\\%$ ) for reasoning with a small number of steps, but as the number of steps increases, reaching 20 or more, the accuracy drops significantly to  $36\\%$ , indicating a significant disparity [90]. As a result, it is necessary to develop chain-of-thought technology to improve LLMs' reasoning ability and ability to solve complex problems [117], thereby promoting the integration of large models and collaborative education.\n\nLimitations of LLMs [107]. Firstly, in pre-training, models that simultaneously satisfy the reasonable model size, advanced few-shot learning capability, and advanced fine-tuning capability have not been achieved yet. For example, GPT-3 lacks a reasonable model size and is relatively large in scale [16]. Furthermore, the high complexity and strong data dependency of LLMs may be exploited by malicious data to affect their training process and generation\n\nresults, as well as output uncertainty and other factors. The lack of interpretability in LLMs' technology makes their internal mechanisms unclear. The widespread application of LMs requires interpretability to ensure application security, overcome performance limitations, and control societal impact, which has triggered corresponding considerations regarding these issues. In the future, LLM's technology still needs optimization and innovation, and researchers need to consider the interpretability of the model more based on the user's situation.\n\n# 6.2. Main challenges\n\nTechnological challenges. The application of LLMEdu relies on AI-based technologies, which are complex and challenging. If the technology is not perfected, it becomes difficult to provide high-quality educational services. The availability of high-quality data sources is one important factor influencing the improvement of LLM technology. High-quality data transformation involves capture and conversion processes. It is necessary to consider how to expand the perception of the educational field to capture dynamic performance data from any learning activity in educational subjects and how to improve the quality of the data through efficient processing. Moreover, LLMEdu faces technological challenges such as speech recognition, NLP, AIGC [119], multimodal LLMs [120], and other aspects. The above-mentioned issues require researchers to always pay attention to the development of other technologies in the AI field and actively integrate them into LLM to bring a better experience to the education industry.\n\nArtificial intelligence security. The intelligence level of LLMs continues to improve, and security issues have become more severe. The first is the LLMs' biased cognition. Some studies have pointed out that when LLMs are tested using gender bias data sets, their answers will reflect gender bias [57]. Therefore, when training an LLM, the data should be filtered. The second is the lack of correct social, moral, and ethical values. For some issues that violate social ethics, LLMs are unable to judge, which increases the risk of crime. Therefore, the country should formulate a more complete legal system to regulate the use of LLMs. The third is the most common issue among artificial intelligence ethical issues: \"AI replaces human activities\". AI has limitations in education. While AI has great potential in education, it cannot replace the role of teachers, such as encouraging critical thinking, solving complex problems, and providing psychological and social support. However, humans should also flexibly adjust their roles, regulate and guide the development of AI from an ethical perspective, and maintain their dominant position.\n\nEducation quality. The use of LLMedu provides many opportunities for smart education, but it also presents challenges in terms of quality. If LLMedu cannot provide high-quality educational services, it will be difficult to gain recognition from students and teachers. Furthermore, educational institutions that use LMs must strike a balance between educational quality and technological innovation. Otherwise,\n\nthere may be an overreliance on technology, neglecting the quality of education itself. Therefore, to ensure the quality of education, the first consideration is to ensure the educational content, which requires educators to adjust reasonable teaching content and clarify the auxiliary functions of LLMs. Then, technology developers are required to ensure that the technology of LLMs is steadily progressing.\n\nTechnological dependence. Note that the future LLMEd should be human-centric but not technology-centric [127]. Overreliance on AI may reduce students' ability for independent learning and innovative thinking, and it may even lead to cheating and academic misconduct, such as using ChatGPT to complete assignments and papers. It is necessary to prevent the passive application of LLMs, as seen in the examples in reality. While using AI, the student should be encouraged to think independently, explore problems, and find answers. Furthermore, students should be educated on time management, ensuring sufficient time for other important activities while using AI, and avoiding excessive dependence on it.\n\nTechnical accessibility and training. The introduction of AI technology requires corresponding hardware infrastructure and network support. In resource-limited areas, this can be a challenge. Combined with the pressures and entrenched thinking that fear is being replaced [126], there is a phenomenon of fear and refusal to use AI in education, in other words, cognitive limitations. In such cases, technical access and training become difficult. Therefore, efforts should be made to promote the long-term advantages of AI in the education industry, guide teachers and students to receive appropriate training, better understand the application ideas and specific methods of intelligent technology, enhance willingness to use, and better adapt to and utilize these tools.\n\nEquity issues. Although AI has the potential to improve the quality and efficiency of education, its use can lead to unfairness among students. For example, some families may not be able to afford AI learning tools, or in certain areas, students may lack access to the necessary technological facilities for tools like ChatGPT. Educational equity is the cornerstone of social development, and interventions are needed to address the examples mentioned above effectively. For instance, when designing and optimizing LLMs, efforts should be made to balance characteristics such as race, gender, and age, reducing the digital divide and gender gap.\n\nData privacy and security [129]. Data privacy, including privacy protection, is a significant concern in the application of LLMs. LLMs involve collecting personal information and learning data from students and teachers. Therefore, privacy protection becomes an important issue in LLM applications. Educational institutions need to ensure the effective protection of student's and teacher's privacy while also ensuring the security and reliability of the data. Parents and teachers should focus on cultivating children's awareness of data privacy and security, as well as educating students to avoid privacy risks associated with the use of LLMs. Moreover, when collecting and processing student's\n\nlearning data, it is essential to ensure that this information is properly protected to avoid data breaches or improper use.\n\nIn the future, following the development characteristics of the era of integrating intelligence and education, while continuing to optimize core technologies and technological innovations, LLMs such as ChatGPT, GPT-4, and MathGPT will continue to empower the education field. Moreover, based on the existing LLMs, we must continue to look for more effective training methods to more efficiently train models with large-scale parameters [11].\n\n# 7. Conclusion\n\nIn this article, we have introduced the development and application of LLMs in the field of education as comprehensively as possible. There are still some technologies that have not been included, as well as other issues that have not been discussed in depth. It is hoped that the technology introduced in this article and the thinking presented can help scholars and researchers better develop and optimize educational LLMs. This article summarizes the process of integrating education and LLMs. LLMs have excellent language generation and interactive capabilities that cannot be provided by traditional book-based teaching. It demonstrates the creative role of AI in education, as well as teachers, and the changing roles of parents and students. For smart education, we call for more mature education and AI development standards, technical specifications, and data security guidelines to focus on more practical issues. How to ensure data security? How can we limit the behavior that relies too much on AI technology? How to cultivate students' active exploration abilities? LLMs and education complement each other. The application of LLMs in education makes education more intelligent and efficient, and the data accumulated over many years in education can help optimize LLM training. More attention should be paid to these development conditions. How can we create more valuable LLM.edu application scenarios? We look forward to the future of LLM.edu.\n\nAcknowledgments This research was supported in part by the National Natural Science Foundation of China (No. 62272196), the Natural Science Foundation of Guangdong Province (No. 2022A1515011861), Guangzhou Basic and Applied Basic Research Foundation (No. 2024A04J9971).\n\nAuthor contributions Hanyi Xu: paper reading and review, writing original draft. Wensheng Gan: conceptualization, review and editing, supervisor. Zhenlian Qi: conceptualization, review and editing. Jiayang Wu: writing original draft. Philip S. Yu: review and editing.\n\nData availability This is a review paper, and no data was generated during the study.\n\nConflict of interest The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n# References\n\n[1] Ahmad, N., Murugesan, S., Kshetri, N., 2023. Generative Artificial Intelligence and the Education Sector. Computer 56, 72-76.  \n[2] Al-Garaady, J., Mahyoob, M., 2023. ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners. Arab World English Journals.  \n[3] Amer-Yahia, S., Bonifati, A., Chen, L., Li, G., Shim, K., Xu, J., Yang, X., 2023. From Large Language Models to Databases and Back: A Discussion on Research and Education. ArXiv E-prints, arXiv:2306.01388.  \n[4] Amin, M.M., Cambria, E., Schuller, B.W., 2023. Will Affective Computing Emerge from Foundation Models and General AI? A First Evaluation on ChatGPT. ArXiv E-prints, arXiv:2303.03186.  \n[5] Bahrami, M., Srinivasan, R., 2023. Examining LLM's Awareness of the United Nations Sustainable Development Goals, in: ICLR Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models.  \n[6] Bai, K., Shrivastava, A., 2010. Heap Data Management for Limited Local Memory Multi-Core Processors, in: Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis, ACM. p. 317-326.  \n[7] Baidoo-Anu, D., Ansah, L.O., 2023. Education in the Era of Generative Artificial Intelligence: Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning. Journal of AI 7, 52-62.  \n[8] Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L., Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M., et al., 2022. Fine-tuning Language Models to Find Agreement among Humans with Diverse Preferences. Advances in Neural Information Processing Systems 35, 38176-38189.  \n[9] Bao, H., Dong, L., Wei, F., Wang, W., Yang, N., Liu, X., Wang, Y., Gao, J., Piao, S., Zhou, M., et al., 2020. UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 642–652.  \n[10] Beck, J., Stern, M., Haugsjaa, E., 1996. Applications of AI in Education. XRDS: Crossroads, The ACM Magazine for Students 3, 11-15.  \n[11] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S., 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?, in: ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623.  \n[12] Bhutoria, A., 2022. Personalized Education and Artificial Intelligence in the United States, China, and India: A Systematic Review Using A Human-in-the-loop Model. Computers and Education: Artificial Intelligence 3, 100068.  \n[13] Biggs, J., Tang, C., Kennedy, G., 2022. Ebook: Teaching for Quality Learning at University 5e. McGraw-hill education (UK).  \n[14] Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G.B., Lespiau, J.B., Damoc, B., Clark, A., et al., 2022. Improving Language Models by Retrieving from Trillions of Tokens, in: International Conference on Machine Learning, PMLR. pp. 2206-2240.  \n[15] Brem, A., Giones, F., Werle, M., 2021. The AI Digital Revolution in Innovation: A Conceptual Framework of Artificial Intelligence Technologies for the Management of Innovation. IEEE Transactions on Engineering Management 70, 770-776.  \n[16] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al., 2020. Language Models are Few-shot lLarners. Advances in Neural Information Processing Systems 33, 1877-1901.  \n[17] Budiharso, T., Tarman, B., 2020. Improving Quality Education through Better Working Conditions of Academic Institutes. Journal of Ethnic and Cultural Studies 7, 99-115.  \n[18] Bunnell, T., Courtois, A., Donnelly, M., 2020. British Elite Private Schools and Their Overseas Branches: Unexpected Actors in the Global Education Industry. British Journal of Educational Studies 68, 691-712.\n\n[19] Butcher, K.R., Sumner, T., 2011. Self-Directed Learning and the Sensemaking Paradox. Human-Computer Interaction 26, 123–159.  \n[20] Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K., Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., et al., 2023. A Survey on Evaluation of Large Language Models. ArXiv E-prints, arXiv:2307.03109.  \n[21] Chen, L., Chen, P., Lin, Z., 2020a. Artificial Intelligence in Education: A Review. IEEE Access 8, 75264-75278.  \n[22] Chen, X., Xie, H., Hwang, G.J., 2020b. A Multi-perspective Study on Artificial Intelligence in Education: Grants, Conferences, Journals, Software Tools, Institutions, and Researchers. Computers and Education: Artificial Intelligence 1, 100005.  \n[23] Chen, X., Xie, H., Zou, D., Hwang, G.J., 2020c. Application and Theory Gaps During the Rise of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence 1, 100002.  \n[24] Cheng, X., Jiao, F., Ji, G., Tian, Y., 2023. The Artificial Intelligence Revolution Led by ChatGPT, in: International Seminar on Computer Science and Engineering Technology, IEEE. pp. 360-363.  \n[25] Chung, Y.A., Zhang, Y., Han, W., Chiu, C.C., Qin, J., Pang, R., Wu, Y., 2021. W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-supervised Speech Pre-training, in: IEEE Automatic Speech Recognition and Understanding Workshop, IEEE. pp. 244-250.  \n[26] Deng, Y., Liu, X., Meng, L., Jiang, W., Dong, Y., Liu, C., 2023. Multi-Modal Information Fusion for Action Unit Detection in the Wild, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 5855–5862.  \n[27] DeRose, J.F., Wang, J., Berger, M., 2020. Attention flows: Analyzing and Comparing Attention Mechanisms in Language Models. IEEE Transactions on Visualization and Computer Graphics 27, 1160-1170.  \n[28] Dillenbourg, P., 2016. The Evolution of Research on Digital Education. International Journal of Artificial Intelligence in Education 26, 544-560.  \n[29] Dong, L., Jiang, F., Peng, Y., Wang, K., Yang, K., Pan, C., Schober, R., 2023. LAMBO: Large Language Model Empowered Edge Intelligence. ArXiv E-prints, arXiv:2308.15078.  \n[30] Edyko, K., Petryla, P., Ostafin, K., Minkner, M., Bienkowski, B., Feja, K., Suwała, Z., Rektor, N., Luczak, E., Marchewka, U., 2023. Utilizing Artificial Intelligence Tools Using the GPT Chatbot in Medicine-A Review of Flaws, Advantages, and Limitations. Journal of Education, Health and Sport 46, 122-133.  \n[31] Elnaggar, A., Heinzinger, M., Dallago, C., Rehawi, G., Wang, Y., Jones, L., Gibbs, T., Feher, T., Angerer, C., Steinegger, M., et al., 2021. ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 7112-7127.  \n[32] Fan, W., Zhao, Z., Li, J., Liu, Y., Mei, X., Wang, Y., Tang, J., Li, Q., 2023a. Recommender Systems in the Era of Large Language Models (LLMs). ArXiv E-prints, arXiv:2307.02046.  \n[33] Fan, Y., Jiang, F., Li, P., Li, H., 2023b. GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning, in: Natural Language Processing and Chinese Computing, Springer Nature Switzerland. pp. 69–80.  \n[34] Gan, W., Lin, J.C.W., Chao, H.C., Yu, P.S., 2023a. Discovering high utility episodes in sequences. IEEE Transactions on Artificial Intelligence 4, 473-486.  \n[35] Gan, W., Lin, J.C.W., Fournier-Viger, P., Chao, H.C., Tseng, V.S., Yu, P.S., 2021. A Survey of Utility-oriented Pattern Mining. IEEE Transactions on Knowledge and Data Engineering 33, 1306-1327.  \n[36] Gan, W., Qi, Z., Wu, J., Lin, J.C.W., 2023b. Large Language Models in Education: Vision and Opportunities, in: IEEE International Conference on Big Data, IEEE. pp. 4776-4785.  \n[37] Gan, W., Wan, S., Yu, P.S., 2023c. Model-as-a-Service (MaaS): A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 4636-4645.  \n[38] Gan, W., Ye, Z., Wan, S., Yu, P.S., 2023d. Web 3.0: The Future of Internet, in: Companion Proceedings of the ACM Web Conference,\n\npp. 1266-1275.  \n[39] Gao, B., Cai, K., Qu, T., Hu, Y., Chen, H., 2020. Personalized Adaptive Cruise Control Based on Online Driving Style Recognition Technology and Model Predictive Control. IEEE Transactions on Vehicular Technology 69, 12482-12496.  \n[40] Ghojogh, B., Ghodsi, A., 2020. Attention mechanism, transformers, bert, and gpt: tutorial and survey.  \n[41] Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., Poon, H., 2021. Domain-specific Language Model Pretraining for Biomedical Natural Language Processing. ACM Transactions on Computing for Healthcare 3, 1-23.  \n[42] Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M., 2020. Retrieval Augmented Language Model Pre-Training, in: International Conference on Machine Learning, PMLR. pp. 3929-3938.  \n[43] Han, J., Zhang, R., Shao, W., Gao, P., Xu, P., Xiao, H., Zhang, K., Liu, C., Wen, S., Guo, Z., et al., 2023. ImageBind-LLM: Multi-modality Instruction Tuning. ArXiv E-prints, arXiv:2309.03905.  \n[44] Han, J.M., Rute, J., Wu, Y., Ayers, E.W., Polu, S., 2021. Proof Artifact Co-training for Theorem Proving with Language Models. ArXiv E-prints, arXiv:2102.06203.  \n[45] Hawley, R., Allen, C., 2018. Student-generated Video Creation for Assessment: Can It Transform Assessment Within Higher Education? International Journal for Transformative Research 5, 1-11.  \n[46] Hsu, H.P., Wenting, Z., Hughes, J.E., 2019. Developing Elementary Students' Digital Literacy Through Augmented Reality Creation: Insights From a Longitudinal Analysis of Questionnaires, Interviews, and Projects. Journal of Educational Computing Research 57, 1400-1435.  \n[47] Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., Li, J., 2023. A Survey of Knowledge Enhanced Pre-trained Language Models. IEEE Transactions on Knowledge and Data Engineering, 1-19.  \n[48] Huang, G., Gan, W., Weng, J., Yu, P.S., 2023a. US-Rule: Discovering Utility-driven Sequential Rules. ACM Transactions on Knowledge Discovery from Data 17, 1-22.  \n[49] Huang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., Yin, H., Xu, C., Yang, R., Zheng, Q., et al., 2023b. ChatGPT for Shaping the Future of Dentistry: the Potential of Multi-modal Large Language Model. International Journal of Oral Science 15, 29.  \n[50] Huang, J., Chang, K.C.C., 2022. Towards Reasoning in Large Language Models: A Survey. ArXiv E-prints, arXiv:2212.10403.  \n[51] Huang, Y., Bai, Y., Zhu, Z., Zhang, J., Zhang, J., Su, T., Liu, J., Lv, C., Zhang, Y., Lei, J., et al., 2023c. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. ArXiv E-prints, arXiv:2305.08322.  \n[52] Ivanov, S., Soliman, M., 2023. Game of Algorithms: ChatGPT Implications for the Future of Tourism Education and Research. Journal of Tourism Futures 9, 214-221.  \n[53] Jeon, J., Lee, S., 2023. Large Language Models in Education: A Focus on the Complementary Relationship between Human Teachers and ChatGPT. Education and Information Technologies 28, 15873-15892.  \n[54] Kim, J.W., Yoon, H., Jung, H.Y., 2022. Improved Spoken Language Representation for Intent Understanding in a Task-Oriented Dialogue System. Sensors 22, 1509.  \n[55] Koksal, I., 2020. The Rise of Online Learning. FORBES.  \n[56] Kopnina, H., 2020. Education for the Future? Critical Evaluation of Education for Sustainable Development Goals. The Journal of Environmental Education 51, 280-291.  \n[57] Kotek, H., Dockum, R., Sun, D., 2023. Gender Bias and Stereotypes in Large Language Models, in: The ACM Collective Intelligence Conference, pp. 12-24.  \n[58] Lai, J., Gan, W., Wu, J., Qi, Z., Yu, P.S., 2023. Large Language Models in Law: A survey. arXiv preprint arXiv:2312.03718.  \n[59] Latif, E., Mai, G., Nyaaba, M., Wu, X., Liu, N., Lu, G., Li, S., Liu, T., Zhai, X., 2023. Artificial General Intelligence for Education. ArXiv E-prints, arXiv:2304.12479.  \n[60] Li, L., 2020. Education Supply Chain in the Era of Industry 4.0. Systems Research and Behavioral Science 37, 579-592.\n\n[61] Li, S., Challoo, R., 2006. Restructuring An Electric Machinery Course with An Integrative Approach and Computer-assisted Teaching Methodology. IEEE Transactions on Education 49, 16-28.  \n[62] Li, Y., Hu, B., Chen, X., Ma, L., Xu, Y., Zhang, M., 2023. LMEye: An Interactive Perception Network for Large Language Models. ArXiv E-prints, arXiv:2305.03701.  \n[63] Li, Y., Zhao, J., Zheng, D., Hu, Z.Y., Chen, Z., Su, X., Huang, Y., Huang, S., Lin, D., Lyu, M.R., et al., 2023. CLEVA: Chinese Language Models EVALuation Platform. ArXiv E-prints, arXiv:2308.04813.  \n[64] Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D., Yang, X., Vodrahalli, K., He, S., Smith, D., Yin, Y., McFarland, D., Zou, J., 2023. Can Large Language Models Provide Useful Feedback on Research Papers? A Large-scale Empirical Analysis. ArXiv E-prints, arXiv:2310.01783.  \n[65] Lim, J., Sa, I., MacDonald, B., Ahn, H.S., 2023. A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. ArXiv EA-prints, arXiv:2309.16898.  \n[66] Lin, H., Wan, S., Gan, W., Chen, J., Chao, H.C., 2022. Metaverse in Education: Vision, Opportunities, and Challenges, in: IEEE International Conference on Big Data, IEEE. pp. 2857-2866.  \n[67] Lin, J., Yang, A., Bai, J., Zhou, C., Jiang, L., Jia, X., Wang, A., Zhang, J., Li, Y., Lin, W., et al., 2021. M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining. ArXiv E-prints, arXiv:2110.03888.  \n[68] Lin, J.C.W., Gan, W., Fournier-Viger, P., Hong, T.P., 2015. Mining High-utility Itemsets with Multiple Minimum Utility Thresholds, in: The Eighth International C* Conference on Computer Science & Software Engineering, pp. 9-17.  \n[69] Liu, C., Jin, R., Ren, Y., Yu, L., Dong, T., Peng, X., Zhang, S., Peng, J., Zhang, P., Lyu, Q., et al., 2023. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. ArXiv E-prints, arXiv:2305.10263.  \n[70] Liu, H., Ning, R., Teng, Z., Liu, J., Zhou, Q., Zhang, Y., 2023. Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. ArXiv E-prints, arXiv:2304.03439.  \n[71] Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., He, H., Li, A., He, M., Liu, Z., et al., 2023. Summary of ChatGPT-Related Research and Perspective towards the Future of Large Language Models. Meta-Radiology 1, 100017.  \n[72] Luckin, R., Holmes, W., 2016. Intelligence Unleashed: An Argument for AI in Education.  \n[73] Lv, Z., Han, Y., Singh, A.K., Manogaran, G., Lv, H., 2020. Trustworthiness in Industrial IoT Systems Based on Artificial Intelligence. IEEE Transactions on Industrial Informatics 17, 1496-1504.  \n[74] Lyu, C., Xu, J., Wang, L., 2023. New Trends in Machine Translation using Large Language Models: Case Examples with ChatGPT. ArXiv E-prints, arXiv:2305.01181.  \n[75] Ma, X., Fang, G., Wang, X., 2023. LLM-Pruner: On the Structural Pruning of Large Language Models. ArXiv E-prints, arXiv:2305.11627.  \n[76] Maddigan, P., Susnjak, T., 2023. Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models. IEEE Access 11, 45181-45193.  \n[77] Malodia, S., Islam, N., Kaur, P., Dhir, A., 2021. Why Do People Use Artificial Intelligence-Enabled Voice Assistants? IEEE Transactions on Engineering Management, 1-15.  \n[78] Meng, Y., Zhang, Y., Huang, J., Xiong, C., Ji, H., Zhang, C., Han, J., 2020. Text Classification Using Label Names Only: A Language Model Self-Training Approach. ArXiv E-prints, arXiv:2010.07245.  \n[79] Mhlanga, D., 2023. Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, in: FinTech and Artificial Intelligence for Sustainable Development: The Role of Smart Technologies in Achieving Development Goals. Springer, pp. 387-409.  \n[80] Morales, E.F., Escalante, H.J., 2022. A Brief Introduction to Supervised, Unsupervised, and Reinforcement Learning, in: Biosignal Processing and Classification Using Computational Learning and\n\nIntelligence. Academic Press, pp. 111-129.  \n[81] Moura, L.d., Ullrich, S., 2021. The Lean 4 Theorem Prover and Programming Language, in: Automated Deduction - CADE 28, Springer International Publishing. pp. 625-635.  \n[82] Narayanan, D., Shoeybi, M., Casper, J., LeGresley, P., Patwary, M., Korthikanti, V., Vainbrand, D., Kashinkunti, P., Bernauer, J., Catanzaro, B., et al., 2021. Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM, in: The International Conference for High Performance Computing, Networking, Storage and Analysis, ACM. pp. 1-15.  \n[83] Naseem, U., Razzak, I., Khan, S.K., Prasad, M., 2021. A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models. Transactions on Asian and Low-Resource Language Information Processing 20, 1–35.  \n[84] Ng, E., Subramanian, S., Klein, D., Kanazawa, A., Darrell, T., Ginosar, S., 2023. Can Language Models Learn to Listen?, in: The IEEE/CVF International Conference on Computer Vision, pp. 10083-10093.  \n[85] Ouyang, F., Jiao, P., 2021. Artificial Intelligence in Education: The Three Paradigms. Computers and Education: Artificial Intelligence 2, 100020.  \n[86] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al., 2022. Training Language Models to Follow Instructions with Human Feedback. Advances in Neural Information Processing Systems 35, 27730-27744.  \n[87] P, D., 2020. AI in the Wild: Sustainability in the Age of Artificial Intelligence. MIT Press.  \n[88] Pan, S., Luo, L., Wang, Y., Chen, C., Wang, J., Wu, X., 2023. Unifying Large Language Models and Knowledge Graphs: A Roadmap. ArXiv E-prints, arXiv:2306.08302.  \n[89] Pankiewicz, M., Baker, R.S., 2023. Large Language Models (GPT) for Automating Feedback on Programming Assignments. ArXiv E-prints, arXiv:2307.00150.  \n[90] Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., Tulio Ribeiro, M., 2023. ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models. ArXiv E-prints, arXiv:2303.09014.  \n[91] Philippe, S., Souchet, A.D., Lameras, P., Petridis, P., Caporal, J., Coldeboeuf, G., Duzan, H., 2020. Multimodal Teaching, Learning and Training in Virtual Reality: A Review and Case Study. Virtual Reality & Intelligent Hardware 2, 421-442.  \n[92] Qidwai, U., Kashem, S.B.A., Conor, O., 2020. Humanoid Robot as a Teacher's Assistant: Helping Children with Autism to Learn Social and Academic Skills. Journal of Intelligent & Robotic Systems 98, 759-770.  \n[93] Rajbhandari, S., Rasley, J., Ruwase, O., He, Y., 2020. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, in: SC20: International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE. pp. 1-16.  \n[94] Rawte, V., Sheth, A., Das, A., 2023. A Survey of Hallucination in Large Foundation Models. ArXiv E-prints, arXiv:2309.05922.  \n[95] Rudovic, O., Zhang, M., Schuller, B., Picard, R., 2019. MultiModal Active Learning From Human Data: A Deep Reinforcement Learning Approach, in: International Conference on Multimodal Interaction, pp. 6-15.  \n[96] Saini, M.K., Goel, N., 2019. How Smart Are Smart Classrooms? A Review of Smart Classroom Technologies. ACM Computing Survey 52, 1-28.  \n[97] Scarlatos, A., Lan, A., 2023. Tree-Based Representation and Generation of Natural and Mathematical Language. ArXiv E-prints, arXiv:2302.07974.  \n[98] Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom, T., 2023. Toolformer: Language Models Can Teach Themselves to Use Tools. ArXiv Eprints, arXiv:2302.04761.\n\n[99] Schlecker Lamoureux, P., Winther, K.T., Garrido Torres, J.A., Streibel, V., Zhao, M., Bajdich, M., Abild-Pedersen, F., Bligaard, T., 2019. Machine Learning for Computational Heterogeneous Catalysis. ChemCatChem 11, 3581-3601.  \n[100] Schwartz, R., Dodge, J., Smith, N.A., Etzioni, O., 2020. Green AI. Communications of the ACM 63, 54-63.  \n[101] Srinivas Tida, V., Hsu, S., 2022. Universal Spam Detection using Transfer Learning of BERT Model. ArXiv E-prints, arXiv:2202.03480.  \n[102] Su, H.F.H., Ricci, F.A., Mnatsakanian, M., 2016. Mathematical Teaching Strategies: Pathways to Critical Thinking and Metacognition. International Journal of Research in Education and Science 2, 190–200.  \n[103] Sun, J., Gan, W., Chao, H.C., Yu, P.S., Ding, W., 2023. Internet of Behaviors: A Survey. IEEE Internet of Things Journal 10, 11117-11134.  \n[104] Tan, M., Le, Q., 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, in: The 36th International Conference on Machine Learning, PMLR. pp. 6105-6114.  \n[105] Tang, Y., Liang, J., Hare, R., Wang, F.Y., 2020. A Personalized Learning System for Parallel Intelligent Education. IEEE Transactions on Computational Social Systems 7, 352-361.  \n[106] Tao, S., Qiu, R., Ping, Y., Ma, H., 2021. Multi-modal Knowledge-aware Reinforcement Learning Network for Explainable Recommendation. Knowledge-Based Systems 227, 107217.  \n[107] Thirunavukarasu, A.J., Ting, D.S.J., Elangovan, K., Gutierrez, L., Tan, T.F., Ting, D.S.W., 2023. Large language models in medicine. Nature Medicine 29, 1930-1940.  \n[108] Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.T., Jin, A., Bos, T., Baker, L., Du, Y., et al., 2022. Language Models for Dialog Applications. arXiv preprint, arXiv:2201.08239.  \n[109] Tirumala, K., Markosyan, A., Zettlemoyer, L., Aghajanyan, A., 2022. Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models. Advances in Neural Information Processing Systems 35, 38274-38290.  \n[110] Valverde Valencia, Å., 2023. An Interdisciplinary and Applied Approach to Generative Artificial Intelligence in Secondary School for the Development of Communicative Competencies.  \n[111] Wang, C.X., Di Renzo, M., Stanczak, S., Wang, S., Larsson, E.G., 2020a. Artificial Intelligence Enabled Wireless Networking for 5G and Beyond: Recent Advances and Future Challenge. IEEE Wireless Communications 27, 16-23.  \n[112] Wang, D., Weisz, J.D., Muller, M., Ram, P., Geyer, W., Dugan, C., Tausczik, Y., Samulowitz, H., Gray, A., 2019. Human-AI Collaboration in Data Science: Exploring Data Scientists' Perceptions of Automated AI. The ACM on Human-Computer Interaction 3, 1–24.  \n[113] Wang, H., Yeung, D.Y., 2020. A Survey on Bayesian Deep Learning. ACM Computing Survey 53, 1-37.  \n[114] Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., Zhou, M., 2020b. MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. Advances in Neural Information Processing Systems 33, 5776–5788.  \n[115] Wang, Y., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y., Gu, J., Xue, S., Zhang, J.Y., Cui, Q., et al., 2023. Enhancing Recommender Systems with Large Language Model Reasoning Graphs. ArXiv E-prints, arXiv:2308.10835.  \n[116] Wei, J., Bosma, M., Zhao, V.Y., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M., Le, Q.V., 2021. Finetuned Language Models Are Zero-Shot Learners. ArXiv E-prints, arXiv:2109.01652.  \n[117] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al., 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824-24837.  \n[118] Williamson, B., Macgilchrist, F., Potter, J., 2023. Re-examining AI, Automation and Datafication in Education. Learning, Media and Technology 48, 1-5.\n\n[119] Wu, J., Gan, W., Chen, Z., Wan, S., Lin, H., 2023a. AI-Generated Content (AIGC): A Survey. arXiv preprint arXiv:2304.06632.  \n[120] Wu, J., Gan, W., Chen, Z., Wan, S., Yu, P.S., 2023b. Multimodal Large Language Models: A Survey, in: IEEE International Conference on Big Data, IEEE. pp. 2247-2256.  \n[121] Wu, T., Zhu, B., Zhang, R., Wen, Z., Ramchandran, K., Jiao, J., 2023c. Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment. arXiv preprint arXiv:2310.00212.  \n[122] Xie, H., Qin, Z., Li, G. Y., Juang, B. H., 2021. Deep Learning Enabled Semantic Communication Systems. IEEE Transactions on Signal Processing 69, 2663-2675.  \n[123] Xu, H., 2023. No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. ArXiv E-prints, arXiv:2309.03224.  \n[124] Xu, L., Li, A., Zhu, L., Xue, H., Zhu, C., Zhao, K., He, H., Zhang, X., Kang, Q., Lan, Z., 2023. SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. ArXiv E-prints, arXiv:2307.15020.  \n[125] Yan, K., Cai, J., Jin, D., Miao, S., Guo, D., Harrison, A.P., Tang, Y., Xiao, J., Lu, J., Lu, L., 2022. Self-Supervised Learning of Pixel-Wise Anatomical Embeddings in Radiological Images. IEEE Transactions on Medical Imaging 41, 2658-2669.  \n[126] Yan, L., Sha, L., Zhao, L., Li, Y., Martinez-Maldonado, R., Chen, G., Li, X., Jin, Y., Gašević, D., 2024. Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review. British Journal of Educational Technology 55, 90-112.  \n[127] Yang, R., Li, L., Gan, W., Chen, Z., Qi, Z., 2023. The Human-centric Metaverse: A Survey, in: Companion Proceedings of the ACM Web Conference, pp. 1296-1306.  \n[128] Yang, W., Li, H., 2019. Changing Culture, Changing Curriculum: A Case Study of Early Childhood Curriculum Innovations in Two Chinese Kindergartens. The Curriculum Journal 30, 279–297.  \n[129] Yu, Z., Wu, Y., Zhang, N., Wang, C., Vorobeychik, Y., Xiao, C., 2023. CodeIPPrompt: Intellectual Property Infringement Assessment of Code Language Models, in: International Conference on Machine Learning, PMLR. pp. 40373-40389.  \n[130] Zamfirescu-Pereira, J., Wong, R.Y., Hartmann, B., Yang, Q., 2023. Why Johnny Can't Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts, in: CHI Conference on Human Factors in Computing Systems, Curran Associates, Inc.. pp. 1-21.  \n[131] Zeng, F., Gan, W., Wang, Y., Liu, N., Yu, P.S., 2023a. Large Language Models for Robotics: A Survey. arXiv preprint arXiv:2311.07226.  \n[132] Zeng, F., Gan, W., Wang, Y., Yu, P.S., 2023b. Distributed Training of Large Language Models, in: IEEE 29th International Conference on Parallel and Distributed Systems, IEEE. pp. 840-847.  \n[133] Zeng, H., 2023. Measuring Massive Multitask Chinese Understanding. ArXiv E-prints, arXiv:2304.12986.  \n[134] Zeng, Y., Mahmud, T., 2023. ChatGPT in English Class: Perspectives of Students and Teachers from Swedish Upper Secondary Schools.  \n[135] Zhang, C., Dai, Q., Du, Z., Gan, W., Weng, J., Yu, P.S., 2023a. TUSQ: Targeted High-Utility Sequence Querying. IEEE Transactions on Big Data 9, 512–527.  \n[136] Zhang, C., Zhang, C., Zheng, S., Qiao, Y., Li, C., Zhang, M., Dam, S.K., Thwal, C.M., Tun, Y.L., Huy, L.L., et al., 2023b. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need? ArXiv E-prints, arXiv:2303.11717.  \n[137] Zhang, M., Li, J., 2021. A Commentary of GPT-3 in MIT Technology Review. Fundamental Research 1, 831–833.  \n[138] Zhao, L., 2022. A Study on Data-Driven Teaching Decision Optimization of Distance Education Platforms. International Journal of Emerging Technologies in Learning 17.  \n[139] Zhao, S., Blaabjerg, F., Wang, H., 2020. An Overview of Artificial Intelligence Applications for Power Electronics. IEEE Transactions on Power Electronics 36, 4633-4658.  \n[140] Zheng, R., Dou, S., Gao, S., Shen, W., Wang, B., Liu, Y., Jin, S., Liu, Q., Xiong, L., Chen, L., et al., 2023. Secrets of RLHF in Large\n\nLanguage Models Part I: PPO. ArXiv E-prints, arXiv:2307.04964.  \n[141] Zhipeng, G., Yi, X., Sun, M., Li, W., Yang, C., Liang, J., Chen, H., Zhang, Y., Li, R., 2019. Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System, 25-30.  \n[142] Zhong, W., Cui, R., Guo, Y., Liang, Y., Lu, S., Wang, Y., Saied, A., Chen, W., Duan, N., 2023. AGIEval: A Human-centric Benchmark for Evaluating Foundation Models. ArXiv E-prints, arXiv:2304.06364.  \n[143] Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D., 2021. Pre-Trained Language Model Based Ranking in Baidu Search, in: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, ACM. pp. 4014-4022.",
    "arxiv_id": "2405.13001",
    "error_message": null,
    "embedding": [
      0.671875,
      -2,
      -1.1484375,
      -2.703125,
      -0.2734375,
      1.1484375,
      -1.9296875,
      -2.484375,
      -0.828125,
      2.390625,
      2.4375,
      2.421875,
      2.46875,
      2.546875,
      0.76953125,
      3.328125,
      -1.765625,
      -0.490234375,
      1.765625,
      -5.78125,
      -0.1318359375,
      0.9921875,
      0.578125,
      -4.90625,
      4.5625,
      -7.1875,
      -3.234375,
      4.21875,
      1.9609375,
      0.5625,
      8.125,
      -3.953125,
      0.173828125,
      0.49609375,
      -1.09375,
      0.26953125,
      -2.5,
      -1.15625,
      4.21875,
      3.453125,
      -7.15625,
      1.8125,
      0.197265625,
      5.15625,
      -0.11962890625,
      3.109375,
      0.86328125,
      0.59765625,
      -6.78125,
      -1.671875,
      -5,
      -1.6484375,
      7.53125,
      0.15234375,
      3.203125,
      -3.1875,
      -5.6875,
      5.28125,
      -3.9375,
      -0.384765625,
      1.8671875,
      0.30078125,
      0.447265625,
      -1.125,
      5.5,
      3.046875,
      0.53515625,
      0.73828125,
      -2.109375,
      2.09375,
      0.96484375,
      2.546875,
      5.5625,
      -3.859375,
      7.78125,
      6.78125,
      3.484375,
      2.546875,
      -2.34375,
      3.59375,
      -5.875,
      5.4375,
      5.15625,
      -1.359375,
      5.09375,
      2.984375,
      1.328125,
      0.091796875,
      -2.734375,
      1.359375,
      -0.39453125,
      0.60546875,
      -4.8125,
      0.357421875,
      -3.5625,
      4.6875,
      -1.28125,
      -3.1875,
      -5.84375,
      0.61328125,
      -2.203125,
      -0.859375,
      0.3203125,
      -7,
      -4.53125,
      -3.78125,
      -3.671875,
      -6.96875,
      0.06591796875,
      -1.875,
      -0.1884765625,
      3.140625,
      1.25,
      -2.390625,
      4.8125,
      -0.0281982421875,
      1.0859375,
      -3.234375,
      -5.46875,
      -1.1796875,
      1.1484375,
      -0.224609375,
      -1.6796875,
      0.9921875,
      2.5,
      1.6875,
      -4.25,
      3.28125,
      6.53125,
      -3.4375,
      4.65625,
      -0.052490234375,
      5.125,
      -2.390625,
      -8.9375,
      -1.6796875,
      -5.125,
      3.46875,
      1.1875,
      3.9375,
      -5.53125,
      -1.03125,
      -2.484375,
      -7.875,
      2.59375,
      1.6875,
      -7.375,
      -1.2890625,
      3.625,
      -4.15625,
      0.380859375,
      1.0703125,
      0.96484375,
      7.9375,
      0.171875,
      -2.84375,
      2.296875,
      1.7265625,
      0.51171875,
      -2.03125,
      -0.0166015625,
      2.703125,
      0.099609375,
      0.6796875,
      -0.0152587890625,
      -0.8046875,
      -5.3125,
      1.1171875,
      0.80859375,
      -1.0703125,
      0.96484375,
      15.125,
      1.296875,
      -1.890625,
      1.65625,
      0.70703125,
      -1.25,
      9.625,
      2.265625,
      0.427734375,
      0.89453125,
      2.0625,
      -3.234375,
      3.78125,
      -1.3828125,
      1.5078125,
      3.0625,
      -3.90625,
      2.0625,
      -2.0625,
      0.466796875,
      4.46875,
      4.53125,
      1.1796875,
      -4.5625,
      0.828125,
      4.5625,
      -1.234375,
      0.006561279296875,
      1.5703125,
      -1.1640625,
      -10.4375,
      -0.71875,
      -1.90625,
      -5.8125,
      -2.203125,
      1.1953125,
      -4.46875,
      1.1875,
      -1.2734375,
      -1.015625,
      2.125,
      2.546875,
      -0.3125,
      7.34375,
      2.359375,
      2.25,
      -2.53125,
      4.59375,
      1.0078125,
      4.28125,
      4.875,
      2.625,
      0.40234375,
      -0.1796875,
      2.109375,
      2.9375,
      3.015625,
      2.046875,
      8.125,
      -0.25390625,
      4.15625,
      4.6875,
      -4.40625,
      -3.4375,
      -0.93359375,
      -4.25,
      -0.54296875,
      -2.453125,
      1.7109375,
      -3.5,
      -4.03125,
      0.1982421875,
      2.953125,
      1.3984375,
      -0.83203125,
      -0.5234375,
      -2.046875,
      0.462890625,
      -8.3125,
      0.2353515625,
      4.25,
      -9.8125,
      -3.5625,
      4.65625,
      6.875,
      0.87890625,
      -0.26953125,
      0.78515625,
      -4.96875,
      3.125,
      -2.1875,
      -5.3125,
      1.890625,
      0.79296875,
      -4.0625,
      4.15625,
      0.6015625,
      1.671875,
      3.140625,
      1.2265625,
      0.9921875,
      -4.4375,
      1.65625,
      -3.484375,
      4.65625,
      2.171875,
      -3.828125,
      0.93359375,
      -2.296875,
      -6.9375,
      -9.4375,
      4.03125,
      -4,
      2.46875,
      -0.78515625,
      -0.72265625,
      6.15625,
      -2.21875,
      12.625,
      1.5,
      1.703125,
      0.734375,
      0.0172119140625,
      -1.90625,
      1.1328125,
      -1.484375,
      0.1708984375,
      -4.75,
      1.390625,
      4.3125,
      -0.2451171875,
      -1.7265625,
      -2.75,
      -0.1435546875,
      2.5,
      -0.984375,
      -4.28125,
      1.328125,
      4.53125,
      0.298828125,
      1.46875,
      5.28125,
      -3.765625,
      3.484375,
      -4.46875,
      -2.9375,
      3.46875,
      2.03125,
      -2.421875,
      -7.375,
      -3.828125,
      -2.21875,
      -2.640625,
      -2.640625,
      -4.46875,
      1.484375,
      -0.0869140625,
      5.625,
      2.140625,
      1.5234375,
      0.625,
      -6.4375,
      -8.25,
      6.84375,
      -3.703125,
      3.34375,
      1.546875,
      -0.76171875,
      2.640625,
      -0.36328125,
      -1.671875,
      1.3359375,
      -3.75,
      -2.078125,
      -0.51953125,
      4.90625,
      -1.5703125,
      3.21875,
      -6.40625,
      4.75,
      2.890625,
      1.40625,
      4.21875,
      7.40625,
      -1.390625,
      2.3125,
      -1.84375,
      -1.7265625,
      1.2421875,
      0.482421875,
      -3.25,
      7.59375,
      0.2060546875,
      -2.609375,
      -3.875,
      -2.875,
      2.625,
      -0.85546875,
      -1.25,
      -2.234375,
      -2.359375,
      0.8984375,
      3.3125,
      0.703125,
      1.6875,
      1.7890625,
      -3.28125,
      -4.1875,
      2.25,
      -1.484375,
      1.578125,
      -0.2265625,
      3.484375,
      4.25,
      1.4296875,
      -0.87890625,
      5.09375,
      1.40625,
      -3.484375,
      -2.046875,
      0.87109375,
      -3.609375,
      1.4765625,
      4.1875,
      1.09375,
      -2.171875,
      2.203125,
      -0.58984375,
      -3.6875,
      4.59375,
      -1.3828125,
      -0.3359375,
      -1.703125,
      -1.8984375,
      -1.4140625,
      2.28125,
      -7.25,
      1.4609375,
      -0.384765625,
      -1.2421875,
      1.0859375,
      -1.046875,
      2.359375,
      -0.6796875,
      4.40625,
      -2.765625,
      1.875,
      -7.53125,
      -0.765625,
      -3.515625,
      -2.078125,
      1.6484375,
      -1.765625,
      1.734375,
      -0.04931640625,
      0.32421875,
      4.6875,
      2.1875,
      0.154296875,
      -0.0888671875,
      1.9296875,
      -3.984375,
      1.1640625,
      -0.703125,
      -5.90625,
      1.1640625,
      -5.125,
      -4.8125,
      2.6875,
      3.359375,
      -0.1376953125,
      6.65625,
      4.65625,
      -2.546875,
      -3.34375,
      2.046875,
      2.625,
      -4.5625,
      -2.375,
      1.6328125,
      -1.453125,
      0.6484375,
      -0.65625,
      2.96875,
      0.353515625,
      -1.828125,
      2.84375,
      0.94140625,
      0.0146484375,
      0.8359375,
      -1.28125,
      0.515625,
      1.4375,
      1.5390625,
      1.1640625,
      -2.671875,
      6.25,
      6.65625,
      -6.65625,
      -8.4375,
      2.609375,
      0.6875,
      -1.7421875,
      -1.390625,
      3.328125,
      1.5546875,
      0.486328125,
      -5.5,
      -4.96875,
      -1.53125,
      -0.83984375,
      4.625,
      3.0625,
      0.283203125,
      -3.390625,
      -3.8125,
      4.53125,
      -2.390625,
      4.15625,
      0.271484375,
      -1.4765625,
      0.62890625,
      -4.03125,
      4.90625,
      0.765625,
      5.71875,
      -4.6875,
      -0.41015625,
      3.5,
      -9.375,
      -0.43359375,
      -3.171875,
      -0.1318359375,
      -0.5859375,
      -0.455078125,
      5.125,
      -3.640625,
      0.1533203125,
      0.79296875,
      5.96875,
      -2.390625,
      -0.93359375,
      2.5,
      -7.09375,
      -2.34375,
      1.0703125,
      2.4375,
      2.53125,
      -1.9375,
      -4.84375,
      0.353515625,
      -0.212890625,
      -0.5234375,
      -2.25,
      -1.0390625,
      -3.25,
      -1.9296875,
      1.6015625,
      3.671875,
      2.234375,
      0.2060546875,
      -0.8515625,
      -3.703125,
      -2.578125,
      -0.98828125,
      1.5234375,
      -0.357421875,
      1.234375,
      0.333984375,
      2.6875,
      3.421875,
      -2.546875,
      -1.484375,
      -1.28125,
      3.203125,
      -2.875,
      1.6953125,
      0.55078125,
      1.921875,
      3.375,
      2.078125,
      -1.3515625,
      -1.59375,
      0.6875,
      -1.8515625,
      -4.65625,
      -1.453125,
      4.6875,
      -0.78515625,
      0.00689697265625,
      -4.90625,
      0.76953125,
      0.71484375,
      1.8984375,
      -0.70703125,
      0.10595703125,
      6.21875,
      1.28125,
      0.255859375,
      2.203125,
      5.8125,
      -2.34375,
      0.68359375,
      0.57421875,
      1.171875,
      -7.21875,
      -7.4375,
      -3.734375,
      3.578125,
      8.4375,
      -0.1181640625,
      5.15625,
      -5.03125,
      4.84375,
      0.2890625,
      0.2412109375,
      -14.6875,
      2.515625,
      0.8203125,
      -5.71875,
      -2.625,
      0.111328125,
      4.71875,
      -0.91015625,
      4.03125,
      -0.91015625,
      -0.99609375,
      1.3828125,
      3.96875,
      -1.0078125,
      -2.234375,
      6.09375,
      3.828125,
      -3.59375,
      2.46875,
      -1.8046875,
      -4.9375,
      0.30078125,
      0.09619140625,
      2.671875,
      4.09375,
      6.875,
      -0.392578125,
      1.1640625,
      4.25,
      -4.8125,
      -0.404296875,
      1.4921875,
      0.8125,
      -2.90625,
      1.6484375,
      -5.65625,
      1.3046875,
      -3.78125,
      1.0859375,
      0.053466796875,
      -3.046875,
      0.1689453125,
      4.15625,
      -1.921875,
      -1.7734375,
      -1.3515625,
      1.328125,
      3.140625,
      5.625,
      -6.5625,
      0.91015625,
      0.4921875,
      0.255859375,
      2.609375,
      -2.203125,
      -0.75390625,
      -3.203125,
      3.03125,
      1.03125,
      -2.703125,
      5.03125,
      -0.734375,
      -5.375,
      3.125,
      0.60546875,
      -1.171875,
      -0.0625,
      3.09375,
      0.265625,
      0.09521484375,
      -0.390625,
      2.203125,
      1.1328125,
      -3.9375,
      -2.890625,
      -0.76171875,
      -2.34375,
      3.890625,
      -0.9609375,
      -2.9375,
      -3.28125,
      -4.0625,
      1.2890625,
      1.8828125,
      3.078125,
      1.125,
      2.25,
      3.203125,
      -4.5,
      0.5,
      -4.71875,
      -3.90625,
      1.2734375,
      -3.59375,
      -2.015625,
      0.9453125,
      1.0390625,
      2.171875,
      -1.1640625,
      -1.53125,
      -3.75,
      -4.40625,
      -2.1875,
      1.2109375,
      1.3359375,
      2.234375,
      -1.109375,
      6.125,
      -0.62890625,
      -2.796875,
      0.12255859375,
      -1.40625,
      -0.146484375,
      -1.015625,
      1.3671875,
      -5.625,
      -0.66015625,
      5.875,
      1.375,
      -3.328125,
      6.25,
      -0.58984375,
      -0.9921875,
      -1.7578125,
      2.703125,
      -0.5078125,
      -0.474609375,
      0.8046875,
      -3.90625,
      -2.765625,
      -3.8125,
      -0.032470703125,
      -1.3203125,
      3.28125,
      0.56640625,
      0.70703125,
      -0.96484375,
      -7.875,
      2.84375,
      0.2236328125,
      -0.349609375,
      2.375,
      5.84375,
      -0.65625,
      -1.2421875,
      2.515625,
      0.74609375,
      -0.79296875,
      -0.8671875,
      -4.0625,
      4.375,
      2.328125,
      3.765625,
      -3.96875,
      -6.3125,
      -0.3671875,
      -1.09375,
      -1.6640625,
      4.625,
      -0.6875,
      -0.392578125,
      5.34375,
      2.484375,
      -4.90625,
      -2.125,
      5.4375,
      -3.796875,
      0.984375,
      2.34375,
      2.828125,
      0.408203125,
      4.21875,
      -1.6953125,
      -2.84375,
      -0.921875,
      5.75,
      2.890625,
      -1.109375,
      -0.76171875,
      3.859375,
      0.2421875,
      4.46875,
      -6,
      -5.15625,
      0.90625,
      0.90625,
      -1.984375,
      0.021484375,
      6.4375,
      -1.84375,
      0.181640625,
      0.470703125,
      -0.1884765625,
      3.375,
      1.3828125,
      1.0390625,
      0.1123046875,
      1.703125,
      1.484375,
      0.84765625,
      1.9453125,
      -1.1953125,
      -0.330078125,
      -1.1640625,
      0.408203125,
      -1.9296875,
      3.5625,
      -3.78125,
      0.6328125,
      -1.609375,
      3.765625,
      -0.265625,
      5.75,
      5.09375,
      0.07177734375,
      0.54296875,
      -0.84375,
      6.875,
      -1.6015625,
      6.53125,
      1.3671875,
      8.5,
      -2.359375,
      -3.625,
      1.4296875,
      0.1787109375,
      -0.98046875,
      0.87890625,
      -6.9375,
      -1.9296875,
      -1.375,
      -0.11474609375,
      -0.82421875,
      2.796875,
      -5.15625,
      -0.8046875,
      3.265625,
      3.671875,
      3.890625,
      2.90625,
      4.84375,
      0.9296875,
      0.80859375,
      -3.15625,
      -1.828125,
      0.466796875,
      0.5390625,
      3.578125,
      -4.03125,
      0.984375,
      1.546875,
      5.40625,
      -0.055908203125,
      -3.140625,
      -3.234375,
      7.375,
      2.15625,
      -2.296875,
      1.8671875,
      -1.6015625,
      0.94921875,
      0.984375,
      3.875,
      -5.625,
      -3.0625,
      6.75,
      5.03125,
      -0.828125,
      3.265625,
      0.09033203125,
      2.171875,
      -3.46875,
      -0.9296875,
      0.03173828125,
      -0.054931640625,
      -4.15625,
      -3,
      0.62890625,
      3.96875,
      -4.78125,
      1.9765625,
      0.96875,
      -2.75,
      2.328125,
      1.0625,
      -2.234375,
      1.6640625,
      0.2314453125,
      6.75,
      0.5234375,
      -5.8125,
      -4.59375,
      -7.34375,
      -3.96875,
      0.208984375,
      2.125,
      2.796875,
      2.15625,
      -3.375,
      2.65625,
      -5.1875,
      -1.1171875,
      -4.78125,
      3.6875,
      3.59375,
      -4.75,
      -2.5,
      -2,
      -7.875,
      -3.8125,
      -0.94921875,
      -1.34375,
      -2.609375,
      -5.625,
      -2.015625,
      2.453125,
      -5.03125,
      -1,
      -2.03125,
      -1.25,
      4.28125,
      -0.296875,
      0.74609375,
      -4.5625,
      4.875,
      1.71875,
      -2.296875,
      5.3125,
      1.953125,
      2.6875,
      2.15625,
      0.1494140625,
      -0.11669921875,
      -4.71875,
      4.09375,
      -1.5390625,
      9.0625,
      4.09375,
      1.875,
      -4.65625,
      4.3125,
      1.84375,
      1.4921875,
      -4.46875,
      -0.76953125,
      -2.5,
      2.234375,
      1.671875,
      -1.203125,
      2.34375,
      -2.578125,
      -1.5,
      0.859375,
      -2.390625,
      -0.46484375,
      3.25,
      -0.01519775390625,
      4.375,
      1.6171875,
      0.482421875,
      0.1728515625,
      0.2216796875,
      1.6875,
      -0.51953125,
      5.8125,
      -5.125,
      2.359375,
      -5.3125,
      -0.96875,
      0.78125,
      -1.1796875,
      -0.69140625,
      -0.41015625,
      -0.30078125,
      1.765625,
      2.828125,
      1.6953125,
      1.1015625,
      4.78125,
      -2.765625,
      -0.09423828125,
      0.72265625,
      -2.421875,
      4.9375,
      -0.0634765625,
      -1.0234375,
      -0.8359375,
      -0.7890625,
      -0.310546875,
      1.28125,
      0.85546875,
      -7.90625,
      -1.3828125,
      -1.296875,
      -4.1875,
      7.09375,
      0.921875,
      -0.73828125,
      1.4453125,
      4.0625,
      6.21875,
      3.765625,
      -0.92578125,
      -1.109375,
      -0.25,
      -2.265625,
      3.875,
      -2.15625,
      -0.65234375,
      4.34375,
      3.84375,
      3.546875,
      -0.9453125,
      -0.62109375,
      -2.796875,
      0.1015625,
      4.90625,
      -1.765625,
      -1.0546875,
      6.6875,
      -2.90625,
      0.12353515625,
      -2.015625,
      -2.59375,
      -1.9296875,
      -1.6328125,
      2.671875,
      2.25,
      2.4375,
      -2.046875,
      -2.53125,
      -7.71875,
      1.9453125,
      -0.1533203125,
      -0.984375,
      -1.171875,
      1.6875,
      -0.2138671875,
      1.4921875,
      -2.078125,
      -2.0625,
      -0.302734375,
      -3.859375,
      -0.0361328125,
      2.765625,
      0.0966796875,
      1.3828125,
      -0.341796875,
      2.84375,
      -2.140625,
      2.484375,
      3.828125,
      -5.625,
      2.140625,
      0.90234375,
      -1.71875,
      3.6875,
      1.9765625,
      1.4140625,
      2.734375,
      -1.2578125,
      0.78125,
      -0.44921875,
      -1.734375,
      1.0625,
      -3,
      0.5859375,
      1.8984375,
      3.375,
      -2.34375,
      3.09375,
      0.8515625,
      -4.34375,
      3.6875,
      -3.59375,
      -7.15625,
      -1.046875,
      0.033935546875,
      -0.8828125,
      -1.4140625,
      -2.3125,
      1.2265625,
      2.671875,
      -7.375,
      5.6875,
      -1.5390625,
      5.4375,
      2.734375,
      -1.0625,
      -2.8125,
      0.69140625,
      2.234375,
      -1.5703125,
      2.28125,
      1.6484375,
      -1.765625,
      3.984375,
      -3.34375,
      1.3984375,
      -0.95703125,
      0.55859375,
      3.21875,
      -1.0703125,
      0.86328125,
      -0.134765625,
      1.0546875,
      -9.5625,
      -3.4375,
      -1.9765625,
      -0.353515625,
      1.9375,
      -0.6015625,
      2.3125,
      -2.859375,
      2.53125,
      -4.03125,
      2.984375,
      -5.1875,
      -3.171875,
      1.7109375,
      -1.9453125,
      4.53125,
      2.109375,
      -2.3125,
      0.205078125,
      0.359375,
      -4.46875,
      -2.140625,
      -2.6875,
      0.02392578125,
      -3.09375,
      -1.9296875,
      -0.35546875,
      2.84375,
      -0.2001953125,
      1.84375,
      -0.875,
      3.140625,
      4.09375,
      -0.59375,
      3.015625,
      0.5078125,
      0.54296875,
      -3.125,
      -4.28125,
      -4.53125,
      2.078125,
      3.71875,
      -3.203125,
      2.46875,
      -0.96875,
      2,
      2,
      -0.83984375,
      -0.15625,
      1.1328125,
      1.859375,
      -0.71484375,
      -2.03125,
      2.5,
      -1.421875,
      1.890625,
      -2.203125,
      -4.1875,
      -4.1875,
      -0.1484375,
      0.953125,
      0.220703125,
      0.9921875,
      -1.046875,
      -1.7421875,
      -1.1875,
      -4.25,
      -2.6875,
      4.875,
      0.58984375,
      5.25,
      0.60546875,
      1.171875,
      -3.078125,
      -1.1953125,
      -1.375,
      6,
      0.7578125,
      -2.75,
      3.953125,
      -2.15625,
      5.4375,
      -2.09375,
      -1.78125,
      -9.1875,
      -1.90625,
      7.125,
      2.109375,
      -0.61328125,
      1.2578125,
      0.337890625,
      2.359375,
      -0.026611328125,
      5.40625,
      -3.140625,
      -1.5546875,
      -0.296875,
      3.578125,
      1.765625,
      -5.53125,
      0.62109375,
      1.9140625,
      -1.5078125,
      1.6015625,
      5.6875,
      5.78125,
      -2.140625,
      3.421875,
      -4,
      -2.859375,
      -4.78125,
      4.15625,
      -0.7109375,
      -0.765625,
      -1.71875,
      -3.1875,
      -0.271484375,
      -1.4921875,
      0.26953125,
      7.28125,
      -4.4375,
      2.609375,
      -0.8984375,
      4.09375,
      0.90234375,
      -0.98046875,
      -0.84375,
      2.859375,
      2.671875,
      -1.03125,
      -1.1640625,
      -5.9375,
      -1.875,
      -0.59765625,
      -7.34375,
      1.9765625,
      1.734375,
      0.99609375,
      2.265625,
      -1.84375,
      2.25,
      3.15625,
      -2.515625,
      -0.80859375,
      -2.140625,
      2.8125,
      4.6875,
      1.5,
      -2.859375,
      1.2265625,
      -0.9765625,
      -0.33203125,
      -5.09375,
      3.09375,
      -1.828125,
      4.28125,
      3,
      3.078125,
      -4.125,
      -4.28125,
      -3.234375,
      -1.6640625,
      -3.78125,
      1.15625,
      0.064453125,
      1.6171875,
      3.734375,
      -0.080078125,
      -3.546875,
      -1.3828125,
      -3.90625,
      1.515625,
      -0.5625,
      1.5078125,
      -6.8125,
      2.46875,
      -6.40625,
      0.6640625,
      1.3359375,
      -3.140625,
      0.2412109375,
      3.453125,
      1.9140625,
      2.265625,
      3.765625,
      -1.5703125,
      -3.484375,
      3.5,
      -3.921875,
      -2,
      -5,
      0.275390625,
      -0.369140625,
      -4.21875,
      3.203125,
      -2.890625,
      2.265625,
      -2.4375,
      -2.96875,
      0.341796875,
      -1.09375,
      -0.5390625,
      3.515625,
      2.125,
      -2.34375,
      1.7890625,
      -1.0390625,
      5.84375,
      2.640625,
      -2.40625,
      1.6875,
      -0.33984375,
      1.7109375,
      -6.09375,
      4.25,
      0.68359375,
      -1.4375,
      3.296875,
      5.125,
      -3.234375,
      1,
      2.234375,
      5.75,
      -2.703125,
      -1.3515625,
      0.4140625,
      4.71875,
      -3.96875,
      -0.002166748046875,
      -4.09375,
      0.01531982421875,
      1.53125,
      -1.6953125,
      5.03125,
      -1.734375,
      3.8125,
      -5.0625,
      0.33203125,
      1.296875,
      1.328125,
      2.9375,
      -5.25,
      3.890625,
      2.375,
      -1.3984375,
      5.09375,
      -0.75,
      -5.46875,
      -2.28125,
      2.171875,
      -4.625,
      -3.03125,
      -5.09375,
      0.0400390625,
      -2.40625,
      -1.6796875,
      -0.7109375,
      0.37109375,
      1.09375,
      2.515625,
      -1.671875,
      -1.5546875,
      -3.109375,
      -4.375,
      1.171875,
      -2.015625,
      -6.6875,
      -0.400390625,
      2.15625,
      3.296875,
      5.53125,
      7.625,
      3.09375,
      -4.34375,
      2.640625,
      -1.515625,
      1.2265625,
      -0.09912109375,
      -0.1328125,
      -0.54296875,
      -2.921875,
      2.65625,
      0.828125,
      3.484375,
      -6.90625,
      -0.7890625,
      -4.71875,
      -1.15625,
      -0.212890625,
      0.193359375,
      -0.1796875,
      2.390625,
      4.875,
      -2.4375,
      3.84375,
      1.5234375,
      -0.1220703125,
      -5.1875,
      2.421875,
      -1.4921875,
      2.640625,
      4.5,
      0.62890625,
      -4.96875,
      6.65625,
      2.3125,
      -2.703125,
      3.015625,
      0.006561279296875,
      -3.546875,
      -3.34375,
      1.3046875,
      0.515625,
      4.0625,
      -1.078125,
      0.86328125,
      2.734375,
      -0.6015625,
      3.84375,
      2.625,
      0.73828125,
      0.259765625,
      4.46875,
      0.8203125,
      -4.9375,
      -1.3046875,
      2.421875,
      -3.296875,
      -3.984375,
      2.15625,
      -0.640625,
      2.65625,
      -0.1416015625,
      2.078125,
      1.7109375,
      6.84375,
      -4.5,
      3.046875,
      -6.125,
      0.14453125,
      -7.09375,
      2.3125,
      -8,
      2.0625,
      0.8515625,
      6.1875,
      -0.04150390625,
      -4.40625,
      3.3125,
      5.53125,
      1.90625,
      -4.5625,
      2.640625,
      2.515625,
      -0.875,
      -5.78125,
      -2.734375,
      4.3125,
      0.87890625,
      3.0625,
      -4.8125,
      1.34375,
      3.703125,
      -1.6796875,
      -5.34375,
      0.515625,
      -0.2265625,
      -6.46875,
      -5.71875,
      -2.03125,
      -0.515625,
      -1.3671875,
      2,
      4.34375,
      -1.921875,
      2.109375,
      0.47265625,
      4.1875,
      2.578125,
      -1.3046875,
      2.984375,
      0.291015625,
      -0.255859375,
      2.21875,
      3.890625,
      -2.53125,
      1.5625,
      -1.015625,
      1.09375,
      3.0625,
      -1.8671875,
      -0.24609375,
      -6.8125,
      1.71875,
      4.34375,
      2.03125,
      0.10595703125,
      -3.8125,
      -3.015625,
      2.046875,
      -1.390625,
      -3.171875,
      1.078125,
      -1.7109375,
      -0.32421875,
      1.1328125,
      -1.8828125,
      3.828125,
      0.76171875,
      -0.5078125,
      -2.09375,
      -0.69921875,
      -2.015625,
      -1.5546875,
      -3.71875,
      3.15625,
      -0.62109375,
      4.34375,
      -0.5703125,
      -4.21875,
      -2.03125,
      3.671875,
      1.1328125,
      2.375,
      -1.8203125,
      -1.2890625,
      3.1875,
      3.6875,
      1.3359375,
      -1.328125,
      0.60546875,
      1.265625,
      0.302734375,
      -3.265625,
      -1.625,
      -1.8671875,
      3.21875,
      -1.8671875,
      -1.34375,
      -2.46875,
      1.9765625,
      -1.265625,
      -8.0625,
      0.890625,
      -0.0361328125,
      -0.69921875,
      -5,
      0.396484375,
      2.296875,
      2.078125,
      4.75,
      3.234375,
      2.9375,
      -2.109375,
      2.84375,
      18.625,
      -2.734375,
      -4.9375,
      -1.71875,
      0.267578125,
      2.84375,
      8.5625,
      1.171875,
      0.0235595703125,
      -1.8359375,
      1.546875,
      4.375,
      2.828125,
      3.28125,
      0.6875,
      0.90625,
      2.71875,
      1.9375,
      -2.65625,
      -4.1875,
      -1.03125,
      2.34375,
      -0.99609375,
      3.078125,
      -2.640625,
      3.28125,
      3.296875,
      -1.5,
      -0.2275390625,
      -4.90625,
      1.1328125,
      -3.140625,
      -1.3203125,
      -5.1875,
      1.296875,
      -4.90625,
      1,
      2.03125,
      0.75390625,
      -2.125,
      -2.46875,
      -4.28125,
      3.140625,
      -0.96484375,
      -0.4609375,
      0.90625,
      -2.3125,
      1.4765625,
      -0.79296875,
      -0.7890625,
      -2.515625,
      -3.6875,
      -3.515625,
      2.25,
      0.64453125,
      -2.578125,
      0.8203125,
      -7.03125,
      -2.359375,
      -5.40625,
      -1.5703125,
      -2.3125,
      -3.375,
      -2.71875,
      -3.875,
      -2.421875,
      -2.3125,
      -0.296875,
      -0.1591796875,
      -1.4921875,
      -6,
      -0.220703125,
      5.03125,
      5.5,
      0.1552734375,
      -2.453125,
      2.71875,
      2.40625,
      2.203125,
      1.5390625,
      -0.5234375,
      3.328125,
      -2.25,
      -1.46875,
      -0.8828125,
      0.875,
      -5.34375,
      2.21875,
      0.232421875,
      -0.193359375,
      4.40625,
      -2.796875,
      2.28125,
      -0.6640625,
      -3.453125,
      -1.5,
      -0.29296875,
      3.40625,
      0.119140625,
      -0.78125,
      2.75,
      -0.466796875,
      -0.82421875,
      -2.078125,
      -0.474609375,
      -1.5859375,
      1.7734375,
      -1.625,
      1.828125,
      -0.796875,
      1.3046875,
      2.0625,
      0.80859375,
      -2.203125,
      -0.45703125,
      2.9375,
      -6.78125,
      -1.9296875,
      1.8984375,
      -0.7265625,
      4.3125,
      -2.109375,
      -3.9375,
      -0.287109375,
      -8.625,
      -5.53125,
      -1.9140625,
      -3.0625,
      3.515625,
      -2.203125,
      1.4609375,
      -1.03125,
      -1.890625,
      -1.359375,
      2.8125,
      -4.34375,
      3.703125,
      3.875,
      1.0703125,
      0.373046875,
      -2.828125,
      2.171875,
      1.1796875,
      -2.796875,
      -2.546875,
      0.8046875,
      -4.625,
      2.515625,
      5.53125,
      1.3203125,
      -3.671875,
      4.78125,
      -0.6953125,
      -3.34375,
      -2.4375,
      3.1875,
      -0.0908203125,
      -0.7265625,
      -1.3203125,
      -1.9375,
      0.63671875,
      0.51171875,
      -2.78125,
      -4.375,
      -1.90625,
      -1.953125,
      2.765625,
      -0.5703125,
      -7.15625,
      0.88671875,
      5.53125,
      -7,
      1.03125,
      -1.5703125,
      5.78125,
      -5.75,
      0.5859375,
      5.375,
      -0.26171875,
      0.66015625,
      2.203125,
      3.171875,
      -2.015625,
      -6.3125,
      1.8046875,
      4.46875,
      -2.703125,
      2.28125,
      2.9375,
      -1.484375,
      0.60546875,
      -4.15625,
      -4.65625,
      6.96875,
      5.875,
      -5.09375,
      0.6796875,
      -2.875,
      -1.2109375,
      -1.3359375,
      -5.1875,
      2.421875,
      1.296875,
      1.3203125,
      0.8203125,
      0.9296875,
      -3.734375,
      -0.8671875,
      -0.94921875,
      -2.546875,
      -2.15625,
      2.859375,
      -1.1875,
      4.09375,
      -6.03125,
      5.53125,
      3.5,
      0.68359375,
      -4.1875,
      3.28125,
      4.40625,
      0.1083984375,
      -4.53125,
      -1.4296875,
      -0.9765625,
      4.625,
      -6.375,
      4.28125,
      -3.0625,
      1.6015625,
      -1.125,
      2.3125,
      -1.3515625,
      3.171875,
      -2.9375,
      -6.0625,
      -3.546875,
      3.421875,
      1.0703125,
      1.953125,
      2.796875,
      -0.84375,
      1.109375,
      2.109375,
      -3.359375,
      1.7890625,
      -0.9375,
      -0.7734375,
      3.34375,
      -2.1875,
      0.13671875,
      -0.2197265625,
      2.390625,
      -2.46875,
      -2.9375,
      -1.7421875,
      -3.5,
      0.9921875,
      -4.28125,
      3.71875,
      3.015625,
      -7.1875,
      4.5625,
      -3.515625,
      -1.8828125,
      1.9921875,
      0.71875,
      -5.59375,
      6.125,
      4.15625,
      -4.46875,
      4.5,
      -0.1630859375,
      -2,
      0.5859375,
      -1.578125,
      0.90625,
      -5.3125,
      0.6328125,
      3.671875,
      -4.9375,
      1.1875,
      3.09375,
      -2.59375,
      -0.09326171875,
      -1.3203125,
      5.53125,
      1.1953125,
      3.375,
      0.7109375,
      2.578125,
      5.875,
      -4.15625,
      1.65625,
      -2.234375,
      -0.953125,
      -2.8125,
      -0.6640625,
      -1.265625,
      -2.171875,
      2.203125,
      3.296875,
      1.2578125,
      -9.875,
      -3.875,
      2.515625,
      -3.953125,
      3.6875,
      1.4453125,
      1.15625,
      -3.296875,
      -1.4921875,
      0.71875,
      2.78125,
      -2.0625,
      -2.75,
      -2.3125,
      3.21875,
      1.453125,
      -6.125,
      -0.72265625,
      0.455078125,
      -2.546875,
      -0.484375,
      -2,
      -2.03125,
      0.390625,
      5.59375,
      -6.03125,
      2.84375,
      1.6171875,
      3.296875,
      4.75,
      -1.4375,
      2.890625,
      3.953125,
      -3.03125,
      -7.09375,
      -1.3359375,
      0.40625,
      0.0118408203125,
      1.9140625,
      -2.953125,
      2.78125,
      0.35546875,
      3.5,
      -5.5,
      1.6796875,
      3.3125,
      -6.34375,
      4.6875,
      -3.484375,
      0.70703125,
      -1.5625,
      -5.875,
      -0.62109375,
      4.3125,
      0.578125,
      -0.033935546875,
      0.6640625,
      -1.578125,
      0.0037994384765625,
      2.609375,
      -0.984375,
      -0.98046875,
      -0.30859375,
      3.703125,
      -3.34375,
      1.671875,
      2.5625,
      0.5078125,
      -0.60546875,
      -3.515625,
      2.65625,
      -1.2890625,
      -2.78125,
      4.6875,
      5.15625,
      -1.1171875,
      -3.65625,
      -5.59375,
      1.5234375,
      -0.0771484375,
      -3.84375,
      0.52734375,
      -2.5,
      1.1875,
      -3.328125,
      1.671875,
      0.73046875,
      -5.96875,
      -3.046875,
      -3.859375,
      -1.234375,
      0.8046875,
      2.859375,
      2.1875,
      -2.1875,
      -1.8671875,
      3.953125,
      3.21875,
      -0.87890625,
      -5.03125,
      1.5546875,
      -1.1953125,
      -1.8984375,
      -3.5625,
      1.296875,
      -3.296875,
      -0.734375,
      1.7421875,
      -0.36328125,
      -0.427734375,
      -5.8125,
      -2.453125,
      1.1796875,
      -0.41015625,
      -0.00115203857421875,
      -2.640625,
      -0.146484375,
      1.9140625,
      4.40625,
      -4.0625,
      -1.1171875,
      0.58203125,
      1.7109375,
      -6.4375,
      -1.6015625,
      2.078125,
      -1.25,
      0.2578125,
      4.59375,
      1.3671875,
      1.9765625,
      1.1484375,
      -4.46875,
      -2.53125,
      5.25,
      3.765625,
      0.0201416015625,
      0.66015625,
      -1.8125,
      -2.484375,
      4.875,
      7.5625,
      -2.703125,
      -2.328125,
      -0.98828125,
      -1.8046875,
      -2.609375,
      -2.34375,
      0.0791015625,
      -0.21875,
      -7.46875,
      7.125,
      -1.8125,
      3.65625,
      1.5625,
      -4.71875,
      4.8125,
      -4.3125,
      -1.2890625,
      -0.53515625,
      0.173828125,
      3.703125,
      -3.59375,
      -1.328125,
      -3.265625,
      0.484375,
      0.6328125,
      -2.046875,
      0.2392578125,
      1.421875,
      4.375,
      -0.1552734375,
      -1.3828125,
      -1.3671875,
      -1.4375,
      5.6875,
      -1.9453125,
      -2.703125,
      0.040283203125,
      -3.28125,
      1.4453125,
      -1.734375,
      1.4140625,
      -5.15625,
      -0.9609375,
      -1.859375,
      2.0625,
      1.2109375,
      1.75,
      -0.76953125,
      -3.5,
      -1.9140625,
      4.28125,
      1.5,
      4.96875,
      1.875,
      3.53125,
      0.73046875,
      1.1640625,
      2.234375,
      3.234375,
      3.640625,
      -2.4375,
      0.61328125,
      -0.375,
      -0.2392578125,
      -0.78125,
      -1.59375,
      2.734375,
      1.3046875,
      4.6875,
      -0.7421875,
      -0.44140625,
      -3.59375,
      -2.296875,
      0.99609375,
      -1.296875,
      3.109375,
      3.0625,
      -2.1875,
      0.1845703125,
      -0.515625,
      2.875,
      0.9453125,
      4.28125,
      0.375,
      -1.9140625,
      -2.328125,
      1.1171875,
      1.796875,
      -0.45703125,
      0.6171875,
      -1.640625,
      1.421875,
      -0.59375,
      -2.953125,
      0.232421875,
      2.625,
      -2.65625,
      1.34375,
      -0.007110595703125,
      0.275390625,
      0.404296875,
      -1.9921875,
      -0.283203125,
      0.9609375,
      -0.73046875,
      4.65625,
      0.2392578125,
      -0.482421875,
      1.9296875,
      3.390625,
      -1.5859375,
      0.267578125,
      1.6875,
      -0.7578125,
      -1.4765625,
      -1.765625,
      2.296875,
      -2.5625,
      4.28125,
      -1.6640625,
      0.1826171875,
      -0.232421875,
      -1.46875,
      -3.6875,
      2.15625,
      -3.640625,
      -0.2470703125,
      -2.109375,
      0.98828125,
      2.859375,
      0.41796875,
      0.546875,
      1.046875,
      0.27734375,
      -1.75,
      -1.6015625,
      -1.7265625,
      -3.390625,
      -4.4375,
      -2.796875,
      0.953125,
      0.5859375,
      -0.5859375,
      0.80859375,
      0.287109375,
      2.09375,
      -0.044921875,
      -0.9140625,
      2.375,
      1.8203125,
      -2.59375,
      -1.75,
      1.1328125,
      -0.0810546875,
      1.1484375,
      -1.0546875,
      -2.375,
      -0.248046875,
      0.07861328125,
      -0.58203125,
      1.6953125,
      -0.431640625,
      -0.3515625,
      0.609375,
      1.109375,
      -1.625,
      1.0546875,
      0.259765625,
      2.34375,
      -0.6171875,
      0.1982421875,
      1.9296875,
      0.80078125,
      -1.3046875,
      3.0625,
      3.4375,
      -2.125,
      -0.66796875,
      -0.1982421875,
      1.359375,
      2.171875,
      -1.6953125,
      -0.99609375,
      1.7421875,
      -1.9296875,
      -2.734375,
      0.96875,
      2.09375,
      -2.28125,
      0.74609375,
      -2.515625,
      -0.9609375,
      -1.3359375,
      0.220703125,
      1.6796875,
      -0.85546875,
      -0.98046875,
      -1.890625,
      1.171875,
      1.96875,
      0.6015625,
      0.486328125,
      -1.0859375,
      -2.46875,
      -0.51171875,
      1.3671875,
      -1.46875,
      -1.6796875,
      0.40234375,
      -0.46875,
      2.375,
      0.96484375,
      0.79296875,
      -0.75390625,
      -1.265625,
      -0.435546875,
      -0.67578125,
      -0.73828125,
      -3.390625,
      1.3125,
      2.3125,
      1.140625,
      -1.25,
      -0.8515625,
      -3.265625,
      -1.5546875,
      -4.59375,
      2.0625,
      0.7421875,
      -2.84375,
      0.25,
      1.8125,
      1.265625,
      1.9765625,
      -0.404296875,
      1.203125,
      1.71875,
      -0.28125,
      2.578125,
      0.8046875,
      1.9375,
      -3.421875,
      -0.796875,
      0.01263427734375,
      0.314453125,
      0.609375,
      1.15625,
      -0.9453125,
      2.828125,
      1.1484375,
      -1.234375,
      1.84375,
      2.0625,
      1.1796875,
      1.96875,
      -3.390625,
      3.234375,
      2.421875,
      0.66796875,
      -1.2890625,
      -0.04248046875,
      0.419921875,
      0.037109375,
      -3.140625,
      0.65234375,
      -0.5703125,
      3.890625,
      0.2314453125,
      -0.55078125,
      -0.984375,
      0.9375,
      1.296875,
      -1.640625,
      0.7578125,
      -2.953125,
      2.234375,
      1.0390625,
      1.515625,
      -0.43359375,
      -0.51171875,
      -1.890625,
      2.6875,
      -5.1875,
      0.337890625,
      -0.84375,
      0.64453125,
      0.9609375,
      0.71484375,
      -1.3125,
      -2.96875,
      -1.4296875,
      1.9453125,
      -1.921875,
      2.03125,
      1.9375,
      -0.8671875,
      0.03662109375,
      2.28125,
      0.1494140625,
      0.2177734375,
      1.578125,
      -2.53125,
      1.078125,
      -0.921875,
      -1.9375,
      -3.15625,
      -1.875,
      -6.875,
      -2.203125,
      -1.546875,
      -1.578125,
      0.6171875,
      2.078125,
      0.94921875,
      0.23828125,
      -1.65625,
      1.7265625,
      3.734375,
      0.0018157958984375,
      -1.1640625,
      2.4375,
      -1.6875,
      0.66796875,
      -1.890625,
      -0.404296875,
      0.5859375,
      0.484375,
      3.234375,
      -0.50390625,
      3,
      0.66796875,
      -1.8359375,
      1.2265625,
      0.2431640625,
      -0.95703125,
      -1.3828125,
      0.1376953125,
      1.3125,
      2.125,
      3.765625,
      3.75,
      2.5625,
      -0.96875,
      -0.7109375,
      0.54296875,
      0.83203125,
      6.53125,
      0.875,
      -1.171875,
      -1.25,
      2.734375,
      1.09375,
      0.97265625,
      0.486328125,
      0.7578125,
      5.59375,
      0.89453125,
      0.2041015625,
      -1.75,
      -0.01300048828125,
      -1.078125,
      0.171875,
      5.46875,
      -4.6875,
      0.296875,
      -1.34375,
      -1.0703125,
      1.8203125,
      -0.2021484375,
      3.40625,
      0.1123046875,
      5.03125,
      1.7578125,
      0.4140625,
      0.99609375,
      1.046875,
      -0.96875,
      2.359375,
      1.4296875,
      -2.078125,
      -0.51171875,
      0.07421875,
      -0.58203125,
      2.28125,
      -1.421875,
      -0.96484375,
      2.0625,
      -2.578125,
      1.5390625,
      -0.08203125,
      1.5078125,
      2.28125,
      -1.109375,
      -1.5625,
      -3.484375,
      -1.8203125,
      1.40625,
      3.84375,
      0.62109375,
      -3.578125,
      -0.435546875,
      -0.306640625,
      -0.494140625,
      -2.015625,
      0.322265625,
      -1.875,
      -3.078125,
      -2.515625,
      -1.7578125,
      -3.359375,
      5.3125,
      -1.609375,
      2.421875,
      4.5625,
      3.296875,
      2.8125,
      2.90625,
      -0.142578125,
      3.75,
      -2.890625,
      0.345703125,
      3.765625,
      -0.4609375,
      -1.21875,
      -0.8125,
      1.25,
      -0.99609375,
      -2.84375,
      -1.21875,
      -0.5234375,
      1.671875,
      -0.455078125,
      -4.03125,
      -1.40625,
      0.054443359375,
      -3.46875,
      -1.546875,
      0.74609375,
      -2.375,
      -1.6796875,
      0.8046875,
      1.921875,
      0.2265625,
      1.609375,
      -0.19921875,
      0.322265625,
      0.6171875,
      -0.85546875,
      -2.296875,
      -1.34375,
      1.1875,
      2.078125,
      -1.6015625,
      -0.07373046875,
      -0.75,
      4.46875,
      -3.875,
      2.515625,
      -1.3828125,
      -2.0625,
      2.71875,
      9.1875,
      0.75,
      -0.228515625,
      -0.07177734375,
      0.69921875,
      -3.609375,
      1.3046875,
      0.031982421875,
      -2.953125,
      -3.375,
      3.78125,
      -1.6328125,
      1.84375,
      0.78125,
      -0.1669921875,
      0.1787109375,
      -2.625,
      0.431640625,
      -3.546875,
      -2.0625,
      3.203125,
      4.53125,
      -1.8671875,
      -0.80078125,
      1.828125,
      -4.34375,
      3.015625,
      -2.78125,
      -2.328125,
      1.328125,
      4.71875,
      -1.1796875,
      5.15625,
      0.498046875,
      -1.5859375,
      3.0625,
      0.251953125,
      1.7734375,
      2.03125,
      -2.328125,
      -0.94140625,
      -1.8828125,
      2.65625,
      -1.609375,
      -5.40625,
      -0.044677734375,
      -1.7890625,
      -0.8671875,
      -0.058837890625,
      0.024169921875,
      2.8125,
      0.1865234375,
      -0.298828125,
      2.546875,
      1.8671875,
      0.57421875,
      1.5078125,
      -0.1181640625,
      0.77734375,
      -6.34375,
      0.4765625,
      -1.25,
      0.494140625,
      0.359375,
      1.1484375,
      1.515625,
      -0.26953125,
      -0.58203125,
      -1.4140625,
      1.4921875,
      -0.5703125,
      0.82421875,
      -0.193359375,
      -0.2578125,
      -2.140625,
      0.455078125,
      -3.578125,
      2.90625,
      -2.421875,
      -2.296875,
      0.64453125,
      -1.9453125,
      -1.8125,
      -4.40625,
      1.046875,
      1.9921875,
      -0.09912109375,
      1.1640625,
      -0.009033203125,
      2.59375,
      -2.6875,
      1.8515625,
      0.9375,
      1.046875,
      1.109375,
      -1.6640625,
      -0.86328125,
      -3.921875,
      1.65625,
      -1.3203125,
      0.62890625,
      4.125,
      -1.75,
      -2.984375,
      2.546875,
      1.5
    ],
    "summary": "对大型语言模型在教育领域的应用进行全面系统的梳理和分析，总结当前技术现状、挑战和未来发展方向",
    "structure": {
      "sections": [
        {
          "title": "Large Language Models for Education: A Survey",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ARTICLE INFO",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 18
        },
        {
          "title": "1. Introduction",
          "level": 1,
          "start_line": 22
        },
        {
          "title": "2. Characteristics of LLM in Education",
          "level": 1,
          "start_line": 44
        },
        {
          "title": "2.1. Characteristics of LLMs",
          "level": 1,
          "start_line": 55
        },
        {
          "title": "2.2. Characteristics of education",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "2.2.1. Educational development process",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "2.2.2. Impact on teachers",
          "level": 1,
          "start_line": 93
        },
        {
          "title": "2.2.3. Educational challenges",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "2.3. Characteristics of LLMEdu",
          "level": 1,
          "start_line": 123
        },
        {
          "title": "2.3.1. Specific embodiment of \"LLMs + education\"",
          "level": 1,
          "start_line": 127
        },
        {
          "title": "2.3.2. Impact of \"LLMs + education\"",
          "level": 1,
          "start_line": 144
        },
        {
          "title": "3. How to Gradually Integrate LLMs into Education",
          "level": 1,
          "start_line": 172
        },
        {
          "title": "3.1. Reasons why LLMs for education",
          "level": 1,
          "start_line": 176
        },
        {
          "title": "3.2. Fusion strategies",
          "level": 1,
          "start_line": 198
        },
        {
          "title": "4. Key Technologies for LLMEdu",
          "level": 1,
          "start_line": 214
        },
        {
          "title": "5. Implementation of LLMEdu",
          "level": 1,
          "start_line": 247
        },
        {
          "title": "5.1. LLMs-empowered education",
          "level": 1,
          "start_line": 254
        },
        {
          "title": "5.2. LLMs in Mathematics",
          "level": 1,
          "start_line": 278
        },
        {
          "title": "6. Issues and Challenges",
          "level": 1,
          "start_line": 298
        },
        {
          "title": "6.1. Main issues",
          "level": 1,
          "start_line": 302
        },
        {
          "title": "6.2. Main challenges",
          "level": 1,
          "start_line": 323
        },
        {
          "title": "7. Conclusion",
          "level": 1,
          "start_line": 345
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 357
        }
      ]
    },
    "suggested_tags": [
      "教育技术",
      "LLMs",
      "智能教育",
      "文献综述",
      "AI教育应用"
    ],
    "tag_suggestions": [
      {
        "name": "教育技术",
        "confidence": 0.95,
        "reason": "论文核心研究领域是大型语言模型在教育领域的应用，属于教育技术范畴"
      },
      {
        "name": "LLMs",
        "confidence": 0.9,
        "reason": "论文聚焦大型语言模型的技术特点、应用方法和挑战分析"
      },
      {
        "name": "智能教育",
        "confidence": 0.85,
        "reason": "论文系统综述了LLMs在个性化教学、自适应学习等智能教育场景的应用"
      },
      {
        "name": "文献综述",
        "confidence": 0.8,
        "reason": "论文采用综述研究方法，系统总结当前技术现状、挑战和未来发展方向"
      },
      {
        "name": "AI教育应用",
        "confidence": 0.75,
        "reason": "论文探讨人工智能技术特别是LLMs在教育行业的具体应用场景和效益"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283602068",
          "title": "Evaluating Adaptive and Generative AI-Based Feedback and Recommendations in a Knowledge-Graph-Integrated Programming Learning System",
          "authors": [
            "Lalita Na Nongkhai",
            "Jingyun Wang",
            "Adam T. Wynn",
            "T. Mendori"
          ],
          "year": 2025,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283438556",
          "title": "FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing",
          "authors": [
            "Jingheng Ye",
            "Shen Wang",
            "Jiaqi Chen",
            "Hebin Wang",
            "Deqing Zou",
            "Yanyu Zhu",
            "Jiwei Tang",
            "Hai-Tao Zheng",
            "Ruitong Liu",
            "Haoyang Li",
            "Yanfeng Wang",
            "Qingsong Wen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283261962",
          "title": "LOOM: Personalized Learning Informed by Daily LLM Conversations Toward Long-Term Mastery via a Dynamic Learner Memory Graph",
          "authors": [
            "Justin Cui",
            "Kevin Pu",
            "Tovi Grossman"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283299903",
          "title": "Research on the Intelligent Reform Pathway of Higher Education Empowered by Generative Artificial Intelligence",
          "authors": [
            "Gao Min"
          ],
          "year": 2025,
          "venue": "Artificial Intelligence and Digital Technology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283025009",
          "title": "THE RISE OF LARGE LANGUAGE MODELS: A BEGINNER’S SURVEY",
          "authors": [
            "Gustavo de Aquino Mouzinho",
            "Leandro Youiti Silva Okimoto",
            "Leonardo Yuto Suzuki Camelo",
            "Nádila da Silva de Azevedo",
            "Hendrio Bragança",
            "Rubens de Andrade Fernandes",
            "Fabricio Ribeiro Seppe",
            "Raimundo Claúdio Souza Gomes",
            "Fábio de Sousa Cardoso"
          ],
          "year": 2025,
          "venue": "ARACÊ",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283103684",
          "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education",
          "authors": [
            "Bingquan Zhang",
            "Xiaoxiao Liu",
            "Yuchi Wang",
            "Lei Zhou",
            "Qianqian Xie",
            "Benyou Wang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282911236",
          "title": "Using LLMs to support assessment of student work in higher education: a viva voce simulator",
          "authors": [
            "Ian M. Church",
            "Lyndon Drake",
            "Mark Harris"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283569751",
          "title": "SPARK – Smart Plug-and-Play AI Framework for RAG & Knowledge",
          "authors": [
            "Nirmit Dagli",
            "Chetan Jaiswal",
            "Sanjeev Kumar Marimekala"
          ],
          "year": 2025,
          "venue": "Ubiquitous Computing, Electronics & Mobile Communication Conference",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282107557",
          "title": "Modular Framework Integrating Large Language Models with Drilling Hazard Detection Systems to Provide Operational Context-Informed Interpretations and Recommended Actions",
          "authors": [
            "S. Suhail",
            "T. S. Robinson",
            "O. Revheim",
            "P. Bekkeheien"
          ],
          "year": 2025,
          "venue": "SPE Annual Technical Conference and Exhibition",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281787333",
          "title": "Defying Data Scarcity: High-Performance Indonesian Short Answer Grading via Reasoning-Guided Language Model Fine-Tuning",
          "authors": [
            "Muhammad Naufal Faza",
            "P. D. Purnamasari",
            "A. A. P. Ratna"
          ],
          "year": 2025,
          "venue": "International Journal of Electrical, Computer, and Biomedical Engineering",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T19:03:39.467259",
      "references": [
        {
          "external_id": "CorpusId:266054920",
          "title": "Large Language Models in Law: A Survey",
          "authors": [
            "Jinqi Lai",
            "Wensheng Gan",
            "Jiayang Wu",
            "Zhenlian Qi",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "AI Open",
          "citation_count": 150
        },
        {
          "external_id": "CorpusId:265351653",
          "title": "Multimodal Large Language Models: A Survey",
          "authors": [
            "Jiayang Wu",
            "Wensheng Gan",
            "Zefeng Chen",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 282
        },
        {
          "external_id": "CorpusId:265352038",
          "title": "Large Language Models in Education: Vision and Opportunities",
          "authors": [
            "Wensheng Gan",
            "Zhenlian Qi",
            "Jiayang Wu",
            "Chun-Wei Lin"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 128
        },
        {
          "external_id": "CorpusId:265149884",
          "title": "Large Language Models for Robotics: A Survey",
          "authors": [
            "Fanlong Zeng",
            "Wensheng Gan",
            "Yongheng Wang",
            "Ning Liu",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:265128707",
          "title": "Model-as-a-Service (MaaS): A Survey",
          "authors": [
            "Wensheng Gan",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 35
        },
        {
          "external_id": "CorpusId:263608784",
          "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis",
          "authors": [
            "Weixin Liang",
            "Yuhui Zhang",
            "Hancheng Cao",
            "Binglu Wang",
            "Daisy Ding",
            "Xinyu Yang",
            "Kailas Vodrahalli",
            "Siyu He",
            "D. Smith",
            "Yian Yin",
            "Daniel A. McFarland",
            "James Zou"
          ],
          "year": 2023,
          "venue": "NEJM AI",
          "citation_count": 217
        },
        {
          "external_id": "CorpusId:263334045",
          "title": "Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment",
          "authors": [
            "Tianhao Wu",
            "Banghua Zhu",
            "Ruoyu Zhang",
            "Zhaojin Wen",
            "K. Ramchandran",
            "Jiantao Jiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 70
        },
        {
          "external_id": "CorpusId:263310363",
          "title": "A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM",
          "authors": [
            "Jongyoon Lim",
            "Inkyu Sa",
            "Bruce A. MacDonald",
            "Ho Seok Ahn"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 9
        },
        {
          "external_id": "CorpusId:261582620",
          "title": "ImageBind-LLM: Multi-modality Instruction Tuning",
          "authors": [
            "Jiaming Han",
            "Renrui Zhang",
            "Wenqi Shao",
            "Peng Gao",
            "Peng Xu",
            "Han Xiao",
            "Kaipeng Zhang",
            "Chris Liu",
            "Song Wen",
            "Ziyu Guo",
            "Xudong Lu",
            "Shuai Ren",
            "Yafei Wen",
            "Xiaoxin Chen",
            "Xiangyu Yue",
            "Hongsheng Li",
            "Y. Qiao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 148
        },
        {
          "external_id": "CorpusId:261582366",
          "title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function",
          "authors": [
            "Haotian Xu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 15
        }
      ],
      "references_fetched_at": "2025-12-16T19:03:40.082147"
    },
    "category": "AI Research教育AI"
  },
  "659fea70-f22c-4b54-9382-aa768ec096e8": {
    "id": "659fea70-f22c-4b54-9382-aa768ec096e8",
    "filename": "ssrn-5095149.pdf",
    "file_path": "data/uploads/47e5d413-0cfd-43be-ba5a-dd4b0c5160c5/659fea70-f22c-4b54-9382-aa768ec096e8_ssrn-5095149.pdf",
    "status": "completed",
    "created_at": "2025-12-16 21:36:27.474020",
    "updated_at": "2025-12-16 13:37:57.338826",
    "user_id": "47e5d413-0cfd-43be-ba5a-dd4b0c5160c5",
    "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
    "markdown_content": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning – understanding and retaining information – remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material<sup>17</sup>. Models of reading comprehension, such as the Construction-Integration (CI) model<sup>18</sup>, highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text)<sup>17</sup>. This multi-level structure is supported by neuroimaging studies<sup>19;20;21;22;16</sup>. The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge<sup>17</sup>. A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals)<sup>23;24;25;26;27</sup>, the text itself (e.g., genre, length, word and sentence complexity, cohesion)<sup>28;29</sup>, and the reading context (e.g., reading for leisure or academic purposes)<sup>30;31</sup>.\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately —through semantic analysis involving meaning, inferences, and implications— can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies – note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes $^{35;36}$ , setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ ,  $95\\%$  CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ ,  $95\\%$  CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9a2f4d9cc9579f597bbeeb013a133f3f56b5f7e78028c7f54b3caea7c03b5ee.jpg)  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/23e6863e1c87df8e23a0c590c8e6744c9f75059bb10033cad565cccdca9a1e8e.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/2f7b3c6eb55edba33c7498db63ee23202e70938030ee28f26ed778c685bd2de3.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-taking—whether done alone or alongside LLM usage—produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learning—offering opportunities to clarify, explore, and contextualise material—but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the LLM and LLM+Notes conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot ②\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/659fea70-f22c-4b54-9382-aa768ec096e8/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 – upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\text {O r d e r} _ {i j} + \\beta_ {7} \\text {G e n d e r} _ {i j} + \\beta_ {8} \\text {F S M} _ {i j} + \\beta_ {9} \\text {E A L} _ {i j} + \\beta_ {1 0} \\text {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. Aleksić-Maslac, F. Borović, and Z. Biočina. PERCEPTION AND USAGE OFchat GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434–442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In Children's comprehension problems in oral and written language: A cognitive perspective, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344-360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 × 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 × 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 × 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 × 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 × 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 × 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 × 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 × 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 × 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 × 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 × 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 × 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 × 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (≥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (≥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\n· figuring out what the main ideas and concepts in the text are,\n· what they mean,\n· how they relate to each other, and\n· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\n· The meaning of important words and concepts\n· The meaning of complex sentences\n· The key points or ideas, such as the dates, places, people and events\n· The connections between places, people and events\n· What happened, and why and how it happened\n· Similarities and differences between ideas and concepts\n· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\nYou can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\n You can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>“It took less time to use the LLM”, “Notes take too much time.”</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>“The note-taking seemedunnec-\nsessary as the bot already helped explain”, “Using one sort of meant I didn’t need the other.”</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you don’t have to do the work your-\nself. The task becomes easier if you don’t have to take notes.</td><td>“Didn’t have to do any work”, “Clarify any information I didn’t know immediately without hav-\ning to scour the text”, “It was difficult to take notes at the same time as using the chatbot.”</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>“I didn’t have enough time to ask as many questions when taking notes”, “I had more time to un-\nderstand the text.”</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.”</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>“Less time-consuming”, “Much quicker.”</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>“More simple”, “It was easier.”</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>“Actively engaging with the bot”, “Felt more interactive.”</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>“Enjoyed reading its responses”, “More fun to use.”</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>“Allowed me to focus more on the text.”</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>“It gives you a better understanding”, “I could confirm anything I was unsure of to ensure I understood it.”</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>“The AI helped me to learn more efficiently”, “I was able to understand and learn the text a lot easier and quicker at a higher level.”</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you don’t understand.</td><td>“Ask any relevant questions”, “If I had a question, it could answer it.”</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>“I was given more background”, “It gives me the full context.”</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>“It puts it in a simpler way and form”, “I can ask the AI chatbot to rephrase key points”, “It can summarise key points.”</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>“It has stuck in my head more”, “Giving me prompt questions, mnemonics, etc., which helped me remember”, “Took less time to memorise than note-taking.”</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>“I can remember things better when I write them down”, “More helpful for developing recall”, “I learned more with note-taking”, “Just gave more background, rather than consolidating the knowledge.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>“It was easier for me to understand what I was reading”, “I was understanding it more”, “Test what you have learned by paraphrasing.”</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>“Better active reading”, “Allows me to actively engage.”</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>“You have to personally analyse it”, “I could condense the information into my own words”, “Made me think for myself”, “It is your view on the matter you are looking at”, “Alows me to feel proud of my work in the future.”</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>“I was able to break down and process the text”, “Summarising the second text myself helped me to process the information.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“I am able to write down my own knowledge of what I had learned”, “I could actually learn the information rather than being told it.”</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>“I can come back to these notes at a later date if I am doing revision”, “Note-taking gives you something better to look back on in future.”</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>“Easier to summarise”, “IDK, easier.”</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>“It is easy to organise my notes”, “It is easier to keep track of your train of thoughts”, “Helped me to break down the text into smaller chunks.”</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>“I found myself easily distracted by the AI and was more tempted to ask random questions”, “It’s not clear as it gives too much information.”</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>“It felt that it was just repeating it-self.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>“I struggled to think of questions to ask the AI”, “The text was very easy therefore didn’t feel the need to ask many questions.”</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>“I enjoy using both at the same time”, “If I had to use the chatbot and ask it 20 questions, I would be very bored.”</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>“It was easier to have my key notes summarised as well as text with more detail”, “It allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isn’t clear.”</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>“Most helpful and easy to learn”, “Because I find it easier to remember and learn this way.”</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>“In order for me to process this, I find note-taking at the same time very helpful.”</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>“If I am only using the chatbot, then I have to scroll up to find what I am looking for”, “It was easier to keep track of things and go back over them.”</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>“It meant I was doing actual work.”</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>“I like to write out information as I think it helps me remember it better.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>“Simplifying it on paper made it easier to understand and remember.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“You learn more”, “You can simplify what you have learnt in the notes.”</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>“Some of the questions I had for the bot were not answered explicitly.”</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>“You will not get an AI chatbot at all times.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>“I wasn’t sure what I was supposed to say to the bot. It was just kinda irritating.”</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xlsx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: “Help me to summarise this paragraph”, “Summarise the text”, “Give me a summary of the first paragraph”, “Tell me what this text is about.”</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: “Make notes for the first paragraph.”</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: “What are the main points?”, “Give me all the important dates”, “What’s the takeaway message?”</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: “Put the important dates into chronological order”, “Give me a timeline of the events.”</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: “What does apartheid mean?”, “What is a colony?”, “What is a missile?”, “I don’t know what a blockade is.”</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: “Explain this in simple words”, “Make the text simpler”, “What does this sentence mean?”, “Simplify this text.”</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: “The US did not like Cuba because they thought that Castro was a communist, right?”, “So it was one officer that prevented the whole war?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide context—information that is not too central for understanding the text but could be relevant.\nExamples: “Who was Kennedy?”, “What was Mandela famous for?”, “Tell me more about Cuba”, “How many British colonies were there in Africa?”, “Where were the Turkish missiles located?”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: “Why did the US not like Castro?”, “Why did the exiles invade Cuba?”, “How did black people feel during apartheid?”</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: “What are examples of how apartheid affected daily life?”, “Is there an analogy that explains the Cold War tensions?”, “What unfair laws were passed?”, “What were some of the boycotts?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: “How is apartheid different from segregation in the US?”, “Compare Kennedy and Khrushchev&#x27;s leadership styles.”</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: “What are the strengths and weaknesses of Kennedy&#x27;s decision?”, “Evaluate the effectiveness of the blockade.”</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: “What were the long-term effects of the crisis?”, “What is the situation like now?”, “Why should I care or learn about this?”</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: “Make a mnemonic”, “Write four questions about the text”, “How can I remember this better?”</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: “Summarize the main points in bullet points”, “Can you create a chart of the different policies?”, “Use only a few words”, “Make it short.”</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: “I don’t understand what you said”, “Explain that again but shorter”, “What do you mean?”,\n“Simpler please”, “Can you write that in simpler terms?”, “Make the summary shorter.”</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: “How are you?”, “Thank you”, “Hello.”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: “What are your sources?”, “Why should I believe you?”, “I think your answer is wrong.”</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: “Nelson Mandela”, “In 1910, four British colonies joined to create the Union of South Africa”, “Missile.”</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: “Who is Che Guevara?”, “What is the song Abraxas?”</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that don’t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: “asdfgh”, “.”, “123”, “???”</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
    "arxiv_id": "2401.15081",
    "error_message": null,
    "embedding": [
      -1.625,
      -1.7578125,
      0.1728515625,
      -4.40625,
      -1.7265625,
      0.091796875,
      -0.55859375,
      -1.7578125,
      0.64453125,
      2.515625,
      2.109375,
      1.1484375,
      2.0625,
      2.984375,
      -0.890625,
      4,
      -0.0172119140625,
      -0.5390625,
      0.33984375,
      -7.1875,
      0.50390625,
      1.640625,
      1.1953125,
      -5.5,
      3.75,
      -4.28125,
      -1.125,
      1.0546875,
      0.5703125,
      0.302734375,
      7.09375,
      -7.0625,
      0.65234375,
      2.53125,
      0.89453125,
      1.1875,
      -2.15625,
      -2.03125,
      7.15625,
      3.375,
      -4.9375,
      0.302734375,
      1.7890625,
      1.5,
      -0.0123291015625,
      2.890625,
      1.421875,
      -1.90625,
      -4.4375,
      -0.66796875,
      -3.203125,
      -5,
      7.96875,
      -3.34375,
      3.046875,
      -3.171875,
      -5.0625,
      5.4375,
      -3.296875,
      -0.431640625,
      0.287109375,
      -0.92578125,
      1.265625,
      0.23046875,
      2.890625,
      1.4765625,
      1.484375,
      0.96484375,
      -3.390625,
      1.71875,
      2.265625,
      1.625,
      5.84375,
      -4.34375,
      9.0625,
      7.75,
      3.21875,
      2.09375,
      -0.296875,
      2.5625,
      -5.9375,
      5.0625,
      4.1875,
      -2.125,
      6.53125,
      3.03125,
      -1.09375,
      -2.15625,
      -2.78125,
      2.53125,
      -1.09375,
      -0.34765625,
      -6.3125,
      -3.046875,
      0.2392578125,
      3.0625,
      -0.8203125,
      -5.25,
      -4.78125,
      -0.470703125,
      -1.8515625,
      -3.140625,
      1.0390625,
      -6.71875,
      -4.71875,
      -4.53125,
      -3,
      -7.25,
      -0.76171875,
      -1.5625,
      -0.458984375,
      2.53125,
      0.51171875,
      -1.3125,
      0.7109375,
      -0.470703125,
      3.296875,
      -5.40625,
      -3.1875,
      -0.4375,
      0.578125,
      2.625,
      -1.0390625,
      0.515625,
      1.2265625,
      2.90625,
      -5.28125,
      2.984375,
      5.53125,
      -0.90234375,
      3.296875,
      -1.1640625,
      5.46875,
      -0.6328125,
      -6.25,
      -3.375,
      -4.25,
      2.046875,
      4.84375,
      7.125,
      -4.4375,
      -0.1943359375,
      -1.8046875,
      -9,
      2.859375,
      0.953125,
      -6.84375,
      0.3046875,
      3.84375,
      -4.59375,
      -1.15625,
      0.82421875,
      4.09375,
      4.78125,
      -1.90625,
      -5,
      3.125,
      2.5625,
      0.1484375,
      -2.171875,
      2.390625,
      1.109375,
      -1.2421875,
      1.1953125,
      -0.546875,
      -3.234375,
      -7.03125,
      1.7578125,
      -3.078125,
      -1.0078125,
      2.90625,
      13.875,
      2.453125,
      -1.5546875,
      0.055419921875,
      0.65234375,
      -2.71875,
      6.21875,
      2.09375,
      -0.765625,
      2.65625,
      1.7109375,
      -3.78125,
      1.609375,
      -0.1689453125,
      0.439453125,
      3.453125,
      -3.375,
      2.203125,
      -1.2109375,
      2.8125,
      4.90625,
      1.9375,
      0.072265625,
      -4.65625,
      0.296875,
      3.8125,
      1.390625,
      -0.66015625,
      2.046875,
      1.1796875,
      -8.4375,
      1.25,
      -1.484375,
      -3.765625,
      -2.25,
      4.125,
      -1.0859375,
      2.984375,
      -1.4453125,
      1.671875,
      -1.703125,
      0.76171875,
      1.6953125,
      7.4375,
      1.8125,
      1.3203125,
      -0.18359375,
      3.953125,
      3.28125,
      4.0625,
      3.0625,
      2.46875,
      1.1875,
      -0.76953125,
      3.109375,
      2.609375,
      3.71875,
      -0.0908203125,
      5.40625,
      -0.2373046875,
      4.0625,
      5.53125,
      -1.9921875,
      -2.046875,
      0.287109375,
      -3.390625,
      -0.73828125,
      -1.2734375,
      0.1591796875,
      -3.984375,
      -2.265625,
      0.671875,
      2.75,
      1.71875,
      -1.4453125,
      -0.5546875,
      -1.078125,
      -0.69140625,
      -6.875,
      0.671875,
      1.9296875,
      -9.875,
      -3.609375,
      5.625,
      8.8125,
      -0.392578125,
      -0.220703125,
      -2.890625,
      -0.59375,
      3.390625,
      -1.5625,
      -3.640625,
      -0.2041015625,
      1.90625,
      -4.15625,
      5.78125,
      -1.46875,
      3.796875,
      1.2890625,
      0.57421875,
      -1.78125,
      -1.984375,
      -0.0498046875,
      0.1845703125,
      5.4375,
      3.78125,
      -3.34375,
      0.51953125,
      -2.234375,
      -6.28125,
      -9.25,
      5.625,
      -3.25,
      5.5,
      -0.89453125,
      0.578125,
      4.84375,
      -1.640625,
      12.6875,
      2.09375,
      1.6875,
      0.6484375,
      -1.0859375,
      -4.53125,
      1.359375,
      -4.0625,
      2.65625,
      -4.8125,
      -0.365234375,
      4.75,
      4.15625,
      -1.609375,
      -4.21875,
      1.140625,
      4.3125,
      1.625,
      -3.578125,
      0.58984375,
      2.84375,
      -3.9375,
      1.984375,
      7,
      -3.53125,
      3.640625,
      -7.0625,
      -2.375,
      6.25,
      1.3125,
      -0.89453125,
      -5.1875,
      -3.15625,
      -1.0546875,
      -2.65625,
      -2.90625,
      -2.53125,
      0.33984375,
      -0.2890625,
      2.546875,
      -0.55859375,
      1.0859375,
      0.7109375,
      -5.40625,
      -9.625,
      7.5625,
      -3.578125,
      5.3125,
      0.91796875,
      -1.3671875,
      3.96875,
      -2.28125,
      -3.5625,
      3.46875,
      -1.9921875,
      -0.125,
      -1.7421875,
      4.5625,
      -2.5,
      1.4765625,
      -8.1875,
      2.96875,
      0.8125,
      1.25,
      5.0625,
      6.8125,
      -3.8125,
      1.1875,
      -2.375,
      -2.578125,
      -0.404296875,
      1,
      -1.4140625,
      6.65625,
      -0.72265625,
      -3.953125,
      -2.734375,
      -0.515625,
      3.8125,
      -0.80078125,
      -0.6015625,
      0.162109375,
      -4.25,
      0.44140625,
      0.85546875,
      1.1015625,
      3.515625,
      2.640625,
      -2.421875,
      -1.7109375,
      3.671875,
      -3.671875,
      0.81640625,
      -0.0703125,
      -1.015625,
      3.046875,
      1.6796875,
      0.9609375,
      3.015625,
      2.75,
      0.054931640625,
      -2.265625,
      1.0390625,
      -2.5625,
      3.15625,
      1.6171875,
      3.34375,
      -0.9921875,
      1.984375,
      -0.88671875,
      -2.453125,
      5.6875,
      0.1982421875,
      -0.3359375,
      -2.84375,
      -3.5625,
      1.1875,
      1.859375,
      -7.1875,
      0.326171875,
      2.078125,
      -1.3671875,
      3,
      -2.203125,
      0.053955078125,
      -0.228515625,
      3.359375,
      -1,
      2.78125,
      -5.71875,
      -3.140625,
      -3.359375,
      0.142578125,
      1.5390625,
      -0.73046875,
      -0.330078125,
      0.6015625,
      4.34375,
      6.03125,
      1.109375,
      -1.6328125,
      1.3125,
      0.06494140625,
      -2.734375,
      0.306640625,
      -0.0174560546875,
      0.06982421875,
      1.234375,
      -4.6875,
      -4.5,
      -0.2578125,
      2.921875,
      0.60546875,
      5.1875,
      5.28125,
      -2.5625,
      -2.34375,
      2,
      3.140625,
      -4.0625,
      -5.09375,
      -0.9453125,
      0.515625,
      -1.28125,
      1.8046875,
      1.875,
      0.81640625,
      -0.031494140625,
      4.59375,
      2.0625,
      1.6015625,
      2.53125,
      -0.291015625,
      -1.5546875,
      -0.287109375,
      -0.015625,
      0.1484375,
      -3.671875,
      4.125,
      6.3125,
      -11.4375,
      -10.875,
      3.171875,
      0.86328125,
      -0.54296875,
      -0.2373046875,
      4.84375,
      2,
      1.6953125,
      -6.21875,
      -4.40625,
      -0.3046875,
      -0.734375,
      3.5,
      2.140625,
      -0.99609375,
      -2.921875,
      -3.890625,
      4.46875,
      -0.51953125,
      4.53125,
      -0.2431640625,
      0.0751953125,
      1.8203125,
      -5.375,
      2.234375,
      1.5703125,
      6.9375,
      -6.03125,
      0.12255859375,
      0.8125,
      -8.375,
      -1.3828125,
      -3.71875,
      -0.12060546875,
      -0.047119140625,
      -0.953125,
      5.3125,
      -3.28125,
      -0.48828125,
      -1.109375,
      2.4375,
      -4.09375,
      -3.34375,
      3.4375,
      -3.1875,
      -3.171875,
      0.333984375,
      0.70703125,
      1.078125,
      -1.375,
      -1.265625,
      -0.33203125,
      3.84375,
      2.171875,
      0.140625,
      -1.546875,
      -0.94140625,
      -2.640625,
      0.326171875,
      4.09375,
      3.1875,
      3.03125,
      1.265625,
      -5.125,
      -2.0625,
      -0.6171875,
      0.5859375,
      1.5390625,
      -0.1962890625,
      0.11181640625,
      0.388671875,
      3.453125,
      -4.125,
      1.5546875,
      0.5078125,
      0.470703125,
      -3.40625,
      0.0478515625,
      4.21875,
      3.34375,
      2.984375,
      3.109375,
      -0.5859375,
      1.15625,
      0.83984375,
      -4.1875,
      -3.40625,
      -1.546875,
      2.078125,
      1.09375,
      -3.34375,
      -0.1591796875,
      -1.6171875,
      -0.9765625,
      0.46875,
      -0.8984375,
      3.375,
      6.90625,
      -2.34375,
      1.1015625,
      -0.318359375,
      2.25,
      -2.125,
      1.96875,
      1.984375,
      2.859375,
      -5.9375,
      -6.09375,
      -3.03125,
      -0.0947265625,
      6.75,
      0.045166015625,
      4.40625,
      -2.78125,
      5.34375,
      1.3125,
      -0.06396484375,
      -15.1875,
      2.4375,
      -1.03125,
      -3.4375,
      -0.0260009765625,
      -4.21875,
      2.90625,
      -1.8046875,
      4.0625,
      0.3671875,
      -1.5859375,
      -2.703125,
      5.25,
      1.0390625,
      -0.54296875,
      4.8125,
      2.28125,
      -5.8125,
      1.28125,
      -0.41796875,
      -1.0859375,
      0.9140625,
      -1.2890625,
      1.6875,
      4.5625,
      4.59375,
      -1.7890625,
      -0.7421875,
      1.5625,
      -4.3125,
      -0.171875,
      1.59375,
      2.546875,
      1.5390625,
      2.609375,
      -0.81640625,
      2.90625,
      -3.75,
      2.015625,
      -0.1591796875,
      -1.78125,
      -0.5859375,
      6.34375,
      0.6484375,
      -3.078125,
      -4.03125,
      -2.328125,
      4.625,
      3.3125,
      -5.84375,
      0.50390625,
      0.8359375,
      -2.15625,
      3.765625,
      -0.421875,
      -0.34765625,
      -2.671875,
      0.41796875,
      1.328125,
      -3.328125,
      6.46875,
      2.90625,
      -5.78125,
      0.3984375,
      0.38671875,
      1.3125,
      0.3046875,
      1.1640625,
      0.1572265625,
      -2.6875,
      -1.1171875,
      3.71875,
      -0.6328125,
      -3.90625,
      -0.9296875,
      1.4609375,
      -4.6875,
      4.65625,
      -3.6875,
      -0.4375,
      -2.65625,
      -1.21875,
      3.53125,
      2.25,
      2.171875,
      0.054931640625,
      2.859375,
      2.890625,
      -3.125,
      5.90625,
      -5.25,
      -1.7109375,
      0.765625,
      -4.96875,
      -3.609375,
      0.71484375,
      -0.33203125,
      2.359375,
      -0.1875,
      -1.6953125,
      -1.5546875,
      -6.375,
      -1.625,
      1.1171875,
      0.009033203125,
      2.109375,
      -0.35546875,
      7.65625,
      -2.34375,
      -1.25,
      1.9140625,
      -1.4140625,
      -2.6875,
      -1.7890625,
      -1.6171875,
      -6.875,
      0.30859375,
      5.53125,
      4.28125,
      -1.4453125,
      7.03125,
      -0.3046875,
      -1.6875,
      -1,
      6.3125,
      -1.140625,
      -0.5234375,
      1.1796875,
      -0.62109375,
      -1.3203125,
      -4.8125,
      -0.78125,
      -2.203125,
      3.625,
      -1.640625,
      -0.1220703125,
      1.3359375,
      -4.375,
      2.1875,
      -0.9609375,
      -3.015625,
      -1.1875,
      3.875,
      -0.5234375,
      -1.890625,
      4.59375,
      1.3671875,
      2.390625,
      2.328125,
      -1.6953125,
      5,
      0.6328125,
      2.34375,
      -3.734375,
      -4.65625,
      -1.0859375,
      -0.412109375,
      -1.140625,
      2.359375,
      -2.203125,
      0.80859375,
      5.34375,
      1.3125,
      -4.90625,
      -1.5390625,
      4.125,
      -0.875,
      0.03564453125,
      -0.4453125,
      4.15625,
      1.3828125,
      1.6796875,
      -0.8671875,
      -4.90625,
      -1.9609375,
      4.59375,
      3.28125,
      -1.609375,
      0.9609375,
      4.3125,
      0.52734375,
      3.625,
      -4.6875,
      -5.09375,
      1.2734375,
      -0.1015625,
      -1,
      -1.609375,
      8.3125,
      -4.625,
      0.19921875,
      -0.203125,
      0.5546875,
      0.0206298828125,
      1.609375,
      -0.9765625,
      0.359375,
      2.3125,
      -1.109375,
      1.421875,
      3.96875,
      -0.8046875,
      -0.1884765625,
      0.431640625,
      -0.376953125,
      -1.8671875,
      2.109375,
      1.5703125,
      -1.265625,
      -1.484375,
      -0.80078125,
      -1.4296875,
      4.65625,
      5.90625,
      0.77734375,
      -0.58203125,
      2.796875,
      5.875,
      -0.0341796875,
      6.78125,
      1.625,
      9.0625,
      -2.5,
      -2.296875,
      4.8125,
      -4.15625,
      0.150390625,
      2.28125,
      -6.40625,
      -0.44140625,
      -0.68359375,
      -1.171875,
      -3.5,
      0.859375,
      -3.484375,
      -2.234375,
      6.25,
      2.90625,
      0.267578125,
      3.921875,
      5.59375,
      0.96875,
      -0.9765625,
      -4.8125,
      -2.796875,
      1.09375,
      0.8046875,
      2.46875,
      -1.9921875,
      0.65625,
      1.8828125,
      2.328125,
      1.1171875,
      0.0128173828125,
      -2.46875,
      5.6875,
      0.234375,
      0.35546875,
      5.34375,
      -2.359375,
      2.71875,
      0.380859375,
      3.515625,
      -3.890625,
      -1.1875,
      8.1875,
      2.484375,
      -2.0625,
      0.84765625,
      0.244140625,
      0.150390625,
      -2.421875,
      -1.609375,
      -0.6328125,
      0.251953125,
      -3.78125,
      -1.625,
      -0.361328125,
      1.953125,
      -3.0625,
      1.7109375,
      2.046875,
      -4.25,
      1.3046875,
      -0.255859375,
      -0.6171875,
      3.5,
      0.8046875,
      4.5,
      0.99609375,
      -2.953125,
      -5.125,
      -4.1875,
      -2.109375,
      0.486328125,
      1.8515625,
      1.9140625,
      0.3515625,
      -3.65625,
      0.75,
      -5.84375,
      -0.287109375,
      -6.28125,
      4.625,
      -0.00518798828125,
      -6.375,
      -1.0859375,
      -2.796875,
      -7.59375,
      -2.484375,
      -1.3671875,
      -2.546875,
      -1.015625,
      -4.4375,
      -0.08349609375,
      -1.1953125,
      -4.125,
      -0.0712890625,
      -2.421875,
      -1.1953125,
      3.203125,
      -0.59375,
      2.21875,
      -5,
      1.015625,
      0.921875,
      -0.66796875,
      2.296875,
      1.4609375,
      4.59375,
      4.90625,
      -0.9765625,
      2.15625,
      -2.34375,
      3.875,
      -2.859375,
      8.75,
      4.21875,
      0.3359375,
      -6.15625,
      2.390625,
      -0.6953125,
      0.66015625,
      -4.71875,
      -1.78125,
      -0.953125,
      -2.75,
      -0.88671875,
      0.32421875,
      2.359375,
      -4.96875,
      -2.96875,
      0.546875,
      -4.46875,
      1.90625,
      2.609375,
      -0.67578125,
      4.875,
      -0.042236328125,
      3.109375,
      1.234375,
      2.15625,
      2.390625,
      -1.6484375,
      4.0625,
      -7,
      2.59375,
      0.271484375,
      -1.03125,
      -0.6171875,
      -2.953125,
      1.546875,
      -1.0078125,
      0.72265625,
      2.390625,
      2.59375,
      1.1484375,
      -0.5234375,
      5.125,
      -1.140625,
      -1,
      -0.55078125,
      -1.734375,
      3.78125,
      1.6640625,
      1.65625,
      -3,
      1.3359375,
      -2.671875,
      -0.09716796875,
      2.234375,
      -2.78125,
      -1.4375,
      -1.40625,
      -4.4375,
      5.84375,
      -1.8515625,
      -0.26953125,
      2.1875,
      3.203125,
      3.171875,
      3.296875,
      1.6875,
      1.703125,
      1.2578125,
      -5.21875,
      5,
      -1.421875,
      -3.09375,
      4.90625,
      3.28125,
      6.625,
      -2.1875,
      -2.21875,
      -2.109375,
      -3.59375,
      7.25,
      -3.15625,
      -0.6015625,
      7.5,
      -0.83203125,
      0.06005859375,
      -1.8984375,
      0.2333984375,
      1.1484375,
      -0.76171875,
      -1.8515625,
      8.875,
      6,
      -2.453125,
      -1.1015625,
      -4.09375,
      -2.859375,
      -1.6015625,
      -1.6875,
      0.42578125,
      -0.78515625,
      2.046875,
      0.76953125,
      -0.5703125,
      -1.734375,
      0.6484375,
      -1.75,
      2.578125,
      3.359375,
      0.359375,
      1.4921875,
      -1.3828125,
      1.734375,
      -2.125,
      1.96875,
      3.828125,
      -5.03125,
      1.3359375,
      3.078125,
      -0.78125,
      3.34375,
      2.25,
      -0.5234375,
      -1.3125,
      -0.6171875,
      0.9375,
      1.0703125,
      -1.1171875,
      0.87890625,
      -4.3125,
      1.2734375,
      4.8125,
      2.78125,
      -3.578125,
      5.9375,
      0.51953125,
      -2.796875,
      1.71875,
      -1.6171875,
      -4.15625,
      1.5234375,
      -3.234375,
      0.9140625,
      -0.130859375,
      -0.9765625,
      0.3125,
      1.4375,
      -6.8125,
      5,
      -3.328125,
      6.125,
      1.5625,
      -0.484375,
      0.52734375,
      -0.3671875,
      -0.65625,
      -1.109375,
      2.25,
      2.140625,
      -2.15625,
      1.03125,
      -3.703125,
      -0.126953125,
      -3.15625,
      -2.4375,
      4.625,
      -2.046875,
      2.46875,
      -2.109375,
      2.1875,
      -7.15625,
      -2.53125,
      -0.44140625,
      -0.291015625,
      -0.1318359375,
      2.8125,
      1.7109375,
      -1.2890625,
      1.609375,
      -2.96875,
      0.921875,
      -3.921875,
      -1.1171875,
      0.1455078125,
      -1.25,
      1.609375,
      0.76953125,
      -1.953125,
      1.65625,
      -0.875,
      -3.546875,
      -1.3203125,
      -1.7734375,
      2.0625,
      -1.0703125,
      -1.875,
      0.47265625,
      1.3828125,
      1.3671875,
      -0.65234375,
      1.0859375,
      0.69921875,
      3.0625,
      -0.7734375,
      2.296875,
      -0.91015625,
      -2.875,
      -3.359375,
      -3.625,
      -5.15625,
      1.65625,
      3.265625,
      -3.90625,
      1.5546875,
      0.036376953125,
      2.59375,
      1.796875,
      1.140625,
      -0.79296875,
      1.765625,
      1.7890625,
      0.890625,
      -0.134765625,
      2.078125,
      -0.859375,
      3.40625,
      -1.3359375,
      -3.171875,
      -2.453125,
      -1.5703125,
      -0.5234375,
      1.5,
      -0.71484375,
      -2.34375,
      -1.953125,
      -2.6875,
      -0.6171875,
      -3.453125,
      6.0625,
      2.140625,
      5.71875,
      3.0625,
      -0.70703125,
      0.474609375,
      -0.251953125,
      0.27734375,
      3.125,
      0.3359375,
      0.56640625,
      -0.1279296875,
      -0.6328125,
      2.59375,
      -3.875,
      -2.09375,
      -4.1875,
      0.5234375,
      4.53125,
      -0.1416015625,
      0.0155029296875,
      1.3984375,
      -0.9765625,
      0.9140625,
      0.263671875,
      3.9375,
      -1.2890625,
      -1.0625,
      -1.0234375,
      2.421875,
      1.2890625,
      -3.375,
      1.109375,
      0.77734375,
      -0.93359375,
      0.35546875,
      2.453125,
      6.125,
      -0.65234375,
      3.984375,
      -1.7578125,
      -4,
      -4.03125,
      3,
      -0.5625,
      0.201171875,
      -1.578125,
      -6.25,
      -0.5390625,
      -2.390625,
      -1.609375,
      6.21875,
      0.78125,
      3.59375,
      -0.609375,
      3.875,
      0.154296875,
      -5.65625,
      -3.3125,
      3.25,
      1.34375,
      -5.40625,
      -0.162109375,
      -4.34375,
      -0.4609375,
      -1.125,
      -8.25,
      0.80859375,
      1.4140625,
      3.703125,
      2.203125,
      0.154296875,
      2.125,
      -0.8359375,
      -4.28125,
      -2.984375,
      -1.0703125,
      2.921875,
      2.21875,
      0.890625,
      -2.984375,
      1.2578125,
      -3.625,
      1.1796875,
      -3.578125,
      4.59375,
      -0.5625,
      5.46875,
      1.4296875,
      4.84375,
      -8.5625,
      -2.296875,
      -2.75,
      -2.75,
      -3.40625,
      -0.3359375,
      0.8671875,
      1.578125,
      1.8359375,
      0.318359375,
      -3.125,
      -1.046875,
      -2.390625,
      3.53125,
      1.4375,
      0.34765625,
      -0.8984375,
      -0.1181640625,
      -5.21875,
      -1.4921875,
      2.28125,
      -2.140625,
      -3.3125,
      3.671875,
      -0.96875,
      4.9375,
      2.34375,
      0.26171875,
      -2.21875,
      4.375,
      -0.6328125,
      -4.34375,
      -5.8125,
      -0.60546875,
      -0.279296875,
      -5.59375,
      1.0546875,
      -3.34375,
      1.4765625,
      -4.5,
      0.03466796875,
      -0.41015625,
      -1.515625,
      0.70703125,
      5.8125,
      2.375,
      -2.484375,
      3.125,
      -3.75,
      6.4375,
      3.6875,
      0.5,
      2.265625,
      0.55078125,
      1.1171875,
      -4.46875,
      4.59375,
      -0.65625,
      -2.984375,
      3.546875,
      5.125,
      -3.90625,
      -0.0267333984375,
      1,
      1.125,
      -1.5078125,
      -0.054931640625,
      -3.046875,
      4.75,
      -1.46875,
      -0.89453125,
      -5.4375,
      1.1328125,
      2.03125,
      -1.3359375,
      2.375,
      -1.578125,
      3.03125,
      -3.9375,
      -4.71875,
      3.1875,
      2.15625,
      4.25,
      -3.421875,
      1.25,
      2.765625,
      1.359375,
      2.9375,
      -1.125,
      -4.09375,
      -1.34375,
      0.6171875,
      -5.09375,
      0.337890625,
      -4.8125,
      -0.271484375,
      -4.09375,
      0.69921875,
      -4.40625,
      0.9765625,
      0.17578125,
      -1.359375,
      -2.546875,
      -3.53125,
      -5.53125,
      -3.28125,
      -1.1640625,
      -1.40625,
      -6.53125,
      -2.421875,
      1.65625,
      3.8125,
      4.21875,
      5.90625,
      3.59375,
      -1.53125,
      0.71484375,
      -0.859375,
      0.267578125,
      0.296875,
      0.248046875,
      -1.765625,
      -2.203125,
      0.921875,
      -0.58984375,
      5.25,
      -3.46875,
      -2.4375,
      -3.3125,
      0.0927734375,
      -1.4765625,
      1.1796875,
      0.625,
      -0.80859375,
      4.65625,
      -2.859375,
      2.875,
      3.03125,
      -1.6328125,
      -5,
      4.0625,
      -1.015625,
      1.9140625,
      2.9375,
      0.333984375,
      -5,
      3.15625,
      3.859375,
      -4.25,
      3.625,
      1.1640625,
      -1.53125,
      -3.453125,
      0.28125,
      1.1640625,
      5.75,
      -1.7734375,
      3.5,
      4.125,
      -1.0859375,
      3.515625,
      5.5,
      -0.35546875,
      -2.0625,
      2.15625,
      0.44921875,
      -2,
      -2.484375,
      1.7265625,
      -2.765625,
      -4.71875,
      3.609375,
      2.515625,
      -0.9921875,
      -0.72265625,
      -1.5078125,
      4.40625,
      3.125,
      -3.859375,
      0.404296875,
      -4.15625,
      1.6796875,
      -2.9375,
      -1.1640625,
      -4.75,
      -0.490234375,
      -0.64453125,
      6.15625,
      -2.5625,
      -4.09375,
      5.0625,
      5.15625,
      -1.0546875,
      -1.1953125,
      5.0625,
      1.2109375,
      -0.9921875,
      -4.5,
      -2.484375,
      5.65625,
      1.3203125,
      4.96875,
      -0.98046875,
      1.3515625,
      0.96484375,
      -2.546875,
      -5.53125,
      1.171875,
      -2.421875,
      -4.8125,
      -3.171875,
      -2.40625,
      2.78125,
      -2.640625,
      4.25,
      3.96875,
      0.58203125,
      2.1875,
      0.3359375,
      2.6875,
      3.015625,
      -3.46875,
      1.4296875,
      1.328125,
      -2.9375,
      0.3984375,
      1.1328125,
      -2.140625,
      0.345703125,
      -2.546875,
      1.8359375,
      3.5,
      -0.84765625,
      -1.9765625,
      -7,
      2.234375,
      3.71875,
      5.125,
      -0.1708984375,
      -4.53125,
      1.5078125,
      1.3359375,
      -2.6875,
      -1.25,
      2.53125,
      0.73828125,
      1.5546875,
      -1.6328125,
      -1.0859375,
      4.78125,
      0.8125,
      1.7265625,
      -1.421875,
      -4.09375,
      -2.65625,
      -0.98046875,
      -3.375,
      -0.1552734375,
      -2.09375,
      5.9375,
      -1.859375,
      -1.0625,
      0.1416015625,
      5.96875,
      1.6015625,
      2.328125,
      0.1416015625,
      0.404296875,
      -0.310546875,
      3,
      2.671875,
      -3.5625,
      1.9296875,
      -0.150390625,
      -1.1484375,
      -2.59375,
      -1.6796875,
      -1.484375,
      1.34375,
      -3.890625,
      -0.40625,
      -0.1259765625,
      2.140625,
      -1.8515625,
      -9.625,
      0.75,
      1.15625,
      -3.25,
      -2.25,
      -2.390625,
      1.40625,
      6.5625,
      1,
      4.8125,
      0.193359375,
      -2.90625,
      3.40625,
      13.875,
      -3.125,
      -3.75,
      0.3984375,
      -1.296875,
      6.28125,
      6.46875,
      0.546875,
      2.640625,
      1.0546875,
      -0.396484375,
      3.625,
      0.734375,
      4.375,
      1.0078125,
      1.515625,
      3.15625,
      0.99609375,
      -3.265625,
      -5.875,
      -1.03125,
      -1.0703125,
      -1.484375,
      2.15625,
      -1.5,
      0.5234375,
      0.7421875,
      -3.109375,
      -1.8046875,
      -2.46875,
      -3.703125,
      -0.83984375,
      -0.1962890625,
      -1.984375,
      -0.703125,
      -3.890625,
      -0.9765625,
      0.55078125,
      -0.177734375,
      -3.84375,
      -5.65625,
      -6.15625,
      2.171875,
      -0.99609375,
      -4.96875,
      2.109375,
      -3.15625,
      -3.328125,
      0.00933837890625,
      -1,
      -1.1171875,
      0.2197265625,
      -6.6875,
      0.87890625,
      0.265625,
      -0.95703125,
      -1.3203125,
      -3.5625,
      -4.375,
      -4.4375,
      -1.3515625,
      -0.53515625,
      -0.45703125,
      -3.40625,
      -3.875,
      -3.21875,
      -0.83203125,
      1.9375,
      1.3125,
      1.1328125,
      -2.984375,
      -1.1953125,
      2.78125,
      2.875,
      -0.765625,
      -3.46875,
      2.171875,
      0.890625,
      0.97265625,
      2.5625,
      -3.265625,
      2.625,
      -2.0625,
      -0.9296875,
      -0.53125,
      1.4765625,
      -4.6875,
      0.373046875,
      1.9375,
      -2.421875,
      5.9375,
      -5.78125,
      3.4375,
      -0.1474609375,
      -6.4375,
      -0.4140625,
      1.125,
      1.765625,
      -2.28125,
      -0.99609375,
      2.078125,
      -1.296875,
      1.6875,
      0.427734375,
      -0.130859375,
      1.46875,
      0.734375,
      -5.21875,
      0.0693359375,
      1.234375,
      0.80859375,
      4.3125,
      2.375,
      -0.4609375,
      -0.875,
      4.40625,
      -1.28125,
      -1.5546875,
      -3.0625,
      -2.234375,
      6,
      1.1796875,
      -0.93359375,
      0.294921875,
      -7.0625,
      -3.65625,
      -1.484375,
      -5.25,
      4,
      -1.2265625,
      0.396484375,
      -3.46875,
      -4.125,
      -0.0390625,
      3.25,
      -4.5625,
      3.65625,
      2.3125,
      3.96875,
      -0.07421875,
      -3.515625,
      1.328125,
      0.8671875,
      -2.078125,
      -3.609375,
      3.421875,
      -3.0625,
      2.59375,
      5.03125,
      2.375,
      -4.8125,
      4.1875,
      -1.4140625,
      -4.6875,
      -0.11767578125,
      2.859375,
      -1.71875,
      -1.1328125,
      -4.6875,
      0.052734375,
      -0.5234375,
      -2.046875,
      -0.8203125,
      -5.46875,
      -2.484375,
      -0.9921875,
      3.296875,
      1.3671875,
      -4.875,
      2.59375,
      2.671875,
      -6.0625,
      -0.283203125,
      -4.8125,
      4.53125,
      -1.6171875,
      2.921875,
      4.53125,
      -0.73828125,
      -1.0625,
      1.015625,
      1.9375,
      -1.8671875,
      -4.3125,
      3.796875,
      2.09375,
      -3.90625,
      3.140625,
      3.296875,
      -1.9921875,
      -0.310546875,
      -4.375,
      -1.3359375,
      5.15625,
      3.53125,
      -3.46875,
      -2.125,
      -0.8828125,
      1.328125,
      -4.5625,
      -5.40625,
      4.0625,
      1.359375,
      2.046875,
      1.9296875,
      1.3125,
      -3.046875,
      -1.75,
      -0.40625,
      -2.21875,
      -3.40625,
      2.515625,
      -2.296875,
      3.59375,
      -3.3125,
      6.09375,
      2.8125,
      1.2109375,
      -1.625,
      0.1728515625,
      2.59375,
      1.1328125,
      -3.9375,
      0.453125,
      0.5390625,
      3.828125,
      -6.53125,
      4.1875,
      -2.859375,
      2.9375,
      -4.8125,
      3.921875,
      -0.6875,
      -0.5,
      -5.0625,
      -4.1875,
      -3.265625,
      3.296875,
      0.99609375,
      0.84765625,
      3.328125,
      -0.40234375,
      0.291015625,
      -0.279296875,
      -3.25,
      1.578125,
      -2.34375,
      -0.057861328125,
      1.15625,
      -0.609375,
      0.7421875,
      0.3359375,
      7.25,
      -2.78125,
      -1.0703125,
      -2.359375,
      -2.328125,
      -0.59765625,
      -4.75,
      2.53125,
      -1.8125,
      -3.5,
      3.40625,
      1.8515625,
      -1.90625,
      3.125,
      1.0625,
      -2.78125,
      4.78125,
      3.25,
      -5.4375,
      5.0625,
      -1.078125,
      -3.984375,
      0.478515625,
      -0.7890625,
      -0.97265625,
      -5.8125,
      -0.30859375,
      4.09375,
      -3.484375,
      0.1376953125,
      2.359375,
      0.7734375,
      0.32421875,
      -2.859375,
      5.15625,
      1.765625,
      1.6484375,
      2.78125,
      4.09375,
      3.125,
      -4.78125,
      0.51953125,
      -1.8828125,
      -0.470703125,
      -2.390625,
      -4.65625,
      2.375,
      -1.1875,
      3.125,
      4.53125,
      -1.640625,
      -9.625,
      -3.71875,
      2.171875,
      -2.140625,
      2.8125,
      1.9765625,
      0.9765625,
      -2,
      0.69140625,
      0.84765625,
      4.1875,
      -0.9921875,
      -0.84765625,
      -5.5625,
      0.09619140625,
      -0.78515625,
      -5.6875,
      0.73828125,
      0.91796875,
      -0.330078125,
      -2.25,
      0.5,
      -0.96484375,
      0.99609375,
      3.53125,
      -4.3125,
      2.25,
      -1,
      -0.4375,
      5.90625,
      0.4921875,
      5.15625,
      3.078125,
      -2.875,
      -5.28125,
      0.1865234375,
      -0.2421875,
      1.265625,
      1.8359375,
      1.171875,
      5.21875,
      0.373046875,
      2.40625,
      -6.8125,
      5.03125,
      0.09765625,
      -11.1875,
      2.375,
      -3.015625,
      0.8203125,
      -0.7578125,
      -8.3125,
      -3.046875,
      4.21875,
      -0.796875,
      -0.8046875,
      5.78125,
      0.47265625,
      0.185546875,
      1.5390625,
      -0.52734375,
      -4.9375,
      2.25,
      3.953125,
      -2.3125,
      0.28125,
      3.796875,
      -1.953125,
      0.78125,
      -0.197265625,
      3.015625,
      0.318359375,
      -3.375,
      3.421875,
      2.234375,
      -2.421875,
      -3.234375,
      -4.15625,
      -0.1328125,
      1.0859375,
      -3.765625,
      1.3046875,
      -2.15625,
      2.328125,
      -1.8125,
      -0.038818359375,
      -0.365234375,
      -3.984375,
      -1.671875,
      -2.75,
      -2.125,
      0.84765625,
      3,
      3.03125,
      -2.34375,
      -1.9765625,
      4.25,
      0.400390625,
      -0.640625,
      -2.65625,
      4.0625,
      -3.09375,
      -3.125,
      -2.515625,
      4.1875,
      -2.75,
      -3.1875,
      1.9140625,
      -0.5625,
      -2.203125,
      -3.453125,
      -2.78125,
      2.421875,
      -1.921875,
      -1.5234375,
      -2.296875,
      -0.9375,
      3.859375,
      4.6875,
      -4.84375,
      -3.421875,
      -2.796875,
      -0.72265625,
      -5.53125,
      -3.609375,
      -0.6796875,
      -2.9375,
      0.8671875,
      5.1875,
      -0.150390625,
      0.9921875,
      0.349609375,
      -6.71875,
      -2.421875,
      3.859375,
      1.453125,
      -3.734375,
      1.375,
      -1.0546875,
      -4.15625,
      4.84375,
      9.5625,
      2.53125,
      -3.1875,
      1.0625,
      -1.1328125,
      -2.515625,
      -1.734375,
      2.4375,
      -0.48046875,
      -5.125,
      5.8125,
      -2.8125,
      4.1875,
      2.125,
      -1.265625,
      5.75,
      -4.9375,
      3,
      -1.2578125,
      0.62890625,
      3.234375,
      -4.5625,
      -1.828125,
      -3.484375,
      -2.734375,
      0.99609375,
      -0.5546875,
      1.1875,
      -1.234375,
      2.625,
      2.28125,
      0.74609375,
      -0.609375,
      -0.2373046875,
      5.3125,
      -4.46875,
      -0.443359375,
      -2.296875,
      -1.734375,
      -0.322265625,
      -2.59375,
      1.5859375,
      -5.0625,
      2.375,
      0.7578125,
      1.609375,
      1.1640625,
      1.7109375,
      -3.390625,
      -2.3125,
      -5.84375,
      1.1796875,
      1.140625,
      4.90625,
      1.34375,
      1.9140625,
      3.078125,
      0.279296875,
      3.4375,
      4.125,
      6.25,
      -3.640625,
      0.69921875,
      -0.8125,
      0.43359375,
      -0.087890625,
      -1.3203125,
      -0.75,
      1.1328125,
      4.625,
      0.31640625,
      -2.15625,
      -3.46875,
      -1.625,
      -2.53125,
      -1.1171875,
      1.6328125,
      2.515625,
      0.90234375,
      0.86328125,
      -1.25,
      0.77734375,
      0.796875,
      5.125,
      0.80859375,
      0.55078125,
      -2.671875,
      1.8203125,
      -2.734375,
      -2.125,
      2.859375,
      -2.0625,
      2.375,
      -1.0546875,
      -1.2890625,
      -0.44140625,
      2.078125,
      -3.859375,
      3.203125,
      -1.6640625,
      2.546875,
      1.2421875,
      1.515625,
      -2.703125,
      1.4921875,
      -0.01287841796875,
      2.515625,
      -4.0625,
      -0.890625,
      2.828125,
      2.6875,
      0.01470947265625,
      0.36328125,
      0.01336669921875,
      1.0859375,
      0.71484375,
      -1.515625,
      -1.0625,
      -0.85546875,
      3.171875,
      -0.486328125,
      0.6484375,
      1.8984375,
      0.458984375,
      -3.75,
      2.203125,
      -0.96875,
      -0.51171875,
      -3.390625,
      -0.193359375,
      2.984375,
      1.0703125,
      -0.10107421875,
      -0.90234375,
      -3.546875,
      -2.21875,
      -2.703125,
      -3.890625,
      -0.287109375,
      -2.3125,
      -4.59375,
      1.78125,
      2.71875,
      0.40625,
      0.484375,
      0.2734375,
      1.3984375,
      0.263671875,
      -2.296875,
      -0.267578125,
      1.34375,
      0.29296875,
      -2.46875,
      2.4375,
      1.265625,
      2.21875,
      2.15625,
      -0.71875,
      0.474609375,
      -0.90625,
      0.6796875,
      0.458984375,
      -2.171875,
      0.365234375,
      0.53515625,
      -1.6328125,
      -0.6953125,
      -0.86328125,
      -1.1328125,
      0.1220703125,
      -1.3828125,
      -0.83984375,
      1.4140625,
      0.022216796875,
      -2.15625,
      2.296875,
      4.28125,
      -3.25,
      -1.6875,
      -3.140625,
      -0.62109375,
      -0.484375,
      1.4140625,
      -4.53125,
      0.609375,
      -3.296875,
      -1.203125,
      -0.671875,
      1.1015625,
      1.578125,
      -3.90625,
      -0.8984375,
      -1.765625,
      0.451171875,
      0.048095703125,
      2.609375,
      1.203125,
      -5.09375,
      -3.265625,
      0.70703125,
      -0.58203125,
      -0.43359375,
      1.2421875,
      -2.046875,
      -1.546875,
      2.71875,
      3.25,
      -0.83984375,
      -2,
      1.1484375,
      0.69921875,
      0.306640625,
      1.9375,
      -0.14453125,
      1.8828125,
      0.16015625,
      -1.484375,
      0.4609375,
      -1.09375,
      -0.51171875,
      -0.486328125,
      -0.55859375,
      0.28515625,
      -1.9609375,
      -1.5703125,
      -2.140625,
      0.091796875,
      -2.6875,
      1.8125,
      1.1953125,
      -1.6484375,
      1.375,
      1.5234375,
      -0.29296875,
      2.453125,
      1.2421875,
      2.625,
      -0.62109375,
      0.345703125,
      0.72265625,
      1.953125,
      1.765625,
      1.2890625,
      -2.25,
      -1.5234375,
      0.2470703125,
      1.015625,
      0.90234375,
      -3.453125,
      3.375,
      1.0625,
      0.65234375,
      1.7265625,
      1.046875,
      0.86328125,
      1.1875,
      -4.03125,
      2.28125,
      2.703125,
      -0.69140625,
      -0.462890625,
      0.89453125,
      0.36328125,
      -0.74609375,
      -1.2578125,
      -0.33203125,
      -0.99609375,
      3.5625,
      -0.00469970703125,
      1.1171875,
      2.03125,
      -2.296875,
      -0.09912109375,
      -1.453125,
      1.3046875,
      -2.03125,
      5.09375,
      -2.453125,
      1.390625,
      2.8125,
      0.337890625,
      -2.09375,
      -0.6171875,
      -7.90625,
      -2.046875,
      -0.6953125,
      0.7421875,
      -0.54296875,
      -1.0390625,
      -1.515625,
      -2.296875,
      -0.189453125,
      0.59765625,
      -2.109375,
      2.359375,
      2.109375,
      1.7890625,
      2.296875,
      0.486328125,
      -3.609375,
      -0.72265625,
      3.109375,
      -1.4921875,
      3.375,
      -0.1328125,
      -2.078125,
      -1.1953125,
      -2.03125,
      -5.25,
      -0.7421875,
      -1.7109375,
      1.1015625,
      0.90234375,
      6.1875,
      1.265625,
      -2.359375,
      -0.5703125,
      0.72265625,
      2.5625,
      -1.203125,
      -2.5,
      3.3125,
      -0.7890625,
      1.1640625,
      -2.328125,
      -0.609375,
      -2.234375,
      0.5703125,
      1.4609375,
      -0.45703125,
      3.4375,
      -0.609375,
      -1.3203125,
      -0.04833984375,
      -0.09814453125,
      0.48046875,
      1.296875,
      0.12109375,
      4.6875,
      0.310546875,
      0.734375,
      2.125,
      3.6875,
      0.1494140625,
      -0.84765625,
      3.140625,
      0.0947265625,
      3.1875,
      4,
      -2.921875,
      -2.921875,
      2.109375,
      0.7578125,
      0.37109375,
      0.392578125,
      0.2099609375,
      3.5,
      -0.8125,
      0.703125,
      1.375,
      -0.408203125,
      -2.65625,
      -1.640625,
      2.78125,
      -4.8125,
      -0.3359375,
      0.69921875,
      -2,
      -0.2294921875,
      0.953125,
      4.40625,
      1.2578125,
      0.294921875,
      1.46875,
      1.0859375,
      -0.1396484375,
      0.42578125,
      -1.390625,
      1.9296875,
      3.625,
      -0.171875,
      -2.375,
      1.8984375,
      3.03125,
      4.0625,
      -0.017822265625,
      -2.390625,
      2.96875,
      0.7265625,
      1.0078125,
      0.890625,
      -1.4765625,
      2.03125,
      2.03125,
      -0.408203125,
      -0.56640625,
      -1.453125,
      0.5234375,
      2.765625,
      0.55859375,
      -2.640625,
      3.625,
      1.015625,
      -1.90625,
      -1.1328125,
      -0.54296875,
      -1.3203125,
      -1.5390625,
      -2.625,
      -1.015625,
      -2.03125,
      4.78125,
      -3.125,
      0.322265625,
      2.234375,
      2.296875,
      2.734375,
      2.859375,
      1.1171875,
      2.265625,
      -4.9375,
      -0.80078125,
      1.703125,
      -1.4765625,
      -4.4375,
      1.640625,
      -2.21875,
      -5.03125,
      0.75390625,
      -1.1015625,
      -1.53125,
      -1.6953125,
      -0.31640625,
      -2,
      -2.5,
      0.74609375,
      -1.5625,
      1.5546875,
      -4.375,
      -1.0078125,
      -0.5703125,
      3.703125,
      1.0078125,
      -1.765625,
      2.09375,
      -0.205078125,
      0.89453125,
      0.359375,
      -0.59765625,
      -0.77734375,
      -1.9296875,
      1.2109375,
      1.71875,
      -1.0390625,
      -0.96484375,
      -1.34375,
      3.625,
      -1.8359375,
      -0.92578125,
      -1.4296875,
      -1.21875,
      -0.06884765625,
      6.90625,
      2.546875,
      0.9453125,
      -2.34375,
      -2.171875,
      -0.58203125,
      3.703125,
      -0.78125,
      -1.515625,
      -2.1875,
      3.171875,
      -1.734375,
      -1.3125,
      -1.0703125,
      0.68359375,
      -1.4453125,
      -3.265625,
      0.423828125,
      -4.09375,
      0.244140625,
      4.8125,
      1.15625,
      -0.0615234375,
      -1.765625,
      2.609375,
      -3.296875,
      3.421875,
      -1.1328125,
      0.078125,
      5.125,
      0.6796875,
      0.2060546875,
      0.9765625,
      0.546875,
      0.2578125,
      2.390625,
      1.140625,
      2.453125,
      2.5,
      -0.404296875,
      -0.921875,
      0.234375,
      2.265625,
      -0.67578125,
      -3.140625,
      -1.1328125,
      -1.328125,
      -4.25,
      0.25390625,
      3.828125,
      1.28125,
      0.1396484375,
      1.15625,
      2.171875,
      -0.01318359375,
      2.6875,
      2.859375,
      0.08056640625,
      0.1748046875,
      -1.0390625,
      -2.703125,
      -2.65625,
      1.28125,
      -0.62890625,
      1.171875,
      1.2265625,
      -1.3515625,
      1.359375,
      -1.71875,
      4.90625,
      -2.375,
      0.54296875,
      -0.06689453125,
      -1.4609375,
      -2.8125,
      -2.453125,
      -2.53125,
      2.84375,
      -1.4296875,
      -0.05615234375,
      2.140625,
      0.072265625,
      -1.6484375,
      -1.3046875,
      -0.15625,
      3.03125,
      -0.4609375,
      -3.578125,
      -0.43359375,
      3.625,
      -1.7265625,
      0.828125,
      4.5,
      1.9765625,
      0.072265625,
      0.09326171875,
      1.8671875,
      -3.90625,
      0.1787109375,
      0.02099609375,
      1.1796875,
      3.109375,
      -2.484375,
      -4.09375,
      2.59375,
      1.921875
    ],
    "summary": "通过预注册的随机对照实验，在真实学校环境中比较单独使用LLM、传统笔记以及两者结合对中学生阅读理解与记忆的影响，并采用定量与定性相结合的混合方法进行分析。",
    "structure": {
      "sections": [
        {
          "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Affiliations:",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 14
        },
        {
          "title": "Main",
          "level": 1,
          "start_line": 18
        },
        {
          "title": "Results",
          "level": 1,
          "start_line": 46
        },
        {
          "title": "Learning outcomes",
          "level": 1,
          "start_line": 50
        },
        {
          "title": "Behavioural engagement",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "Prompting behaviour",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "Learning experiences and perceptions",
          "level": 1,
          "start_line": 93
        },
        {
          "title": "Activity preferences",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "Future use",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "Discussion",
          "level": 1,
          "start_line": 125
        },
        {
          "title": "Materials and Methods",
          "level": 1,
          "start_line": 153
        },
        {
          "title": "Participants",
          "level": 1,
          "start_line": 157
        },
        {
          "title": "Experimental design and procedure",
          "level": 1,
          "start_line": 165
        },
        {
          "title": "Setup and system",
          "level": 1,
          "start_line": 193
        },
        {
          "title": "Apartheid in South Africa",
          "level": 1,
          "start_line": 199
        },
        {
          "title": "AI Chatbot ②",
          "level": 1,
          "start_line": 209
        },
        {
          "title": "Notepad",
          "level": 1,
          "start_line": 213
        },
        {
          "title": "Learning task and materials (Session 1)",
          "level": 1,
          "start_line": 228
        },
        {
          "title": "Test task and materials (Session 2)",
          "level": 1,
          "start_line": 242
        },
        {
          "title": "Survey questions",
          "level": 1,
          "start_line": 256
        },
        {
          "title": "Analytic strategies",
          "level": 1,
          "start_line": 264
        },
        {
          "title": "Estimation of condition effects on text comprehension and retention",
          "level": 1,
          "start_line": 270
        },
        {
          "title": "Qualitative exploration of student prompts",
          "level": 1,
          "start_line": 302
        },
        {
          "title": "Quantitative exploration of students' learning experience",
          "level": 1,
          "start_line": 308
        },
        {
          "title": "Qualitative exploration of students' activity preferences",
          "level": 1,
          "start_line": 312
        },
        {
          "title": "Data availability",
          "level": 1,
          "start_line": 325
        },
        {
          "title": "Code availability",
          "level": 1,
          "start_line": 329
        },
        {
          "title": "Ethics declarations",
          "level": 1,
          "start_line": 333
        },
        {
          "title": "Competing interests",
          "level": 1,
          "start_line": 335
        },
        {
          "title": "Acknowledgements",
          "level": 1,
          "start_line": 339
        },
        {
          "title": "Supplementary Material",
          "level": 1,
          "start_line": 343
        },
        {
          "title": "Table of Contents",
          "level": 1,
          "start_line": 345
        },
        {
          "title": "Supplementary Information",
          "level": 1,
          "start_line": 347
        },
        {
          "title": "Supplementary Tables",
          "level": 1,
          "start_line": 351
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 374
        },
        {
          "title": "1 Supplementary Information",
          "level": 1,
          "start_line": 451
        },
        {
          "title": "1.1 Participant Exclusion Criteria",
          "level": 1,
          "start_line": 453
        },
        {
          "title": "2 Supplementary Tables",
          "level": 1,
          "start_line": 464
        },
        {
          "title": "2.1 Student Characteristics",
          "level": 1,
          "start_line": 466
        },
        {
          "title": "2.2 Familiarity with Learning Activities",
          "level": 1,
          "start_line": 475
        },
        {
          "title": "2.3 Descriptive Statistics",
          "level": 1,
          "start_line": 483
        },
        {
          "title": "2.4 Mixed Effects Regression Results",
          "level": 1,
          "start_line": 489
        },
        {
          "title": "2.5 Behavioural Engagement",
          "level": 1,
          "start_line": 495
        },
        {
          "title": "2.6 Student Task Instructions",
          "level": 1,
          "start_line": 501
        },
        {
          "title": "2.7 Test Questions",
          "level": 1,
          "start_line": 567
        },
        {
          "title": "2.8 Inter-rater Reliability Results",
          "level": 1,
          "start_line": 589
        },
        {
          "title": "2.9 Survey Questions and Response Scales",
          "level": 1,
          "start_line": 595
        },
        {
          "title": "2.10 Learning Experiences and Perceptions",
          "level": 1,
          "start_line": 624
        },
        {
          "title": "2.11 Coding Scheme Activity Preferences",
          "level": 1,
          "start_line": 630
        },
        {
          "title": "2.12 Coding Scheme Prompt Interactions",
          "level": 1,
          "start_line": 653
        },
        {
          "title": "2.13 Frequency of Prompt Types",
          "level": 1,
          "start_line": 691
        }
      ]
    },
    "suggested_tags": [
      "教育技术",
      "LLM应用",
      "学习科学",
      "人机交互"
    ],
    "tag_suggestions": [
      {
        "name": "教育技术",
        "confidence": 0.98,
        "reason": "论文核心研究领域是评估大型语言模型（LLM）在中学教育场景中对学生学习效果（阅读理解与记忆）的影响，属于教育技术与学习科学的交叉研究。"
      },
      {
        "name": "LLM应用",
        "confidence": 0.95,
        "reason": "研究聚焦于生成式AI（特别是LLM，如ChatGPT）在教育中的实际使用效果、学生交互模式（提示行为原型）及其对学生认知过程的影响。"
      },
      {
        "name": "学习科学",
        "confidence": 0.9,
        "reason": "研究基于认知科学理论（如建构-整合模型、加工水平理论），通过随机对照实验定量比较传统笔记与AI辅助学习对长期记忆和理解的影响，探讨认知参与机制。"
      },
      {
        "name": "人机交互",
        "confidence": 0.85,
        "reason": "论文采用混合方法（定量实验与定性分析），重点分析了学生与LLM的交互行为、感知有用性及认知负荷，属于教育场景下的人机交互研究。"
      }
    ],
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283549586",
          "title": "ChatGPT ile tasarlanan matematiksel oyunların 4. sınıf öğrencilerinin matematik motivasyon ve tutumlarına etkisi",
          "authors": [
            "Ramazan Divrik",
            "Ömer Çelik",
            "Zeynep Elmas"
          ],
          "year": 2025,
          "venue": "Kocaeli Üniversitesi Eğitim Dergisi",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282974790",
          "title": "Artificial intelligence and its effects on critical thinking and problem-solving abilities in higher education",
          "authors": [
            "Ide Aprianto",
            "Sofyan Sofyan",
            "Sophia Rahmawati",
            "Susanti Sufyadi"
          ],
          "year": 2025,
          "venue": "Indonesian Journal of Educational Development",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283138035",
          "title": "L'Intelligence Artificielle dans la Formation des Enseignants des SVT : Entre Adoption Prometteuse et Défis Persistants",
          "authors": [
            "Zerrouqi Zahra",
            "Laghmari Mustapha",
            "Bouzidi Chaymae",
            "E. Ahlam",
            "Mazza Fatima Zahra"
          ],
          "year": 2025,
          "venue": "International Journal For Multidisciplinary Research",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282755329",
          "title": "An AI for an AI: AI-generated interactive animated questions as a defense against AI-based cheating",
          "authors": [
            "Saleem Hamady"
          ],
          "year": 2025,
          "venue": "The Physical Educator",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282955449",
          "title": "STEM Education: Understanding Secondary Students’ Epistemic Cognition in the Design Process with the Support of a Personalized Multi-Agent System",
          "authors": [
            "Lei Gao",
            "Morris Siu-Yung Jong",
            "Ching-sing Chai",
            "Keru Li"
          ],
          "year": 2025,
          "venue": "Computers &amp; Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283326712",
          "title": "Effects of LLM Use and Note-Taking on Reading Comprehension and Memory: A Randomised Experiment in Secondary Schools",
          "authors": [
            "Pia Kreijkes",
            "Viktor Kewenig",
            "Martina Kuvalja",
            "Mina Lee",
            "Jake M. Hofman",
            "Sylvia Vitello",
            "Abigail Sellen",
            "Sean Rintel",
            "Daniel G. Goldstein",
            "David Rothschild",
            "Lev Tankelevitch",
            "Tim Oates"
          ],
          "year": 2025,
          "venue": "Computers &amp; Education",
          "citation_count": 6
        },
        {
          "external_id": "CorpusId:283351055",
          "title": "Will AI Write the Next \"Chapter\" in Literature Reviews?",
          "authors": [
            "Felix Blanc-Durand",
            "M. Koopman",
            "S. P. Patel",
            "M. Aldea",
            "J. Kather"
          ],
          "year": 2025,
          "venue": "Annals of Oncology",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282580958",
          "title": "Do generative artificial intelligence (GenAI) and science education mix? A systematic review of the literature",
          "authors": [
            "Kason Ka Ching Cheung",
            "Amina Zerouali",
            "Jenna Koenen",
            "S. Erduran"
          ],
          "year": 2025,
          "venue": "Studies in science education",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282432222",
          "title": "Use of ChatGPT in nursing education: A mixed method research on student perceptions and experiential practice recommendations.",
          "authors": [
            "Suna Uysal Yalçın",
            "Y. Dikmen"
          ],
          "year": 2025,
          "venue": "Nurse Education in Practice",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281931116",
          "title": "Exploring the Impact of AI Tools on Cognitive Skills: A Comparative Analysis",
          "authors": [
            "Nurlan Musazade",
            "J. Mezei",
            "Xiaolu Wang"
          ],
          "year": 2025,
          "venue": "Algorithms",
          "citation_count": 1
        }
      ],
      "citations_fetched_at": "2025-12-16T21:43:30.232272",
      "references": [
        {
          "external_id": "CorpusId:267242459",
          "title": "Generative AI Professional Development Needs for Teacher Educators",
          "authors": [
            "Matthew Nyaaba",
            "Xiaoming Zhai"
          ],
          "year": 2024,
          "venue": "Journal of AI",
          "citation_count": 42
        },
        {
          "external_id": "CorpusId:265352181",
          "title": "NERIF: GPT-4V for Automatic Scoring of Drawn Models",
          "authors": [
            "Gyeong-Geon Lee",
            "Xiaoming Zhai"
          ],
          "year": 2023,
          "venue": "Journal of Science Education and Technology",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:264144600",
          "title": "Efficacy and limitations of ChatGPT as a biostatistical problem-solving tool in medical education in Serbia: a descriptive study",
          "authors": [
            "Aleksandra Ignjatović",
            "Lazar Stevanović"
          ],
          "year": 2023,
          "venue": "Journal of Educational Evaluation for Health Professions",
          "citation_count": 31
        },
        {
          "external_id": "CorpusId:261049075",
          "title": "Elucidating STEM Concepts through Generative AI: A Multi-modal Exploration of Analogical Reasoning",
          "authors": [
            "Chen Cao",
            "Zijian Ding",
            "Gyeong-Geon Lee",
            "Jiajun Jiao",
            "Jionghao Lin",
            "Xiaoming Zhai"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:259968382",
          "title": "Artificial Intelligence Generative Tools and Conceptual Knowledge in Problem Solving in Chemistry",
          "authors": [
            "Wajeeh M. Daher",
            "Hussam Diab",
            "A. Rayan"
          ],
          "year": 2023,
          "venue": "Inf.",
          "citation_count": 46
        },
        {
          "external_id": "CorpusId:257943792",
          "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
          "authors": [
            "Tufan Adiguzel",
            "M. H. Kaya",
            "Fatih Kursat Cansu"
          ],
          "year": 2023,
          "venue": "Contemporary Educational Technology",
          "citation_count": 596
        },
        {
          "external_id": "CorpusId:259196547",
          "title": "A Testing Load: Investigating Test Mode Effects on Test Score, Cognitive Load and Scratch Paper Use with Secondary School Students",
          "authors": [
            "James Pengelley",
            "P. Whipp",
            "N. Rovis-Hermann"
          ],
          "year": 2023,
          "venue": "Educational Psychology Review",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:258846153",
          "title": "Human-like problem-solving abilities in large language models using ChatGPT",
          "authors": [
            "G. Orrú",
            "Andrea Piarulli",
            "C. Conversano",
            "A. Gemignani"
          ],
          "year": 2023,
          "venue": "Frontiers in Artificial Intelligence",
          "citation_count": 137
        },
        {
          "external_id": "CorpusId:258570040",
          "title": "Revolutionizing Medical Education: Can ChatGPT Boost Subjective Learning and Expression?",
          "authors": [
            "R. Seetharaman"
          ],
          "year": 2023,
          "venue": "Journal of medical systems",
          "citation_count": 69
        },
        {
          "external_id": "CorpusId:267376872",
          "title": "ChatGPT in Education",
          "authors": [
            "Sayım Aktay",
            "Seçkin Gök",
            "Dilşat Uzunoğlu"
          ],
          "year": 2023,
          "venue": "Türk Akademik Yayınlar Dergisi",
          "citation_count": 44
        }
      ],
      "references_fetched_at": "2025-12-16T21:43:30.878453"
    }
  },
  "25ba1751-4fe9-4436-9e78-28c28672d0eb": {
    "id": "25ba1751-4fe9-4436-9e78-28c28672d0eb",
    "filename": "ASC4459881735682400.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/25ba1751-4fe9-4436-9e78-28c28672d0eb_ASC4459881735682400.pdf",
    "status": "completed",
    "created_at": "2025-12-16 22:43:06.059507",
    "updated_at": "2025-12-16 14:45:11.809002",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "A Systematic Review of Automatic Neural Question Generation",
    "markdown_content": "# A Systematic Review of Automatic Neural Question Generation\n\nAsmaa M. Abdelwahab, Mahmoud M. Eid\n\nHigher Institute of Computers and Information Technology, Computer Science Department, El-Shorouk Academy, Cairo, Egypt\n\nEmail: asmaa. Abdelwahab@sha.edu.eq, mahmoud.eid@sha.edu.eq,\n\n# 1 Abstract\n\nThe ability to formulate meaningful questions is a fundamental aspect of both human and artificial intelligence. Neural Question Generation (NQG) uses deep learning techniques to automatically generate relevant questions from a given context. NQG systems have significant applications in improving question-answering models, facilitating educational tools, and enhancing conversational agents such as chatbots. However, a key challenge in NQG is the effective selection of target sentences and concepts for question formulation. This paper presents a systematic literature review (SLR) of NQG, analyzing different datasets, input preprocessing methods, methodologies, and evaluation techniques. We also highlight emerging trends and future directions in the field. Our review provides a comprehensive overview of NQG research, offering insights into current progress and remaining challenges. We find that all NQG models share a common Seq2Seq framework. In addition, the integration of Seq2Seq with attention mechanisms, as well as the use of part-of-speech (POS) tagging and named entity recognition (NER), contributes to the generation of accurate questions.\n\nIndex Terms—Natural Language Processing (NLP), Neural Question Generation (NQG), Deep Neural Networks, Question Answering Systems, Systematic Literature Review (SLR).\n\n# 1. INTRODUCTION\n\nNatural Language Processing (NLP) is a central subfield of computer science and artificial intelligence that focuses on enabling computers to understand and interact with human language. A fundamental challenge in NLP is training machines to process and analyze large amounts of natural language data (Joseph, 2016) (Sarkar, S,2025). The overall goal is to develop systems that can understand the content of various text formats, including sentences, queries, paragraphs, and documents. NLP techniques facilitate tasks such as text classification, where textual units are assigned labels or tags (Yang, 2020) (Maity, 2025). Applications of NLP range from answering questions and spam detection to sentiment analysis and news categorization. The sources of text data are diverse, including web content, email, forums, social media, and user reviews.\n\nAutomated text classification uses a variety of methods, including rule-based techniques and machine learning algorithms such as decision trees, naive Bayes, and k-means clustering (Semerikov, S. O, 2025) (Shervin et al., 2021). In addition, deep learning approaches, particularly those using neural networks, have gained prominence. Preprocessing steps, which can include punctuation removal, word segmentation, stop word filtering, and stemming (Elbes, 2019) (AlKhuzay, 2024), are critical to improving classifier performance. Feature selection methods, including information gain (IG), expected cross entropy (ECE), mutual information (MI), Gini index (GI), and chi-square (CHI) (Mucciaccia, 2025) (Bennabi, 2020), also play an important role in optimizing results.\n\nThis paper primarily focuses on neural Question Generation (QG), which uses deep neural networks to automatically generate questions from various inputs, such as raw text, databases, or semantic representations. Historically, question generation has relied on heuristic methods that rely heavily on human-designed transformation and generation rules, making it difficult to adapt to different domains (Heilman, 2011; Chali and Hasan, 2015). In contrast, Serban et al. (2016) introduced a neural network approach for generating factual questions from structured data. The ability to generate effective questions is crucial for assessing knowledge and promoting self-directed learning in educational contexts. In addition, QG can improve question-answering systems and enable chatbots to engage more dynamically in conversations.\n\nThe rest of this paper is organized as follows: The second section outlines the research methodology, specifically a Systematic Literature Review (SLR). The third section covers input text preprocessing techniques, including tokenization, segmentation, and the use of NLP tools such as word embeddings, Part-Of-Speech (POS) tagging, and Named Entity Recognition (NER). We will also explore neural question generation models, such as the sequence-to-sequence (seq2seq) model using Gated Recurrent Units (GRU) and seq2seq models with attention mechanisms. In addition, we will discuss evaluation metrics, including BLEU and precision. Finally, the fourth section presents conclusions and suggestions for future research.\n\n# 2. METHODOLOGY\n\nThe research approach follows the Systematic Literature Review (SLR) guidelines for the discipline of computer engineering as proposed by Kitchenham and Charter (Kitchenham, 2012). Figure 2.1 illustrates the key stages of our process, which we will discuss in the following sections.\n\nIn the planning stage, we defined our research topics and established the basic elements of the review protocol. To minimize subjectivity, we required that each phase begin only after the previous one had been thoroughly evaluated and approved.\n\nThe search strategy includes the criteria for selecting studies, the methods used, the search strings used, and the assessment of study quality. A significant portion of the third phase is devoted to developing our data extraction strategy. Finally, the final phase of the systematic review involves the preparation of a synthesis matrix to summarize and analyze the results.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/c268a39ab7c480d748d8c8ee361bfff22e7a144760aad18f81290a2ed00b2b71.jpg)  \nFigure 2.1: The key stages of our process (SLR).\n\n# 2.1 Research Questions\n\n# 2.1.1 Old Research Questions:\n\n[1] What is text classification and when did it originate?  \n[2] What are the different applications of text classification?  \n[3] Which languages are of interest for classification in this research?\n\n[4] What are the limitations and challenges of existing text classification methods?\n\n4.1 What are the limitations and challenges of existing automatic text classification (ATC) methods?\n\n[5] What data sets are available to evaluate model performance?\n\n5.1 What is an appropriate approach to document representation?  \n5.2 What are the different types of data preprocessing techniques?  \n5.3 How can unstructured data be handled effectively?\n\n[6] What are the appropriate methods for feature extraction and feature selection?  \n[7] What techniques are used for text classification, especially for news categorization and question answering applications? Which models perform best in these areas?  \n7.1 What techniques are used in ATC and which models are most effective?  \n[8] What solutions exist to improve the performance of current techniques?  \n[9] What methods are used to evaluate the performance of text classification models?  \n[10] What are the future research directions in text classification, especially in automatic text classification (ATC)?\n\n# 2.1.2 New Research Questions:\n\nThe primary objective of this research will be achieved by answering the following questions:\n\nRQ1. What is Neural Question Generation (NQG)?  \nRQ2. What are the different applications of NQG?  \nRQ3. Which languages are of interest for NQG research?  \nRQ4. What are the limitations and challenges of existing NQG methods?  \nRQ5. What benchmark data sets are available to evaluate the performance of NQG models?  \nRQ5.1 What is an appropriate approach for representing words?  \nRQ5.2 What are the different types of input preprocessing techniques?  \nRQ6. Which techniques are used in NQG?  \nRQ7. What are some possible solutions and strategies to improve the performance of current NQG methods?  \nRQ8. What methods are used to evaluate the performance of NQG models?  \nRQ9. What are future research directions for NQG?\n\n# 2.2 Data Sources and Search Strategy\n\nTable 2.1 illustrates how we identified research publications in computer science and software engineering using various database sources. The search terms were defined to include the following keywords, which were generated using logical operators to optimize the search results:\n\n1. Search string 1: ('document' OR 'text') AND ('classifier' OR 'categorization' OR 'classification') AND ('document representation' OR 'document preprocessing' OR 'models' OR 'methods' OR 'application' OR 'evaluation' OR 'assessment' OR 'challenges' OR 'limitations').  \n2. Search string 2: ('document' OR 'text') AND ('classifier' OR 'categorization' OR 'classification') AND ('research') AND ('future' OR 'trend' OR 'direction').  \n3. Search string 3: ('characteristic' OR 'attribute') AND ('selection' OR 'selected') AND ('text' OR 'document') AND ('classification' OR 'classifier' OR 'categorization').\n\nThese search strings were adapted to take advantage of the built-in tools for refining and filtering results in each database. In addition, we included gray literature and used a snowballing approach where each publication identified by our search criteria could be manually linked to other relevant citations in its references.\n\n<table><tr><td>Database</td><td>URL</td></tr><tr><td>ACM</td><td>ACM Digital Library</td></tr><tr><td>IEEE</td><td>https://ieeexplore.ieee.org/</td></tr><tr><td>Springer</td><td>http://link.springer.com/</td></tr><tr><td>Semantic Scholar</td><td>https://wwwsemanticscholar.org/</td></tr></table>\n\nTable 2.1: Databases\n\n# 2.3 Study Selection Criteria\n\nTo ensure the collection of quality and relevant data in response to our research questions, we implemented strict inclusion and exclusion criteria during this step. These criteria were applied after reviewing the title, abstract, and full text of each article.\n\n# Inclusion Criteria:\n\nThe paper is relevant to text classification (e.g., news categorization, question answering).  \nThe publication date is between 2016 and 2024.  \n- The paper highlights one or more problems, weaknesses, or limitations of existing text classification techniques, along with proposed solutions.  \nIt uses relevant keywords.  \nIt is related to the Arabic and/or English languages.  \nThe paper is written in English.\n\n# Exclusion criteria:\n\n- Articles not written in English.  \n- Articles published before 2016 or after 2024.  \nText classification models that are not evaluated using Arabic or English.\n\n# 2.4 Study Selection Process\n\nThe primary study selection process consisted of three separate steps, as shown in Figure 2.2. Applying the search string to the four scientific databases listed in Table 2.1 generated over 2,000 articles.\n\n# - Iteration 0 - Filtering by Title\n\nIn this phase, the titles were evaluated against the inclusion and exclusion criteria. Articles deemed relevant were immediately included in the next phase. A total of 230 publications were selected for further review.\n\n- Iteration 1 - Filtering by Abstract and Keywords\n\nIn this phase, the abstracts and keywords were evaluated against the inclusion and exclusion criteria. Articles considered relevant were included in the next stage. A total of 220 publications were selected in this phase.\n\n# - Iteration 2 - Filtering by Full Text\n\nThis was the final step in which the full texts were examined based on the quality assessment criteria (as detailed in section E). We ranked the papers from the previous step and selected the top 15 for further review. My supervisor then provided me with 6 key papers. Finally, 21 articles were included in the final step.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/701417b28c38c1a25214d49265bf20bc90a7b325f82ca5ba4688fdd8d35617c7.jpg)  \nFigure 2.2: The number of studies included in each study selection phase.\n\n# 2.5 Quality Assessment\n\nIncluded papers had to pass a quality check, which included positive answers to the following questions\n\nWhat is the impact factor of the journal or conference?  \nWhat is the number of citations?  \nIs the data set clearly identified and well described?  \nAre the preprocessing techniques used in the study well described and their selection justified?  \n- Is the total number of training and test data provided?  \n- Are the classifiers used in the study discussed in detail?  \n- Is there a comparison of different approaches?  \nAre performance metrics defined in detail?\n\n<table><tr><td>Ref</td><td>QA1</td><td>QA2</td><td>QA3</td><td>QA4</td><td>QA5</td><td>QA6</td><td>QA7</td><td>QA8</td><td>Total</td><td>percentage</td></tr><tr><td>(Minaee,2021)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7.5</td><td>93.75%</td></tr><tr><td>(Alabbas,2016)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Ahlam Wahdan,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Abdeen,2019)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Bennabi,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(AI Qadi, Leen,2019)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Ezzeldin,2012)</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Zhang,2021)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Elbes,2019)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Rachid,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Pandolfi,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Wahdan,2021)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Liu,2020)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>1</td><td>7</td><td>87.50%</td></tr><tr><td>(Kadhim,2019)</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>6.5</td><td>81.25%</td></tr><tr><td>(Shehab,2016)</td><td>1</td><td>0.5</td><td>1</td><td>1</td><td>0.5</td><td>1</td><td>0.5</td><td>1</td><td>6.5</td><td>81.25%</td></tr></table>\n\nTable 2.2: QA Paper\n\n# 2.6 Included papers\n\nIn this section, we present the distribution of included papers based on the following criteria: database, year, type (journal or conference), and publisher.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/c59825cc251724398f34d513513584066e8cdbf75d8cf59f82d9fd5e1907be37.jpg)  \nFigure 2.1: distribution based on type\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/aff849c475477ddc6cffd4eff620759c7206451779e1bfd12d458bb61917fa5d.jpg)  \nFigure 2.2: based on databases\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/8b24582aed7778c07ef370d28cb4216769b280d0d690b4173007e0e0cad6a994.jpg)\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/acda562152bc49e3fd8241fec1224d786d9f7db4abd17070b52f44827cb25315.jpg)\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/a427a1beb7f6e5e264c7b4a10f144fb057739f9b671de422a8af87b489a72b10.jpg)  \nFigure 2.3: distribution based on year  \nFigure 2.4: Distribution of top 15 papers  \nFigure 2.5: distribution based on publisher\n\n# 2.7 Data Extraction Strategy\n\nData were extracted from the studies, and Table 2.3 shows the characteristics that were collected and included:\n\n# Paper Information:\n\nTitle Author  \nPublication year  \nJournal name  \nStudy type\n\n# Data extracted:\n\nThe form included the following characteristics:\n\n- Paper Objective  \nExcerpts from Introduction  \nExcerpts from Literature Review  \nQuestion Generation (QG) Algorithm  \nEvaluation Metrics  \nConclusion  \nResearch Questions Addressed\n\nThe data extracted from the sample papers is shown in Table 2.4.\n\n<table><tr><td colspan=\"2\">Paper Information</td></tr><tr><td>1. Title</td><td></td></tr><tr><td>2. Author</td><td></td></tr><tr><td>3. Year</td><td></td></tr><tr><td>4. Journal</td><td></td></tr><tr><td>5. Study Type</td><td></td></tr><tr><td colspan=\"2\">Extracted Data</td></tr><tr><td>6. Which research question will be answered?</td><td></td></tr><tr><td>7. Objective extracted from the study</td><td></td></tr><tr><td>8. Extracted pieces from Introduction</td><td></td></tr><tr><td>9. Extracted pieces from Literature review</td><td></td></tr><tr><td>10. Extracted pieces from EXPERIMENTAL STUDY (optional)</td><td></td></tr><tr><td>11. Conclusion Extracted</td><td></td></tr></table>\n\nTable 2.3: DE Form  \n\n<table><tr><td colspan=\"2\">Paper Information</td></tr><tr><td>1. Title</td><td>Learning to Ask: Neural Question Generation for Reading Comprehension</td></tr><tr><td>2. author</td><td>Du &amp; Shao (2017)</td></tr><tr><td>3. Year</td><td>2017</td></tr><tr><td>4. journal</td><td>arXiv preprint arXiv:1705.00106 (2017).</td></tr><tr><td>5. Study Type</td><td>Experimental Study</td></tr><tr><td colspan=\"2\">Extracted Data</td></tr><tr><td>6. Which research question will be answered?</td><td>RQ1 – RQ2 – RQ4 – RQ6– RQ7 - RQ8</td></tr><tr><td>7. Objective extracted from the study</td><td>In reading comprehension, investigate automatic question generation for sentences from text passages.</td></tr><tr><td>8. Extracted pieces from Introduction</td><td>·Question generation (QG) is a technique for generating natural questions from a sentence or paragraph.\n·One of the most common uses of question creation is in the field of education, where it is used to produce reading comprehension questions.\n·Question generation has traditionally been approached using rule-based methodologies.\n·In contrast to previous work, we propose framing the task of question production as a sequence-to-sequence learning issue, in which a sentence from a text passage is immediately translated into a question.</td></tr><tr><td>9. Extracted pieces from Literature review</td><td>·Reading comprehension is a difficult challenge for robots since it necessitates both a grasp of natural language and a knowledge of the world.\n·The majority of work takes a rule-based approach to solving the problem.\n·They usually start by converting the input sentence to its syntactic representation, which they then utilise to create an interrogative sentence.\n·To our knowledge, no previous work has employed a deep sequence-to-sequence learning approach to generate questions or framed QG for reading comprehension in an seq-to-seq manner.</td></tr><tr><td>10. Extracted pieces from EXPERIMENTAL STUDY and Results</td><td>Dataset:\n·SQuAD dataset\nPerprocessing:\n·first use Stanford CoreNLP Tokenization and sentence splitting are used for pre-processing. The full dataset is then lower-cased.\nModel:\n·encoder:encode both sentence and paragraph-level information with attention mechanism.\n·Decoder:Decodes the questions using the concatenated representation.\nEvaluation Metrics:\n·Automatic Evaluation\n·Human Evaluation\nResults:\n·The proposed model, which simply encodes sentence-level information, outperforms all others on all criteria.\n·The proposed model, which encodes paragraph information, performs best on questions in the \"w/ paragraph\" category.</td></tr><tr><td>11. Conclusion</td><td>It demonstrated a technique to autonomous question development for reading comprehension based entirely on data-driven neural networks.\nUsing an attention-based neural networks method, we investigate the effect of encoding sentence-level vs. paragraph-level information.\nThe suggested model produces state-of-the-art results in both automatic and human evaluations.</td></tr></table>\n\n# 2.8 Synthesis Matrix\n\nThe synthesis matrix for the studies is tabulated as shown in Table 2.5. It includes the following characteristics:\n\nAuthor  \nPublication Year  \n- Paper Objective  \n- Preprocessing Methods (if applicable)  \n- Datasets Used  \n- Question Generation (QG) Algorithms/Methodology  \nEvaluation Metrics  \nConclusion\n\nTable 2.4: Data extracted from sample paper  \n\n<table><tr><td>Source (Author//Year)</td><td>Application Type(QA/QG P/QG /NC/Survey)</td><td>Purpose of study</td><td>Preprocessing Methods</td><td>Datasets</td><td>Methodology/Algo rithm</td><td>Results/ Evaluation Metrics</td><td>Conclusion</td></tr><tr><td>Derwin Suharto no,2024</td><td>automatic question generation</td><td>to compare several state- of-the-art pre-trained models to create an automatic question generator with narrative paragraphs as input.</td><td>-the paragraph is broken down into smaller units called tokens.-These tokens can be individual words, punctuation marks, or other meaningful units.-Each token is assigned a part-of-speech tag, specific answers are extracted</td><td>SQuAD, TyDiQA, IDK-MRC Datasets</td><td>uses the Sequence-to-Sequence Learning architecture of BiGRU, BiLSTM, Transformer, BERT, BART, and GPT</td><td>BLEU-1: IndoBERTFo rmer 29.14 IndoBERTFo rmer 30.45</td><td>- this research only evaluates these models for the case of creating short answer questions this research only uses three trained models: Indo BERTFormer, IndoBARTFom er, IndoTransGPT, Our methodology efficiently uses context-to-</td></tr><tr><td></td><td></td><td></td><td>from the postage tensor based on specific criteria or questions.</td><td></td><td></td><td></td><td>answer attention more reliably than longer answers to extract more relevant information from surrounding sentences</td></tr><tr><td>Xinya Du,2017</td><td>Question Generation</td><td>In reading comprehension, investigate automatic question generation for sentences from text passages.</td><td>To begin, perform pre-processing with Stanford CoreNLP, which includes tokenization and sentence splitting. The full dataset is then lower-cased.</td><td>SQuAD dataset</td><td>encoder: use an attention technique to encode information at the sentence and paragraph levels.Decoder: decodes the questions using the concatenated representation.</td><td>Metrics:AE,HE Results:The proposed approach obtains the greatest results by just encoding sentence-level information.</td><td>In both automatic and human evaluations, the proposed model (encoder - decoder with attention mechanism) achieves state-of-the-art performance.</td></tr><tr><td>Wang,2020</td><td>Question Generation</td><td>Based on an encoder-decoder framework and reinforcement learning, we propose an ADDQG model. Questions can be generated from answers and document representations.</td><td>Use pre-trained GloVe word vectors for word embedding.</td><td>HotpotQA,</td><td>The model's main idea is to merge the answer information with the content using an answer-aware initialization module and a semantic rich fusion attention mechanism. In addition, reinforcement learning is used. Using the Maxout Pointer and the Copy Mechanism</td><td>MetricsAutomatic Evaluation:BLEU, METEOR, ROUGE Human Evaluation</td><td>Reinforcement learning is also used to improve ADDQG training by using both syntactic and semantic metrics as the reward.</td></tr><tr><td>Zhou,2017</td><td>Question Generation</td><td>It proposes that natural language sentences be used to generate relevant and diversified queries using the neural encoder decoder architecture.</td><td>--</td><td>SQuAD dataset</td><td>The NQG framework consists of a feature-rich encoder and an attention-based decoder.The BiGRU encoder reads the concatenated sentence word vector, lexical characteristics, and answer position feature.Copy Mechanism</td><td>This demonstrates how lexical features and an indicator of answer position can help with question development. With the assistance of the copy mechanism,</td><td>The suggested technique uses a feature-rich encoder to encode answer location, POS, and NER tag information.Experiments demonstrate that the proposed NQG technique is effective.</td></tr><tr><td>Yao, 2021</td><td>Question and Answer Pair Generation</td><td>Create an educational automated</td><td>--</td><td>Using Fairy Tale QA, a new QA</td><td>Methodology: The QAG system in this paper consists</td><td>ResultsAll of the data reveal that our</td><td>The work sets a strong foundation for</td></tr><tr><td></td><td></td><td>question-answer generation (QAG) system. The technology can generate QA pairings that can be used to assess a range of student comprehension skills automatically.</td><td></td><td>dataset with 278 kid-friendly storybooks and 10,580 expert-labeled QA pairs.</td><td>of three steps: (1) extracting candidate answers from given storybook passages using carefully designed heuristics based on a pedagogical framework; (2) generating appropriate questions corresponding to each of the extracted; and (3) ranking top QA-pairs with a specific threshold for the maximum amount of QA-pairs for each section..</td><td>approach receives above-average 601 (&gt;3) ratings, implying that it achieves acceptable levels of user satisfaction across all three aspects (Readability, Question Relevancy, Answer Relevancy).</td><td>the bright future of applying artificial intelligence to automate educational question-answering chores.</td></tr><tr><td>Pan, 2019</td><td>Survey(NQG)</td><td>give a thorough examination of the corpora, methodology, and evaluation methods for neural question generation</td><td>--</td><td>SQuAD, MS MARCO,Ne wsQA,RAC E,LearningQ ,NarrativeQ A.</td><td>give a thorough examination of the corpora, methodology, and evaluation methods for neural question generation In passage X, asking about the goal response A is defined as finding the optimal question Y. The Seq2Seq framework is shared by all NQG models, but they differ in how they consider (1) QG-specific characteristics (for example, response encoding, question word formation, and paragraph-level contexts) and (2) common NLG techniques (e.g., copying mechanism, linguistic features, and reinforcement learning).</td><td>Human evaluation is used in the majority of QG systems. BLEU, METEOR, and ROUGE are examples of automatic evaluation metrics.</td><td>This research offered a comprehensive overview of NQG, identifying current NQG models based on QG-specific and common technical changes, and highlighting three growing NQG trends: multitasking, a wider range of input modalities, and the development of profound questions.. In many real-world applications, such as automated tutoring and conversational systems, where the question plays a crucial role, knowing when to enquire has become a vital difficulty.</td></tr><tr><td>Benaissa Azzeddine Rachid,20 20</td><td>News Classification</td><td>Researchers used neural network models (Convolutional and Recurrent Neural Networks) and pre-trained word embeddings in a series of experiments to classify cyberbullying situations using an Arabic channel news comments dataset.</td><td>Punctuation in Arabic and English has been removed. word embeddings as a source of data for deep learning algorithms</td><td>Aljazeera.net, an Arabic news station.</td><td>CNN, LSTM GRU combination of both. SVM</td><td>The findings show that using simple and combined Convolutional and Recurrent Neural Networks (CNN/LSTM/GRU) with Arabic pre-trained word embeddings (AraVec and Fast text) combined with Arabic pre-trained word embeddings (AraVec and Fast text) combined with Arabic pre-trained word embeddings (AraVec and Fast text) can achieve an F1 score of 84 percent on a balanced dataset..</td><td>techniques of CNN-RNN , both simple and mixed, perform well.</td></tr><tr><td>Menghan Zhang,20 21</td><td>News Classification</td><td>the concept of a customised algorithm, which is a mix of deep learning algorithms such as CNN and LSTM</td><td>Using the word2vec model, word segmentation and stop word filtering</td><td>Reuters News</td><td>For the classification of news text data, a bespoke DCLSTM-MLP model was used.</td><td>Accuracy of DCLSTM-MLP is 94%</td><td>The DCLSTM-MLP model outperforms the CNN and LSTM models in terms of accuracy.</td></tr><tr><td>Ahmed Magdy ,2012</td><td>Answer Generation(survey)</td><td>--</td><td>Stemming, Named Entity Recognition</td><td>SQuAD</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Leen Al Qadi, 2019</td><td>News Articles classification</td><td>To automatically determine a document's category.</td><td>--</td><td>---</td><td>Famous techniques in classification were used: Logistic Regression, Nearest Centroid, Decision Tree (DT), Support Vector Machines (SVM), K-nearest neighbors (KNN), XGBoost Classifier, RandomForest Classifier, Multinomial Classifier, Ada-Boost Classifier,</td><td>--</td><td>Among all the other classifiers, the SVM model generated the best results.</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>and Multi-Layer Perceptron (MLP).</td><td></td><td></td></tr><tr><td>Shervin Minaee,20 21</td><td>TC(A Comprehensive Review)</td><td>provide a quantitative analysis of various deep learning models' performance on popular benchmark datasets</td><td>--</td><td>Sentiment Analysis (YelpIMDb) NCDatasets( AG News, 20 Newsgroups.</td><td>Naïve Bayes, (SVM), hidden Markov model (HMM), gradient boosting trees, and random forests</td><td>--</td><td>--</td></tr><tr><td>Sakina Rim BENNAB I,2020</td><td>FS(Comparative Study)</td><td>The goal of this paper is to give a comparison of several feature selection strategies.</td><td>--</td><td>--</td><td>Classification algorithms: SVM, KNN and NB.</td><td>--</td><td>--</td></tr><tr><td>Mohamm ad A.R. Abdeen, 2019</td><td>ATC (Review Paper)</td><td>a thorough examination of the Arabic text classification: The methodology, datasets, and feature selection strategies described in this paper</td><td>Normalization stemming algorithms</td><td>--</td><td>TC Methods : Decision Trees: Naïve Bayesian k-means algorithms Hierarchical clustering algorithms.(better than K-means).</td><td>--</td><td>--</td></tr><tr><td>Ahlam Wahdan,2 020</td><td>ATC(Systematic Literature Review)</td><td>examining neural network-based Arabic text categorization</td><td>--</td><td>--</td><td>Classification Techniques : Techniques that are both manual and statistical. Machine learning techniques</td><td>--</td><td>--</td></tr><tr><td>W.Alabba s, 2016</td><td>ATC(Systematic Literature Review)</td><td>Arabic text is classified using a variety of TC approaches and methods.</td><td>--</td><td>--</td><td>SVM,NB, Decision-tree, k-NN</td><td>--</td><td>--</td></tr><tr><td>Ammar Ismael Kadhim,2 019</td><td>Survey(ML for TC)</td><td>Text classification surveys, the process of varying term weighing strategies, and a comparison of alternative categorization procedures.</td><td>--</td><td>--</td><td>Naïve Bayes, SVM KNN</td><td>--</td><td>--</td></tr><tr><td>Shehab,20 16</td><td>multilabel classification of Arabic articles</td><td>focuses on Arabic article multilabel categorization</td><td>--</td><td>--</td><td>classifiers are considered (DT, RF and KNN).</td><td>--</td><td>--</td></tr><tr><td>Ahlam Wahdan, 2021</td><td>ATC</td><td>The goal of this study is to see how deep learning affects ANLP text classification.</td><td>--</td><td>--</td><td>Many techniques, such as word embedding and deep learning, have been employed to improve the application of</td><td>--</td><td>--</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>natural language processing.</td><td></td><td></td></tr><tr><td>Maurizio, 2021</td><td>Web News</td><td>News-related data was gathered from the web and classified using machine learning and data mining techniques.</td><td>Stop words removal, Stemming, Tokenizing</td><td>--</td><td>Clustering, support vector machines, and generative models were the three most common paradigms discovered.</td><td>--</td><td>--</td></tr><tr><td>Mohammed Elbes,2019</td><td>P-Stemmer or NLTK Stemmer for Arabic Text Classification?</td><td>Using the above-mentioned categorization technique, we compared the outcomes of two stemmers: P-Stemmer and NLTK stemmer.</td><td>Preprocessing: P-Stemmer and the NLTK</td><td>--</td><td>--</td><td>--</td><td>--</td></tr><tr><td>Liu,2020</td><td>Comparison on Feature Selection Methods for Text Classification</td><td>Discussions to compare the performance of common feature selection strategies used in text classification studies in the past.</td><td>Feature selection techniques: Information gain (IG) Expected cross entropy (ECE) mutual information (MI) Gini index (GI) The core of Chi-square (CHI) The core of Odd ration (OR)</td><td>--</td><td>--</td><td>--</td><td>--</td></tr></table>\n\nTable 2.5: Synthesis Matrix\n\n# 3. RESULT AND DISCUSSION\n\n# 3.1 Neural Question Generation (NQG)\n\nThe NQG model focuses on generating a question based on the target answer within a passage. Several modern NQG models use the Seq2Seq architecture, including RRN, LSTM, and GRU, often incorporating an attention mechanism to process a passage and its target answer. Popular NQG techniques include copying mechanisms and reinforcement learning (Pan, 2019).\n\n- Datasets commonly used in NQG include SQuAD, MS MARCO, NewsQA, RACE, LearningQ, and NarrativeQA.  \n- The evaluation metrics used in the field include both human and automated techniques such as BLEU, METEOR, ROUGE, and precision.\n\nThe remainder of this section will focus primarily on the Seq2Seq architecture (especially GRU), attention mechanisms, lexical features (POS and NER), and evaluation metrics, especially BLEU and precision.\n\n# 3.1.1 Word Embedding\n\nLanguage comprehension has always been a strong suit of humans. The relationships between words are often easy for humans to understand; however, this task can be challenging for computers. For example, while humans easily recognize the relationships between words such as \"king\" and \"queen,\" \"man\" and \"woman,\" or \"tiger\" and \"tigress,\" computers must learn to recognize these connections (Yin & Shen, 2018).\n\nWord embeddings are a type of word representation that bridge language understanding between machines and humans. They are n-dimensional text representations in which words with similar meanings are represented by similar vectors that are located close together in vector space. This capability is essential for addressing many challenges in natural language processing.\n\nIn word embeddings, each unique word is represented as a real-valued vector in a defined vector space. Each word is characterized by a single vector whose values are learned in a manner similar to a neural network.\n\nWord2Vec (Rong, 2014) is one of the most widely used shallow neural network algorithms for learning word embeddings. It was developed in 2013 by Tomas Mikolov at Google.\n\n# 3.1.2 Seq2Seq\n\nA major challenge with the basic RNN model is that it struggles with long sentences, often resulting in poor understanding of meaning. To deal with long dependencies, we use sequence-to-sequence (Seq2Seq) models (Shao, 2017).\n\nDeep learning techniques, especially Seq2Seq models, have achieved significant success in applications such as machine translation, text summarization, image captioning, question answering (QA), and question generation (QG). In late 2016, Google Translate began using such a model in its production environment.\n\nA Seq2Seq model generates a new sequence of words from a given input sequence.\n\nThe Model As shown in Figure 3.2, the model consists of an encoder and a decoder. Each element in the input sequence is processed by the encoder, which converts the collected data into a vector called the context. Once the entire input sequence has been processed, this context is sent from the encoder to the decoder, which begins to generate the output sequence token by token.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/425af988c6117a62be1fe84f8d618e3b6c677defc3dde28f28180a5f9dbe9d28.jpg)  \nFigure 3.1: [9] Encoder - Decoder architecture.\n\nThe context is represented by a vector, and recurrent neural networks (RNNs) are commonly used for both the encoder and decoder. The size of the context vector can be specified during model creation and is typically determined by the number of hidden units in the encoder RNN. In real-world applications, the context vector may be 256, 512, or 1024 units long.\n\nAt each time step, an RNN takes two inputs: the current input (in the case of the encoder, a single word from the source sentence) and the previous hidden state. To generate the output for that time step, the RNN combines the current input vector with the previous hidden state. After processing its inputs, the RNN produces an output for that time step and updates its hidden state based on the current and previous inputs. The decoder also maintains hidden states that are carried across time steps, although we haven't illustrated this in this context.\n\nAmong the various approaches to sequence-to-sequence modeling, one notable option is the Gated Recurrent Unit (GRU).\n\n# 3.2 Gated Recurrent Units (GRUs)\n\nGRUs are a special type of RNN designed to learn long-term dependencies. They were introduced in 2014 by Kyunghyun Cho. Like Long Short-Term Memory (LSTM) networks, GRUs manage the flow of information through gates. However, GRUs are relatively new compared to LSTMs, and they often perform better due to their simpler architecture (Yuan, 2019).\n\n# The Architecture of the GRU\n\nNow let's understand how GRUs work. A GRU consists of two main gates: the update gate and the reset gate, as shown in Figure 3.3. These gates help determine what information should be retained, passed on, or discarded.\n\nAs mentioned earlier, the gates' output values between 0 and 1. A value of 0 indicates that the information is unimportant, while a value of 1 indicates that it is important. Values closer to 0 indicate unimportance and values closer to 1 indicate importance.\n\nAt each timestamp  $t$ , the GRU takes an input  $X_{t}$  and the previous state  $H_{t-1}$  from the previous timestamp. As shown in Figure 3.4, it then generates a new hidden state  $H_{t}$ , which is passed to the next timestamp.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/6a3095fe543d86ce6d046c97c29f2582389ff832c8067d0dd68d7b3fc7e1cfca.jpg)  \nFigure 3.2: Overall structure within the GRU cell (sefidian,2020)\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/1fcc81348220b9417d7a09906664f8c1f39c044bad02ca252be70409cad09fda.jpg)  \nFigure 3.3: GRUs follow the same flow as the typical RNN (sefidian,2020)\n\nUpdate Gate (z): The primary function of this gate is to inform the model how much of the previous information should be preserved, i.e., passed on to future states.\n\nReset Gate (r): This gate is used by the model to determine how much information from the past should be forgotten.\n\nAs usual, there are weights associated with each gate.\n\n# Math and pictorial representation to understand the functioning\n\n# Update gate:\n\n-  $Z_{t}$  represents the update gate.  \n- The parameters are the input representation  $X_{t}$  and the prior hidden state  $H_{t - 1}$  state information multiplied by their corresponding weights.  \n-  $Z_{t}$  is calculated using sigmoid activation. as shown in Figure 3.5.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/57c67f150b4b27bdc1bfd66c95d3e2947d4addefdf7280dd7debd56a40cedb5e.jpg)  \nFigure 3.1: Update Gate (andreaperlato, 2022)\n\n$$\nZ _ {t} = \\sigma (W ^ {(Z)} X _ {t} + U ^ {(Z)} h _ {t - 1})\n$$\n\n# Where,\n\nt: current step.  \n-  $X_{t}$ : Input vector.  \nZt: update gate vector.  \nW and U are vectors and parameter matrices.  \n-  $h_{t - 1}$ : The previous hidden state.\n\n# Reset gate\n\n-  $r_t$  represents the reset gate  \n- The parameters are the input representation  $X_{t}$  and the prior hidden state  $H_{t - 1}$  state information multiplied by their corresponding weights.  \n-  $\\mathsf{r}_{\\mathrm{t}}$  is calculated using sigmoid activation as show in Figure 3.6.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/9337c41bdc6d1cffe84293459239b87fb3b16a05fefa7ce083fa8bea93261242.jpg)  \nFigure 3.2: Reset Gate (andreaperlato, 2022)\n\n$$\nr _ {t} = \\sigma (W ^ {(Z)} X _ {t} + U ^ {(r)} h _ {t - 1})\n$$\n\n# Where,\n\nt: current step.  \n-  $X_{t}$ : Input vector.  \n-  $r_t$ : vector of Reset gate.  \nW and U: vectors and parameter matrices.  \n-  $h_{t-1}$ : The previous hidden state.\n\n# How GRU Works\n\n- A new device has been introduced: the reset gate, which is used to retrieve previously stored data from a memory device.  \n- Consider a movie review. Initially, you might start with \"The movie was directed by X; it starred Y\". After about ten lines, you conclude, \"I think the movie is bad for the money I paid. In this case, the actual review is the last line. The neural network should not remember the earlier sentences and should focus on the last sentence to capture the essence of your opinion. This focus is enabled by the reset gate.  \n- To discard irrelevant information,  $r_t$  is set to 0 until the last sentence is analyzed.  \n- Then the tanh activation function is applied, resulting in  $h_{\\mathrm{t}}^{\\prime}$  (Candidate Hidden State), as shown in Figure 3.7.  \n- The final phase of the network is to compute and output the  $h_t$  vector, which contains information about the current unit.  \nThis process requires the use of the update gate as shown in Figure 3.8.\n\n$$\nh _ {t} ^ {\\prime} = \\tanh (W X _ {t} + r _ {t} \\theta U h _ {t - 1})\n$$\n\n$$\nh _ {t} = Z _ {t} \\theta h _ {t - 1} + (1 - Z _ {t}) \\theta h _ {t} ^ {\\prime}\n$$\n\nWhere,\n\n$h_t^\\prime$  : candidate hidden state vector.  \n$h_t$ : The output vector.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/3c47a63bf9083d6124b7965c5647e7dc16e619b104661ab42a4533e9d3734f19.jpg)  \nFigure 3.3: Candidate hidden state architecture (Krishnan,2022).\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/39533c141137efbc3e1d190ce4dee13131e49a57d8760017f797f0d06dbf02fc.jpg)  \nFigure 3.4: The architecture of GRU in recurrent neural networks (Krishnan,2022).\n\n# What is the difference between the GRU and the LSTM?\n\nThe main differences are as follows (Li, 2021):\n\nNumber of gates: LSTM has three gates, while GRU has two.\n\n- Internal memory and output gate: LSTM contains both an internal memory cell and an output gate, which are absent in GRU.  \n- Gate functionality: In LSTM, the update gate connects the input and forget gates, while in GRU, the reset gate is applied directly to the previous hidden state. In LSTM, the reset gate is shared by the input and forget gates.  \n- Training parameters: GRU has fewer training parameters than LSTM, which means it uses less memory and runs faster. However, LSTM generally provides more accuracy on large data sets, while it may be less accurate on smaller data sets. If you're working with long sequences and accuracy is critical, LSTM is preferable. If you have limited memory and need faster results, GRU is the better choice.\n\n# 3.2.1 Word2Vec\n\nWord2Vec is a neural network-based method for rapidly building word embeddings. It was developed by Tomas Mikolov at Google in 2013 in response to the need for more efficient training of neural network-based embeddings, and has since become the de facto standard for developing pre-trained word embeddings.\n\nWord2Vec takes a text document as input and produces a set of feature vectors representing the words in the document. Although Word2Vec is not a deep neural network, it translates text into a numerical representation that deep neural networks can recognize. According to the Word2Vec objective function, words with similar contexts will have similar embeddings. As a result, such words are located close to each other in this vector space. Mathematically, the cosine of the angle  $Q$  between these vectors should be close to 1, which means that the angle itself should be as close to 0 as possible, as shown in Figure 3.1. Word2vec has two types: CBOW and the Skip-gram model.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/415c418a586a12ce9ac9e5a33d77c336d6d02d53f3a90e1dfa796818831b901b.jpg)  \nFigure 3.5: Similar words are closely placed in vector space (Great Learning Team, 2020)\n\n# 3.2.2 Seq2Seq with Attention Mechanism\n\nThe Seq2Seq paradigm is designed to transform a source sequence into a target sequence, as shown in Figure 3.9.\n\nWhen we input an English source sentence into the encoder, it gathers all the information from the source sequence into a single real-valued vector called the context vector. This context vector is then used by the decoder to construct an output sequence in a target language, such as Hindi. The primary goal of the context vector is to condense the entire input sequence into a single representation.\n\nBut can a single vector from the encoder effectively contain all the important information when the input sentence is long? Is it possible to predict the target word by focusing on a few relevant words in the sentence rather than relying on a single vector?\n\nThe attention mechanism addresses these challenges. Its main purpose is to eliminate the need for a single vector representation for each sentence. Instead, it uses attention weights to focus on specific input vectors from the sentence.\n\nDuring each decoding step, the decoder receives a set of attention weights that indicate how much \"attention\" should be given to each input word. These attention weights provide the decoder with contextual information for translation, as shown in Figure 3.10.\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/2eee881ac681ca9ad893c3dc2d3e6e9f5613c70ae8c9bd50a59d946f8f074db6.jpg)  \nFigure 3.6: Seq2Seq Architecture with attention mechanism (Li,2021).\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/117c0211e9cb0f304687185985d2e434e33b6e900c7ffef48acbe79361ecb837.jpg)  \nFigure 3.7: Seq2Seq Architecture (Li,2021).\n\n# 3.2.3 Preprocessing\n\nThere are two types of preprocessing: traditional and QG-specific. Traditional preprocessing prepares the input for subsequent tasks, including segmentation, tokenization, and part-of-speech (POS) tagging.\n\nIn some cases, named entity recognition (NER) is also required. In this report, we focus on POS tagging and NER.\n\n# 3.2.4 Lexical Feature (POS)\n\nPart-of-speech tagging: Assign a part-of-speech tag to each token in a sentence.\n\nFor example:\n\n<table><tr><td>I</td><td>like</td><td>his</td><td>watch</td></tr><tr><td>Pro</td><td>verb</td><td>pro</td><td>noun</td></tr></table>\n\n<table><tr><td>the</td><td>Fans</td><td>watch</td><td>the</td><td>race</td></tr><tr><td>Dt</td><td>Noun</td><td>verb</td><td>dt</td><td>noun</td></tr></table>\n\nThe words categorize into 2 classes (open Vs close):\n\n![](/uploads/images/25ba1751-4fe9-4436-9e78-28c28672d0eb/4ed984763c63d36c08d1ad82ab489cdc3cb137d9736dce71740c0f4afcb604c8.jpg)\n\n# Framework for POS discovering:\n\nMost freq tag.  \n- Maxtent P(t/w).  \nTnT.  \nBidirectional dependencies.  \nUpper bound.\n\n# 3.2.5 Lexical Features (NER)\n\nEntities: Common things that belong to the noun family.\n\nNamed Entity Recognition: A very important subtask to find and classify names in text, for example\n\nThe decision by the independent MP Andrew Wilkie to withdraw his support for the minority Labor government sounded dramatic but it should not further threaten its stability. When, after the 2010 election, Wilkie, Rob Oakeshott, Tony Windsor and the Greens agreed to support Labor, they gave just two guarantees: confidence and supply.\n\nPerson Date Location Organization\n\n# Methods of NER\n\nOne approach is to use various machine learning techniques.  \n- Another option is the Conditional Random Field (CRF), which is supported by both NLP Speech Tagger and NLTK. CRF is a probabilistic model used to model sequential data.  \nNER can also be based on deep learning techniques.\n\n# 3.2.6 BLUE and precision Evaluation Metrics\n\n# Precision:\n\n- compared a generated questions to one or more reference questions\n\n$$\n\\text {u n i g r a m P r e c i s i o n} = \\frac {\\text {N u m w o r d m a t c h e s}}{\\text {N u m w o r d s i n g e n e r a t i o n}}\n$$\n\n- But QGS can over generate reasonable words.!!!\n\n# BLEU, which stands for Bi-Lingual Evaluation Understudy:\n\n- BLEU compared a generated questions to one or more reference questions.  \n- BLEU compared n-grams of the generation with n-grams of the reference  \n- BLUE uses a modified n-gram precision to clip the number of matches.\n\n$$\n\\text {M o d i f i e d u n i g r a m P r e c i s i o n} = \\frac {\\operatorname {c l i p} (\\text {N u m w o r d m a t c h e s})}{\\text {N u m w o r d s i n g e n e r a t i o n}}\n$$\n\n- BLUE also uses bigrams, trigrams, and 4-grams to handle ordering problems\n\n$$\n4 - \\text {g r a m} \\quad \\text {P r e c i s i o n} = \\frac {\\Sigma c l i p (N u m w o r d m a t c h e s)}{\\Sigma N u m 4 - g r a m s i n g e n e r a t i o n}\n$$\n\n# 3.3 Update on Research Questions\n\nThere has been a significant shift in the research questions. Initially, the focus was on text classification. However, it evolved to Question Generation (QG) because my role as a teaching assistant emphasizes the importance of Natural Question Generation (NQG) for educational purposes.\n\nAs a result, we replaced the text classification questions - such as definition, application, limitations, preprocessing, feature extraction, solutions to limitations, datasets used, evaluation metrics, and directions for future research - with NQG questions covering the same areas. The expected responses for each research question are summarized in Table 3.1.\n\n<table><tr><td>RQ</td><td>Expected Outcome / Result</td></tr><tr><td>Q1: What is NQG?</td><td>It is the task of using deep neural networks to generate questions from a given context.</td></tr><tr><td>Q2: What are different applications of NQG?</td><td>1- machine reading comprehension\n2- Improving question answering system\n3- Assisting chatbots in initiating or continuing a conversation with humans</td></tr><tr><td>Q3: What are the languages that this research is interested in for NQG?</td><td>English Language</td></tr><tr><td>Q4: What are limitations and challenges of the existing NQG?</td><td>1- Existing neural question generation models are insufficient mostly owing to their failure to adequately simulate the process of how each word in the question is chosen, i.e., whether the text is repeated, or a vocabulary is formed.\n2- Most existing solutions are aimed at improving document representations. due to a lack of attention paid to the answer information, The created question may not be appropriate for the answer type, making the response irrelevant.</td></tr><tr><td>Q5: What are benchmark datasets to evaluate the performance of models of QAPG?</td><td>SQuAD, MS MARCO,NewsQA,RACE,LearningQ and NarrativeQA</td></tr><tr><td>Q5.1: What is a proper approach to represent word?</td><td>Word Embedding:\n  · Word2Vec\n  · Glove</td></tr><tr><td>Q5.2: What are different types of input preprocessing?</td><td>There are two forms of preprocessing: traditional preprocessing and QG-specific preparation. Segmentation, phrase splitting, tokenization, POS tagging, and coreference resolution are all part of standard preprocessing, which is used to prepare the data for the next task. In some circumstances, it also entails the recognition of named entities (NER)</td></tr><tr><td>Q6: What are the techniques used in NQG?</td><td>· NQG models all share the Seq2Seq framework.</td></tr><tr><td></td><td>• Or Use seq2seq with attention mechanism</td></tr><tr><td>Q7: What are possible Solutions and how to improve the performance of the existing technique of NQG?</td><td>• Adding attention mechanism\n• The model improves when the intended response is used as a guide to help with question generation. Use NLP Tools such as POS and NER.</td></tr><tr><td>Q8: What are the methods used to evaluate the performance of models for MQG?</td><td>• BLEU, METEOR and ROUGE.</td></tr><tr><td>Q9: What are directions for future research on NQG?</td><td>•Generation of Deep Questions\n•Wider Input Modalities\n•Use reinforcement learning</td></tr></table>\n\nTable 3.1: The expected result for each research question.\n\n# 3.4 Threats to Validity\n\nThis study has several limitations:\n\nIt focuses solely on the English language.  \n- It does not address how to predict question types based on input response (e.g., yes/no, multiple choice, or extractive) and context.  \nIt does not cover the transformer model.  \nThere is a need for practical applications of the mentioned models to better understand and develop them.\n\n# 4. CONCLUSION AND FUTURE WORK\n\nThis research explores the use of neural network models for generating natural language questions (QG), highlighting their importance for educational materials and for improving question-answering (QA) systems. We analyzed several techniques and evaluation metrics from the literature.\n\nThe results show that all NQG models share the Seq2Seq framework. Furthermore, the integration of Seq2Seq with attention mechanisms and the use of part-of-speech (POS) tagging and named entity recognition (NER) contribute to the generation of accurate questions.\n\nThe future work of Question Generation (QG) techniques focuses on improving the quality, diversity, and applicability of automatically generated questions. Here are some key areas for future research and development:\n\n1. Enhancing Question Quality and Diversity  \n2. Multimodal Question Generation  \n3. Personalized and Adaptive QG  \n4. Integration with Large Language Models (LLMs)  \n5. Improving QG in Low-Resource Languages  \n6. Domain-Specific QG  \n7. Reinforcement Learning (RL) for Question Generation\n\n# 8. Graph Encoders for Question Generation\n\n# 5. REFERENCES\n\nAithal, S. G., Rao, A. B., & Singh, S. (2021). Automatic question-answer pairs generation and question similarity mechanism in question answering system. Applied Intelligence, 51(11), 8484-8497.  \nAlabbas, W., Al-Khateeb, H. M., & Mansour, A. (2016, October). Arabic text classification methods: Systematic literature review of primary studies. In 2016 4th IEEE International Colloquium on Information Science and Technology (CiSt) (pp. 361-367). IEEE.  \nAlKhuzay, S., Grasso, F., Payne, T. R., & Tamma, V. (2024). Text-based question difficulty prediction: A systematic review of automatic approaches. International Journal of Artificial Intelligence in Education, 34(3), 862-914.\n\nandreaperlato,2022.\"Recurrent Neural Network in Theory\": aipost, https://www.andreaperlato.com/aipost/recurrent-neural-network-in  \nBennabi, S. R., & Elberrichi, Z. (2020, June). Feature Selection based Arabic Text Classification using Different Machine Learning Algorithms: Comparative Study. In Proceedings of the 10th International Conference on Information Systems and Technologies (pp. 1-5).  \nBennabi, S. R., & Elberrichi, Z. (2020, June). Feature Selection based Arabic Text Classification using Different Machine Learning Algorithms: Comparative Study. In Proceedings of the 10th International Conference on Information Systems and Technologies (pp. 1-5).  \nChali, Y., & Hasan, S. A. (2015). Towards topic-to-question generation. Computational Linguistics, 41(1), 1-20.  \nDu, X., Shao, J., & Cardie, C. (2017). Learning to ask: Neural question generation for reading comprehension. arXiv preprint arXiv:1705.00106.  \nElbes, M., Aldajah, A., & Sadaqa, O. (2019, October). P-stemmer or NLTK stemmer for arabic text classification?. In 2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS) (pp. 516-520). IEEE.  \nEzzeldin, A. M., & Shaheen, M. (2012, December). A survey of Arabic question answering: challenges, tasks, approaches, tools, and future trends. In Proceedings of The 13th international Arab conference on information technology (ACIT 2012) (pp. 1-8).  \nHeilman, M. (2011). Automatic factual question generation from text (Doctoral dissertation, Carnegie Mellon University).  \nJoseph, S. R., Hlomani, H., Letsholo, K., Kaniwa, F., & Sedimo, K. (2016). Natural language processing: A review. International Journal of Research in Engineering and Applied Sciences, 6(3), 207-210.  \nKadhim, A. I. (2019). Survey on supervised machine learning techniques for automatic text classification. Artificial Intelligence Review, 52(1), 273-292.  \nKrishnan, S., Magalingam, P., & Ibrahim, R. B. (2020). Advanced recurrent neural network with tensorflow for heart disease prediction. International Journal of Advanced Science and Technology, 29(5), 966-977.  \nLi, A., Xiao, F., Zhang, C., & Fan, C. (2021). Attention-based interpretable neural network for building cooling load prediction. Applied Energy, 299, 117238.  \nMinaee, S., Kalchbrenner, N., Cambria, E., Nikzad, N., Chenaghlu, M., & Gao, J. (2021). Deep learning--based text classification: a comprehensive review. ACM Computing Surveys (CSUR), 54(3), 1-40.  \nPan, L., Lei, W., Chua, T. S., & Kan, M. Y. (2019). Recent advances in neural question generation. arXiv preprint arXiv:1905.08949.\n\nPandolfi-González, M., Quesada-López, C., Martínez, A., & Jenkins, M. (2020, September). Automatic Classification of Web News: A Systematic Mapping Study. In Proceedings of SAI Intelligent Systems Conference (pp. 558-574). Springer, Cham.  \nRachid, B. A., Azza, H., & Ghezala, H. H. B. (2020, July). Classification of cyberbullying text in arabic.  \nIn 2020 International Joint Conference on Neural Networks (IJCNN) (pp. 1-7). IEEE.  \nReda Affane,2020.\" Understanding the Hype Around Transformer NLP Models\": dataiku,  \nUnderstanding the Hype Around Transformer NLP Models (dataiku.com)  \nRong, X. (2014). word2vec parameter learning explained. arXiv preprint arXiv:1411.2738.\n\nSefidian,2020. \"Understanding Gated Recurrent Unit (GRU) with PyTorch code\": gated-recurrent-unit-gru-with-pytorch, http://www.sefidian.com/2020/01/30/gated-recurrent-unit-gru-with-pytorch/Shehab, Mohammed A., et al. \"A supervised approach for multi-label classification of Arabic news articles.\" 2016 7th international conference on computer science and information technology (CSIT). IEEE, 2016.  \nSlobodianiuk, A. V., & Semerikov, S. O. (2025). Advances in neural text generation: A systematic review.  \nSuhartono, D., Majiid, M. R. N., & Fredyan, R. (2024). Towards automatic question generation using pretrained model in academic field for Bahasa Indonesia. *Education and Information Technologies*, 29(16), 21295-21330.  \nWahdan, Ahlam, Said A. Salloum, and Khaled Shaalan. \"Text Classification of Arabic Text: Deep Learning in ANLP.\" International Conference on Advanced Machine Learning Technologies and Applications. Springer, Cham, 2021  \nWahdan, K. A., Hantoobi, S., Salloum, S. A., & Shaalan, K. (2020). A systematic review of text classification research based ondeep learning models in Arabic language. Int. J. Electr. Comput. Eng, 10(6), 6629-6643.  \nWang, L., Xu, Z., Lin, Z., Zheng, H., & Shen, Y. (2020, December). Answer-driven Deep Question Generation based on Reinforcement Learning. In Proceedings of the 28th International Conference on Computational Linguistics (pp. 5159-5170).  \nYang, J., Bai, L., & Guo, Y. (2020, October). A survey of text classification models. In Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence (pp. 327-334).  \nYao, B., Wang, D., Wu, T., Hoang, T., Sun, B., Li, T. J. J., ... & Xu, Y. (2021). It is AI's Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in Fairy TaleQA Dataset. arXiv preprint arXiv:2109.03423.  \nYuan, J., & Tian, Y. (2019). An intelligent fault diagnosis method using GRU neural network towards sequential data in dynamic processes. *Processes*, 7(3), 152.\n\nZhang, M. (2021). Applications of deep learning in news text classification. Scientific Programming, 2021.  \nZhou, Q., Yang, N., Wei, F., Tan, C., Bao, H., & Zhou, M. (2017, November). Neural question generation from text: A preliminary study. In National CCF Conference on Natural Language Processing and Chinese Computing (pp. 662-671). Springer, Cham.  \nMucciaccia, S. S., Paixão, T. M., Mutz, F. W., Badue, C. S., de Souza, A. F., & Oliveira-Santos, T. (2025, January). Automatic Multiple-Choice Question Generation and Evaluation Systems Based on LLM: A Study Case With University Resolutions. In Proceedings of the 31st International Conference on Computational Linguistics (pp. 2246-2260).  \nMaity, Subhankar, Aniket Deroy, and Sudeshna Sarkar. \"Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains.\" arXiv preprint arXiv:2501.17397 (2025).  \nGreat Learning Team, 2020. \"What is Word Embedding | Word2Vec | GloVe\". Great learning, https://www.mygreatlearning.com/blog/word-embedding/\n\nAbdeen, M. A., AlBouq, S., Elmahalawy, A., & Shehata, S. (2019). A closer look at arabic text classification. Int. J. Adv. Comput. Sci. Appl., 10(11), 677-688.  \nAl Faraby, S., Adiwijaya, A., & Romadhony, A. (2024). Review on neural question generation for education purposes. International Journal of Artificial Intelligence in Education, 34(3), 1008-1045.  \nAl Qadi, L., El Rifai, H., Obaid, S., & Elnagar, A. (2019, October). Arabic text classification of news articles using classical supervised classifiers. In 2019 2nd International conference on new trends in computing sciences (ICTCS) (pp. 1-6). IEEE.  \nKitchenham, B. A. (2012, September). Systematic review in software engineering: where we are and where we should be going. In Proceedings of the 2nd international workshop on Evidential assessment of software technologies (pp. 1-2).  \nLiu, W., Xiao, J., & Hong, M. (2020, January). Comparison on feature selection methods for text classification. In Proceedings of the 2020 4th international conference on management engineering, software engineering and service sciences (pp. 82-86).  \nMaity, S., Deroy, A., & Sarkar, S. (2025). Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains. arXiv preprint arXiv:2501.17397.  \nSerban, I., Sordoni, A., Bengio, Y., Courville, A., & Pineau, J. (2016, March). Building end-to-end dialogue systems using generative hierarchical neural network models. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 30, No. 1).  \nSlobodianiuk, A. V., & Semerikov, S. O. (2025). Advances in neural text generation: A systematic review.  \nYin, Z., & Shen, Y. (2018). On the dimensionality of word embedding. Advances in neural information processing systems, 31.",
    "arxiv_id": "1705.00106",
    "error_message": null,
    "embedding": [
      -1.703125,
      1.3125,
      -2.109375,
      -1.40625,
      2.4375,
      2.203125,
      -2.15625,
      -2.109375,
      2.03125,
      1.4921875,
      1.5,
      3.046875,
      0.396484375,
      0.70703125,
      1.53125,
      2.25,
      1.3671875,
      -0.3828125,
      0.63671875,
      -6.75,
      1.125,
      2.515625,
      -1.7578125,
      -6.40625,
      1.3984375,
      -4.21875,
      0.37109375,
      3.4375,
      1.015625,
      -0.5703125,
      4.625,
      -4.8125,
      0.271484375,
      -0.498046875,
      -0.55078125,
      -0.1201171875,
      -3.46875,
      -0.52734375,
      3.796875,
      5.28125,
      -6.15625,
      -0.04931640625,
      -2.546875,
      3,
      -0.50390625,
      0.038818359375,
      2.28125,
      -3.53125,
      -0.2578125,
      -0.2138671875,
      -4.84375,
      -4.9375,
      5.625,
      -1.71875,
      5.4375,
      -3.21875,
      -6.84375,
      5.875,
      -3.515625,
      2.25,
      2.046875,
      -1.3125,
      1.46875,
      1.21875,
      3,
      7.125,
      -0.31640625,
      1.625,
      -4.15625,
      3.828125,
      -1.375,
      0.451171875,
      8.4375,
      -1.953125,
      9.25,
      5.59375,
      2.875,
      2.96875,
      -4.71875,
      2.40625,
      -5.65625,
      1.1640625,
      3.421875,
      -1.0703125,
      4.84375,
      0.90234375,
      -2.40625,
      0.181640625,
      -1.828125,
      3.375,
      -2.6875,
      1.640625,
      -2.375,
      -1.6328125,
      -0.65625,
      3.734375,
      -0.0673828125,
      -7.09375,
      -5.84375,
      0.359375,
      -0.07421875,
      -0.2333984375,
      2.34375,
      -7.5,
      -1.4296875,
      -1.3828125,
      -5.03125,
      -4.46875,
      -3.234375,
      -1.984375,
      -1.5,
      1.4921875,
      1.4921875,
      -1.640625,
      4.09375,
      0.56640625,
      4.71875,
      -3.71875,
      -5.21875,
      -1.65625,
      2.078125,
      2.984375,
      -1.8984375,
      -0.7109375,
      3.90625,
      1.0078125,
      -2.71875,
      1.1953125,
      4.71875,
      -0.7890625,
      4.53125,
      0.09716796875,
      7.1875,
      1.6171875,
      -10.3125,
      -3.546875,
      -2,
      4.3125,
      2.40625,
      2.71875,
      -4.6875,
      -0.263671875,
      -3.484375,
      -2.5625,
      3.875,
      -1.34375,
      -5.875,
      0.0947265625,
      4.1875,
      -4.6875,
      0.25390625,
      2.359375,
      3.90625,
      6.125,
      -2.453125,
      -7.8125,
      2.21875,
      1.6875,
      3.359375,
      -1.8671875,
      -0.8984375,
      4.0625,
      1.3125,
      -0.53125,
      -2.640625,
      2.140625,
      -3.890625,
      0.83984375,
      -1.2265625,
      1.6953125,
      1.5859375,
      13.8125,
      2.953125,
      -2.875,
      0.56640625,
      2.8125,
      -1.8359375,
      5.15625,
      1.3046875,
      1.4765625,
      2.390625,
      0.1494140625,
      -2.40625,
      4.875,
      -0.83203125,
      -0.71484375,
      1.4921875,
      -2.515625,
      5.1875,
      -2.546875,
      1.7421875,
      1.140625,
      3.359375,
      -1.8046875,
      -5.4375,
      0.047607421875,
      1.3359375,
      -0.04345703125,
      -1.21875,
      5.03125,
      -2.03125,
      -9.1875,
      -1.53125,
      -0.11474609375,
      -4.875,
      -1.5625,
      1.953125,
      -2.703125,
      1.21875,
      -2.171875,
      1.640625,
      1.296875,
      -1.2421875,
      1.5078125,
      8.25,
      2.546875,
      3.609375,
      -0.08935546875,
      3.34375,
      0.3984375,
      2.359375,
      5.375,
      4.375,
      -1.15625,
      -1.1875,
      2.390625,
      3.671875,
      5.625,
      1.90625,
      6.34375,
      1.1171875,
      2.5,
      4.15625,
      -5.28125,
      -3.25,
      -0.53125,
      -3.015625,
      1.828125,
      -3.984375,
      -0.53515625,
      -3.078125,
      -5.46875,
      -1.3359375,
      4.15625,
      1.890625,
      1.0078125,
      -1.0625,
      -4.84375,
      -3.96875,
      -6.375,
      -0.162109375,
      5.65625,
      -8.4375,
      -5,
      5.5625,
      6.78125,
      -2.0625,
      0.049072265625,
      -1.2578125,
      -2.84375,
      4.625,
      -2.9375,
      -4.03125,
      -0.0052490234375,
      3.34375,
      -4.28125,
      3.25,
      -1.7734375,
      2.296875,
      -0.7578125,
      5.5,
      -0.25390625,
      -1.5234375,
      1.421875,
      -4.25,
      5.09375,
      0.41796875,
      -6.28125,
      1.8125,
      -2.75,
      -5.3125,
      -7.4375,
      5.71875,
      -2.703125,
      2.78125,
      -2.21875,
      3.359375,
      4.90625,
      -3.046875,
      11.5,
      7.1875,
      -0.326171875,
      -1.28125,
      2.234375,
      -3.015625,
      -1.9296875,
      -1.546875,
      -1.3203125,
      -5.0625,
      3.34375,
      3.859375,
      0.1630859375,
      -3.953125,
      0.396484375,
      0.67578125,
      2.46875,
      1.125,
      -6.21875,
      4.25,
      0.349609375,
      -1.015625,
      0.341796875,
      10.5625,
      -1.5546875,
      3.734375,
      -5,
      -0.95703125,
      3.328125,
      0.875,
      -3.171875,
      -2.953125,
      -4.75,
      -2.390625,
      -1.078125,
      -1.703125,
      -1.4375,
      3.015625,
      -1.25,
      2.765625,
      -0.09130859375,
      2.578125,
      -0.7890625,
      -6.40625,
      -6.34375,
      8.4375,
      -0.04296875,
      2.828125,
      2.46875,
      0.287109375,
      6.03125,
      -4.0625,
      -6.125,
      2.09375,
      -1.8203125,
      0.28125,
      0.41796875,
      1.5234375,
      -4.09375,
      -0.1845703125,
      -6.3125,
      2.40625,
      2.0625,
      0.828125,
      4.25,
      4.90625,
      -2.15625,
      3.09375,
      1.2890625,
      -0.03564453125,
      0.032958984375,
      2.5,
      -2.265625,
      5.5,
      1.1171875,
      -0.70703125,
      -4.75,
      -3.015625,
      1.3515625,
      -3.890625,
      -2.359375,
      -1.6484375,
      -5.375,
      -1.6015625,
      -0.205078125,
      1.265625,
      0.3359375,
      0.9765625,
      -5.21875,
      -4.5625,
      2.09375,
      -4.34375,
      -1.34375,
      0.8828125,
      -0.78515625,
      4.1875,
      2.984375,
      1.15625,
      3.703125,
      1.265625,
      -5.78125,
      -1.7421875,
      0.42578125,
      -0.1083984375,
      1.875,
      5.09375,
      3.828125,
      -0.032958984375,
      3.296875,
      -3.109375,
      -1.0546875,
      5.875,
      1.015625,
      -0.53515625,
      -0.21484375,
      -6,
      1.0390625,
      0.66796875,
      -8.4375,
      3.421875,
      0.216796875,
      -0.07275390625,
      0.050048828125,
      1.125,
      0.162109375,
      -2.34375,
      1.4140625,
      -0.85546875,
      3.546875,
      -6.125,
      -1.53125,
      -2.71875,
      1.328125,
      1.9765625,
      1.8984375,
      -1.2109375,
      -1.7578125,
      3.15625,
      6.1875,
      0.7109375,
      1.8046875,
      0.5625,
      1.3984375,
      -4.84375,
      2.21875,
      -1.171875,
      -0.87890625,
      5.9375,
      -3.46875,
      -5.375,
      -1.5546875,
      1.5390625,
      -4.28125,
      4.1875,
      2.5,
      -5,
      -0.921875,
      2.78125,
      5.0625,
      -2.953125,
      -1.375,
      0.2021484375,
      -0.91015625,
      -2.40625,
      2.125,
      1.390625,
      3.59375,
      -4.28125,
      3.46875,
      2.859375,
      -3.09375,
      -1.4765625,
      -4.96875,
      -2.5,
      1.15625,
      0.96875,
      -0.66796875,
      -2.609375,
      3.953125,
      7.25,
      -9.125,
      -10.5625,
      2.953125,
      1.234375,
      -5.6875,
      -1.59375,
      3.421875,
      1.3828125,
      1.4375,
      -5.21875,
      -4.28125,
      -2.375,
      -2.0625,
      0.9453125,
      2.21875,
      0.298828125,
      -1.5078125,
      -4.46875,
      6.8125,
      1.0625,
      5.71875,
      0.31640625,
      -1.0078125,
      -0.34375,
      -5.34375,
      2.796875,
      1.7421875,
      6.09375,
      -5,
      1.25,
      2.875,
      -7.84375,
      0.66015625,
      -3.484375,
      -3.171875,
      0.68359375,
      -1.1328125,
      4.8125,
      -1.5546875,
      -3.140625,
      -1.5390625,
      3.390625,
      -2.984375,
      -2.6875,
      -0.1328125,
      -6.65625,
      -3.125,
      2.046875,
      0.60546875,
      1.2109375,
      -0.01043701171875,
      -2.3125,
      0.9453125,
      -0.9609375,
      0.234375,
      -0.6328125,
      -0.031494140625,
      -0.041748046875,
      -4.84375,
      2.609375,
      3.53125,
      2.3125,
      -0.51953125,
      0.10693359375,
      -4.03125,
      -2.75,
      -1.5546875,
      0.2578125,
      -1.4921875,
      0.51171875,
      0.66015625,
      0.80859375,
      4.03125,
      -3.203125,
      0.0703125,
      0.0133056640625,
      1.9453125,
      -3.921875,
      0.65625,
      1.6640625,
      0.060791015625,
      1.53125,
      1.921875,
      -3.171875,
      -0.349609375,
      1.5625,
      -5,
      -6.09375,
      -1.21875,
      4.15625,
      -2,
      -0.392578125,
      -5.6875,
      2.078125,
      3.40625,
      1.8515625,
      -1.5390625,
      -0.2353515625,
      5.8125,
      -1.734375,
      -0.5859375,
      1.0234375,
      5.125,
      -1.15625,
      -0.0771484375,
      3.609375,
      0.41796875,
      -4.25,
      -7.375,
      -1.3828125,
      0.9921875,
      4.1875,
      -2.578125,
      5.1875,
      -1.6328125,
      5.34375,
      -0.27734375,
      -0.2177734375,
      -16.25,
      3.3125,
      -2.40625,
      -6.28125,
      -2.5625,
      -3.1875,
      0.032958984375,
      -4.625,
      3.78125,
      2.921875,
      -0.875,
      2.140625,
      3.765625,
      0.2236328125,
      -4.96875,
      2.171875,
      1.078125,
      -1.65625,
      0.89453125,
      -4.09375,
      -4.34375,
      1.5390625,
      -5.4375,
      2.03125,
      1.515625,
      5.15625,
      -5.625,
      0.37109375,
      0.287109375,
      -6.96875,
      1.046875,
      2.6875,
      2.625,
      -1.6484375,
      1.7421875,
      -4.75,
      3.84375,
      -4.90625,
      4.96875,
      0.392578125,
      -0.921875,
      1.3203125,
      4.875,
      -0.37109375,
      -3.78125,
      -1.8125,
      -2.015625,
      5.65625,
      2.546875,
      -7.125,
      2.640625,
      -2.59375,
      0.796875,
      0.431640625,
      -2.703125,
      -3.5,
      -2.046875,
      2.484375,
      2.546875,
      -4.84375,
      8.0625,
      0.6484375,
      -2.3125,
      1.796875,
      0.0274658203125,
      0.88671875,
      -1.171875,
      1.75,
      -1.890625,
      -3.71875,
      -0.169921875,
      1.96875,
      0.6328125,
      -7.09375,
      -2.140625,
      2.59375,
      -3.25,
      2.265625,
      -1.53125,
      0.7265625,
      -2.40625,
      -4.375,
      0.890625,
      2.90625,
      5.15625,
      2.5,
      3.671875,
      2.6875,
      -5.15625,
      1.6953125,
      -1.1484375,
      -4.25,
      1,
      -1.015625,
      -1.265625,
      -0.39453125,
      -1.53125,
      2.375,
      0.26953125,
      -1.8828125,
      -5.625,
      -6.0625,
      -1.6484375,
      1.421875,
      -1.5234375,
      4.65625,
      -0.578125,
      5.9375,
      0.4765625,
      -3.5,
      1.109375,
      -3.640625,
      1.625,
      -1.7578125,
      1.015625,
      -6.53125,
      -1.7421875,
      8.875,
      2.890625,
      -2.890625,
      8.0625,
      0.40625,
      -1.8515625,
      -0.87109375,
      3.40625,
      -1.0234375,
      -0.63671875,
      0.201171875,
      -1.6640625,
      -3.921875,
      -2.125,
      2.078125,
      -3.21875,
      3.15625,
      -2.84375,
      -3.328125,
      -2.328125,
      -3.8125,
      -2.109375,
      2.34375,
      -6.25,
      0.7734375,
      3.53125,
      -2.75,
      -0.6796875,
      5,
      0.7265625,
      0.62890625,
      -1.3671875,
      -1.546875,
      2.546875,
      1.6640625,
      6.1875,
      -1.75,
      -2.96875,
      0.9609375,
      -0.1357421875,
      -1.6484375,
      3.515625,
      -1.9765625,
      0.6171875,
      1.9375,
      0.498046875,
      -5.65625,
      -4.78125,
      2.453125,
      -1.3125,
      -0.1728515625,
      -0.232421875,
      2.515625,
      0.0294189453125,
      3.484375,
      0.96875,
      -5.8125,
      -3.625,
      5.34375,
      2.109375,
      0.6875,
      -1.3359375,
      4.21875,
      -1.4140625,
      3.21875,
      -5.59375,
      -3.28125,
      0.384765625,
      0.28125,
      -3.578125,
      0.1015625,
      10.3125,
      -0.98828125,
      -1.0859375,
      -0.51953125,
      1.140625,
      3.96875,
      -1.2734375,
      1.4296875,
      -0.37890625,
      4.78125,
      -1.359375,
      1.3515625,
      2.5,
      -0.7109375,
      -5.28125,
      0.002685546875,
      2.203125,
      -2.125,
      4.375,
      -1.0625,
      -2.5,
      -2.453125,
      -2.109375,
      0.11669921875,
      4.71875,
      5.96875,
      -1.65625,
      1.5390625,
      -0.0849609375,
      4.84375,
      -2.59375,
      5.5,
      0.91796875,
      6.65625,
      -1.3984375,
      -4.65625,
      0.40234375,
      -0.546875,
      -2.0625,
      0.10791015625,
      -4.84375,
      -4.34375,
      1.9609375,
      2.421875,
      -2.296875,
      3.609375,
      -6.59375,
      0.53515625,
      3.0625,
      1.390625,
      3.578125,
      3.6875,
      5.90625,
      2.234375,
      -1.265625,
      0.2451171875,
      -2.03125,
      -0.9921875,
      -0.29296875,
      0.515625,
      -2.6875,
      3.25,
      1.078125,
      5.3125,
      0.7734375,
      1.484375,
      -2.5625,
      6.375,
      0.859375,
      -2.671875,
      5.03125,
      -0.9765625,
      3.015625,
      4.125,
      2.046875,
      -2.546875,
      1.5390625,
      7.65625,
      4.3125,
      -1.2109375,
      -0.63671875,
      -0.33203125,
      0.625,
      -3.109375,
      -3.671875,
      0.11376953125,
      0.2060546875,
      -0.84375,
      -0.25,
      -0.50390625,
      3.3125,
      -3.125,
      4.8125,
      -0.71484375,
      -3.828125,
      2.09375,
      3.046875,
      -2.640625,
      1.7578125,
      0.796875,
      4.09375,
      -3.5,
      -3.546875,
      -3.359375,
      -5.53125,
      -1.7734375,
      -2.25,
      3.453125,
      0.474609375,
      5.15625,
      -2.125,
      2.8125,
      -6.875,
      -0.515625,
      -3.84375,
      4.4375,
      5.28125,
      -3.75,
      1.84375,
      -1.359375,
      -9.5,
      -7.5625,
      -2.25,
      -2.4375,
      -0.546875,
      -4.40625,
      -1.4375,
      0.9375,
      -2.140625,
      1.21875,
      -1.9765625,
      -0.478515625,
      1.859375,
      -0.2353515625,
      4.1875,
      -5.28125,
      3.453125,
      2.515625,
      -2.828125,
      1.6640625,
      2.640625,
      -0.83203125,
      3.03125,
      -3.328125,
      -0.1796875,
      -4.5625,
      6.5625,
      -5.375,
      8.5625,
      2.890625,
      1.78125,
      -5.8125,
      4.21875,
      -1.28125,
      2.953125,
      -5.9375,
      -2.609375,
      -2.71875,
      0.047607421875,
      -0.2412109375,
      0.1396484375,
      0.431640625,
      -3.765625,
      -1.3984375,
      1.0234375,
      -4.1875,
      0.0537109375,
      1.734375,
      0.9375,
      4.09375,
      0.0966796875,
      4.65625,
      1.2265625,
      -2.25,
      -0.46484375,
      0.353515625,
      1.2890625,
      -2.75,
      3.171875,
      0.349609375,
      -1.6875,
      0.76953125,
      -0.72265625,
      2.328125,
      -0.435546875,
      -1.671875,
      3.28125,
      0.79296875,
      1.78125,
      -1.1328125,
      0.52734375,
      -0.5390625,
      1.65625,
      3.15625,
      -2.71875,
      6.03125,
      1.2734375,
      1.4140625,
      -3.84375,
      0.69140625,
      -3.109375,
      0.97265625,
      -3.203125,
      -4.65625,
      -1.734375,
      0.404296875,
      -4.4375,
      1.75,
      -3.109375,
      -1.2734375,
      4.46875,
      0.8203125,
      3.40625,
      4.40625,
      -2.171875,
      1.296875,
      1.4453125,
      -1.5,
      8.5625,
      -3.34375,
      2.484375,
      4.5625,
      1.921875,
      3.203125,
      -0.337890625,
      -0.9296875,
      -3.859375,
      -0.5234375,
      8.125,
      -1.6875,
      -0.8828125,
      5.6875,
      0.380859375,
      0.9765625,
      2.078125,
      -0.8515625,
      -0.3046875,
      -2.4375,
      -0.439453125,
      5.1875,
      5.71875,
      -4,
      -1.3984375,
      -4.25,
      0.984375,
      -0.1103515625,
      -0.51171875,
      -0.5546875,
      1.4296875,
      0.828125,
      1.3203125,
      0.25390625,
      -2.234375,
      -0.1708984375,
      -4.65625,
      0.03955078125,
      4.3125,
      -0.30078125,
      0.314453125,
      2.671875,
      5.5625,
      -1.65625,
      4.21875,
      2.0625,
      -1.78125,
      4.4375,
      2.21875,
      0.470703125,
      4.21875,
      2.46875,
      2.453125,
      2.59375,
      -2.90625,
      -1.2109375,
      -1.265625,
      -3.84375,
      0.40625,
      -4.1875,
      0.205078125,
      3.390625,
      4.59375,
      -1.5078125,
      3.21875,
      -0.875,
      1.59375,
      1.15625,
      -1.5390625,
      -6.09375,
      -1.4921875,
      -0.08935546875,
      -4,
      0.05419921875,
      -0.91796875,
      -0.51953125,
      2.90625,
      -6.1875,
      5.5625,
      -3.890625,
      6.25,
      0.7421875,
      -1.5078125,
      -4.9375,
      -2.359375,
      2.109375,
      -0.1279296875,
      0.89453125,
      2.28125,
      -2.84375,
      1.375,
      -2.15625,
      1.9296875,
      3.46875,
      -1.65625,
      2.28125,
      -2.90625,
      1.1875,
      -0.3359375,
      0.7734375,
      -5.8125,
      -4.46875,
      0.431640625,
      1.015625,
      -0.181640625,
      -0.337890625,
      1.8046875,
      -1.0390625,
      2.71875,
      -3.03125,
      1.28125,
      -1.2734375,
      -1.9765625,
      2.171875,
      -0.2421875,
      5.84375,
      0.77734375,
      -0.1591796875,
      -0.10693359375,
      -2.046875,
      -8.5625,
      -1.8359375,
      -0.166015625,
      3.671875,
      -3.359375,
      1.4921875,
      0.578125,
      0.625,
      0.84375,
      -1.1484375,
      1.328125,
      3.09375,
      4.21875,
      1.6953125,
      2.3125,
      -2.109375,
      -0.35546875,
      -4.96875,
      -5.1875,
      -5,
      2.015625,
      3.578125,
      -3.953125,
      1.3671875,
      -4.65625,
      1.5703125,
      -0.46875,
      -1.0078125,
      -1.6796875,
      -0.138671875,
      4.53125,
      0.236328125,
      -2.4375,
      1.5546875,
      -3,
      0.5703125,
      -0.330078125,
      -2.5625,
      -2.828125,
      2.625,
      -0.396484375,
      2.0625,
      0.0245361328125,
      -2.796875,
      1.8984375,
      -2.484375,
      -2.59375,
      -2.109375,
      2.453125,
      1.3203125,
      4.25,
      4.28125,
      0.466796875,
      -2.90625,
      1.71875,
      -0.271484375,
      5.9375,
      0.279296875,
      -0.859375,
      2.09375,
      -0.23828125,
      3.703125,
      -1.59375,
      -0.68359375,
      -5.46875,
      0.75390625,
      6.875,
      0.90625,
      -0.09814453125,
      1.5859375,
      -0.7265625,
      2.609375,
      1.40625,
      3.484375,
      -3.234375,
      -1.8359375,
      -3.390625,
      2.84375,
      1.7421875,
      -4.40625,
      1.078125,
      3.4375,
      -3.9375,
      2.984375,
      4.0625,
      5.5625,
      -1.2109375,
      3.171875,
      -3.953125,
      -3.6875,
      -3.78125,
      1.6796875,
      2.84375,
      1.9296875,
      -2.46875,
      -5,
      -1.2421875,
      1.671875,
      2.875,
      6.21875,
      -3.328125,
      1.0390625,
      1.1875,
      3.171875,
      1.109375,
      -0.9140625,
      -0.298828125,
      2.828125,
      -1.28125,
      -2.734375,
      2.25,
      -2.71875,
      0.57421875,
      -0.8671875,
      -7.78125,
      -0.291015625,
      1.046875,
      -1,
      3,
      -1.140625,
      -2.171875,
      1.1328125,
      -1.78125,
      -1.0078125,
      -2.125,
      0.482421875,
      2.078125,
      -1.484375,
      -1.59375,
      2.09375,
      -0.84375,
      -2.625,
      -1.3828125,
      2.703125,
      -1.34375,
      2.53125,
      4.875,
      4.46875,
      -4.28125,
      -5.4375,
      0.7265625,
      -1.2578125,
      -4.125,
      -0.408203125,
      -0.66796875,
      -0.034912109375,
      1.7421875,
      -1.1484375,
      -2.484375,
      -1.3046875,
      -5.375,
      4.65625,
      1.0703125,
      5.90625,
      -3.84375,
      5.59375,
      -5.71875,
      2.28125,
      0.578125,
      -4.125,
      -2.234375,
      1.4453125,
      -2.109375,
      1.359375,
      3.921875,
      -0.10009765625,
      -0.07470703125,
      2.484375,
      -1.1953125,
      -2.34375,
      -2.84375,
      1.1015625,
      1.375,
      0.26171875,
      2.75,
      -0.37109375,
      1.9921875,
      -2.265625,
      -2.671875,
      0.40234375,
      1.03125,
      -0.71875,
      3.65625,
      1.6640625,
      -1.1796875,
      3.703125,
      -0.80078125,
      3.765625,
      0.2021484375,
      -1.9453125,
      1.140625,
      -1.765625,
      -0.146484375,
      -4.75,
      3.75,
      -0.009033203125,
      -1.2109375,
      3.359375,
      5.4375,
      -3.46875,
      -1.59375,
      2.984375,
      3.375,
      -5.84375,
      0.4375,
      -2.0625,
      6.125,
      -1.359375,
      2.59375,
      -4.125,
      -1.6640625,
      0.671875,
      -2.578125,
      2.65625,
      -0.302734375,
      1.8359375,
      -3.078125,
      -2.484375,
      4.96875,
      1.7890625,
      1.3046875,
      -3.0625,
      -1.046875,
      1.203125,
      -1.140625,
      4.34375,
      -0.421875,
      -2.515625,
      -2.96875,
      3.6875,
      -2.71875,
      -1.9453125,
      -9,
      -0.640625,
      -2.734375,
      -2.359375,
      -1.890625,
      1.921875,
      1.125,
      1.8515625,
      -1.4921875,
      -2.25,
      -3.28125,
      -4.8125,
      2.484375,
      -1.3125,
      -3.328125,
      -0.353515625,
      0.0986328125,
      3.390625,
      6,
      5.53125,
      2.453125,
      -2.828125,
      -0.427734375,
      -1.7265625,
      3.671875,
      0.94921875,
      -1.7265625,
      -2.859375,
      -1.6328125,
      2.53125,
      1.7734375,
      2.0625,
      -5.40625,
      -3.984375,
      -4.28125,
      -3.09375,
      -1.4453125,
      3.703125,
      -1.375,
      1.890625,
      6.53125,
      -1.6875,
      0.435546875,
      1.2890625,
      -0.61328125,
      -4.53125,
      -1.40625,
      -0.66015625,
      5.75,
      2.171875,
      5.09375,
      -2.078125,
      7.90625,
      2.453125,
      -2.140625,
      2.25,
      0.154296875,
      1.265625,
      -3.8125,
      5.375,
      1.53125,
      1.9453125,
      1.5,
      0.3671875,
      4.25,
      1.6328125,
      3.734375,
      3.0625,
      4.15625,
      -2.78125,
      1.7109375,
      0.828125,
      -2.25,
      -1.2421875,
      0.86328125,
      -1.8828125,
      -0.65234375,
      4.0625,
      1.5546875,
      4.75,
      -2.09375,
      0.70703125,
      1.5078125,
      2.015625,
      -6,
      0.3359375,
      -6.65625,
      -0.3046875,
      -5.15625,
      -2,
      -8.9375,
      -0.88671875,
      3.15625,
      3.890625,
      -0.56640625,
      -2.96875,
      4.15625,
      6.5,
      -1.0703125,
      -4.78125,
      4.6875,
      -0.21875,
      -1.890625,
      -3.65625,
      -2.171875,
      5.5625,
      1.2421875,
      2.515625,
      -4.46875,
      1.3046875,
      0.349609375,
      -0.6640625,
      -3.296875,
      2.859375,
      -0.53515625,
      -8,
      -6.9375,
      -4.96875,
      -0.8828125,
      -3.53125,
      3.9375,
      2.28125,
      -0.181640625,
      0.37109375,
      0.73828125,
      0.2236328125,
      2.359375,
      -1.59375,
      0.84375,
      1.125,
      -1.546875,
      -1.171875,
      5.25,
      -2.453125,
      2.25,
      -2.234375,
      2.5625,
      0.9375,
      -2.6875,
      -0.9453125,
      -8,
      2.390625,
      4.46875,
      3.171875,
      0.2275390625,
      -0.734375,
      0.9921875,
      1.1640625,
      -2.1875,
      -0.546875,
      4.59375,
      -0.32421875,
      -3.609375,
      -1.3671875,
      -2.78125,
      2.703125,
      -0.5546875,
      0.0235595703125,
      1.0234375,
      -0.306640625,
      -1.0625,
      -3.8125,
      -5.125,
      3.515625,
      -0.376953125,
      3.5625,
      -3.546875,
      -0.9609375,
      0.55859375,
      3.953125,
      2.421875,
      2.46875,
      -0.0400390625,
      -0.9609375,
      2.234375,
      3.59375,
      0.70703125,
      -2.625,
      0.28515625,
      3.09375,
      -3.03125,
      -2.953125,
      -2.359375,
      -0.275390625,
      2.421875,
      -3.03125,
      -2.859375,
      -0.765625,
      0.85546875,
      -0.55078125,
      -8.625,
      0.359375,
      -3.1875,
      -0.6640625,
      -3.15625,
      -0.6171875,
      3,
      3.03125,
      1.109375,
      4.4375,
      3.234375,
      -1.5,
      5.21875,
      19.75,
      -2.4375,
      -1.53125,
      0.53515625,
      -2.5,
      4.53125,
      3.8125,
      3.140625,
      -0.031494140625,
      0.1015625,
      -2.0625,
      2.28125,
      2.21875,
      3.03125,
      0.4453125,
      -1.375,
      0.6015625,
      0.359375,
      -2.96875,
      -3.953125,
      2.484375,
      -3.40625,
      -0.412109375,
      0.2373046875,
      -2.40625,
      1.3984375,
      0.35546875,
      0.69140625,
      -2.734375,
      -1.265625,
      -0.546875,
      0.6328125,
      -0.80859375,
      -6.03125,
      0.5234375,
      -1.890625,
      0.5,
      0.1875,
      -3.234375,
      -4.25,
      -0.5859375,
      -2.4375,
      4.9375,
      -0.9296875,
      -1.1171875,
      1.1796875,
      -1.2578125,
      1.1015625,
      -0.953125,
      1.3984375,
      -1.1953125,
      1.1328125,
      -3.96875,
      1.7890625,
      0.2470703125,
      0.1044921875,
      -0.38671875,
      -5.46875,
      -3.46875,
      -3.65625,
      -1.3203125,
      -1.3671875,
      -4.4375,
      -0.1669921875,
      -0.5546875,
      -3.65625,
      -0.2080078125,
      -0.97265625,
      0.1767578125,
      -0.484375,
      -2.5,
      0.60546875,
      5.59375,
      1.7421875,
      0.625,
      -1.9296875,
      1.5546875,
      2.671875,
      -0.546875,
      2.578125,
      -2.234375,
      0.93359375,
      -1.1640625,
      0.91015625,
      -1.84375,
      1.3515625,
      -3.21875,
      3.265625,
      1.4375,
      -2.421875,
      4.53125,
      -6.125,
      4.625,
      3.328125,
      -6.125,
      -0.2373046875,
      1.4453125,
      5.9375,
      -3.921875,
      -1.859375,
      2.90625,
      -1.4140625,
      -0.1298828125,
      -2.515625,
      -0.404296875,
      -2.109375,
      0.96484375,
      -0.796875,
      1.59375,
      -0.57421875,
      -0.953125,
      5.34375,
      2.8125,
      -0.08935546875,
      1.0859375,
      1.109375,
      -5.375,
      -0.78515625,
      0.08447265625,
      -0.76171875,
      3.671875,
      1.203125,
      -1.6484375,
      0.00457763671875,
      -9.25,
      -4.25,
      -2.34375,
      -6.84375,
      1.9453125,
      -6.21875,
      1.3125,
      0.8984375,
      -2.53125,
      -1.25,
      1.6015625,
      -3.875,
      2.59375,
      5.125,
      0.9765625,
      -2,
      -3.6875,
      -0.02392578125,
      -0.486328125,
      -1.609375,
      1.5859375,
      2.734375,
      -2.640625,
      2.390625,
      3.8125,
      -0.1923828125,
      -0.97265625,
      3.3125,
      -1.7421875,
      -5.71875,
      0.91796875,
      5.34375,
      0.53125,
      -2.0625,
      -2.046875,
      -0.62890625,
      -2.03125,
      0.84765625,
      -2.390625,
      -1.90625,
      -3.234375,
      -2.21875,
      2.578125,
      -1.1484375,
      -4.5625,
      1.2421875,
      0.71875,
      -6.59375,
      0.091796875,
      -3.15625,
      5.84375,
      -5.28125,
      1.1953125,
      8.5625,
      -0.08837890625,
      1.4140625,
      2.890625,
      0.287109375,
      -2.0625,
      -6.28125,
      3.84375,
      4.96875,
      -3.625,
      2.40625,
      3.03125,
      -1.4609375,
      1.25,
      -1.5234375,
      -3.6875,
      6,
      4.65625,
      -5.25,
      -0.50390625,
      0.197265625,
      1.875,
      -0.84765625,
      -3.09375,
      3.359375,
      2.34375,
      1.546875,
      1.3203125,
      0.03076171875,
      -7.21875,
      -2.671875,
      -1.7421875,
      0.546875,
      -1.1796875,
      1.6484375,
      -0.1748046875,
      1.0703125,
      -7.09375,
      5.21875,
      2.125,
      5.5,
      -2.890625,
      2.515625,
      5.59375,
      2.53125,
      -3.890625,
      -0.0213623046875,
      1.3515625,
      3.421875,
      -6.65625,
      -0.171875,
      -3.6875,
      2.484375,
      -2.9375,
      1.3671875,
      -2.28125,
      0.83203125,
      -3.25,
      -2.296875,
      -5.65625,
      1.3359375,
      1.8203125,
      -0.146484375,
      1.4609375,
      -1.4765625,
      0.8203125,
      3.40625,
      -3.921875,
      1.6328125,
      -2.859375,
      0.76953125,
      -0.40234375,
      -2.0625,
      4.625,
      3.53125,
      4.28125,
      -1.5703125,
      -1.2734375,
      -1.6953125,
      -5.1875,
      1.1171875,
      -5.8125,
      -1.578125,
      0.62109375,
      -6.25,
      4.0625,
      -1.140625,
      -0.251953125,
      0.427734375,
      0.671875,
      -6.03125,
      2.28125,
      3.0625,
      -2.890625,
      2.578125,
      -5,
      -2.703125,
      0.50390625,
      -2.5625,
      0.69921875,
      -4.4375,
      -1.6015625,
      2.28125,
      -3.96875,
      0.5234375,
      3.703125,
      -1.1484375,
      1.0234375,
      -1.9140625,
      5.4375,
      0.95703125,
      2.359375,
      3.734375,
      3.28125,
      4.75,
      -4.75,
      2.0625,
      -3.765625,
      -1.3203125,
      -4.78125,
      0.318359375,
      1.984375,
      -2.03125,
      1.6875,
      1.6484375,
      -0.46484375,
      -7.75,
      -2.390625,
      0.546875,
      -0.55078125,
      2.359375,
      -0.4375,
      0.3515625,
      -1.6796875,
      -0.48046875,
      2.828125,
      0.287109375,
      -0.84375,
      -1.640625,
      -0.50390625,
      -0.1826171875,
      3.828125,
      -7.09375,
      -0.2578125,
      1.7265625,
      0.1611328125,
      0.1796875,
      -1.6640625,
      -0.53125,
      -0.380859375,
      5.28125,
      -4.03125,
      1.3515625,
      0.4375,
      2.65625,
      5.9375,
      -0.361328125,
      1.1171875,
      1.046875,
      -0.9296875,
      -3.90625,
      0.76953125,
      -2.5,
      0.050537109375,
      2.8125,
      -3.171875,
      4.1875,
      0.234375,
      1.046875,
      -2.0625,
      6.625,
      1.4375,
      -7.40625,
      4.28125,
      -2.984375,
      2.78125,
      -0.322265625,
      -3.296875,
      -3.890625,
      4.84375,
      1.2109375,
      -0.765625,
      2.96875,
      0.0186767578125,
      2.0625,
      1.2734375,
      -0.0098876953125,
      -4.40625,
      1.6796875,
      -0.7890625,
      -3.78125,
      3.28125,
      5.34375,
      -0.058349609375,
      -0.515625,
      -0.97265625,
      4.25,
      -2.21875,
      -2.90625,
      4.84375,
      4.40625,
      -0.0252685546875,
      -3.03125,
      -1.3671875,
      -0.032958984375,
      -1.21875,
      -2.140625,
      0.259765625,
      -0.3984375,
      2.703125,
      -2.84375,
      1.6171875,
      2.78125,
      -2.828125,
      -4.0625,
      -4.1875,
      -1.75,
      1.3203125,
      1.921875,
      2.984375,
      -4.28125,
      0.87109375,
      2.78125,
      0.1611328125,
      -1.9609375,
      -2.296875,
      1.34375,
      -3,
      -3.140625,
      -1.890625,
      1.2109375,
      -1.25,
      -1.265625,
      0.91796875,
      0.65625,
      0.1376953125,
      -4.75,
      -1.9375,
      0.62890625,
      2.1875,
      -2.15625,
      -3.234375,
      -2.890625,
      3.640625,
      2.828125,
      -4.125,
      0.359375,
      -0.7578125,
      3.5,
      -4.65625,
      -1.4296875,
      2.15625,
      -2.28125,
      0.60546875,
      6.71875,
      0.427734375,
      0.75390625,
      3.046875,
      -3.796875,
      -2.890625,
      3.328125,
      1.890625,
      0.89453125,
      1.3828125,
      -0.95703125,
      -3.59375,
      4.09375,
      6.75,
      -1.484375,
      -0.62109375,
      1.65625,
      -0.26953125,
      -2.953125,
      -2.046875,
      2.578125,
      -1.203125,
      -5.65625,
      3.5625,
      -1,
      3.9375,
      4.125,
      -3.546875,
      4.75,
      -4.1875,
      -0.65625,
      0.96875,
      2.84375,
      0.98046875,
      -3.71875,
      0.640625,
      -5.34375,
      -2.734375,
      -1.2265625,
      -1.4453125,
      -0.044921875,
      0.11279296875,
      3.078125,
      -1.265625,
      -3.546875,
      -1.3125,
      -1.1796875,
      4.96875,
      -1.5625,
      -1.0625,
      0.2578125,
      -1.9609375,
      2.15625,
      -2.46875,
      0.287109375,
      -4.125,
      -1.5859375,
      -2.5,
      2.78125,
      0.52734375,
      0.1142578125,
      -1.2265625,
      -3.21875,
      -2.484375,
      5.78125,
      2.09375,
      1.78125,
      0.70703125,
      2.765625,
      -0.94921875,
      1.0234375,
      3.015625,
      6.25,
      3.0625,
      -0.189453125,
      0.921875,
      0.375,
      0.38671875,
      -0.205078125,
      -1.3125,
      0.4296875,
      1.53125,
      6.0625,
      1.46875,
      0.7734375,
      -1.7890625,
      -2.5625,
      -3.71875,
      -1.7109375,
      1.1796875,
      0.43359375,
      -0.87109375,
      1.9140625,
      1.265625,
      3,
      -0.3125,
      1.1328125,
      -0.6875,
      -0.1875,
      -1.1796875,
      2.609375,
      -2.53125,
      -2.359375,
      -1.4296875,
      -0.55859375,
      0.310546875,
      -1.4140625,
      -4.84375,
      1.6015625,
      3.1875,
      -1.765625,
      3.84375,
      -0.498046875,
      -0.5625,
      -1.921875,
      0.85546875,
      0.34375,
      2.03125,
      -0.2109375,
      4.1875,
      -1.046875,
      1.0703125,
      2.421875,
      0.1484375,
      0.6015625,
      1.4375,
      0.1298828125,
      0.828125,
      0.2138671875,
      0.236328125,
      -0.9609375,
      -1.7109375,
      4.53125,
      2.90625,
      0.423828125,
      -0.76171875,
      -0.24609375,
      -4.5,
      1.2421875,
      -1.3203125,
      -0.69921875,
      0.474609375,
      -0.0012969970703125,
      -1.0078125,
      2.359375,
      -0.69140625,
      0.62109375,
      2.328125,
      -2.171875,
      -0.1123046875,
      -2.703125,
      2.375,
      -2.96875,
      0.625,
      2.625,
      2.171875,
      -2.140625,
      -1.5234375,
      2.265625,
      -0.171875,
      0.2578125,
      -1.1015625,
      0.2119140625,
      0.52734375,
      0.515625,
      -1.9609375,
      2.453125,
      2.09375,
      2.125,
      3.265625,
      0.4609375,
      1.9453125,
      -1.1328125,
      -0.1591796875,
      0.58984375,
      1.6484375,
      -0.953125,
      -0.0947265625,
      -0.1455078125,
      -0.79296875,
      0.5546875,
      1.1953125,
      0.39453125,
      2.171875,
      -0.30078125,
      0.1845703125,
      -2.546875,
      -0.76171875,
      1.109375,
      0.193359375,
      -2.0625,
      -3.046875,
      0.25390625,
      -1.3203125,
      1.3203125,
      0.97265625,
      -2.390625,
      0.70703125,
      -2.53125,
      -1.3515625,
      3.296875,
      0.48828125,
      -1.96875,
      3.09375,
      -1.6328125,
      0.6328125,
      0.4296875,
      1.125,
      -2.265625,
      0.275390625,
      -1.0546875,
      -2.84375,
      -0.57421875,
      -1.6953125,
      0.30078125,
      0.32421875,
      -0.53125,
      0.70703125,
      0.384765625,
      -0.5078125,
      0.5,
      -1.8671875,
      -0.427734375,
      1.3203125,
      2.203125,
      2.09375,
      4.125,
      -0.359375,
      3.46875,
      -0.0771484375,
      -2.71875,
      2.859375,
      -0.380859375,
      -1.203125,
      0.90234375,
      -1.1171875,
      -0.040283203125,
      -0.228515625,
      -1.6484375,
      -0.80078125,
      -1.828125,
      -0.2265625,
      1.609375,
      -0.58203125,
      1.6796875,
      3.375,
      0.298828125,
      1.1953125,
      -0.8125,
      2.015625,
      0.0546875,
      1.2578125,
      2.859375,
      2.140625,
      -1.25,
      -1.25,
      -1.8828125,
      -1.046875,
      -0.5078125,
      -0.54296875,
      2.359375,
      -3.78125,
      1.71875,
      4.34375,
      -0.98828125,
      3.015625,
      -1.265625,
      0.2041015625,
      0.255859375,
      -0.5390625,
      0.427734375,
      4.0625,
      -0.028076171875,
      0.271484375,
      1.734375,
      -0.087890625,
      -0.040771484375,
      -3.046875,
      1.75,
      1.515625,
      -0.65625,
      0.33984375,
      3.203125,
      0.90234375,
      1.9609375,
      1.484375,
      1.1640625,
      2.109375,
      -1.6328125,
      5.59375,
      1.7109375,
      0.2412109375,
      2.53125,
      0.9296875,
      1.703125,
      1.3828125,
      -3.59375,
      0.7421875,
      -1.6171875,
      1.1328125,
      3.265625,
      0.482421875,
      1.4296875,
      -1.90625,
      -1.671875,
      1.3359375,
      -1.0078125,
      1.3984375,
      1.2265625,
      2.359375,
      -0.9140625,
      0.734375,
      -0.486328125,
      -0.0166015625,
      0.36328125,
      -4.125,
      -0.53125,
      1.125,
      -0.04833984375,
      -3.046875,
      -1.671875,
      -5,
      -2.640625,
      -1.6328125,
      -2.171875,
      0.90234375,
      1.3359375,
      -1.125,
      -2.734375,
      -2.140625,
      -1.125,
      3.640625,
      0.06396484375,
      -0.72265625,
      4.15625,
      0.57421875,
      0.44140625,
      -1.7265625,
      -2.640625,
      -1.15625,
      1.1875,
      -0.9375,
      -1.5,
      -1.265625,
      -0.765625,
      -1.515625,
      -0.7734375,
      2.1875,
      -1.390625,
      -3.453125,
      -0.90234375,
      1.0546875,
      -4.5,
      2.625,
      -2.234375,
      4.53125,
      0.74609375,
      1.2734375,
      0.0830078125,
      -0.015869140625,
      4.34375,
      1.3046875,
      -3.34375,
      -2.984375,
      3.03125,
      -0.306640625,
      0.93359375,
      -0.61328125,
      1.796875,
      6.5625,
      -0.87890625,
      -1.1484375,
      1.90625,
      0.9453125,
      -0.298828125,
      1.984375,
      4.4375,
      -5,
      -0.35546875,
      0.40234375,
      -1.7109375,
      1.3046875,
      2.5,
      2.953125,
      2.71875,
      4.15625,
      -1.3125,
      1.390625,
      -0.859375,
      -2.140625,
      0.58984375,
      1.5703125,
      0.36328125,
      -1.890625,
      -0.19140625,
      0.90234375,
      0.1376953125,
      3.265625,
      -1.0234375,
      0.9609375,
      1.9921875,
      -3.140625,
      0.08447265625,
      0.9453125,
      -0.2236328125,
      5.09375,
      2.0625,
      -1.296875,
      0.283203125,
      -0.248046875,
      2.671875,
      -0.25390625,
      2.140625,
      -1.65625,
      2.5,
      -1.5390625,
      -7.03125,
      -2.171875,
      1.7109375,
      -1.6015625,
      -0.2021484375,
      -2.765625,
      -2.28125,
      -1.984375,
      3.09375,
      -2.4375,
      0.77734375,
      4.21875,
      2.53125,
      2.421875,
      2.828125,
      0.007232666015625,
      2.375,
      2.1875,
      -4.4375,
      2.640625,
      -0.85546875,
      -4.84375,
      -2.515625,
      1.734375,
      -2.203125,
      -2.578125,
      -1.859375,
      -0.4453125,
      -1.7421875,
      -0.58984375,
      0.46875,
      -5.09375,
      2.78125,
      -4,
      -1.0078125,
      -2.28125,
      -0.056396484375,
      -4.03125,
      0.006591796875,
      -0.921875,
      -0.88671875,
      2.59375,
      -0.66015625,
      2,
      -1.765625,
      -1.078125,
      2.078125,
      -5.03125,
      0.1865234375,
      2.703125,
      -2.609375,
      -1.96875,
      -1.7578125,
      2.734375,
      -0.419921875,
      -1.0546875,
      0.3359375,
      -0.2470703125,
      1.984375,
      3.65625,
      -2.03125,
      1.34375,
      -2.75,
      -1.1875,
      -2.953125,
      0.95703125,
      -1.1875,
      -2.140625,
      -2.078125,
      3.078125,
      -3.796875,
      2.9375,
      -1.640625,
      0.81640625,
      0.75390625,
      -2.90625,
      1.609375,
      -1.3828125,
      -4.625,
      0.5078125,
      0.87890625,
      0.02587890625,
      -0.93359375,
      4.75,
      -3.328125,
      1.8828125,
      -2.21875,
      0.74609375,
      1.2734375,
      1.453125,
      -1.78125,
      2.578125,
      0.80078125,
      -0.48828125,
      3.6875,
      2.359375,
      -0.98046875,
      -0.78515625,
      -0.6015625,
      -0.765625,
      -0.93359375,
      4.40625,
      -1.6875,
      -4.46875,
      -0.486328125,
      -0.703125,
      1.734375,
      -1.75,
      1.4609375,
      -1.6640625,
      1.203125,
      0.71484375,
      3.0625,
      2,
      0.58984375,
      2.171875,
      1.71875,
      0.69921875,
      -1.5703125,
      -1.8046875,
      0.1376953125,
      4.8125,
      0.341796875,
      -2.0625,
      3.609375,
      0.30078125,
      -0.5703125,
      -1.6015625,
      1.53125,
      0.63671875,
      -0.24609375,
      -2.5625,
      -2.671875,
      -0.490234375,
      -2.734375,
      -3.015625,
      2.828125,
      0.86328125,
      -0.4609375,
      3.21875,
      1,
      -2.15625,
      -0.5625,
      -1.6015625,
      2.921875,
      0.6015625,
      0.7109375,
      0.064453125,
      2.515625,
      -1.4140625,
      0.9296875,
      0.8046875,
      1.2265625,
      3.25,
      0.66015625,
      -0.06005859375,
      -1.59375,
      2.125,
      -0.73828125,
      3.078125,
      1.875,
      0.380859375,
      -2.265625,
      3.359375,
      2.890625
    ],
    "summary": "采用结构化、可复现的流程，对神经问题生成（NQG）领域的现有研究进行全面检索、筛选、分析和综合，以总结该领域的现状、方法、趋势和挑战。",
    "structure": {
      "sections": [
        {
          "title": "A Systematic Review of Automatic Neural Question Generation",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "1 Abstract",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "1. INTRODUCTION",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "2. METHODOLOGY",
          "level": 1,
          "start_line": 25
        },
        {
          "title": "2.1 Research Questions",
          "level": 1,
          "start_line": 36
        },
        {
          "title": "2.1.1 Old Research Questions:",
          "level": 1,
          "start_line": 38
        },
        {
          "title": "2.1.2 New Research Questions:",
          "level": 1,
          "start_line": 61
        },
        {
          "title": "2.2 Data Sources and Search Strategy",
          "level": 1,
          "start_line": 77
        },
        {
          "title": "2.3 Study Selection Criteria",
          "level": 1,
          "start_line": 91
        },
        {
          "title": "Inclusion Criteria:",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "Exclusion criteria:",
          "level": 1,
          "start_line": 104
        },
        {
          "title": "2.4 Study Selection Process",
          "level": 1,
          "start_line": 110
        },
        {
          "title": "- Iteration 0 - Filtering by Title",
          "level": 1,
          "start_line": 114
        },
        {
          "title": "- Iteration 2 - Filtering by Full Text",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "2.5 Quality Assessment",
          "level": 1,
          "start_line": 129
        },
        {
          "title": "2.6 Included papers",
          "level": 1,
          "start_line": 146
        },
        {
          "title": "2.7 Data Extraction Strategy",
          "level": 1,
          "start_line": 165
        },
        {
          "title": "Paper Information:",
          "level": 1,
          "start_line": 169
        },
        {
          "title": "Data extracted:",
          "level": 1,
          "start_line": 176
        },
        {
          "title": "2.8 Synthesis Matrix",
          "level": 1,
          "start_line": 216
        },
        {
          "title": "3. RESULT AND DISCUSSION",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "3.1 Neural Question Generation (NQG)",
          "level": 1,
          "start_line": 237
        },
        {
          "title": "3.1.1 Word Embedding",
          "level": 1,
          "start_line": 246
        },
        {
          "title": "3.1.2 Seq2Seq",
          "level": 1,
          "start_line": 256
        },
        {
          "title": "3.2 Gated Recurrent Units (GRUs)",
          "level": 1,
          "start_line": 275
        },
        {
          "title": "The Architecture of the GRU",
          "level": 1,
          "start_line": 279
        },
        {
          "title": "Math and pictorial representation to understand the functioning",
          "level": 1,
          "start_line": 299
        },
        {
          "title": "Update gate:",
          "level": 1,
          "start_line": 301
        },
        {
          "title": "Where,",
          "level": 1,
          "start_line": 314
        },
        {
          "title": "Reset gate",
          "level": 1,
          "start_line": 322
        },
        {
          "title": "Where,",
          "level": 1,
          "start_line": 335
        },
        {
          "title": "How GRU Works",
          "level": 1,
          "start_line": 343
        },
        {
          "title": "What is the difference between the GRU and the LSTM?",
          "level": 1,
          "start_line": 371
        },
        {
          "title": "3.2.1 Word2Vec",
          "level": 1,
          "start_line": 381
        },
        {
          "title": "3.2.2 Seq2Seq with Attention Mechanism",
          "level": 1,
          "start_line": 390
        },
        {
          "title": "3.2.3 Preprocessing",
          "level": 1,
          "start_line": 408
        },
        {
          "title": "3.2.4 Lexical Feature (POS)",
          "level": 1,
          "start_line": 414
        },
        {
          "title": "Framework for POS discovering:",
          "level": 1,
          "start_line": 428
        },
        {
          "title": "3.2.5 Lexical Features (NER)",
          "level": 1,
          "start_line": 436
        },
        {
          "title": "Methods of NER",
          "level": 1,
          "start_line": 446
        },
        {
          "title": "3.2.6 BLUE and precision Evaluation Metrics",
          "level": 1,
          "start_line": 452
        },
        {
          "title": "Precision:",
          "level": 1,
          "start_line": 454
        },
        {
          "title": "BLEU, which stands for Bi-Lingual Evaluation Understudy:",
          "level": 1,
          "start_line": 464
        },
        {
          "title": "3.3 Update on Research Questions",
          "level": 1,
          "start_line": 480
        },
        {
          "title": "3.4 Threats to Validity",
          "level": 1,
          "start_line": 498
        },
        {
          "title": "4. CONCLUSION AND FUTURE WORK",
          "level": 1,
          "start_line": 507
        },
        {
          "title": "8. Graph Encoders for Question Generation",
          "level": 1,
          "start_line": 523
        },
        {
          "title": "5. REFERENCES",
          "level": 1,
          "start_line": 525
        }
      ]
    },
    "suggested_tags": [
      "自然语言处理",
      "神经问题生成",
      "序列到序列模型",
      "系统文献综述",
      "教育技术"
    ],
    "tag_suggestions": [
      {
        "name": "自然语言处理",
        "confidence": 0.98,
        "reason": "论文核心研究对象是自然语言处理（NLP）领域中的自动问题生成任务，全文围绕NLP技术展开讨论。"
      },
      {
        "name": "神经问题生成",
        "confidence": 0.95,
        "reason": "论文主题为‘神经问题生成’的系统性综述，深入分析了基于深度学习的NQG模型、方法、数据集和评估。"
      },
      {
        "name": "序列到序列模型",
        "confidence": 0.9,
        "reason": "论文明确指出所有NQG模型共享一个Seq2Seq基础框架，并重点讨论了结合注意力机制的Seq2Seq模型。"
      },
      {
        "name": "系统文献综述",
        "confidence": 0.85,
        "reason": "论文采用的研究方法是系统文献综述，旨在全面梳理和总结该领域的研究现状、趋势与挑战。"
      },
      {
        "name": "教育技术",
        "confidence": 0.75,
        "reason": "论文多次提及NQG在教育领域的应用，如促进自主学习和作为教育工具，这是其主要应用场景之一。"
      }
    ],
    "category": "自然语言处理",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:282895720",
          "title": "VocQuiz: Vocabulary Question Generation for English Language Education",
          "authors": [
            "Yongqi Li",
            "Jiajun Wu",
            "Shangqing Tu",
            "Jifan Yu",
            "Huiqin Liu",
            "Lei Hou",
            "Juanzi Li"
          ],
          "year": 2025,
          "venue": "International Conference on Information and Knowledge Management",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282272756",
          "title": "Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization",
          "authors": [
            "Yuto Tomikawa",
            "Masaki Uto"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281960356",
          "title": "Automated question generation for Arabic language",
          "authors": [
            "Rahaf A. Alhazaymeh",
            "Mostafa Z. Ali"
          ],
          "year": 2025,
          "venue": "Cluster Computing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282163675",
          "title": "Coordinated LLM multi-agent systems for collaborative question-answer generation",
          "authors": [
            "Sami Saadaoui",
            "Eduardo Alonso"
          ],
          "year": 2025,
          "venue": "Knowledge-Based Systems",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282223830",
          "title": "Knowledge graph question generation based on crucial semantic information",
          "authors": [
            "Mingtao Zhou",
            "Juxiang Zhou",
            "Jianhou Gan",
            "Jun Wang",
            "Jiatian Mei"
          ],
          "year": 2025,
          "venue": "Data & Knowledge Engineering",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281351414",
          "title": "A literature review of research on question generation in education",
          "authors": [
            "XiaoHui Dong",
            "Xinyu Zhang",
            "Zhengluo Li",
            "Quanxin Hou",
            "Jixiang Xue",
            "Xiaoyi Li"
          ],
          "year": 2025,
          "venue": "PeerJ Computer Science",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280870274",
          "title": "Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails",
          "authors": [
            "Kellen Cheng",
            "Anna Lisa Gentile",
            "Chad DeLuca",
            "Guang-Jie Ren"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280686598",
          "title": "Ask Good Questions for Large Language Models",
          "authors": [
            "Qi Wu",
            "Zhong Lu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280641733",
          "title": "Learning Facts at Scale with Active Reading",
          "authors": [
            "Jessy Lin",
            "Vincent-Pierre Berges",
            "Xilun Chen",
            "Wen-tau Yih",
            "Gargi Ghosh",
            "Barlas Oğuz"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:280649596",
          "title": "Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis",
          "authors": [
            "Linqing Chen",
            "Hanmeng Zhong",
            "Wentao Wu",
            "Weilei Wang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        }
      ],
      "citations_fetched_at": "2025-12-16T22:48:21.493125",
      "references": [
        {
          "external_id": "CorpusId:16538528",
          "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
          "authors": [
            "Guillaume Klein",
            "Yoon Kim",
            "Yuntian Deng",
            "Jean Senellart",
            "Alexander M. Rush"
          ],
          "year": 2017,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1934
        },
        {
          "external_id": "CorpusId:260460088",
          "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
          "authors": [
            "Payal Bajaj",
            "Daniel Fernando Campos",
            "Nick Craswell",
            "Li Deng",
            "Jianfeng Gao",
            "Xiaodong Liu",
            "Rangan Majumder",
            "Andrew McNamara",
            "Bhaskar Mitra",
            "Tri Minh Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "A. Stoica",
            "Saurabh Tiwary",
            "Tong Wang"
          ],
          "year": 2016,
          "venue": "",
          "citation_count": 525
        },
        {
          "external_id": "CorpusId:1289517",
          "title": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
          "authors": [
            "Daniel Fernando Campos",
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "L. Deng",
            "Bhaskar Mitra"
          ],
          "year": 2016,
          "venue": "CoCo@NIPS",
          "citation_count": 3111
        },
        {
          "external_id": "CorpusId:8820379",
          "title": "Summarizing Source Code using a Neural Attention Model",
          "authors": [
            "Srini Iyer",
            "Ioannis Konstas",
            "Alvin Cheung",
            "Luke Zettlemoyer"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 734
        },
        {
          "external_id": "CorpusId:11816014",
          "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
          "authors": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
          ],
          "year": 2016,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 8827
        },
        {
          "external_id": "CorpusId:6360322",
          "title": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task",
          "authors": [
            "Danqi Chen",
            "Jason Bolton",
            "Christopher D. Manning"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 578
        },
        {
          "external_id": "CorpusId:133195",
          "title": "Abstractive Sentence Summarization with Attentive Recurrent Neural Networks",
          "authors": [
            "S. Chopra",
            "Michael Auli",
            "Alexander M. Rush"
          ],
          "year": 2016,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 915
        },
        {
          "external_id": "CorpusId:12241221",
          "title": "Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus",
          "authors": [
            "Iulian Serban",
            "Alberto García-Durán",
            "Çaglar Gülçehre",
            "Sungjin Ahn",
            "A. Chandar",
            "Aaron C. Courville",
            "Yoshua Bengio"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 297
        },
        {
          "external_id": "CorpusId:16227864",
          "title": "Generating Natural Questions About an Image",
          "authors": [
            "N. Mostafazadeh",
            "Ishan Misra",
            "Jacob Devlin",
            "Margaret Mitchell",
            "Xiaodong He",
            "Lucy Vanderwende"
          ],
          "year": 2016,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 313
        },
        {
          "external_id": "CorpusId:1918428",
          "title": "A Neural Attention Model for Abstractive Sentence Summarization",
          "authors": [
            "Alexander M. Rush",
            "S. Chopra",
            "J. Weston"
          ],
          "year": 2015,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 2788
        }
      ],
      "references_fetched_at": "2025-12-16T22:48:22.585729"
    }
  },
  "bbccfac3-3da5-44b5-af1f-3a65af0482ba": {
    "id": "bbccfac3-3da5-44b5-af1f-3a65af0482ba",
    "filename": "2025.bea-1.69.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/bbccfac3-3da5-44b5-af1f-3a65af0482ba_2025.bea-1.69.pdf",
    "status": "completed",
    "created_at": "2025-12-16 22:43:19.655981",
    "updated_at": "2025-12-16 14:44:46.269740",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "STAIR-AIG: Optimizing the Automated Item Generation Process through Human-AI Collaboration for Critical Thinking Assessment",
    "markdown_content": "# STAIR-AIG: Optimizing the Automated Item Generation Process through Human-AI Collaboration for Critical Thinking Assessment\n\nEuigyum Kim<sup>1</sup>, Seewoo Li<sup>2</sup>, Salah Khalil<sup>3</sup>, and Hyo Jeong Shin<sup>1*</sup>\n\n$^{1}$ Sogang University, Seoul, South Korea\n\n$^{2}$ University of California, Los Angeles, USA\n\n$^{3}$ MACAT International Ltd., United Kingdom\n\n# Abstract\n\nThe advent of artificial intelligence (AI) has marked a transformative era in educational measurement and evaluation, particularly in the development of assessment items. Large language models (LLMs) have emerged as promising tools for scalable automatic item generation (AIG), yet concerns remain about the validity of AI-generated items in various domains. To address this issue, we propose STAIR-AIG (Systematic Tool for Assessment Item Review in Automatic Item Generation), a human-in-the-loop framework that integrates expert judgment to optimize the quality of AIG items. To explore the functionality of the tool, AIG items were generated in the domain of critical thinking. Subsequently, the human expert and four OpenAI LLMs conducted a review of the AIG items. The results show that while the LLMs demonstrated high consistency in their rating of the AIG items, they exhibited a tendency towards leniency. In contrast, the human expert provided more variable and strict evaluations, identifying issues such as the irrelevance of the construct and cultural insensitivity. These findings highlight the viability of STAIR-AIG as a structured human-AI collaboration approach that facilitates rigorous item review, thus optimizing the quality of AIG items. Furthermore, STAIR-AIG enables iterative review processes and accumulates human feedback, facilitating the refinement of models and prompts. This, in turn, would establish a more reliable and comprehensive pipeline to improve AIG practices.\n\n# 1 Introduction\n\nRecent advances in natural language processing (NLP) and generative artificial intelligence (AI), particularly large language models (LLMs), have transformed educational measurement from relatively labor-intensive processes to more automated, scalable, and efficient approaches (Srini\n\nvasan, 2022; Wang et al., 2024). Prominent examples include automated scoring (Latif and Zhai, 2024; Lee et al., 2024; Luchini et al., 2025) and automated feedback generation (Hahn et al., 2021; Chan et al., 2025), which substantially improve efficiency by reducing human labor while ensuring relatively valid and consistent outcomes.\n\nAmong these innovations, automatic item generation (AIG) has emerged as a particularly pertinent application of LLM for the rapid and effective development of assessment items (Gierl and Lai, 2013; Kurdi et al., 2020). Traditional AIG approaches generated new items by replacing different numbers or words in predefined models or templates, aiming to assess the same underlying construct. With the advent of LLMs, AIG has now entered a new phase, enabling educational researchers and practitioners to generate numerous items with minimal programming expertise. However, regardless of the AIG model used, the quality, appropriateness, and validity of AI-generated items still remain questionable. Consequently, the incorporation of quality assurance processes and human participation is deemed inevitable to ensure that AIG systems are generating content as intended (von Davier and Burstein, 2024).\n\nIn particular, it is important to ensure that the assessment items are aligned with target measurement constructs, as poorly defined constructs and superficially designed items can undermine the validity and reliability of the assessment (Liu et al., 2016). Consequently, a robust human-AI collaboration (HAIC) (Fragiadakis et al., 2025) is essential not only to leverage the scalability and efficiency of the AIG process, but also to ensure overall quality and safeguard the validity of AI-generated assessment items (Hao et al., 2024). Nevertheless, prior literature reveals a lack of empirical studies validating the appropriateness of AI-generated items for assessing cognitive skills within human-AI collaborative contexts.\n\nTo address this gap, the present study introduces STAIR-AIG (Systematic Tool for Assessment Item Review in Automatic Item Generation), an item review tool that supports systematic and efficient human review of AI-generated assessment items. We illustrate its potential as both a practical tool and a conceptual AIG framework by applying it to the domain of critical thinking (CT), a higher-order cognitive skill widely recognized as an essential 21st-century core competency (World Economic Forum, 2015). In complex cognitive domains, such as CT, the expert review by the human is particularly important in that defining the measurement structures and developing the assessment items are quite challenging (Shin et al., 2025).\n\nBy leveraging NLP techniques, our tool provides a comprehensive linguistic feature analysis of items. This empowers human reviewers to integrate their domain knowledge in a more effective way. Furthermore, the evaluations of AIG items by human experts are stored as data, so they continuously contribute to the improvement and refinement of the internal LLMs within the AIG pipeline. In contrast to conventional methods, which generally rely exclusively on human review as a final gatekeeping measure in a linear fashion, STAIR-AIG incorporates multiple structured touch-points for expert judgment at each stage. This facilitates continuous evaluation, targeted refinement of AI-generated elements, and ongoing enhancement of LLMs for AIG through structured human feedback and prompt optimization in a dynamic manner.\n\nIn the following, we illustrate the use of the STAIR-AIG tool as a human-in-the-loop AIG process. We review the relevant literature on AIG and the traditional item review process. Then, we present a case study that demonstrates the use of the STAIR-AIG tool in the CT domain. Subsequently, we compare the evaluations performed by a human expert with those generated by the LLM to identify discrepancies and examine the implications of their collaboration for enhancing the AIG process.\n\n# 2 Related Works\n\n# 2.1 Automatic Item Generation\n\nWith the growing interest in AIG to build reliable computer-based assessments by stably and efficiently feeding items into the item bank, the number of publications on AIG has recently increased (Kurdi et al., 2020). Before the advent of LLMs, the techniques of AIG studies were based on syntax\n\nor templates that harness computational power to reduce human labor, such as employing grammar correction programs and developing templates to build software programs (Bejar, 1996, 2002; Singley and Bennett, 2002). In contrast, the recent rise of LLMs in the AI research field has enabled AIG researchers to generate items without extensive software engineering, while empowering item developers to effectively realize their nuanced intentions within the generation process (Attali et al., 2022; Bezirhan and von Davier, 2023).\n\nIn line with current research trends in AIG based on LLMs, this study utilizes CT items developed through a structured AIG procedure (Shin et al., 2025). This approach leverages prompt engineering techniques using LLM and is structured into three distinct modules—passage, question, and choices statements—to support systematic generation and monitoring. Within each module, detailed prompts are provided to the LLM to generate components of items intended to assess CT skills. The modules are executed sequentially to form a complete item, which is then finalized through expert review and revision. Psychometric analyses of the pilot-study data confirmed that the generated items were functioning as intended (Shin et al., 2025).\n\n# 2.2 Assessment Item Review Procedure\n\nTraditionally, the development and validation of assessment items have relied heavily on expert-driven review procedures to ensure validity, cognitive alignment, and fairness (Haladyna and Rodriguez, 2013). Guidelines from organizations such as the National Council on Measurement in Education (NCME) and the International Test Commission (ITC) emphasize the need for refinements guided by expert judgment to avoid common errors in the writing of items and to secure the validity of the construct (Haladyna and Rodriguez, 2013; Commission and of Test Publishers, 2022). However, this systematic review process, while essential, is highly time-consuming, especially in large-scale assessment contexts.\n\nTo overcome these challenges and efficiently support assessments at scale, hybrid frameworks integrating automation with human supervision are increasingly adopted. An innovative example is the Item Factory developed for the Duolingo English Test (DET), an item review system that incorporates human-in-the-loop processes, particularly for the development of high-stakes international DET items (von Davier et al., 2024). The Item Factory\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/79b7513fec02512fa0ea73e76e044bff48542c491add722f10b6a3600ca3b7cb.jpg)  \nFigure 1: Pipeline of STAIR-AIG workflow\n\nfacilitates asynchronous collaboration between subject matter experts, supports reviewer calibration, and provides a structured audit trail of editorial decisions (von Davier et al., 2024). This approach not only maintains rigorous educational standards and test fairness, but also exemplifies how scalable and automated processes complemented by human oversight can enhance the quality and efficiency of assessment item review.\n\nItem review tools, including Item Factory, are likely to be designed according to the types of items that are closely related to measurement constructs. To our knowledge, no open-source tool yet facilitates AIG item review for higher-order thinking skills. In the following, we present the STAIR-AIG tool and workflow as a human-in-the-loop procedure to review and optimize AIG items for CT.\n\n# 3 Development of STAIR-AIG\n\n# 3.1 STAIR-AIG Workflow\n\nSTAIR-AIG is developed as an iterative HAIC framework that goes beyond the static and unidirectional AIG process by continuously incorporating human reviewers' feedback to refine LLM behavior. By providing supplementary NLP features to human reviewers, human experts are expected to integrate their domain knowledge more effectively. In addition, it envisions the advancement of an AIG pipeline by automatically converting human reviews into training data for LLMs. These evaluations and human expert insights are then used to iteratively improve both AIG models through reinforcement learning from human feedback (RLHF) (Christiano et al., 2017; Ziegler et al., 2020) and optimize their associated prompts (Lin et al., 2024),\n\nultimately reducing the human effort required to develop and review items that target complex cognitive constructs such as CT.\n\nFigure 1 represents a comprehensive pipeline of the STAIR-AIG workflow. As seen in the figure, the STAIR-AIG workflow is organized as a multistage iterative loop. Preliminary items generated through prompt engineering by LLMs undergo initial evaluation and review via automated analytics, where LLMs function as auxiliary reviewers. Human reviewers then assess each item based on qualitative criteria, including content validity, appropriateness, and cognitive alignment using the STAIR-AIG tool. Importantly, reviewers provide both three-point scale ratings and open-ended feedback, and in many cases, they can directly edit the content of items. These structured data, comments, scores, and editorial changes are saved as review metadata and would be utilized to refine and enhance the performance of the AIG models.\n\nWhat distinguishes STAIR-AIG is its integration of these human-generated review signals into both upstream and downstream optimization processes. On the one hand, reviewer feedback is used for prompt optimization (Lin et al., 2024), improving future item generation by refining how prompts are constructed. On the other hand, the accumulated data from reviews and edits serves as training data for RLHF (Christiano et al., 2017), fine-tuning the LLM to produce items that better align with expert judgment and the intended assessment objectives. As shown in Figure 2, this feedback loop system, inspired by the HAIC framework presented in Huang (2019), exemplifies a HAIC-based workflow designed to optimize the quality of AIG items.\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/252be5f1d8975d9e71707a6ee01076378a0709a1722536ad70a50b9a7b87b6fc.jpg)  \nFigure 2: HAIC workflow in AIG\n\n# 3.2 STAIR-AIG Modules\n\nThe STAIR-AIG system comprises two central modules designed to systematically evaluate and continuously improve the AIG process.\n\n# 3.2.1 Item Analysis Module\n\nThe item analysis module operates as the preliminary review stage. Items undergo automated analysis based on quantitative linguistic metrics. The metrics include traditional NLP features, including type-token ratio, sentence length, and readability indices such as Flesch-Kincaid grade level, ensuring that the items are written clearly for the target age groups (Collins-Thompson, 2014). These metrics are selected to capture linguistic features that influence item clarity, cognitive load, and appropriateness, and to support early-stage quality screening for human review.\n\n- Type-Token Ratio (TTR): A common measure of lexical diversity, defined as\n\n$$\n\\mathrm {T T R} = \\frac {| V |}{| W |} \\tag {1}\n$$\n\nwhere  $|V|$  is the number of unique types and  $|W|$  is the total number of tokens.\n\n- Average Sentence Length (ASL): A measure of syntactic complexity, defined as\n\n$$\n\\mathrm {A S L} = \\frac {N _ {w}}{N _ {s}} \\tag {2}\n$$\n\nwhere  $N_{w}$  is the total words count and  $N_{s}$  is the total number of sentences.\n\n- Average Syllables per Word (ASW): A measure of word complexity, defined as\n\n$$\n\\mathrm {A S W} = \\frac {N _ {\\text {s y l l}}}{N _ {w}} \\tag {3}\n$$\n\nwhere  $N_{s y l l}$  is the total number of syllables and  $N_{w}$  is the total number of words.\n\n- Flesch-Kincaid Grade Level: A readability index that estimates the school grade level required to understand a given text (Kincaid et al., 1975), calculated as\n\n$$\n\\mathrm {F K G L} = 0. 3 9 \\cdot \\mathrm {A S L} + 1 1. 8 \\cdot \\mathrm {A S W} - 1 5. 5 9 \\tag {4}\n$$\n\nWe compute linguistic features by applying an XLM-RoBERTa tokenizer as a text preprocessing step (Conneau et al., 2020). Leveraging these linguistic features, the module automatically evaluates text difficulty, grade-level appropriateness, and lexical diversity metrics, which significantly reduce the workload placed upon human reviewers, thereby enhancing review efficiency and providing human reviewer with detailed item specification information to facilitate effective and timely review.\n\n# 3.2.2 Item Review Module\n\nCentral to the STAIR-AIG system is the item review module, a structured interface that enables human experts to systematically evaluate AI-generated items. Items approved by the initial automated analysis are presented through this module interface. This module segments each item into specific components, such as passages, questions, and answer choices, allowing reviewers to provide detailed evaluations of each component.\n\nExpert reviewers evaluate each component using a three-point quality scale that serves as the basis for determining whether an item would be accepted, revised, or discarded. Reviewer feedback serves a dual purpose. Qualitative comments contribute to improving the item generation prompts, while direct revision suggestions help finalize the item for operational use and also support future model refinement. Through this human-in-the-loop iterative process, STAIR-AIG continuously improves the quality and validity of the items. Once finalized, high-quality items generated by AI and modified by human experts are stored in an item bank for operational deployment. Item review module as an interface of STAIR-AIG is shown in Figure 3.\n\n# 4 Empirical Research\n\nIn this empirical study, only the first round review was performed within the STAIR-AIG workflow. This initial implementation served to examine the utility of the tool and to investigate the discrepancies of review results between the human reviewer and LLM judges at the early stage of the proposed STAIR-AIG workflow.\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/e277486f97873bf9becfe60d865ee622eb8005128720a6be72ef809af020946b.jpg)  \nFigure 3: STAIR-AIG interface\n\n# 4.1 Data\n\nThe items that were reviewed through STAIR-AIG in this study were developed by a MACAT, specializing in CT frameworks and evaluation solutions. They are based on a framework that measures and assesses CT competencies across six subdomains—Problem solving, Analysis, Creative thinking, Interpretation, Evaluation, and Reasoning (PACIER) (MACAT, 2025; Shin et al., 2025).\n\nIn this round, a total of 24 AI-generated items were reviewed, comprising multiple choice (MC) and fill-in-the-blank (FIB) types. Specifically, the assessment included 18 MC items (3 per PACIER domain) and 6 FIB items (1 per PACIER domain). Although actual CT assessment typically employs 4 choices for MC items and 3 choices for FIB items, the initial AIG items were deliberately prompted to generate 10 and 6 choices respectively, to promote a rigorous quality review without being forced to choose from all the bad choices. As for an example, an operating sample item for MACAT's CT assessment is illustrated in Figure 4.\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/a64643a2b34924ba1f8c4d54efa0ff88bfb55032675c733b9c7ddb7f2261aa40.jpg)  \nFigure 4: Sample item of CT assessment.\n\n# 4.2 Item Review by Human Expert\n\nThe key review process for the 24 AIG items was conducted by a human expert who specialized in\n\nCT domain. The human expert reviewed each item systematically following the instructions and steps using the STAIR-AIG tool, indicating the quality of the items and their components on three-point rating scales.\n\n- Dissatisfied: Fundamentally flawed or inappropriate item for CT assessment, and thus should be discarded. (Score: 1)  \n- Neutral: Requires revisions to improve clarity and relevance or modification of difficulty level. (Score: 2)  \nSatisfied: Suitable for immediate use or requires minimal edits. (Score: 3)\n\nSpecifically, the expert provided ratings and comments on each of the item components, including passages, questions, choices, and overall quality of the items, referencing the analytic information provided by the item analysis module. Revision suggestions were also written directly by the expert in the open text field when necessary. Items that were rated as neutral or satisfied received detailed revision suggestions to support iterative refinement. After the review, all data including evaluations, revisions, and edits were provisionally stored as a CSV file for future model fine-tuning.\n\n# 4.3 Item Quality Review by LLMs\n\nIn parallel to the human review, four OpenAI LLMs (GPT-4o, GPT-4.5-preview, o1-mini, and o3-mini) performed independent quality assessments using the LLM-as-a-judge methodology (Zheng et al., 2023). Although prior work has shown that LLM-as-a-judge is closely aligned with human preferences on a variety of tasks (Zheng et al., 2023; Gu et al., 2025), there is a lack of prior research exploring its applicability in the context of complex cognitive skills, specifically in the evaluation of the quality of the AIG items. Therefore, we explored the possibility of using LLM-as-a-judge as an additional reviewer.\n\nEach model evaluated the AIG items based on the same criteria and the same interface used by human reviewers. The prompts were carefully aligned and mirrored with the human evaluation guidelines to ensure methodological consistency. To maintain independence between human and LLM evaluations, we adopted zero-shot learning as an incontext learning approach in which models relied solely on their pre-trained knowledge without being\n\nprovided with any task-specific examples (Brown et al., 2020). This prevents potential contamination between evaluation sources while utilizing LLM's generalized reasoning capabilities, distinct from human influence. The evaluations by LLMs were then compared with human review. Detailed prompts are provided in the Appendix A.\n\n# 5 Results\n\n# 5.1 Quantitative Results\n\n# 5.1.1 Comparison of Human Reviews with LLM-generated Reviews\n\nAnalysis of 18 MC and 6 FIB items reveals differences in rating patterns between the human expert and LLM judges. The descriptive statistics for both item types are reported in Table 1, indicating that a human expert tends to assign lower scores overall and exhibits greater variability across all items.\n\nIn contrast, LLM judges consistently delivered higher scores across all evaluated dimensions with lower standard deviations. The o3-mini model, in particular, demonstrated extreme uniformity, assigning perfect or near-perfect scores with minimal variance. Specifically, even among LLMs, there is a subtle stratification that GPT-4.5-preview and GPT-4o exhibited slightly more variation and lower means than o3-mini. Also, in MC evaluations, the scores of the o1-mini model were closer to those of the human expert, especially in question quality.\n\nConcretely, as illustrated in Figure 5 and Figure 6, LLMs tend to be consistently generous in their evaluations, while the human expert demonstrated a more critical and sensitive attitude marked by greater variability. A particularly notable pattern emerges in the 'Question Rating' category for FIB items, that the human expert consistently assigned the highest score to the 6 items. This uniformity is not coincidental. Since all FIB items had an identical question format, a consistent rating is justifiable and is an expected result, whereas some LLMs failed to reflect this.\n\n# 5.1.2 Distribution of Ratings across Evaluators\n\nTable 2 further illuminates the contrasting behaviors of human expert and LLM judges in evaluating the quality of AIG items. A notable pattern is the relatively frequent use of the lowest rating Dissatisfied (score of 1) by the human expert. Rather than indicating inconsistency, this tendency may reflect the human expert's awareness of the qualitative\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/66b72eb071fca59b38c1636ee3710c8e2354342e07cb4e7e4ad4c3f5afc3626e.jpg)  \nFigure 5: Rating patterns by evaluators for MC items\n\n![](/uploads/images/bbccfac3-3da5-44b5-af1f-3a65af0482ba/ecace7e3d5b5f3375a81a1a58ad0dc8aa081e795f138047691e89e96fa0c61b3.jpg)  \nFigure 6: Rating patterns by evaluators for FIB item\n\naspects of the content of the item. This indicates that contextual appropriateness, coherence, and educational validity are often more readily detected through human expert, whereas automated systems may overlook such nuanced deficiencies.\n\nIn comparison, LLMs rarely gave the lowest rating of Dissatisfied. For example, o3-mini gave  $100\\%$  Satisfied (score of 3) ratings in nearly every category. In the human rater effect study, this can be interpreted as a leniency or generosity (Wolfe, 2004). Even more conservative models such as o1-mini and GPT-4o showed minimal to zero use of the lowest category across MC and FIB items.\n\nFurthermore, the human evaluator showed a more frequent use of the Neutral category (score of 2), which accounts for most of the responses. This middle-ground positioning can be interpreted as a nuanced case-by-case approach by the human evaluator, in contrast to the strong tendency of LLMs to assign the highest rating across most items.\n\n# 5.2 Qualitative Feedback from Human Expert\n\nTo closely examine the reviews provided by the human expert, we performed a qualitative analysis of the reviewer's written comments. Table 3 lists four themes that categorize and summarize the feedback. The human expert specialized in the as\n\nTable 1: Descriptive statistics for MC and FIB item reviews by evaluators  \n\n<table><tr><td rowspan=\"2\">Item Type</td><td rowspan=\"2\">Evaluator</td><td colspan=\"4\">Overall Quality Score</td><td colspan=\"4\">Passage Rating</td><td colspan=\"4\">Question Rating</td><td colspan=\"4\">Item Choices Rating</td></tr><tr><td>Mean</td><td>Std</td><td>Min</td><td>Max</td><td>Mean</td><td>Std</td><td>Min</td><td>Max</td><td>Mean</td><td>Std</td><td>Min</td><td>Max</td><td>Mean</td><td>Std</td><td>Min</td><td>Max</td></tr><tr><td rowspan=\"5\">MC</td><td>Human</td><td>2.22</td><td>0.65</td><td>1</td><td>3</td><td>2.39</td><td>0.70</td><td>1</td><td>3</td><td>2.11</td><td>0.58</td><td>1</td><td>3</td><td>2.70</td><td>0.29</td><td>2</td><td>3</td></tr><tr><td>GPT-4.5-preview</td><td>2.61</td><td>0.50</td><td>2</td><td>3</td><td>2.78</td><td>0.43</td><td>2</td><td>3</td><td>2.61</td><td>0.50</td><td>2</td><td>3</td><td>2.80</td><td>0.30</td><td>2</td><td>3</td></tr><tr><td>GPT-4o</td><td>2.56</td><td>0.51</td><td>2</td><td>3</td><td>2.67</td><td>0.49</td><td>2</td><td>3</td><td>2.61</td><td>0.50</td><td>2</td><td>3</td><td>2.60</td><td>0.54</td><td>1</td><td>3</td></tr><tr><td>o1-mini</td><td>2.28</td><td>0.46</td><td>2</td><td>3</td><td>2.78</td><td>0.43</td><td>2</td><td>3</td><td>2.11</td><td>0.58</td><td>1</td><td>3</td><td>2.81</td><td>0.35</td><td>2</td><td>3</td></tr><tr><td>o3-mini</td><td>2.82</td><td>0.39</td><td>2</td><td>3</td><td>2.94</td><td>0.24</td><td>2</td><td>3</td><td>2.89</td><td>0.32</td><td>2</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td></tr><tr><td rowspan=\"5\">FIB</td><td>Human</td><td>2.17</td><td>0.41</td><td>2</td><td>3</td><td>1.67</td><td>1.03</td><td>1</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>2.19</td><td>0.41</td><td>1</td><td>3</td></tr><tr><td>GPT-4.5-preview</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>2.86</td><td>0.22</td><td>2</td><td>3</td></tr><tr><td>GPT-4o</td><td>2.67</td><td>0.52</td><td>2</td><td>3</td><td>2.83</td><td>0.41</td><td>2</td><td>3</td><td>2.83</td><td>0.41</td><td>2</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td></tr><tr><td>o1-mini</td><td>2.17</td><td>0.41</td><td>2</td><td>3</td><td>2.83</td><td>0.41</td><td>2</td><td>3</td><td>2.17</td><td>0.41</td><td>2</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td></tr><tr><td>o3-mini</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>3.00</td><td>0.00</td><td>3</td><td>3</td><td>2.97</td><td>0.07</td><td>2</td><td>3</td></tr></table>\n\nTable 2: Rating frequency and proportion for MC and FIB item reviews by evaluators  \n\n<table><tr><td rowspan=\"2\">Item Type</td><td rowspan=\"2\">Evaluator</td><td colspan=\"3\">Overall Quality</td><td colspan=\"3\">Passage</td><td colspan=\"3\">Question</td><td colspan=\"3\">Item Choice</td></tr><tr><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td><td>Dissatisfied</td><td>Neutral</td><td>Satisfied</td></tr><tr><td rowspan=\"5\">MC</td><td>Human</td><td>2 (11%)</td><td>10 (56%)</td><td>6 (33%)</td><td>2 (11%)</td><td>7 (39%)</td><td>9 (50%)</td><td>2 (11%)</td><td>12 (67%)</td><td>4 (22%)</td><td>4 (2%)</td><td>46 (26%)</td><td>130 (72%)</td></tr><tr><td>GPT-4.5</td><td>0 (0%)</td><td>7 (39%)</td><td>11 (61%)</td><td>0 (0%)</td><td>4 (22%)</td><td>14 (78%)</td><td>0 (0%)</td><td>7 (39%)</td><td>11 (61%)</td><td>3 (2%)</td><td>30 (17%)</td><td>147 (82%)</td></tr><tr><td>GPT-4o</td><td>0 (0%)</td><td>8 (44%)</td><td>10 (56%)</td><td>0 (0%)</td><td>6 (33%)</td><td>12 (67%)</td><td>0 (0%)</td><td>7 (39%)</td><td>11 (61%)</td><td>28 (16%)</td><td>9 (5%)</td><td>143 (79%)</td></tr><tr><td>o1-mini</td><td>0 (0%)</td><td>13 (72%)</td><td>5 (28%)</td><td>0 (0%)</td><td>4 (22%)</td><td>14 (78%)</td><td>2 (11%)</td><td>12 (67%)</td><td>4 (22%)</td><td>15 (8%)</td><td>15 (8%)</td><td>150 (83%)</td></tr><tr><td>o3-mini</td><td>0 (0%)</td><td>3 (17%)</td><td>15 (83%)</td><td>0 (0%)</td><td>1 (6%)</td><td>17 (94%)</td><td>0 (0%)</td><td>2 (11%)</td><td>16 (89%)</td><td>0 (0%)</td><td>0 (0%)</td><td>180 (100%)</td></tr><tr><td rowspan=\"5\">FIB</td><td>Human</td><td>0 (0%)</td><td>5 (83%)</td><td>1 (17%)</td><td>4 (67%)</td><td>0 (0%)</td><td>2 (33%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>10 (28%)</td><td>9 (25%)</td><td>17 (47%)</td></tr><tr><td>GPT-4.5</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>5 (14%)</td><td>31 (86%)</td></tr><tr><td>GPT-4o</td><td>0 (0%)</td><td>2 (33%)</td><td>4 (67%)</td><td>0 (0%)</td><td>1 (17%)</td><td>5 (83%)</td><td>0 (0%)</td><td>1 (17%)</td><td>5 (83%)</td><td>0 (0%)</td><td>0 (0%)</td><td>36 (100%)</td></tr><tr><td>o1-mini</td><td>0 (0%)</td><td>5 (83%)</td><td>1 (17%)</td><td>0 (0%)</td><td>1 (17%)</td><td>5 (83%)</td><td>0 (0%)</td><td>5 (83%)</td><td>1 (17%)</td><td>0 (0%)</td><td>0 (0%)</td><td>36 (100%)</td></tr><tr><td>o3-mini</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>0 (0%)</td><td>6 (100%)</td><td>0 (0%)</td><td>1 (3%)</td><td>35 (97%)</td></tr></table>\n\nsessment of CT skills provided detailed comments, such as concerns about vague terminology, overly obvious item structure, conceptual inconsistencies, and cultural bias, which were often overlooked by LLM judges. These qualitative insights are stored as data and will play an instrumental role in shaping the future STAIR-AIG protocol, particularly in optimizing the prompts used for AIG and in systematizing the rubrics for the LLM-based review.\n\nIt is also worth noting that the human expert raised the issue of the content validity of some AIG items. Specifically, some items were on the borderline of assessing CT or reading comprehension. In such cases, the human expert not only provided a detailed explanation of their reasoning but also directly revised the wording of the items to better align with the intended purpose of the assessment. Such feedback can also be saved as data and used to fine-tune the LLMs, ultimately supporting the development of more valid and reliable AIG-powered assessment content.\n\n# 6 Conclusions & Implications\n\n# 6.1 Conclusions\n\nThis study introduces STAIR-AIG, a structured, human-in-the-loop framework designed to improve the quality and validity of AI-generated assessment items. Using the STAIR-AIG tool, we collected and compared item reviews from a human expert\n\nand four OpenAI LLMs. Our quantitative and qualitative analyses revealed that, while LLM's evaluations demonstrated high consistency, their feedback was generally superficial and overly lenient. Often, LLMs neglected critical issues such as ambiguous terminology, cultural insensitivity, and insufficient cognitive depth. In contrast, the human expert provided more critical and nuanced feedback, effectively identifying subtle yet significant flaws.\n\nThe two core modules of STAIR-AIG significantly support human reviewers in conducting rigorous, systematic evaluations aligned with the test-taker's background and the assessment goals, enhancing review efficiency. Notably, the discrepancies observed between human reviewers and LLM judges underscore the importance of a human-in-the-loop framework and an iterative review process. Ultimately, the data collected through these structured reviews is expected to improve the quality of AIG items and facilitate the development of more robust and refined assessment items.\n\n# 6.2 Implications\n\nAs an example of a human-in-the-loop approach to AIG, this study sets the groundwork for extending STAIR-AIG into a comprehensive, full-cycle framework encompassing AIG, collaborative human-AI review, iterative refinement, pilot testing, psychometric validation, and model retrain\n\n<table><tr><td>Feedback Category</td><td>Review Comments</td></tr><tr><td>Terminology &amp; Language Use</td><td>- &quot;Do not use so many different words for the same meaning.&quot;</td></tr><tr><td rowspan=\"3\">Vague, overly technical, and struc-turally complex, which makes it mis-aligned with the assessment&#x27;s purpose.</td><td>- &quot;(...) is a difficult formulation for not-so-strong readers.&quot;</td></tr><tr><td>- &quot;(...) is unnecessarily vague scientific jargon.&quot;</td></tr><tr><td>- &quot;The term (...) might be too technical for many students and may lead to incorrect interpretations.&quot;</td></tr><tr><td>Item Construction &amp; Clue Issues</td><td>- &quot;When mentioning acronym, use full name, and in all further mentions, use acronym.&quot;</td></tr><tr><td rowspan=\"4\">Wording or structure that makes an-swers too obvious or misleads test-takers.</td><td>- &quot;Change order to avoid misinterpretation.&quot;</td></tr><tr><td>- &quot;Answer appears verbatim in the passage.&quot;</td></tr><tr><td>- &quot;Too simple and easy to see the answer.&quot;</td></tr><tr><td>- &quot;Why use the term (...) whereas in all statements you use the term (...)? Be consistent.&quot;</td></tr><tr><td>Conceptual Accuracy &amp; Fit</td><td>- &quot;I have read some publications about (...) but the definition that is used here does not really fit very well.&quot;</td></tr><tr><td rowspan=\"2\">Inaccurate or inconsistent statements, which make it unsuitable for valid as-sessment.</td><td>- &quot;Biased or misleading conclusion.&quot;</td></tr><tr><td>- &quot;(...) and (...) depends on interpretation.&quot;</td></tr><tr><td>Cultural Sensitivity</td><td>- &quot;The concept of the (...) varies by culture and perspective.&quot;</td></tr><tr><td rowspan=\"3\">Culturally biased, which offers a lim-ited perspective and potentially dis-advantageing test-takers from diverse backgrounds.</td><td>- &quot;(...) might be ideal in some contexts, while (...) may carry a clearer negative connotation.&quot;</td></tr><tr><td>- &quot;(...) portrayed in a one-sided positive light.&quot;</td></tr><tr><td>- &quot;(...) is culturally or ethically biased.&quot;</td></tr></table>\n\nTable 3: Categorization of reviewer feedback and representative comments\n\ning. The human-generated reviews collected in this study would serve as a valuable resource for the first round of LLM refinement. Drawing on this empirical data, future work would focus on optimizing LLM prompting strategies and applying RLHF to improve both the quality and validity of AI-generated items. This process will help establish a more data-driven and feedback-informed basis for optimizing AIG systems.\n\nIn addition, this research contributes to the emerging field of HAIC-based test design and administration, where prior work remains limited. By demonstrating the utility of structured human reviews in guiding both AIG prompting and model fine-tuning, the study highlights a scalable pathway for the application of AI to educational measurement. Similar to how the Item Factory is used for DET, the proposed STAIR-AIG tool is being implemented for MACAT's CT assessment. The number of CT assessment items has rapidly doubled with the STAIR-AIG process, and the tool is being fully implemented to create an item bank of human-authored items alongside AIG for the CT assessment (Shin et al., 2024). This HAIC-driven approach showcases the increasing potential for the scholarly and sustainable use of AI in education.\n\n# 6.3 Limitations\n\nDespite its promise, this study has several limitations. First, the study was confined to an initial review by a human expert and four OpenAI LLMs,\n\nfollowed by a comparative analysis of their ratings. The end-to-end STAIR-AIG workflow process, particularly the integration and refinement of the AIG model through iterative review, has yet to be realized. Future work will involve more comprehensive testing of the entire STAIR-AIG pipeline.\n\nSecond, although the STAIR-AIG framework is designed to support multiple rounds of review, the current study only included one round of review by one expert reviewer. Consequently, the results may not reflect the full potential of iterative refinement, thereby limiting the framework's generalizability. Future research should explore the point at which discrepancies between LLMs and expert ratings converge. This will help us understand how LLMs behave when judging higher-order thinking skills, as well as inform the optimal stage for finalizing items for operational use and determining the maximum number of review cycles.\n\nThird, while the item-review module was helpful to human reviewers, it could only analyze superficial metrics, such as TTR, ASL, and conventional readability indices. In the present study, grade-level suitability was judged solely based on these readability measures. Moving forward, the review module will integrate additional linguistic indicators that capture semantic dimensions in order to provide reviewers with more comprehensive support. Similarly, we did not directly measure whether the module substantially reduced the time reviewers\n\nneeded to complete their tasks. Therefore, future research would evaluate the practical effectiveness of STAIR-AIG by determining the degree to which it aids item review and the amount of time it saves compared to standard, tool-free review procedures.\n\nLastly, LLMs were given instructions that closely mirrored those provided to the human reviewer, yet their evaluations consistently exhibited leniency. To achieve a more harmonious integration of human and LLM ratings, future work should consider various prompt engineering techniques to calibrate LLM judgments more closely with the human evaluation standard in the CT domain. Furthermore, optimizing prompts accompanied by the psychometric results of the test data is expected to improve AIG models' ability to accurately generate and evaluate item difficulty and distractor plausibility. This would, in turn, strengthen the efficiency and validity of human-AI collaboration in test development.\n\n# Acknowledgments\n\nThis research was conducted in collaboration with the MACAT International Ltd., who provided support. We also sincerely appreciate the insightful comments and thoughtful suggestions on potential future directions for this research from the anonymous reviewers.\n\n# References\n\nYigal Attali, Andrew Runge, Geoffrey T. LaFlair, Kevin Yancey, Sarah Goodwin, Yena Park, and Alina A. von Davier. 2022. The interactive reading task: Transformer-based automatic item generation. Frontiers in Artificial Intelligence, 5.  \nIsaac I. Bejar. 1996. Generative response modeling: Leveraging the computer as a test delivery medium. ETS Research Report RR-96-13, Educational Testing Service, Princeton, NJ.  \nIsaac I. Bejar. 2002. Generative testing: From conception to implementation. In Sidney H. Irvine and Patrick C. Kyllonen, editors, Item Generation for Test Development, pages 199-218. Lawrence Erlbaum Associates, Mahwah, NJ.  \nUmmugul Bezirhan and Matthias von Davier. 2023. Automated reading passage generation with openai's large language model. Computers and Education: Artificial Intelligence, 5:100161.  \nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,\n\nGretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. Preprint, arXiv:2005.14165.  \nSumie Chan, Noble Lo, and Alan Wong. 2025. Leveraging generative ai for enhancing university-level english writing: comparative insights on automated feedback and student engagement. *Cogent Education*, 12(1):2440182.  \nPaul F. Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. Deep reinforcement learning from human preferences. In Advances in Neural Information Processing Systems, pages 4299-4307.  \nKevyn Collins-Thompson. 2014. Computational assessment of text readability: A survey of current and future research. ITL - International Journal of Applied Linguistics, 165(2):97-135.  \nInternational Test Commission and Association of Test Publishers. 2022. Guidelines for technology-based assessment. https://www.intestcom.org/page/28 and https://www.testpublishers.org/white-papers.ISBN 979-8-88862-517-0.  \nAlexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettle-moyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440-8451, Online. Association for Computational Linguistics.  \nGeorge Fragiadakis, Christos Diou, George Kousiouris, and Mara Nikolaidou. 2025. Evaluating human-ai collaboration: A review and methodological framework. Preprint, arXiv:2407.19098.  \nMark J Gierl and Hollis Lai. 2013. Instructional topics in educational measurement (ITEMS) module: Using automated processes to generate test items. Educational Measurement: Issues and Practice, 32(3):36-50.  \nJiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, Saizhuo Wang, Kun Zhang, Yuanzhuo Wang, Wen Gao, Lionel Ni, and Jian Guo. 2025. A survey on llm-as-a-judge. Preprint, arXiv:2411.15594.  \nMarcelo Guerra Hahn, Silvia Margarita Baldiris Navarro, Luis De La Fuente Valentín, and Daniel Burgos. 2021. A systematic review of the effects of automatic scoring and automatic feedback in educational settings. IEEE Access, 9:108190-108198.\n\nThomas M. Haladyna and Michael C. Rodriguez. 2013. Developing and Validating Test Items. Routledge, London, UK.  \nJiangang Hao, Alina A. von Davier, Victoria Yaneva, Susan Lottridge, Matthias von Davier, and Deborah J. Harris. 2024. Transforming assessment: The impacts and implications of large language models and generative ai. Educational Measurement: Issues and Practice. All authors contributed equally.  \nJanet Huang. 2019. Human-ai co-learning for data-driven ai. https://speakerdeck.com/janetyc/human-ai-co-learning-for-data-driven-ai. Accessed: 2025-05-03.  \nJ. Peter Kincaid, Richard P. Fishburne, Robert L. Rogers, and Brad S. Chissom. 1975. Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. Research Branch Report 8-75, Naval Technical Training, U.S. Naval Air Station, Millington, TN. Archive from the original on December 10, 2020.  \nGhader Kurdi, Jared Leo, Biban Parsia, Uli Sattler, and Salam Al-Emari. 2020. A systematic review of automatic question generation for educational purposes. International Journal of Artificial Intelligence in Education, 30:121-204.  \nEhsan Latif and Xiaoming Zhai. 2024. Fine-tuning chatgpt for automatic scoring. Computers and Education: Artificial Intelligence, 6:100210.  \nGyeong-Geon Lee, Ehsan Latif, Xuansheng Wu, Ning-hao Liu, and Xiaoming Zhai. 2024. Applying large language models and chain-of-thought for automatic scoring. Computers and Education: Artificial Intelligence, 6:100213.  \nXiaoqiang Lin, Zhongxiang Dai, Arun Verma, SeeKiong Ng, Patrick Jaillet, and Bryan Kian Hsiang Low. 2024. Prompt optimization with human feedback. Preprint, arXiv:2405.17346.  \nOu Lydia Liu, Liyang Mao, Lois Frankel, and Jun Xu. 2016. Assessing critical thinking in higher education: The heightenTM approach and preliminary validity evidence. Assessment and Evaluation in Higher Education, 41(5):677-694.  \nS. A. Luchini, N. T. Maliakkal, P. V. DiStefano, A. Laverghetta Jr., J. D. Patterson, R. E. Beaty, and R. Reiter-Palmon. 2025. Automated scoring of creative problem solving with large language models: A comparison of originality and quality ratings. *Psychology of Aesthetics*, Creativity, and the Arts. Advance online publication.  \nMACAT. 2025. Critical thinking assessments. https://www.macat.com/critical-thinking. Retrieved April 16, 2025.\n\nHyo Jeong. Shin, Seewoo. Li, Salah. Khalil, and Alina A. von Davier. 2024. Designing for adaptive testing using automatically generated items. In Proceedings of the Annual Meeting of the International Association for Computerized Adaptive Testing (IACAT), Seoul, Korea.  \nHyo Jeong. Shin, Seewoo. Li, Jihoon. Ryoo, Alina A. von Davier, T. Lubart, and Salah. Khalil. 2025. The nature and measure of critical thinking: The pacier framework and assessment. Manuscript submitted for publication.  \nMark K. Singley and Randy E. Bennett. 2002. Item generation and beyond: Applications of schema theory to mathematics assessment. In Sidney H. Irvine and Patrick C. Kyllonen, editors, Item Generation for Test Development, pages 361-384. Lawrence Erlbaum Associates, Inc., Mahwah, NJ.  \nVenkat Srinivasan. 2022. AI & learning: A preferred future. Computers and Education: Artificial Intelligence, 3:100062.  \nAlina A. von Davier and Jill Burstein. 2024. Ai in the assessment ecosystem: A human-centered ai perspective. In Peter Ilic, Ian Casebourne, and Rupert Wegerif, editors, Artificial Intelligence in Education: The Intersection of Technology and Pedagogy, volume 261 of Intelligent Systems Reference Library. Springer, Cham.  \nAlina A. von Davier, Andrew Runge, Yena Park, Yigal Attali, Jacqueline Church, and Geoff LaFlair. 2024. The item factory: Intelligent automation in support of test development at scale. In Machine Learning, Natural Language Processing, and Psychometrics, pages 1-25. Information Age Publishing, Charlotte, NC.  \nShan Wang, Fang Wang, Zhen Zhu, Jingxuan Wang, Tam Tran, and Zhao Du. 2024. Artificial intelligence in education: A systematic literature review. Expert Systems with Applications, 252(Part A):124167.  \nEdward W Wolfe. 2004. Identifying rater effects using latent trait models. Psychology Science, 46:35-51.  \nWorld Economic Forum. 2015. New vision for education: Unlocking the potential of technology. https://wiqdtents.weforum.org/nve-2015/ chapter1.html. Accessed April 14, 2025.  \nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena. Preprint, arXiv:2306.05685.  \nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2020. Fine-tuning language models from human preferences. Preprint, arXiv:1909.08593.\n\n# A Appendix\n\n# A.1 Prompt for Item Review by LLMs\n\nThe following is an excerpt of the prompt used to instruct the LLMs in reviewing the quality of CT items. The prompt defines the evaluation criteria, output structure, and PACIER framework to assess item quality.\n\n# Listing 1: System prompt\n\n```txt\nYou are a Critical Thinking Assessment's **Item Review Expert** with extensive experience in educational evaluation and test design, specializing in critical thinking.\n```\n\n```txt\nYour role is to systematically evaluate the quality of test items based on established frameworks, ensuring fairness, reliability, and alignment with learning objectives.\n```\n\n# Listing 2: User prompt: Review Context\n\n## Review Context\n\n- The exam items are designed for Grade 7~8 learners.  \n- Each item consists of a Passage, a Question, and 6 Answer Choices (each with an Explanation).  \n- Your task is to rigorously evaluate the quality of each component and provide structured feedback.\n\nPACIER Framework (Cognitive Process Dimensions)\n\nThe PACIER framework categorizes cognitive processes into six distinct levels:\n\n- \\*\\*Problem-Solving (P)  $^{**}$  ...  \n- **Creative Thinking (C):** (...)  \n- \\*\\*Interpretation (I):\\*\\* (...  \n- \\*\\*Evaluation (E):\\*\\* (. . .)  \n- \\*\\*Reasoning (R):\\*\\* (. . .\n\nEach test item should align with at least one PACIER category, ensuring it assesses critical thinking skills effectively.\n\n# Listing 3: User prompt: Review Methods\n\nEvaluation Methodology\n\n1. Assessment Criteria\n\n- Passage: Relevance, clarity, and cognitive demand.  \n- Question: Alignment with passage, clarity, and ability to assess critical thinking.  \n- Answer Choices: Plausibility of distractors, clarity, and correctness of explanations.\n\n2. Comparative Judgment\n\n- Evaluate each component relative to high-quality reference items to ensure consistency.\n\n3. Rating Scale\n\n- Dissatisfied: Fundamentally flawed or inappropriate for assessment and thus discarded without revision suggestions.  \n- Neutral: Requires revisions to improve clarity, relevance, or difficulty. You should provide detailed feedback and specific revision recommendations.  \n- Satisfied: Suitable for immediate use or required minimal edits. You could directly accept these items or suggest minor enhancements.\n\n4. Actionable Feedback\n\n- Provide concise but specific feedback justifying each rating.\n\n5. Final Output Format (Plain Key-Value Pairs, CSV-Ready)\n\nOutput only concise final results in plain key-value pairs (one per line) using the following CSV column structure:\n\nItem Number, Type, Topic, Subtopic, PACIER, Difficulty,\n\nOverall Quality Score, Overall Comment,\n\nPassage Comment, Passage Rating, Passage Revision,\n\nQuestion Comment, Question Rating, Question Revision,\n\n```txt\nItem_1_Choice_1 Review, Item_1_Choice_1 Rating, Item_1_Choice_1 Revision Suggestion, ... (repeat for Choices 2 through 10)\n```\n\nAdditional Guidelines\n\n- Ensure alignment with cognitive and linguistic proficiency standards.  \n- **Maintain consistency** across evaluations to avoid bias.  \n- Do not include markdown, bullet points, or additional explanations.  \n- Return only key-value pairs as output.",
    "arxiv_id": "2005.14165",
    "error_message": null,
    "embedding": [
      1,
      3.78125,
      0.34375,
      -1.734375,
      -1.421875,
      3.375,
      1.921875,
      -0.0361328125,
      1.78125,
      0.62109375,
      -1.125,
      2.296875,
      1.59375,
      1.0703125,
      -2.546875,
      1.2734375,
      1.9140625,
      0.2197265625,
      1.84375,
      -6.84375,
      0.37109375,
      0.296875,
      -1.3046875,
      -6.03125,
      6.09375,
      -3.046875,
      3.375,
      3.578125,
      2.40625,
      0.06005859375,
      6.0625,
      -6.0625,
      -0.2451171875,
      2.546875,
      -3.03125,
      2.078125,
      -2.75,
      0.259765625,
      2.65625,
      1.5,
      -5.03125,
      2.296875,
      2.71875,
      2.015625,
      -2.703125,
      1.5,
      2.828125,
      -0.6328125,
      -5.9375,
      -1.109375,
      -3.453125,
      -5.34375,
      5.15625,
      -0.1689453125,
      2.671875,
      -5.03125,
      -7.125,
      4.625,
      -0.99609375,
      -2.453125,
      2.09375,
      -1.5859375,
      5.03125,
      0.33984375,
      2.96875,
      3.921875,
      1.640625,
      -0.9375,
      -3.4375,
      -1.328125,
      -0.78125,
      3.03125,
      7.75,
      -4.1875,
      6.8125,
      6.6875,
      2.1875,
      1.4296875,
      -0.7109375,
      4.28125,
      -5.71875,
      2.46875,
      2.46875,
      -0.76171875,
      6.375,
      3.15625,
      0.453125,
      -1.8671875,
      -1.765625,
      3.5625,
      -2.75,
      3.171875,
      -5.09375,
      -1.0859375,
      3.328125,
      7.09375,
      -1.8125,
      -3.796875,
      -7.90625,
      1.6171875,
      -1.1171875,
      -0.169921875,
      -0.2470703125,
      -5.125,
      -2.359375,
      -4.5,
      -5.34375,
      -7.875,
      -1.4453125,
      -1.875,
      0.078125,
      2.765625,
      2.765625,
      -0.8515625,
      3.375,
      -2.640625,
      6.90625,
      -4.59375,
      -2.8125,
      -1.265625,
      2.75,
      -0.72265625,
      -2.21875,
      -0.0302734375,
      5.65625,
      1.796875,
      -6.25,
      1.171875,
      6.15625,
      0.64453125,
      4,
      2.546875,
      5.34375,
      0.85546875,
      -7.1875,
      -2.3125,
      -5.21875,
      2.765625,
      3.28125,
      4.78125,
      -4.75,
      -1.296875,
      -1.703125,
      -5.65625,
      3.09375,
      1.140625,
      -6.71875,
      0.2890625,
      1.1953125,
      -1.75,
      1.59375,
      0.9609375,
      0.76953125,
      7.1875,
      -1.8359375,
      -4.375,
      5.65625,
      2.15625,
      0.515625,
      0.5390625,
      0.921875,
      1.3046875,
      -0.2177734375,
      -1.015625,
      -2.625,
      -1.0078125,
      -5.40625,
      1.4609375,
      0.63671875,
      -2.625,
      2.46875,
      15.25,
      2.828125,
      -2.921875,
      3.09375,
      2.96875,
      -3.328125,
      9.125,
      2.40625,
      1.5390625,
      -0.341796875,
      1.8671875,
      -1.984375,
      4.65625,
      -0.291015625,
      -1.1328125,
      1.9453125,
      -4.46875,
      0.53125,
      -3.984375,
      1.5703125,
      2.703125,
      7.5625,
      1.1875,
      -6.15625,
      3.46875,
      2.515625,
      -0.72265625,
      -0.63671875,
      2.921875,
      0.99609375,
      -8.5625,
      1.484375,
      -0.46484375,
      -3.34375,
      -1.8828125,
      4.25,
      -1.3828125,
      -0.134765625,
      -1.796875,
      2.265625,
      2.859375,
      0.94921875,
      2.96875,
      5.40625,
      3.671875,
      2.578125,
      -1.25,
      3.640625,
      2.953125,
      5.59375,
      1.8515625,
      1.03125,
      0.66015625,
      -0.1875,
      1.1015625,
      3.578125,
      5.0625,
      0.1416015625,
      6.78125,
      -1.875,
      2.546875,
      5.0625,
      -0.6484375,
      -1.6015625,
      -1.28125,
      -5.4375,
      2.84375,
      0.439453125,
      0.796875,
      -2.421875,
      -3.8125,
      -1.8671875,
      0.515625,
      2.078125,
      -3.03125,
      0.8828125,
      -3.09375,
      -3.375,
      -4.8125,
      2.328125,
      2.375,
      -5.4375,
      -3.078125,
      4.125,
      4.1875,
      -0.99609375,
      -3.359375,
      -0.79296875,
      -2.390625,
      5.4375,
      -1.5,
      -5.90625,
      1.1015625,
      1.4765625,
      -5.65625,
      1.5,
      -1.546875,
      3.828125,
      0.6640625,
      1.296875,
      0.328125,
      -1.5,
      0.01397705078125,
      -0.67578125,
      5.15625,
      2.265625,
      -6.1875,
      -0.84765625,
      -3.75,
      -3.125,
      -7.96875,
      5.8125,
      -3.953125,
      5.03125,
      -1.4765625,
      -0.322265625,
      5.96875,
      -5.28125,
      9.4375,
      4.4375,
      2.546875,
      -0.88671875,
      0.171875,
      -6.875,
      -1.5390625,
      -1.9375,
      -0.55078125,
      -6.84375,
      0.66796875,
      6.375,
      -1.515625,
      -1.390625,
      -0.2890625,
      -3.140625,
      3.265625,
      0.60546875,
      -2.375,
      2.171875,
      1.921875,
      -3.15625,
      -1.7421875,
      7.5,
      -1.59375,
      1.6875,
      -2.984375,
      -2.84375,
      3.53125,
      1.3203125,
      -3.953125,
      -4.5,
      -3.015625,
      2.859375,
      -3.84375,
      -0.88671875,
      -2.34375,
      -0.138671875,
      0.75,
      5.125,
      -0.12255859375,
      1.5859375,
      0.4296875,
      -5.4375,
      -6.875,
      7.28125,
      -2.65625,
      2.828125,
      -0.1640625,
      -1.96875,
      4.40625,
      -0.400390625,
      -3.703125,
      0.97265625,
      -4.25,
      -2.359375,
      0.6640625,
      4.9375,
      -4.5625,
      -1.5234375,
      -6.3125,
      2.65625,
      1.7421875,
      -1.078125,
      2.171875,
      5.5625,
      -1.515625,
      0.16015625,
      -0.1865234375,
      2.9375,
      0.73828125,
      3.40625,
      -1.9453125,
      6.53125,
      0.40234375,
      -0.5625,
      -4.8125,
      0.1484375,
      1.171875,
      0.359375,
      0.373046875,
      -0.82421875,
      -4.78125,
      -0.88671875,
      1.84375,
      1.7890625,
      -0.65234375,
      1.5,
      -3.84375,
      -3.6875,
      1.3125,
      -3.953125,
      0.09912109375,
      -2.65625,
      -1.265625,
      3.265625,
      2.203125,
      0.171875,
      4.96875,
      0.34765625,
      -2.671875,
      -2.234375,
      -0.78125,
      -3.5,
      1.46875,
      0.37890625,
      1.515625,
      -0.265625,
      1.734375,
      -0.027587890625,
      -1.7890625,
      3.859375,
      1.3515625,
      -0.1708984375,
      0.2578125,
      -4.25,
      1.6484375,
      -1.546875,
      -4.75,
      3.015625,
      -0.453125,
      -1.9609375,
      1.7109375,
      -0.6875,
      -2.359375,
      0.75,
      2.6875,
      -0.98828125,
      1.3984375,
      -6.21875,
      -2.015625,
      -3.6875,
      0.287109375,
      1.8828125,
      -3,
      -0.5078125,
      -0.77734375,
      2,
      5.3125,
      0.37890625,
      1.875,
      1.9375,
      1.4296875,
      -4.78125,
      2.1875,
      -4.75,
      -5.03125,
      3.40625,
      -3.375,
      -3.890625,
      0.77734375,
      2.5,
      1.1953125,
      2.421875,
      2.640625,
      -5.125,
      -0.56640625,
      1.546875,
      4.46875,
      -3.875,
      -1.9453125,
      1.734375,
      1.859375,
      -0.7265625,
      1.8984375,
      1.375,
      1.1640625,
      -3.328125,
      5.1875,
      1.4921875,
      -2.15625,
      1.0078125,
      -0.8984375,
      1.625,
      -1.4765625,
      -0.61328125,
      -0.486328125,
      -3.296875,
      1.765625,
      3.640625,
      -8.125,
      -11.1875,
      2.59375,
      0.51171875,
      1.765625,
      -1.4375,
      2.484375,
      2.15625,
      -0.2138671875,
      -6.78125,
      -6.1875,
      -1.8828125,
      -1.2578125,
      2.4375,
      1.625,
      -0.353515625,
      -1.6171875,
      -3.984375,
      4.34375,
      1.40625,
      4.0625,
      0.3671875,
      -1.8203125,
      1.359375,
      -5.40625,
      3.640625,
      2.21875,
      9,
      -5.96875,
      0.59375,
      1.8984375,
      -8.3125,
      -1.7578125,
      -4.71875,
      -2.71875,
      -1.15625,
      0.609375,
      3.78125,
      -2.359375,
      -3.03125,
      -0.12890625,
      2.390625,
      -1.84375,
      -2.46875,
      3.78125,
      -4.46875,
      -3.53125,
      3.34375,
      0.07421875,
      0.4453125,
      -0.58984375,
      -4.6875,
      2.25,
      -2.1875,
      3.203125,
      -0.9140625,
      -1.5625,
      -1.9296875,
      -2.453125,
      3.984375,
      2.890625,
      3.21875,
      1.6015625,
      -2.703125,
      -4.625,
      -3.09375,
      -0.890625,
      1.6328125,
      -2.109375,
      2.15625,
      -2.90625,
      4.8125,
      5.28125,
      -1.7734375,
      -1.203125,
      -0.859375,
      3.640625,
      -4.28125,
      0.03515625,
      0.271484375,
      3.5625,
      2.578125,
      1.6015625,
      -1.09375,
      -1.1484375,
      -0.62109375,
      -2.296875,
      -3.671875,
      -0.390625,
      3,
      -0.1572265625,
      -0.006591796875,
      0.197265625,
      -0.1513671875,
      0.01904296875,
      1.0546875,
      -1.9453125,
      0.490234375,
      3.578125,
      1.6640625,
      -1.875,
      0.59765625,
      4.84375,
      -2.109375,
      1.1328125,
      1.9921875,
      1.8046875,
      -7.25,
      -6.15625,
      -0.87890625,
      1.7421875,
      6.34375,
      -3.40625,
      4.96875,
      -1.234375,
      3.109375,
      -0.80078125,
      0.373046875,
      -14.9375,
      1.8203125,
      -1.0078125,
      -3.53125,
      -0.78515625,
      -1.7890625,
      3.59375,
      -1.265625,
      1.8203125,
      -0.8828125,
      -1.078125,
      1.1953125,
      4.875,
      -0.8828125,
      -1.1171875,
      6.25,
      2.890625,
      -1.390625,
      3.328125,
      -0.83984375,
      -3.078125,
      -0.8359375,
      -2.71875,
      0.53125,
      2.21875,
      6.1875,
      -0.03515625,
      -0.6796875,
      0.98828125,
      -2.484375,
      -4.0625,
      0.88671875,
      4.59375,
      -0.478515625,
      3.4375,
      -2.40625,
      3.015625,
      -5.09375,
      2.015625,
      0.9765625,
      -1.8671875,
      2.609375,
      1.6796875,
      -1.640625,
      0.004730224609375,
      -2.609375,
      -1.703125,
      3.0625,
      2.984375,
      -6.75,
      0.70703125,
      -2.203125,
      0.0155029296875,
      1.53125,
      -1.734375,
      0.8203125,
      -3.34375,
      1.796875,
      1.953125,
      -5.25,
      7.625,
      -1.0625,
      -3.828125,
      -0.267578125,
      0.6328125,
      0.06396484375,
      -2.234375,
      3.421875,
      3.765625,
      -2.546875,
      -0.92578125,
      0.23046875,
      -0.625,
      -4.59375,
      1.0859375,
      -1.8203125,
      -3.21875,
      5.5,
      -1.6171875,
      -2.4375,
      -1.125,
      -3.46875,
      1.890625,
      2.890625,
      1.34375,
      1.734375,
      2.203125,
      2.5625,
      -1.125,
      5.3125,
      -4.46875,
      -5.375,
      -0.859375,
      -3.59375,
      -3.109375,
      -0.0272216796875,
      -1.6953125,
      1.4375,
      -0.212890625,
      -1.1484375,
      -3.375,
      -7.53125,
      -1.109375,
      1.0546875,
      1.484375,
      1.765625,
      -1.8515625,
      2.5,
      -2.75,
      -2.78125,
      -2.515625,
      0.162109375,
      0.953125,
      -0.0238037109375,
      -0.28515625,
      -7.0625,
      -1.1015625,
      5.625,
      5,
      -5.21875,
      3.3125,
      1.0078125,
      -2.375,
      -1.71875,
      1.3984375,
      -3.65625,
      -1.3671875,
      1.8984375,
      -2.328125,
      -2.421875,
      -4.15625,
      2.265625,
      -4.21875,
      5.59375,
      0.1435546875,
      -1.53125,
      -1.7890625,
      -6.09375,
      -3.125,
      0.1943359375,
      -3.953125,
      4.15625,
      0.68359375,
      -3.328125,
      -1.125,
      4.46875,
      -0.458984375,
      0.63671875,
      -0.08251953125,
      -0.765625,
      4,
      -0.40625,
      3.71875,
      -2.890625,
      -3.359375,
      -0.6171875,
      0.921875,
      -0.031005859375,
      2.515625,
      -1.2890625,
      1,
      5.25,
      0.2265625,
      -5.15625,
      -1.2265625,
      2.828125,
      -1.59375,
      0.0191650390625,
      -1.3359375,
      1.8203125,
      -0.1484375,
      1.4921875,
      1.2734375,
      -3.15625,
      -0.734375,
      1.53125,
      3.1875,
      -0.35546875,
      -0.86328125,
      1.25,
      -0.039306640625,
      5.125,
      -5.03125,
      -6.8125,
      2.4375,
      3.625,
      -1.921875,
      0.259765625,
      4.125,
      -1.2890625,
      -0.65625,
      -1.046875,
      1.3515625,
      1.265625,
      2.515625,
      1.671875,
      1.609375,
      4.40625,
      2.984375,
      -0.81640625,
      0.384765625,
      -0.13671875,
      -3.4375,
      -0.8203125,
      -0.671875,
      -1.3359375,
      5.0625,
      -1.34375,
      -3.25,
      -2.109375,
      1.0234375,
      1.1953125,
      5.5,
      7.5,
      0.1337890625,
      3.03125,
      1.609375,
      4.0625,
      -0.2275390625,
      7.8125,
      4.65625,
      11.4375,
      -0.69921875,
      -2.921875,
      4.125,
      -2.15625,
      0.326171875,
      2.125,
      -9.375,
      -1.671875,
      -0.515625,
      1.203125,
      -3.421875,
      1.53125,
      -6.09375,
      -0.2265625,
      4.84375,
      -0.1611328125,
      3.109375,
      3.84375,
      5.1875,
      2.609375,
      -1.890625,
      -3.421875,
      -3.796875,
      -1.5625,
      -0.0732421875,
      0.078125,
      -3.40625,
      1.8984375,
      0.11328125,
      2.125,
      0.25390625,
      -3.015625,
      -2.78125,
      7.96875,
      -0.453125,
      -0.46875,
      1.65625,
      1.078125,
      1.4765625,
      3.984375,
      0.78515625,
      -5,
      0.037841796875,
      6.78125,
      4.65625,
      -0.39453125,
      2,
      -0.55859375,
      -0.1591796875,
      -0.396484375,
      -3.8125,
      1.8671875,
      -0.3515625,
      -4.3125,
      -0.84765625,
      1.5078125,
      -0.58203125,
      -3.40625,
      4.59375,
      1.484375,
      -3.28125,
      2.109375,
      2.671875,
      0.875,
      2.25,
      2.21875,
      7.03125,
      0.58203125,
      -0.94140625,
      -3.609375,
      -3.234375,
      -2.671875,
      -1.875,
      1.796875,
      4.3125,
      2.359375,
      -2.109375,
      2.390625,
      -6.53125,
      -0.65625,
      -3.53125,
      2.453125,
      0.98046875,
      -3.28125,
      0.87890625,
      -1.5703125,
      -9.875,
      -7.1875,
      -1.921875,
      -2.84375,
      -0.5078125,
      -6.53125,
      -0.640625,
      2.640625,
      -5.8125,
      1.3046875,
      -1.25,
      -2.25,
      3.640625,
      -1.5078125,
      2.09375,
      -3.5625,
      2,
      1.6015625,
      0.294921875,
      3.875,
      3.3125,
      1.1796875,
      3.921875,
      -1.1953125,
      1.328125,
      -4.46875,
      4.90625,
      -0.5859375,
      6,
      2.703125,
      -0.2578125,
      -4.0625,
      4.34375,
      -2.359375,
      2.15625,
      -3.21875,
      -1.1640625,
      -1.3515625,
      -1.953125,
      1.1640625,
      0.44140625,
      3.328125,
      -4.4375,
      -1.8203125,
      0.74609375,
      -4.75,
      -0.1435546875,
      4.28125,
      -0.01092529296875,
      4.375,
      -2.3125,
      -0.84375,
      2.625,
      -2.71875,
      7.03125,
      0.061767578125,
      1.3984375,
      -5.625,
      0.5703125,
      -0.84375,
      2.1875,
      0.67578125,
      -0.96484375,
      0.93359375,
      -1.0703125,
      2.28125,
      5.3125,
      -0.0201416015625,
      2.734375,
      1.6953125,
      2.515625,
      -0.9921875,
      -0.400390625,
      0.8203125,
      -3.359375,
      4.875,
      1.203125,
      0.353515625,
      1.03125,
      0.921875,
      -3.921875,
      -0.71484375,
      3.234375,
      -4.40625,
      -3.421875,
      -2.296875,
      -4.28125,
      2.875,
      0.1357421875,
      -0.71484375,
      4.03125,
      3.4375,
      2.5,
      2.46875,
      -0.6484375,
      4.15625,
      -0.79296875,
      0.7734375,
      7.3125,
      -1.5703125,
      0.0247802734375,
      5.03125,
      1.53125,
      5.4375,
      1.7734375,
      -1.3671875,
      -2.421875,
      0.859375,
      3.578125,
      -1.9609375,
      3.375,
      8,
      -2.984375,
      2.765625,
      -0.13671875,
      -1.078125,
      -0.2412109375,
      -0.578125,
      1.4140625,
      5.0625,
      5.4375,
      -1.203125,
      -3.53125,
      -2.46875,
      1.0625,
      0.326171875,
      -0.7578125,
      -1.640625,
      0.64453125,
      -0.25,
      1.0703125,
      -0.33984375,
      -2.390625,
      2.15625,
      -3.84375,
      -0.8203125,
      3.28125,
      0.046142578125,
      0.30078125,
      -0.57421875,
      0.765625,
      -2.3125,
      2.984375,
      2.328125,
      -0.88671875,
      0.86328125,
      2.46875,
      -1.1015625,
      3.703125,
      1.53125,
      -0.51953125,
      1.9765625,
      -2.078125,
      -2.65625,
      2.28125,
      -1.0390625,
      0.00335693359375,
      -1.703125,
      -0.3515625,
      4.15625,
      4.4375,
      -1.3125,
      4.28125,
      -2.375,
      -2.03125,
      2.109375,
      -3.640625,
      -4.4375,
      0.08740234375,
      -0.5390625,
      -1.8046875,
      0.103515625,
      1.3203125,
      -2.4375,
      3.375,
      -5.75,
      3.9375,
      -4.40625,
      6.3125,
      0.45703125,
      -2.359375,
      -0.5859375,
      -2.609375,
      2.296875,
      -1.015625,
      1.5859375,
      1.9609375,
      0.1064453125,
      1.734375,
      -1.9375,
      0.224609375,
      -1.90625,
      -0.08740234375,
      4.0625,
      -3.734375,
      3.0625,
      2.046875,
      2.625,
      -4.4375,
      -3.203125,
      0.375,
      -1.5,
      0.65234375,
      1.6171875,
      0.244140625,
      -0.98046875,
      3.328125,
      -4.1875,
      3.109375,
      -2.25,
      -0.90625,
      1.4609375,
      -1.859375,
      5.15625,
      0.271484375,
      -2.140625,
      1.46875,
      -0.51953125,
      -5.75,
      -1.703125,
      -1.7265625,
      3.953125,
      -2.9375,
      -1.84375,
      1.7109375,
      1.7421875,
      -2.15625,
      1.9765625,
      3.28125,
      1.9375,
      1.8046875,
      -1.546875,
      1.234375,
      0.73828125,
      1.921875,
      -4.28125,
      -6,
      -2.734375,
      2.109375,
      0.5390625,
      -1.6953125,
      0.341796875,
      -1.09375,
      0.71484375,
      0.85546875,
      -0.90625,
      -0.2216796875,
      -0.95703125,
      3.09375,
      -0.51171875,
      -3.59375,
      1.828125,
      1.71875,
      1.9609375,
      -2.90625,
      0.0947265625,
      -2.453125,
      0.265625,
      0.9921875,
      1.59375,
      -0.2138671875,
      -3.578125,
      0.37890625,
      -0.09814453125,
      -3.78125,
      -2.203125,
      4.21875,
      1.34375,
      5.15625,
      3.625,
      -0.421875,
      -1.2734375,
      -1.1953125,
      0.154296875,
      2.625,
      1.3828125,
      -4.28125,
      2.734375,
      -1.0859375,
      6,
      -1.828125,
      -3.453125,
      -5.4375,
      1.3203125,
      5.5625,
      0.365234375,
      -2.5,
      1.3125,
      0.2294921875,
      3.0625,
      -0.349609375,
      3,
      -2.4375,
      -3.171875,
      -0.71484375,
      3.109375,
      2.03125,
      -5.78125,
      1.8515625,
      3.328125,
      -1.6640625,
      2.03125,
      3.21875,
      5.53125,
      -3.34375,
      -0.5234375,
      -0.341796875,
      -4.90625,
      -2.296875,
      2.09375,
      1.1640625,
      1.015625,
      -0.10546875,
      -3.78125,
      -0.263671875,
      -2.140625,
      0.1484375,
      6.9375,
      -2.421875,
      3.046875,
      -3.421875,
      3.71875,
      2.546875,
      -2.140625,
      -1.84375,
      2.78125,
      1.9296875,
      -0.41015625,
      0.06689453125,
      -3.390625,
      2.609375,
      -0.404296875,
      -7.4375,
      1.6875,
      1.5625,
      -0.28125,
      -0.208984375,
      -1.6328125,
      -0.294921875,
      1.0078125,
      -3.53125,
      -0.34375,
      -2.859375,
      3.171875,
      3.65625,
      0.111328125,
      -1.796875,
      3.390625,
      -1.6875,
      -0.11962890625,
      -0.58203125,
      3.28125,
      -1.8671875,
      2.921875,
      0.7734375,
      3.46875,
      -4.65625,
      -3.46875,
      -3.265625,
      -1.765625,
      -2.609375,
      1.796875,
      0.302734375,
      -0.83203125,
      3.984375,
      1.125,
      -2.625,
      0.06982421875,
      -2.4375,
      1.9765625,
      -0.86328125,
      1.6640625,
      -3.53125,
      3.859375,
      -4.25,
      1.234375,
      2.171875,
      -1.984375,
      -3.15625,
      1.6171875,
      -2.359375,
      2.8125,
      3.796875,
      -0.7109375,
      -4.5,
      2.28125,
      -3.421875,
      -6.125,
      -5.75,
      3.40625,
      -1.7109375,
      -3.421875,
      -0.90625,
      -3.15625,
      1.4921875,
      -1.5625,
      -2.046875,
      -1.2421875,
      -1.3828125,
      0.2353515625,
      2.390625,
      4.09375,
      -2.140625,
      -2.65625,
      -1.65625,
      5.28125,
      1.234375,
      -1.078125,
      3.15625,
      0.62890625,
      0.57421875,
      -4.40625,
      3.84375,
      1.5390625,
      -1.4296875,
      4.40625,
      7.78125,
      -5.15625,
      -0.421875,
      4.84375,
      2.9375,
      -2.171875,
      -0.83203125,
      -2.0625,
      5.21875,
      -2.46875,
      2.6875,
      -2.859375,
      -0.0020751953125,
      1.828125,
      -1.609375,
      5.0625,
      2,
      1.96875,
      -1.078125,
      -2.375,
      3.109375,
      3.421875,
      4.78125,
      -1.2421875,
      4.5625,
      3,
      -1.1953125,
      3.046875,
      -0.150390625,
      -4.3125,
      -2.875,
      2.34375,
      -7.4375,
      0.96875,
      -7.03125,
      -0.83984375,
      -3.40625,
      -3.3125,
      -1.0234375,
      0.64453125,
      2.1875,
      1.5078125,
      -3.03125,
      0.318359375,
      -1.7578125,
      -0.8203125,
      0.8359375,
      -0.6328125,
      -3.40625,
      2.75,
      0.578125,
      -0.1708984375,
      4,
      2,
      -0.365234375,
      -1.15625,
      2.1875,
      -1.140625,
      0.283203125,
      -2.5625,
      2.546875,
      1.1875,
      -0.1796875,
      0.94140625,
      2.484375,
      4.5625,
      -6.625,
      -3.15625,
      -4.90625,
      -1.9375,
      -0.451171875,
      0.68359375,
      -3.953125,
      -0.35546875,
      4.625,
      -2.109375,
      4.21875,
      0.65234375,
      -0.08837890625,
      -7.53125,
      0.5625,
      -0.69921875,
      2.375,
      0.451171875,
      1.390625,
      -3.53125,
      3.890625,
      1.2734375,
      -3.484375,
      1.8359375,
      0.703125,
      -1.6484375,
      -5.25,
      2.109375,
      -0.6640625,
      2.65625,
      2.171875,
      2.65625,
      2.484375,
      0.63671875,
      2.921875,
      8,
      1.265625,
      -1.765625,
      2.28125,
      -1.8515625,
      -5.59375,
      -2.90625,
      2.09375,
      -0.9140625,
      -3.3125,
      1.8125,
      0.7890625,
      2.234375,
      1.0625,
      0.470703125,
      4.1875,
      2.90625,
      -2.5,
      2.578125,
      -4.78125,
      1.21875,
      -6.875,
      -0.95703125,
      -2.6875,
      0.5859375,
      2.046875,
      6.65625,
      -2.03125,
      -2.5,
      4.1875,
      2.796875,
      2.609375,
      -2.671875,
      4,
      2.296875,
      -1.90625,
      -3.078125,
      -4.3125,
      4,
      2.03125,
      0.1376953125,
      -1.4609375,
      1.875,
      1.703125,
      -1.6171875,
      -4.625,
      0.83203125,
      0.65625,
      -5.90625,
      -5.21875,
      -2.25,
      3,
      -4.875,
      -0.65625,
      2.90625,
      -3.21875,
      2.6875,
      -0.298828125,
      -1.40625,
      1.1328125,
      -1.453125,
      1.578125,
      -0.232421875,
      -2.1875,
      1.1171875,
      1.265625,
      -2.0625,
      2.859375,
      -1.1171875,
      1.421875,
      1.5390625,
      -2.09375,
      -3.15625,
      -4.625,
      5,
      2.671875,
      1.3359375,
      4.0625,
      -3.921875,
      4.4375,
      0.34375,
      -0.76171875,
      -2.1875,
      3.703125,
      0.796875,
      0.65234375,
      0.07568359375,
      -0.953125,
      4.15625,
      -0.60546875,
      1.3671875,
      0.3046875,
      0.5703125,
      -2.703125,
      0.1923828125,
      -3.40625,
      0.1708984375,
      -0.061279296875,
      3.046875,
      -1.75,
      -2.140625,
      1.1484375,
      1.1796875,
      0.7578125,
      4.28125,
      -1.53125,
      -1.3125,
      2.84375,
      2.3125,
      0.349609375,
      -2.484375,
      -0.984375,
      -0.70703125,
      -1.3515625,
      -0.51953125,
      0.263671875,
      -2.65625,
      1.7109375,
      -1.203125,
      -2.734375,
      1.546875,
      2.21875,
      -1.7109375,
      -10.75,
      -0.470703125,
      0.27734375,
      -0.921875,
      -1.4921875,
      0.82421875,
      4,
      4.40625,
      2.765625,
      4.71875,
      -0.494140625,
      -4.46875,
      2.984375,
      15.875,
      -1.703125,
      -3.59375,
      2.1875,
      1.1171875,
      0.2353515625,
      5.5625,
      0.1767578125,
      0.470703125,
      -2.625,
      1.765625,
      4.90625,
      -1,
      1.0234375,
      0.36328125,
      -2.015625,
      1.3515625,
      2.515625,
      -3.765625,
      -4.15625,
      -0.234375,
      2.625,
      -2.046875,
      4.90625,
      -0.53515625,
      2.8125,
      1.453125,
      0.2294921875,
      0.515625,
      -2.375,
      -2.609375,
      -1.8359375,
      0.08349609375,
      -4.0625,
      -1.28125,
      -5.15625,
      0.400390625,
      -0.99609375,
      -0.87890625,
      -3.28125,
      -4.375,
      -3.21875,
      1.515625,
      -0.859375,
      2.203125,
      -0.69921875,
      -1.7734375,
      -1.234375,
      1.65625,
      0.33203125,
      -1.4375,
      -0.6953125,
      -1.59375,
      2.109375,
      1.5,
      -1.90625,
      1.6640625,
      -3.296875,
      -2.390625,
      0.30078125,
      -1.3671875,
      0.3203125,
      0.224609375,
      -0.984375,
      -0.98828125,
      -1.1796875,
      -2.625,
      0.458984375,
      0.01324462890625,
      1.0859375,
      -5.78125,
      -2.90625,
      4.28125,
      0.62890625,
      -1.1171875,
      -3.59375,
      1.0078125,
      1.375,
      2.328125,
      2.859375,
      -0.07080078125,
      2.796875,
      -4.34375,
      -0.07568359375,
      -1.140625,
      1.296875,
      -4.78125,
      0.2890625,
      1.2265625,
      1.3515625,
      6.3125,
      -4.4375,
      4.71875,
      2.921875,
      -5.71875,
      -1.0078125,
      1.2578125,
      -0.78515625,
      0.021484375,
      -1.625,
      0.66796875,
      0.2119140625,
      -0.78515625,
      1.875,
      2.3125,
      -0.609375,
      1.578125,
      -5.21875,
      1.796875,
      -0.7578125,
      -2.875,
      3.15625,
      -2.84375,
      -4.15625,
      -1.53125,
      4.46875,
      -2.1875,
      -2.125,
      2.546875,
      -1.3046875,
      2.796875,
      0.50390625,
      -1.921875,
      0.11572265625,
      -9.3125,
      -5.28125,
      -1.359375,
      -5.84375,
      2.4375,
      -3.0625,
      0.421875,
      0.515625,
      -2.09375,
      -2.90625,
      0.302734375,
      -1.9375,
      3.484375,
      5.625,
      3.21875,
      -1.46875,
      -2.390625,
      0.83203125,
      1.5390625,
      -2.0625,
      -1.7890625,
      0.1943359375,
      -2.09375,
      1.6875,
      3.65625,
      3.25,
      -2.5,
      3.578125,
      -0.4921875,
      -4.1875,
      -1.203125,
      3.140625,
      -0.50390625,
      0.37109375,
      -2.34375,
      -3.65625,
      -2.015625,
      0.053466796875,
      -1.8984375,
      -2.296875,
      0.3203125,
      -2.828125,
      3.28125,
      -0.69921875,
      -5.9375,
      4.21875,
      -0.05517578125,
      -5.6875,
      0.1318359375,
      -2.890625,
      5.4375,
      -4.25,
      5.8125,
      5.1875,
      -0.0157470703125,
      -0.421875,
      3.265625,
      3.171875,
      -2.46875,
      -5.21875,
      0.2041015625,
      6.09375,
      -4.4375,
      1.0859375,
      5.25,
      -1.7578125,
      2.875,
      -1.953125,
      -5.625,
      6.09375,
      3.171875,
      -5.5625,
      0.330078125,
      -0.55859375,
      -0.29296875,
      -1.765625,
      -0.70703125,
      2.3125,
      0.6796875,
      4.3125,
      1.1328125,
      -2.484375,
      -5.71875,
      -0.46484375,
      1.1640625,
      -2.5,
      -1.90625,
      1.5859375,
      0.71875,
      2.984375,
      -6.75,
      3.203125,
      1.7578125,
      0.59765625,
      -0.9453125,
      3.21875,
      2.3125,
      -0.173828125,
      -5.84375,
      1.421875,
      2.484375,
      0.337890625,
      -4.09375,
      3.515625,
      -0.875,
      0.314453125,
      -2.703125,
      1.015625,
      -1.21875,
      3.015625,
      -2.09375,
      -2.09375,
      -4.125,
      5.71875,
      -0.06494140625,
      0.7578125,
      3.828125,
      -3.109375,
      0.0908203125,
      1.4453125,
      -1.703125,
      1.1796875,
      -3.40625,
      0.86328125,
      1.1640625,
      1.2109375,
      0.61328125,
      2.46875,
      3.390625,
      -4.3125,
      -1.8984375,
      -5.5,
      -5.65625,
      0.050537109375,
      -1.4140625,
      0.765625,
      -0.90625,
      -8.625,
      2.609375,
      -0.50390625,
      -0.9140625,
      -0.1884765625,
      0.95703125,
      -5.8125,
      3.46875,
      5.9375,
      -4.09375,
      3.9375,
      0.06982421875,
      -2.671875,
      -1.8984375,
      -1.875,
      0.5234375,
      -3.96875,
      0.265625,
      1.90625,
      -3.734375,
      -2.703125,
      2.28125,
      -1.5625,
      2.515625,
      -1.4296875,
      4.09375,
      1.6015625,
      3.734375,
      1.0859375,
      0.85546875,
      5.125,
      -3.1875,
      -0.37890625,
      -1.34375,
      2.28125,
      -2.09375,
      0.0296630859375,
      0.6953125,
      -0.8671875,
      2.75,
      0.408203125,
      0.5625,
      -9.375,
      -3.828125,
      1.5859375,
      -1.7109375,
      4.375,
      1.3515625,
      -0.67578125,
      -0.1962890625,
      2.359375,
      0.298828125,
      -0.515625,
      -1.0546875,
      -1.703125,
      -3.40625,
      0.8125,
      1.3125,
      -7.5,
      -0.482421875,
      -0.6328125,
      0.77734375,
      1.09375,
      -0.244140625,
      -3.546875,
      -0.53515625,
      4.03125,
      -3.8125,
      -0.6953125,
      1.8828125,
      -1.2578125,
      5.40625,
      -0.035400390625,
      -0.1884765625,
      1.8671875,
      -3.328125,
      -7.34375,
      1.5625,
      -0.8984375,
      -3.65625,
      1.09375,
      -1.5390625,
      2.609375,
      -1.0703125,
      3.984375,
      -4.625,
      4.96875,
      1.2109375,
      -9.5625,
      4.25,
      -3,
      1.21875,
      -3.703125,
      -6,
      -3.609375,
      7.28125,
      -2.015625,
      -0.51953125,
      3.296875,
      -0.7265625,
      2.359375,
      2.875,
      -2.484375,
      -4.5625,
      1.6796875,
      4.25,
      -4.78125,
      2.046875,
      3.828125,
      1.3125,
      -1.7890625,
      1.3984375,
      3.765625,
      -1.1015625,
      -0.87890625,
      2.65625,
      3.1875,
      -0.384765625,
      -1.7265625,
      -2.234375,
      1.203125,
      -1.2421875,
      -2.171875,
      0.578125,
      -2.265625,
      1.0078125,
      -1.4921875,
      0.73828125,
      -1.0390625,
      -3.34375,
      -2.1875,
      0.2021484375,
      -1.390625,
      -0.2392578125,
      2.078125,
      -0.291015625,
      -1.6015625,
      0.478515625,
      3.359375,
      2.171875,
      -0.208984375,
      -4.4375,
      0.38671875,
      -0.67578125,
      -3.515625,
      -0.248046875,
      2.828125,
      -2.984375,
      -2.046875,
      0.734375,
      1.4921875,
      0.33203125,
      -2.5625,
      -2.828125,
      0.0439453125,
      2.0625,
      0.2255859375,
      -3.40625,
      -1.8828125,
      -0.2734375,
      5.25,
      -4.21875,
      -3.234375,
      0.06298828125,
      0.58203125,
      -3.171875,
      -1.390625,
      1.3046875,
      -2.09375,
      0.9296875,
      5.0625,
      -0.053955078125,
      0.84375,
      3.328125,
      -3.203125,
      -1.4453125,
      6.5625,
      3.03125,
      -1.609375,
      -0.2177734375,
      -1.484375,
      -4.9375,
      5.09375,
      8.125,
      -0.091796875,
      -0.984375,
      -0.82421875,
      -3.546875,
      -3.703125,
      -3.4375,
      0.6640625,
      -1.5390625,
      -5.875,
      4.03125,
      -1.4140625,
      2.421875,
      0.0091552734375,
      -1.0859375,
      4.625,
      0.119140625,
      0.021728515625,
      -1.7421875,
      0.6796875,
      4.25,
      -3.15625,
      0.30078125,
      -3.71875,
      0.322265625,
      -1.09375,
      1.8515625,
      0.453125,
      -2.140625,
      6.71875,
      -0.0106201171875,
      -1.109375,
      -0.84375,
      1.3671875,
      5.125,
      -1.3359375,
      -4.96875,
      -2,
      0.412109375,
      0.98046875,
      -3.421875,
      2.546875,
      -6.40625,
      -1.75,
      -1.6171875,
      2.640625,
      0.54296875,
      -0.55859375,
      0.015869140625,
      -2.171875,
      -0.91796875,
      2.875,
      2.109375,
      1.390625,
      2.0625,
      1.875,
      0.1962890625,
      -2.125,
      0.703125,
      3.3125,
      1.34375,
      0.5390625,
      -1.03125,
      0.71875,
      0.796875,
      -1.1328125,
      1.78125,
      -0.5234375,
      3.640625,
      1.8828125,
      -2.8125,
      2.078125,
      -3.09375,
      -4,
      -4.15625,
      1.609375,
      2.953125,
      1.421875,
      -1.03125,
      -0.35546875,
      -0.90234375,
      0.44140625,
      -0.099609375,
      -1.875,
      -0.1494140625,
      -2.625,
      1.5078125,
      4.78125,
      -1.1796875,
      -1.6875,
      1.71875,
      1.390625,
      0.1572265625,
      -1.9453125,
      -5,
      1.8046875,
      1.3671875,
      -1.0703125,
      0.921875,
      -2.921875,
      1.90625,
      -0.58984375,
      -3.015625,
      -1.1015625,
      1.1796875,
      -1.40625,
      3.953125,
      -0.80859375,
      -1.765625,
      0.6015625,
      3.875,
      0.322265625,
      2.21875,
      0.400390625,
      1.90625,
      -1.6015625,
      -2.703125,
      -0.7578125,
      0.251953125,
      5.71875,
      -0.6015625,
      1.1171875,
      1.2578125,
      0.86328125,
      -2.09375,
      4.75,
      -3.34375,
      -1.1796875,
      -2.0625,
      1.84375,
      0.291015625,
      -0.2578125,
      1.6484375,
      1.0703125,
      1.5078125,
      -0.94921875,
      -2.421875,
      -5.9375,
      -0.8125,
      -1.9765625,
      -1.140625,
      0.3046875,
      0.416015625,
      -0.7421875,
      1.3671875,
      2.46875,
      1.8671875,
      -0.671875,
      -0.36328125,
      -0.359375,
      -1.0234375,
      2.765625,
      0.2197265625,
      2.328125,
      0.73046875,
      0.8671875,
      1.9296875,
      -0.8671875,
      0.6484375,
      -0.59375,
      0.306640625,
      2.359375,
      -0.384765625,
      -1.453125,
      1.1015625,
      -0.1796875,
      -1.4921875,
      -1.0703125,
      0.322265625,
      1.0546875,
      0.5234375,
      1.9609375,
      0.765625,
      -0.91015625,
      -0.78515625,
      2.640625,
      3.359375,
      -3.71875,
      -2.96875,
      -0.8203125,
      1.5546875,
      -1.5,
      -1.3671875,
      -2.3125,
      1.6484375,
      -1.359375,
      0.32421875,
      3.171875,
      0.388671875,
      -1.546875,
      -2.734375,
      -0.443359375,
      -1.625,
      -2.234375,
      2.140625,
      1.203125,
      1.125,
      -1.625,
      -3.03125,
      1.25,
      1.1484375,
      0.25,
      2.1875,
      2.03125,
      -0.384765625,
      2.953125,
      -2.4375,
      1.5703125,
      -2.8125,
      1.2734375,
      2.671875,
      -0.97265625,
      0.37109375,
      0.94921875,
      -0.265625,
      0.9296875,
      -3.78125,
      -2.4375,
      -1.78125,
      -1.234375,
      1.046875,
      0.421875,
      0.056884765625,
      -2.921875,
      2.796875,
      -2.34375,
      0.1884765625,
      -1.1171875,
      0.1572265625,
      2.109375,
      -0.341796875,
      -1.859375,
      1.21875,
      0.6484375,
      -0.208984375,
      -2.0625,
      -0.5,
      0.703125,
      3.03125,
      1.8046875,
      4.1875,
      1.1796875,
      -1.3515625,
      1.46875,
      -0.48828125,
      -1.6640625,
      0.2138671875,
      -0.267578125,
      -1.875,
      2.125,
      3.578125,
      1.828125,
      0.734375,
      1.671875,
      -0.1962890625,
      0.03271484375,
      0.040771484375,
      2.84375,
      1.0546875,
      -0.66015625,
      -0.8359375,
      -1.21875,
      0.251953125,
      -1.0703125,
      -0.08544921875,
      0.43359375,
      0.298828125,
      0.87890625,
      -0.84765625,
      0.29296875,
      0.265625,
      -1.2109375,
      2.640625,
      0.142578125,
      0.478515625,
      -1.0078125,
      3.265625,
      -1.703125,
      -0.91796875,
      2.015625,
      -0.8828125,
      -0.9453125,
      2.3125,
      -6.5,
      0.0634765625,
      -1.1953125,
      -0.6953125,
      -0.12255859375,
      0.169921875,
      2.65625,
      0.216796875,
      -2.15625,
      1.71875,
      0.318359375,
      2.375,
      -0.4765625,
      2.15625,
      -1.125,
      0.58203125,
      -0.078125,
      -2.125,
      2.515625,
      0.1650390625,
      0.2158203125,
      1.8203125,
      -0.3203125,
      1.21875,
      -1.4453125,
      -3.046875,
      -4.53125,
      -1.2734375,
      0.18359375,
      0.75390625,
      3.765625,
      1.3203125,
      -1.078125,
      2.078125,
      -1.8359375,
      3.390625,
      -0.515625,
      -2.265625,
      -0.64453125,
      0.9296875,
      -1.9375,
      -3.3125,
      -0.359375,
      -0.263671875,
      0.7734375,
      1.546875,
      0.3515625,
      -1.3046875,
      -1.2890625,
      -4.21875,
      2.828125,
      -1.5625,
      0.328125,
      -0.0478515625,
      -0.78515625,
      3.03125,
      -2.1875,
      4.21875,
      1.5625,
      1.3671875,
      0.46484375,
      0.1455078125,
      -0.0218505859375,
      3.296875,
      2.53125,
      0.1982421875,
      -2.703125,
      -1.953125,
      0.26171875,
      1.59375,
      0.2392578125,
      2.34375,
      1.4375,
      4.09375,
      -1.6328125,
      1.5234375,
      1.109375,
      -2.203125,
      -0.1357421875,
      1.6015625,
      0.83984375,
      -2.75,
      -1.6171875,
      -0.306640625,
      1.1796875,
      -1.09375,
      1.90625,
      3.921875,
      0.2216796875,
      1.59375,
      -1.2265625,
      0.984375,
      -1.078125,
      1.3515625,
      -2.046875,
      2.34375,
      0.6953125,
      -1.6015625,
      0.314453125,
      -0.9140625,
      -1.1484375,
      -1.6796875,
      0.88671875,
      -1.0390625,
      2.671875,
      -1.5234375,
      -0.07275390625,
      -0.8984375,
      -0.75,
      0.7578125,
      1.09375,
      0.828125,
      1.078125,
      -0.490234375,
      2.375,
      -0.431640625,
      -0.14453125,
      -1.8203125,
      3.515625,
      -4.9375,
      -3.984375,
      -2.59375,
      -0.73046875,
      0.0220947265625,
      -0.99609375,
      -2.265625,
      2.203125,
      -0.39453125,
      1.65625,
      -1.3203125,
      -0.1142578125,
      4.5625,
      4.96875,
      1.3828125,
      2.640625,
      0.005950927734375,
      1.6796875,
      -0.9296875,
      -1.8359375,
      3.328125,
      -2.328125,
      -1.9765625,
      -1.3828125,
      0.95703125,
      -2.171875,
      -1.75,
      -1.4296875,
      -1.1484375,
      0.01300048828125,
      -1.125,
      -2.1875,
      -1.515625,
      -0.470703125,
      -4.125,
      -0.1298828125,
      -2.703125,
      0.1298828125,
      -0.0654296875,
      1.5703125,
      1.234375,
      -0.3203125,
      1.484375,
      1.2890625,
      1.1015625,
      -0.5859375,
      -1.34375,
      0.494140625,
      -3.671875,
      0.41796875,
      3.015625,
      -1.6328125,
      -3.828125,
      0.35546875,
      4.6875,
      -0.275390625,
      0.498046875,
      -3.296875,
      -0.1171875,
      2.84375,
      3.015625,
      1.8515625,
      -0.38671875,
      -1.765625,
      1.0859375,
      -2.203125,
      2.875,
      -1.1484375,
      -2.140625,
      0.54296875,
      -0.30078125,
      0.10205078125,
      3.296875,
      1.2109375,
      -0.275390625,
      0.94921875,
      -2.484375,
      -0.53515625,
      -1.9140625,
      -1.859375,
      4.03125,
      -0.94921875,
      0.435546875,
      0.439453125,
      2.546875,
      -4.125,
      -0.072265625,
      -2.625,
      0.37109375,
      -1.609375,
      2.328125,
      -1.609375,
      -0.060302734375,
      1.0859375,
      -0.39453125,
      5.625,
      3.75,
      -0.169921875,
      -2.59375,
      -1.9375,
      1.09375,
      -0.93359375,
      3.15625,
      -1.828125,
      -2.28125,
      -0.0308837890625,
      -0.5625,
      2.078125,
      -0.9921875,
      1.1640625,
      -2.140625,
      -0.376953125,
      1.3984375,
      0.33984375,
      1.1953125,
      2.046875,
      2.859375,
      -1.921875,
      -0.4375,
      -3.40625,
      -3.0625,
      -2.140625,
      1.4296875,
      -0.6953125,
      0.03759765625,
      -0.25390625,
      -0.60546875,
      -1.8984375,
      -2.84375,
      1.828125,
      -1.375,
      -0.98046875,
      1.234375,
      -0.6328125,
      -2.28125,
      0.984375,
      -1.875,
      -0.056396484375,
      -2.46875,
      -4.125,
      1.171875,
      -1.078125,
      0.62109375,
      -3.515625,
      -0.11865234375,
      2.53125,
      -1.5,
      -3.453125,
      -3.09375,
      2.3125,
      -1.265625,
      -2.125,
      1.109375,
      2.421875,
      0.98828125,
      -0.408203125,
      -0.40625,
      -5.3125,
      0.126953125,
      -4.53125,
      2.21875,
      3.4375,
      0.8046875,
      0.177734375,
      3.078125,
      2.671875
    ],
    "summary": "提出一种人机协同循环框架，通过整合专家判断来优化自动项目生成（AIG）的质量，特别针对批判性思维评估领域，旨在解决AI生成项目的效度问题。",
    "structure": {
      "sections": [
        {
          "title": "STAIR-AIG: Optimizing the Automated Item Generation Process through Human-AI Collaboration for Critical Thinking Assessment",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 11
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "2 Related Works",
          "level": 1,
          "start_line": 31
        },
        {
          "title": "2.1 Automatic Item Generation",
          "level": 1,
          "start_line": 33
        },
        {
          "title": "2.2 Assessment Item Review Procedure",
          "level": 1,
          "start_line": 41
        },
        {
          "title": "3 Development of STAIR-AIG",
          "level": 1,
          "start_line": 54
        },
        {
          "title": "3.1 STAIR-AIG Workflow",
          "level": 1,
          "start_line": 56
        },
        {
          "title": "3.2 STAIR-AIG Modules",
          "level": 1,
          "start_line": 69
        },
        {
          "title": "3.2.1 Item Analysis Module",
          "level": 1,
          "start_line": 73
        },
        {
          "title": "3.2.2 Item Review Module",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "4 Empirical Research",
          "level": 1,
          "start_line": 115
        },
        {
          "title": "4.1 Data",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "4.2 Item Review by Human Expert",
          "level": 1,
          "start_line": 131
        },
        {
          "title": "4.3 Item Quality Review by LLMs",
          "level": 1,
          "start_line": 143
        },
        {
          "title": "5 Results",
          "level": 1,
          "start_line": 151
        },
        {
          "title": "5.1 Quantitative Results",
          "level": 1,
          "start_line": 153
        },
        {
          "title": "5.1.1 Comparison of Human Reviews with LLM-generated Reviews",
          "level": 1,
          "start_line": 155
        },
        {
          "title": "5.1.2 Distribution of Ratings across Evaluators",
          "level": 1,
          "start_line": 163
        },
        {
          "title": "5.2 Qualitative Feedback from Human Expert",
          "level": 1,
          "start_line": 179
        },
        {
          "title": "6 Conclusions & Implications",
          "level": 1,
          "start_line": 195
        },
        {
          "title": "6.1 Conclusions",
          "level": 1,
          "start_line": 197
        },
        {
          "title": "6.2 Implications",
          "level": 1,
          "start_line": 205
        },
        {
          "title": "6.3 Limitations",
          "level": 1,
          "start_line": 217
        },
        {
          "title": "Acknowledgments",
          "level": 1,
          "start_line": 231
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "A Appendix",
          "level": 1,
          "start_line": 278
        },
        {
          "title": "A.1 Prompt for Item Review by LLMs",
          "level": 1,
          "start_line": 280
        },
        {
          "title": "Listing 1: System prompt",
          "level": 1,
          "start_line": 284
        },
        {
          "title": "Listing 2: User prompt: Review Context",
          "level": 1,
          "start_line": 294
        },
        {
          "title": "Review Context",
          "level": 2,
          "start_line": 296
        },
        {
          "title": "Listing 3: User prompt: Review Methods",
          "level": 1,
          "start_line": 314
        }
      ]
    },
    "suggested_tags": [
      "教育评估",
      "人机协同",
      "自动项目生成",
      "大语言模型",
      "批判性思维"
    ],
    "tag_suggestions": [
      {
        "name": "教育评估",
        "confidence": 0.95,
        "reason": "论文核心研究领域是教育测量与评估，特别是针对批判性思维这一高阶认知技能的评估项目生成与质量保证。"
      },
      {
        "name": "人机协同",
        "confidence": 0.9,
        "reason": "论文提出并验证了STAIR-AIG框架，这是一个系统性的人机协同（Human-in-the-loop）工具，旨在通过整合专家判断来优化自动项目生成流程。"
      },
      {
        "name": "自动项目生成",
        "confidence": 0.9,
        "reason": "论文聚焦于利用大语言模型进行自动项目生成，并致力于解决其生成项目的质量、有效性和适当性问题，这是论文的核心技术应用。"
      },
      {
        "name": "大语言模型",
        "confidence": 0.85,
        "reason": "研究以LLMs（如OpenAI模型）作为AIG的核心技术，探讨其在项目生成与评审中的表现、局限性，并利用人类反馈进行模型优化。"
      },
      {
        "name": "批判性思维",
        "confidence": 0.8,
        "reason": "论文选择批判性思维作为具体的应用和验证领域，这是一个复杂且具有挑战性的高阶认知技能评估场景。"
      }
    ],
    "category": "教育评估",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:282837002",
          "title": "Sorry, it's my fault: Politeness, attribution, and anthropomorphism in managing generative AI hallucinations",
          "authors": [
            "Hayeon Kim",
            "Sang Woo Lee"
          ],
          "year": 2026,
          "venue": "International Journal of Information Management",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283006637",
          "title": "From hallucinations to hazards: benchmarking LLMs for hazard analysis in safety-critical systems",
          "authors": [
            "Ioannis M. Dokas"
          ],
          "year": 2026,
          "venue": "Safety Science",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283171596",
          "title": "A review of knowledge graph construction using large language models in transportation: Problems, methods, and challenges",
          "authors": [
            "Yancheng Ling",
            "Zhenlin Qin",
            "Zhengliang Ma"
          ],
          "year": 2026,
          "venue": "Transportation Research Part C: Emerging Technologies",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283205299",
          "title": "A singular learning theory for unified large language model pruning",
          "authors": [
            "Xinyu Wang",
            "Zhaoxin Fan",
            "Faguo Wu",
            "Hongwei Zheng",
            "Yuanze Hu",
            "Gen Li",
            "Zhichao Yang",
            "Qiu Ye",
            "Yifan Sun",
            "Wenjun Wu"
          ],
          "year": 2026,
          "venue": "Neurocomputing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283296470",
          "title": "Multimodal large model driven pseudo labeling for unbiased scene graph generation",
          "authors": [
            "Songju Li",
            "Bin Sun",
            "Shutao Li",
            "Bin Yang"
          ],
          "year": 2026,
          "venue": "Neurocomputing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283434047",
          "title": "AugGen: a generative framework for continual generalized zero-shot learning",
          "authors": [
            "Na Han",
            "Honglin Chen",
            "Bingzhi Chen",
            "Lei Zhang",
            "Yue Huang",
            "Qintao Luo",
            "Xiaozhao Fang"
          ],
          "year": 2026,
          "venue": "Neurocomputing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283533669",
          "title": "Intelligent system modeling using GenAI: A methodology for automated simulation model generation",
          "authors": [
            "Lin Zhang",
            "Yuteng Zhang",
            "Dusit Niyato",
            "Lei Ren",
            "Pengfei Gu",
            "Zhen Chen",
            "Y. Laili",
            "Wentong Cai",
            "A. Bruzzone"
          ],
          "year": 2026,
          "venue": "Simulation modelling practice and theory",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283643870",
          "title": "Synthetic data generation for joint electric vehicle driving and charging events via deep generative networks",
          "authors": [
            "Zhi Li",
            "Wei Ma",
            "Mónica Menéndez",
            "Zhibin Chen",
            "Minghui Zhong"
          ],
          "year": 2026,
          "venue": "Transportation Research Part C: Emerging Technologies",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283854590",
          "title": "ESA-Net: An Efficient and Lightweight Model for Medical Image Segmentation",
          "authors": [
            "Haiquan Liu",
            "Mingcan Cen",
            "Chong Zhang",
            "Angela An",
            "Shuxiang Song"
          ],
          "year": 2026,
          "venue": "Big Data Mining and Analytics",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280514888",
          "title": "IGen: Redefining long-term event prediction with iterative generation and dynamic balancing",
          "authors": [
            "Yuxin Zhang",
            "Yan Wang",
            "Songlin Zhai",
            "Yongrui Chen",
            "Shenyu Zhang",
            "Yuan Meng",
            "Zhihua Chai",
            "Sheng Bi",
            "Guilin Qi"
          ],
          "year": 2026,
          "venue": "Information Processing & Management",
          "citation_count": 0
        }
      ],
      "citations_fetched_at": "2025-12-16T22:45:09.108500",
      "references": [
        {
          "external_id": "CorpusId:219800227",
          "title": "All the News That’s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation",
          "authors": [
            "S. Kreps",
            "Miles McCain",
            "Miles Brundage"
          ],
          "year": 2020,
          "venue": "Journal of Experimental Political Science",
          "citation_count": 289
        },
        {
          "external_id": "CorpusId:218971825",
          "title": "Language (Technology) is Power: A Critical Survey of “Bias” in NLP",
          "authors": [
            "Su Lin Blodgett",
            "Solon Barocas",
            "Hal Daum'e",
            "Hanna M. Wallach"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1463
        },
        {
          "external_id": "CorpusId:218869575",
          "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
          "authors": [
            "Patrick Lewis",
            "Ethan Perez",
            "Aleksandara Piktus",
            "F. Petroni",
            "Vladimir Karpukhin",
            "Naman Goyal",
            "Heinrich Kuttler",
            "M. Lewis",
            "Wen-tau Yih",
            "Tim Rocktäschel",
            "Sebastian Riedel",
            "Douwe Kiela"
          ],
          "year": 2020,
          "venue": "Neural Information Processing Systems",
          "citation_count": 9778
        },
        {
          "external_id": "CorpusId:218487293",
          "title": "How Can We Accelerate Progress Towards Human-like Linguistic Generalization?",
          "authors": [
            "Tal Linzen"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 202
        },
        {
          "external_id": "CorpusId:218487109",
          "title": "UnifiedQA: Crossing Format Boundaries With a Single QA System",
          "authors": [
            "Daniel Khashabi",
            "Sewon Min",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Oyvind Tafjord",
            "Peter Clark",
            "Hannaneh Hajishirzi"
          ],
          "year": 2020,
          "venue": "Findings",
          "citation_count": 785
        },
        {
          "external_id": "CorpusId:216035815",
          "title": "Experience Grounds Language",
          "authors": [
            "Yonatan Bisk",
            "Ari Holtzman",
            "Jesse Thomason",
            "Jacob Andreas",
            "Yoshua Bengio",
            "J. Chai",
            "Mirella Lapata",
            "Angeliki Lazaridou",
            "Jonathan May",
            "Aleksandr Nisnevich",
            "Nicolas Pinto",
            "Joseph P. Turian"
          ],
          "year": 2020,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 393
        },
        {
          "external_id": "CorpusId:215828184",
          "title": "StereoSet: Measuring stereotypical bias in pretrained language models",
          "authors": [
            "Moin Nadeem",
            "Anna Bethke",
            "Siva Reddy"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 1198
        },
        {
          "external_id": "CorpusId:215828407",
          "title": "Adversarial Training for Large Neural Language Models",
          "authors": [
            "Xiaodong Liu",
            "Hao Cheng",
            "Pengcheng He",
            "Weizhu Chen",
            "Yu Wang",
            "Hoifung Poon",
            "Jianfeng Gao"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 203
        },
        {
          "external_id": "CorpusId:215745290",
          "title": "Pretrained Transformers Improve Out-of-Distribution Robustness",
          "authors": [
            "Dan Hendrycks",
            "Xiaoyuan Liu",
            "Eric Wallace",
            "Adam Dziedzic",
            "R. Krishnan",
            "D. Song"
          ],
          "year": 2020,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 457
        },
        {
          "external_id": "CorpusId:212747731",
          "title": "TTTTTackling WinoGrande Schemas",
          "authors": [
            "Sheng-Chieh Lin",
            "Jheng-Hong Yang",
            "Rodrigo Nogueira",
            "Ming-Feng Tsai",
            "Chuan-Ju Wang",
            "Jimmy Lin"
          ],
          "year": 2020,
          "venue": "arXiv.org",
          "citation_count": 6
        }
      ],
      "references_fetched_at": "2025-12-16T22:45:09.878682"
    }
  },
  "6f24f8d1-03ac-4741-a063-e53bea9bab70": {
    "id": "6f24f8d1-03ac-4741-a063-e53bea9bab70",
    "filename": "A CHATGPT-BASED APPROACH FOR QUESTIONS GENERATION IN  HIGHER EDUCATION.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/6f24f8d1-03ac-4741-a063-e53bea9bab70_A CHATGPT-BASED APPROACH FOR QUESTIONS GENERATION IN  HIGHER EDUCATION.pdf",
    "status": "completed",
    "created_at": "2025-12-16 22:48:04.525748",
    "updated_at": "2025-12-16 14:49:03.434120",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "AchatGPT-BASED APPROACH FOR QUESTIONS GENERATION IN HIGHER EDUCATION",
    "markdown_content": "# AchatGPT-BASED APPROACH FOR QUESTIONS GENERATION IN HIGHER EDUCATION\n\nA PREPRINT\n\nSinh Trong Vu\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\nsinhvt@hvnh.edu.vn\n\nHuong Thu Truong\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\ntrgthuhg@gmail.com\n\nOanh Tien Do\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\noanhvy2bg@gmail.com\n\nTu Anh Le\n\nBanking Academy of Vietnam\n\nHanoi, Vietnam\n\nleanhtu.work@gmail.com\n\nTai Tan Mai\n\nDublin City University\n\nDublin, Ireland\n\ntai.tanmai@dcu.ie\n\nJune 10, 2024\n\n# ABSTRACT\n\nLarge language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a \"Blind test\" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.\n\nKeywords Large language model  $\\cdot$  ChatGPT  $\\cdot$  question generation\n\n# 1 Introduction\n\nOne of the most prominent advances in Artificial Intelligence recently is the development of large language models (LLMs), such as ChatGPT, BingChat, and Bard (developed by OpenAI, Microsoft, and Google, respectively). It can be said that large language models have been developing strongly in the past 2 years and creating a strong influence in the field of Generative AI (GenAI) [1].\n\nLLMs are capable of solving a wide range of tasks, such as natural language understanding, text generation, and sentiment analysis in various domains [2]. Since the breakthroughs of AI and LLM, education, as a crucial role in shaping society through almost every single individual, might receive significant benefits from these new LLM-based initiatives. AI is transforming education, bridging its gaps, and promoting a more inclusive and productive learning environment by customizing learning experiences, automating administrative tasks, and providing real-time feedback [3].\n\nAdvancements in AI and LLMs have fueled the development of many educational technology innovations that aim to automate the often time-consuming and laborious tasks of generating and analyzing textual content, including generating test questions. For the application of LLM in education, this technology holds great potential in this field at all levels, especially university level [4]. Therefore, this study conducts a research to comprehensively understand the capabilities of LLMs, especially ChatGPT when supporting lecturer to build question banks for learning modules in university setting. During the literature review, we witnessed that although the LLMs can provide quite a lot of support in teaching activities [5], the work of testing and evaluating learners, which takes up a lot of time and effort of\n\nlecturers, has not been studied in-depth by previous works. Therefore, in this paper, we decide to conduct research on the application of LLMs for generating question banks, with initial results at the Banking Academy of Vietnam. Specifically, the contributions of the paper are summarized as follows:\n\n1. Investigate the most potential LLM-based tool that satisfy the following criteria: (i): capable of processing multiple languages; (ii) widely accessible by the public and (iii) suitable for university educational setting.  \n2. Design a novel approach to generate prompting patterns to interact with ChatGPT, thereby design an effective prompt pattern for creating question banks at university level.  \n3. Generate a question bank for a specific subject with diverse question types as the sample module of university level in Vietnam, in order to present the potential direction for further related research in the field of broader modules of higher education.  \n4. Design and conduct a \"Blind Test\" survey aimed at students to evaluate the quality of the generated questions\n\n# 2 Related works\n\nWith the growing interest in LLM for education, many studies around the world focusing on this issue have been conducted and have produced some interesting results. A group of authors from the University of Minnesota Law School have conducted research on ChatGPT's performance in answering a set of questions including 95 multiple-choice questions and 12 essay questions related to four undergraduate-level subjects in the law class. The results showed that ChatGPT studied and performed on the test at a level equivalent to a  $\\mathrm{C + }$  grade for college students [6].\n\nAnother study put ChatGPT to the test in completing the Dutch secondary school exam in the subject of English reading comprehension. This study concluded that ChatGPT achieved results with an average score of 7.3, comparable to the average score of all high school students in the country [7].\n\nIn another research on evaluating the performance of LLMs when taking a high school level Biology test by the author namely Dao Xuan Quy, ChatGPT showed positive results with an accuracy of  $71\\%$  for remembering level questions and  $61.82\\%$  for understanding level questions. This result shows how effective ChatGPT is in capturing and clarifying concepts related to the required subject [8].\n\nThe use of LLMs in supporting the construction of questions to test and evaluate students' knowledge should be encouraged. While exam-style questions are an important instructional tool for several reasons, manually creating questions is a time-consuming process that necessitates expertise, experience, and resources. This, in turn, impedes and inhibits the implementation of instructional activities (e.g., offering practice questions) and educational initiatives (e.g., adaptive testing) that need a huge pool of questions. Therefore, automatic question generating (AQG) approaches based on AI were established for research in both developed and developing nations [9].\n\nThe general state of scientific research on the use of LLM in education is limited because its implementation in educational settings is still in its early stages. To the best of our knowledge, there is no study on evaluating quality and practicality of using questions generated by LLMs to test real students, especially in higher education. Therefore, in this study we will conduct an experiment on questions bank generation using LLMs, with some early results from a university in Vietnam.\n\nSelecting the optimal LLM-based solution. Nowadays, many advanced large language models can be widely applied in the field of education such as ChatGPT, BingAI, Gemini, etc. Most prominently, ChatGPT is an advanced general AI model based on a Generative Pretrained Transformer (GPT). This feature refers to the LLM being pre-trained with the available dataset and can generate grammatically and contextually human-like responses according to the user's request through natural language processing. The current most popular versions of ChatGPT are GPT-3.5 and GPT-4, with the upgraded version GPT-4 can be used with a fee, which according to OpenAI performs much better with a 10 times larger pre-training datasets capacity [10].\n\nThe initial goal of this research is to evaluate various LLMs in order to find the one having performance and suitability for generating questions in the higher educational context. Each model has its own advantages and disadvantages, so our team has to compare consider which one can fulfill the both factors. As we prioritize the best ones meeting educational standards, ChatGPT Plus and Claude are two potential options. However, ChatGPT Plus has a relatively high fee (\\(20/month) and Claude has a few limitations in its capabilities [11].\n\nFor the following reasons, we finally decided to choose ChatGPT 3.5 as the model for this research:\n\n- ChatGPT 3.5 is freely usable so this choice can save on our research costs.\n\n- ChatGPT 3.5 has been proven through scientific research to be able to produce high-quality text, similar to text written by humans[12].  \n- ChatGPT 3.5 currently has 180 million users, with 100 million weekly active users and 1.6 billion website visit times [13]. This number shows that ChatGPT 3.5 is sufficiently popular and trustworthy.\n\nStriking the perfect balance between capability and cost, ChatGPT 3.5 is selected as it is sufficiently suitable to the context of educating in the Banking Academy of Vietnam.\n\n# 3 Research design\n\n# 3.1 Choosing a subject for experimentation\n\nIn most universities, building a question bank is the primary way to facilitate the procedure of making tests and final semester exams. The question bank is usually based on the learning outcomes and lesson content, thereby determining the types of questions to create. Questions are arranged according to each chapter, with cognitive levels depending on the objectives and lesson knowledge. Here, we conduct research on creating questions for the subject \"Corporate Finance I\" with the LLM ChatGPT 3.5, by these reasons and purposes:\n\n- First, to test and evaluate ChatGPT 3.5's natural language processing ability with a variety of different question types. This is because \"Corporate Finance I\" has a variety of question types that have been extensively put under tests and final exams: Multiple Choice Questions (MCQs), True-False statements, Real-Scenario/Calculative exercises,...  \n- Second, to make the experiment more effective with the highest possible number of survey participants \"Corporate Finance I\" is a popular module format as it is a compulsory curriculum for almost every faculty in the Banking Academy of Vietnam for specialized learning outcomes towards the students of the academy.  \n- Third, to qualitifiedly evaluate this scientific study. Throughout many subjects our research team discussed, \"Corporate Finance I\" has been chosen since this is the subject that we have obtained a certain basic understanding of.\n\nTo conduct research, we combine personal knowledge and use documents including the textbook \"Corporate Finance I\" (Author & Editor: Le Thi Xuan), the workbook \"Corporate Finance I\" of the Banking Academy and also refer to Course Learning Outcomes (CLOs), syllabus structure, test question formats, and examples of exam questions in this subject.\n\n# 3.2 The investigation of appropriate Prompt patterns\n\nThrough research on the meaning of elements as well as the operation of available Prompt templates such as RTF (Role, Task, Format), RISE (Role, Input, Steps, Expectation), RTCF (Role, Task, Context, Format), RTCEF (Role, Task, Context, Example, Format). We have filtered, selected and separated into specific factors as shown in the Table 1 [14].\n\nThen, one by one, we select and combine the above factors and then test and evaluate the results returned by ChatGPT ourselves. The goal of this experiment is to answer: Whether to continue adding or removing any factor to see if it affects the quality of returned results? If the results are better, we consider that factor to be kept and conversely, if there is no change and we find it unnecessary, we remove that factor. As a result, we choose the most suitable prompt type for each type of question we want to create below.\n\n# 3.2.1 For multiple-choice questions\n\nPrompt: Role + Task + Context + Example + Format\n\nFollowing the structure, here is our formative prompt:\n\nRole: You are a lecturer of [subject name]\n\nTask: Please create [a specific number] questions\n\nContext: [The kind of exercise] questions that focus on the content of [name of the lesson to test]\n\nExample: (This is the example I want you to imitate: [specific example of the type of exercise to create])\n\nFormat: Present output in [format name]\n\nTable 1: Prompt elements and their uses  \n\n<table><tr><td>Factor</td><td>Purpose</td></tr><tr><td>Task</td><td>Describe the task you want the AI to perform, usually starting with verbs such as: Create [...] , do [...] , ... This is a required part in most prompts to use for ChatGPT</td></tr><tr><td>Context</td><td>Provide information about the context and task objectives</td></tr><tr><td>Input</td><td>Describe the context in more detail</td></tr><tr><td>Format</td><td>Specify the desired format for the output, usually a standard that has been agreed upon and used</td></tr><tr><td>Example</td><td>Provide specific example instructions to guide the AI, often in parentheses</td></tr><tr><td>Role</td><td>Clearly define the role of AI in a specific context, usually with role statements such as: Play the role of [...] , you are [...] , ...</td></tr></table>\n\n# 3.2.2 For True-False statements\n\nPrompt:  $=$  Role + Task + Context + Example + Format\n\nFollowing the structure, here is our formative prompt:\n\nRole: You are a lecturer of [subject name]\n\nTask: Please create [a specific number] questions\n\nContext: [The kind of exercise]. You should make the exam of [number of statements] including [number of correct statements] correct statements and [number of incorrect statements] incorrect statements with content about [name of content]\n\nExample: (This is the example I want you to imitate: [specific example of the type of exercise to create])\n\nFormat: All comments are in the same paragraph. The line determining the truth/falseness and explanation of that statement must immediately follow, starting with \"ANSWER:\" (NOTE: Space after the colon) and then giving the appropriate answer and explanation.\n\n# 3.2.3 For Real-Scenario/Calculative exercises\n\nPrompt:  $=$  Task + Context + Input + Tone\n\nFollowing the structure, here is our formative prompt:\n\nTask: Create exercises with specific data\n\nContext: About [name of content]\n\nInput: The topic includes [starting data] [detailed information]\n\nTone: You have to solve the exercise as you are dealing with real business context\n\n# 3.3 Evaluation methods and test results\n\n# 3.4 Preliminary self-assessment and optimization utilizing ChatGPT.\n\nApplying the above prompt samples with ChatGPT3.5, we obtain a list of questions, in which the MCQ and True/False questions are along with the solutions. We perform a preliminary self-assessment by checking whether the question list containing any duplication or lack of assumption to solve. From a total of 390 questions generated, we found and remove 74 ones with this strategy, in which,  $28\\%$  of the calculation exercises are insufficient data. For instance, the exercise \"PQR Company wants to optimize ordering costs for product D. The annual demand is 600 tons, the purchase\n\nprice per ton is 15,000 USD. Holding cost is  $1.5\\%$  of inventory value/year. Calculate the optimal order level.\" lacks the \"ordering costs\" value, makes it unsolvable. This is one of the drawback of large language model based method, relying on the probability of word's appearance rather than the logical factors. We show the self-assessment result in Table 2 below.\n\nTable 2: Evaluation of question quality. (Unit: %)  \n\n<table><tr><td>Question Type</td><td>MCQs</td><td>True-False Statement</td><td>Calculation exercise</td></tr><tr><td>Total Number of Questions</td><td>230 questions</td><td>100 questions</td><td>60 question</td></tr><tr><td>Duplicated</td><td>19,13%</td><td>3%</td><td>0</td></tr><tr><td>Insufficient assumptions to solve</td><td>3,48%</td><td>4%</td><td>28%</td></tr></table>\n\n# 3.5 The \"Blind Test\" method\n\nTo evaluate the quality of the questions more objectively, our research team conducted a survey using the \"Blind test\" method to collect answers from students to lecturers. Based on the well-known Turing Test, the \"Blind test\" aims to get empirical insight into people's ability to discriminate between artificial and human content [15].\n\nBased on this idea, we have prepared two sets of question banks. One is the questions created by ChatGPT 3.5 and the other is the questions in the workbook of Corporate Finance 1 published by the Banking Academy of Vietnam. The questions from the two groups were mixed together. We proceed to create a survey form testing with a list of 15 questions, with an example shown in Figure 1. Each question includes 2 options: created by humans or created by ChatGPT. We obtain the answer from a total of 91 people including lecturers, students who studied, are currently studying or have not studied Corporate Finance I before. The detail statistics about this survey is evaluated in the following sections.\n\n1. Private enterprises are allowed to issue bonds to mobilize investment capital.  \nCreated by human  \nCreated by ChatGPT\n\nFigure 1: An example question from the \"Blind Test\" survey\n\n# 3.6 Result of evaluation\n\n# 3.6.1 Survey assumption\n\nDuring the survey, the course-completed rate is expected to be distributed in proportion:  $60\\%$  have completed and are in progress of completing, and  $40\\%$  have not started. This provides the opportunity for multi-pronged analysis looking at different outcomes based on these two main groups.\n\nThe general expectation of our research team is that the number of questions prepared by ChatGPT but predicted to be created by humans is high, for approximately over  $60\\%$ . To better understand this result, we need to analyze each group more carefully as follows:\n\n- For lecturers, they have the ability to deeply evaluate the similarity between the question and the content, evaluate the difficulty level of the question as well as the feasibility of solving it. This allows them to most accurately identify which questions truly reflect knowledge and are capable of assessing students' skills like real exam questions.  \n- For the group of people who have studied, they can analyze the content of the questions, consider the level of difficulty and the ability to apply learned knowledge to solve questions. This helps them better recognize how each knowledge is asked in the real exam, thereby pointing out the questions created by ChatGPT with its shortcomings.\n\n- The group of in-progress learners can focus on evaluating the reflectiveness of the question on the content they are approaching. From their perspective, they will distinguish between questions created by ChatGPT or people based on their progressed knowledge and their own understanding.  \n- Finally, the group of students that haven't learned this subject may only be able to evaluate the naturalness and the grammar accuracy in the question.\n\n# 3.6.2 General analysis\n\nThe performance of each group of survey participants is presented in the Figure 2.\n\n![](/uploads/images/6f24f8d1-03ac-4741-a063-e53bea9bab70/03734fc52da67de08e4acfe73b604f737a6b9a51f9e87149c9196e05dd0ea520.jpg)  \nFigure 2: Average number of correct answers from different groups of surveyors\n\n- The survey results showed that lecturers have a relatively high ability to distinguish between questions generated by ChatGPT and those generated by humans, with an accuracy rate of up to 13.5/15 questions.  \n- Students who have studied the subject are better at distinguishing between ChatGPT-generated and human-generated questions than students who are currently studying  $(8.0833 > 7)$ , and students who have studied have a higher average correct answer rate than students who have not studied  $(7 > 6.7059)$ . This suggests that exposure to course content and knowledge helps students become more sensitive to the differences between human-generated and AI-generated questions.\n\n# 3.6.3 Specific analysis\n\nOur data shows that the 9 questions having the least percentage of students answering correctly have an average of only  $32.5\\%$  answers correct. In particular, the survey showed that the multiple-choice section had the lowest rate of correct answers with only about  $30\\%$ . This may stem from the fact that human lecturers often create short, concise multiple-choice questions with the goal of simply testing whether students have grasped the knowledge surrounding the concept being asked. In fact, LLM like ChatGPT has the ability to grasp the subject and create related questions to support learners[8]. Therefore, this tool is capable of creating MCQs properly along with the lecturers in an even faster way.\n\nTable 3: The best questions that ChatGPT generates  \n\n<table><tr><td>1. The principle of time value of money is: \nA. The longer a currency retains its value, the better \nB. The value of money increases over time \nC. A currency today has a higher value than it will in the future \nD. Money loses value over time</td><td>2. What are some of the main benefits of long-term investing? \nA. High short-term profits. \nB. Increase the value of long-term assets. \nC. Low risk. \nD. Stable market.</td></tr><tr><td>Participant result: \n63 (69,2%) wrongly rated as Human, 28 (30,8%) correctly rated as ChatGPT</td><td>Participant result: \n67 (73,6%) wrongly rated as Human, 24 (26,4%) correctly rated as ChatGPT</td></tr></table>\n\nTo explain the results above, the differentiating difficulty of AI-generated exercise questions is based on two factors:\n\n- The question type: Whether it is an MCQ or a T/F, Exercise question.  \n- The quality requirement of information input: In the process of making a good question, whether the question is required to capture completely learning materials or a few texts for example.\n\nSubjectively stated, a broad and general list of MCQs surveyed are less difficult to be guessed than real-life scenario exercises, or calculative ones that we had to give ChatGPT some examples to train it. Furthermore, these models can generate plausible distractors, which are incorrect answers that are designed to be similar to the correct answer, making it more challenging for humans to discern the difference. According to the study of Bitew et al. (2023), ChatGPT, when guided by question items and in-context examples, can generate high-quality distractors that are suitable for immediate use in an educational context.[16]\n\nTable 4: Worst question ChatGPT creates  \n\n<table><tr><td>Private enterprises are allowed to issue bonds to mobilize investment capital. (True/False)</td><td>Strengthening overdue debt management helps businesses optimize capital resources. (True/False)</td></tr><tr><td>Participant result: 70 (76,9%) correctly rated as Human, 21 (23,1%) wrongly rated as ChatGPT</td><td>Participant result: 70 (76,9%) correctly rated as Human, 21 (23,1%) wrongly rated as ChatGPT</td></tr></table>\n\nHowever, there are a few limitations needed to be considered to the performance of LLMs in generating questions in order to decide the optimal usage of this tool. Firstly, the 9 AI-generated questions, especially the True-False questions and Exercise questions that are leastly mistaken for human-generated ones shown, are all lacking structured links to other concepts and overall reasoning around the subject. This proves that the discriminatory power of those 9 questions might not be as high as other questions in the list. To clarify this point, our research team have tried to answer the questions ourselves as students and stated that more than half of the questions can be referenced for posting on the real exam, but there are a few problems:\n\n- In regards of the questions' content, they are simply the same so it is hard to use these questions to encourage students to link back what they have learned.  \n- Some of the AI-generated questions are quite vague to make clear its meaning.  \n- In the Vietnamese version of the questions, the way ChatGPT used related terms is not really exact for academic context due to the language barrier.\n\n# 4 Conclusion\n\nIn this study, we have researched an overview of the major language models available today, through which we propose to use Chat GPT3.5 because it has a wide reach to users, suitable for the Practical events at the Banking Academy. We have researched and extracted effective command samples that interact with Chat GPT3.5 to create a question bank for Corporate Finance 1 subject at the Banking Academy today and then create a bank. Questions types include: multiple choice, true or false judgment and calculation exercises. The question bank created by Chat GPT3.5 is post processed, then evaluated by a \"Blind Test\" conducted on lecturers and students who studied, studying or have not studied this subject. The results show that ChatGPT has great potential in supporting learner assessment through the application of creating questions that contribute to the test bank. This conclusion is proven by accurate data, with a level of differentiation of about  $80\\%$  at an average level similar to the target of test banks created by instructors.\n\nDuring the research and implementation process, we encountered a limitation that is needed for other works. Currently, with the rapid development of artificial intelligence, many new tools have emerged to support users in creating question and answer systems for their specific purposes, which can upload user's documents. These documents play as a knowledge base which contributes to improving the quality of questions generated. Additionally, users only need to provide the initial prompt, and educators do not need to learn about prompts but can simply request questions based on quantity and topic. Therefore, we hope to integrate our methodology with other scientific solutions to save time and effort for lecturers in evaluating learners in higher education.\n\n# References\n\n[1] Irfan Jahic, Martin Ebner, and Sandra Schön. Harnessing the power of artificial intelligence and chatgpt in education - a first rapid literature review. In Proceedings of EdMedia + Innovate Learning, pages 1462-1470, 07 2023.  \n[2] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. A survey on evaluation of large language models, 2023.  \n[3] Firuz Kamalov, David Santandreu Calonge, and Ikhlaas Gurrib. New era of artificial intelligence in education: Towards a sustainable multifaceted revolution. Sustainability, 15(16), 2023. ISSN 2071-1050. doi:10.3390/su151612451. URL https://www.mdpi.com/2071-1050/15/16/12451.  \n[4] Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Martinez-Maldonado, Guanliang Chen, Xinyu Li, Yueqiao Jin, and Dragan Gasević. Practical and ethical challenges of large language models in education: A systematic scoping review. British Journal of Educational Technology, 55(1):90–112, August 2023. ISSN 1467-8535. doi:10.1111/bjet.13370. URL http://dx.doi.org/10.1111/bjet.13370.  \n[5] Dao Xuan-Quy, Ngoc-Bich Le, Xuan-Dung Phan, and Bac-Bien Ngo. An evaluation of chatgpt's proficiency in english language testing of the Vietnamese national high school graduation examination. SSRN Electronic Journal, 06 2023. doi:10.2139/ssrn.4473369.  \n[6] H. Choi Jonathan, E. Hickman Kristin, Monahan Amy, and Schwarcz Daniel. Chatgpt goes to law school. Social Science Research Network, Jan 2023. doi:https://doi.org/10.2139/ssrn.4335905. URL https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4335905.  \n[7] Joost C. F. de Winter. Can chatgpt pass high school exams on english language comprehension? International Journal of Artificial Intelligence in Education, Sep 2023. doi:https://doi.org/10.1007/s40593-023-00372-z. URL https://link.springer.com/article/10.1007/s40593-023-00372-z.  \n[8] Dao Xuan-Quy and Ngoc-Bich Le. Llms' capabilities at the high school level in chemistry: Cases of chatgpt and microsoft bing ai chat. 06 2023. doi:10.26434/chemrxiv-2023-kxxpd.  \n[9] Kurdi Ghader, Jared Leo, Parsia Bijan, Sattler Uli, and Al-Emari Salam. A systematic review of automatic question generation for educational purposes. International Journal of Artificial Intelligence in Education, 30(1): 121-204, Nov 2019. doi:https://doi.org/10.1007/s40593-019-00186-y. URL https://link.springer.com/article/10.1007/s40593-019-00186-y.  \n[10] Katikapalli Subramanyam Kalyan. A survey of gpt-3 family large language models including chatgpt and gpt-4. Natural Language Processing Journal, 6:100048, 2024. ISSN 2949-7191. doi:https://doi.org/10.1016/j.nlp.2023.100048. URL https://www.sciencedirect.com/science/article/pii/S2949719123000456.  \n[11] Edisa Lozić and Benjamin Štular. Fluent but not factual: A comparative analysis of chatgpt and other ai chatbots' proficiency and originality in scientific writing for humanities. Future Internet, 15(10):336, October 2023. ISSN 1999-5903. doi:10.3390/fit15100336. URL http://dx.doi.org/10.3390/fit15100336.  \n[12] Partha Pratim Ray. Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. _Internet of Things and Cyber-Physical Systems_, 3:121-154, 2023. ISSN 2667-3452. doi:https://doi.org/10.1016/j.iotpcs.2023.04.003. URL https://www.sciencedirect.com/science/article/pii/S266734522300024X.  \n[13] Dave Ver Meer. Number of chatgpt users and key stats, March 2024. URL https://www.namepepper.com/chatgpt-users?fbclid=IwAR2XxzRq4ZVZ-SeVP_RqFMTOEnq_OhmMwnynX6HwK2IiJsXbqihFBs7G-ow#user-number. Online.  \n[14] Matuš Čavojský, Gabriel Bugar, Tomas Kormanik, and Martin Hasin. Exploring the capabilities and possible applications of large language models for education. pages 91–98, 10 2023. doi:10.1109/ICETA61311.2023.10344166.  \n[15] Nils Köbis and Luca D. Mossink. Artificial intelligence versus maya angelou: Experimental evidence that people cannot differentiate ai-generated from human-written poetry. Computers in Human Behavior, 114:106553, 2021. ISSN 0747-5632. doi:https://doi.org/10.1016/j.chb.2020.106553. URL https://www.sciencedirect.com/science/article/pii/S0747563220303034.  \n[16] Semere Kiros Bitew, Johannes Deleu, Chris Develder, and Thomas Demeester. Distractor generation for multiple-choice questions with predictive prompting and large language models, 2023.",
    "arxiv_id": null,
    "error_message": null,
    "embedding": [
      -1.328125,
      -0.21875,
      -4.25,
      -2.84375,
      -3.046875,
      1.765625,
      -2.1875,
      -0.72265625,
      3.078125,
      3.859375,
      0.390625,
      -0.2431640625,
      2.453125,
      0.357421875,
      1.4765625,
      1.4609375,
      -1.796875,
      -0.365234375,
      0.90625,
      -6.375,
      -0.4140625,
      5.625,
      -1.265625,
      -6.9375,
      5.53125,
      -6.1875,
      -1.859375,
      -0.1669921875,
      2.5,
      -0.9375,
      7.3125,
      -5.34375,
      1.1640625,
      0.1474609375,
      -2.46875,
      0.83203125,
      -2.0625,
      -1.484375,
      4.5,
      4.5625,
      -6.5625,
      1.109375,
      -0.494140625,
      1.1015625,
      0.1884765625,
      3.78125,
      3.96875,
      -1.7421875,
      -4.5625,
      -2.390625,
      -1.8984375,
      -3.453125,
      4.875,
      -0.34765625,
      4.125,
      -5.8125,
      -6.90625,
      8.25,
      -4.71875,
      0.36328125,
      1.046875,
      -3.25,
      5.84375,
      1.0390625,
      5.5625,
      3.3125,
      0.76953125,
      3.140625,
      -1.359375,
      1.71875,
      -0.455078125,
      1.546875,
      6.5625,
      -2.609375,
      7.96875,
      8.375,
      3.546875,
      5.625,
      -1.6953125,
      4.65625,
      -4.875,
      1.8203125,
      4.90625,
      1.8359375,
      5.46875,
      2.6875,
      1.0390625,
      0.10205078125,
      -4.34375,
      0.5,
      -3.3125,
      -0.328125,
      -4.65625,
      -0.82421875,
      -1.5390625,
      6.40625,
      -2.4375,
      -3.234375,
      -6.25,
      0.87890625,
      -1.9296875,
      -2.09375,
      3.171875,
      -6.71875,
      -2.96875,
      -4.34375,
      -2.578125,
      -6.5625,
      -2.21875,
      -1.953125,
      0.345703125,
      1.46875,
      0.042724609375,
      0.48046875,
      3.8125,
      -1.40625,
      2.484375,
      -4.15625,
      -6.40625,
      -0.453125,
      0.265625,
      -1.484375,
      -0.98046875,
      1.5703125,
      1.8515625,
      2.15625,
      -5.875,
      1.2890625,
      6.25,
      0.271484375,
      3.4375,
      -0.828125,
      6.21875,
      0.287109375,
      -7,
      -4.09375,
      -3.140625,
      3.28125,
      1.703125,
      6.625,
      -7.6875,
      1.578125,
      -1.546875,
      -5.625,
      3.3125,
      1.03125,
      -6.1875,
      0.77734375,
      4.875,
      -4.21875,
      -1.234375,
      1.9765625,
      3.84375,
      5,
      -0.10302734375,
      -4.625,
      4.5625,
      1.1796875,
      0.55859375,
      -0.28125,
      -2.03125,
      2.140625,
      -0.90234375,
      0.2392578125,
      -0.42578125,
      0.94921875,
      -6.375,
      -0.236328125,
      1.484375,
      -2.3125,
      1.3125,
      15.0625,
      3.328125,
      -2.40625,
      1.390625,
      2.765625,
      0.8125,
      7.25,
      0.353515625,
      0.330078125,
      1.3984375,
      0.96875,
      -5.625,
      5.34375,
      -2.890625,
      0.83984375,
      2.046875,
      -1.9609375,
      1.625,
      -2.5,
      0.78125,
      3.046875,
      0.75390625,
      -0.004608154296875,
      -6.625,
      0.10791015625,
      0.52734375,
      0.55078125,
      1.2421875,
      2.21875,
      -2.6875,
      -8.8125,
      -1.09375,
      -3.640625,
      -4.25,
      0.0625,
      0.76171875,
      -2.765625,
      1.7578125,
      -1.3828125,
      1.140625,
      -0.58984375,
      2.796875,
      2.734375,
      6.125,
      2.796875,
      4.5625,
      -0.08447265625,
      4.96875,
      0.703125,
      4.53125,
      3.203125,
      3.53125,
      -1.0625,
      -1.875,
      2.046875,
      3.375,
      4.9375,
      1.5703125,
      8.1875,
      0.78515625,
      1.828125,
      4.15625,
      -4.75,
      -2.734375,
      -0.96875,
      -3.953125,
      0.6953125,
      -0.74609375,
      -0.01348876953125,
      -2.625,
      -3.171875,
      1.1796875,
      2.90625,
      1.7109375,
      -0.5859375,
      -1.609375,
      -3.15625,
      -2.984375,
      -7.84375,
      0.240234375,
      3.484375,
      -6.875,
      -3.484375,
      2.78125,
      9.5625,
      1.484375,
      -1.7578125,
      0.92578125,
      -3.546875,
      3.71875,
      -4.9375,
      -4.625,
      1.7265625,
      2.265625,
      -5.6875,
      2.96875,
      -1.3671875,
      0.52734375,
      0.64453125,
      0.26953125,
      -2.046875,
      -4.71875,
      -1.453125,
      -4.375,
      4.90625,
      3.921875,
      -3.359375,
      2.296875,
      -3.4375,
      -5.21875,
      -11.625,
      5.21875,
      -4.1875,
      3.25,
      -0.279296875,
      0.56640625,
      2.375,
      -1.7890625,
      12.5,
      2.4375,
      1.4453125,
      2.640625,
      0.65234375,
      -4.09375,
      3.171875,
      -2.15625,
      1.234375,
      -8,
      0.51953125,
      5.5,
      2.03125,
      -3.109375,
      -0.78125,
      -2.96875,
      4.0625,
      -0.73828125,
      -4.15625,
      1.15625,
      1.2890625,
      -3.125,
      3.96875,
      7.8125,
      -1.0234375,
      3.28125,
      -4.5,
      -3.234375,
      1.375,
      0.291015625,
      -2.1875,
      -6.0625,
      -4.5625,
      -1.71875,
      -0.921875,
      -2.09375,
      -1.4296875,
      -0.59765625,
      1.7421875,
      5.875,
      -0.9375,
      2.4375,
      4.53125,
      -6.71875,
      -9.125,
      8.5,
      -0.287109375,
      2.078125,
      2.5,
      0.4140625,
      5.03125,
      0.0089111328125,
      -0.84375,
      2.0625,
      -3.21875,
      -2.625,
      0.06494140625,
      4.90625,
      -4.84375,
      -0.212890625,
      -6.75,
      3.453125,
      1.234375,
      -0.375,
      3.125,
      7.78125,
      -3.15625,
      1.15625,
      0.45703125,
      0.65625,
      0.1962890625,
      2.234375,
      -2.578125,
      6.03125,
      -1.3125,
      0.07177734375,
      -1.59375,
      -6.375,
      3.40625,
      -3.984375,
      -0.306640625,
      -1.1640625,
      -1.6484375,
      1.2734375,
      3.8125,
      2.015625,
      -0.71484375,
      0.427734375,
      -4.84375,
      -5.625,
      3.6875,
      -4.3125,
      0.796875,
      -1.359375,
      -1.640625,
      4.28125,
      0.83984375,
      1.40625,
      4.09375,
      0.84765625,
      -2.9375,
      -1.1875,
      0.46875,
      -4.46875,
      -0.37890625,
      2.71875,
      1.46875,
      -1.671875,
      1.46875,
      -0.64453125,
      -2.078125,
      5.46875,
      -0.349609375,
      1.265625,
      -2.734375,
      -4.65625,
      -0.357421875,
      1.6484375,
      -8.5,
      2.6875,
      3.484375,
      -1.78125,
      1.9296875,
      0.6640625,
      -0.1337890625,
      -1.1640625,
      4,
      -2.3125,
      3.015625,
      -6.21875,
      -0.62109375,
      -3,
      -1.53125,
      1.3359375,
      -1.203125,
      2.53125,
      -0.0556640625,
      1.7265625,
      6.4375,
      0.50390625,
      -1.734375,
      3.34375,
      2.234375,
      -2.859375,
      3.390625,
      -3.625,
      -5.0625,
      5.5,
      -2.203125,
      -3.546875,
      -0.01129150390625,
      3.453125,
      -1.9609375,
      5,
      4,
      -2.78125,
      -1.421875,
      3.6875,
      4.84375,
      -2.390625,
      -0.82421875,
      0.54296875,
      -0.87890625,
      0.20703125,
      1.5625,
      1.9609375,
      -0.1474609375,
      -4.34375,
      4.84375,
      2.5625,
      1.6484375,
      0.21484375,
      0.6953125,
      -0.9453125,
      4.09375,
      1.609375,
      0.451171875,
      -2.515625,
      1.9140625,
      6.6875,
      -6.09375,
      -9.5,
      4.0625,
      2.421875,
      1.2890625,
      -0.86328125,
      1.34375,
      2.953125,
      -0.87890625,
      -4.4375,
      -4.75,
      -1.7734375,
      -2.828125,
      3.921875,
      3.125,
      -1.6796875,
      -2.859375,
      -5.34375,
      4.375,
      -0.36328125,
      4,
      0.4296875,
      -1.125,
      1.53125,
      -4.46875,
      3.078125,
      3.15625,
      7.65625,
      -3.96875,
      -1.21875,
      0.95703125,
      -10.25,
      1.4296875,
      -1.3125,
      1.1796875,
      1.3046875,
      2.4375,
      5,
      -3.34375,
      -1.3671875,
      0.439453125,
      4.25,
      -3.40625,
      -1.6328125,
      2.984375,
      -5,
      -0.201171875,
      2.3125,
      1.21875,
      0.400390625,
      -4.40625,
      -2.4375,
      1.25,
      0.8515625,
      1.9375,
      0.16796875,
      -2.328125,
      -2.6875,
      -3.515625,
      3.515625,
      2.109375,
      1.2421875,
      1.734375,
      -0.11328125,
      -4.5,
      -2.140625,
      -0.21484375,
      0.796875,
      -0.96484375,
      -0.63671875,
      0.443359375,
      0.8125,
      2.421875,
      -5.625,
      -0.0196533203125,
      0.396484375,
      -0.2333984375,
      -6.3125,
      0.9296875,
      1.078125,
      3.125,
      0.3828125,
      2.234375,
      -2.234375,
      -0.890625,
      -0.11279296875,
      -4.1875,
      -5.625,
      -2.0625,
      4.625,
      -2.875,
      -0.1875,
      -2.359375,
      1.6796875,
      1.703125,
      0.484375,
      2.328125,
      -0.828125,
      6.375,
      -0.392578125,
      -0.08203125,
      0.1962890625,
      4.84375,
      -1.265625,
      1.3671875,
      2.828125,
      0.39453125,
      -7.5,
      -5.3125,
      -5.21875,
      1.8515625,
      6.6875,
      -0.88671875,
      5.125,
      -0.34375,
      4.375,
      -1.4609375,
      1.625,
      -15.6875,
      2.4375,
      -0.53125,
      -6.90625,
      -1.84375,
      0.640625,
      2.984375,
      0.05810546875,
      2.046875,
      1.609375,
      -0.8671875,
      1.1953125,
      6.125,
      2.203125,
      -3.3125,
      5.21875,
      2.984375,
      -0.67578125,
      1.75,
      -0.42578125,
      -4.75,
      0.5546875,
      -2.515625,
      1.515625,
      3.03125,
      3.6875,
      3.3125,
      0.7890625,
      2.390625,
      -5.40625,
      2.3125,
      2.015625,
      2.59375,
      -0.0380859375,
      -0.173828125,
      -5.21875,
      6.03125,
      -4.625,
      3.453125,
      -1.625,
      -5.125,
      1.0546875,
      2.734375,
      -1.3046875,
      -1.984375,
      -0.99609375,
      -1.78125,
      3.546875,
      3.03125,
      -5.84375,
      0.46484375,
      -2.53125,
      -2.21875,
      3.375,
      -0.734375,
      -2.578125,
      -3.3125,
      2.703125,
      2.53125,
      -2.40625,
      7.5625,
      -0.5234375,
      -2.828125,
      1.5546875,
      -0.322265625,
      0.62109375,
      -2.484375,
      -0.2109375,
      1.28125,
      -3.6875,
      -3.9375,
      3.6875,
      1.828125,
      -4.21875,
      -1.7265625,
      -1.34375,
      -0.5625,
      1.90625,
      -0.59375,
      -2.546875,
      -4.21875,
      -0.55078125,
      1.796875,
      1.3515625,
      3.125,
      0.9296875,
      3.625,
      4.625,
      -2.609375,
      5.375,
      -4.4375,
      -3.609375,
      1.5859375,
      -3.03125,
      -3.59375,
      -2.5625,
      -0.37109375,
      1.1875,
      -3.078125,
      -3.765625,
      -2.75,
      -6.75,
      -3.421875,
      0.87109375,
      0.703125,
      3.546875,
      -2.28125,
      5.09375,
      -1.640625,
      -3.875,
      0.796875,
      -1.5625,
      1.796875,
      -2.265625,
      1.125,
      -4.03125,
      -0.390625,
      5.09375,
      3.671875,
      -5.375,
      5.84375,
      0.12890625,
      -1.578125,
      -1.5,
      2.8125,
      -3.40625,
      -0.41796875,
      -0.030029296875,
      -1.921875,
      -2,
      -3.53125,
      1.109375,
      -1.265625,
      3.78125,
      -0.330078125,
      0.26171875,
      -2.734375,
      -3.96875,
      -1.2265625,
      0.546875,
      -5.28125,
      3.09375,
      2.984375,
      0.400390625,
      1.3125,
      3.734375,
      4.1875,
      2.53125,
      0.0712890625,
      -1.921875,
      3.765625,
      3.3125,
      6,
      -3.03125,
      -5.375,
      -0.326171875,
      0.90234375,
      -2.90625,
      3.46875,
      -0.2294921875,
      1.7578125,
      3.796875,
      3.53125,
      -4.25,
      -2.234375,
      4.71875,
      -3.84375,
      0.2294921875,
      3.578125,
      2.40625,
      -0.28515625,
      5.71875,
      -1.53125,
      -5.46875,
      -2.03125,
      3.9375,
      3.140625,
      0.3671875,
      -0.94140625,
      2.53125,
      -0.302734375,
      5.09375,
      -2.25,
      -4.90625,
      2.609375,
      2.046875,
      -3.109375,
      0.74609375,
      6.46875,
      -0.93359375,
      2.203125,
      -0.76953125,
      1.1171875,
      1.484375,
      2.171875,
      2.625,
      0.71875,
      2.703125,
      0.140625,
      2.15625,
      0.69140625,
      -0.7890625,
      -3.828125,
      1.25,
      -0.03515625,
      -1.7421875,
      3.1875,
      -2.984375,
      -1.484375,
      -0.84375,
      0.447265625,
      0.88671875,
      3,
      6.625,
      -0.35546875,
      0.46484375,
      -0.7265625,
      4.625,
      -2.015625,
      5.71875,
      1.8046875,
      9.125,
      -2.171875,
      -3.171875,
      0.275390625,
      -2.21875,
      0.337890625,
      -2.375,
      -7.15625,
      -3.015625,
      -2.15625,
      -0.55078125,
      -3.125,
      2.109375,
      -3.875,
      -0.193359375,
      3.796875,
      1.359375,
      2.890625,
      3.578125,
      3.84375,
      -1.9296875,
      -0.59765625,
      -2.5,
      -2.46875,
      -1.0546875,
      0.6640625,
      0.76953125,
      -3.0625,
      0.330078125,
      1.2265625,
      5.5625,
      0.8828125,
      -0.49609375,
      -0.19140625,
      9.25,
      -0.0274658203125,
      0.546875,
      4.09375,
      0.765625,
      1.6015625,
      3.203125,
      3.859375,
      -3.71875,
      -4.1875,
      9.5,
      6.34375,
      -2.875,
      0.53515625,
      -0.045654296875,
      0.69921875,
      -5.625,
      -1.578125,
      2.40625,
      0.92578125,
      -5.4375,
      -1.8359375,
      3.015625,
      2.640625,
      -3.421875,
      1.015625,
      -1.1640625,
      -5.65625,
      3.21875,
      3.96875,
      1.6484375,
      2.40625,
      1.140625,
      4.40625,
      -0.99609375,
      -4.3125,
      -4.125,
      -0.53515625,
      -2.03125,
      -1.359375,
      0.953125,
      2.515625,
      4.0625,
      -1.2890625,
      0.65234375,
      -5.03125,
      -0.703125,
      -2.59375,
      1.8046875,
      2.640625,
      -3.828125,
      -0.02587890625,
      -2.4375,
      -8.875,
      -4.34375,
      -0.400390625,
      -3.15625,
      -1.3203125,
      -3.4375,
      -0.283203125,
      3.265625,
      -6.21875,
      -0.6875,
      -3.0625,
      -2.8125,
      3.03125,
      0.12158203125,
      0.83984375,
      -2.265625,
      1.640625,
      0.90625,
      -2.96875,
      2.59375,
      4.25,
      4.09375,
      3.3125,
      -2.296875,
      2.59375,
      -2.21875,
      7.15625,
      -1.921875,
      7.40625,
      3.703125,
      3.265625,
      -7.125,
      2.046875,
      0.2021484375,
      3.125,
      -5.03125,
      -1.59375,
      -2.734375,
      -1.3203125,
      0.49609375,
      -1.4296875,
      3.6875,
      -3.296875,
      -1.8359375,
      0.44921875,
      -3.140625,
      1.0859375,
      3.234375,
      2.796875,
      5.375,
      -1.4609375,
      0.69921875,
      0.48828125,
      1.6484375,
      3.4375,
      -2,
      3.90625,
      -3.453125,
      0.1767578125,
      -3.78125,
      1.703125,
      -1.3125,
      -1.375,
      0.12451171875,
      -1.4453125,
      0.419921875,
      2.25,
      1.21875,
      6.09375,
      1.640625,
      3.640625,
      0.515625,
      -2.4375,
      -0.0751953125,
      -0.419921875,
      7.375,
      1.5625,
      -1.3046875,
      -2.84375,
      -0.83203125,
      -3.59375,
      2.265625,
      -1.7109375,
      -6.8125,
      -0.11328125,
      0.07275390625,
      -7.25,
      3.4375,
      -1.1953125,
      -0.365234375,
      0.62109375,
      4.71875,
      2.671875,
      2.921875,
      -0.439453125,
      1.203125,
      0.423828125,
      -1.8828125,
      5.03125,
      -3.921875,
      0.55078125,
      6.3125,
      3.546875,
      3.328125,
      -4,
      -0.8515625,
      -1.5078125,
      1.5546875,
      5.4375,
      -2.25,
      -1.3203125,
      7.40625,
      0.05126953125,
      1.03125,
      -0.21484375,
      0.353515625,
      -0.64453125,
      -2.90625,
      1.34375,
      3.46875,
      3.75,
      -0.6640625,
      -1.3125,
      -6.8125,
      -0.76953125,
      -3.296875,
      -1.4921875,
      -2.203125,
      0.2158203125,
      -0.6875,
      0.18359375,
      -1.765625,
      -3,
      -0.6015625,
      -1.5625,
      0.1865234375,
      4.59375,
      0.37890625,
      0.416015625,
      -0.58984375,
      4.28125,
      -2.796875,
      4.125,
      1.3203125,
      -2.734375,
      2.171875,
      3.875,
      -4.4375,
      4.40625,
      6.4375,
      -1.015625,
      -0.109375,
      -2.9375,
      0.58984375,
      -1.2265625,
      -3.296875,
      0.7421875,
      -3.40625,
      1.234375,
      5.25,
      3.421875,
      -1.40625,
      1.015625,
      -1.15625,
      -0.1611328125,
      4.03125,
      -7,
      -2.578125,
      -1.6171875,
      -1.453125,
      -1.7734375,
      -1.578125,
      -2.796875,
      0.072265625,
      3.359375,
      -5.65625,
      4.90625,
      -4.375,
      6.6875,
      0.54296875,
      -2.71875,
      -0.287109375,
      -3.125,
      2.359375,
      -1.84375,
      2.671875,
      2.59375,
      -2.484375,
      3.6875,
      -0.5,
      -2.21875,
      -0.1455078125,
      -1.0234375,
      3.03125,
      0.291015625,
      2,
      0.1142578125,
      -0.65625,
      -5.625,
      -3.6875,
      -3.96875,
      -2.71875,
      -0.10205078125,
      1.4453125,
      0.04541015625,
      -0.8125,
      1.4453125,
      -2.515625,
      -0.2421875,
      -3.015625,
      -1.546875,
      0.85546875,
      1.171875,
      6.875,
      1.3828125,
      -0.3359375,
      1.2109375,
      -2.421875,
      -7.34375,
      -0.4140625,
      -1.7578125,
      2.28125,
      -1.3515625,
      -0.06103515625,
      1.3515625,
      1.34375,
      -1.140625,
      0.412109375,
      -0.59375,
      4.65625,
      4.3125,
      -0.765625,
      2.75,
      -0.004058837890625,
      0.8125,
      -3.78125,
      -3.765625,
      -5.90625,
      1.125,
      0.8671875,
      -5.03125,
      1.609375,
      -2.671875,
      1.2421875,
      2.6875,
      -3.453125,
      0.8125,
      -0.0673828125,
      2.5625,
      -1.8125,
      -2.46875,
      1.8203125,
      -2.15625,
      3.203125,
      -2.765625,
      -4.9375,
      -1.25,
      1.2734375,
      -0.71875,
      0.298828125,
      -1.78125,
      -2.3125,
      -1.390625,
      -0.408203125,
      -3.796875,
      -3.046875,
      3.046875,
      0.1708984375,
      2.65625,
      1.0625,
      -0.91796875,
      -0.75390625,
      0.4140625,
      1.8359375,
      6.875,
      1.1328125,
      -1.3125,
      0.384765625,
      -0.10986328125,
      4.90625,
      -1.7265625,
      -1.2421875,
      -6.53125,
      -3.109375,
      6.3125,
      -0.462890625,
      -2.34375,
      -0.19140625,
      -0.98046875,
      4.25,
      0.5703125,
      4,
      -1.40625,
      -0.080078125,
      -1.6171875,
      6.46875,
      2.328125,
      -4.34375,
      1.3125,
      2.6875,
      -5.03125,
      2.34375,
      4.15625,
      5.59375,
      -0.73046875,
      3.4375,
      -4.6875,
      -5.25,
      -5.8125,
      4.125,
      0.265625,
      -0.5,
      -1.0390625,
      -2.765625,
      -1.546875,
      1.296875,
      -0.283203125,
      3.34375,
      -4.4375,
      4.71875,
      0.412109375,
      2.875,
      1.0625,
      -3.96875,
      -2.53125,
      4.21875,
      2.734375,
      -3.59375,
      -1.46875,
      -4.03125,
      -2.3125,
      -0.890625,
      -7.21875,
      1.1875,
      0.396484375,
      1.2734375,
      5.03125,
      -0.1572265625,
      5,
      0.65625,
      -1.765625,
      -4.25,
      -1.5390625,
      1.1875,
      3.171875,
      2.15625,
      -3.46875,
      -0.828125,
      -1.6953125,
      0.76171875,
      -4.5625,
      4.875,
      -2.09375,
      3.890625,
      2.546875,
      1.5390625,
      -4.875,
      -2.453125,
      -1.703125,
      -0.353515625,
      -1.8203125,
      1.953125,
      0.8359375,
      -1.4609375,
      3.890625,
      0.71484375,
      -4.03125,
      0.263671875,
      -1.5078125,
      1.46875,
      2.234375,
      2.6875,
      -4.59375,
      2.734375,
      -6.28125,
      0.267578125,
      3.6875,
      -2.25,
      -1.296875,
      1.2265625,
      -0.189453125,
      3.75,
      1.8828125,
      0.427734375,
      -1.046875,
      4.125,
      -1.6328125,
      -3.1875,
      -4.90625,
      -0.625,
      -1.84375,
      -1.546875,
      3.828125,
      -6.375,
      3.53125,
      -2.78125,
      -5.1875,
      -0.439453125,
      -1.5703125,
      -0.166015625,
      3.765625,
      2.953125,
      -2.8125,
      -1.828125,
      -3.375,
      3.984375,
      2.171875,
      -3.0625,
      1.875,
      -0.52734375,
      0.78515625,
      -4.53125,
      3.859375,
      -0.9296875,
      -2.34375,
      3.78125,
      6,
      -5.34375,
      -1.765625,
      1.4609375,
      2.234375,
      -2.84375,
      -1.3671875,
      0.78125,
      5.15625,
      -3.453125,
      -0.26953125,
      -2.875,
      -1.1484375,
      2.5,
      -2.3125,
      -0.0576171875,
      1.34375,
      1.21875,
      -1.6171875,
      -2.984375,
      4.15625,
      3.609375,
      3.71875,
      -3.5625,
      0.75390625,
      1.5546875,
      0.47265625,
      2.5,
      -0.482421875,
      -3.25,
      -1.1484375,
      2.65625,
      -3.9375,
      -1.734375,
      -5.65625,
      -0.376953125,
      -2.671875,
      -0.82421875,
      -0.5390625,
      0.8125,
      -0.400390625,
      -1.7578125,
      -0.2099609375,
      -0.8359375,
      -4.4375,
      -2.953125,
      1.296875,
      -1.4140625,
      -5.46875,
      2.109375,
      2.484375,
      1.9453125,
      5.09375,
      4.625,
      1.3828125,
      -5.09375,
      2.90625,
      -2.296875,
      1.765625,
      -1.484375,
      -0.00634765625,
      -4.09375,
      -2.171875,
      3.15625,
      1.0078125,
      2.65625,
      -5.125,
      -4.40625,
      -5.53125,
      0.83984375,
      -3.296875,
      3.8125,
      -1.203125,
      2,
      4.3125,
      -0.578125,
      2.640625,
      0.57421875,
      -0.259765625,
      -7.40625,
      1.3046875,
      0.8359375,
      4.71875,
      3.046875,
      0.48828125,
      -5.3125,
      4.21875,
      2.15625,
      -3.953125,
      3.5625,
      0.1796875,
      1.3359375,
      -5.1875,
      2.78125,
      -0.02197265625,
      3.265625,
      -1.359375,
      2.515625,
      4.625,
      0.7109375,
      4.8125,
      3.59375,
      0.11474609375,
      -1.515625,
      3.03125,
      0.58984375,
      -4.78125,
      -1.15625,
      2.1875,
      -2.328125,
      -0.2138671875,
      2.546875,
      -0.054443359375,
      4.5625,
      -0.625,
      1.078125,
      0.027099609375,
      4.90625,
      -6.53125,
      1.6953125,
      -6.375,
      2.15625,
      -3.6875,
      1.3671875,
      -5.3125,
      0.56640625,
      2.6875,
      4.375,
      -1.2109375,
      -4.15625,
      2.84375,
      2.5,
      2.28125,
      -3.984375,
      3.15625,
      1.828125,
      -1.515625,
      -2.390625,
      -2.3125,
      4.28125,
      -0.50390625,
      1.921875,
      -4.84375,
      -0.314453125,
      0.07373046875,
      -2.21875,
      -3.015625,
      2.328125,
      -0.8046875,
      -7.0625,
      -5.5,
      -3.296875,
      0.23828125,
      -3.0625,
      2.359375,
      3.546875,
      -1.578125,
      1.5078125,
      -2.984375,
      4.09375,
      1.1875,
      -1.6328125,
      0.349609375,
      1.1015625,
      -1.3359375,
      -0.236328125,
      3.4375,
      -4.53125,
      -0.9375,
      -0.73828125,
      -0.10205078125,
      3.765625,
      -2.28125,
      -2.53125,
      -5.59375,
      -1.375,
      3.53125,
      3.0625,
      -1.3984375,
      -2.9375,
      2.390625,
      -0.59765625,
      -0.91796875,
      -0.89453125,
      0.7265625,
      0.36328125,
      -0.3515625,
      0.2138671875,
      -0.091796875,
      3.984375,
      0.283203125,
      1.734375,
      -0.8125,
      -1.4453125,
      -2.90625,
      -0.9921875,
      -3.921875,
      1.8984375,
      -0.6484375,
      3.328125,
      0.8515625,
      -1.390625,
      0.37890625,
      3.796875,
      2.59375,
      1.96875,
      -3.0625,
      0.41796875,
      5.5,
      5.1875,
      0.52734375,
      -1.3125,
      0.89453125,
      1.2109375,
      -2.3125,
      -0.419921875,
      -0.5546875,
      0.63671875,
      2.8125,
      -5.75,
      -0.796875,
      0.333984375,
      1.9453125,
      -1.921875,
      -9.3125,
      2.71875,
      0.1279296875,
      0.34375,
      -3.65625,
      0.92578125,
      3.953125,
      2.890625,
      1.1328125,
      2.625,
      2.90625,
      -0.3671875,
      2.75,
      20.625,
      -2.796875,
      -3.40625,
      2.078125,
      -2.65625,
      2.71875,
      6.125,
      1.1640625,
      -0.65625,
      1.953125,
      0.298828125,
      2.234375,
      -0.51171875,
      6.3125,
      -0.06201171875,
      2.5625,
      3.046875,
      1.4609375,
      -1.8828125,
      -5.1875,
      1.3671875,
      0.44921875,
      -0.333984375,
      2.21875,
      -3.34375,
      1.90625,
      2.28125,
      -1.0859375,
      -2.53125,
      -5.0625,
      -0.375,
      -0.57421875,
      1.1953125,
      -2.25,
      0.72265625,
      -2.59375,
      -0.74609375,
      1.96875,
      1.1953125,
      -0.95703125,
      -1.5234375,
      -2.8125,
      2.734375,
      -0.349609375,
      0.0242919921875,
      0.302734375,
      -2.140625,
      0.0174560546875,
      1.1015625,
      3.53125,
      -0.462890625,
      -3.734375,
      -1.9765625,
      1.3828125,
      1.046875,
      -2.15625,
      -2.84375,
      -6.125,
      -5.15625,
      -0.6171875,
      -1.1328125,
      -2.921875,
      -0.8984375,
      -3.15625,
      -2.21875,
      -3.875,
      -5.34375,
      -1.875,
      -2.578125,
      0.3984375,
      -7.1875,
      -1.7578125,
      5.75,
      5.625,
      -3.34375,
      -2.6875,
      0.279296875,
      2.21875,
      -0.396484375,
      3.71875,
      -3.953125,
      -1.3359375,
      -3.265625,
      0.384765625,
      -2.234375,
      1.046875,
      -6.03125,
      0.71484375,
      0.1396484375,
      -0.875,
      3.6875,
      -3.890625,
      1.9765625,
      -0.62109375,
      -5.1875,
      1.0859375,
      2.359375,
      0.0810546875,
      -2.515625,
      0.498046875,
      2.703125,
      0.65625,
      1.109375,
      -1.7578125,
      1.34375,
      -2.140625,
      3,
      0.0068359375,
      1.1484375,
      1.921875,
      -2.328125,
      5.09375,
      -0.45703125,
      -2.015625,
      1.4453125,
      4.5,
      -6,
      -3.375,
      -0.359375,
      -4.09375,
      2.8125,
      -0.181640625,
      0.0086669921875,
      0.25390625,
      -10.4375,
      -6,
      -0.275390625,
      -5.84375,
      3.1875,
      -3.03125,
      2.390625,
      -0.302734375,
      -2.46875,
      -4.25,
      0.75390625,
      -3.265625,
      4.4375,
      5.71875,
      0.84375,
      0.59375,
      -4.5625,
      2.1875,
      1.7421875,
      -2.4375,
      -1.6640625,
      2.734375,
      0.28125,
      3.109375,
      3.921875,
      1.1171875,
      -0.337890625,
      3.078125,
      0.390625,
      -3.125,
      -1.125,
      4.03125,
      -2.75,
      -1.71875,
      -2.578125,
      -0.890625,
      -0.6484375,
      0.025390625,
      -4.15625,
      -3.65625,
      -1.09375,
      -1.5,
      3.734375,
      -3.109375,
      -6.53125,
      3.703125,
      2.046875,
      -3.703125,
      0.2255859375,
      -1.2890625,
      3.296875,
      -2.8125,
      2,
      4.96875,
      -3.9375,
      1.109375,
      2.78125,
      4.09375,
      -0.09375,
      -5.5,
      2.15625,
      5.21875,
      -4.5,
      1.6015625,
      4.6875,
      -1.34375,
      1.8828125,
      -4.21875,
      -6.71875,
      5.75,
      2.5625,
      -4.375,
      -0.828125,
      -2.09375,
      0.6875,
      -3,
      -3.34375,
      2.203125,
      -0.67578125,
      2.296875,
      4.65625,
      0.65625,
      -3.96875,
      -2.15625,
      -2.21875,
      -1.1953125,
      -1.90625,
      4.03125,
      0.25390625,
      3.140625,
      -5.625,
      5.1875,
      3.359375,
      1.3828125,
      0.45703125,
      2.015625,
      3.328125,
      0.3125,
      -2.796875,
      -1,
      0.85546875,
      3.078125,
      -3.390625,
      1.546875,
      -3.25,
      2.171875,
      -1.875,
      2.09375,
      0.59375,
      1.3984375,
      -4.53125,
      -2.65625,
      -4.34375,
      3.1875,
      -0.2177734375,
      1.640625,
      2.109375,
      -0.091796875,
      0.004058837890625,
      1.09375,
      -1.4453125,
      1.046875,
      -0.6015625,
      1.625,
      1.109375,
      -1.65625,
      0.66796875,
      2.546875,
      3.046875,
      -1.421875,
      -0.58203125,
      -2.328125,
      -3.078125,
      0.5703125,
      -5.5,
      -1.203125,
      0.80859375,
      -5.5,
      3.28125,
      0.73046875,
      1.390625,
      -0.333984375,
      1.515625,
      -6.3125,
      6,
      2.59375,
      -5.59375,
      3.5,
      -1.546875,
      -3.4375,
      -0.15625,
      -1.453125,
      1.5,
      -5.1875,
      1.0234375,
      4.6875,
      -3.765625,
      2.3125,
      3.3125,
      -2.015625,
      -0.40625,
      -2.796875,
      4.84375,
      2.328125,
      4.71875,
      2.015625,
      2.515625,
      4.65625,
      -4.40625,
      2.25,
      -4.84375,
      -0.004852294921875,
      -2.140625,
      2.359375,
      -0.8515625,
      -3.171875,
      1.21875,
      4.1875,
      1.640625,
      -9.4375,
      -4.65625,
      0.056884765625,
      -2.46875,
      4.75,
      3.21875,
      0.6796875,
      -2.625,
      0.294921875,
      3.890625,
      3.265625,
      1,
      -1.40625,
      -3.25,
      0.447265625,
      1.9453125,
      -6.78125,
      1.0078125,
      -0.71875,
      -4.5,
      -1,
      -2.421875,
      -3.515625,
      -0.1513671875,
      6.3125,
      -3.328125,
      0.8359375,
      1.8359375,
      1.359375,
      3.40625,
      2.875,
      1.09375,
      1.6328125,
      -5.5,
      -8.75,
      -2.4375,
      -0.3046875,
      -0.5625,
      2.03125,
      -1.3203125,
      3.640625,
      -0.8046875,
      2.953125,
      -4.84375,
      5.53125,
      1.9375,
      -7.53125,
      3.140625,
      -1.9765625,
      -0.3125,
      -2.90625,
      -3.0625,
      -1.1875,
      1.625,
      1.1484375,
      -1.828125,
      3.171875,
      0.8671875,
      0.96875,
      1.9921875,
      -4.4375,
      -1.3359375,
      0.7578125,
      2.546875,
      -2.640625,
      4.1875,
      4.46875,
      -0.34375,
      -2.34375,
      -0.96875,
      3.453125,
      -0.0859375,
      -3.984375,
      4.21875,
      1.3125,
      -0.486328125,
      -0.271484375,
      -3.5,
      0.1533203125,
      -0.1513671875,
      -1.265625,
      0.90234375,
      -0.4296875,
      0.703125,
      -1.234375,
      -0.162109375,
      1.5,
      -1.0234375,
      -2.328125,
      -1.421875,
      -1.1015625,
      0.365234375,
      4.09375,
      -0.35546875,
      -2.640625,
      -2.265625,
      3.34375,
      1.1875,
      -1.4453125,
      -4.09375,
      0.5625,
      -1.9375,
      -3.1875,
      -3.578125,
      1.390625,
      -1.5546875,
      -2.46875,
      -0.486328125,
      -1.1796875,
      -0.01458740234375,
      -4.4375,
      -1.3828125,
      3.265625,
      1.2734375,
      -2.890625,
      -0.294921875,
      -0.7265625,
      -0.11181640625,
      1.0390625,
      -3.640625,
      -0.41796875,
      -0.19140625,
      1.859375,
      -5.53125,
      -3.90625,
      2.8125,
      -2.21875,
      2.125,
      5.125,
      0.63671875,
      1.296875,
      2.953125,
      -3.109375,
      -2.40625,
      5.90625,
      2.4375,
      -1.609375,
      1.8359375,
      0.7578125,
      -2.25,
      5.0625,
      6.75,
      -3.15625,
      -2.859375,
      -1.0625,
      -1.6171875,
      -0.9609375,
      -2.015625,
      1.3203125,
      -0.0081787109375,
      -5.71875,
      6.6875,
      -3.359375,
      3.75,
      1.3203125,
      -1.9140625,
      4.375,
      -1.109375,
      0.578125,
      0.55859375,
      0.72265625,
      4.1875,
      -6.25,
      1.8671875,
      -4.375,
      -3.078125,
      -0.283203125,
      0.36328125,
      2.28125,
      1.8203125,
      4.125,
      0.99609375,
      -2.03125,
      -4.5625,
      -0.83984375,
      5.15625,
      -0.671875,
      -4.03125,
      1.09375,
      -4.03125,
      0.2451171875,
      -1.421875,
      0.921875,
      -4.03125,
      -1.265625,
      -2.4375,
      1.4453125,
      3.359375,
      0.482421875,
      -2.921875,
      -1.640625,
      -2.234375,
      2.71875,
      3.796875,
      0.40234375,
      0.984375,
      3.75,
      0.208984375,
      0.1103515625,
      7.625,
      3.859375,
      1.625,
      -1.6875,
      1,
      0.828125,
      1.90625,
      -1.7734375,
      -0.4453125,
      1.5234375,
      3.546875,
      5.21875,
      -2.15625,
      1.46875,
      -0.79296875,
      0.80859375,
      -2.21875,
      -0.7109375,
      -0.058349609375,
      1.828125,
      -0.859375,
      2.03125,
      -0.043212890625,
      2.40625,
      0.1875,
      -0.81640625,
      -2.921875,
      -1.4453125,
      -1.8671875,
      1.5546875,
      -0.8671875,
      -0.8984375,
      -1.203125,
      0.1279296875,
      2.65625,
      0.30078125,
      -4.375,
      2.140625,
      1.7265625,
      -1.171875,
      4.96875,
      -2.234375,
      0.06689453125,
      2.296875,
      0.0311279296875,
      -1.1328125,
      3.5,
      -2.578125,
      2.28125,
      -0.671875,
      -0.380859375,
      2.453125,
      2.796875,
      0.2158203125,
      1.3125,
      -1.609375,
      0.70703125,
      1.921875,
      -1.2109375,
      -1.328125,
      -3.234375,
      2.109375,
      -1.734375,
      -1.234375,
      -0.306640625,
      0.9296875,
      -1.96875,
      1.5,
      -2.21875,
      -2.78125,
      -0.60546875,
      -3.078125,
      0.97265625,
      0.0264892578125,
      3.546875,
      1.6796875,
      1.1953125,
      -0.458984375,
      -2.28125,
      -2.953125,
      -0.341796875,
      -2.1875,
      -1.359375,
      -0.12890625,
      1.0703125,
      -0.73828125,
      2.890625,
      0.251953125,
      -0.93359375,
      -2.140625,
      0.82421875,
      -0.2275390625,
      1.875,
      0.435546875,
      -0.1806640625,
      1.5,
      0.447265625,
      1.015625,
      1.6875,
      -0.1650390625,
      -0.322265625,
      0.59375,
      0.94921875,
      1.46875,
      1.5,
      -1.53125,
      0.4609375,
      1.4296875,
      -1.2890625,
      0.51171875,
      2.140625,
      1.1484375,
      0.0322265625,
      -2.25,
      2.3125,
      -1.328125,
      -0.1220703125,
      2.28125,
      1.40625,
      -4.1875,
      -0.8828125,
      -0.72265625,
      -1.7734375,
      -0.65625,
      -2.140625,
      -1.2109375,
      0.98828125,
      -2.828125,
      0.6328125,
      3.484375,
      3.21875,
      -2.0625,
      1.109375,
      1.96875,
      -3.640625,
      -1.921875,
      0.5078125,
      0.35546875,
      1.2421875,
      -2.609375,
      -4.25,
      -0.76171875,
      -0.20703125,
      0.8359375,
      0.9609375,
      -0.91015625,
      -1.859375,
      -1.25,
      2.859375,
      0.380859375,
      -5.875,
      -0.294921875,
      -0.85546875,
      0.62890625,
      2.171875,
      1.484375,
      1.7578125,
      2.53125,
      -1.3203125,
      1.125,
      -0.82421875,
      -1.4453125,
      -0.019775390625,
      2.34375,
      -2.0625,
      -3.96875,
      0.447265625,
      -2.921875,
      -0.796875,
      -0.86328125,
      0.94921875,
      0.439453125,
      1.15625,
      0.64453125,
      -0.51953125,
      -1.9921875,
      1.1015625,
      -0.45703125,
      0.490234375,
      0.67578125,
      3.046875,
      4.03125,
      2.390625,
      1.3125,
      0.1640625,
      -0.8515625,
      0.0186767578125,
      -0.69140625,
      1.203125,
      -0.1474609375,
      -4.8125,
      0.78515625,
      2.359375,
      2.015625,
      2.96875,
      -0.5390625,
      1.8828125,
      1.5390625,
      -3.796875,
      2.84375,
      3.359375,
      2.21875,
      -0.50390625,
      0.22265625,
      -0.8828125,
      -0.78515625,
      -0.494140625,
      1.9375,
      -1.953125,
      1.5703125,
      -0.84375,
      -1.8359375,
      -0.11865234375,
      -0.21875,
      4.8125,
      1.3359375,
      1.3203125,
      -1.4765625,
      3.734375,
      -3.265625,
      1.0390625,
      -0.18359375,
      0.7734375,
      -1.4921875,
      2.765625,
      -3.140625,
      0.267578125,
      0.7265625,
      1.9296875,
      1.15625,
      0.34375,
      -0.58203125,
      -2.609375,
      -2.4375,
      1.078125,
      -2.234375,
      0.92578125,
      3.609375,
      1.7890625,
      -0.474609375,
      -0.2255859375,
      -2.625,
      -0.67578125,
      0.953125,
      2.28125,
      0.1572265625,
      2.515625,
      -0.2080078125,
      1.8203125,
      -1.1796875,
      -0.51953125,
      -1.46875,
      -1.1171875,
      -2,
      2.171875,
      2.671875,
      -0.4765625,
      -1.0546875,
      -1,
      -0.25390625,
      5.03125,
      -0.60546875,
      -1.125,
      2.21875,
      -1.0703125,
      -2.1875,
      -1.8671875,
      -1.96875,
      0.66796875,
      2.109375,
      3.875,
      -0.72265625,
      4.40625,
      -2.484375,
      -1.8125,
      1.53125,
      -1.1875,
      -2.65625,
      -3.109375,
      -1.703125,
      3,
      0.33984375,
      0.3984375,
      1.453125,
      4.15625,
      -0.08203125,
      0.98046875,
      -2.078125,
      1.5234375,
      3.875,
      -0.034912109375,
      -5.4375,
      0.22265625,
      -0.90234375,
      2.046875,
      1.15625,
      -0.7265625,
      1.515625,
      4.34375,
      1.359375,
      1.4609375,
      -0.302734375,
      -0.384765625,
      -0.427734375,
      2.078125,
      4.15625,
      -3.734375,
      2.453125,
      0.048583984375,
      -3.046875,
      -1.1015625,
      2.75,
      3.078125,
      -0.75390625,
      2.46875,
      0.53515625,
      1.1328125,
      -1.5078125,
      1.46875,
      1.3359375,
      1.4140625,
      -0.609375,
      -1.0234375,
      -0.953125,
      1.796875,
      -3.53125,
      3.46875,
      -1.8828125,
      -0.60546875,
      1.484375,
      -0.404296875,
      0.95703125,
      1.6796875,
      -1.0859375,
      5.8125,
      -2.1875,
      -1.34375,
      2.671875,
      -1.375,
      0.65625,
      1.328125,
      0.9140625,
      -1.046875,
      3.9375,
      0.396484375,
      -3.171875,
      0.6171875,
      -0.75390625,
      -1.2109375,
      0.92578125,
      -4.875,
      0.35546875,
      -0.35546875,
      3.671875,
      -1.2890625,
      1.4140625,
      5.40625,
      1.703125,
      1.9140625,
      2.578125,
      1.46875,
      1.78125,
      -2.390625,
      -2.015625,
      1.9765625,
      -2.28125,
      -1.8203125,
      -0.8828125,
      0.291015625,
      -2.15625,
      -4.625,
      0.02783203125,
      -0.2421875,
      -0.051513671875,
      -1.2734375,
      -3.109375,
      -1.171875,
      1.1015625,
      -2.4375,
      0.15234375,
      -1.7578125,
      -0.96875,
      -0.06591796875,
      -1.3046875,
      -0.0201416015625,
      1.7109375,
      1.28125,
      0.4140625,
      0.279296875,
      -0.8828125,
      0.416015625,
      0.0830078125,
      -2.125,
      1.25,
      4.46875,
      -2.71875,
      -0.30859375,
      -1.109375,
      1.1640625,
      -0.90625,
      0.1025390625,
      -0.546875,
      -2.109375,
      2.71875,
      3.171875,
      1.2421875,
      0.203125,
      0.41015625,
      0.3515625,
      -1.6171875,
      -2.15625,
      0.54296875,
      -1.734375,
      1.1328125,
      2.09375,
      0.11962890625,
      1.859375,
      -2.5,
      0.65234375,
      1.0546875,
      -4.46875,
      0.59765625,
      -1.9296875,
      0.01953125,
      0.34765625,
      1.5390625,
      -2.046875,
      -2.5625,
      1.671875,
      -4.78125,
      1.2265625,
      -2.25,
      -2.921875,
      0.19140625,
      1.6328125,
      -0.10595703125,
      3.640625,
      -2.734375,
      0.85546875,
      5.46875,
      4.71875,
      1.6171875,
      0.578125,
      -3.734375,
      0.79296875,
      -2.859375,
      1.5234375,
      -4.71875,
      -2.390625,
      1.0234375,
      -0.482421875,
      -0.765625,
      0.83984375,
      1.6796875,
      -0.72265625,
      -1.8046875,
      -0.9921875,
      2.3125,
      -0.20703125,
      -1.8671875,
      2.828125,
      -1.390625,
      -0.30078125,
      -3.953125,
      -1.5234375,
      0.7734375,
      2.859375,
      0.90625,
      -0.421875,
      1.3984375,
      -0.61328125,
      2.21875,
      -1.9375,
      0.8125,
      1.734375,
      -1.203125,
      -1.9296875,
      -2.515625,
      -1.8828125,
      -1.2109375,
      -1.984375,
      1.828125,
      -0.765625,
      -0.96875,
      2.96875,
      -0.875,
      -3.3125,
      -2.4375,
      1.859375,
      -0.07275390625,
      0.71484375,
      0.271484375,
      -1.40625,
      2.5625,
      -0.92578125,
      1.25,
      -0.39453125,
      1.3203125,
      -0.51953125,
      0.609375,
      -2.125,
      -2.75,
      -3.1875,
      -0.197265625,
      1.71875,
      2.65625,
      1.0390625,
      -0.8046875,
      2.578125,
      2.4375
    ],
    "summary": "通过设计交互式提示模式优化ChatGPT生成高等教育测验题目，并采用盲测调查法让利益相关者（讲师与学习者）对生成题目质量进行评估。",
    "structure": {
      "sections": [
        {
          "title": "AchatGPT-BASED APPROACH FOR QUESTIONS GENERATION IN HIGHER EDUCATION",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 47
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 53
        },
        {
          "title": "2 Related works",
          "level": 1,
          "start_line": 68
        },
        {
          "title": "3 Research design",
          "level": 1,
          "start_line": 93
        },
        {
          "title": "3.1 Choosing a subject for experimentation",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "3.2 The investigation of appropriate Prompt patterns",
          "level": 1,
          "start_line": 105
        },
        {
          "title": "3.2.1 For multiple-choice questions",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "3.2.2 For True-False statements",
          "level": 1,
          "start_line": 131
        },
        {
          "title": "3.2.3 For Real-Scenario/Calculative exercises",
          "level": 1,
          "start_line": 147
        },
        {
          "title": "3.3 Evaluation methods and test results",
          "level": 1,
          "start_line": 161
        },
        {
          "title": "3.4 Preliminary self-assessment and optimization utilizing ChatGPT.",
          "level": 1,
          "start_line": 163
        },
        {
          "title": "3.5 The \"Blind Test\" method",
          "level": 1,
          "start_line": 173
        },
        {
          "title": "3.6 Result of evaluation",
          "level": 1,
          "start_line": 185
        },
        {
          "title": "3.6.1 Survey assumption",
          "level": 1,
          "start_line": 187
        },
        {
          "title": "3.6.2 General analysis",
          "level": 1,
          "start_line": 199
        },
        {
          "title": "3.6.3 Specific analysis",
          "level": 1,
          "start_line": 209
        },
        {
          "title": "4 Conclusion",
          "level": 1,
          "start_line": 244
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 250
        }
      ]
    },
    "suggested_tags": [
      "教育科技",
      "大语言模型",
      "提示工程",
      "自动问答生成"
    ],
    "tag_suggestions": [
      {
        "name": "教育科技",
        "confidence": 0.95,
        "reason": "论文核心研究场景是高等教育，探索利用AI技术辅助教学评估，属于教育技术（EdTech）的典型应用。"
      },
      {
        "name": "大语言模型",
        "confidence": 0.9,
        "reason": "研究基于ChatGPT这一具体的大语言模型（LLM）进行应用探索，是论文采用的核心技术。"
      },
      {
        "name": "提示工程",
        "confidence": 0.85,
        "reason": "论文重点贡献之一是设计交互式提示模式（prompting patterns）以优化与ChatGPT的交互，这是当前LLM应用的关键方法。"
      },
      {
        "name": "自动问答生成",
        "confidence": 0.8,
        "reason": "论文的具体任务是利用AI自动生成测验题目（quiz questions），这是自然语言处理在教育领域的一个具体任务。"
      }
    ],
    "category": "教育科技"
  },
  "27e18ce7-8ba5-4887-bd0e-8aead7e78240": {
    "id": "27e18ce7-8ba5-4887-bd0e-8aead7e78240",
    "filename": "2410.09576v1.pdf",
    "file_path": "data/uploads/4fb8d8f7-e088-4e16-a829-e48afdbeef00/27e18ce7-8ba5-4887-bd0e-8aead7e78240_2410.09576v1.pdf",
    "status": "completed",
    "created_at": "2025-12-16 23:15:44.214753",
    "updated_at": "2025-12-16 15:17:15.094587",
    "user_id": "4fb8d8f7-e088-4e16-a829-e48afdbeef00",
    "title": "The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models",
    "markdown_content": "# The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models\n\nSubhankar Maity  \nDepartment of Artificial Intelligence  \nIndian Institute of Technology Kharagpur  \nsubhankar.ai@kgpian.iitkgp.ac.in\n\nAniket Deroy  \nComputer Science & Engineering  \nIndian Institute of Technology Kharagpur  \nroydanik18@kgpian.iitkgp.ac.in\n\nIn recent years, large language models (LLMs) and generative AI have revolutionized natural language processing (NLP), offering unprecedented capabilities in education. This chapter explores the transformative potential of LLMs in automated question generation and answer assessment. It begins by examining the mechanisms behind LLMs, emphasizing their ability to comprehend and generate human-like text. The chapter then discusses methodologies for creating diverse, contextually relevant questions, enhancing learning through tailored, adaptive strategies. Key prompting techniques, such as zero-shot and chain-of-thought prompting, are evaluated for their effectiveness in generating high-quality questions, including open-ended and multiple-choice formats in various languages. Advanced NLP methods like fine-tuning and prompt-tuning are explored for their role in generating task-specific questions, despite associated costs. The chapter also covers the human evaluation of generated questions, highlighting quality variations across different methods and areas for improvement. Furthermore, it delves into automated answer assessment, demonstrating how LLMs can accurately evaluate responses, provide constructive feedback, and identify nuanced understanding or misconceptions. Examples illustrate both successful assessments and areas needing improvement. The discussion underscores the potential of LLMs to replace costly, time-consuming human assessments when appropriately guided, showcasing their advanced understanding and reasoning capabilities in streamlining educational processes.\n\nKeywords: Natural Language Processing (NLP), Large Language Models (LLMs), Education, Automated Question Generation (AQG), Answer Assessment, Prompt Engineering\n\n# 1. INTRODUCTION\n\nThe educational landscape is evolving rapidly, driven by the integration of advanced technologies that challenge traditional teaching methods. Among these technologies, Large Language Models (LLMs) have emerged as powerful tools, capable of revolutionizing the way we approach learning and assessment. These models, epitomized by systems such as GPT-4 (Achiam et al., 2023) and beyond, have demonstrated an extraordinary ability to understand and generate human-like text, enabling them to perform tasks that were once the exclusive domain\n\nof human educators (Brown et al., 2020; Floridi and Chiriatti, 2020). In the realm of education, question generation and assessment are critical components that shape the learning experience. Traditionally, these tasks require significant human effort, involving educators in the meticulous design of questions that not only test knowledge but also promote deeper understanding (Mazidi and Nielsen, 2014). Assessing student responses, particularly in open-ended formats, is another labor-intensive task that demands careful consideration of context, nuance, and individual student needs (Chappuis et al., 2015). However, as the demand for personalized and adaptive learning grows, the limitations of human-driven approaches have become more apparent.\n\nThis chapter delves into the transformative potential of LLMs in automating these crucial educational tasks. We explore how LLMs can be leveraged to generate a wide variety of questions—ranging from simple factual queries to complex, open-ended questions—that are contextually relevant and aligned with educational goals (Maity et al., 2023; Maity et al., 2024a; Maity et al., 2024c). We also examine the capabilities of LLMs in automated answer assessment, where these models can evaluate student responses, offer feedback, and even identify subtle misconceptions, all at a scale and efficiency that human educators cannot match (Fagbohun et al., 2024). The introduction of LLMs into the educational process is not without challenges. Issues such as the quality and relevance of generated questions, the accuracy of automated assessments, and the ethical implications of relying on AI for education require careful consideration (Floridi and Cowls, 2022).\n\nThis chapter addresses these concerns, offering insights into how LLMs can be guided and refined to ensure they complement and enhance human-led education rather than replacing it. In the sections that follow, we will first provide a detailed overview of LLMs, focusing on their architecture and underlying mechanisms. This will set the stage for a discussion on various methodologies and prompting techniques used to generate educational questions. We will then explore the role of advanced NLP methods such as fine-tuning and prompt-tuning in enhancing the quality and specificity of generated questions. The chapter will also cover human evaluation metrics for assessing the quality of these questions and the performance of LLMs in automated answer assessment. Finally, we will discuss the broader implications of integrating LLMs into education, highlighting both their potential benefits and the challenges that must be addressed to fully realize their capabilities.\n\n# 2. UNDERSTANDING LARGE LANGUAGE MODELS IN EDUCATION\n\n# 2.1. THE ARCHITECTURE AND MECHANISMS OF LLMS\n\nLarge Language Models (LLMs), built on the foundations of deep learning and transformer architectures (Vaswani et al., 2017), have brought about a paradigm shift in natural language processing (NLP). These models, trained on vast corpora of text data, are designed to predict and generate text based on a given input (Radford et al., 2019). Their ability to understand context, recognize patterns, and generate coherent, contextually appropriate text makes them particularly well-suited for educational applications.\n\nAt the core of LLMs is the transformer architecture, which uses self-attention mechanisms to weigh the importance of different words in a sentence relative to each other (Vaswani et al., 2017). This allows the model to capture long-range dependencies in text, making it capable of understanding complex sentences and generating nuanced responses. For educational purposes, this means LLMs can generate questions that are not only grammatically correct but also context\n\ntually relevant and pedagogically sound. The training process of LLMs involves exposure to diverse datasets that cover a wide range of topics and writing styles (Raiaan et al., 2024). This extensive training enables the models to develop a broad understanding of language, which they can then apply to specific tasks such as question generation and assessment. However, while LLMs excel in generating human-like text, their effectiveness in educational contexts depends on how well they are guided and fine-tuned for specific tasks.\n\n# 2.2. THE ROLE OF FINE-TUNING AND PROMPT-TUNING\n\nTo adapt LLMs for educational question generation and assessment, techniques such as fine-tuning and prompt-tuning are employed. Fine-tuning involves training the LLM on a specialized dataset that is closely aligned with the target task. This allows the model to learn the nuances of educational content and generate questions that are more closely aligned with the curriculum and learning objectives (Li et al., 2023).\n\nPrompt-tuning, on the other hand, involves designing specific prompts that guide the LLM in generating the desired output (Lester et al., 2021). This technique leverages the model's existing knowledge and directs it towards generating contextually relevant and pedagogically valuable questions. For instance, a prompt might instruct the LLM to generate a question based on a specific passage of text, encouraging the model to focus on key concepts and ideas that are essential for learning.\n\nBoth fine-tuning and prompt-tuning have their advantages and challenges. Fine-tuning can produce highly specialized models that excel in specific tasks, but it is resource-intensive and requires access to large, high-quality datasets (Raffel et al., 2020). Prompt-tuning, while more flexible and less resource-demanding, relies heavily on the design of effective prompts and may not always achieve the same level of specificity as fine-tuned models (Lester et al., 2021). Despite these challenges, both techniques have shown significant promise in enhancing the performance of LLMs in educational settings.\n\n# 3. AUTOMATED QUESTION GENERATION: METHODOLOGIES AND TECHNIQUES\n\n# 3.1. GENERATING Diverse AND CONTEXTUALLY RELEVANT QUESTIONS\n\nThe automated generation of questions using large language models (LLMs) represents a powerful tool in education, enabling the creation of diverse and contextually relevant questions tailored to various learning objectives (Maity et al., 2024a). The methodologies employed in question generation are varied, each contributing to the quality and applicability of the generated content. Below are the key methods utilized in this domain:\n\n- Zero-Shot Prompting: Zero-shot learning allows models like GPT-3 (Brown et al., 2020) to generate questions based on minimal instructions. The model leverages its pre-trained knowledge to generate relevant questions directly from the provided text, without the need for additional examples or fine-tuning (Brown et al., 2020). This approach is particularly useful for generating questions across a wide range of topics, but the quality may vary depending on the complexity of the input text (Maity et al., 2023; Maity et al., 2024b).  \n- Few-Shot Prompting: Few-shot prompting provides the model with a few examples of the task to guide its question generation. By including a few question-answer pairs as\n\npart of the prompt, this method enhances the model's understanding of the task, leading to improved relevance and quality of the generated questions (Brown et al., 2020). This technique is effective in scenarios where the desired question format or content is more complex and needs to be clearly defined for the model.\n\n- Chain-of-Thought Prompting: A structured technique that involves guiding the LLM through a step-by-step reasoning process before it generates the final question. For example, the model may first be asked to summarize a passage, identify key concepts, and then generate a question that tests understanding of these concepts (Wei et al., 2022; Maity et al., 2024d). This approach is particularly effective for generating higher-order questions that require critical thinking and analysis, ensuring that the questions align with specific educational goals.  \n- Fine-Tuning: Fine-tuning involves further training the LLM on a specific dataset of questions and answers relevant to the target domain. By learning the patterns and structures of effective questions from the training data, fine-tuning allows the model to generate more accurate and context-specific questions (Raffel et al., 2020). This method is resource-intensive but results in highly specialized models that can produce high-quality questions tailored to specific subjects or curricula (Maity et al., 2023).  \n- Prompt-Tuning: A recent and computationally efficient technique, prompt-tuning involves adjusting a small set of parameters (the prompt) while leaving the rest of the model unchanged. This method has proven effective in generating high-quality questions across various educational contexts, especially when the goal is to adapt a general-purpose LLM to a specific task without extensive retraining (Lester et al., 2021). Prompt-tuning allows for quick adaptation and customization of LLMs to generate questions that are both relevant and aligned with specific educational objectives.  \n- Multifacet and Multilingual Question Generation: LLMs are capable of generating both open-ended (Maity et al., 2023) and multiple-choice questions (Maity et al., 2024d), catering to different assessment needs. Open-ended questions encourage critical thinking and exploration, while multiple-choice questions are useful for evaluating specific knowledge or skills (Maity et al., 2024d). Additionally, the multilingual capabilities of LLMs enable the generation of questions in various languages, making them valuable tools for language learning and cross-cultural education (Radford et al., 2019; Maity et al., 2024d).\n\nThese methodologies, when applied effectively, enhance the educational process by generating diverse, high-quality questions that cater to different learning contexts and objectives. As LLMs continue to evolve, the integration of these techniques will further improve the relevance, accuracy, and utility of automated question generation in education.\n\n# 3.2. TYPES OF QUESTIONS GENERATED BY LLMS\n\nIn the context of education, different types of questions serve varied pedagogical functions, and LLMs are capable of generating a broad spectrum of question types. Below are the primary categories:\n\n- Factual Questions: These questions focus on the recall of specific information, such as dates, definitions, or events. They are typically straightforward and aim to assess the student's memory and basic understanding of the subject matter (Mulla and Gharpure, 2023).\n\nExample: \"What is the capital of France?\"\n\n- Open-Ended Questions: Open-ended questions are designed to encourage deep thinking and exploration, allowing students to express their thoughts freely and creatively. These questions do not have a single correct answer, promoting critical thinking and discussion (Mulla and Gharpure, 2023; Maity et al., 2023).\n\nExample: \"What does purchasing power parity do?\"\n\n- Multiple-Choice Questions (MCQs): MCQs assess specific knowledge or skills by providing a set of possible answers from which the student must choose the correct one. They are widely used for their efficiency in testing and grading (Maity et al., 2024d).\n\nExample: \"Which of the following is the largest planet in our solar system?\n\n(a) Earth (b) Jupiter (c) Mars (d) Venus\"\n\nLLMs, through their sophisticated language processing capabilities, can generate these varied question types effectively, adapting them to different educational contexts and learning objectives.\n\n# 4. AUTOMATED ANSWER ASSESSMENT: EVALUATING STUDENT RESPONSES\n\n# 4.1. THE CAPABILITIES OF LLMS IN AUTOMATED ANSWER ASSESSMENT\n\nIn addition to generating questions, LLMs have demonstrated significant potential in automated answer assessment (Fagbohun et al., 2024). The ability to accurately evaluate student responses and provide feedback is a critical component of the educational process (Fagbohun et al., 2024). Traditionally, this task has been performed by human educators, who must carefully consider the content, context, and nuance of each response (Balfour, 2013). However, as the demand for personalized and scalable education grows, the limitations of human-driven assessment become more apparent (Luckin and Holmes, 2016).\n\nLLMs offer a scalable solution to automated answer assessment, with the ability to evaluate a wide range of responses, from simple factual answers to complex, open-ended essays (Fagbohun et al., 2024). By leveraging their deep understanding of language and context, LLMs can identify key concepts, assess the accuracy of the response, and provide constructive feedback (Stamper et al., 2024). This capability is particularly valuable in large-scale educational settings, where the volume of student responses can be overwhelming for human assessors (Broadbent et al., 2018).\n\nOne of the key strengths of LLMs in automated assessment is their ability to identify nuanced understanding or misconceptions in student responses (Kazi, 2023). For example, an LLM can evaluate an essay on a historical event, recognizing whether the student has grasped the underlying causes and implications of the event, rather than simply recounting facts (Kasneci et al., 2023).\n\nHowever, while LLMs have shown great promise in automated assessment, there are challenges to be addressed (Fagbohun et al., 2024). One of the primary concerns is the accuracy and\n\nconsistency of the assessments. LLMs, like all AI systems, are not infallible and can sometimes produce incorrect or biased evaluations (Owan et al., 2023). Ensuring that the assessments are fair, accurate, and aligned with the learning objectives is crucial for the successful integration of LLMs into the educational process (Fagbohun et al., 2024).\n\n# 4.2. EXAMPLES OF SUCCESSFUL ASSESSMENTS AND AREAS FOR IMPROVEMENT\n\nTo illustrate the capabilities of LLMs in automated answer assessment, consider the following examples:\n\n- Short-Answer Evaluation: An LLM is tasked with evaluating short-answer responses in a biology exam (Shin and Gierl, ). The model is able to accurately assess whether the student has correctly identified the function of a specific organelle within a cell, providing feedback on both correct and incorrect answers. The LLM also identifies common misconceptions, such as confusing the roles of the mitochondria and the nucleus, and provides corrective feedback to guide the student's learning.  \n- Essay Grading: In a history class, students are asked to write essays on the causes and effects of World War II. The LLM evaluates the essays based on criteria such as understanding of key events, analysis of historical factors, and coherence of argument. The model is able to identify well-reasoned arguments and provide feedback on areas where the student could improve, such as providing more evidence or considering alternative perspectives (Mansour et al., 2024; Henkel et al., 2024).  \n- Multiple-Choice Question Analysis: An LLM is used to analyze student responses to multiple-choice questions in a mathematics exam (Henkel et al., 2024). In addition to identifying the correct answers, the model also analyzes the patterns of incorrect responses, identifying common errors and misconceptions. This information is used to provide targeted feedback and suggest areas for further study.\n\nWhile these examples demonstrate the potential of LLMs in automated assessment, there are also areas for improvement. One challenge is ensuring that the feedback provided by the LLM is constructive and actionable (Meyer et al., 2024a). For instance, while the model may correctly identify an error in a student's response, it must also provide clear guidance on how to address the mistake. Additionally, the LLM must be able to adapt its feedback to the individual needs of each student, taking into account their prior knowledge and learning style.\n\nAnother area for improvement is the ability of LLMs to assess more complex and creative responses, such as those involving critical thinking, problem-solving, or artistic expression. While LLMs have made significant strides in understanding and generating text, evaluating these higher-order skills remains a challenge (Hsiao et al., 2023). Future research and development will be needed to enhance the capabilities of LLMs in these areas, ensuring that they can fully support the diverse needs of learners.\n\n# 5. HUMAN EVALUATION AND QUALITY METRICS FOR GENERATED QUESTIONS\n\n# 5.1. ASSESSING THE QUALITY OF GENERATED QUESTIONS\n\nThe quality of questions generated by LLMs is a critical factor in their effectiveness as educational tools. High-quality questions should be clear, relevant, and aligned with the learning objectives, challenging students to think critically and apply their knowledge. To ensure that the questions generated by LLMs meet these standards, human evaluation and quality metrics play a crucial role (Kurdi et al., 2020).\n\nHuman evaluation involves assessing the generated questions based on a set of predefined criteria, such as grammaticality, relevance, clarity, complexity, and alignment with the curriculum (Kurdi et al., 2020; Maity et al., 2023). Expert educators or subject matter experts typically conduct this evaluation, providing feedback on the strengths and weaknesses of the questions. This feedback is invaluable for refining the prompts and improving the quality of the generated questions.\n\nIn addition to human evaluation, automated quality metrics can be used to assess the generated questions. These metrics may include measures such as unigram-, bigram-, and ngram-based evaluations, which provide quantitative insights into the quality of the questions (Kurdi et al., 2020). However, these automated evaluation metrics used for assessing LLM-generated questions have limitations. This limitation arises because these metrics often prioritize linguistic similarity (e.g., character, unigrams, bigrams, or longest common subsequence-based overlap) rather than deeper contextual understanding (Nema and Khapra, 2018).\n\nOne of the challenges in evaluating the quality of generated questions is the subjective nature of some of the criteria. For instance, what one educator considers a challenging and thought-provoking question, another might view as overly complex or unclear (Crogman and Trebeau Crogman, 2018). To address this, it is important to establish clear guidelines and criteria for evaluation, ensuring consistency and objectivity in the assessment process.\n\n# 5.2. VARIATIONS IN QUALITY ACROSS DIFFERENT METHODS\n\nThe quality of questions generated by LLMs can vary significantly depending on the methods and techniques used. For example, questions generated using zero-shot prompting may be more general and less tailored to the specific content, while those generated using fine-tuning or prompt-tuning may be more precise and relevant (Maity et al., 2023). Understanding these variations is essential for selecting the appropriate method for a given educational context.\n\nOne common variation in quality is related to the complexity of the generated questions. LLMs are capable of generating both simple, factual questions and more complex, analytical questions (Maity et al., 2024b). However, the latter requires a deeper understanding of the content and context, which may not always be achievable through basic prompting techniques. To generate higher-order questions, more advanced techniques, such as chain-of-thought prompting (Wei et al., 2022) or fine-tuning (Raffel et al., 2020), may be necessary.\n\nAnother variation in quality is related to the cultural and linguistic diversity of the generated questions. LLMs trained on diverse datasets are better equipped to generate questions that are culturally relevant and appropriate for different student populations. However, this diversity can also introduce challenges, as the model may generate questions that are less familiar or relevant to certain groups of students. Ensuring that the generated questions are inclusive and accessi\n\nble to all learners is an important consideration in the evaluation process (Maity et al., 2024a; Maity et al., 2024b).\n\n# 6. BROADER IMPLICATIONS AND FUTURE DIRECTIONS\n\n# 6.1. THE ROLE OF LLMS IN PERSONALIZED AND ADAPTIVE LEARNING\n\nAs LLMs continue to evolve, their role in personalized and adaptive learning is becoming increasingly significant. The ability of LLMs to generate contextually relevant questions and assess student responses on a large scale opens up new possibilities for personalized education (Alier et al., 2023). By leveraging LLMs, educators can create tailored learning experiences that adapt to the individual needs and progress of each student (Goslen et al., 2024).\n\nOne of the key benefits of using LLMs in personalized learning is the ability to provide immediate feedback and guidance (Meyer et al., 2024b). As students interact with the system, LLMs can generate questions that challenge their understanding, identify areas of difficulty, and offer targeted feedback to support their learning. This real-time interaction can help students stay engaged and motivated, while also providing educators with valuable insights into their progress.\n\nHowever, the integration of LLMs into personalized learning also raises important questions about the balance between human and AI-driven education (Yekollu et al., 2024). While LLMs can offer scalable and efficient solutions, they cannot replace the nuanced understanding and empathy that human educators bring to the classroom. The challenge lies in finding the right balance, where LLMs complement and enhance human-led education, rather than supplanting it.\n\n# 6.2. ETHICAL CONSIDERATIONS AND CHALLENGES\n\nThe use of LLMs in education also raises important ethical considerations (Meyer et al., 2024b). Issues such as bias, fairness, and transparency are central to the responsible use of AI in education (Memarian and Doleck, 2023). LLMs, like all AI systems, are trained on data that may contain biases, and these biases can be reflected in the questions they generate or the assessments they perform (Memarian and Doleck, 2023). Ensuring that LLMs are fair and unbiased requires careful attention to the training data, as well as ongoing monitoring and evaluation of the system's outputs.\n\nAnother ethical consideration is the transparency of the AI-driven educational process (Badawi et al., 2018). Students and educators need to understand how LLMs generate questions and assess responses, and they should be informed about the potential limitations and biases of the system (Memarian and Doleck, 2023). Transparency is key to building trust in AI-driven education and ensuring that students and educators feel confident in the use of these technologies (Kim, 2024).\n\nFinally, the use of LLMs in education raises questions about data privacy and security (Rahman et al., 2024). As LLMs interact with students and assess their responses, they may collect and store sensitive information about the student's performance and learning history. Protecting this data and ensuring that it is used responsibly is essential for maintaining the integrity and security of the educational process.\n\n# 6.3. FUTURE DIRECTIONS IN AUTOMATED QUESTION GENERATION AND ASSESSMENT\n\nLooking to the future, the role of LLMs in automated question generation and assessment is likely to expand and evolve (Fagbohun et al., 2024). Advances in AI and NLP technologies will enable the development of more sophisticated models that are better equipped to handle complex and creative educational tasks (Alqahtani et al., 2023). As these models become more integrated into the educational process, they will play a key role in supporting personalized and adaptive learning, providing scalable solutions that enhance the quality and accessibility of education.\n\nOne promising direction for future research is the development of models that can assess higher-order thinking skills, such as critical thinking, problem-solving, and creativity. These skills are essential for success in the 21st century, and the ability to assess them accurately and efficiently is a major challenge for educators. LLMs, with their advanced language understanding and generation capabilities, have the potential to address this challenge, providing new tools for assessing and supporting the development of these critical skills (Moore et al., 2023).\n\nAnother important direction for future research is the exploration of new methodologies for fine-tuning and prompt-tuning LLMs for specific educational tasks. As LLMs continue to be used in a wider range of educational contexts, it will be important to develop techniques that allow for the efficient and effective adaptation of these models to different subject areas, student populations, and learning objectives.\n\n# 7. CONCLUSION\n\nIn conclusion, large language models have the potential to revolutionize education through automated question generation and answer assessment. These models, with their ability to understand and generate human-like text, offer scalable solutions that can enhance personalized and adaptive learning. By leveraging advanced prompting techniques and fine-tuning methodologies, educators can create high-quality, contextually relevant questions that challenge students and support their learning. Furthermore, LLMs' capabilities in automated assessment can provide timely and constructive feedback, helping students identify areas for improvement and guiding their educational journey.\n\nHowever, the integration of LLMs into education also presents challenges and ethical considerations that must be carefully addressed. Ensuring the fairness, accuracy, and transparency of AI-driven educational processes is essential for building trust and confidence in these technologies. As we look to the future, ongoing research and development will be key to realizing the full potential of LLMs in education, creating a more personalized, adaptive, and accessible learning experience for all students.\n\n# REFERENCES\n\nACHIAM, J., ADLER, S., AGARWAL, S., AHMAD, L., AKKAYA, I., ALEMAN, F. L., ALMEIDA, D., ALTENSCHMIDT, J., ALTMAN, S., ANADKAT, S., ET AL. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.  \nALIER, M., CASAN, M. J., AND FILVA, D. A. 2023. Smart learning applications: Leveraging llms for contextualized and ethical educational technology. In International conference on technological ecosystems for enhancing multiculturality. Springer, 190-199.\n\nALQAHTANI, T., BADRELDIN, H. A., ALRASHED, M., ALSHAYA, A. I., ALGHAMDI, S. S., BIN SALEH, K., ALOWAIS, S. A., ALSHAYA, O. A., RAHMAN, I., AL YAMI, M. S., ET AL. 2023. The emergent role of artificial intelligence, natural learning processing, and large language models in higher education and research. Research in Social and Administrative Pharmacy 19, 8, 1236-1242.  \nBADAWI, G., DE BEYROUTH, G., AND BADAWI, H. 2018. AI-driven educational paradigms: Opportunities and challenges, and ethical considerations in teaching and learning.  \nBALFOUR, S. P. 2013. Assessing writing in moocs: Automated essay scoring and calibrated peer review™. Research & Practice in Assessment 8, 40-48.  \nBROADBENT, J., PANADERO, E., AND BOUD, D. 2018. Implementing summative assessment with a formative flavour: A case study in a large class. Assessment & Evaluation in Higher Education 43, 2, 307-322.  \nBROWN, T., MANN, B., RYDER, N., SUBBIAH, M., KAPLAN, J. D., DHARIWAL, P., NEELAKANTAN, A., SHYAM, P., SASTRY, G., ASKELL, A., AGARWAL, S., HERBERT-VOSS, A., KRUEGER, G., HENIGHAN, T., CHILD, R., RAMESH, A., ZIEGLER, D., WU, J., WINTER, C., HESSE, C., CHEN, M., SIGLER, E., LITWIN, M., GRAY, S., CHESS, B., CLARK, J., BERNER, C., MCCANDLISH, S., RADFORD, A., SUTSKEVER, I., AND AMODEI, D. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, Eds. Vol. 33. Curran Associates, Inc., 1877-1901.  \nCHAPPUIS, J. ET AL. 2015. Seven strategies of assessment for learning. Pearson.  \nCROGMAN, H. AND TREBEAU CROGMAN, M. 2018. Modified generated question learning, and its classroom implementation and assessment. *Cogent Education* 5, 1, 1459340.  \nFAGBOHUN, O., IDUWE, N., ABDULLAHI, M., IFATUROTI, A., AND NWANNA, O. 2024. Beyond traditional assessment: Exploring the impact of large language models on grading practices. Journal of Artificial Intelligence and Machine Learning & Data Science 2, 1, 1-8.  \nFLORIDI, L. AND CHRIATTI, M. 2020. Gpt-3: Its nature, scope, limits, and consequences. *Minds and Machines* 30, 681–694.  \nFLORIDI, L. AND COWLS, J. 2022. A unified framework of five principles for ai in society. Machine learning and the city: Applications in architecture and urban design, 535-545.  \nGOSLEN, A., KIM, Y. J., ROWE, J., AND LESTER, J. 2024. LIm-based student plan generation for adaptive scaffolding in game-based learning environments. International Journal of Artificial Intelligence in Education, 1-26.  \nHENKEL, O., HILLS, L., BOXER, A., ROBERTS, B., AND LEVONIAN, Z. 2024. Can large language models make the grade? an empirical study evaluating llms ability to mark short answer questions in k-12 education. In Proceedings of the Eleventh ACM Conference on Learning@ Scale. 300-304.  \nHSIAO, Y.-P., KLIJN, N., AND CHIU, M.-S. 2023. Developing a framework to re-design writing assignment assessment for the era of large language models. Learning: Research and Practice 9, 2, 148-158.  \nKASNECI, E., SESSLER, K., KUCHEMANN, S., BANNERT, M., DEMENTIEVA, D., FISCHER, F., GASSER, U., GROH, G., GUNNEMANN, S., HULLERMEIER, E., ET AL. 2023. Chatgpt for good? on opportunities and challenges of large language models for education. Learning and individual differences 103, 102274.  \nKAZI, N. H. 2023. Automated short-answer grading and misconception detection using large language models. University of North Florida.  \nKIM, J. 2024. Leading teachers' perspective on teacher-ai collaboration in education. *Education and Information Technologies* 29, 7, 8693–8724.\n\nKURDI, G., LEO, J., PARSIA, B., SATTLER, U., AND AL-EMARI, S. 2020. A systematic review of automatic question generation for educational purposes. International Journal of Artificial Intelligence in Education 30, 121-204.  \nLESTER, B., AL-RFOU, R., AND CONSTANT, N. 2021. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691.  \nLI, Q., FU, L., ZHANG, W., CHEN, X., YU, J., XIA, W., ZHANG, W., TANG, R., AND YU, Y. 2023. Adapting large language models for education: Foundational capabilities, potentials, and challenges. arXiv preprint arXiv:2401.08664.  \nLUCKIN, R. AND HOLMES, W. 2016. Intelligence unleashed: An argument for ai in education.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2023. Harnessing the power of prompt-based techniques for generating school-level questions using large language models. In Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation. 30-39.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024a. Exploring the capabilities of prompted large language models in educational and assessment applications. In Proceedings of the 17th International Conference on Educational Data Mining, B. PaaÄyen and C. D. Epp, Eds. International Educational Data Mining Society, Atlanta, Georgia, USA, 961-968.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024b. How effective is gpt-4 turbo in generating school-level questions from textbooks based on bloom's revised taxonomy?  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024c. How ready are generative pre-trained large language models for explaining bengali grammatical errors? In Proceedings of the 17th International Conference on Educational Data Mining, B. PaaÄyen and C. D. Epp, Eds. International Educational Data Mining Society, Atlanta, Georgia, USA, 664-671.  \nMAITY, S., DEROY, A., AND SARKAR, S. 2024d. A novel multi-stage prompting approach for language agnostic mcq generation using gpt. In European Conference on Information Retrieval. Springer, 268-277.  \nMANSOUR, W., ALBATARNI, S., ELTANBOULY, S., AND ELSAYED, T. 2024. Can large language models automatically score proficiency of written essays? arXiv preprint arXiv:2403.06149.  \nMAZIDI, K. AND NIELSEN, R. 2014. Linguistic considerations in automatic question generation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 321-326.  \nMEMARIAN, B. AND DOLECK, T. 2023. Fairness, accountability, transparency, and ethics (fate) in artificial intelligence (ai), and higher education: A systematic review. Computers and Education: Artificial Intelligence, 100152.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., AND FLECKENSTEIN, J. 2024a. Using llms to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students' text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence 6, 100199.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., AND FLECKENSTEIN, J. 2024b. Using llms to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students' text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence 6, 100199.  \nMOORE, S., TONG, R., SINGH, A., LIU, Z., HU, X., LU, Y., LIANG, J., CAO, C., KHOSRAVI, H., Denny, P., ET AL. 2023. Empowering education with llms-the next-gen interface and content generation. In International Conference on Artificial Intelligence in Education. Springer, 32-37.\n\nMULLA, N. AND GHARPURE, P. 2023. Automatic question generation: a review of methodologies, datasets, evaluation metrics, and applications. Progress in Artificial Intelligence 12, 1, 1-32.  \nNEMA, P. AND KHAPRA, M. M. 2018. Towards a better metric for evaluating question generation systems. arXiv preprint arXiv:1808.10192.  \nOWAN, V. J., ABANG, K. B., IDIKA, D. O., ETTA, E. O., AND BASSEY, B. A. 2023. Exploring the potential of artificial intelligence tools in educational measurement and assessment. Eurasia Journal of Mathematics, Science and Technology Education 19, 8, em2307.  \nRADFORD, A., WU, J., CHILD, R., LUAN, D., AMODEI, D., SUTSKEVER, I., ET AL. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8, 9.  \nRAFFEL, C., SHAZEER, N., ROBERTS, A., LEE, K., NARANG, S., MATENA, M., ZHOU, Y., LI, W., AND LIU, P. J. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of machine learning research 21, 140, 1-67.  \nRAHMAN, M. A., ALQAHTANI, L., ALBOOQ, A., AND AINOUSAH, A. 2024. A survey on security and privacy of large multimodal deep learning models: Teaching and learning perspective. In 2024 21st Learning and Technology Conference (L&T). IEEE, 13-18.  \nRAIAAN, M. A. K., MUKTA, M. S. H., FATEMA, K., FAHAD, N. M., SAKIB, S., MIM, M. M. J., AHMAD, J., ALI, M. E., AND AZAM, S. 2024. A review on large language models: Architectures, applications, taxonomies, open issues and challenges. IEEE Access.  \nSHIN, J. AND GIERL, M. J. Automated short-response scoring for automated item generation in science assessments. In The Routledge International Handbook of Automated Essay Evaluation. Routledge, 504-534.  \nSTAMPER, J., XIAO, R., AND HOU, X. 2024. Enhancing llm-based feedback: Insights from intelligent tutoring systems and the learning sciences. In International Conference on Artificial Intelligence in Education. Springer, 32-43.  \nVASWANI, A., SHAZEER, N., PARMAR, N., USZKOREIT, J., JONES, L., GOMEZ, A. N., KAISER, L. U., AND POLOSUKHIN, I. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds. Vol. 30. Curran Associates, Inc.  \nWEI, J., WANG, X., SCHUURMANS, D., BOSMA, M., ICHTER, B., XIA, F., CHI, E., LE, Q. V., AND ZHOU, D. 2022. Chain-of-thought prompting elicits reasoning in large language models. In Advances in Neural Information Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds. Vol. 35. Curran Associates, Inc., 24824-24837.  \nYEKOLLU, R. K., BHIMRAJ GHUGE, T., SUNIL BIRADAR, S., HALDIKAR, S. V., AND FAROOK MOHIDEEN ABDUL KADER, O. 2024. Ai-driven personalized learning paths: Enhancing education through adaptive systems. In International Conference on Smart Data Intelligence. Springer, 507-517.",
    "arxiv_id": "2410.09576",
    "error_message": null,
    "embedding": [
      0.4375,
      0.265625,
      -1.7421875,
      -0.8203125,
      -1.921875,
      1.09375,
      -2.15625,
      -1.765625,
      2.109375,
      4.3125,
      0.2421875,
      3.296875,
      3.546875,
      0.6953125,
      -0.474609375,
      4.0625,
      -1.296875,
      1.140625,
      2.1875,
      -8.8125,
      0.09619140625,
      2.125,
      -0.15625,
      -4.15625,
      3.328125,
      -4.3125,
      -1.046875,
      3.328125,
      3.953125,
      -0.412109375,
      6.25,
      -3.9375,
      -0.8515625,
      -0.15625,
      -0.91796875,
      0.027587890625,
      -2.515625,
      -0.33984375,
      6.8125,
      4.9375,
      -6.03125,
      -0.04052734375,
      0.765625,
      2.5,
      -1.28125,
      3.375,
      1.4140625,
      0.39453125,
      -3,
      -2.015625,
      -4.5625,
      -3.171875,
      6.75,
      -0.734375,
      2.15625,
      -3.65625,
      -7.375,
      5.9375,
      -5.71875,
      1.3125,
      3.5,
      -1.1875,
      2.265625,
      1.9921875,
      4,
      4.6875,
      -0.953125,
      0.07470703125,
      -2.453125,
      2.59375,
      0.328125,
      0.76171875,
      7.03125,
      -1.578125,
      9.625,
      3.40625,
      2.5625,
      7.15625,
      -2,
      4.1875,
      -5.375,
      3.921875,
      2.234375,
      0.283203125,
      5.84375,
      3.15625,
      1.21875,
      -0.69921875,
      -4.875,
      1.359375,
      -3.90625,
      1.796875,
      -4.40625,
      -1.4375,
      -2.125,
      3.953125,
      -3.25,
      -4.40625,
      -7.96875,
      0.4765625,
      -1.1015625,
      -2.625,
      0.451171875,
      -8.125,
      -2.4375,
      -0.98046875,
      -3.875,
      -5.9375,
      -1.9375,
      -1.140625,
      -1.7578125,
      2.078125,
      -0.6171875,
      -1.859375,
      3.140625,
      0.7265625,
      3.5,
      -4.8125,
      -5.53125,
      -1.875,
      -0.15625,
      -0.006622314453125,
      -1.2421875,
      0.7265625,
      5.15625,
      2.984375,
      -4.59375,
      2.515625,
      5.40625,
      -2.171875,
      5.28125,
      -1.21875,
      6.9375,
      0.345703125,
      -9.4375,
      -3.921875,
      -6.25,
      4.4375,
      3.609375,
      5.90625,
      -6.65625,
      -0.291015625,
      -2.15625,
      -7.125,
      2.390625,
      0.484375,
      -8.375,
      -0.21484375,
      1.421875,
      -4.5625,
      -0.2470703125,
      1.859375,
      1.7265625,
      6.40625,
      -3.21875,
      -2.59375,
      6.21875,
      1.5390625,
      1.171875,
      -1.2734375,
      0.07080078125,
      2.796875,
      -1.125,
      -0.126953125,
      1.25,
      0.4921875,
      -6.53125,
      1.9296875,
      -0.8828125,
      -0.58203125,
      -0.66015625,
      14.1875,
      3.84375,
      -1.4921875,
      1.2265625,
      4.65625,
      2.5,
      5.65625,
      1.4296875,
      0.00299072265625,
      1.921875,
      1.90625,
      -4.375,
      5.15625,
      -2.953125,
      1.1875,
      2.28125,
      -4.28125,
      1.796875,
      -2.28125,
      0.97265625,
      1.4921875,
      3.546875,
      2.53125,
      -8.3125,
      0.400390625,
      1.421875,
      -0.8125,
      -1.9453125,
      1.8984375,
      -0.09716796875,
      -9.6875,
      0.64453125,
      -2.296875,
      -5.28125,
      -0.05126953125,
      2.96875,
      -3.40625,
      1.46875,
      -0.79296875,
      1.3515625,
      0.65234375,
      1.265625,
      0.828125,
      8.5625,
      5.3125,
      3.34375,
      -0.2314453125,
      4.4375,
      0.059814453125,
      5.6875,
      5.625,
      3.484375,
      -0.8359375,
      -0.37109375,
      3.046875,
      3.8125,
      4.9375,
      0.56640625,
      5.9375,
      0.8359375,
      1.328125,
      4.65625,
      -4.71875,
      -2.03125,
      -1.453125,
      -3.71875,
      -1.1015625,
      0.6640625,
      -1.7578125,
      -4.3125,
      -2.453125,
      0.37890625,
      2.984375,
      2.546875,
      -0.7734375,
      0.051513671875,
      -1.6171875,
      -5.84375,
      -7.84375,
      0.83203125,
      5.28125,
      -9.625,
      -5.625,
      4.0625,
      9.375,
      -1.21875,
      -1.0859375,
      -0.71875,
      -4.375,
      4.8125,
      -1.609375,
      -5.15625,
      4.21875,
      1.765625,
      -3.328125,
      4,
      -3.203125,
      3.15625,
      1.734375,
      -0.051025390625,
      -0.07568359375,
      -3.703125,
      1.0390625,
      -4.0625,
      4.125,
      1.21875,
      -5.3125,
      1.7109375,
      -3.984375,
      -7.03125,
      -10.5625,
      5.8125,
      -5.5625,
      2.234375,
      -0.390625,
      0.828125,
      3.890625,
      -1.5703125,
      12.5,
      3.890625,
      2.875,
      1.3828125,
      2.25,
      -2.71875,
      0.87890625,
      -2.140625,
      -0.0830078125,
      -6.75,
      1.546875,
      5.75,
      -0.0849609375,
      -0.41015625,
      -1.984375,
      0.1435546875,
      3.640625,
      -0.314453125,
      -4.125,
      1.078125,
      0.96875,
      -3.5,
      1.046875,
      4.90625,
      -1.8046875,
      4,
      -4.65625,
      -3.34375,
      5.53125,
      1.640625,
      -2.296875,
      -4.46875,
      -3.046875,
      -1.390625,
      -2.234375,
      -2.28125,
      -2.359375,
      2.5,
      1.53125,
      4.53125,
      -1,
      2.96875,
      -1.359375,
      -6.15625,
      -6.65625,
      7.09375,
      -2.734375,
      4.59375,
      2.90625,
      -2.34375,
      3.34375,
      -1.3046875,
      -3.265625,
      2.875,
      -1.40625,
      -2.21875,
      -0.0498046875,
      6.25,
      -2.59375,
      1.578125,
      -5.75,
      4.84375,
      -0.443359375,
      -1.0390625,
      1.3828125,
      5.75,
      -2.25,
      1.078125,
      -1.2890625,
      0.2734375,
      1.140625,
      5.03125,
      -2.796875,
      7.6875,
      -2.5,
      0.0018463134765625,
      -3.546875,
      -4.75,
      0.359375,
      -2.109375,
      -1.28125,
      0.5546875,
      -3.390625,
      1.6171875,
      2.890625,
      0.3828125,
      2.484375,
      0.890625,
      -3.734375,
      -2.3125,
      3.46875,
      -2.328125,
      -0.7890625,
      -2.703125,
      -0.640625,
      3.640625,
      1.4765625,
      -0.96484375,
      2.53125,
      2.296875,
      -1.5859375,
      -1.953125,
      0.2294921875,
      -4.59375,
      1.8828125,
      2.234375,
      2.34375,
      -0.890625,
      0.2578125,
      0.10888671875,
      -2.21875,
      6.46875,
      -0.1455078125,
      -1.5078125,
      0.2333984375,
      -4.71875,
      2.375,
      0.6953125,
      -7.75,
      3.421875,
      0.1806640625,
      -1.8359375,
      0.97265625,
      0.408203125,
      2.859375,
      -0.79296875,
      2.53125,
      -3.484375,
      1.9140625,
      -8.375,
      -2.03125,
      -3.828125,
      0.0341796875,
      3,
      -1.25,
      0.423828125,
      -0.93359375,
      1.5234375,
      5,
      -0.5078125,
      1.421875,
      1.2890625,
      -0.796875,
      -3.140625,
      2.34375,
      -3.0625,
      -4.03125,
      4.65625,
      -3.109375,
      -5.03125,
      0.7890625,
      0.93359375,
      -1.9609375,
      5.15625,
      2.90625,
      -3.8125,
      -0.33984375,
      2.796875,
      5.71875,
      -4.03125,
      -1.25,
      0.08349609375,
      -1.1328125,
      -1.3828125,
      1.6171875,
      -0.08740234375,
      2.5625,
      -5.5,
      3.25,
      1.796875,
      -0.1259765625,
      0.5234375,
      -1.9765625,
      -2.921875,
      -0.859375,
      1.546875,
      -0.2275390625,
      -2.359375,
      3.859375,
      6.65625,
      -6.34375,
      -10.6875,
      2.59375,
      1.2890625,
      -0.373046875,
      -0.765625,
      0.71875,
      1,
      0.201171875,
      -6.15625,
      -3.921875,
      -0.138671875,
      -2.078125,
      3.375,
      2.09375,
      -1.4765625,
      -3.59375,
      -2.171875,
      4.375,
      0.59765625,
      3.203125,
      -1.0390625,
      -1.328125,
      0.08349609375,
      -2.515625,
      3.625,
      1.171875,
      9.75,
      -4.90625,
      0.2421875,
      1.8984375,
      -9.125,
      2.6875,
      -2.875,
      1.046875,
      2.015625,
      0.2490234375,
      5.625,
      -4.8125,
      -1.984375,
      -0.91796875,
      4.96875,
      -3.265625,
      -0.68359375,
      2.546875,
      -7.53125,
      -1.0390625,
      0.035888671875,
      1.9765625,
      2.453125,
      -1.09375,
      -5.84375,
      1.421875,
      1.359375,
      2.5,
      -0.5703125,
      -1.0078125,
      -2.453125,
      -4.1875,
      2.109375,
      5.09375,
      1.0234375,
      1.859375,
      -0.13671875,
      -3.890625,
      -1.9921875,
      -1.140625,
      2.015625,
      -1.5546875,
      -0.1298828125,
      -0.62890625,
      -0.0888671875,
      5.75,
      -1.7265625,
      -1.875,
      0.251953125,
      3.40625,
      -6.5625,
      -0.341796875,
      0.65234375,
      1.34375,
      3.875,
      1.8046875,
      -1.390625,
      -2.5,
      2.90625,
      -3.0625,
      -4.96875,
      0.15625,
      4.03125,
      -2.015625,
      -0.34375,
      -5.25,
      -1.109375,
      1.6171875,
      3.109375,
      -0.2470703125,
      -0.6171875,
      6.8125,
      -0.58203125,
      -1.9609375,
      -1.625,
      5.5,
      -1.6875,
      0.27734375,
      1.4453125,
      0.9921875,
      -7,
      -6.21875,
      -3,
      2.8125,
      7.65625,
      -3.109375,
      4.8125,
      -2.4375,
      4.53125,
      -2.09375,
      -0.86328125,
      -13.125,
      3.953125,
      0.48828125,
      -5.34375,
      -1.1640625,
      -0.91796875,
      2.296875,
      0.67578125,
      3.28125,
      0.453125,
      -0.78515625,
      1.9765625,
      4.34375,
      1.1015625,
      -0.59375,
      3,
      2.90625,
      -2.890625,
      2.234375,
      -2.953125,
      -3.421875,
      3,
      -1.3828125,
      1.6484375,
      2.375,
      4.625,
      1.0703125,
      -0.2294921875,
      1.1015625,
      -4.03125,
      0.55078125,
      2.390625,
      2.1875,
      1.109375,
      0.423828125,
      -3.03125,
      3.28125,
      -3.9375,
      2.765625,
      0.314453125,
      -3.921875,
      2.125,
      6.1875,
      -0.58203125,
      -2.828125,
      -2.328125,
      0.330078125,
      4.09375,
      4.78125,
      -5.46875,
      2.671875,
      -2.84375,
      -0.52734375,
      1.96875,
      -1.40625,
      -0.8671875,
      -3.171875,
      4.46875,
      1.03125,
      -3.234375,
      5.34375,
      1.0859375,
      -4.6875,
      -0.515625,
      0.5703125,
      -0.58203125,
      -1.2578125,
      1.9296875,
      0.353515625,
      -2.3125,
      0.423828125,
      3.0625,
      0.045166015625,
      -4.28125,
      -1.734375,
      0.345703125,
      -4.125,
      3.984375,
      -1.9765625,
      -2.65625,
      -2.765625,
      -3.03125,
      1.71875,
      1.140625,
      1.9765625,
      0.10009765625,
      4.65625,
      3.421875,
      -3.671875,
      3.0625,
      -3.453125,
      -2.328125,
      -0.482421875,
      -2.484375,
      -3.28125,
      -0.5703125,
      0.81640625,
      1.4375,
      -4.25,
      -2.96875,
      -3.1875,
      -6.6875,
      -2.75,
      2.015625,
      -1.0625,
      4.46875,
      -2.203125,
      6.75,
      -1.703125,
      -1.7734375,
      0.60546875,
      0.4296875,
      0.1572265625,
      -1.625,
      0.7890625,
      -5.03125,
      -0.400390625,
      7.8125,
      2.34375,
      -3.390625,
      6.25,
      -2.484375,
      -3.734375,
      1.3984375,
      2.4375,
      -2.890625,
      -2.015625,
      0.1630859375,
      -1.4609375,
      -3.1875,
      -2.515625,
      0.2333984375,
      -2.625,
      2.8125,
      -1.0234375,
      0.322265625,
      1.1875,
      -6.5625,
      -2.203125,
      0.63671875,
      -3.34375,
      2.4375,
      4.1875,
      -0.076171875,
      -2.578125,
      3.53125,
      1.28125,
      1.5390625,
      0.1953125,
      -2.90625,
      4.75,
      1.3046875,
      5.125,
      -0.55078125,
      -6.75,
      -0.8671875,
      0.73046875,
      0.40234375,
      3.890625,
      -2.84375,
      2.703125,
      5.9375,
      3.9375,
      -5.9375,
      -3.046875,
      2.625,
      -3.90625,
      -0.0032501220703125,
      3.984375,
      3.796875,
      -0.06982421875,
      1.171875,
      -1.90625,
      -5.71875,
      -1.03125,
      4.875,
      2.203125,
      -2.96875,
      1.3046875,
      5,
      1.3046875,
      5,
      -4.34375,
      -3.46875,
      -0.197265625,
      1.9140625,
      -3.296875,
      -1.4453125,
      7.15625,
      -1.875,
      0.4453125,
      -0.369140625,
      1.765625,
      1.40625,
      2.15625,
      0.8671875,
      -0.59375,
      3.59375,
      1.578125,
      -0.0341796875,
      3.25,
      -2.25,
      -0.030029296875,
      2.15625,
      -0.0751953125,
      -1.765625,
      1.9609375,
      -0.95703125,
      -0.126953125,
      -1.46875,
      -0.34765625,
      1.0703125,
      4.53125,
      4.5625,
      -1.1953125,
      -1.2578125,
      -0.490234375,
      8.375,
      -1.9921875,
      6.75,
      2.296875,
      9.6875,
      -0.5703125,
      -0.7109375,
      1.625,
      -3,
      -2.15625,
      -0.6328125,
      -5.75,
      -4.625,
      -0.53515625,
      -0.90625,
      -3.109375,
      3.9375,
      -5.21875,
      -0.0966796875,
      5.46875,
      -0.1220703125,
      4.78125,
      3.09375,
      4.46875,
      -0.609375,
      -0.33984375,
      -2.171875,
      -1.4375,
      -0.3359375,
      0.6953125,
      0.54296875,
      -6.46875,
      3.53125,
      2.0625,
      3.3125,
      0.310546875,
      -0.57421875,
      -2.734375,
      7.15625,
      0.63671875,
      -2.09375,
      4.25,
      0.74609375,
      1.265625,
      3.078125,
      4.03125,
      -3.40625,
      -2.03125,
      5.75,
      6.0625,
      -2.5,
      2.140625,
      0.6328125,
      -0.44140625,
      -2.390625,
      0.96875,
      0.11328125,
      1.5390625,
      -4.875,
      -0.94140625,
      -0.5546875,
      2.640625,
      -5.5625,
      -0.70703125,
      1.3125,
      -4.34375,
      3.46875,
      3.140625,
      -1.40625,
      0.71484375,
      -0.06689453125,
      6.40625,
      -0.3828125,
      -5.09375,
      -3.390625,
      -4.84375,
      -2.625,
      -0.0264892578125,
      2.578125,
      0.96484375,
      3.46875,
      -3.265625,
      -0.12890625,
      -4,
      -2.046875,
      -4.84375,
      4.53125,
      2.796875,
      -4.5625,
      -0.5703125,
      -2.625,
      -6.59375,
      -6.46875,
      -0.859375,
      -3.328125,
      0.0859375,
      -4.9375,
      -0.376953125,
      1.7109375,
      -5.375,
      0.10400390625,
      -1.4453125,
      -3.5,
      1.6796875,
      -0.78515625,
      0.76171875,
      -2.5625,
      1.1328125,
      1.75,
      -1.453125,
      3.46875,
      3.84375,
      2.84375,
      3.46875,
      -1.1484375,
      -0.384765625,
      -2.578125,
      6.96875,
      -3.515625,
      6.40625,
      5.9375,
      2.796875,
      -7.40625,
      3.625,
      -0.423828125,
      2.359375,
      -5.40625,
      -1.5390625,
      -2.53125,
      1.078125,
      2.5,
      -0.5390625,
      1.9921875,
      -4.6875,
      -3.203125,
      2.375,
      -5.125,
      -0.07568359375,
      2.828125,
      -0.2333984375,
      4.65625,
      -0.314453125,
      -0.2021484375,
      1.265625,
      0.9375,
      2.828125,
      -1.1953125,
      2.25,
      -4,
      0.85546875,
      -3.671875,
      1.2734375,
      -0.0037841796875,
      -2.828125,
      0.333984375,
      0.455078125,
      0.6484375,
      3.359375,
      2.609375,
      3.890625,
      1.671875,
      2.90625,
      -0.2294921875,
      1.0859375,
      2.625,
      -2.75,
      7.09375,
      1.2109375,
      -0.71875,
      -2.0625,
      -0.3828125,
      -3.546875,
      2.328125,
      -1.1328125,
      -4.28125,
      -0.37890625,
      -1.984375,
      -3.5,
      2.78125,
      0.1484375,
      0.345703125,
      2,
      3.109375,
      3.890625,
      1.984375,
      -0.69921875,
      0.61328125,
      2.0625,
      -4.59375,
      5.1875,
      -4.34375,
      -0.8359375,
      5.34375,
      2.5625,
      3.40625,
      -1.0390625,
      -1.3984375,
      -3.4375,
      0.419921875,
      3.203125,
      -2.4375,
      1.7421875,
      4.40625,
      -2.578125,
      1.0859375,
      -0.9453125,
      1.71875,
      1.1171875,
      -1.4921875,
      -0.52734375,
      2.359375,
      4.1875,
      -1.3359375,
      -1.8515625,
      -3.875,
      0.87109375,
      -0.88671875,
      -3.625,
      -1.59375,
      1.0234375,
      -1.3203125,
      -0.314453125,
      -0.19140625,
      -2.453125,
      -1.0546875,
      -3.40625,
      0.7421875,
      3.453125,
      0.23828125,
      0.9921875,
      0.326171875,
      2.625,
      -1.34375,
      2.265625,
      2.703125,
      -2.859375,
      2.890625,
      4.25,
      -1.5,
      4.59375,
      3.703125,
      -0.5234375,
      2.5625,
      -3.125,
      0.9765625,
      1.0703125,
      -2.578125,
      -0.76953125,
      -5.4375,
      0.8046875,
      4,
      2.890625,
      -2.15625,
      2.890625,
      -1.3828125,
      -2,
      4.09375,
      -3.765625,
      -4.65625,
      -1.3515625,
      0.59375,
      -4.84375,
      -2,
      -2.046875,
      1.1328125,
      2.65625,
      -7.09375,
      4.03125,
      -4.1875,
      7,
      1.7734375,
      -2.953125,
      -0.1669921875,
      -3.21875,
      2.75,
      -1.9609375,
      1.5,
      0.2333984375,
      -2.9375,
      2.75,
      -2.328125,
      1.390625,
      0.78125,
      -1.4296875,
      1.65625,
      -1.875,
      0.578125,
      0.984375,
      0.31640625,
      -7.96875,
      -5.3125,
      -3.640625,
      -2.1875,
      -0.1884765625,
      1.28125,
      -0.234375,
      0.5078125,
      0.1376953125,
      -4.625,
      0.51171875,
      -1.625,
      -1.9375,
      1.71875,
      -0.296875,
      4.9375,
      2.421875,
      -0.72265625,
      -0.8359375,
      0.396484375,
      -6.9375,
      -1.9375,
      -0.80078125,
      0.7890625,
      -3.359375,
      0.55078125,
      0.9453125,
      2.703125,
      -0.86328125,
      1.1953125,
      -0.69140625,
      2.84375,
      4,
      -0.0849609375,
      1.90625,
      -2.375,
      1.734375,
      -2.546875,
      -4.0625,
      -6.125,
      -1.265625,
      1.3515625,
      -3.40625,
      0.37109375,
      -2.546875,
      1.6015625,
      2.890625,
      -0.01708984375,
      -0.9375,
      0.9375,
      5.09375,
      -0.69140625,
      -3.4375,
      3.03125,
      -0.83984375,
      4.03125,
      -1.6796875,
      -2.359375,
      -1.8515625,
      1.5859375,
      1.2265625,
      2.8125,
      -2.234375,
      -2.546875,
      1.3984375,
      -0.50390625,
      -4.53125,
      -3.375,
      3.65625,
      -0.2119140625,
      5.46875,
      4.0625,
      -1.265625,
      -1.328125,
      -0.28515625,
      0.142578125,
      3.453125,
      1.6875,
      0.39453125,
      3.25,
      1.1875,
      6.5,
      -2.234375,
      -0.5625,
      -8.75,
      -1.6796875,
      9.0625,
      0.55078125,
      -0.765625,
      -2.015625,
      -0.005462646484375,
      1.7734375,
      0.80078125,
      2.90625,
      -1.375,
      -0.357421875,
      -1.640625,
      3.6875,
      2.484375,
      -3.640625,
      0.75,
      1.703125,
      -3.546875,
      1.8203125,
      4.28125,
      4.1875,
      -0.6328125,
      3.765625,
      -1.5859375,
      -3.296875,
      -3.859375,
      4.75,
      1.3984375,
      -0.28125,
      0.2216796875,
      -2.765625,
      1.109375,
      -0.84765625,
      1.1171875,
      5.78125,
      -4.03125,
      2.9375,
      -1.1796875,
      3.125,
      -0.609375,
      -2.78125,
      -1.1484375,
      4.34375,
      3.234375,
      -1.640625,
      -0.1708984375,
      -2.34375,
      -0.1337890625,
      -2.078125,
      -7.0625,
      1.6953125,
      1,
      2.265625,
      3.8125,
      -1.2109375,
      1.953125,
      0.515625,
      -3,
      -1.953125,
      -1.9765625,
      2.65625,
      3.3125,
      1.7890625,
      -3.84375,
      -0.7265625,
      -0.73046875,
      -1.375,
      -3.078125,
      5.78125,
      -2.296875,
      2.40625,
      2.9375,
      3.09375,
      -5.5625,
      -3.5625,
      -1.5078125,
      -2.6875,
      -6.5,
      1.625,
      0.9921875,
      -0.64453125,
      3.984375,
      0.734375,
      -2.953125,
      -0.11181640625,
      -3.765625,
      0.62890625,
      1.671875,
      2.234375,
      -5.1875,
      3.984375,
      -5.40625,
      -0.69140625,
      4.21875,
      -2.765625,
      -2.203125,
      -0.2021484375,
      -0.91015625,
      2.234375,
      2.609375,
      -1.0859375,
      -1.640625,
      2.390625,
      -2.5,
      -3.765625,
      -5.125,
      1.1015625,
      0.2021484375,
      -2.984375,
      1.8125,
      -1.484375,
      2.296875,
      -3.96875,
      -4.5,
      0.3828125,
      -1.4296875,
      -1.90625,
      4.15625,
      3.453125,
      -3.046875,
      1.9921875,
      -3.109375,
      7.84375,
      2.34375,
      -0.40234375,
      -0.0250244140625,
      -1.1328125,
      1.5625,
      -4.46875,
      4.25,
      -0.1748046875,
      -1.5234375,
      3.296875,
      5.84375,
      -4.34375,
      -1.6484375,
      0.890625,
      5.375,
      -5.09375,
      -0.1923828125,
      -1.015625,
      5.5,
      -2.671875,
      -0.44140625,
      -4.09375,
      -1.7890625,
      1.875,
      -1.78125,
      1.859375,
      -1.2421875,
      3.328125,
      -3.40625,
      -2.734375,
      2.515625,
      1.3125,
      3.78125,
      -3.390625,
      1.796875,
      3.703125,
      -2.421875,
      4.03125,
      -0.2314453125,
      -1.171875,
      -2.46875,
      0.50390625,
      -4.84375,
      -2.84375,
      -7.1875,
      0.5703125,
      -2.234375,
      -0.7578125,
      -1.3671875,
      1.453125,
      0.3046875,
      0.5390625,
      -2.765625,
      -0.62109375,
      -4.125,
      -3.921875,
      0.8984375,
      -2.734375,
      -3.4375,
      0.92578125,
      0.578125,
      1.8671875,
      5.4375,
      5,
      1.96875,
      -3.4375,
      2.4375,
      -3.203125,
      0.07470703125,
      -2.3125,
      0.051513671875,
      -1.7578125,
      -0.92578125,
      3.21875,
      2.984375,
      3.015625,
      -5.5625,
      -2.859375,
      -5.375,
      -0.8359375,
      -0.6953125,
      -0.8046875,
      0.640625,
      2.203125,
      4.59375,
      -2.984375,
      3.484375,
      1.9609375,
      0.62109375,
      -5.9375,
      0.96875,
      -1.7890625,
      3.875,
      2.421875,
      4.40625,
      -4.375,
      5.25,
      2.5625,
      -3.546875,
      2.90625,
      0.05908203125,
      -0.076171875,
      -3.71875,
      2.171875,
      -1.6640625,
      6.09375,
      -0.91796875,
      1.4609375,
      2.609375,
      1.296875,
      3.046875,
      2.8125,
      1.9453125,
      -0.47265625,
      3.375,
      0.87109375,
      -4.0625,
      -1.96875,
      4.84375,
      -2.890625,
      -0.79296875,
      3.234375,
      -0.486328125,
      2.375,
      1.75,
      3.8125,
      1.4296875,
      1.8984375,
      -3.546875,
      2.265625,
      -5.71875,
      -1.265625,
      -6.28125,
      -0.41015625,
      -6.21875,
      2.140625,
      3.484375,
      4.3125,
      -1.421875,
      -3.5,
      2.984375,
      2.203125,
      0.9609375,
      -6.25,
      5.375,
      2.015625,
      -0.365234375,
      -3.0625,
      -4.53125,
      4.65625,
      2.75,
      2.53125,
      -3.875,
      2.46875,
      1.0234375,
      -1.5859375,
      -4.34375,
      2.484375,
      -1.5546875,
      -7.15625,
      -4.625,
      -5.15625,
      4.46875,
      -2.921875,
      2.28125,
      5.46875,
      -1.3359375,
      3.140625,
      -1.0234375,
      2.40625,
      0.47265625,
      -1.78125,
      -0.90625,
      0.73046875,
      -0.4765625,
      -1.03125,
      4.625,
      -2.515625,
      1.9453125,
      -1.265625,
      2.0625,
      1.53125,
      -2.0625,
      -0.94140625,
      -5.78125,
      3.046875,
      3.25,
      0.7890625,
      0.318359375,
      -3.625,
      0.59375,
      0.390625,
      -0.390625,
      -2.015625,
      1.984375,
      -0.8515625,
      -0.91015625,
      0.2470703125,
      -1.140625,
      0.27734375,
      0.494140625,
      2.53125,
      -0.51953125,
      -0.54296875,
      -1.71875,
      -2.015625,
      -3.1875,
      3.09375,
      -0.6953125,
      4.71875,
      0.94140625,
      -2.515625,
      -1.3046875,
      3.359375,
      2.5,
      1.8046875,
      -0.53125,
      -2.328125,
      -0.6171875,
      4.3125,
      0.9375,
      -3.671875,
      -0.9609375,
      -0.52734375,
      -1.5625,
      -3.53125,
      -2.703125,
      -0.640625,
      5.6875,
      -3.828125,
      -2.609375,
      -1,
      2.34375,
      -1.515625,
      -10.125,
      0.20703125,
      0.72265625,
      0.150390625,
      -1.9609375,
      -0.212890625,
      2.34375,
      3.578125,
      0.98046875,
      4.34375,
      2.921875,
      -1.5625,
      2.53125,
      16.625,
      -5.125,
      -3.65625,
      0.408203125,
      -0.65625,
      -0.25,
      9.5,
      1.1875,
      -0.3671875,
      0.171875,
      1.8359375,
      3.484375,
      0.7890625,
      4.53125,
      1.9609375,
      1.59375,
      2.921875,
      1.796875,
      -0.1435546875,
      -4.3125,
      0.640625,
      -0.34765625,
      0.2080078125,
      2.75,
      -2.46875,
      3.1875,
      1.65625,
      -2.71875,
      -0.49609375,
      -4.25,
      0.365234375,
      -2.640625,
      -1.90625,
      -4.53125,
      -0.49609375,
      -2.921875,
      -0.353515625,
      -0.11865234375,
      -0.6796875,
      -2.3125,
      -1.1796875,
      -4.03125,
      1.4140625,
      -0.59765625,
      -2.59375,
      0.040283203125,
      -0.96484375,
      -0.11376953125,
      0.78515625,
      0.55859375,
      -1.609375,
      -2.09375,
      -4.15625,
      -0.79296875,
      3.390625,
      -0.82421875,
      -1.5625,
      -5.625,
      -3.140625,
      -1.296875,
      -1.234375,
      -3.390625,
      -3.953125,
      -1.625,
      -2.1875,
      -3.84375,
      -3.796875,
      -0.130859375,
      -0.08349609375,
      0.1474609375,
      -4.1875,
      -0.9765625,
      5.84375,
      2.34375,
      -1.65625,
      -3.828125,
      2.265625,
      3.3125,
      1.6171875,
      2.25,
      -2.5,
      3.359375,
      -2.0625,
      -1.390625,
      -2.546875,
      1.3828125,
      -5.46875,
      3.140625,
      -0.0130615234375,
      -1.671875,
      4.5,
      -4.03125,
      2.1875,
      0.412109375,
      -5.65625,
      0.10498046875,
      1.421875,
      -0.06103515625,
      -0.212890625,
      -1.6015625,
      3.140625,
      0.392578125,
      -1.1953125,
      -0.78125,
      -1.0625,
      -0.9453125,
      1.0859375,
      -1.9765625,
      2.03125,
      -0.6328125,
      -2.875,
      3.9375,
      -0.390625,
      -0.94140625,
      -0.10986328125,
      1.4765625,
      -4.6875,
      -0.21875,
      0.2412109375,
      -1.5,
      2.84375,
      -2.375,
      -0.01348876953125,
      -0.9609375,
      -8.3125,
      -4.125,
      -1.9296875,
      -4.21875,
      4.0625,
      -4.90625,
      0.95703125,
      -1.3984375,
      -3.8125,
      -2.484375,
      2.75,
      -4.25,
      3.328125,
      4.8125,
      3.109375,
      -0.87109375,
      -2.015625,
      2.578125,
      -1.0390625,
      -1.8515625,
      -0.94921875,
      1.3984375,
      -2.96875,
      3.78125,
      4.9375,
      0.478515625,
      -1.7890625,
      4.59375,
      0.83203125,
      -6.5625,
      2.078125,
      4.65625,
      -1.09375,
      0.37109375,
      -3.46875,
      -2.75,
      -0.01171875,
      -0.025390625,
      -3.921875,
      -2.625,
      -1.5859375,
      -0.1533203125,
      4.15625,
      -2.3125,
      -7.9375,
      1.4921875,
      2.5625,
      -6.21875,
      1.5078125,
      -2.34375,
      5.65625,
      -3.125,
      1.5703125,
      5.4375,
      -0.58984375,
      2.203125,
      4.59375,
      3.71875,
      -2.484375,
      -7.53125,
      4.84375,
      3.921875,
      -3.78125,
      2.671875,
      3.6875,
      -2.015625,
      0.9140625,
      -5.5,
      -3.640625,
      5.3125,
      4.625,
      -4.59375,
      0.236328125,
      -2.234375,
      0.578125,
      -1.8828125,
      -2.25,
      4.15625,
      2.125,
      2.84375,
      4.4375,
      -0.376953125,
      -3.125,
      -0.3828125,
      -1.2421875,
      -1.1328125,
      -2.328125,
      0.8125,
      0.283203125,
      3.1875,
      -6.53125,
      5.96875,
      2.59375,
      1.1640625,
      -2.296875,
      4.40625,
      2.453125,
      -0.35546875,
      -3.953125,
      -1.5078125,
      2.234375,
      4.0625,
      -6.4375,
      2.5,
      -3.140625,
      -0.451171875,
      -1.5390625,
      -0.294921875,
      0.9140625,
      -0.0380859375,
      -3.21875,
      -4.34375,
      -3.09375,
      4.21875,
      1.609375,
      -1.03125,
      3.28125,
      -0.86328125,
      2.65625,
      2.03125,
      -4.53125,
      1.6875,
      -4.75,
      0.2314453125,
      2.671875,
      -4.0625,
      1.640625,
      1.921875,
      2.828125,
      -0.310546875,
      0.2158203125,
      -3.390625,
      -4.4375,
      0.3828125,
      -5.8125,
      -0.6328125,
      0.9765625,
      -4.90625,
      3.8125,
      -2.234375,
      -0.490234375,
      -0.396484375,
      1.421875,
      -5.71875,
      5.4375,
      3.640625,
      -4.65625,
      3.5,
      -2.421875,
      -3.640625,
      1.109375,
      -2.578125,
      2.875,
      -5.9375,
      -0.0966796875,
      2.21875,
      -3.046875,
      0.015380859375,
      1.0390625,
      -1.7421875,
      1.40625,
      -2.3125,
      4.875,
      0.490234375,
      3.265625,
      4.5625,
      2.828125,
      4.28125,
      -3.8125,
      2.734375,
      -1.640625,
      -0.5703125,
      -3.265625,
      1.8125,
      -0.54296875,
      -3.546875,
      1.671875,
      3.640625,
      -0.244140625,
      -8.6875,
      -0.671875,
      1.09375,
      -2.328125,
      1.65625,
      1.796875,
      -0.12109375,
      -2.125,
      -0.2353515625,
      2.265625,
      4.65625,
      -2.65625,
      -2.21875,
      -1.7578125,
      3.25,
      0.98828125,
      -6.75,
      0.8046875,
      -0.07666015625,
      0.77734375,
      -1.8984375,
      0.66796875,
      -3.5625,
      2.890625,
      3.671875,
      -4.3125,
      1.34375,
      2.65625,
      1.453125,
      3.734375,
      -0.53515625,
      0.61328125,
      1.9453125,
      -3.65625,
      -5.625,
      2.015625,
      0.1396484375,
      -1.15625,
      1.1953125,
      -2.40625,
      5.46875,
      1.3828125,
      3.5625,
      -5.84375,
      4.09375,
      1.0546875,
      -8.1875,
      4.25,
      -3.75,
      0.181640625,
      -4.3125,
      -5.15625,
      -2.453125,
      3.109375,
      -1.0859375,
      -1.8125,
      4.40625,
      0.80859375,
      0.20703125,
      2.171875,
      -1.1953125,
      -0.625,
      2.40625,
      3.171875,
      -3.03125,
      4.78125,
      3.984375,
      -0.7734375,
      0.2578125,
      -2.890625,
      2.65625,
      -2.328125,
      -3.953125,
      3.921875,
      3.84375,
      1.0078125,
      -2.453125,
      -4.375,
      0.138671875,
      -1.6875,
      -3.296875,
      1.921875,
      -3.25,
      0.91796875,
      -2.578125,
      -0.275390625,
      1.7890625,
      -4.3125,
      -2.484375,
      -1.9921875,
      -2.265625,
      1.3359375,
      2.234375,
      2.78125,
      -2.125,
      -0.7109375,
      2.953125,
      1.8515625,
      -0.29296875,
      -3.34375,
      0.37109375,
      -2.25,
      -3.09375,
      -1.15625,
      2.5,
      -1.984375,
      -2.28125,
      1.7578125,
      -0.80078125,
      1.203125,
      -5.34375,
      -2.1875,
      1.421875,
      2.21875,
      0.7578125,
      -2.484375,
      -0.94921875,
      1.1484375,
      3.75,
      -4.1875,
      -2.265625,
      -0.369140625,
      5,
      -5.90625,
      -3.375,
      0.107421875,
      -2.09375,
      1.1875,
      3.15625,
      1.2734375,
      0.58203125,
      0.361328125,
      -5.125,
      -1.4296875,
      7.59375,
      4.78125,
      -1.1171875,
      0.478515625,
      -2.71875,
      -1.5,
      4.84375,
      7,
      -3.84375,
      -1.375,
      -0.9375,
      -3.5,
      -2.765625,
      -2.703125,
      1.8125,
      -0.431640625,
      -6.375,
      5.53125,
      -2.390625,
      3.0625,
      2.84375,
      -2.25,
      4.59375,
      -4.0625,
      0.1328125,
      -1.1484375,
      2.0625,
      2.375,
      -3.046875,
      -1.0390625,
      -5.03125,
      -1.7265625,
      -1.3515625,
      -1.7421875,
      0.2216796875,
      0.25,
      6.1875,
      1.34375,
      -1.546875,
      -1.4375,
      -0.62890625,
      2.609375,
      -1.1484375,
      -1.9921875,
      -1.4296875,
      -1.359375,
      0.828125,
      -2.0625,
      1.625,
      -4.5625,
      -0.578125,
      -2.453125,
      2.859375,
      1.6015625,
      1.96875,
      -3.609375,
      -4.0625,
      -2.6875,
      2.3125,
      0.87109375,
      3.625,
      2.25,
      3.515625,
      1.65625,
      -1.0859375,
      2.25,
      5.15625,
      3.140625,
      -2.296875,
      1.6015625,
      -0.375,
      0.66796875,
      -0.81640625,
      -0.61328125,
      1.109375,
      2.734375,
      4.15625,
      -1.8359375,
      -0.201171875,
      -3.390625,
      -2.078125,
      -2.078125,
      0.66796875,
      2.125,
      3.15625,
      0.515625,
      1.265625,
      -1.0546875,
      5.125,
      -0.12353515625,
      3.265625,
      -1.078125,
      -0.9765625,
      -1.890625,
      0.1611328125,
      -2.125,
      -3.78125,
      0.79296875,
      -1.328125,
      1.8203125,
      -0.65625,
      -3.4375,
      0.0595703125,
      4.90625,
      -2.59375,
      2.015625,
      -2.296875,
      2.0625,
      0.95703125,
      0.4609375,
      1.1171875,
      2.953125,
      -1.1875,
      2.8125,
      -2.3125,
      0.1259765625,
      1.640625,
      3.15625,
      -0.205078125,
      -0.435546875,
      0.22265625,
      0.6796875,
      -2.34375,
      -0.84765625,
      2.546875,
      -2.734375,
      4.40625,
      0.8046875,
      -0.98828125,
      0.40625,
      -0.8984375,
      -2.609375,
      2.65625,
      -3.421875,
      -1.359375,
      0.8671875,
      0.1748046875,
      0.72265625,
      -0.890625,
      2.859375,
      2.421875,
      1.1484375,
      -1.4453125,
      -3.453125,
      -1.171875,
      -0.45703125,
      -2.8125,
      -1.46875,
      1.5234375,
      0.099609375,
      -1.7265625,
      0.95703125,
      1.9765625,
      2.0625,
      -0.08642578125,
      -1.6640625,
      -1.671875,
      1.125,
      -0.2353515625,
      -1.2109375,
      0.734375,
      1.6796875,
      4.09375,
      1.34375,
      -1.375,
      0.765625,
      -0.53515625,
      -0.625,
      0.2734375,
      -0.89453125,
      -1.859375,
      -0.283203125,
      0.62890625,
      -0.3359375,
      0.236328125,
      0.09326171875,
      1.5,
      0.63671875,
      0.42578125,
      3.328125,
      1.015625,
      -0.62109375,
      3.015625,
      3.890625,
      -1.90625,
      -2.734375,
      -0.75390625,
      3.046875,
      3.171875,
      -0.435546875,
      -2.15625,
      1.6875,
      -1.6640625,
      -2.484375,
      0.6171875,
      4.03125,
      -4.03125,
      0.69140625,
      1.78125,
      -1.796875,
      -0.265625,
      -1.296875,
      1.2890625,
      1.4921875,
      -3.5,
      -3.78125,
      -0.46875,
      0.8125,
      0.5703125,
      0.5,
      -0.61328125,
      0.8359375,
      -2.140625,
      -0.06591796875,
      2.015625,
      -2.96875,
      0.51171875,
      -1.1484375,
      -0.63671875,
      0.06396484375,
      -0.10205078125,
      0.0291748046875,
      3.46875,
      -2.765625,
      -1.3046875,
      -0.4765625,
      0.439453125,
      -1.2734375,
      2.546875,
      2.140625,
      -4.0625,
      1.71875,
      -2.953125,
      0.4609375,
      -0.287109375,
      1.515625,
      2,
      -1.53125,
      -0.51171875,
      0.73828125,
      -0.396484375,
      1.8671875,
      -0.640625,
      -0.4296875,
      1.203125,
      2.875,
      2.8125,
      3.046875,
      -0.353515625,
      -1.609375,
      -2.515625,
      -1.5859375,
      2.21875,
      0.66015625,
      2.875,
      -3.53125,
      0.671875,
      1.4921875,
      -0.263671875,
      0.11328125,
      -0.1416015625,
      2.09375,
      2.015625,
      -0.5,
      4.28125,
      2.875,
      1.4375,
      1.375,
      -0.87890625,
      1.9140625,
      -0.62109375,
      -2.46875,
      0.32421875,
      -1.625,
      3.90625,
      -0.486328125,
      -1.59375,
      -0.0771484375,
      -0.392578125,
      1.171875,
      0.349609375,
      2.421875,
      -1.2109375,
      2.96875,
      0.1552734375,
      -0.02734375,
      0.578125,
      -3.03125,
      0.439453125,
      3.390625,
      -5.28125,
      -0.76171875,
      -0.79296875,
      0.84375,
      0.337890625,
      -0.115234375,
      -0.2265625,
      -0.671875,
      -1.5390625,
      -0.578125,
      0.34375,
      1.5625,
      2.0625,
      1.5078125,
      1.640625,
      1.9765625,
      -1.21875,
      0.337890625,
      0.1142578125,
      0.828125,
      1.578125,
      -0.400390625,
      0.92578125,
      -0.2392578125,
      -1.2109375,
      -4.6875,
      -4,
      -2.53125,
      -0.8125,
      2.9375,
      1.2421875,
      -0.91796875,
      -1.5234375,
      -0.2236328125,
      -0.28125,
      3.0625,
      3.109375,
      -2.921875,
      2.984375,
      -2.3125,
      -0.494140625,
      -1.5625,
      -1.1953125,
      -1.1953125,
      0.44140625,
      2.796875,
      0.10888671875,
      2.078125,
      -1.7109375,
      -0.98828125,
      2.28125,
      0.6796875,
      -1.2109375,
      1.1484375,
      0.375,
      1.40625,
      -1.0859375,
      2.421875,
      -1.0234375,
      3.484375,
      -0.306640625,
      0.353515625,
      2.5,
      2.515625,
      4.03125,
      0.83203125,
      -3.78125,
      -1.6640625,
      1,
      0.498046875,
      1.140625,
      0.3828125,
      0.5859375,
      6.65625,
      0.314453125,
      -1.71875,
      -1.421875,
      -1.484375,
      -1.59375,
      0.83984375,
      5.125,
      -5.59375,
      1.0859375,
      0.005645751953125,
      -1.421875,
      0.259765625,
      1.7734375,
      3.5,
      1.265625,
      1.5625,
      1.546875,
      0.439453125,
      -3.515625,
      0.2197265625,
      0.14453125,
      1.9765625,
      1.0546875,
      -1.6875,
      -0.83984375,
      0.267578125,
      -0.98828125,
      2.796875,
      -0.6796875,
      0.023681640625,
      3.75,
      0.1943359375,
      1.8984375,
      -0.6484375,
      -0.263671875,
      5.34375,
      -0.50390625,
      -1.7890625,
      -1.3046875,
      -2.390625,
      3.375,
      0.90234375,
      -0.27734375,
      -2.421875,
      2.5625,
      -0.94921875,
      -2.578125,
      -3.5,
      -1.671875,
      -2.96875,
      -1.5703125,
      -4.625,
      -0.98828125,
      -1.90625,
      4.3125,
      -1.4765625,
      0.498046875,
      1.1796875,
      4.4375,
      2.640625,
      3.875,
      -0.031494140625,
      2.71875,
      -0.984375,
      0.6328125,
      4.03125,
      -1.1328125,
      -3.796875,
      0.361328125,
      -1.2578125,
      -2.890625,
      -3.109375,
      -0.92578125,
      -2.390625,
      -0.64453125,
      -1.4375,
      -2.84375,
      0.384765625,
      1.3984375,
      -4.5625,
      0.5,
      -1.84375,
      0.69140625,
      0.7578125,
      0.6328125,
      -0.388671875,
      -0.03857421875,
      4.84375,
      -0.67578125,
      -0.04736328125,
      -1.25,
      -1.234375,
      0.6640625,
      -2,
      2.5,
      2.15625,
      -2.03125,
      -1.1640625,
      -1.3359375,
      2.578125,
      -3.015625,
      1.3984375,
      -0.330078125,
      -1.3046875,
      1.578125,
      6.0625,
      1.9140625,
      1.3671875,
      -1.3125,
      3.078125,
      -4.15625,
      -0.1826171875,
      -1.5078125,
      -0.91015625,
      -2.25,
      2.25,
      -1.2578125,
      3.265625,
      -1.1328125,
      2.3125,
      0.72265625,
      -4.84375,
      -0.1669921875,
      -2.953125,
      -2.484375,
      3.296875,
      -0.9609375,
      -3.25,
      -1.1953125,
      4.03125,
      -3.15625,
      2,
      -1.0859375,
      -0.44921875,
      2.15625,
      2.046875,
      1.15625,
      3.28125,
      -0.25390625,
      1.296875,
      5.375,
      1.796875,
      1.265625,
      1.484375,
      -1.640625,
      1.375,
      -1.1796875,
      2.5,
      -2.5625,
      -3.265625,
      0.08984375,
      0.1767578125,
      -0.54296875,
      -2.1875,
      2.359375,
      0.76171875,
      1.6015625,
      -1.8125,
      3.390625,
      0.86328125,
      3.78125,
      3.796875,
      0.71484375,
      -0.1708984375,
      -6.25,
      -2.5625,
      -0.671875,
      1.5390625,
      0.60546875,
      0.7265625,
      0.5078125,
      -2.03125,
      0.91796875,
      -1.78125,
      2.296875,
      -1.5859375,
      -0.86328125,
      -0.419921875,
      0.125,
      -0.1689453125,
      0.349609375,
      -4.0625,
      2.578125,
      -2.484375,
      -1.7265625,
      5.125,
      -0.7265625,
      -2.140625,
      -2.15625,
      2.515625,
      2.625,
      0.72265625,
      -0.279296875,
      0.0986328125,
      2.203125,
      -3.046875,
      1.4296875,
      2.921875,
      -0.16015625,
      1.53125,
      -1.1171875,
      -0.7734375,
      -5.46875,
      -1.125,
      -1.1875,
      1.671875,
      1.875,
      0.91015625,
      -0.43359375,
      5.59375,
      2.78125
    ],
    "structure": {
      "sections": [
        {
          "title": "The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "1. INTRODUCTION",
          "level": 1,
          "start_line": 17
        },
        {
          "title": "2. UNDERSTANDING LARGE LANGUAGE MODELS IN EDUCATION",
          "level": 1,
          "start_line": 27
        },
        {
          "title": "2.1. THE ARCHITECTURE AND MECHANISMS OF LLMS",
          "level": 1,
          "start_line": 29
        },
        {
          "title": "2.2. THE ROLE OF FINE-TUNING AND PROMPT-TUNING",
          "level": 1,
          "start_line": 37
        },
        {
          "title": "3. AUTOMATED QUESTION GENERATION: METHODOLOGIES AND TECHNIQUES",
          "level": 1,
          "start_line": 45
        },
        {
          "title": "3.1. GENERATING Diverse AND CONTEXTUALLY RELEVANT QUESTIONS",
          "level": 1,
          "start_line": 47
        },
        {
          "title": "3.2. TYPES OF QUESTIONS GENERATED BY LLMS",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "4. AUTOMATED ANSWER ASSESSMENT: EVALUATING STUDENT RESPONSES",
          "level": 1,
          "start_line": 83
        },
        {
          "title": "4.1. THE CAPABILITIES OF LLMS IN AUTOMATED ANSWER ASSESSMENT",
          "level": 1,
          "start_line": 85
        },
        {
          "title": "4.2. EXAMPLES OF SUCCESSFUL ASSESSMENTS AND AREAS FOR IMPROVEMENT",
          "level": 1,
          "start_line": 97
        },
        {
          "title": "5. HUMAN EVALUATION AND QUALITY METRICS FOR GENERATED QUESTIONS",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "5.1. ASSESSING THE QUALITY OF GENERATED QUESTIONS",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "5.2. VARIATIONS IN QUALITY ACROSS DIFFERENT METHODS",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "6. BROADER IMPLICATIONS AND FUTURE DIRECTIONS",
          "level": 1,
          "start_line": 131
        },
        {
          "title": "6.1. THE ROLE OF LLMS IN PERSONALIZED AND ADAPTIVE LEARNING",
          "level": 1,
          "start_line": 133
        },
        {
          "title": "6.2. ETHICAL CONSIDERATIONS AND CHALLENGES",
          "level": 1,
          "start_line": 141
        },
        {
          "title": "6.3. FUTURE DIRECTIONS IN AUTOMATED QUESTION GENERATION AND ASSESSMENT",
          "level": 1,
          "start_line": 149
        },
        {
          "title": "7. CONCLUSION",
          "level": 1,
          "start_line": 157
        },
        {
          "title": "REFERENCES",
          "level": 1,
          "start_line": 163
        }
      ]
    },
    "suggested_tags": [
      "教育AI",
      "自动出题",
      "LLM",
      "答案评估",
      "提示工程"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.98,
        "reason": "全文聚焦生成式AI在个性化教学、自动出题与评分等教育场景的应用，是核心应用领域。"
      },
      {
        "name": "自动出题",
        "confidence": 0.96,
        "reason": "系统探讨零样本、思维链、微调与提示微调等方法生成多语言、多题型试题，为论文主要任务。"
      },
      {
        "name": "LLM",
        "confidence": 0.95,
        "reason": "以GPT-4等大规模语言模型为技术底座，分析其机制、优势与挑战，贯穿全文。"
      },
      {
        "name": "答案评估",
        "confidence": 0.92,
        "reason": "专设章节研究LLM自动评分、反馈与 misconception 检测，是论文另一关键任务。"
      },
      {
        "name": "提示工程",
        "confidence": 0.9,
        "reason": "比较零样本、CoT 等提示策略对出题与评估质量的影响，为方法学重点。"
      }
    ],
    "category": "教育AI",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283473265",
          "title": "AI-Driven Question Generation System: Benchmarking Large Language Models for Examination Systems",
          "authors": [
            "Shahd Hassan Abdelhamied",
            "Kenzy Khaled Antr",
            "Cecilia Mohamed Abdellah",
            "Mohamed Khaled Antr",
            "Zeyad Mohamed Mahrous",
            "Noha Gamal Eldin"
          ],
          "year": 2025,
          "venue": "2025 16th Student Research Conference on Applied Computing (SRC)",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281553166",
          "title": "Neural Network Model for Automated Test Generation for Students in the Moodle System Based on the Analysis of Methodological Materials",
          "authors": [
            "К. С. Курочка",
            "Ю. С. Башаримов",
            "Konstantin S. Kurochka",
            "Yury S. Basharymau"
          ],
          "year": 2025,
          "venue": "Digital Transformation",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281511200",
          "title": "AI-Based Examination Content Creation: Evaluating Large Language Models for Question Generation",
          "authors": [
            "Shahd Hassan Abdelhamied",
            "Kenzy Khaled Antr",
            "Cecilia Mohamed Abdellah",
            "Mohamed Khaled Antr",
            "Zeyad Mohamed Mahrous",
            "Noha Gamal Eldin"
          ],
          "year": 2025,
          "venue": "Internet, Multimedia Systems and Applications",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280407655",
          "title": "Question Crafting System for Personalized Learning using Large Language Model",
          "authors": [
            "R. Dhanalakshmi",
            "Madala Akhil",
            "Gondrala Chethan",
            "Bijja Arun Teja",
            "Kulampalli Divyand"
          ],
          "year": 2025,
          "venue": "2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:279191318",
          "title": "Optimizing Automated Question Generation for Educational Assessments",
          "authors": [
            "Sumayyah Alamoudi",
            "Lama A. Al Khuzayem",
            "A. Jamal"
          ],
          "year": 2025,
          "venue": "Engineering, Technology &amp; Applied Science Research",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:273969892",
          "title": "CryptoLLM: Unleashing the Power of Prompted LLMs for SmartQnA and Classification of Crypto Posts",
          "authors": [
            "Aniket Deroy",
            "Subhankar Maity"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:273963099",
          "title": "Cancer-Answer: Empowering Cancer Care with Advanced Large Language Models",
          "authors": [
            "Aniket Deroy",
            "Subhankar Maity"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:273850172",
          "title": "Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages",
          "authors": [
            "Aniket Deroy",
            "Subhankar Maity"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:278672872",
          "title": "Toward Generating Quality Test Questions and Answers Using Quantized Low-Rank Adapters in LLMs",
          "authors": [
            "Jebum Choi",
            "SeongJun Hong",
            "SeoYoon Hong",
            "JiYeon Park",
            "Eun-Sung Jung"
          ],
          "year": 2025,
          "venue": "IEEE Access",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280036248",
          "title": "Machine Learning in Education: Innovations, Impacts, and Ethical Considerations",
          "authors": [
            "E. Elbasi",
            "Muhammad Nadeem",
            "Y. Alzoubi",
            "A. Topcu",
            "Greeshma Varghese"
          ],
          "year": 2025,
          "venue": "IEEE Access",
          "citation_count": 2
        }
      ],
      "citations_fetched_at": "2025-12-16T23:20:25.227984",
      "references": [
        {
          "external_id": "CorpusId:270209971",
          "title": "How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors?",
          "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
          ],
          "year": 2024,
          "venue": "Educational Data Mining",
          "citation_count": 10
        },
        {
          "external_id": "CorpusId:269921800",
          "title": "Exploring the Capabilities of Prompted Large Language Models in Educational and Assessment Applications",
          "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
          ],
          "year": 2024,
          "venue": "Educational Data Mining",
          "citation_count": 14
        },
        {
          "external_id": "CorpusId:269626345",
          "title": "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences",
          "authors": [
            "John Stamper",
            "Ruiwei Xiao",
            "Xinynig Hou"
          ],
          "year": 2024,
          "venue": "AIED Companion",
          "citation_count": 67
        },
        {
          "external_id": "CorpusId:267527222",
          "title": "Beyond Traditional Assessment: Exploring the Impact of Large Language Models on Grading Practices",
          "authors": [
            "Oluwole Fagbohun",
            "Nwaamaka Pearl Iduwe",
            "Mustapha Abdullahi",
            "Adeseye Ifaturoti",
            "Obinna Nwanna"
          ],
          "year": 2024,
          "venue": "Journal of Artificial Intelligence, Machine Learning and Data Science",
          "citation_count": 41
        },
        {
          "external_id": "CorpusId:268613943",
          "title": "A Survey on Security and Privacy of Large Multimodal Deep Learning Models: Teaching and Learning Perspective",
          "authors": [
            "Md. Abdur Rahman",
            "Lamyaa Alqahtani",
            "Amna Albooq",
            "Alaa Ainousah"
          ],
          "year": 2024,
          "venue": "2024 21st Learning and Technology Conference (L&T)",
          "citation_count": 15
        },
        {
          "external_id": "CorpusId:266999078",
          "title": "A Novel Multi-Stage Prompting Approach for Language Agnostic MCQ Generation using GPT",
          "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
          ],
          "year": 2024,
          "venue": "European Conference on Information Retrieval",
          "citation_count": 20
        },
        {
          "external_id": "CorpusId:266668276",
          "title": "Using LLMs to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students' text revision, motivation, and positive emotions",
          "authors": [
            "Jennifer Meyer",
            "Thorben Jansen",
            "Ronja Schiller",
            "Lucas Liebenow",
            "Marlene Steinbach",
            "Andrea Horbach",
            "Johanna Fleckenstein"
          ],
          "year": 2023,
          "venue": "Computers and Education: Artificial Intelligence",
          "citation_count": 182
        },
        {
          "external_id": "CorpusId:261470278",
          "title": "Leading teachers' perspective on teacher-AI collaboration in education",
          "authors": [
            "Jinhee Kim"
          ],
          "year": 2023,
          "venue": "Education and Information Technologies : Official Journal of the IFIP technical committee on Education",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:259367508",
          "title": "Exploring the potential of artificial intelligence tools in educational measurement and assessment",
          "authors": [
            "Valentine Joseph Owan",
            "Kinsgley Bekom Abang",
            "D. Idika",
            "Eugene Onor Etta",
            "B. Bassey"
          ],
          "year": 2023,
          "venue": "Eurasia Journal of Mathematics, Science and Technology Education",
          "citation_count": 221
        },
        {
          "external_id": "CorpusId:262183178",
          "title": "Developing a framework to re-design writing assignment assessment for the era of Large Language Models",
          "authors": [
            "Ya-Ping Hsiao",
            "Nadia Klijn",
            "Mei-Shiu Chiu"
          ],
          "year": 2023,
          "venue": "Learning: Research and Practice",
          "citation_count": 31
        }
      ],
      "references_fetched_at": "2025-12-16T23:20:26.278416"
    },
    "translated_content": "# 生成式人工智能时代的未来学习：基于大语言模型的自动问题生成与评估\n\nSubhankar Maity  \n人工智能系  \n印度理工学院哈拉格普尔分校  \nsubhankar.ai@kgpian.iitkgp.ac.in\n\nAniket Deroy  \n计算机科学与工程系  \n印度理工学院哈拉格普尔分校  \nroydanik18@kgpian.iitkgp.ac.in\n\n近年来，大语言模型（LLMs）与生成式人工智能彻底革新了自然语言处理（NLP），在教育领域展现出前所未有的能力。本章探讨 LLMs 在自动问题生成与答案评估中的变革潜力。首先剖析 LLMs 的内在机制，强调其理解并生成类人文本的能力；继而阐述创建多样化、语境相关问题的诸多方法，通过个性化、自适应策略提升学习效果。文中评估了零样本提示（zero-shot prompting）与思维链提示（chain-of-thought prompting）等关键提示技术在生成高质量问题（涵盖开放式与多选题，且支持多语言）方面的有效性。此外，探讨了微调（fine-tuning）与提示微调（prompt-tuning）等高级 NLP 方法在生成任务特定问题中的作用，尽管其伴随一定成本。本章亦涵盖生成问题的人工评估，揭示不同方法在质量上的差异及改进空间。进一步地，文章深入自动答案评估，展示 LLMs 如何精准评判作答、提供建设性反馈，并识别细微理解或误解。案例既呈现了成功评估，也指出待改进之处。讨论强调，在适当引导下，LLMs 有望替代昂贵且耗时的人工评估，彰显其在简化教育流程中的高级理解与推理能力。\n\n关键词：自然语言处理（NLP），大语言模型（LLMs），教育，自动问题生成（AQG），答案评估，提示工程\n\n# 1. 引言\n\n教育格局正以前所未有的速度演进，先进技术的融入不断挑战传统教学方式。其中，大语言模型（LLMs）已成为强大工具，足以革新学习与评估的路径。以 GPT-4（Achiam 等，2023）及后续系统为代表的这些模型，已展现出非凡的类人文本理解与生成能力，使其能够执行曾专属于人类的任务。of human educators (Brown et al., 2020; Floridi and Chiriatti, 2020)。在教育领域，问题生成与测评是塑造学习体验的关键环节。传统上，这些任务需要大量人力投入，教师需精心设计既能检验知识又能促进深层理解的问题（Mazidi and Nielsen, 2014）。对学生回答的评估，尤其是开放式回答，更是一项劳动密集型工作，需要充分考虑语境、细微差别以及学生个体差异（Chappuis et al., 2015）。然而，随着个性化与自适应学习需求的不断增长，纯人工方法的局限性日益凸显。\n\n本章深入探讨大语言模型（LLMs）在自动化这些核心教育任务中的变革潜力。我们将研究如何利用 LLMs 生成从简单事实性提问到复杂开放式问题的多样化题型，使其既贴合语境又契合教育目标（Maity et al., 2023; Maity et al., 2024a; Maity et al., 2024c）。同时，我们考察 LLMs 在自动答案评估中的能力：这些模型可在规模和效率上超越人工，评估学生回答、提供反馈，甚至识别微妙的误解（Fagbohun et al., 2024）。将 LLMs 引入教育过程并非没有挑战。生成问题的质量与相关性、自动评估的准确性，以及依赖 AI 带来的伦理问题，均需审慎考量（Floridi and Cowls, 2022）。\n\n本章回应上述关切，提出如何引导并优化 LLMs，使其补充并增强而非取代以人为主导的教育。随后各节中，我们首先概述 LLMs，聚焦其架构与底层机制，为后续讨论教育问题生成的各类方法与提示技术奠定基础。继而探讨微调（fine-tuning）与提示调优（prompt-tuning）等高级 NLP 方法，以提升生成问题的质量与针对性。本章还将介绍用于评估问题质量的人工评价指标，以及 LLMs 在自动答案评估中的表现。最后，我们讨论将 LLMs 整合至教育中的广泛影响，强调其潜在益处与需应对的挑战，以充分实现其潜能。\n\n# 2. 教育中的大语言模型：理解篇\n\n# 2.1 LLMs 的架构与机制大型语言模型（LLMs）以深度学习与 Transformer 架构（Vaswani et al., 2017）为基础，在自然语言处理（NLP）领域引发了范式变革。这类模型通过大规模文本语料训练，旨在根据给定输入预测并生成文本（Radford et al., 2019）。其理解语境、识别模式并生成连贯且语境恰当文本的能力，使其尤为适用于教育场景。\n\nLLM 的核心在于 Transformer 架构，该架构利用自注意力机制衡量句子中不同词汇之间的相对重要性（Vaswani et al., 2017）。这使得模型能够捕获文本中的长程依赖，从而理解复杂句子并生成细致入微的回应。就教育应用而言，这意味着 LLM 不仅能生成语法正确的问题，还能确保问题在语境上相关且符合教学原则。LLM 的训练过程涉及对涵盖广泛主题与写作风格的多样化数据集的暴露（Raiaan et al., 2024）。这种大规模训练使模型形成对语言的广泛理解，进而可应用于问题生成与评估等具体任务。然而，尽管 LLM 在生成类人文本方面表现卓越，其在教育情境中的有效性仍取决于针对特定任务的引导与微调程度。\n\n# 2.2 微调与提示微调的作用\n\n为使 LLM 适应教育领域的问题生成与评估，研究者采用微调（fine-tuning）与提示微调（prompt-tuning）等技术。微调通过在专门构建、与目标任务高度对齐的数据集上继续训练 LLM，使模型习得教育内容的细微差别，从而生成更贴合课程与学习目标的问题（Li et al., 2023）。\n\n提示微调则通过设计特定提示，引导 LLM 生成期望输出（Lester et al., 2021）。该技术利用模型既有知识，并将其导向生成语境相关且具教学价值的问题。例如，提示可指令 LLM 基于特定文本段落生成问题，促使模型聚焦对学习至关重要的关键概念与思想。微调（fine-tuning）与提示调优（prompt-tuning）各有优势与挑战。微调能够产生高度专门化、在特定任务上表现卓越的模型，但其过程资源密集，且需依赖大规模、高质量的数据集（Raffel et al., 2020）。提示调优则更为灵活且资源需求较低，但其效果高度依赖于提示的设计，且未必能达到微调模型所具备的特定任务精度（Lester et al., 2021）。尽管存在上述挑战，两种技术均在提升大语言模型于教育场景中的表现方面展现出巨大潜力。\n\n# 3. 自动问题生成：方法论与技术\n\n# 3.1 生成多样化且情境相关的问题\n\n利用大语言模型（LLMs）进行自动问题生成，已成为教育领域的一项有力工具，能够针对多元学习目标生成多样化且情境相关的问题（Maity et al., 2024a）。该领域所采用的方法论丰富多样，各自对生成内容的质量与适用性产生贡献。以下列举了本领域中的关键方法：\n\n- **零样本提示（Zero-Shot Prompting）**：零样本学习使得 GPT-3 等模型（Brown et al., 2020）可在极少指令下生成问题。模型依托其预训练知识，无需额外示例或微调，即可直接从给定文本生成相关问题（Brown et al., 2020）。该方法适用于跨领域问题生成，但生成质量可能因输入文本复杂度而异（Maity et al., 2023；Maity et al., 2024b）。\n- **少样本提示（Few-Shot Prompting）**：少样本提示通过向模型提供若干任务示例来引导问题生成。通过在提示中加入少量问答对，该方法可增强模型对任务的理解，从而提升生成问题的相关性与质量（Brown et al., 2020）。当所需问题格式或内容较为复杂、需向模型明确界定时，此技术尤为有效。- 思维链提示（Chain-of-Thought Prompting）：一种结构化技术，通过在生成最终问题之前引导大语言模型（LLM）进行逐步推理。例如，模型可先被要求总结一段文本、识别关键概念，然后生成一个考查这些概念理解的问题（Wei et al., 2022；Maity et al., 2024d）。该方法尤其适用于生成需要批判性思维与分析的高阶问题，确保问题与特定教育目标一致。  \n- 微调（Fine-Tuning）：通过在目标领域相关的问题-答案数据集上进一步训练 LLM，使其学习有效问题的模式与结构，从而生成更准确且语境特定的问题（Raffel et al., 2020）。该方法资源密集，但可得到高度专业化的模型，能够针对特定学科或课程生成高质量问题（Maity et al., 2023）。  \n- 提示微调（Prompt-Tuning）：一种新近且计算高效的技术，仅调整少量参数（即提示），其余模型参数保持不变。该方法已在多种教育场景中被证明能有效生成高质量问题，尤其适用于在不进行大规模重训练的情况下，将通用 LLM 适配到特定任务（Lester et al., 2021）。提示微调可快速实现 LLM 的适配与定制，以生成既相关又符合特定教育目标的问题。  \n- 多面与多语言问题生成：LLM 既能生成开放式问题（Maity et al., 2023），也能生成选择题（Maity et al., 2024d），以满足不同评估需求。开放式问题促进批判性思维与探究，而选择题则便于评估具体知识或技能（Maity et al., 2024d）。此外，LLM 的多语言能力使其能够在多种语言中生成问题，成为语言学习与跨文化教育的重要工具（Radford et al., 2019；Maity et al., 2024d）。\n\n若有效应用，这些方法可通过生成多样化、高质量的问题，提升教育过程，满足不同学习情境与目标。随着 LLM 的不断演进，这些技术的整合将进一步提高教育领域自动问题生成的相关性、准确性与实用性。\n\n# 3.2. LLM 生成的问题类型\n\n在教育语境中，不同类型的问题承担不同的教学功能，而 LLM 能够生成广泛的问题类型。主要类别如下：- 事实性问题：此类问题聚焦于对具体信息（如日期、定义或事件）的回忆，通常较为直接，旨在评估学生对学科内容的记忆与基本理解（Mulla and Gharpure, 2023）。\n\n示例：“法国的首都是哪里？”\n\n- 开放性问题：开放性问题旨在鼓励深入思考与探索，允许学生自由且富有创造性地表达观点。这类问题并无唯一正确答案，有助于促进批判性思维与课堂讨论（Mulla and Gharpure, 2023；Maity et al., 2023）。\n\n示例：“购买力平价的作用是什么？”\n\n- 多项选择题（MCQs）：MCQs 通过提供一组备选答案，要求学生从中选出正确答案，以评估特定知识或技能。因其测试与评分的效率而被广泛使用（Maity et al., 2024d）。\n\n示例：“以下哪颗行星是太阳系中最大的？\n\n(a) 地球 (b) 木星 (c) 火星 (d) 金星”\n\n凭借先进的语言处理能力，大语言模型（LLMs）能够有效生成上述多种题型，并根据不同的教育情境与学习目标进行适配。\n\n# 4. 自动化答案评估：对学生回答的评价\n\n# 4.1 大语言模型在自动化答案评估中的能力\n\n除生成问题外，大语言模型在自动化答案评估方面也展现出显著潜力（Fagbohun et al., 2024）。准确评估学生回答并提供反馈，是教育过程中的关键环节（Fagbohun et al., 2024）。传统上，该任务由人类教师完成，他们需仔细考量每份回答的内容、语境与细微差别（Balfour, 2013）。然而，随着对个性化与可扩展教育需求的不断增长，人工评估的局限性日益凸显（Luckin and Holmes, 2016）。\n\n大语言模型为自动化答案评估提供了可扩展的解决方案，能够评估从简单事实性答案到复杂开放性论文的广泛回答类型（Fagbohun et al., 2024）。借助其对语言与语境的深层理解，大语言模型可识别关键概念、判断回答的准确性，并提供建设性反馈（Stamper et al., 2024）。在大规模教育场景中，学生回答数量庞大，人工评阅难以为继，该能力尤显珍贵（Broadbent et al., 2018）。\n\n大语言模型在自动化评估中的一大核心优势，是能够识别学生回答中的细微理解或误解（Kazi, 2023）。例如，在评估一篇关于历史事件的论文时，大语言模型可判断学生是否把握了事件的深层原因与影响，而非仅仅罗列事实（Kasneci et al., 2023）。然而，尽管大语言模型（LLM）在自动评估方面展现出巨大潜力，但仍需应对若干挑战（Fagbohun et al., 2024）。首要关切之一在于评估的准确性与一致性。LLM 与所有人工智能系统一样并非无懈可击，有时会生成错误或有偏见的评价（Owan et al., 2023）。确保评估公平、准确，并与学习目标保持一致，对于 LLM 在教育过程中的成功整合至关重要（Fagbohun et al., 2024）。\n\n# 4.2 成功评估案例与改进空间\n\n为说明 LLM 在自动答案评估中的能力，可参看以下示例：\n\n- **简答题评分**：某 LLM 被用于生物学考试中简答题的评分（Shin and Gierl, ）。该模型能够准确判断学生是否正确识别了细胞内某一细胞器的功能，并针对正确与错误答案均提供反馈。LLM 还能识别常见误解，例如将线粒体与细胞核的功能混淆，并给出纠正性反馈以引导学生学习。  \n- **作文评分**：在历史课上，学生需撰写关于第二次世界大战起因与影响的短文。LLM 依据理解关键事件、分析历史因素及论证连贯性等标准对作文进行评价。模型能够识别论证充分之处，并就学生可改进之处（如提供更多证据或考虑替代视角）给出反馈（Mansour et al., 2024; Henkel et al., 2024）。  \n- **选择题分析**：某 LLM 被用于分析数学考试中选择题的学生作答情况（Henkel et al., 2024）。除识别正确答案外，模型还分析错误选项的分布模式，识别常见错误与误解，并据此提供针对性反馈，指出需进一步学习的领域。\n\n尽管上述示例展示了 LLM 在自动评估中的潜力，但仍存在改进空间。一项挑战在于确保 LLM 提供的反馈具有建设性且可执行（Meyer et al., 2024a）。例如，模型在正确指出学生错误的同时，还需就如何纠正错误提供明确指导。此外，LLM 必须能够根据每位学生的先备知识与学习风格，调整其反馈内容，以满足个体化需求。另一个亟需改进的方向是提升大语言模型（LLM）对复杂且富有创造性的回答——例如涉及批判性思维、问题解决或艺术表达的回答——进行评估的能力。尽管 LLM 在理解与生成文本方面已取得显著进展，但对这些高阶技能的评估仍面临挑战（Hsiao et al., 2023）。未来的研究与开发需进一步增强 LLM 在此类任务上的能力，以确保其能够全面满足学习者多样化的需求。\n\n# 5. 生成题目的人工评估与质量指标\n\n# 5.1 生成题目的质量评估\n\nLLM 生成题目的质量是决定其作为教育工具有效性的关键因素。高质量题目应当清晰、相关，并与学习目标保持一致，能够促使学生进行批判性思考并应用所学知识。为确保 LLM 生成的题目达到上述标准，人工评估与质量指标发挥着至关重要的作用（Kurdi et al., 2020）。\n\n人工评估依据一套预先设定的标准对生成题目进行评判，这些标准包括语法正确性、相关性、清晰度、复杂度以及与课程的对齐程度（Kurdi et al., 2020；Maity et al., 2023）。评估通常由资深教师或学科专家执行，他们针对题目的优缺点提供反馈。此类反馈对于优化提示语并提升生成题目的质量具有不可替代的价值。\n\n除人工评估外，还可借助自动化质量指标对生成题目进行评价。这些指标可能包括基于 unigram、bigram 及 n-gram 的评估方法，能够从量化角度提供题目质量的洞见（Kurdi et al., 2020）。然而，用于评估 LLM 生成题目的自动化指标存在局限性：其往往侧重于语言表层相似度（如字符、unigram、bigram 或最长公共子序列的重合度），而非更深层的语境理解（Nema and Khapra, 2018）。\n\n评估生成题目质量的一大挑战在于部分标准具有主观性。例如，某位教师可能认为某题具有挑战性且发人深省，而另一位教师则可能视其为过于复杂或表述不清（Crogman and Trebeau Crogman, 2018）。为此，必须制定明确的评估指南与标准，以确保评估过程的一致性与客观性。\n\n# 5.2 不同方法间质量的差异由大语言模型（LLM）生成的问题质量会因所用方法与技术而显著差异。例如，采用零样本提示（zero-shot prompting）生成的问题往往较为宽泛，且与特定内容的契合度较低；而经过微调（fine-tuning）或提示微调（prompt-tuning）生成的问题则通常更为精准且相关（Maity et al., 2023）。理解这些差异对于在特定教育情境中选择恰当方法至关重要。\n\n质量差异的一个常见维度体现在生成问题的复杂度上。LLM 既能生成简单的事实性问题，也能生成更具分析性的高阶问题（Maity et al., 2024b）。然而，后者需要对内容与情境有更深层的理解，仅凭基础提示技术未必能够实现。为生成高阶问题，往往需借助更先进的技术，如思维链提示（chain-of-thought prompting）（Wei et al., 2022）或微调（Raffel et al., 2020）。\n\n另一质量差异则与生成问题所体现的文化与语言多样性有关。基于多样化数据集训练的 LLM 更擅长生成具有文化相关性、适用于不同学生群体的问题。然而，这种多样性亦可能带来挑战：模型可能生成某些学生群体不甚熟悉或关联度较低的问题。因此，在评估过程中，确保生成的问题具有包容性并能为所有学习者所理解，是一项重要考量（Maity et al., 2024a; Maity et al., 2024b）。\n\n# 6. 更广泛的影响与未来方向\n\n# 6.1 LLM 在个性化与自适应学习中的作用\n\n随着 LLM 的不断演进，其在个性化与自适应学习中的作用日益凸显。LLM 能够大规模生成情境相关的问题并评估学生回答，这为个性化教育开辟了新路径（Alier et al., 2023）。借助 LLM，教育者可打造量身定制的学习体验，使之适应每位学生的个体需求与学习进度（Goslen et al., 2024）。\n\n在个性化学习中应用 LLM 的一大优势在于其能够提供即时反馈与指导（Meyer et al., 2024b）。当学生与系统互动时，LLM 可生成挑战其理解的问题，识别其困难领域，并提供针对性反馈以支持学习。这种实时互动不仅有助于学生保持投入与动机，也为教育者提供了关于学生进展的宝贵洞察。然而，将大语言模型（LLMs）融入个性化学习也引发了关于“人—机”教育平衡的重要议题（Yekollu et al., 2024）。尽管 LLMs 能够提供可扩展且高效的解决方案，却无法取代人类教师对课堂情境的细腻理解与情感共鸣。关键在于寻求恰当平衡，使 LLMs 成为人类主导教育的补充与增强，而非取而代之。\n\n# 6.2 伦理考量与挑战\n\n在教育领域部署 LLMs 亦带来一系列伦理关切（Meyer et al., 2024b）。偏见、公平性与透明度等问题是负责任地使用教育 AI 的核心（Memarian and Doleck, 2023）。LLMs 同所有 AI 系统一样，依赖的训练数据可能蕴含偏见，这些偏见会体现在其生成的问题或评估结果中（Memarian and Doleck, 2023）。要确保 LLMs 的公平与无偏，需对训练数据保持审慎，并对系统输出进行持续监测与评估。\n\n另一项伦理考量是 AI 驱动教育过程的透明度（Badawi et al., 2018）。学生与教师需要理解 LLMs 如何生成问题、如何评判答案，并知晓系统潜在的局限与偏见（Memarian and Doleck, 2023）。透明度是建立对 AI 教育信任的关键，也能确保师生在使用这些技术时保持信心（Kim, 2024）。\n\n最后，LLMs 在教育中的应用还引发数据隐私与安全的问题（Rahman et al., 2024）。当 LLMs 与学生互动并评估其作答时，可能收集并存储有关学生表现与学习历程的敏感信息。保护这些数据并确保其被负责任地使用，对于维护教育过程的完整性与安全性至关重要。\n\n# 6.3 自动问题生成与评估的未来方向\n\n展望未来，LLMs 在自动问题生成与评估中的作用有望进一步扩展与演化（Fagbohun et al., 2024）。人工智能与自然语言处理技术的进步将催生更复杂的模型，使其能够胜任复杂且富有创造性的教育任务（Alqahtani et al., 2023）。随着这些模型更深地融入教育流程，它们将在支持个性化与自适应学习方面发挥关键作用，提供可扩展的解决方案，从而提升教育的质量与可及性。未来研究的一个颇具前景的方向是开发能够评估高阶思维技能（如批判性思维、问题解决与创造力）的模型。这些技能对 21 世纪的成功至关重要，而准确且高效地评估它们则是教育工作者面临的一项重大挑战。凭借先进的语言理解与生成能力，大语言模型（LLMs）有望应对这一挑战，为评估并支持这些关键技能的发展提供新的工具（Moore et al., 2023）。\n\n未来研究的另一重要方向是探索用于微调（fine-tuning）与提示调优（prompt-tuning）LLMs 的新方法，以适配特定的教育任务。随着 LLMs 被应用于日益广泛的教育情境，开发能够高效且有效地将这些模型适配到不同学科领域、学生群体及学习目标的技术显得尤为关键。\n\n# 7. 结论\n\n综上所述，大语言模型有望通过自动问题生成与答案评估革新教育。这些模型凭借理解与生成类人文本的能力，提供了可扩展的解决方案，能够增强个性化与自适应学习。借助先进的提示技术与微调方法，教育工作者可创建高质量、情境相关的问题，既能挑战学生，又能支持其学习。此外，LLMs 在自动评估方面的能力可提供及时且建设性的反馈，帮助学生识别改进领域并引导其学习旅程。\n\n然而，将 LLMs 融入教育亦带来需审慎应对的挑战与伦理考量。确保人工智能驱动的教育过程的公平性、准确性与透明度，对于建立对这些技术的信任与信心至关重要。展望未来，持续的研究与开发将是实现 LLMs 教育潜能的关键，从而为所有学生创造更加个性化、自适应且可及的学习体验。\n\n# 参考文献\n\nACHIAM, J., ADLER, S., AGARWAL, S., AHMAD, L., AKKAYA, I., ALEMAN, F. L., ALMEIDA, D., ALTENSCHMIDT, J., ALTMAN, S., ANADKAT, S., ET AL. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.  \nALIER, M., CASAN, M. J., AND FILVA, D. A. 2023. Smart learning applications: Leveraging llms for contextualized and ethical educational technology. In International conference on technological ecosystems for enhancing multiculturality. Springer, 190-199.ALQAHTANI, T., BADRELDIN, H. A., ALRASHED, M., ALSHAYA, A. I., ALGHAMDI, S. S., BIN SALEH, K., ALOWAIS, S. A., ALSHAYA, O. A., RAHMAN, I., AL YAMI, M. S., 等. 2023. 人工智能、自然语言处理与大型语言模型在高等教育与研究中的新兴角色. *Research in Social and Administrative Pharmacy* 19, 8, 1236-1242.  \nBADAWI, G., DE BEYROUTH, G., 与 BADAWI, H. 2018. AI 驱动的教育范式：教学与学习中的机遇、挑战与伦理考量.  \nBALFOUR, S. P. 2013. MOOCs 中的写作评估：自动作文评分与 Calibrated Peer Review™. *Research & Practice in Assessment* 8, 40-48.  \nBROADBENT, J., PANADERO, E., 与 BOUD, D. 2018. 以形成性取向实施总结性评估：大班教学案例研究. *Assessment & Evaluation in Higher Education* 43, 2, 307-322.  \nBROWN, T., MANN, B., RYDER, N., SUBBIAH, M., KAPLAN, J. D., DHARIWAL, P., NEELAKANTAN, A., SHYAM, P., SASTRY, G., ASKELL, A., AGARWAL, S., HERBERT-VOSS, A., KRUEGER, G., HENIGHAN, T., CHILD, R., RAMESH, A., ZIEGLER, D., WU, J., WINTER, C., HESSE, C., CHEN, M., SIGLER, E., LITWIN, M., GRAY, S., CHESS, B., CLARK, J., BERNER, C., MCCANDLISH, S., RADFORD, A., SUTSKEVER, I., 与 AMODEI, D. 2020. 语言模型是小样本学习者. 载于 *Advances in Neural Information Processing Systems*, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, 与 H. Lin 编. 第 33 卷. Curran Associates, Inc., 1877-1901.  \nCHAPPUIS, J. 等. 2015. 促进学习的七种评估策略. Pearson.  \nCROGMAN, H. 与 TREBEAU CROGMAN, M. 2018. 改进的生成问题学习及其课堂实施与评估. *Cogent Education* 5, 1, 1459340.  \nFAGBOHUN, O., IDUWE, N., ABDULLAHI, M., IFATUROTI, A., 与 NWANNA, O. 2024. 超越传统评估：探索大型语言模型对评分实践的影响. *Journal of Artificial Intelligence and Machine Learning & Data Science* 2, 1, 1-8.  \nFLORIDI, L. 与 CHRIATTI, M. 2020. GPT-3：其本质、范围、局限与后果. *Minds and Machines* 30, 681–694.  \nFLORIDI, L. 与 COWLS, J. 2022. 面向社会的 AI 五大原则统一框架. 载于 *Machine Learning and the City: Applications in Architecture and Urban Design*, 535-545.  \nGOSLEN, A., KIM, Y. J., ROWE, J., 与 LESTER, J. 2024. 基于 LIM 的学生计划生成用于游戏化学习环境中的自适应支架. *International Journal of Artificial Intelligence in Education*, 1-26.  \nHENKEL, O., HILLS, L., BOXER, A., ROBERTS, B., 与 LEVONIAN, Z. 2024. 大型语言模型能否给出合格分数？评估 LLM 在 K-12 教育中批改简答题能力的实证研究. 载于 *Proceedings of the Eleventh ACM Conference on Learning@ Scale*, 300-304.  \nHSIAO, Y.-P., KLIJN, N., 与 CHIU, M.-S. 2023. 构建面向大型语言模型时代的写作作业评估再设计框架. *Learning: Research and Practice* 9, 2, 148-158.  \nKASNECI, E., SESSLER, K., KÜCHEMANN, S., BANNERT, M., DEMENTIEVA, D., FISCHER, F., GASSER, U., GROH, G., GUNNEMANN, S., HÜLLERMEIER, E., 等. 2023. ChatGPT 能否向善？论大型语言模型在教育中的机遇与挑战. *Learning and Individual Differences* 103, 102274.  \nKAZI, N. H. 2023. 利用大型语言模型实现自动简答题评分与迷思检测. University of North Florida.  \nKIM, J. 2024. 教师视角下的教师—AI 协作教育. *Education and Information Technologies* 29, 7, 8693–8724.KURDI, G., LEO, J., PARSIA, B., SATTLER, U., 与 AL-EMARI, S. 2020. 面向教育目的的自动问题生成研究综述. International Journal of Artificial Intelligence in Education 30, 121-204.  \nLESTER, B., AL-RFOU, R., 与 CONSTANT, N. 2021. 规模之力：参数高效提示微调. arXiv 预印本 arXiv:2104.08691.  \nLI, Q., FU, L., ZHANG, W., CHEN, X., YU, J., XIA, W., ZHANG, W., TANG, R., 与 YU, Y. 2023. 面向教育的大型语言模型适配：基础能力、潜力与挑战. arXiv 预印本 arXiv:2401.08664.  \nLUCKIN, R. 与 HOLMES, W. 2016. 智能释放：教育人工智能之辩.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2023. 利用基于提示的技术借助大型语言模型生成中小学水平问题. 见：第 15 届信息检索评估论坛年会论文集. 30-39.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024a. 探索提示式大型语言模型在教育与测评应用中的能力. 见：第 17 届教育数据挖掘国际会议论文集，B. PaaÄyen 与 C. D. Epp 编. 国际教育数据挖掘学会，美国佐治亚州亚特兰大，961-968.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024b. GPT-4 Turbo 基于布鲁姆修订版分类法从教科书生成中小学水平问题的有效性如何？  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024c. 生成式预训练大型语言模型解释孟加拉语语法错误的就绪度研究. 见：第 17 届教育数据挖掘国际会议论文集，B. PaaÄyen 与 C. D. Epp 编. 国际教育数据挖掘学会，美国佐治亚州亚特兰大，664-671.  \nMAITY, S., DEROY, A., 与 SARKAR, S. 2024d. 一种用于语言无关多项选择题生成的新型多阶段提示方法——基于 GPT. 见：欧洲信息检索会议. Springer, 268-277.  \nMANSOUR, W., ALBATARNI, S., ELTANBOULY, S., 与 ELSAYED, T. 2024. 大型语言模型能否自动评分书面作文的熟练度？ arXiv 预印本 arXiv:2403.06149.  \nMAZIDI, K. 与 NIELSEN, R. 2014. 自动问题生成中的语言学考量. 见：第 52 届计算语言学协会年会论文集（第 2 卷：短文）. 321-326.  \nMEMARIAN, B. 与 DOLECK, T. 2023. 人工智能（AI）在高等教育中的公平性、问责性、透明性与伦理（FATE）：一项系统综述. Computers and Education: Artificial Intelligence, 100152.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., 与 FLECKENSTEIN, J. 2024a. 利用 LLMs 将循证反馈带入课堂：AI 生成的反馈提升中学生文本修订、动机与积极情绪. Computers and Education: Artificial Intelligence 6, 100199.  \nMEYER, J., JANSEN, T., SCHILLER, R., LIEBENOW, L. W., STEINBACH, M., HORBACH, A., 与 FLECKENSTEIN, J. 2024b. 利用 LLMs 将循证反馈带入课堂：AI 生成的反馈提升中学生文本修订、动机与积极情绪. Computers and Education: Artificial Intelligence 6, 100199.  \nMOORE, S., TONG, R., SINGH, A., LIU, Z., HU, X., LU, Y., LIANG, J., CAO, C., KHOSRAVI, H., Denny, P. 等. 2023. 以 LLMs 赋能教育——下一代界面与内容生成. 见：人工智能教育国际会议. Springer, 32-37.MULLA, N. 与 GHARPURE, P. 2023. 自动问题生成：方法、数据集、评估指标与应用综述. *Progress in Artificial Intelligence* 12, 1, 1-32.  \nNEMA, P. 与 KHAPRA, M. M. 2018. 迈向更优的问题生成系统评估指标. arXiv 预印本 arXiv:1808.10192.  \nOWAN, V. J., ABANG, K. B., IDIKA, D. O., ETTA, E. O., 与 BASSEY, B. A. 2023. 探索人工智能工具在教育测量与评估中的潜力. *Eurasia Journal of Mathematics, Science and Technology Education* 19, 8, em2307.  \nRADFORD, A., WU, J., CHILD, R., LUAN, D., AMODEI, D., SUTSKEVER, I. 等. 2019. 语言模型是无监督多任务学习者. *OpenAI Blog* 1, 8, 9.  \nRAFFEL, C., SHAZEER, N., ROBERTS, A., LEE, K., NARANG, S., MATENA, M., ZHOU, Y., LI, W., 与 LIU, P. J. 2020. 探索迁移学习极限的统一文本到文本 Transformer. *Journal of Machine Learning Research* 21, 140, 1-67.  \nRAHMAN, M. A., ALQAHTANI, L., ALBOOQ, A., 与 AINOUSAH, A. 2024. 大型多模态深度学习模型的安全与隐私综述：教学视角. 载于 *2024 第 21 届学习与科技大会 (L&T)*. IEEE, 13-18.  \nRAIAAN, M. A. K., MUKTA, M. S. H., FATEMA, K., FAHAD, N. M., SAKIB, S., MIM, M. M. J., AHMAD, J., ALI, M. E., 与 AZAM, S. 2024. 大型语言模型综述：架构、应用、分类体系、开放问题与挑战. *IEEE Access*.  \nSHIN, J. 与 GIERL, M. J. 科学评估中自动项目生成的自动短答案评分. 载于 *Routledge 国际自动作文评分手册*. Routledge, 504-534.  \nSTAMPER, J., XIAO, R., 与 HOU, X. 2024. 增强基于大语言模型的反馈：来自智能导学系统与学习科学的洞见. 载于 *人工智能教育国际会议*. Springer, 32-43.  \nVASWANI, A., SHAZEER, N., PARMAR, N., USZKOREIT, J., JONES, L., GOMEZ, A. N., KAISER, L. U., 与 POLOSUKHIN, I. 2017. Attention is all you need. 载于 *神经信息处理系统进展*, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, 与 R. Garnett 编. 第 30 卷. Curran Associates, Inc.  \nWEI, J., WANG, X., SCHUURMANS, D., BOSMA, M., ICHTER, B., XIA, F., CHI, E., LE, Q. V., 与 ZHOU, D. 2022. 思维链提示激发大语言模型推理能力. 载于 *神经信息处理系统进展*, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, 与 A. Oh 编. 第 35 卷. Curran Associates, Inc., 24824-24837.  \nYEKOLLU, R. K., BHIMRAJ GHUGE, T., SUNIL BIRADAR, S., HALDIKAR, S. V., 与 FAROOK MOHIDEEN ABDUL KADER, O. 2024. AI 驱动的个性化学习路径：通过自适应系统提升教育. 载于 *智能数据国际会议*. Springer, 507-517.",
    "is_translated": true
  },
  "f073a540-29cb-4a8a-b4e8-980e96e8a325": {
    "id": "f073a540-29cb-4a8a-b4e8-980e96e8a325",
    "filename": "a-large-language-model-assisted-education-tool-to-provide-feedback-on-open-ended-responses.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/f073a540-29cb-4a8a-b4e8-980e96e8a325_a-large-language-model-assisted-education-tool-to-provide-feedback-on-open-ended-responses.pdf",
    "status": "completed",
    "created_at": "2025-12-17 09:34:10.139329",
    "updated_at": "2025-12-17 01:35:34.355330",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "A large language model-assisted education tool to provide feedback on open-ended responses",
    "markdown_content": "# A large language model-assisted education tool to provide feedback on open-ended responses\n\nJordan K. Matelsky  $^{1,2}$ , Felipe Parodi  $^{3}$ , Tony Liu  $^{4}$ , Richard D. Lange  $^{1,5}$ , and Konrad P. Kording  $^{1,3,4,6}$\n\n$^{1}$ Department of Bioengineering, University of Pennsylvania;  $^{2}$ Research & Exploratory Development Department, Johns Hopkins University Applied Physics Laboratory;  $^{3}$ Department of Neuroscience, University of Pennsylvania;  $^{4}$ Department of Computer Science, University of Pennsylvania;  $^{5}$ Department of Computer Science, Rochester Institute of Technology;  $^{6}$ CIFAR LMB Program\n\nOpen-ended questions are a favored tool among instructors for assessing student understanding and encouraging critical exploration of course material. Providing feedback for such responses is a time-consuming task that can lead to overwhelmed instructors and decreased feedback quality. Many instructors resort to simpler question formats, like multiple-choice questions, which provide immediate feedback but at the expense of personalized and insightful comments. Here, we present a tool that uses large language models (LLMs), guided by instructor-defined criteria, to automate responses to open-ended questions. Our tool delivers rapid personalized feedback, enabling students to quickly test their knowledge and identify areas for improvement. We provide open-source reference implementations both as a web application and as a Jupyter Notebook widget that can be used with instructional coding or math notebooks. With instructor guidance, LLMs hold promise to enhance student learning outcomes and elevate instructional methodologies.\n\nLarge language models | Automated learning assessment | Automated grading | Education Correspondence: matelsky@seas.upenn.edu\n\n# Introduction\n\nOpen-ended questions — questions that require students to produce multi-word, nontrivial responses — are a popular assessment tool in educational environments because they offer students the chance to explore their understanding of learning material. Such questions provide valuable insight into students' grasp of complex concepts and their problem-solving approaches. However, grading open-ended questions can be time-consuming, subjective, and — especially in the\n\ncase of large class sizes — prone to attentional errors. These factors create a critical bottleneck in precision education.\n\nLarge Language Models (LLMs) present an opportunity to automate and promote equity in learning assessments, providing rapid valuable feedback to students while reducing the burden on instructors. We developed a tool that automatically assesses students' responses to open-ended questions by evaluating their responses against a set of instructor-defined criteria. To use our tool, the instructor poses a question along with optional grading criteria. Students respond to these questions, and their answers are relayed to a server. The responses are paired with the grading criteria (which are not revealed to the student), forming a payload for a large language model (LLM). The LLM then generates automated feedback, suggesting areas for improvement to the student.\n\nHere, we describe the technical design of our tool, FreeText, and showcase its utility in educational environments spanning topics and complexity. We further outline the implications of our work for teaching complex subjects, and the potential role of large language models in education (Fig. 1). We share our source code and a public URL (see Supplemental Materials), allowing educators to experiment with FreeText firsthand.\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/6a9cf86fccb148a4b0f5a0c93b45755ea07d2180131b4cd518c60fe668d97ace.jpg)  \nFigure 1. Sketch comparing grading throughput and quality of feedback to students among various assessment methodologies The  $y$ -axis represents throughput (i.e., rapidity of feedback generation and number of assignments evaluated per real-world unit-time or cost), and the  $x$ -axis represents feedback quality (a qualitative measure of personalization and detail of feedback given to students). LLMs have the potential to fill a niche among educational tools by striking a balance between quantity and quality, delivering high throughput with feedback quality comparable to human graders. Improvements in technology (faster GPU cards, better LLM architectures) will continue to push throughput upward, and improvements in prompt design (or other domain-specific adaptations) will improve the quality of LLM-generated feedback.\n\n# Related Work\n\nAutomated grading is a longstanding pursuit in the field of education technology. Early automated grading tools focused on 'solvable' tasks like math or programming assignments, where grading generally relies on unit tests or direct output comparisons (Hollingsworth, 1960; Ureel II and Wallace, 2019; Orr and Russell, 2021; Messer et al., 2023). These approaches often overlook less easily-quantified but nonetheless critical indicators of learning and understanding, such as design quality, code maintainability, or potential areas of student confusion. Modern tools, like AutoGrader, which provides real-time grading for programming exercises, remain narrowly focused on output correctness and do not sufficiently account for documentation or maintainability (Liu et al., 2019).\n\nAssessing students' understanding from natural language responses, however, presents different challenges and has seen significant evolution. Early Automated Short Answer Grading (ASAG) models employed statistical or domain-specific neural network approaches (Heilman and Madnani, 2013; Riordan et al., 2017; Sung et al., 2019). In recent years, LLMs have been shown to outperform domain-specific language models (Radford et al., 2019; Mizumoto et al., 2019; Brown et al., 2020; Chung et al., 2022). LLMs facilitate grading of open-ended assignment responses, without the need for task-specific fine-tuning (Cao, 2023; Mizumoto and Eguchi, 2023; Yoon, 2023). However, Kortemeyer (2023) revealed that while LLMs like GPT-4 could be useful for preliminary grading of introductory physics assignments, they fell short for natural-language responses required in comprehensive exam grading. Further, while LLMs like GitHub Copilot streamline the process of code generation and review, they can fall short on more nuanced programming tasks and open-ended evaluation (Finnie-Ansley et al., 2022). Thus, in their current state, LLMs should be treated as a useful but fallible tool, with final assessments still in the hands of (human) instructors.\n\nIt is also important to consider how students perceive AI graders and how automated graders are deployed to educational settings (Burrows et al., 2015; Saha et al., 2019; Zhu et al., 2022). Many comment on the socio-technical dynamics of automated grading, including the potential for introduction of machine bias (e.g., Hsu et al. (2021)). The use of NLP for short answer grading is not a trivial task and has been set as an evaluation challenge in its own right (Dzikovska et al., 2013).\n\nTo address the evolving needs of grading open-ended responses, our framework proposes four key enhancements. First, it is specifically designed for open-ended questions, which are not typically well-served by the rubric-based grading of most ed-tech tools. Sec-\n\nond, our system leverages LLMs to deliver rapid, personalized feedback for student responses without explicitly attempting to produce a quantitative grade. Third, our framework introduces a feedback loop to continually improve instructor-provided prompts, question suggestions, and grading criteria. Lastly, our tool integrates with the Jupyter Notebook environment, extensively utilized in fields such as computer science, data science, and statistics.\n\n# Approach\n\nWe have designed our tool for use in a variety of educational contexts, ranging from primary school education to graduate courses. FreeText enables educators to integrate open-ended questions into their curriculum without incurring an instructor labor cost. This allows students to gain rapid, individualized, and sophisticated feedback, thereby creating a highly effective learning loop that can enhance the absorption of course materials. It guides students in refining their responses, enhancing their understanding and application of concepts in each iteration. This feedback is generated by a large language model (LLM), which circumvents the attentional errors often made by human graders, particularly when assessing a large volume of assignments. The LLM is capable of delivering intricate responses to students swiftly, as demonstrated by the examples provided in Table 1.\n\nOur software is packaged as a Python library. LLM interactions are handled by the Guidance Python package (Microsoft, 2023). User interfaces and a JSON HTTP API are supported by FastAPI (Lathkar, 2023). We support traditional (e.g., JSON files, SQLite) as well as cloud-based data storage drivers. Our server can be run at low financial and computational cost through the combination of serverless deployment (e.g., to AWS Lambda) and serverless databases (e.g., AWS DYNAMoDB). Student responses are not stored by Free-Text infrastructure by default.\n\nAny Guidance-compatible LLM may be swapped into the Freetext server. That is, by default we access LLMs through the OpenAI API, but it is easy to swap in locally hosted or fine-tuned models: thus, privileged or sensitive information may be kept to on-premise compute resources, or users may opt to change which API-based LLM is accessed. For example, a more powerful LLM may be selected in cases where course content is particularly complex, or a simpler model may be used for more elementary course content.\n\nOne front-end that students can access is a Jupyter Notebook widget, developed using IPyWidgets (Kluyver et al., 2016), making it easy to incorporate natural language short-answer questions as part of a notebook-based active-learning environment.\n\nThe widget communicates with the backend\n\nPython server described above. The widget is designed to be easily integrated into lecture and homework notebooks, enabling instructors to easily enrich existing teaching materials. A distinctive feature of our system is the intermediary server which equips the large language model with 'held-out' information, such as a rubric for correct responses, accessible only to the LLM and instructor, and not to the student. This establishes the useful informational asymmetry between the evaluator and the student.\n\nTo include the widget in a Python environment, the instructor can include the following code:\n\n!pip install freetext_jupyter  \nfrom freetext_jupyter import FreetextWidget\n\nFreetextWidget( # This ID is generated by the instructor. \"07b2c3ef-0f97-46bc-a11e--\"\n\nWhen executed in a Jupyter notebook cell, this code will access the HTTP API to replace the widget with the corresponding question text for the student. Upon encountering the widget in a notebook, the student is presented with an open-ended question accompanied by a text box for response input. When they submit their response, the system transmits it to the server for combination with the feedback criteria set by the instructor.\n\nIn the next stage, the student response and the pre-defined feedback criteria are bundled into a payload dispatched to a large language model. The LLM processes this payload and produces personalized feedback to the response. This feedback is relayed back to the student with seconds of latency through the web or notebook interface, offering them the immediate opportunity to reflect, amend, and improve their response as desired (Fig. 2).\n\nOur tool is designed to be easily deployable and scalable. The FreeText server can be run in resource-constrained or serverless platforms such as AWS Lambda. This allows for easy deployment and scaling, which is particularly important for large-scale projects and massive-scale courses (van Viegen et al., 2021). Our API can also be combined with other existing educational tools in order to capture and store student responses for instructor review.\n\n# Question Design\n\nInstructors can provide a question for students to answer — either programmatically, by accessing our HTTP API — or graphically in the browser using the simple web application UI. Instructors can also provide optional assessment criteria — text like \"make sure the student mentions DNA base pairs in their answer.\"\n\nFreeText can use question content to automatically establish grading criteria, or it can use the assessment criteria to improve the text of the question. The latter process works by asking the AI to serve as a student and answer a question while oblivious to the instructor's grading criteria. Then, the answer is automatically evaluated by a separate instantiation of the LLM — this time, against the instructor criteria. The assessment model determines if the student has been unfairly penalized due to omission of requirements (or a lack of clarity) in the original question text. If so, the question is updated to better encompass the requirements of the grading criteria.\n\nThis process of iteratively incorporating assessment criteria is subtly different from simply including the criteria in the question text: For example, if the question text is, \"What is the Rosetta Stone?\" and the criteria include, \"Mention why the Ptolemaic dynasty created the Rosetta Stone\", a bad question update would be to explicitly ask about the Egyptian political system, as this gives the student more information than the instructor originally intended. A better question update would be \"Explain what the Rosetta Stone is and the context of its creation,\" because this nudges the student to discuss the right material but does not give any new information.\n\n# Question Presentation\n\nThere are two built-in methods to present questions to students: the first is a simple web API, which can be used standalone, coupled with response-collection tools, or embedded within other web applications. The second is a Jupyter Notebook widget that can be embedded in tutorial coding notebooks.\n\nThe JSON web API endpoints may be accessed directly by application code, or students can access a simple web user interface. This interface comprises a question display and a textbox for student responses (see Supplemental Materials). Feedback to students is rendered beneath the response box upon answer submission, and students may reuse the same page to resubmit amended answers.\n\nThe Jupyter Notebook widget is designed to make it easy for instructors to include open-ended questions in their assignments and subject the grading of student responses to custom grading criteria. This flexibility makes it easy for instructors to tailor the tool to their specific needs and teaching style.\n\n# Feedback to Students\n\nOur tool provides two types of feedback to students. The first is a holistic text response that provides feedback on the entire answer as a whole. The second is span-bound feedback (referring to a specific substring of the response) that can be used to highlight specific parts of the text that are erroneous or otherwise need\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/5209fe91ef2047ed5842cbb413bc10aad9a1a2af8167dd3d98ee564bdaacb52d.jpg)\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/cd61c0ae15cf0320be444de8121a19d39c0baa1c3fe9526b165a6ec148060066.jpg)  \nFigure 2. A sequence diagram illustrating the flow of information within the FreeText system. A. First, an instructor formulates a question by supplying a student-facing question (\"Question\") along with grading criteria for the LLM to evaluate student responses. In return, the educator obtains a unique identifier from the database, instrumental in retrieving the question text in the following step. B. Equipped with a unique Question identifier, a student provides an answer to the educator's query (\"Response\"). The API receives this request, pairing the Response with a Prompt based upon the educator's question and criteria, and directs them towards a large language model for evaluation. C. A screenshot of the FreeText Jupyter widget integrated into an interactive code notebook.\n\n![](/uploads/images/f073a540-29cb-4a8a-b4e8-980e96e8a325/bf7f9570f0e3176a21e9fe41333f8aad179f2fa417d93be67dc8da06718deaa9.jpg)\n\nstudent attention. For example, if a student's answer is correct but they misattribute a quote, the FreeText server could highlight the attribution specifically to give feedback. The type of feedback returned can be specified by the instructor during question creation.\n\n# Discussion\n\nHere we introduced FreeText, a framework capable of defining questions, collecting student responses, transmitting these responses alongside instructor expectations to a large language model (LLM), and generating rapid and personalized feedback for the students. Notably, the entirety of the student-facing workflow can be encapsulated within a Jupyter notebook, facilitating real-time enhancement of students' understanding of the course material. FreeText is not confined to a web application and Jupyter notebooks, or the academic subjects mentioned above. The FreeText Server can integrate with any application that consumes a JSON HTTP API, expanding its potential to a wider range of educational settings.\n\nOur system's broad applicability becomes evident when considering diverse learning models, such as the pod-based approach adopted by the online course Neuromatch Academy (van Viegen et al., 2021) in the field of computational neuroscience. In such settings, small student groups or 'pods' collaboratively tackle assignments and projects. Teaching Assistants, tasked with providing feedback, can benefit from our tool, as it can streamline grading processes, reducing potential for attentional errors and freeing up instructors to deliver more personalized guidance to students.\n\nFully automated student evaluation is challenging both from a technical perspective and from a human\n\nperspective, and thus FreeText is designed not to fully automate grading, but to serve as a useful tool benefiting both students and instructors. FreeText benefits students by providing rapid and personalized feedback on short-answer questions. FreeText benefits instructors by helping them to design better questions and grading criteria, by providing first-pass material for learning assessments, and by alleviating some of the burden of providing individualized instruction in large classes. LLMs in general, and FreeText specifically, are not a replacement human instructors, but they can nonetheless fill a niche among education technologies.\n\nLLMs undoubtedly hold immense power and potential. However, it is crucial to have an in-depth discussion about their ethical implications, especially in education. A key issue to consider is the potential biases that LLMs can introduce. These biases could unintentionally touch on sensitive subjects or unintentionally overlook marginalized groups. Instructors have a role to play by carefully designing their questions and assessment criteria. Further, students should be made aware of the nature of the system they are interacting with and its potential to make mistakes or act on internalized biases (Hsu et al., 2021). On the other hand, automated systems such as FreeText present an opportunity to reduce instructors' unconscious biases by evaluating all students' responses equally and without any explicit identification.\n\nFurthermore, we must consider the broader dynamics of the AI ecosystem. The realm of LLMs is not limited to the offerings of large AI conglomerates like OpenAI. A burgeoning industry of alternative LLMs, both from smaller commercial entities and open-source initiatives (Anthropic, 2023; Taori et al., 2023; Touvron et al., 2023; Wolf et al., 2020), is flourishing. Our\n\nframework is designed to be model-agnostic and can be readily adapted to integrate these alternative models.\n\nReliance solely on models from a single entity such as OpenAI raises two significant concerns. First, it centralizes the concentration of AI development resources and power, thereby exacerbating the already pronounced inequalities in the global AI landscape. Second, it can lead to a homogenization of the knowledge and perspectives propagated by AI models, potentially resulting in a limited and biased worldview. FreeText is therefore deliberately agnostic to the underlying LLM model and technologies.\n\nWe intend for our tool to enrich and expand students' educational experience, particularly in large-scale or resource-constrained course settings where detailed human intervention may be limited. Ongoing work includes the careful critique and evaluation of FreeText outputs by expert instructors, taking advantage of upcoming opportunities to apply this technology in a large class setting.\n\nEmbracing both technical as well as human diversity helps mitigate many of the concerns raised above and enriches the AI ecosystem. A broad range of perspectives stalls the monopolization of AI technology and fosters a more balanced, equitable, and robust AI landscape. This viewpoint aligns with our belief in the need for broad and diverse human inputs, both in the creation of AI models and in their applications in society.\n\n# Supplemental Materials\n\nFull-resolution versions of all images and tables from this publication are available at https://llm4edu.experiments.kordinglab.com/paper.\n\nThe FreeText server will be hosted temporarily for public use at https://llm4edu.experiments.kordinglab.com/app, with an interactive example assignment available at https://llm4edu.experiments.kordinglab.com/app/assignments/1393754a-d80f-474d-bff7-b1fec36cdbb7. Educators may contact us at the correspondence email of this preprint for a token, which is required to create new questions on our public instance.\n\nOur Jupyter Notebook Widget is available on GitHub at https://github.com/KordingLab/freetext-jupyter, and is powered by the FreeText Server, which can be found at https://github.com/KordingLab/llm4teach-freetext-server.\n\n# Acknowledgements\n\nResearch in this publication was supported by the National Institutes of Health under award number UC2-NS128361. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.\n\n# Bibliography\n\nAnthropic. Claude, 2023. URL https://www.anthropic.com. Accessed: 24 July 2023. T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901. Curran Associates, Inc., 2020.  \nS. Burrows, I. Gurevych, and B. Stein. The eras and trends of automatic short answer grading. International journal of artificial intelligence in education, 25:60-117, 2015.  \nC. Cao. Leveraging large language model and story-based gamification in intelligent tutoring system to scaffold introductory programming courses: A design-based research study, 2023.  \nH. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma, A. Webson, S. S. Gu, Z. Dai, M. Suzgun, X. Chen, A. Chowdhery, A. Castro-Ros, M. Pellat, K. Robinson, D. Valter, S. Narang, G. Mishra, A. Yu, V. Zhao, Y. Huang, A. Dai, H. Yu, S. Petrov, E. H. Chi, J. Dean, J. Devlin, A. Roberts, D. Zhou, Q. V. Le, and J. Wei. Scaling instruction-finetuned language models, 2022.  \nM. O. Dzikovska, R. Nielsen, C. Brew, C. Leacock, D. Giampicolo, L. Bentivogli, P. Clark, I. Dagan, and H. T. Dang. Semeval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge. In Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 263-274, 2013.  \nJ. Finnie-Ansley, P. Denny, B. A. Becker, A. Luxton-Reilly, and J. Prather. The robots are coming: Exploring the implications of openai codex on introductory programming. In Proceedings of the 24th Australasian Computing Education Conference, pages 10-19, 2022.  \nM. Heilman and N. Madnani. ETS: Domain adaptation and stacking for short answer scoring. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 275-279. Association for Computational Linguistics, 2013.  \nJ. Hollingsworth. Automatic graders for programming classes. Communications of the ACM, 3(10):528-529, 1960. ISSN 0001-0782. doi: 10.1145/367415.367422.  \nS. Hsu, T. W. Li, Z. Zhang, M. Fowler, C. Zilles, and K. Karahalios. Attitudes surrounding an imperfect ai autograder. In Proceedings of the 2021 CHI conference on human factors in computing systems, pages 1-15, 2021.  \nT. Kluyver, B. Ragan-Kelley, F. Perez, B. Granger, M. Bussonnier, J. Frederic, K. Kelley, J. Hamrick, J. Grout, S. Corlay, P. Ivanov, D. Avila, S. Abdalla, and C. Willing. Jupyter notebooks - a publishing format for reproducible computational workflows. In F. Loizides and B. Schmidt, editors, Positioning and Power in Academic Publishing: Players, Agents and Agendas, pages 87 - 90. IOS Press, 2016.  \nG. Kortemeyer. Can an Al-tool grade assignments in an introductory physics course?. 2023.  \nM. Lathkar. Getting started with fastapi. In High-Performance Web Apps with FastAPI: The Asynchronous Web Framework Based on Modern Python, pages 29-64. Springer, 2023.  \nX. Liu, S. Wang, P. Wang, and D. Wu. Automatic grading of programming assignments: An approach based on formal semantics. In 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET), pages 126-137, 2019. doi: 10.1109/ICSE-SEET.2019.00022.  \nM. Messer, N. C. C. Brown, M. Kölling, and M. Shi. Automated grading and feedback tools for programming education: A systematic review, 2023.  \nMicrosoft. Guidance. https://github.com/microsoft/guidance, 2023. Accessed: 24 July 2023.  \nA. Mizumoto and M. Eguchi. Exploring the potential of using an AI language model for automated essay scoring. Research Methods in Applied Linguistics, 2(2):100050, 2023. ISSN 2772-7661. doi: 10.1016/j.rmal.2023.100050.  \nT. Mizumoto, H. Ouchi, Y. Isobe, P. Reisert, R. Nagata, S. Sekine, and K. Inui. Analytic score prediction and justification identification in automated short answer scoring. In Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 316-325. Association for Computational Linguistics, 2019. doi: 10.18653/v1/W19-4433.  \nJ. W. Orr and N. Russell. Automatic assessment of the design quality of python programs with personalized feedback. arXiv preprint arXiv:2106.01399, 2021.  \nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised multitask learners. 2019.  \nB. Riordan, A. Horbach, A. Cahill, T. Zesch, and C. M. Lee. Investigating neural architectures for short answer scoring. In Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications, pages 159-168. Association for Computational Linguistics, 2017. doi: 10.18653/v1/W17-5017.  \nS. Saha, T. I. Dhamecha, S. Marvaniya, P. Foltz, R. Sindhgatta, and B. Sengupta. Joint multi-domain learning for automatic short answer grading. arXiv preprint arXiv:1902.09183, 2019.  \nC. Sung, T. Dhamecha, S. Saha, T. Ma, V. Reddy, and R. Arora. Pre-training BERT on domain resources for short answer grading. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-JCNLP), pages 6071-6075. Association for Computational Linguistics, 2019. doi: 10.18653/v1/D19-1628.  \nR. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and\n\nTable 1. Feedback examples.  \n\n<table><tr><td>Instructor-Generated Prompt</td><td>Student-Generated Answer</td><td>AI-Generated Feedback</td></tr><tr><td>Question\nExplain what a neuron is, detailing how they transmit information and what unique features they have.</td><td rowspan=\"2\">Neurons are cells that transmit information to other nerve, muscle, or gland cells. They use synapses.</td><td rowspan=\"2\">You correctly state that neurons are cells that transmit information to other nerve, muscle, or gland cells.\nYou also mention the use of synapses, which is correct as synapses are the connections between neurons where information is transmitted.\nHowever, your response is quite brief and lacks important details and explanations. Here are some points that you may have missed or misunderstood:\nYou did not provide any information about how neurons transmit information. It would be helpful to explain that neurons transmit information through electrical impulses called action potentials.\nYou did not mention the role of neurotransmitters in transmitting information between neurons. It is important to explain that neurotransmitters are chemical messengers released at the synapse to transmit the signal from one neuron to the next.\nYour response could benefit from more specific and detailed information about the unique features of neurons, such as the three main parts of a neuron (cell body, dendrites, and axon) and how the action potential is propagated along the axon. Overall, your response is a good start, but it would be more complete and accurate if you include the missing details mentioned above. Keep up the effort!</td></tr><tr><td>Criteria\nMust include the terms &quot;synapse&quot; and &quot;action potential.&quot;\nMust mention the role of neurotransmitters.</td></tr><tr><td>Question\nWhat are the components and structure of a molecule of DNA?</td><td rowspan=\"2\">DNA is a complex molecule and it is shaped like a double helix ladder, where the rungs are base pairs ATGC and the scaffold is sugars and phosphates.\nThe base pairs bind (A with G) and (C with T) using hydrogen bonds, which can be separated when the DNA is being read or duplicated.</td><td rowspan=\"2\">Correct points:\nYou correctly mentioned that DNA is shaped like a double helix ladder.\nYou accurately stated that the base pairs in DNA are ATGC.\nYou correctly noted that the base pairs bind using hydrogen bonds.\nPoints to improve:\nYou mentioned that the base pairs bind as A with G and C with T, but it&#x27;s important to clarify that adenine pairs with thymine (A-T) and guanine pairs with cytosine (G-C).\nOverall, you have a solid understanding of the components and structure of DNA. Just make sure to clarify the pairing of base pairs and the temporary breaking of hydrogen bonds during DNA processes. Good work!</td></tr><tr><td>Criteria\nMention base pairs, sugar, and phosphate.\nDescribe that DNA is a double helix.\nNote that base pairs pair up in a specific way using hydrogen bonds (AT and GC).</td></tr><tr><td>Question\nHow can large language models introduce biases into student evaluation?</td><td rowspan=\"2\">LLMs have bias because their training data can have toxic, biased, or inaccurate data in it. When evaluating students, LLMs could also penalize students that know information that is more recent or otherwise outside the LLM&#x27;s training set, which may appear to be inaccurate to the AI model.\nLLMs are also not designed to keep track of accurate information; they are autoregressive language models, and so they do not have a legitimate hold on fact and caution should be used when depending on an AI model for subtle communication.</td><td rowspan=\"2\">Great job in identifying some of the key factors that contribute to biases in large language models (LLMs) in student evaluation. It would be helpful to provide specific examples or evidence of how LLMs can have biased or inaccurate data in their training set. This would strengthen your argument and provide more clarity.\nYour statements align with the current understanding of LLMs and their limitations.\nOverall, your response demonstrates a good understanding of the topic. To further enhance your answer, consider providing more specific examples and expanding on the potential implications of relying on LLMs for student evaluation. Great job!</td></tr><tr><td>Criteria\n(None provided)</td></tr><tr><td>Question\nHow can large language models introduce biases into student evaluation?</td><td rowspan=\"2\">LLMs are biased because they&#x27;re made by large companies.</td><td rowspan=\"2\">Your response to the prompt raises an important point, but there are a few areas where your answer could be elaborated. Large language models (LLMs) are indeed created by large companies, but it&#x27;s important to note that the fact that LLMs are made by large companies does not directly imply bias. Bias can arise from various factors related to the training data and model design.\nConsider mentioning factors such as the source of training data, language patterns, prejudiced examples, feedback loops, lack of contextual understanding, and how evaluation metrics may steer LLM responses.\nOverall, your response is a good starting point, but it would benefit from further elaboration and a deeper understanding of the specific factors that contribute to biases in student evaluation by large language models. Keep up the effort!</td></tr><tr><td>Criteria\n(None provided)</td></tr></table>\n\nT. B. Hashimoto. Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models. https://crfm.stanford.edu/2023/03/13/alpaca.html, 3(6):7, 2023.  \nH. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.  \nL. C. Ureel II and C. Wallace. Automated critique of early programming antipatterns. In Proceedings of the 50th ACM Technical Symposium on Computer Science Education, SIGCSE '19, pages 738-744. Association for Computing Machinery, 2019. ISBN 978-1-4503-5890-3. doi: 10.1145/3287324.3287463.  \nT. van Viegen, A. Akrami, K. Bonnen, E. DeWitt, A. Hyafil, H. Ledmyr, G. W. Lindsay, P. Mineault, J. D. Murray, X. Pitkow, et al. Neuromatch academy: Teaching computational neuroscience with global accessibility. Trends in cognitive sciences, 25(7):535-538, 2021.  \nT. Wolf, L. Debut, V. Sanh, J. Chaumont, C. Delangue, A. Moi, P. Cistac, C. Ma, Y. Jernite, J. Plu, C. Xu, T. Le Scao, S. Gugger, M. Drame, Q. Lhoest, and A. M. Rush. Transformers: State-of-the-Art Natural Language Processing. pages 38-45. Association for Computational Linguistics, Oct. 2020. URL https://www.aclweb.org/anthology/2020.emnlp-demos.6.  \nS.-Y. Yoon. Short answer grading using one-shot prompting and text similarity scoring model, 2023.  \nX. Zhu, H. Wu, and L. Zhang. Automatic short-answer grading via bert-based deep neural networks. IEEE Transactions on Learning Technologies, 15(3):364-375, 2022.",
    "arxiv_id": "2106.01399",
    "error_message": "'\\n  \"paper_type\"'",
    "embedding": [
      0.302734375,
      2.453125,
      -0.95703125,
      0.8046875,
      0.439453125,
      1.7578125,
      -1.421875,
      -4.4375,
      2.0625,
      5.125,
      1.109375,
      2.859375,
      5.03125,
      2.015625,
      0.39453125,
      5.1875,
      -0.1884765625,
      2.375,
      -1.2734375,
      -8,
      1.265625,
      3.90625,
      1.609375,
      -6.09375,
      2.234375,
      -2.53125,
      1.1875,
      4.28125,
      2.171875,
      -1.125,
      6.34375,
      -4.96875,
      -1.21875,
      -0.357421875,
      0.6640625,
      -0.365234375,
      -1.4921875,
      -0.73046875,
      2.59375,
      2.3125,
      -5.46875,
      1.2734375,
      1.234375,
      0.703125,
      -1.0234375,
      6.03125,
      1.5390625,
      -0.78515625,
      -3.453125,
      -0.203125,
      -5.5625,
      -1.2421875,
      5.15625,
      1.3203125,
      0.54296875,
      -5.84375,
      -7.4375,
      6.96875,
      -3.953125,
      0.59375,
      2.78125,
      -0.6953125,
      5.75,
      -0.96875,
      2.5625,
      0.73046875,
      2.4375,
      1.4921875,
      -4.125,
      1.59375,
      0.671875,
      1.953125,
      7.3125,
      -2.1875,
      7.9375,
      5.71875,
      3.34375,
      4.09375,
      -2.765625,
      4.53125,
      -3.5625,
      4,
      4.25,
      -0.546875,
      5.28125,
      3.296875,
      1.3359375,
      1.1015625,
      -0.83203125,
      3.265625,
      -3.296875,
      1.015625,
      -2.578125,
      0.68359375,
      -2.03125,
      4.78125,
      -1.640625,
      -4,
      -6.125,
      1.375,
      0.19140625,
      -3.5625,
      1.8984375,
      -7,
      -0.5546875,
      -3.109375,
      -5.75,
      -5.28125,
      -3.625,
      -1.796875,
      -1.7890625,
      0.9140625,
      1.6875,
      -2.375,
      2.359375,
      -0.890625,
      5.4375,
      -3.96875,
      -4.96875,
      -1.828125,
      1.2265625,
      0.201171875,
      -1.5390625,
      1.15625,
      3.203125,
      2.890625,
      -4.5625,
      3.1875,
      3.28125,
      -1.9609375,
      4.59375,
      -0.7109375,
      6,
      -1.8125,
      -7.875,
      -2.640625,
      -6.3125,
      2.5,
      2.21875,
      5.28125,
      -7.3125,
      -0.30078125,
      0.68359375,
      -4.65625,
      4.6875,
      2.5625,
      -7.1875,
      -0.30859375,
      2.078125,
      -4.59375,
      -0.76953125,
      1.796875,
      2.96875,
      6.53125,
      -2.734375,
      -1.25,
      2.078125,
      3.984375,
      0.78125,
      -2.015625,
      -1.7421875,
      4.4375,
      -0.1396484375,
      0.279296875,
      -0.357421875,
      -1.3671875,
      -5.96875,
      3.3125,
      -2.078125,
      -2.4375,
      -0.478515625,
      13.5,
      2.046875,
      -0.421875,
      0.287109375,
      2.671875,
      -1.6875,
      6.0625,
      2.3125,
      -2.078125,
      0.298828125,
      3.546875,
      -1.3828125,
      6.03125,
      -1.859375,
      1.1171875,
      0.9140625,
      -3.90625,
      2.078125,
      -1.453125,
      3.0625,
      1.5390625,
      2.59375,
      1.7421875,
      -6.5625,
      -0.7578125,
      0.64453125,
      0.18359375,
      -1.5078125,
      2.65625,
      -0.1787109375,
      -9.5625,
      2.09375,
      0.2314453125,
      -4.0625,
      -1.734375,
      1.9453125,
      -2.140625,
      1.5625,
      -3.078125,
      1.25,
      3.40625,
      2.3125,
      -1.640625,
      5.8125,
      5.15625,
      5.90625,
      -2.265625,
      5.59375,
      0.408203125,
      2.65625,
      2.5625,
      6.28125,
      1.84375,
      -0.369140625,
      1.9765625,
      5.1875,
      3.984375,
      -0.75,
      5.84375,
      -0.240234375,
      0.734375,
      3.484375,
      -2.796875,
      -4.125,
      -4.90625,
      -5,
      -0.326171875,
      -0.9296875,
      1.7890625,
      -4.375,
      -6.09375,
      2.03125,
      1.8828125,
      3.421875,
      -3.546875,
      -1.15625,
      -2.921875,
      -2.765625,
      -6.21875,
      2.953125,
      5.8125,
      -5.40625,
      -2.890625,
      3.34375,
      8,
      -2.28125,
      -1.109375,
      -0.40625,
      -4.75,
      4.96875,
      -1.9296875,
      -7,
      3.5,
      1.296875,
      -4.96875,
      2.5,
      0.828125,
      3.25,
      3.09375,
      0.1201171875,
      0.69140625,
      -3.703125,
      0.53125,
      -2.4375,
      4.96875,
      1.34375,
      -7.96875,
      5.34375,
      -2.546875,
      -4.53125,
      -8.8125,
      7.40625,
      -5.15625,
      2.5,
      -2.453125,
      -0.185546875,
      5.65625,
      -2.765625,
      11.125,
      4.78125,
      2.265625,
      0.95703125,
      -3.234375,
      -5.5,
      1.3828125,
      -4.125,
      -1.1953125,
      -7.6875,
      0.203125,
      6.03125,
      0.71484375,
      0.46484375,
      -1.0859375,
      -0.96875,
      1.421875,
      -1.6015625,
      -1.203125,
      -0.05517578125,
      0.71484375,
      -0.486328125,
      -0.51953125,
      8.0625,
      -0.2578125,
      3.515625,
      -5.15625,
      -4.3125,
      2.078125,
      0.64453125,
      -0.8359375,
      -3.5625,
      -5.53125,
      -3.625,
      -3.265625,
      -4.09375,
      -0.90625,
      2.65625,
      1.5546875,
      5.84375,
      -1.1875,
      3.96875,
      -2.15625,
      -3.6875,
      -9.5,
      4.0625,
      -2.703125,
      0.90625,
      1.9765625,
      -2.734375,
      4.75,
      0.181640625,
      -3.328125,
      4.125,
      -2.09375,
      -4.0625,
      1.7734375,
      6.71875,
      -2.796875,
      0.5234375,
      -2.84375,
      3.875,
      1.6640625,
      -0.765625,
      4.21875,
      7.8125,
      -2.890625,
      0.51953125,
      -2.734375,
      -0.353515625,
      -1.2421875,
      5.03125,
      -2.78125,
      5.28125,
      -1.953125,
      0.345703125,
      -2.125,
      -2.9375,
      2.609375,
      -2.28125,
      -1.15625,
      -0.6875,
      -2.546875,
      0.546875,
      -0.16015625,
      -0.275390625,
      0.8359375,
      0.5390625,
      -2.59375,
      -2.5625,
      1.4375,
      -4.25,
      -0.4609375,
      -0.466796875,
      -0.490234375,
      5.375,
      1.1328125,
      -0.0033721923828125,
      1.828125,
      1.578125,
      -2.6875,
      -3.90625,
      0.78125,
      -2.484375,
      1.5390625,
      3.0625,
      0.05712890625,
      0.890625,
      2.234375,
      -0.44921875,
      -0.99609375,
      5.46875,
      -0.80078125,
      -1.0078125,
      0.59765625,
      -2.828125,
      -0.77734375,
      0.006866455078125,
      -5.71875,
      2.546875,
      -0.30859375,
      1.09375,
      0.42578125,
      -1.015625,
      -0.1015625,
      0.302734375,
      5.875,
      -2.328125,
      3.515625,
      -7.875,
      -1.34375,
      -3.71875,
      0.76953125,
      1.1953125,
      0.12158203125,
      0.044921875,
      1.234375,
      -0.072265625,
      4.75,
      1.28125,
      -0.55859375,
      3.28125,
      1.140625,
      -1.9921875,
      2.015625,
      -3.71875,
      -2.640625,
      4.65625,
      -4.4375,
      -2.5625,
      0.58203125,
      4.09375,
      -4.03125,
      5.875,
      6.71875,
      -5.9375,
      -1.3359375,
      1.4765625,
      4.28125,
      -2.9375,
      -0.2734375,
      -0.1865234375,
      -0.1533203125,
      -1.828125,
      0.7734375,
      -0.1884765625,
      1.1953125,
      -5.25,
      4.09375,
      2.546875,
      -1.5703125,
      0.359375,
      -0.470703125,
      -0.05517578125,
      -0.84765625,
      1.078125,
      -1.0234375,
      -0.2314453125,
      5.03125,
      7.4375,
      -8.25,
      -9.3125,
      3.953125,
      0.31640625,
      0.6640625,
      -1.8203125,
      4.375,
      0.2109375,
      0.8359375,
      -6.15625,
      -4.40625,
      1.5078125,
      0.404296875,
      2.078125,
      3.828125,
      -1.125,
      -2.625,
      -1.6640625,
      4.5625,
      1.703125,
      4.34375,
      -0.89453125,
      -1.6484375,
      0.330078125,
      -2.140625,
      3.078125,
      2.40625,
      7.96875,
      -4.59375,
      -1.5390625,
      1.484375,
      -8.125,
      2.03125,
      -2.390625,
      -0.44140625,
      -1.0625,
      2.484375,
      2.3125,
      -3.71875,
      -2.109375,
      -1.7265625,
      3.59375,
      -3.375,
      1.578125,
      2.125,
      -5.34375,
      -2.40625,
      1.609375,
      0.337890625,
      2.546875,
      -0.99609375,
      -4.1875,
      0.66015625,
      1.3046875,
      3.890625,
      -0.78515625,
      -4.53125,
      -1.875,
      -2.96875,
      3.6875,
      1.9453125,
      0.8984375,
      2.984375,
      -1.34375,
      -3.515625,
      1.359375,
      -1.1796875,
      3.03125,
      -0.22265625,
      0.515625,
      1.0234375,
      -1.7109375,
      2.96875,
      -2.40625,
      -2,
      -0.7578125,
      1.296875,
      -4.75,
      3.234375,
      3.96875,
      1.515625,
      2.34375,
      0.9921875,
      -4.96875,
      -3,
      1.734375,
      -4.8125,
      -3.03125,
      -3.390625,
      4.6875,
      -2.359375,
      0.10546875,
      -2.0625,
      -0.63671875,
      0.458984375,
      2,
      -0.494140625,
      2.234375,
      4.03125,
      -1.2734375,
      -2.65625,
      1.0703125,
      4.25,
      -2.984375,
      1.4296875,
      2.546875,
      1.28125,
      -5.625,
      -6.78125,
      -1.4140625,
      0.921875,
      6.6875,
      -2.125,
      1.1796875,
      -2.84375,
      4.5625,
      -0.26171875,
      0.83984375,
      -13.6875,
      1.5,
      -1.3359375,
      -1.765625,
      -1.1796875,
      -1.71875,
      1.640625,
      -1.0859375,
      5.5,
      3.546875,
      -1.078125,
      2.515625,
      4.65625,
      0.7109375,
      -1.5625,
      2.671875,
      -0.314453125,
      -0.86328125,
      1.5546875,
      -2.03125,
      -6.09375,
      -0.50390625,
      -0.9296875,
      0.59765625,
      1.0546875,
      2.140625,
      0.1884765625,
      0.2216796875,
      3.828125,
      -5.375,
      -1.0078125,
      3.265625,
      2.1875,
      -3.734375,
      -0.1318359375,
      -1.375,
      2.265625,
      -4.3125,
      2.03125,
      -0.032958984375,
      -2.0625,
      3.65625,
      3.046875,
      0.65234375,
      -0.349609375,
      -1.90625,
      0.466796875,
      5.09375,
      4.09375,
      -3.140625,
      0.80859375,
      -2.265625,
      -0.224609375,
      5.3125,
      1.1640625,
      -1.5234375,
      -3.09375,
      4.09375,
      0.138671875,
      -2.234375,
      4.65625,
      -1.2265625,
      -5.90625,
      0.033447265625,
      -0.828125,
      0.2333984375,
      -2.140625,
      2.71875,
      -0.4375,
      -1.1328125,
      0.31640625,
      0.263671875,
      0.57421875,
      -3.125,
      -0.29296875,
      -0.1064453125,
      -3.859375,
      1.9296875,
      -0.0186767578125,
      -0.8828125,
      1.3125,
      0.99609375,
      2.09375,
      0.0220947265625,
      3.875,
      2.015625,
      5.28125,
      3.421875,
      -2.53125,
      3.109375,
      -3.578125,
      -3.703125,
      -0.6015625,
      -3.296875,
      -2.015625,
      -0.099609375,
      -1.4921875,
      2.84375,
      -2.015625,
      -2.25,
      -4.0625,
      -5.875,
      -1.2109375,
      2.609375,
      -1.3515625,
      4.28125,
      -3.421875,
      5.5,
      -1.1796875,
      -3.84375,
      1.2421875,
      -0.26171875,
      0.9765625,
      -1.0390625,
      1.7421875,
      -6.75,
      1.625,
      5.03125,
      2.515625,
      -2.40625,
      6,
      0.06396484375,
      -3.921875,
      0.71875,
      2.90625,
      -2.015625,
      -2.671875,
      -1.2421875,
      -2.296875,
      -0.1220703125,
      -1.828125,
      0.95703125,
      -1.8671875,
      3.296875,
      -1.15625,
      -0.380859375,
      -2.21875,
      -5.03125,
      -0.30859375,
      -0.0142822265625,
      -0.9921875,
      3.1875,
      3.03125,
      0.8828125,
      -1.7109375,
      1.90625,
      3.171875,
      -1.1796875,
      1.453125,
      -1.703125,
      2.953125,
      3.109375,
      2.6875,
      0.279296875,
      -6.09375,
      -2.265625,
      0.43359375,
      -1.0625,
      4.28125,
      -1.625,
      3.359375,
      3.875,
      4.46875,
      -6.21875,
      -1.8359375,
      1.90625,
      -4.3125,
      0.41796875,
      2.109375,
      1.6796875,
      -0.6796875,
      -0.08154296875,
      1.1640625,
      -3.15625,
      -1.546875,
      2.90625,
      4.25,
      0.380859375,
      -1.3359375,
      3.359375,
      1.90625,
      6.90625,
      -2.75,
      -6.375,
      2.265625,
      2.328125,
      -2.671875,
      0.2099609375,
      5.40625,
      -3.265625,
      0.65234375,
      -1.8828125,
      2.1875,
      1.1328125,
      -0.345703125,
      1.96875,
      -0.6328125,
      2.0625,
      -0.408203125,
      -0.2001953125,
      3.15625,
      -1.15625,
      1.1640625,
      1.171875,
      -1.234375,
      -0.322265625,
      1.6953125,
      -1.171875,
      -1.5234375,
      -2.703125,
      -1.015625,
      -0.1767578125,
      4.1875,
      4.90625,
      -1.8046875,
      -2.3125,
      0.71875,
      5.25,
      -1.4140625,
      5.78125,
      0.59765625,
      8.875,
      -3.5,
      -3.109375,
      2.578125,
      -2.109375,
      1.5546875,
      -0.369140625,
      -6.9375,
      -2.921875,
      -0.474609375,
      0.470703125,
      -3.46875,
      2.875,
      -4.09375,
      2.28125,
      2.109375,
      2.078125,
      2.453125,
      0.90625,
      1.9921875,
      1.6171875,
      -1.296875,
      -2.828125,
      -3.234375,
      -1.234375,
      -2.34375,
      1.9453125,
      -4.28125,
      3.265625,
      1.0625,
      3.421875,
      -2.078125,
      -2.28125,
      -0.51953125,
      6.09375,
      2.28125,
      -1.140625,
      3.90625,
      2.3125,
      0.65625,
      3.453125,
      3.109375,
      -4.28125,
      -4.28125,
      6.0625,
      3.734375,
      -0.322265625,
      2.421875,
      -2.421875,
      0.98046875,
      -2.171875,
      -1.5078125,
      0.1435546875,
      3.75,
      -4.03125,
      -0.828125,
      -0.326171875,
      4.0625,
      -4.03125,
      2.96875,
      3,
      -6.71875,
      4.6875,
      -1.328125,
      -0.5703125,
      0.51171875,
      -0.06689453125,
      6.09375,
      -0.76953125,
      -0.640625,
      -4.75,
      -6.625,
      -2.9375,
      2.09375,
      1.171875,
      3.71875,
      2.8125,
      -3.046875,
      0.0556640625,
      -5,
      -3.140625,
      -4.96875,
      2.6875,
      0.045166015625,
      -2.4375,
      -2.0625,
      -3.15625,
      -8.5,
      -4.21875,
      -2.4375,
      -1.671875,
      -2.3125,
      -7,
      0.5703125,
      1.953125,
      -5.0625,
      -0.482421875,
      -3.578125,
      -1.6015625,
      1.5390625,
      0.1240234375,
      -0.6171875,
      -1.1953125,
      2.203125,
      3.203125,
      -1.4765625,
      5.59375,
      6.15625,
      2.0625,
      3.875,
      -0.93359375,
      -1.234375,
      -3.6875,
      6.71875,
      -1.796875,
      7.65625,
      4.34375,
      1.5,
      -5.84375,
      -0.255859375,
      -0.458984375,
      -0.75390625,
      -6.78125,
      0.478515625,
      -1.09375,
      -0.0034637451171875,
      2.046875,
      0.76171875,
      3.953125,
      -6.4375,
      -1.4609375,
      3.03125,
      -4.28125,
      0.283203125,
      3.9375,
      -2.5,
      3.015625,
      -2.109375,
      -2.15625,
      -0.333984375,
      1.84375,
      2.484375,
      -2.171875,
      2.0625,
      -3.96875,
      0.39453125,
      -0.91015625,
      -1.625,
      -1.0703125,
      -0.412109375,
      2.640625,
      0.259765625,
      0.4609375,
      2.78125,
      2.90625,
      3.140625,
      2.90625,
      3.125,
      -0.8671875,
      3.421875,
      -0.4609375,
      -6.5,
      4.125,
      0.48046875,
      -1.0390625,
      -0.1279296875,
      2.28125,
      -4.28125,
      1.46875,
      1.53125,
      -3.265625,
      -1.2734375,
      -2.859375,
      -2.78125,
      1.515625,
      -1.71875,
      0.96875,
      4.90625,
      1.7421875,
      1.6015625,
      1.4140625,
      1.75,
      1.5078125,
      0.68359375,
      -1.953125,
      5.78125,
      -4.40625,
      -2.578125,
      4.59375,
      3.046875,
      2.953125,
      -3.421875,
      -1.1015625,
      -4.1875,
      0.054443359375,
      2.265625,
      -1.46875,
      1.140625,
      5.625,
      -2.140625,
      -0.5234375,
      0.259765625,
      -0.1650390625,
      2.109375,
      -0.498046875,
      1.4453125,
      5.59375,
      3.453125,
      -2.59375,
      -0.94140625,
      -5.5,
      1.3828125,
      -2.046875,
      -1.328125,
      -0.1494140625,
      -0.5546875,
      -1.484375,
      1.296875,
      -2.1875,
      0.1181640625,
      1.296875,
      -5.90625,
      -0.154296875,
      4.65625,
      -2.921875,
      -0.004486083984375,
      1,
      2.5,
      -3.359375,
      1.7890625,
      0.828125,
      -2.546875,
      0.8671875,
      1.9375,
      -1.796875,
      4.71875,
      3.015625,
      -1.2421875,
      -0.373046875,
      -4.90625,
      0.267578125,
      1.46875,
      -0.048828125,
      2.25,
      -3,
      2.25,
      3.265625,
      2.84375,
      -1.2890625,
      3.53125,
      -0.16796875,
      -1.6171875,
      3.234375,
      -2.96875,
      -3.578125,
      -0.89453125,
      -1.453125,
      -2.3125,
      -0.1689453125,
      -1.484375,
      0.734375,
      2.546875,
      -7.03125,
      4.84375,
      -6.34375,
      5.65625,
      -0.59375,
      0.0137939453125,
      -2.125,
      -2.3125,
      2.125,
      -3.421875,
      -0.419921875,
      -0.91796875,
      -4.28125,
      3.09375,
      -1.359375,
      -2.015625,
      -0.75,
      -0.396484375,
      4.28125,
      -0.208984375,
      1.765625,
      -0.06787109375,
      1.890625,
      -5.9375,
      -2.25,
      1.6171875,
      -0.828125,
      0.68359375,
      0.115234375,
      -1.953125,
      -0.55859375,
      0.69140625,
      -2.390625,
      3.03125,
      -1.8046875,
      -1.796875,
      2.90625,
      1.4140625,
      4.53125,
      4.46875,
      -1.5078125,
      -0.80859375,
      -0.75,
      -4.5625,
      -5.15625,
      -0.6875,
      -0.31640625,
      -4.84375,
      0.703125,
      0.8671875,
      0.1875,
      0.484375,
      -0.8359375,
      1.5,
      2.234375,
      1.5,
      -0.2197265625,
      5.3125,
      -0.267578125,
      2.375,
      -4.53125,
      -5.5625,
      -6.46875,
      1.890625,
      -0.2890625,
      -4.75,
      -0.291015625,
      -4.71875,
      2.25,
      1.8984375,
      -1.8125,
      0.294921875,
      -0.2021484375,
      6.03125,
      -0.11328125,
      -2.859375,
      2.640625,
      3.515625,
      3.296875,
      -4.53125,
      -3.578125,
      -3.125,
      1.125,
      0.055419921875,
      0.01324462890625,
      -1.4140625,
      -0.671875,
      -2.609375,
      -0.1689453125,
      -6.03125,
      -2.65625,
      4.4375,
      2.234375,
      5.90625,
      0.6328125,
      -0.92578125,
      -2.078125,
      -1.125,
      -1.6171875,
      4.28125,
      3.15625,
      -0.33984375,
      1.203125,
      -3.609375,
      7.5,
      -5.375,
      -2.421875,
      -6.34375,
      -1.4921875,
      5.5,
      1.8359375,
      -3.796875,
      -1.1171875,
      -0.78125,
      1.515625,
      -0.265625,
      2.328125,
      -0.75,
      -2.953125,
      -1.1328125,
      5.03125,
      2.9375,
      -4.8125,
      1.296875,
      0.92578125,
      -3.25,
      -0.5390625,
      2.515625,
      2.984375,
      -1.4921875,
      4.0625,
      -0.94140625,
      -3.890625,
      -3.8125,
      4.28125,
      -0.00026702880859375,
      -0.90234375,
      1.3984375,
      -3.3125,
      1.734375,
      0.158203125,
      -0.1298828125,
      4.40625,
      -1.5390625,
      1.453125,
      -1.3125,
      3.578125,
      0.40234375,
      -1.671875,
      -3.21875,
      4.6875,
      2.71875,
      0.1376953125,
      1.5703125,
      -2.984375,
      -1.5234375,
      0.435546875,
      -7.0625,
      0.82421875,
      4.84375,
      0.0556640625,
      3.40625,
      -0.28515625,
      2.125,
      -3.109375,
      -0.953125,
      -1.0078125,
      -2.15625,
      2.59375,
      2.34375,
      2.390625,
      -2.0625,
      0.58203125,
      0.470703125,
      1.921875,
      0.57421875,
      5.25,
      -2.09375,
      3.296875,
      4.0625,
      3.859375,
      -4.09375,
      -2.734375,
      -0.01116943359375,
      0.74609375,
      -2.3125,
      0.0283203125,
      1.828125,
      -3.328125,
      1.859375,
      0.30078125,
      -1.265625,
      0.203125,
      -3.1875,
      -0.2177734375,
      1.296875,
      -2.921875,
      -5.8125,
      2.546875,
      -5.75,
      0.0869140625,
      4.0625,
      -0.83203125,
      -1.6171875,
      -1.171875,
      -1.2890625,
      2.640625,
      2.953125,
      -0.48828125,
      -2.984375,
      5.3125,
      -2.84375,
      -6.25,
      -4.71875,
      2.515625,
      -0.330078125,
      -2.921875,
      0.6328125,
      -2.8125,
      1.328125,
      -1.5546875,
      -6.0625,
      2.125,
      -1.171875,
      -0.357421875,
      2.703125,
      4.71875,
      -0.84375,
      -1.7265625,
      -2.234375,
      3.765625,
      1.546875,
      -0.0067138671875,
      -0.05078125,
      -0.2294921875,
      0.404296875,
      -3.25,
      3.796875,
      0.03271484375,
      -1.578125,
      4.875,
      3.671875,
      -6.15625,
      1.3984375,
      1.421875,
      4.6875,
      -3.125,
      -2.8125,
      -0.7265625,
      8.8125,
      -0.92578125,
      -0.98046875,
      -4.15625,
      -0.322265625,
      0.84375,
      -1.09375,
      -0.09814453125,
      -1.3671875,
      2.890625,
      -5.0625,
      0.6796875,
      2.0625,
      4.34375,
      3.8125,
      -3.359375,
      1.59375,
      4.625,
      1.2265625,
      4.21875,
      -2.296875,
      -2.859375,
      -2.390625,
      1.03125,
      -5.9375,
      -2.46875,
      -5.875,
      -2.1875,
      -1.65625,
      -2.421875,
      -1.8671875,
      0.84375,
      1.4765625,
      1.546875,
      -2.171875,
      -0.353515625,
      -1.2578125,
      -2.53125,
      1.5625,
      -0.408203125,
      -5.15625,
      2.078125,
      1.671875,
      -0.267578125,
      5.40625,
      2.390625,
      2.890625,
      -3.3125,
      0.61328125,
      -3.90625,
      -1.2890625,
      -2.40625,
      0.57421875,
      1.671875,
      -0.33984375,
      1.9296875,
      -0.1298828125,
      4.09375,
      -4.9375,
      -4.28125,
      -5.3125,
      -2.84375,
      -0.322265625,
      -0.48046875,
      -1.3125,
      0.84375,
      5.34375,
      -1.9453125,
      2.375,
      2.78125,
      0.921875,
      -4.28125,
      0.267578125,
      0.1357421875,
      3.5,
      3.375,
      4.4375,
      -5,
      4.78125,
      1.09375,
      -2.09375,
      4.0625,
      0.734375,
      1.1796875,
      -4.09375,
      2.875,
      -0.0556640625,
      3.8125,
      -4.0625,
      3.125,
      0.14453125,
      2.421875,
      4.6875,
      6.3125,
      1.796875,
      -2.515625,
      1.2734375,
      0.62109375,
      -2.421875,
      -3.0625,
      2.765625,
      -1.15625,
      -2.078125,
      3.328125,
      -0.5390625,
      2.1875,
      2.296875,
      2.375,
      2.015625,
      4.96875,
      -5.96875,
      2.421875,
      -6.1875,
      0.52734375,
      -5.6875,
      0.4921875,
      -6.78125,
      1.6875,
      3.734375,
      4.21875,
      -1.3515625,
      -4.375,
      2.25,
      2.609375,
      0.1787109375,
      -3.234375,
      2.546875,
      0.8359375,
      -0.1708984375,
      -2.796875,
      -3.140625,
      3.609375,
      0.28125,
      -1.3203125,
      -2.71875,
      2.78125,
      0.80859375,
      -0.244140625,
      -3.828125,
      0.10595703125,
      -2.09375,
      -6.71875,
      -3.65625,
      -3.859375,
      1.9296875,
      -3.640625,
      1.4296875,
      4.5,
      -2.21875,
      1.4921875,
      -0.7578125,
      1.8046875,
      2.140625,
      -0.74609375,
      0.1533203125,
      -0.83203125,
      -0.369140625,
      -0.06396484375,
      3.546875,
      -3.28125,
      0.96484375,
      -2.015625,
      3.421875,
      3.4375,
      -0.55859375,
      -1.484375,
      -7.34375,
      4.65625,
      2.1875,
      0.80859375,
      -0.8046875,
      -3.984375,
      2.265625,
      1.1171875,
      -1.8984375,
      -3.25,
      3.875,
      1.2265625,
      -1.046875,
      1.1484375,
      -0.90625,
      4.03125,
      1.5,
      3.171875,
      0.09423828125,
      0.345703125,
      -2.484375,
      -1.9375,
      -0.8359375,
      1.78125,
      -0.8203125,
      4.28125,
      -1.3125,
      -2.859375,
      -0.80078125,
      3.421875,
      0.9375,
      1.765625,
      -1.8046875,
      -2.234375,
      -1.1484375,
      3.140625,
      -1.2734375,
      -2.078125,
      -0.1826171875,
      0.1884765625,
      -1,
      -1.1953125,
      -0.609375,
      -1.671875,
      2.859375,
      -3.03125,
      -2.328125,
      -2.125,
      2.421875,
      0.443359375,
      -8.375,
      0.609375,
      1.0234375,
      0.78515625,
      0.75390625,
      0.2373046875,
      2.46875,
      3.265625,
      2.625,
      4.375,
      -0.2236328125,
      -3.859375,
      3.265625,
      18.125,
      -4.15625,
      -3.203125,
      1.0234375,
      -2.09375,
      1.2734375,
      9.875,
      0.87109375,
      0.81640625,
      1.4375,
      0.28515625,
      3.53125,
      2.890625,
      0.6171875,
      -1.0546875,
      -0.099609375,
      3.3125,
      2.140625,
      -1.5234375,
      -3.578125,
      0.36328125,
      -0.85546875,
      -0.263671875,
      4.25,
      -3.375,
      0.65625,
      1.859375,
      -3.6875,
      -2.40625,
      -1.890625,
      -1.1640625,
      -3.90625,
      -3.0625,
      -2.859375,
      0.84765625,
      -5.0625,
      -0.68359375,
      0.70703125,
      -2.125,
      -0.80078125,
      -2.390625,
      -4.15625,
      1.8515625,
      1.1953125,
      -2.375,
      -3.28125,
      -1.359375,
      0.271484375,
      -0.77734375,
      3.125,
      0.0118408203125,
      -1.9609375,
      -2.875,
      1.796875,
      1.5078125,
      -0.8359375,
      -2.125,
      -5.8125,
      -2.34375,
      -1.3671875,
      -2.21875,
      -2.6875,
      -3.765625,
      -0.2158203125,
      1,
      -3.125,
      -1.5546875,
      -0.169921875,
      0.416015625,
      0.96484375,
      -5.3125,
      -0.15234375,
      4.75,
      4.5,
      1.4453125,
      -1.703125,
      2.109375,
      4.15625,
      1.015625,
      3.015625,
      -1.2890625,
      1.7265625,
      -4.40625,
      0.2099609375,
      -2.859375,
      0.8828125,
      -4.75,
      1.3125,
      1.2109375,
      -0.494140625,
      4.65625,
      -6.125,
      2.609375,
      2.328125,
      -4.125,
      0.017333984375,
      2.484375,
      -1.6171875,
      -1.28125,
      -1.3984375,
      3.546875,
      1.328125,
      1.453125,
      1.1015625,
      0.36328125,
      -1.96875,
      0.16015625,
      -3.34375,
      1.8125,
      -2.359375,
      -2.828125,
      2.3125,
      1.015625,
      -1.5390625,
      0.0252685546875,
      1.2578125,
      -1.515625,
      -1.8046875,
      0.2265625,
      -1.8671875,
      1.2421875,
      -1.7734375,
      -2.859375,
      0.51953125,
      -8.625,
      -2.390625,
      -0.80078125,
      -5.4375,
      1.140625,
      -4.46875,
      -1.515625,
      -2.0625,
      -2.1875,
      -2.328125,
      2.3125,
      -3.796875,
      3.265625,
      4.71875,
      2.390625,
      -1.578125,
      -3.84375,
      2.109375,
      1.234375,
      -1.140625,
      -2.0625,
      2.234375,
      -2.125,
      0.2451171875,
      1.6328125,
      2.4375,
      -0.6171875,
      3.8125,
      2.40625,
      -4.875,
      -5.65625,
      4.6875,
      -2.4375,
      -1.09375,
      -1.15625,
      -1.0703125,
      -1.390625,
      -0.55078125,
      0.006683349609375,
      -2.9375,
      0.91796875,
      -0.0537109375,
      2.609375,
      -0.75,
      -5.75,
      4.8125,
      4.4375,
      -8.375,
      -0.66015625,
      -2.78125,
      1.3828125,
      -1.34375,
      1.59375,
      5.0625,
      1.265625,
      2.125,
      5.40625,
      2.25,
      -3.03125,
      -5.71875,
      0.029296875,
      3.890625,
      -3.171875,
      2.578125,
      2.671875,
      1.4296875,
      0.2294921875,
      -5.53125,
      -4.125,
      4.6875,
      3.09375,
      -3.3125,
      -1.6484375,
      -1.09375,
      -0.79296875,
      -3.75,
      -2.125,
      2.359375,
      1.4921875,
      2.640625,
      3.078125,
      1.4765625,
      -2.0625,
      2.0625,
      0.59765625,
      0.59765625,
      -2.703125,
      2.65625,
      2.25,
      2.1875,
      -7.75,
      4.8125,
      2.828125,
      2.390625,
      -0.5546875,
      0.296875,
      2.21875,
      0.053466796875,
      -4.75,
      -1.4765625,
      2.53125,
      4.125,
      -7.28125,
      2.4375,
      -3.203125,
      0.76953125,
      -2.1875,
      0.8359375,
      1.5859375,
      0.2001953125,
      -6.59375,
      -5,
      -3.609375,
      3.859375,
      2.5625,
      1.703125,
      2.078125,
      -2.140625,
      4.875,
      1.671875,
      -1.46875,
      0.48828125,
      -2.078125,
      -0.9296875,
      0.75,
      2.65625,
      0.359375,
      3.234375,
      3.984375,
      -2.1875,
      0.41015625,
      -5,
      -4.21875,
      -1.109375,
      -5.03125,
      -0.8828125,
      -0.236328125,
      -7.96875,
      4.9375,
      -1.8359375,
      -1.4140625,
      0.0625,
      0.55078125,
      -7.0625,
      5.625,
      3.953125,
      -4.3125,
      3.421875,
      -0.76171875,
      -2.984375,
      -0.62109375,
      -2.234375,
      -0.008544921875,
      -1.9609375,
      0.6640625,
      4.1875,
      -4.53125,
      1.59375,
      1.7421875,
      -2.546875,
      1.0546875,
      -3.109375,
      3.234375,
      -0.271484375,
      3,
      3.140625,
      0.8984375,
      1.4921875,
      -4.5,
      1.2421875,
      -0.890625,
      3.34375,
      -3.375,
      0.53125,
      0.90625,
      -3.171875,
      2.3125,
      2.109375,
      1.1875,
      -6.4375,
      -2.46875,
      1.3828125,
      -2.328125,
      2.6875,
      1.171875,
      2.703125,
      -3.1875,
      0.2080078125,
      2.5,
      2.21875,
      -1.140625,
      1.1953125,
      -5.25,
      2.390625,
      0.52734375,
      -6.6875,
      -3.890625,
      -0.1328125,
      -0.265625,
      -3.28125,
      -4.0625,
      -3.75,
      -0.1015625,
      2.890625,
      -3.609375,
      -0.0869140625,
      0.212890625,
      -1.8515625,
      2.1875,
      -1.0625,
      2.359375,
      0.203125,
      -1.7578125,
      -7.5625,
      -0.060791015625,
      -1.1640625,
      1.75,
      4.0625,
      -1.75,
      5.78125,
      0.08837890625,
      4.0625,
      -6.1875,
      3.390625,
      3.359375,
      -7.6875,
      3.609375,
      -4.1875,
      -0.4453125,
      -2.328125,
      -5.9375,
      -4.0625,
      3.90625,
      -2.453125,
      1.9765625,
      5.21875,
      -0.345703125,
      -0.1884765625,
      0.33203125,
      -2.359375,
      -3.1875,
      1.125,
      3.640625,
      -3.453125,
      4.03125,
      2.734375,
      -1.75,
      0.89453125,
      -1.3671875,
      1.5546875,
      -0.7578125,
      -5.28125,
      3.71875,
      0.85546875,
      -0.451171875,
      -1.328125,
      -4.4375,
      -1.7265625,
      -1.453125,
      -3.265625,
      1.078125,
      -0.71875,
      1.3046875,
      -1.4140625,
      1.6953125,
      -0.59375,
      -5.53125,
      0.8515625,
      -2.390625,
      -0.177734375,
      1.9765625,
      1.390625,
      1.53125,
      -1.8515625,
      0.419921875,
      3.6875,
      3.640625,
      0.7890625,
      -4.75,
      1.2890625,
      -1.015625,
      -1.578125,
      -2.1875,
      2.796875,
      -3.3125,
      -2.8125,
      3.015625,
      2.65625,
      2.5625,
      -4.71875,
      -2.546875,
      0.48046875,
      3.59375,
      0.0059814453125,
      1.1953125,
      0.4453125,
      2.296875,
      4.25,
      -6.15625,
      -4.3125,
      -1.34375,
      2.3125,
      -4.25,
      -4.78125,
      -0.455078125,
      -2.296875,
      1.0859375,
      5.3125,
      0.0224609375,
      2.15625,
      3.890625,
      -6.0625,
      -3,
      6.0625,
      3.3125,
      1.6171875,
      -0.8984375,
      -0.5078125,
      -2.109375,
      2.15625,
      7.65625,
      -3.796875,
      -2.5625,
      0.38671875,
      -3.953125,
      -2.265625,
      -3.046875,
      2.703125,
      -1.1796875,
      -6.90625,
      8.0625,
      -1.4140625,
      2.109375,
      2.0625,
      -0.80859375,
      3.4375,
      -0.21875,
      -0.296875,
      -1.421875,
      2.421875,
      4.03125,
      -3.859375,
      -3.609375,
      -2.09375,
      -1.65625,
      -0.64453125,
      -3.859375,
      0.006591796875,
      -0.57421875,
      4.03125,
      2.203125,
      0.71875,
      -0.0301513671875,
      -0.5859375,
      1.640625,
      -1.4296875,
      -0.78515625,
      -1.4765625,
      -2.5,
      1.0078125,
      -2.171875,
      2.296875,
      -4.0625,
      -2.953125,
      -0.578125,
      2.578125,
      2.015625,
      3.6875,
      -0.75390625,
      -3.203125,
      -4.21875,
      2.46875,
      0.92578125,
      7.125,
      3.734375,
      3.28125,
      1.2578125,
      -2.359375,
      1.0078125,
      4.1875,
      3.6875,
      -1.71875,
      -0.2080078125,
      2.640625,
      0.578125,
      -1.2890625,
      -0.9375,
      1.2890625,
      2.5625,
      3.9375,
      0.357421875,
      -0.86328125,
      -2.40625,
      -0.29296875,
      -4.5625,
      1.71875,
      3.921875,
      3.96875,
      0.400390625,
      -0.7421875,
      2.765625,
      4.6875,
      1.59375,
      1.578125,
      0.37890625,
      -0.76953125,
      -2.890625,
      1.2421875,
      0.58203125,
      -1.0390625,
      2.28125,
      -1.78125,
      -0.93359375,
      0.625,
      -3.125,
      3.421875,
      -1.0234375,
      -3.453125,
      1.1484375,
      -2.15625,
      3.640625,
      -0.0859375,
      0.1474609375,
      -0.28515625,
      1.9609375,
      1.4140625,
      4.65625,
      -1.9609375,
      -0.279296875,
      1.1484375,
      3,
      -0.86328125,
      -1.0234375,
      0.42578125,
      -0.70703125,
      0.8125,
      -1.3046875,
      0.60546875,
      -2.390625,
      2.5625,
      1.4765625,
      -2.25,
      2.375,
      -2.859375,
      -5.75,
      1.9609375,
      -2.625,
      0.1728515625,
      -1.3046875,
      1.578125,
      1.78125,
      0.031982421875,
      2.25,
      0.28125,
      -2.234375,
      -1.5546875,
      -1.921875,
      -0.75,
      -1.421875,
      -4.875,
      -1.640625,
      0.9296875,
      0.8203125,
      -1.5546875,
      1.75,
      1.40625,
      -0.318359375,
      -1.1796875,
      0.6796875,
      -0.5859375,
      1.2890625,
      0.96875,
      -0.0050048828125,
      1.59375,
      2.890625,
      0.9375,
      0.8828125,
      -0.388671875,
      1.6328125,
      -1.2578125,
      1.1015625,
      2.125,
      2.25,
      1.3046875,
      -0.51171875,
      2.171875,
      -0.84765625,
      2.640625,
      -2.375,
      0.50390625,
      -0.22265625,
      -1.78125,
      4.40625,
      -1.5390625,
      -0.640625,
      2.578125,
      2.5625,
      -3.390625,
      -1.5546875,
      -0.96484375,
      1.3515625,
      1.4609375,
      0.57421875,
      -2.40625,
      1.484375,
      0.94921875,
      2.109375,
      1.828125,
      2.671875,
      -4.1875,
      0.80078125,
      1.78125,
      -1.7421875,
      -0.03662109375,
      -0.259765625,
      -1,
      -0.361328125,
      -2.90625,
      -4.75,
      -0.0263671875,
      -0.0712890625,
      0.251953125,
      1.359375,
      -2.984375,
      1.0078125,
      0.07568359375,
      1.78125,
      3.359375,
      -3.484375,
      0.95703125,
      -0.41796875,
      1.109375,
      -1.3125,
      0.486328125,
      -0.85546875,
      1.6640625,
      -3.046875,
      -0.15234375,
      -1.3125,
      -0.875,
      0.00189208984375,
      0.984375,
      -1.421875,
      -4.21875,
      -1.1015625,
      -1.921875,
      -1.671875,
      -3.6875,
      1.96875,
      1.6171875,
      -2.703125,
      -1.03125,
      0.828125,
      -0.1806640625,
      0.447265625,
      -1.4921875,
      -0.703125,
      0.734375,
      2.484375,
      2.65625,
      3.171875,
      -1.90625,
      3,
      -1.6796875,
      -1.6640625,
      -3.59375,
      -0.21484375,
      1.7734375,
      -2.390625,
      2.875,
      -0.0037841796875,
      2.734375,
      3.296875,
      -0.96484375,
      0.80859375,
      1.5546875,
      -0.2275390625,
      4.375,
      3.703125,
      0.57421875,
      -0.08203125,
      0.130859375,
      0.69921875,
      0.482421875,
      0.59375,
      1.453125,
      -1.4921875,
      3.46875,
      -2.25,
      -0.69921875,
      -1.9140625,
      -1.7734375,
      0.51171875,
      -0.2177734375,
      0.90625,
      -3,
      3.1875,
      -0.84375,
      -1.734375,
      -0.578125,
      -0.333984375,
      -1.7421875,
      -0.061279296875,
      -3.65625,
      -2.140625,
      -1.078125,
      -1.3671875,
      1.0703125,
      0.408203125,
      -0.765625,
      -2.828125,
      -2.453125,
      -0.52734375,
      0.150390625,
      0.61328125,
      0.90625,
      1.984375,
      1.4375,
      0.333984375,
      0.92578125,
      -1.6796875,
      1.75,
      1.1171875,
      -0.94921875,
      1.1796875,
      -1.1640625,
      -0.341796875,
      -2.84375,
      -3.46875,
      -0.2060546875,
      -0.5546875,
      -1.640625,
      0.322265625,
      1.1875,
      -1.609375,
      -3.25,
      1.609375,
      -1.953125,
      4.78125,
      -0.275390625,
      -2.359375,
      2.875,
      0.291015625,
      0.412109375,
      -1.78125,
      -2.265625,
      1.1015625,
      -0.431640625,
      1.0546875,
      -1.0234375,
      1.59375,
      -1.1015625,
      0.55078125,
      -1.609375,
      -0.4375,
      -1.125,
      -2.09375,
      0.96484375,
      1.1328125,
      -0.69921875,
      5.4375,
      1.9140625,
      3.09375,
      0.52734375,
      0.22265625,
      0.75390625,
      4.0625,
      2.703125,
      -1.03125,
      -2.15625,
      -1.328125,
      2.796875,
      1.0859375,
      0.2275390625,
      -0.1787109375,
      3.125,
      7.53125,
      -0.51953125,
      -1.5859375,
      -2.90625,
      -0.79296875,
      0.1982421875,
      1.3515625,
      4.84375,
      -5.5,
      -0.27734375,
      0.90625,
      -0.138671875,
      -0.60546875,
      2.296875,
      3.28125,
      -0.357421875,
      2.921875,
      1.2421875,
      1.3359375,
      -1.0546875,
      1.8046875,
      -0.427734375,
      3.09375,
      -0.984375,
      -1.40625,
      -1.2109375,
      0.609375,
      -4.03125,
      2.328125,
      -1.453125,
      -0.1259765625,
      0.78125,
      -0.11474609375,
      3.28125,
      -2.59375,
      0.53515625,
      5.25,
      -0.6875,
      1.0703125,
      -1.421875,
      -0.298828125,
      4.59375,
      0.609375,
      0.74609375,
      -2.46875,
      2.28125,
      -0.373046875,
      -4.21875,
      -3.359375,
      -0.2470703125,
      -3.390625,
      -1.5390625,
      -5.03125,
      -0.0089111328125,
      -1.0703125,
      5.4375,
      -1.625,
      0.68359375,
      1.8515625,
      0.921875,
      1.1328125,
      4.53125,
      2.03125,
      1.84375,
      -0.474609375,
      -0.6171875,
      2.25,
      0.35546875,
      -2.671875,
      -0.8515625,
      2.4375,
      -3.953125,
      1.4765625,
      -1.796875,
      -1.3671875,
      0.578125,
      -2.765625,
      -1.78125,
      -1.6015625,
      1.328125,
      -3.046875,
      2.625,
      0.7421875,
      -0.96484375,
      -3.78125,
      2.75,
      1.5390625,
      1.1796875,
      1.921875,
      -1.3125,
      -2.4375,
      1.6171875,
      0.51171875,
      -0.2451171875,
      -1.3515625,
      3.078125,
      3.65625,
      -0.66015625,
      -2,
      0.5234375,
      3.640625,
      -0.53125,
      0.98828125,
      -2.515625,
      -1.890625,
      0.78515625,
      4.40625,
      2.09375,
      1.375,
      1.4609375,
      3.4375,
      -2.15625,
      1.2421875,
      -0.97265625,
      -3.15625,
      -1.46875,
      1.9375,
      1.1171875,
      1.609375,
      3.78125,
      0.97265625,
      2.203125,
      -3.859375,
      1.609375,
      -0.27734375,
      -2.53125,
      3.140625,
      0.69140625,
      -2.625,
      -2,
      -0.103515625,
      -4.875,
      1.578125,
      -1.1484375,
      -3.671875,
      1.40625,
      0.87109375,
      -0.11865234375,
      0.1826171875,
      -1.671875,
      2.921875,
      5.28125,
      0.8515625,
      1.359375,
      1.1640625,
      0.3671875,
      1.359375,
      -2.21875,
      3.359375,
      -1.640625,
      -3.96875,
      0.515625,
      0.61328125,
      1.7734375,
      -0.15234375,
      0.337890625,
      1.7890625,
      0.00836181640625,
      -1.4375,
      3.71875,
      0.94140625,
      0.25,
      4.40625,
      -0.91015625,
      0.07177734375,
      -3.953125,
      1.9609375,
      0.578125,
      -0.0751953125,
      0.181640625,
      1.578125,
      0.051513671875,
      -2.4375,
      0.2734375,
      -1.453125,
      1.7109375,
      -0.54296875,
      -0.71875,
      -2.21875,
      -2.453125,
      -2.46875,
      0.859375,
      -4.875,
      1.8046875,
      -0.34765625,
      -1.9296875,
      1.34375,
      -1.1875,
      -2.71875,
      -3.640625,
      1.9609375,
      2.203125,
      1.0390625,
      -3.515625,
      0.388671875,
      3.171875,
      -0.8046875,
      1.1875,
      3.53125,
      2.515625,
      -0.09130859375,
      -2.015625,
      1.453125,
      -6.9375,
      0.1982421875,
      -1.5390625,
      1.3203125,
      1.5,
      0.470703125,
      -1.7109375,
      4.03125,
      1.9609375
    ],
    "structure": {
      "sections": [
        {
          "title": "A large language model-assisted education tool to provide feedback on open-ended responses",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Introduction",
          "level": 1,
          "start_line": 11
        },
        {
          "title": "Related Work",
          "level": 1,
          "start_line": 24
        },
        {
          "title": "Approach",
          "level": 1,
          "start_line": 36
        },
        {
          "title": "Question Design",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "Question Presentation",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "Feedback to Students",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "Discussion",
          "level": 1,
          "start_line": 92
        },
        {
          "title": "Supplemental Materials",
          "level": 1,
          "start_line": 114
        },
        {
          "title": "Acknowledgements",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "Bibliography",
          "level": 1,
          "start_line": 126
        }
      ]
    },
    "tags": [
      "教育技术",
      "大语言模型",
      "自动评分"
    ],
    "suggested_tags": [
      "教育技术",
      "大语言模型",
      "自动评分",
      "人机交互"
    ],
    "tag_suggestions": [
      {
        "name": "教育技术",
        "confidence": 0.95,
        "reason": "论文核心是开发一个辅助教育的工具，旨在解决教学评估中的实际问题，属于教育技术（EdTech）领域。"
      },
      {
        "name": "大语言模型",
        "confidence": 0.9,
        "reason": "论文的核心技术是使用大语言模型（LLM）来生成对开放式问题的反馈，LLM是该方法的关键驱动技术。"
      },
      {
        "name": "自动评分",
        "confidence": 0.85,
        "reason": "论文的主要任务是自动化对开放式学生回答的评估和反馈，这是自动评分（Automated Grading）或自动简答评分（ASAG）的典型应用。"
      },
      {
        "name": "人机交互",
        "confidence": 0.75,
        "reason": "论文设计了一个工具（Web应用/Jupyter部件）供教师和学生使用，涉及系统设计以辅助教学流程，属于教育场景下的人机交互范畴。"
      }
    ],
    "tags_confirmed": true,
    "category": "AI Research教育AI",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:276483132",
          "title": "Enhancing Cybersecurity Education using Scoring Engines: A Practical Approach to Hands-On Learning and Feedback",
          "authors": [
            "Christopher Morales-Gonzalez",
            "Matthew Harper",
            "Pranathi Rayavaram",
            "Sashank Narain",
            "Xinwen Fu"
          ],
          "year": 2025,
          "venue": "Technical Symposium on Computer Science Education",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:275786515",
          "title": "A Rubric-Centric Approach for Automated Test Correction Utilizing RAG and Fine Tuning",
          "authors": [
            "G. Harshavardhan",
            "Kulvinder Singh"
          ],
          "year": 2024,
          "venue": "2024 4th International Conference on Technological Advancements in Computational Sciences (ICTACS)",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:271571948",
          "title": "Grading Programming Assignments by Summarization",
          "authors": [
            "Dong Dong",
            "Yue Liang"
          ],
          "year": 2024,
          "venue": "ACM Turing Celebration Conference",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:271462617",
          "title": "Automated Verification of Open/Closed Principle: A Code Analysis Approach",
          "authors": [
            "Gifty Roy",
            "Manohar M",
            "Benjamin A. Jacob"
          ],
          "year": 2024,
          "venue": "2024 5th International Conference for Emerging Technology (INCET)",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:265543562",
          "title": "Intelligent Deep-Learning Tutoring System to Assist Instructors in Programming Courses",
          "authors": [
            "David Roldán-álvarez",
            "Francisco J. Mesa"
          ],
          "year": 2024,
          "venue": "IEEE Transactions on Education",
          "citation_count": 10
        },
        {
          "external_id": "CorpusId:260611570",
          "title": "A large language model-assisted education tool to provide feedback on open-ended responses",
          "authors": [
            "Jordan K Matelsky",
            "Felipe Parodi",
            "Tony Liu",
            "Richard D. Lange",
            "K. Kording"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 30
        },
        {
          "external_id": "CorpusId:259203965",
          "title": "Automated Grading and Feedback Tools for Programming Education: A Systematic Review",
          "authors": [
            "Marcus Messer",
            "Neil C. C. Brown",
            "Michael Kölling",
            "Miaojing Shi"
          ],
          "year": 2023,
          "venue": "ACM Transactions on Computing Education",
          "citation_count": 125
        },
        {
          "external_id": "CorpusId:256194488",
          "title": "Smart tutor to provide feedback in programming courses",
          "authors": [
            "David Rold'an-'Alvarez"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:251881395",
          "title": "Automatic Assessment of the Design Quality of Student Python and Java Programs",
          "authors": [
            "J. Orr"
          ],
          "year": 2022,
          "venue": "Journal of Computing Sciences in Colleges (JCSC; Formerly: Journal of Computing in Small Colleges)",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:250315989",
          "title": "Automated Grading and Feedback of Programming Assignments",
          "authors": [
            "Marcus Messer"
          ],
          "year": 2022,
          "venue": "Annual Conference on Innovation and Technology in Computer Science Education",
          "citation_count": 3
        }
      ],
      "citations_fetched_at": "2025-12-17T09:45:02.640949",
      "references": [
        {
          "external_id": "CorpusId:6967078",
          "title": "The Continuous Hint Factory - Providing Hints in Vast and Sparsely Populated Edit Distance Spaces",
          "authors": [
            "Benjamin Paassen",
            "B. Hammer",
            "T. Price",
            "Tiffany Barnes",
            "S. Gross",
            "Niels Pinkwart"
          ],
          "year": 2017,
          "venue": "arXiv.org",
          "citation_count": 56
        },
        {
          "external_id": "CorpusId:3550454",
          "title": "Learning to Represent Student Knowledge on Programming Exercises Using Deep Learning",
          "authors": [
            "L. Wang",
            "Angela Sy",
            "Larry Liu",
            "C. Piech"
          ],
          "year": 2017,
          "venue": "Educational Data Mining",
          "citation_count": 87
        },
        {
          "external_id": "CorpusId:6515824",
          "title": "Learning Program Embeddings to Propagate Feedback on Student Code",
          "authors": [
            "C. Piech",
            "Jonathan Huang",
            "A. Nguyen",
            "Mike Phulsuksombati",
            "M. Sahami",
            "L. Guibas"
          ],
          "year": 2015,
          "venue": "International Conference on Machine Learning",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:6628106",
          "title": "Adam: A Method for Stochastic Optimization",
          "authors": [
            "Diederik P. Kingma",
            "Jimmy Ba"
          ],
          "year": 2014,
          "venue": "International Conference on Learning Representations",
          "citation_count": 160262
        },
        {
          "external_id": "CorpusId:14832074",
          "title": "Improving neural networks by preventing co-adaptation of feature detectors",
          "authors": [
            "Geoffrey E. Hinton",
            "Nitish Srivastava",
            "A. Krizhevsky",
            "I. Sutskever",
            "R. Salakhutdinov"
          ],
          "year": 2012,
          "venue": "arXiv.org",
          "citation_count": 7891
        },
        {
          "external_id": "CorpusId:26300103",
          "title": "Classification and regression trees",
          "authors": [
            "N. Speybroeck"
          ],
          "year": 2012,
          "venue": "International Journal of Public Health",
          "citation_count": 15842
        },
        {
          "external_id": "CorpusId:740063",
          "title": "A Survey on Transfer Learning",
          "authors": [
            "Sinno Jialin Pan",
            "Qiang Yang"
          ],
          "year": 2010,
          "venue": "IEEE Transactions on Knowledge and Data Engineering",
          "citation_count": 22286
        },
        {
          "external_id": "CorpusId:15539264",
          "title": "Rectified Linear Units Improve Restricted Boltzmann Machines",
          "authors": [
            "Vinod Nair",
            "Geoffrey E. Hinton"
          ],
          "year": 2010,
          "venue": "International Conference on Machine Learning",
          "citation_count": 18220
        },
        {
          "external_id": "CorpusId:7398727",
          "title": "Solving the Multiple Instance Problem with Axis-Parallel Rectangles",
          "authors": [
            "Thomas G. Dietterich",
            "R. Lathrop",
            "Tomas Lozano-Perez"
          ],
          "year": 1997,
          "venue": "Artificial Intelligence",
          "citation_count": 2935
        },
        {
          "external_id": "CorpusId:62710001",
          "title": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS",
          "authors": [
            "F. Rosenblatt"
          ],
          "year": 1963,
          "venue": "",
          "citation_count": 2560
        }
      ],
      "references_fetched_at": "2025-12-17T09:45:03.170339"
    },
    "summary": "[方法型] 开发了一个基于大语言模型（LLM）的自动化反馈工具，该工具根据教师定义的评估标准，对学生的开放式回答进行自动评估并提供个性化反馈。"
  },
  "87710e08-8ea7-4cce-86e6-24aaf2c7e7dd": {
    "id": "87710e08-8ea7-4cce-86e6-24aaf2c7e7dd",
    "filename": "ssrn-4768574.pdf",
    "file_path": "data/uploads/47e5d413-0cfd-43be-ba5a-dd4b0c5160c5/87710e08-8ea7-4cce-86e6-24aaf2c7e7dd_ssrn-4768574.pdf",
    "status": "completed",
    "created_at": "2025-12-20 12:37:17.535100",
    "updated_at": "2025-12-20 04:38:38.063012",
    "user_id": "47e5d413-0cfd-43be-ba5a-dd4b0c5160c5",
    "title": "The cost of auditing service performance information",
    "markdown_content": "Working Paper No. 24-02\n\n# The cost of auditing service performance information\n\nXikai Chen\n\nDepartment of Accounting\n\nDeakin University\n\nMelbourne, Australia\n\nxikai.chen@deakin.edu.au\n\nTom Scott*\n\nDepartment of Accounting\n\nAuckland University of Technology\n\nAuckland, New Zealand\n\nthomas.scott@aut.ac.nz\n\n5 March 2024\n\n# The cost of auditing service performance information\n\n# ABSTRACT\n\nThis paper adds to prior literature by examining the impact on audit effort from requiring the assurance of non-financial information. Specifically, we use a sample of large New Zealand not-for-profits (charities) newly required to report and have assured statements of service performance following accounting and auditing standards. We find an increase in audit fees of  $14.5\\%$ , although there is no change in audit or filing lag. There is no difference based on auditing standard used, audit firm or whether an 'other matter' is expressed in the audit report. Overall, our results suggesting mandating the reporting and assurance of non-financial information should be viewed as having greater costs than adopting International Financial Reporting Standards.\n\nKeywords: Service performance; Not-for-profits; charities; audit fee; non-financial assurance\n\nJEL Classifications: G38, M42, M48\n\n*Corresponding author\n\nDeclaration: The authors have no relevant financial or non-financial conflict of interests to disclose.\n\nAcknowledgments: For comments on previous versions, we thank Michael Bradbury and Arung Mayapada.\n\n# I. INTRODUCTION\n\nThere has been a growing interest in non-financial reporting in the public and not-for-profit sectors (Australian Accounting Standards Board [AASB], 2021; External Reporting Board [XRB], 2017; International Public Sector Accounting Standards Board [IPSASB], 2015, 2022). Service performance reporting is argued to be important in these sectors as it provides contextual information in the form of both quantitative performance indicators and qualitative information that allows users to assess whether the entity has been successful in achieving its mission. Furthermore, if service performance information is disclosed then its assurance may also be mandated to enhance its quality and credibility. However, a longstanding concern with uptake of non-financial assurance is its cost (Farooq and de Villiers, 2017). Although Xu and Yang (2023) provide evidence on the assurance of SSP by smaller NZ charities, they do not document the impact on audit effort. Thus, research examining the cost of service performance reporting and assurance contributes to previous research on SSP and balances prior literature on service performance reporting quality, which although notes benefits also suggests that best practise is not always followed (Connolly and Hyndman, 2013; McConville and Cordery, 2018; Johansson et al., 2022).\n\nWe use the New Zealand (NZ) not-for-profit (charity) sector to provide new insight into the cost of service performance reporting and assurance as the largest not-for-profits in NZ (called Tier 1 entities with total expenses over $30 million) are required to prepare statements of service performance (SSPs) from 1 January 2022. Thus, the NZ not-for-profit setting allows the investigation on whether mandating SSP assurance increases audit fees. Tier 1 not-for-profits must follow Public Benefit Entity International Public Sector Accounting Standards (PBE IPSAS), with the NZ specific standard of PBE FRS 48 Service Performance Reporting applying to SSPs. Furthermore, SSPs are audited as part of financial statement audit with the auditor giving their opinion on the SSPs in the same audit report issued for the financial statements. SSPs may currently be audited under International Standard for Assurance Engagement (ISAE) (NZ) 3000 (Revised) Assurance Engagements Other than Audits or Reviews of Historical Financial Information or NZ Auditing Standard (NZ AS) 1 The Audit of Service Performance Information. We focus on a sample based on all Tier 1 not-for profits to enable the examination of the effect of SSP\n\nreporting and assurance in a setting where they must be prepared following accounting standards and assured under auditing standards.\n\nWe find that there is a large and significant increase in audit fees post-SSPs. In economic terms the increase is equal to  $14.5\\%$  or NZD$15,535 of mean audit fees. Thus, the increase can be viewed as economically larger than the cost of International Financial Reporting Standard (IFRS) adoption which was found to increase audit fees by  $11\\%$  in NZ listed companies (Higgins et al., 2016). We find that  $72\\%$  of observations use NZ AS 1 versus ISAE 3000 when assuring the SSP, with the early adoption of NZ AS 1 resulting in no further increase in audit fees. Thus, we conclude that that the early adopters of this service performance auditing standard did not bear any cost of learning the new standard, in contrast to early adopters of IFRS in NZ (Higgins et al., 2016), but that it also led to no efficiency gains. Furthermore, we find no qualified or emphasis of matter audit reports related to the SPP. We did find that  $62\\%$  of SSP observations expressed an \"other matter\" that the prior year comparative figures were not audited, however the clear disclosure of this also did not result in lower audit fees. In addition, although there is an evidence of a Big 4 fee premium, there is no difference in the post-SSP increase for Big 4 clients. Last, we examine the effects on audit and filing lags, and find no differences post-SSP.\n\nOur results first contribute to the academic literature that documents the effect of accounting standards and regulations on audit pricing. This includes the emerging literature on the cost of non-financial assurance (Lu et al., 2023), responding to calls for further research on the effects of regulating non-financial disclosure and the non-financial reporting practices of PBEs (Farooq and de Villiers, 2017; de Villiers et al., 2022). Our results suggest that the shift to SSP assurance results in a larger increase in audit effort than the adoption of IFRS in NZ. Our audit lag results contrast with Mayapada et al. (2023) who finds moving to more detailed and prescriptive statements of recommended practice increases audit lag. We infer the difference may be driven by a longer period between announcement and the adoption period (almost seven years vs less than one year), reducing the unexpected effort component for auditors.\n\nSecond, we add to the literature on service performance assurance, and Xu and Yang (2022) directly by documenting an increase in audit fees and considering the assurance among larger charities who must follow full accounting and auditing standards. As our study focuses on the largest not-for-profits, they may be more able to have the underlying\n\nreporting systems needed to prepare such information suggesting that the costs may be proportionately higher for smaller not-for-profits (Cordery and Deguchi, 2018). We also document no qualified audit opinions relating to SSPs, allaying concerns that there could be a systemic failure in the ability to prepare and audit SSPs. Thus, we contribute to the burgeoning stream of SSP reporting by empirically measuring the cost of SSP reporting and assurance.\n\nLast, we contribute directly to accounting and auditing standard setters. Our results provide direct evidence to the XRB and to not-for-profit regulators when assessing PBE FRS 48. Our results are likely of interest to other standard-setters for whom service performance reporting for this sector is on the work plan, especially the AASB who plan to use PBE FRS 48 as the primary point of reference and have expressed concerns about the auditability and cost of SSPs. Furthermore, evidence may also be of use to IPASB who are planning to revise their guidance note on service performance reporting and indirectly to the International Accounting and Assurance Standards Board when considering the cost of non-financial assurance.\n\nIn the next section, we discuss the institutional setting, literature review and research questions. This is followed by a discussion of our research method. We then report our results, and the final section provides concluding remarks.\n\n# 2. INSTITUTIONAL SETTING, LITERATURE REVIEW AND RESEARCH QUESTIONS\n\n# Institutional Setting\n\nNot-for-profits (charities) in NZ are governed by the Charities Services (previously Charities Commission), part of Department of Internal Affairs (DIA) and governed by the Charities Act 2005. Promoting public trust and confidence in the charitable sector is the main role of Charities Services, including the registration of charities. Importantly, only donors to registered charities benefit from claiming tax credits and rebates for their charitable donations. To be registered, not-for-profits must file with Charities Services, who maintain and process filings via the Charities Register which is publicly available. Reform to not-for-profits reporting in 2015 created a tier system with different reporting and auditing requirements based on not-for-profits size as shown in Table 1. Large charities use PBE IPSAS, whilst smaller not-for-profits use simple formatting reporting, with the smallest reporting on a cash basis. Tseng et al. (2023) find an increase in accuracy and in donations after the reforms, especially for the smaller not-for-profits.\n\nFurthermore, motivated to better meet user needs about why the entity exists, how the entity intends to achieve its broad objectives, and what the entity has done, charities were also required to prepare a statement of service performance (SSP). SSPs include qualitative and quantitative information (i.e. descriptions of performance and performance indicators) about the entity's supply of goods and services and to communicate the effects an entity has on the community. In preparing SSPs, the qualitative characteristics identified in the PBE conceptual framework must be applied and accounting standards followed. SSPs must be prepared following PBE FRS 48, a new NZ specific standard which replaced PBE IPSAS 1. In contrast to PBE IPSAS 1, PBE FRS 48 does not require service objectives to be expressed in terms of inputs, outputs, outcomes, efficiency or effectiveness. Hsiao et al. (2023) document that in the NZ university sector that early adopters of PBE FRS 48 provide users with more performance indicators about contextual information about why the entity exists, what it intends to achieve and how it goes about this and what the entity has done during the reporting period. Service performance reporting requirements are not novel in NZ, as there has been over a decade of service performance reporting in the public sector including government department, local government, amongst other entries (Scott and Pinny, 2016). Not-for-profit service performance reporting began with the smallest not-\n\nfor-profits from 1 April 2015, with mandatory reporting by the larger charities from 1 January 2022.\n\nSSPs must also be audited. For periods beginning from 1 January 2024 a NZ specific auditing standard, NZ AS 1, is mandatory. Although early adoption is permitted, prior to NZ AS 1 ISAE 3000 was used to audit SSPs. In contrast to ISAE 3000, which applied broadly to non-financial audits, NZ AS 1 is focused solely on the audit of service performance information and was written subsequent to PBE FRS 48. The standard was viewed as resolving audit issues specific to SSP including determining materiality, what is a SSP a misstatement and how outcomes and outputs in SSP relate to assertions (XRB, 2018). Thus, as per Table 1, the largest not-for-profits must prepare a statement of service performance following PBE FRS 48 which must also be audited. Figure 1 in Appendix A provides an extract of a not-for-profit audit report in the SSP period. It highlights that the SSP is audited alongside the financial statements as part of the annual report and must not be reported separately.\n\nTable 1: Reporting requirements  \n\n<table><tr><td></td><td>Tier 1</td><td>Tier 2</td><td>Tier 3</td><td>Tier 4</td></tr><tr><td>Threshold</td><td>&gt; $30 million total expenses or public accountability</td><td>&gt; $2 million and &lt; $30 million total expenses</td><td>&gt; $125 thousand and &lt; $2 million total expenses</td><td>&lt; $125 thousand total operating payments</td></tr><tr><td>Accounting Standard</td><td>PBE IPSAS</td><td>Reduced disclosure regime</td><td>Simple format reporting - accrual</td><td>Simple format reporting - cash</td></tr><tr><td>Service Performance Requirements</td><td>From 1 January 2022</td><td>From 1 January 2022</td><td>From 1 April 2015</td><td>From 1 April 2015</td></tr><tr><td>Assurance Requirements</td><td>Audit</td><td>Audit</td><td>&lt; $500 thousand voluntary, &gt; $1 million audit and between audit or review</td><td>Voluntary</td></tr><tr><td>Assurance standards</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td></tr></table>\n\n# Literature Review and Hypothesis Development\n\nThere is large body of prior research that examines the supply and demand of audit effort (e.g., Hay et al., 2006; DeFond and Zhang, 2014; Causholli et al. 2010; Eierle et al. 2022). Changes in accounting or auditing regulations would result in a newer higher equilibrium price if auditing became more complex or risky. IFRS are typically argued to be more 'complex' than the previous standards used. For example, IFRS have a greater use of fair value accounting, and revaluations are associated with higher audit fees (Yao et al., 2015). Bradbury and Scott (2020) emphasis the cost of monitoring measurement and judgement issues are more likely to borne by auditors than regulators. Thus there are higher audit fees after IFRS adoption (Kim et al. 2012; De George et al. 2013), including in NZ (Griffin et al., 2009; Higgins et al. 2016). Likewise, there is an increase in audit fees after the passage of the Sarbanes-Oxley Act (Griffin and Lont, 2007; Hoitash et al., 2008; Ghosh and Pawlewicz, 2009; Huang et al., 2009). Evidence also suggests that moving to a less 'strict' auditing standard reduces audit fees (Doogar et al. 2010; Krishnan et al. 2011), as do accounting standard changes that better align auditors and preparers (Grosse et al., 2023). International evidence typically finds no evidence that the requirement to disclose Key Audit Matters increase audit fees (Eierle et al. 2022), including in New Zealand (Al-mulla and Bradbury, 2022). Research from the UK not-for-profit sector, finds moving to more detailed and prescriptive statements of recommended practice increases audit fee, audit lag and reporting lag (Mayapada et al., 2023).\n\nEvidence from non-financial information also suggests that the provision of new information that is assured increases audit fees. In a review of the literature, Farooq and De Villiers (2017) note that cost can be a major barrier for the voluntary adoption of sustainability assurance. There is a positive association between audit fees and CSR concerns and strengths, suggesting that CSR is a source of uncertainty (Garcia et al., 2021). Lu et al. (2023) finds an increase in audit fees for integrated reporters, driven by those who have less useful financial information. They argue that by better understanding the connectivity between firm risks, integrated reporting assurance can have a spillover in improved efficiency. Thus, the assurance of more complex financial or non-financial information increases audit fees, although this may be partly offset by better understanding the entity. This leads to our first hypothesis, stated as:\n\nIn addition, while it would seem likely the requirement to prepare and have audited a SSP would increase audit fees, the increase in audit fees may be heterogeneous across the not-for-profit sector based on engagement characteristics. First, in the year of SSP adoption auditors could choose to use ISAE 3000 or the newly available NZ AS 1, which is more aligned with the applicable accounting standard PBE FRS 48. Recall, that less strict or aligning accounting and auditing standards reduce audit fees (Doogar et al. 2010; Krishnan et al. 2011; Grosse et al., 2023), thus the use of NZ AS 1 could also minimize the costs of SSP assurance. On the other hand, early adopters of IFRS had higher audit fees in NZ (Higgins et al., 2016), early adopters of NZ AS 1 could bear the learning costs for audit firms. Thus, it is unclear whether the early adoption of NZ AS 1 would moderate or heighten the positive association between audit fees and SSP assurance. Second, Xu and Yang (2023) provide descriptive evidence on the assurance of SSPs for selected smaller NZ not-for-profits and suggest there is a high tolerance for lower quality performance information, and that it may be driven by a compliance mindset. A compliance mindset may suggest that any cost increase is modest and costs could be further minimised through disclosure of a non-clean audit opinion, with Xu and Yang (2023) reporting 16 of the 81 audits in their sample had a modified opinion – although only one was in relation in statement of service performance information. Furthermore, as service performance information for the previous period does not need to be audited, the auditor must include an other matter paragraph in the auditor's report that says the corresponding figures are unaudited (CA ANZ, 2022). Therefore, the presence of an other matter could suggest less audit effort, and thus a smaller increase in audit fees, as the corresponding figures from the previous year are unaudited. Last, there is a large literature showing differential audit pricing by the Big 4 (Simunic, 1980), including in the not-for-profit space (Vermeer et al., 2009; Yang and Simnett, 2022). Big 4 audit firms may be better able to resource a change in workload or have a differential cost structure with more fixed costs allowing them to absorb the extra work (Higgins et al., 2016). Thus, the increase in audit fees for SSP assurance may differ based on who the auditor is. We state these jointly as our second hypothesis as follows:\n\nH2: The positively association between audit fees and statement of service performance assurance is impacted by use of auditing standard, audit report and auditor\n\n# 3. RESEARCH METHOD\n\n# Sample\n\nOur sample is based on all Tier 1 not-for-profits (charities) in NZ. As our focus is on the initial adoption of service performance reporting by not-for-profits we exclude 11 entities which although also registered not-for-profits which have different reporting obligations mean that they previously reported SPPs by being quasi public-sector organisations such as museums, or university trusts. 17 (21% of the final sample) not-for-profits are excluded through having insufficient audit data – namely not attaching the audit report to their annual report or not clearly disclosing the audit fee. Thus, our first observation is there is not strong compliance with reporting requirements of filing an audited financial statement, including the audit report. This results in a sample of 62 not-for-profits, which as we are interested in a pre- and post-SSP analysis result in 124 entity-year observations. As SSPs were required for financial years beginning 1 January 2022, not-for-profits with a 31 December 2022, 31 March 2023, 30 June 2023 or financial year-end would be the first year of reporting SSP (i.e. the post period). Accordingly, balance dates of 31 December 2021, 31 March 2022 and 30 June 2022 are the pre-SSP period. $^{2}$ . Therefore, our sample is drawn from 2021 to 2023. We use the Charities Register to access annual report and hand collect relevant audit data, whilst control variables are downloaded via the advanced search function of the register.\n\n# Regression Models\n\nOur analysis uses a regression model to estimate audit effort with determinants drawn from prior literature (Vermeer et al., 2009; Yang and Simnett, 2022). Due to our relatively small sample size, we specific following parsimonious regression model (time and firm subscripts omitted for convenience):\n\n$$\nL n A F = \\beta_ {0} + \\beta_ {1} P O S T + \\beta_ {2} L n T A + \\beta_ {5} A R I N V + \\beta_ {7} T L T A + \\beta_ {8} C A S H T A +\n$$\n\n$$\n\\beta_ {8} D o n a t i o n s + \\beta_ {9} C i t y C o s t + \\beta_ {9} L o s s + \\beta_ {9} C l e a n + \\beta_ {1 0} B i g 4 + S e c t o r + \\varepsilon\n$$\n\n(1)\n\nAll variables are formally defined in Table 2.3 First, we specify  $LnAF$  as the dependent variable which measures the natural logarithm of reported audit fees. Next, we specify the dependent variable as  $POST$ , a binary variable equal to one for the period beginning on or after 1 January 2022 (i.e., after the service performance reporting requirements). If  $POST$  is significantly positive, H1 is supported. To test H2, we then rerun the regression model by including one a time variables that measure differences in the audit engagement. Namely, we examine, a binary variable equal to one if NZ AS 1 is used to audit the SSP ( $AS1$ ), a binary variable equal to one if an other matter is expressed that the prior year corresponding figures in the SSP are unaudited ( $SSPOM$ ) and the interaction if the SSP is audited by a Big 4 auditor and  $POST$ ( $POST\\_Big4$ ). If any of these variables are significantly, support for H2 is found. We do not interact  $AS1$  or  $SSPOM$  as they can only equal one in the post-period by design.\n\nIn a meta-analysis of published studies, Hay et al. (2006) find that client size is the most important determinant of audit effort and this is consistent with not-for-profit studies (Vermeer et al., 2009; Yang and Simnett, 2022). Thus, we expect a positive sign on the natural logarithm of total assets (LnTA). Client risk and complexity are associated with higher audit effort (Simunic 1980; Dickins et al. 2008). We expect a negative association between the proportion of total assets that are accounts receivable or inventory (ARINV), but a positive association for the ratio of total liabilities to total assets (TLTA) and the proportion of total assets that is cash or inventory (CASHTA). Donations is the proportion of revenue from donations may suggest a riskier revenue stream (Yang and Simnett, 2022). Entities under greater financial stress, as measured by whether total expenses are larger than total revenue, may also be more risky (Loss). We also control for whether the audit is conducted in a higher cost centre, using a binary variable equal to one if the audit is based out of Auckland (CityCost) (Chan et al. 1993; Grosse et al., 2023) and if there is any modification to the audit report including other matters (Clean). We also control for the effect of any Big4 effect, with a binary variable equal to one if the audit firm is PwC, Ernst\n\n& Young, KPMG or Deloitte (Simunic 1980; Hay et al. 2006).<sup>4</sup> Last, we include not-for-profit sector fixed effects to control differences across not-for-profit organisations (e.g. Education vs Health).\n\nTable 2: Variable definitions  \n\n<table><tr><td>LnAF</td><td>The natural logarithm of reported audit fees</td></tr><tr><td>POST</td><td>A binary variable that takes the value of 1 if the annual report is for the period beginning on or after 1 January 2022, and 0 otherwise</td></tr><tr><td>ASI</td><td>A binary variable that takes the value of 1 if the SSP is assured using NZ AS 1, and 0 otherwise.</td></tr><tr><td>SSPOM</td><td>A binary variable that takes the value of 1 if there was an other matter noting that the comparative figures for the SSP were unaudited, and 0 otherwise.</td></tr><tr><td>LnTA</td><td>The natural logarithm of total assets.</td></tr><tr><td>ARINV</td><td>The ratio of accounts receivables and inventories to total assets.</td></tr><tr><td>TLTA</td><td>The ratio of total liabilities to total assets.</td></tr><tr><td>CASHTA</td><td>The ratio of cash to total assets</td></tr><tr><td>Donation s</td><td>The ratio of donations to total revenue</td></tr><tr><td>CityCost</td><td>A binary variable that takes the value of 1 if the audit was based in Auckland, and 0 otherwise</td></tr><tr><td>Loss</td><td>A binary variable that takes the value of 1 if total expenses are bigger than total revenue</td></tr><tr><td>Clean</td><td>A binary variable that takes the value of 1 if there is no modification or comments on the audit report (including other or emphasis of matter), and 0 otherwise</td></tr><tr><td>Big4</td><td>A binary variable that takes the value of 1 if the auditor is Deloitte, Ernst and Young, KPMG or PwC, and 0 otherwise.</td></tr><tr><td>ALag</td><td>The number of days between when the audit report is signed and the balance date</td></tr><tr><td>FLag</td><td>The number of days between when the annual report is filed with the Charites Register and the balance date</td></tr></table>\n\n# 4. RESULTS\n\nDescriptive Statistics\n\nTable 3 presents our sample statistics. By design our sample is evenly split pre- and post-SSP. In terms of our other variables of interest,  $72\\%$  of post-SSP observations use NZ AS 1 (36% of whole sample). Thus, a majority of not-for-profits are early adopters of the new auditing standard. It is also common (62% of post-SSP observations, 31% of whole\n\nsample) for the audit report to express an other matter paragraph that the prior year SSP figures are unaudited. It could be assumed that in all cases an other matter would be appropriate if they were unaudited as expressed by the local professional accounting body (CA ANZ, 2022). Thus, it is unknown if the remaining sample did not disclose an other matter or carried our more audit work to have the comparative figures audited – including potentially a readiness audit in the previous period. We focus on other matters as there are no cases of any other modification to the audit report in relation to the SSP, either qualified or emphasis of matter. Therefore, consistent with Xu and Yang (2023) who examine smaller NZ charities not following formal accounting standards, we provide descriptive evidence that the assurance of SSPs has not results in an increase cost to preparers in terms of a qualified audit report. Having an unqualified audit report is important to the not-for-profit sector as it can be a condition of grants and donations.\n\nThe mean audit fee of our sample of NZD$107,130. This is substantially larger than the mean of AUD$18,000 reported by Yang and Simnett (2022). This highlights that our sample not-for-profits are substantially larger, as per our focus on entities using IPSAS, and are less likely to have pro bono audits. Consistent with the larger size, is that mean total assets is NZD$240 million compared to $AUD21 million in Yang and Simnett (2022). As the criteria to be a Tier 1 entity is based on NZD$30 million total expenditure, some not-for-profits may have expenditure of that level but less assets if they mainly serve to redistribute funds in the year received. In terms of other variables, we note that 52% of the sample is audited by a Big 4 audit firm. This is less than the 79% of NZ listed companies (Grosse et al., 2023), and is driven by BDO having a relatively large market share of the NZ not-for-profit market. The market is also less concentrated in terms of location, with a CityCost of 52% vs 70% for NZ listed companies (Grosse et al., 2023). The low proportion of ‘clean’ audit opinions is driven by other matters relating to the SSP as discussed above. There are no qualified opinions issued in regard to the financial statements, although there are four emphasis-of-matters paragraphs relating to changing in accounting policy for measure land and buildings, provision for holiday pay remediation and provision for historical abuse. Also included are other matters unrelated to the SSP including six times the auditor changed.<sup>5</sup> Panel B presents our sample broken down into not-for-profit sectors. We use the highest level of sector as self-reported in the Charites Register. We find the\n\nlargest sector is the provision of accommodation services (39%), followed by education and health.\n\nTable 3: Sample statistics  \nPanel A: Descriptive statistics  \n\n<table><tr><td></td><td>Mean</td><td>Median</td><td>SD</td><td>P25</td><td>P75</td></tr><tr><td>AF</td><td>107,139</td><td>66,444</td><td>114,820</td><td>41,516</td><td>122,903</td></tr><tr><td>LnAF</td><td>11.21</td><td>11.10</td><td>0.81</td><td>10.63</td><td>11.72</td></tr><tr><td>POST</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>AS1</td><td>0.36</td><td>0.00</td><td>0.48</td><td>0.00</td><td>1.00</td></tr><tr><td>SSPOM</td><td>0.31</td><td>0.00</td><td>0.46</td><td>0.00</td><td>1.00</td></tr><tr><td>TA (000s)</td><td>240,396</td><td>78,470</td><td>419,621</td><td>28,660</td><td>221,670</td></tr><tr><td>LnTA</td><td>18.29</td><td>18.14</td><td>1.43</td><td>17.15</td><td>19.19</td></tr><tr><td>ARINV</td><td>0.44</td><td>0.00</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>TLTA</td><td>0.34</td><td>0.29</td><td>0.23</td><td>0.15</td><td>0.49</td></tr><tr><td>CASHTA</td><td>0.19</td><td>0.11</td><td>0.21</td><td>0.04</td><td>0.25</td></tr><tr><td>Donations</td><td>0.15</td><td>0.02</td><td>0.28</td><td>0.00</td><td>0.10</td></tr><tr><td>CityCost</td><td>0.52</td><td>1.00</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>Loss</td><td>0.20</td><td>0.00</td><td>0.40</td><td>0.00</td><td>0.00</td></tr><tr><td>Clean</td><td>0.37</td><td>0.00</td><td>0.48</td><td>0.00</td><td>1.00</td></tr><tr><td>Big4</td><td>0.52</td><td>1.00</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>ALag</td><td>135</td><td>126</td><td>47</td><td>100</td><td>160</td></tr><tr><td>FLag</td><td>171</td><td>170</td><td>38</td><td>151</td><td>179</td></tr></table>\n\nPanel B: Sector distribution  \n\n<table><tr><td>Sector</td><td>N</td><td>Percentage</td></tr><tr><td>Accommodation</td><td>48</td><td>39</td></tr><tr><td>Arts</td><td>10</td><td>8</td></tr><tr><td>Community</td><td>14</td><td>11</td></tr><tr><td>Education</td><td>28</td><td>23</td></tr><tr><td>Health</td><td>24</td><td>19</td></tr><tr><td>Total</td><td>124</td><td>100</td></tr></table>\n\nTable 3 presents descriptive statistics for sample variables. Variables are as defined in Table 2.\n\n# Audit Fees and SSPs\n\nTable 4 presents the results of audit fee regressions. Our models have an adjusted  $\\mathbf{R}^2$  of  $69\\%$ , just below the lower end of a range that audit fee research normally achieves (Hay, 2013). We first run the regression focusing on the effect of introduction SSP reporting and assurance (POST) after controlling for other factors. Consistent with our first hypothesis, we find significantly higher audit fees post-SSP. Furthermore, the effect is large with an increase in audit fees of  $14.5\\%$ . This compares with an  $11\\%$  increase in audit fees for the first year of IFRS adoption in NZ (Higgins et al., 2016), suggesting that the transition to requiring SSP reporting, and the increase in assurance is greater than the shift to IFRS. This may be due to a greater degree new work involved with auditing a new statement rather than the wholesale change of accounting standards, such as the preparation of new working papers, templates, materiality estimates etc. Our control variables are broadly consistent with prior literature, with higher audit fees for larger (LnTA), riskier not-for-profits (TLTA and Donations), and those audited by a Big 4 audit firm. However, in contrast to Yang and Simnett (2022) we find a negative association for Loss. As we examine larger more stable not-for-profits, those that a small loss may be viewed as less risky by auditors as the purpose of not-for-profits is to distribute funds for their charitable purpose rather than hoard cash.\n\nNext, in columns (2)-(4), we include our variables to test H2, namely AS1, SSPOM and POST_Big4 one at a time. Across all columns we find consistent evidence that POST remains significantly positive, consistent with our main results. However, there is no difference in the fees for those not-for-profits that adopted AS 1, expressed an other matter or used a Big 4 audit firm. We conclude that the early adopters of NZ AS 1 do not bear the learning costs, or that it is offset by greater alignment of auditing standard with the subject matter. The expression of an other matter may not reduce audit fees as it could be assumed by many users that the comparative figure was unaudited, or other matters are not viewed at mitigating audit risk. For Big 4 firms, while we do find that they have higher audit fees, this relationship has not changed post-SSP. Thus the Big 4 do not have a further premium in regard to non-financial assurance. In untabulated tests, our results are robust to including non-audit fees, excluding sector fixed effects, excluding all control variables, or one at a\n\ntime, and including different controls (e.g. return on assets, current ratio, total expense etc). Overall, we find evidence of a market wide increase audit fees that does not vary with auditing standard, audit report issued, or auditor.\n\nTable 4: Audit fees and SSP  \n\n<table><tr><td></td><td>(1) LnAF</td><td>(2) LnAF</td><td>(3) LnAF</td><td>(4) LnAF</td></tr><tr><td>POST</td><td>0.271**</td><td>0.260**</td><td>0.198*</td><td>0.239**</td></tr><tr><td></td><td>(2.50)</td><td>(2.10)</td><td>(1.65)</td><td>(2.05)</td></tr><tr><td>AS1</td><td></td><td>0.016</td><td></td><td></td></tr><tr><td></td><td></td><td>(0.14)</td><td></td><td></td></tr><tr><td>SSPOM</td><td></td><td></td><td>0.307</td><td></td></tr><tr><td></td><td></td><td></td><td>(1.17)</td><td></td></tr><tr><td>POST_Big4</td><td></td><td></td><td></td><td>0.072</td></tr><tr><td></td><td></td><td></td><td></td><td>(0.41)</td></tr><tr><td>LnTA</td><td>0.433***</td><td>0.432***</td><td>0.444***</td><td>0.434***</td></tr><tr><td></td><td>(7.00)</td><td>(6.88)</td><td>(6.98)</td><td>(7.03)</td></tr><tr><td>ARINV</td><td>-0.048</td><td>-0.048</td><td>-0.073</td><td>-0.047</td></tr><tr><td></td><td>(-0.54)</td><td>(-0.54)</td><td>(-0.82)</td><td>(-0.53)</td></tr><tr><td>TLTA</td><td>0.625**</td><td>0.624**</td><td>0.652**</td><td>0.627**</td></tr><tr><td></td><td>(2.22)</td><td>(2.19)</td><td>(2.22)</td><td>(2.22)</td></tr><tr><td>CASHTA</td><td>0.418</td><td>0.418</td><td>0.438</td><td>0.424</td></tr><tr><td></td><td>(1.57)</td><td>(1.56)</td><td>(1.62)</td><td>(1.58)</td></tr><tr><td>Donations</td><td>-0.404***</td><td>-0.406***</td><td>-0.405***</td><td>-0.404***</td></tr><tr><td></td><td>(-2.78)</td><td>(-2.75)</td><td>(-2.81)</td><td>(-2.77)</td></tr><tr><td>CityCost</td><td>0.120</td><td>0.119</td><td>0.116</td><td>0.119</td></tr><tr><td></td><td>(1.23)</td><td>(1.23)</td><td>(1.19)</td><td>(1.22)</td></tr><tr><td>Loss</td><td>-0.206*</td><td>-0.208*</td><td>-0.207**</td><td>-0.205*</td></tr><tr><td></td><td>(-1.95)</td><td>(-1.90)</td><td>(-2.03)</td><td>(-1.94)</td></tr><tr><td>Clean</td><td>-0.073</td><td>-0.074</td><td>-0.292</td><td>-0.083</td></tr><tr><td></td><td>(-0.65)</td><td>(-0.66)</td><td>(-1.23)</td><td>(-0.70)</td></tr><tr><td>Big4</td><td>0.516***</td><td>0.514***</td><td>0.500***</td><td>0.481***</td></tr><tr><td></td><td>(5.95)</td><td>(5.92)</td><td>(5.69)</td><td>(3.91)</td></tr><tr><td>Observations</td><td>124</td><td>124</td><td>124</td><td>124</td></tr><tr><td>Adjusted R2</td><td>0.692</td><td>0.689</td><td>0.695</td><td>0.689</td></tr><tr><td>Sector FE</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr></table>\n\nTable 4 presents ordinary least square regression results on the natural logarithm of audit fees (LnAF). Other variables are defined in Table 2. Two-tailed test of significance are reported. *** = less than 0.01, ** = less than 0.05, and * = less than 0.1.\n\n# Audit Lag and SSPs\n\nTo provide further evidence on the cost of the SSP reporting and assurance we next examine audit lag. Prior research has shown that audit lag, i.e., the length of time between the end of the financial period and the auditor signing off on the audit report is a proxy for\n\nunexpected audit effort (Knechel and Payne 2001; Knechel et al. 2009; Tanyi et al. 2010). Following Mayapada et al. (2023), we examine both the audit lag and filing lag, which is the length of time between the end of the financial period and when the annual report is recorded was being filed with the Charities Register. NZ charities must file their audited annual report within six months.\n\nTable 5 Panel A, and Panel B provide no support for an increase in audit lag or filing lag post-SSP. This contrasts with Mayapada et al. (2023) who finds an increase in both filing and audit lag when moving towards more detailed and prescriptive statements of recommended practice for UK not-for-profits. One reason for this difference is that the transition to SSP reporting assurance in NZ began with smaller not-for-profits and only applied to the Tier 1 entities in our sample almost seven years later. Thus, as the transition to SSP reporting was known well in advance, we find that it was an increase in expected, but not unexpected audit effort. The results found in Mayapada et al. (2023) may be driven by the change in UK guidance being known less than a year in advance. We conclude that the costs of changing accounting guidance can be minimised by providing a greater period of notice before adoption.\n\nAudit and filing lags also do not vary with assurance standard used, the expression of an other matter or the use of a Big 4 audit firm. This provides further support for our audit fee results that there was no difference in the cost of SSP based on these issues. In terms of control variables, we find that not-for-profits with a greater proportion of donations have a longer lag, while those with a higher percentage of assets in cash have a shorter lag. We infer that donations are relatively more risky to audit, while cash is less so. We also find that the Big 4 have short lags, suggesting that complete their audits in a timelier fashion, consistent with the higher audit fee charged. We find no control variables are significant in the filing lag regression, suggesting that client and auditor characteristics do not drive the filing decision. Despite this, our models appear to be relatively good fits with a higher Adjusted  $\\mathbb{R}^2$  for both audit and filing lags than Mayapada et al. (2023). Our main inferences are also unchanged when we use other measures of logged or change in lag.\n\nTable 5: Lag and SSP  \nPanel A: Audit lag  \n\n<table><tr><td></td><td>(1) ALag</td><td>(2) ALag</td><td>(3) ALag</td><td>(4) ALag</td></tr><tr><td rowspan=\"2\">POST</td><td>-9.356</td><td>-8.745</td><td>3.223</td><td>-2.909</td></tr><tr><td>(-0.71)</td><td>(-0.54)</td><td>(0.29)</td><td>(-0.19)</td></tr><tr><td rowspan=\"2\">AS1</td><td></td><td>-0.901</td><td></td><td></td></tr><tr><td></td><td>(-0.07)</td><td></td><td></td></tr><tr><td>SSPOM</td><td></td><td></td><td>-52.628 (-1.58)</td><td></td></tr><tr><td>POST/big4</td><td></td><td></td><td></td><td>-14.366 (-0.86)</td></tr><tr><td rowspan=\"2\">LnTA</td><td>-6.813</td><td>-6.787</td><td>-8.742</td><td>-6.975</td></tr><tr><td>(-1.19)</td><td>(-1.17)</td><td>(-1.54)</td><td colspan=\"1\">(-1.21)</td></tr><tr><td rowspan=\"2\">ARINV</td><td>13.772</td><td>13.796</td><td>18.039**</td><td>13.698</td></tr><tr><td>(1.62)</td><td>(1.62)</td><td>(2.22)</td><td colspan=\"1\">(1.62)</td></tr><tr><td rowspan=\"2\">TLTA</td><td>11.643</td><td>11.720</td><td>7.001</td><td>11.325</td></tr><tr><td>(0.55)</td><td>(0.55)</td><td>(0.33)</td><td colspan=\"1\">(0.53)</td></tr><tr><td rowspan=\"2\">CASHTA</td><td>-57.978**</td><td>-57.968**</td><td>-61.485**</td><td>-59.179**</td></tr><tr><td>(-2.43)</td><td>(-2.42)</td><td>(-2.60)</td><td colspan=\"1\">(-2.54)</td></tr><tr><td rowspan=\"2\">Donations</td><td>32.522**</td><td>32.639**</td><td>32.662**</td><td>32.567**</td></tr><tr><td>(2.46)</td><td>(2.47)</td><td>(2.51)</td><td colspan=\"1\">(2.52)</td></tr><tr><td rowspan=\"2\">CityCost</td><td>12.248</td><td>12.290</td><td>12.870</td><td>12.416</td></tr><tr><td>(1.35)</td><td>(1.35)</td><td>(1.44)</td><td colspan=\"1\">(1.36)</td></tr><tr><td rowspan=\"2\">Loss</td><td>-6.017</td><td>-5.892</td><td>-5.771</td><td>-6.080</td></tr><tr><td>(-0.65)</td><td>(-0.61)</td><td>(-0.64)</td><td colspan=\"1\">(-0.65)</td></tr><tr><td rowspan=\"2\">Clean</td><td>10.441</td><td>10.499</td><td>47.971</td><td>12.511</td></tr><tr><td>(0.74)</td><td>(0.74)</td><td>(1.45)</td><td colspan=\"1\">(0.86)</td></tr><tr><td rowspan=\"2\">Big4</td><td>-19.827**</td><td>-19.763**</td><td>-17.117*</td><td>-12.804</td></tr><tr><td>(-2.12)</td><td>(-2.09)</td><td>(-1.83)</td><td colspan=\"1\">(-0.89)</td></tr><tr><td>Observations</td><td>124</td><td>124</td><td>124</td><td>124</td></tr><tr><td>Adjusted R²</td><td>0.116</td><td>0.108</td><td>0.156</td><td>0.114</td></tr><tr><td>Sector FE</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr></table>\n\nPanel B: Filing lag  \n\n<table><tr><td></td><td>(1) FLag</td><td>(2) FLag</td><td>(3) FLag</td><td>(4) FLag</td></tr><tr><td>POST</td><td>-9.523(-0.84)</td><td>-16.669(-1.33)</td><td>-1.854(-0.16)</td><td>-4.092(-0.30)</td></tr><tr><td>POST_AS1</td><td></td><td>10.526(0.96)</td><td></td><td></td></tr><tr><td>POST_SSPOM</td><td></td><td></td><td>-32.084(-1.12)</td><td></td></tr><tr><td>POST BIG4</td><td></td><td></td><td></td><td>-12.102(-0.92)</td></tr><tr><td>LnTA</td><td>-1.164(-0.24)</td><td>-1.472(-0.30)</td><td>-2.339(-0.48)</td><td>-1.300(-0.27)</td></tr><tr><td>ARINV</td><td>9.064(1.18)</td><td>8.790(1.13)</td><td>11.665(1.52)</td><td>9.001(1.17)</td></tr><tr><td>TLTA</td><td>-3.264(-0.17)</td><td>-4.160(-0.22)</td><td>-6.095(-0.32)</td><td>-3.532(-0.18)</td></tr><tr><td>CASHTA</td><td>-24.870(-1.15)</td><td>-24.992(-1.16)</td><td>-27.008(-1.24)</td><td>-25.881(-1.20)</td></tr><tr><td>Donations</td><td>6.310(0.65)</td><td>4.938(0.52)</td><td>6.396(0.66)</td><td>6.349(0.66)</td></tr><tr><td>CityCost</td><td>-0.398(-0.05)</td><td>-0.891(-0.11)</td><td>-0.018(-0.00)</td><td>-0.256(-0.03)</td></tr><tr><td>Loss</td><td>0.051(0.01)</td><td>-1.404(-0.15)</td><td>0.200(0.02)</td><td>-0.002(-0.00)</td></tr><tr><td>Clean</td><td>10.743(0.88)</td><td>10.064(0.82)</td><td>33.623(1.23)</td><td>12.486(1.04)</td></tr><tr><td>Big4</td><td>-10.430(-1.21)</td><td>-11.168(-1.26)</td><td>-8.778(-1.04)</td><td>-4.514(-0.39)</td></tr><tr><td>Observations</td><td>124</td><td>124</td><td>124</td><td>124</td></tr><tr><td>Adjusted \\( R^2 \\)</td><td>0.096</td><td>0.103</td><td>0.120</td><td>0.102</td></tr><tr><td>Sector FE</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr></table>\n\nTable 5 presents ordinary least square regression results on the audit lag (ALag) in Panel A and the filing lag (FLag) in Panel B. Other variables are defined in Table 2. Two-tailed test of significance are reported. *** = less than 0.01, ** = less than 0.05, and * = less than 0.1.\n\n# 5. CONCLUSION\n\nThis study examines whether requiring the reporting and assurance of service performance information is associated with an increase in audit effort. Using a sample of NZ Tier 1 not-for-profit entities, who are required to following IPSAS and be audited, we find a large increase in audit fees post-SSP. There is no difference in the audit or filling lag post-SSP, suggesting that the increase in effort was not unexpected. There also are no differences based on the auditing standard used, whether an other matter expressed or depending on what audit firm is used. This study adds to the both the broader literature on the economic costs of requiring more complex accounting, with a particular contribution to emerging areas in non-financial reporting. Despite the importance of service performance reporting, this study is the first to investigate the economic costs of requiring its reporting and assurance and one of the first to investigate the cost of non-financial reporting. As we find the increase in audit fees is greater than the cost of adopting IFRS in NZ for listed companies, we provide evidence that the magnitude of increased audit effort for requiring SSPs to be audited should be framed as greater than adopting IFRS. We infer results would be similar for requiring the reporting and assurance of other non-financial reporting, including integrated or sustainability reporting. Thus, we provide direct of the cost to regulators and policymakers in assessing the impact of the requiring these changes, supplementing evidence showing an improvement in usefulness (Tseng et al., 2023). Our results also provide insight about how to manage the transition to new, more complex standards. As we find no increase in audit or filing lag in our setting, our results confirm the suggestion from Mayapada et al. (2023) that a that greater notice before adoption may reduce costs for new and complex standards.\n\nFurthermore, this study contributes to the emerging not-for-profit auditing literature by providing additional audit fee and market structure evidence from NZ. In contrast, to other jurisdictions studied, Tier 1 NZ entities must follow full IPSAS and be audited under International Auditing Standards (NZ). We confirm the audit fee models used in other\n\nsettings and provide further evidence of a Big 4 fee premium in this market. The NZ setting in provides evidence of interest to global standard setters due to its early adoption of SSP reporting for not-for-profits, following its longstanding use in the public sector, and calls for further reporting in this area and sustainability reporting. A potential limitation of our study is the small sample size inherent in using New Zealand data which reduces our ability to conduct further statistical robustness tests. Future study is likely needed, to examine the longer-term effects including on the quality of reporting.\n\n# REFERENCES\n\nAASB. 2021. AASB agenda consultation 2022-2026, available at: https://aasb.gov.au/admin/file/content105/c9/ITC46_10-21.pdf  \nAl-mulla, M., and M. Bradbury. 2022. Auditor, client and investor consequences of the enhanced auditor's report. International Journal of Auditing 26 (2):134-150.  \nBradbury, M., and T. Scott. 2020. What accounting standards were the cause of enforcement actions following IFRS adoption? Accounting & Finance 61 (S1): 2247-2268.  \nCA ANZ. 2022. Larger New Zealand charities - are you ready to report service performance information? available at: https://www.charteredaccountantsanz.com/news-and-analysis/news/larger-new-zealand-charities  \nCausholli, M., M. De Martinis, D. Hay, and W. R. Knechel. 2010. Audit markets, fees and production: Towards an integrated view of empirical audit research. Journal of Accounting Literature 29:167-215.  \nChan, P., M. Ezzamel, and D. Gwilliam. 1993. Determinants of audit fees for quoted UK companies. Journal of Business Finance & Accounting 20 (6):765-786.  \nConnolly, C. and N. Hyndman. 2013. Towards charity accountability: narrowing the gap between provision and needs? *Public Management Review* 15(7): 945-968.  \nCordery, C. & Deguchi, M. 2018. Charity registration and reporting: a cross-jurisdictional and theoretical analysis of regulatory impact. *Public Management Review*, 20(9), 1332–1352.  \nDe George, E. T., C. B. Ferguson, and N. A. Spear. 2013. How much does IFRS cost? IFRS adoption and audit fees. The Accounting Review 88 (2):429-462.  \nde Villiers, C., Hsiao, P.-C.K., Zambon, S. and Magnaghi, E. (2022a), “Sustainability, non-financial, integrated, and value reporting (extended external reporting): a conceptual framework and an agenda for future research”, Meditari Accountancy Research, Vol. 30 No. 3, pp. 453-471.  \nDeFond, M., and J. Zhang. 2014. A review of archival auditing research. Journal of Accounting and Economics 58 (2):275-326.  \nDickins, D. E., J. L. Higgs, and T. R. Skantz. 2008. Estimating audit fees post-SOX. Current Issues in Auditing 2 (1):A9-A18.\n\nDoogar, R., P. Sivadasan, and I. Solomon. 2010. The regulation of public company auditing: Evidence from the transition to AS5. Journal of Accounting Research 48 (4):795-814.  \nEierle, B., S. Hartlieb, D. C. Hay, L. Niemi, and H. Ojala. 2022. External factors and the pricing of audit services: A systematic review of the archival literature using a PESTLE analysis. Auditing: A Journal of Practice & Theory 41 (3):95-119.  \nFarooq, M. B., and C. De Villiers, 2017. The market for sustainability assurance services: A comprehensive review of the literature and future avenues for research. Pacific Accounting Review 29(1): 79-106.  \nGarcia, J., C. de Villiers, and L. Li. 2021. Is a client's corporate social responsibility performance a source of audit complexity? International Journal of Auditing 25(1): 75-102.  \nGhosh, A., and R. Pawlewicz, 2009, The impact of regulation on auditor fees: evidence from the Sarbanes-Oxley Act, Auditing: A Journal of Practice and Theory 28: 171-197.  \nGriffin, P. A., and Lont, D. H. 2007. An analysis of audit fees following the passage of Sarbanes-Oxley. *Asia-Pacific Journal of Accounting & Economics* 14: 161-192.  \nGriffin, P. A., D. H. Lont, and Y. Sun. 2009. Governance regulatory changes, International Financial Reporting Standards adoption, and New Zealand audit and non-audit fees: empirical evidence. Accounting & Finance 49 (4):697-724.  \nGrosse, M., T. Scott, and Z. Zang. 2023. Aligning disclosure requirements for managerial assessments of going concern risk: Initial evidence from New Zealand. Accounting & Finance.  \nHay, D. 2013. Further evidence from meta-analysis of audit fee research. International Journal of Auditing 17 (2):162-176.  \nHay, D. C., W. R. Knechel, and N. Wong. 2006. Audit fees: A meta-analysis of the effect of supply and demand attributes. Contemporary Accounting Research 23 (1):141-191.  \nHiggins, S., D. Lont, and T. Scott. 2016. Longer term audit costs of IFRS and the differential impact of implied auditor cost structures. Accounting & Finance 56 (1):165-203.\n\nHsiao, P.-C.K., Low, M. and Scott, T. 2023. Service performance reporting and principles-based authoritative guidance: an analysis of New Zealand higher education institutions. Meditari Accountancy Research.  \nIPSASB. 2015. Recommended practice guideline: reporting service performance information, IPSASB, New York, NY.  \nIPSASB. 2022. Advancing public sector sustainability reporting, IPSASB, New York, NY.  \nJohansson, E., P., Carey, G., Tanewski and I. Yusoff. 2022. The effect of members on charities' annual reporting: evidence from companies limited by guarantee in Australia. Accounting & Finance 62: 1851-1886.  \nKim, J.-B., X. Liu, and L. Zheng. 2012. The impact of mandatory IFRS adoption on audit fees: Theory and evidence. *The Accounting Review* 87 (6):2061-2094.  \nKnechel, W. R., and J. L. Payne. 2001. Additional evidence on audit report lag. Auditing: A Journal of Practice & Theory 20 (1):137-146.  \nKnechel, W. R., P. Rouse, and C. Schelleman. 2009. A modified audit production framework: Evaluating the relative efficiency of audit engagements. The Accounting Review 84 (5):1607-1638.  \nKrishnan, J., J. Krishnan, and H. Song. 2011. The effect of Auditing Standard No. 5 on audit fees. Auditing: A Journal of Practice & Theory 30 (4):1-27.  \nLu, M., R., Wang, A., Wu, and S. Zhou. 2023. Integrated Reporting, Audit Quality and Audit Fees. https://ssrn.com/abstract=4600887  \nMcConville, D. and C. Cordery. 2018. Charity performance reporting, regulatory approaches and standard-setting. Journal of Accounting and Public Policy 37 (4): 300-314.  \nMayapada, A., P. Biswas, and H. Roberts. 2023. Economic consequences of new accounting standards in UK charities. Accounting & Finance.  \nScott, J. and Pinny J. 2016. A new PBE Standard on Service Performance Reporting is on the horizon. Available at https://www.charteredaccountantsanz.com  \nSimunic, D. A. 1980. The pricing of audit services: Theory and evidence. Journal of Accounting Research 18 (1):161-190.  \nTanyi, P., K. Raghunandan, and A. Barua. 2010. Audit report lags after voluntary and involuntary auditor changes. Accounting Horizons 24 (4):671-688.\n\nTseng, Y-J., C. Yang and A. Habib. 2023. The impact of differentiated regulation on the accuracy and usefulness of financial reporting for charities: Evidence from New Zealand. Auckland Region Accounting Conference.  \nVermeer, T., K. Raghunandan, and D. Forgione. 2009 Audit Fees at U.S. Non-Profit Organizations. Auditing: A Journal of Practice & Theory 28 (2): 289-303.  \nXRB. 2017. PBE FRS 48 service performance reporting, XRB, Wellington.  \nXRB. 2019. New Xealand Auditing Standard 1 the Audit of Service Performance Information: Explanation of Decisions made, XRB, Wellington.  \nXu., G., and C. Yang. 2023. Service performance assurance for small charities: Experiences from New Zealand. International Journal of Auditing 27 (4): 190-207.  \nYang, Y., and R. Simnett., 2022. Determinants and Consequences of Audit Pricing for Charities, Including the Provision of Pro Bono Audits. *Auditing: A Journal of Practice* & Theory 42 (1): 183-210.  \nYao, D. F., M. Percy, and F. Hu. 2015. Fair value accounting for non-current assets and audit fees: evidence from Australian companies. Journal of Contemporary Accounting and Economics 11, 31-45.\n\n# Appendix A\n\n![](/uploads/images/87710e08-8ea7-4cce-86e6-24aaf2c7e7dd/6ab8abcd5b5ce12ab6291184998d2ecf6a63f7211f4d908401ab440e8c6f4d12.jpg)  \nFigure 1: Extract of audit report  \nBuilding a better working world\n\nIndependent auditor's report to the Territorial Commander and Chief Secretary of The Salvation Army New Zealand\n\n# Opinion\n\nWe have audited the general purpose financial report (the \"performance report\") of The Salvation Army New Zealand (\"the Army\") on pages 2 to 25, which comprises the service performance information, the consolidated statement of financial position of the Army as at 30 June 2023, and the consolidated statement of financial performance, consolidated statement of comprehensive income, consolidated statement of changes in equity and consolidated statement of cash flows for the year then ended of the Army, and the notes to the consolidated financial statements including a summary of significant accounting policies.\n\nIn our opinion, the performance report presents fairly, in all material respects;\n\nthe consolidated financial position of the Army as at 30 June 2023 and its consolidated financial performance and cash flows for the year then ended  \n- the service performance for the year then ended 30 June 2023 in accordance with the Army's service performance criteria\n\nin accordance with Public Benefit Entity Standards issued by the New Zealand Accounting Standards Board.\n\nThis report is made solely to the Territorial Commander and Chief Secretary of the Army, as attorneys for the General of the Army. Our audit has been undertaken so that we might state to the Territorial Commander and Chief Secretary of the Army those matters we are required to state to them in an auditor's report and for no other purpose. To the fullest extent permitted by law, we do not accept or assume responsibility to anyone other than the Army and the Territorial Commander and Chief Secretary of the Army as attorneys for the General of the Army, for our audit work, for this report, or for the opinions we have formed.\n\n# Basis for opinion\n\nWe conducted our audit of the consolidated financial statements in accordance with International Standards on Auditing (New Zealand) and the audit of the service performance information in accordance with NZ AS 1 The Audit of Service Performance Information (\"NZ AS 1\"). Our responsibilities under those standards are further described in the Auditor's Responsibilities for the Audit of the performance report section of our report.\n\nWe are independent of the Army in accordance with Professional and Ethical Standard 1 International Code of Ethics for Assurance Practitioners (including International Independence Standards (New Zealand) issued by the New Zealand Auditing and Assurance Standards Board, and we have fulfilled our other ethical responsibilities in accordance with these requirements.\n\nWe believe that the audit evidence we have obtained is sufficient and appropriate to provide a basis for our opinion.",
    "arxiv_id": null,
    "error_message": null,
    "embedding": [
      -4.0625,
      -0.038818359375,
      -3.078125,
      -4.3125,
      -1.2578125,
      2.25,
      -1.703125,
      -0.1259765625,
      3.046875,
      2.734375,
      3.21875,
      1.359375,
      1.9765625,
      1.1171875,
      0.494140625,
      0.83203125,
      0.228515625,
      2.6875,
      -0.7734375,
      -6.1875,
      0.63671875,
      2.703125,
      1.34375,
      -5.03125,
      1.2265625,
      -2.28125,
      0.84765625,
      2.6875,
      2.453125,
      2.828125,
      5.625,
      -3.96875,
      -1.8671875,
      -0.333984375,
      1.3828125,
      -2.140625,
      -0.60546875,
      -4.21875,
      0.76171875,
      5.625,
      -6.40625,
      1.484375,
      -1.5078125,
      0.6015625,
      -4.8125,
      0.34375,
      -0.7890625,
      -0.498046875,
      -5.0625,
      -3.640625,
      -3.046875,
      -0.4765625,
      7.125,
      -1.6796875,
      5.46875,
      -7.3125,
      -2.65625,
      6.59375,
      -8.875,
      -3.53125,
      3.96875,
      -1.75,
      3.953125,
      1.7578125,
      0.48046875,
      4.5625,
      1.3828125,
      -0.4609375,
      -2.15625,
      -2.796875,
      -2.140625,
      3.09375,
      6.9375,
      -3.421875,
      7.125,
      6.25,
      2.859375,
      2.046875,
      -1.3125,
      2.390625,
      -6.1875,
      1.703125,
      6.34375,
      -0.8359375,
      6.65625,
      0.1943359375,
      2.546875,
      -0.5625,
      -1.2734375,
      0.89453125,
      -0.486328125,
      2.859375,
      -4.46875,
      -0.921875,
      1.09375,
      4.625,
      0.03369140625,
      -3.03125,
      -4.625,
      3,
      -1.8046875,
      -1.3359375,
      2.1875,
      -6.875,
      -2.484375,
      -0.8515625,
      -2.359375,
      -6.4375,
      -3.890625,
      -0.9921875,
      1.078125,
      0.146484375,
      1.171875,
      0.91796875,
      3.671875,
      -2.6875,
      2.09375,
      -2.953125,
      -5.4375,
      -0.515625,
      1.3203125,
      -1.8984375,
      -0.16796875,
      -1.5,
      1.25,
      2.0625,
      -2.28125,
      2.625,
      6.125,
      2.859375,
      2.5,
      0.7578125,
      5.15625,
      -1.28125,
      -6.3125,
      -1.03125,
      1.4609375,
      1.203125,
      1.96875,
      5.25,
      -6.78125,
      -0.515625,
      -5.0625,
      -3.75,
      1.3125,
      -0.2431640625,
      -6.3125,
      1.4453125,
      0.53515625,
      -2.03125,
      0.248046875,
      3.0625,
      5.0625,
      -1.2734375,
      -2.140625,
      -4.75,
      1.890625,
      2.453125,
      -0.08349609375,
      -1.828125,
      -0.26171875,
      1.5390625,
      1.9453125,
      -0.33203125,
      0.50390625,
      -0.671875,
      -1.0078125,
      -0.119140625,
      1.484375,
      1.59375,
      2.40625,
      15,
      0.3203125,
      -2.765625,
      0.80859375,
      6,
      -3.96875,
      5.09375,
      4.3125,
      2.4375,
      -0.369140625,
      0.96484375,
      -4.6875,
      3.125,
      1.921875,
      1.484375,
      2.15625,
      -0.111328125,
      0.98046875,
      1.171875,
      -0.48828125,
      0.96484375,
      5.28125,
      -0.515625,
      -6,
      -2.703125,
      2.078125,
      1.2421875,
      -1.0703125,
      -1.7109375,
      -3.453125,
      -9.0625,
      0.6484375,
      -2.4375,
      -1.0703125,
      -2.171875,
      -0.138671875,
      -1.921875,
      0.337890625,
      -1.4140625,
      3.03125,
      0.99609375,
      2.703125,
      -3.328125,
      4.34375,
      1.046875,
      5.0625,
      1.5078125,
      5.5625,
      1.1015625,
      4.28125,
      1.6640625,
      0.09912109375,
      -1.109375,
      -3.1875,
      -0.50390625,
      4.4375,
      6.59375,
      1.25,
      11.375,
      0.5078125,
      0.439453125,
      2.8125,
      0.55078125,
      -2.078125,
      -1.53125,
      -6.875,
      1.671875,
      0.7890625,
      -0.80859375,
      -3.421875,
      -3.546875,
      -1.3359375,
      1.3828125,
      0.48046875,
      -2.125,
      -2.59375,
      -4.625,
      -2.34375,
      -6.84375,
      -0.5859375,
      3.03125,
      -6.28125,
      0.255859375,
      7.375,
      7.125,
      -1.8359375,
      0.314453125,
      -2.15625,
      -1.0078125,
      1.3125,
      -4.75,
      -5.9375,
      2.953125,
      2.390625,
      -1.0546875,
      0.330078125,
      -1.3515625,
      -0.625,
      2.171875,
      4.59375,
      0.53515625,
      -1.6328125,
      -1.9375,
      -2.40625,
      4.03125,
      0.515625,
      -2.625,
      0.11376953125,
      -5.03125,
      -3.703125,
      -8.6875,
      2.28125,
      -5.96875,
      4.59375,
      -2.140625,
      -0.19921875,
      4.15625,
      -0.298828125,
      10.4375,
      3.484375,
      1.421875,
      -0.47265625,
      0.2236328125,
      -1.5546875,
      0.029052734375,
      -4.875,
      -1.3828125,
      -8.8125,
      -2.515625,
      3.96875,
      2.875,
      -1.09375,
      0.06494140625,
      -2.125,
      3.5625,
      -0.9765625,
      -3.828125,
      2.875,
      1.78125,
      -0.68359375,
      -0.9140625,
      4.21875,
      -3.03125,
      2.9375,
      -4.28125,
      -2.5625,
      2.671875,
      2.15625,
      -1.171875,
      -3.296875,
      -2.75,
      -1.5078125,
      -7.375,
      -0.30078125,
      -0.640625,
      3.765625,
      -0.98828125,
      7.21875,
      -0.2294921875,
      2.0625,
      0.734375,
      -5.28125,
      -6.78125,
      8.9375,
      -1.390625,
      3.03125,
      5.03125,
      4.71875,
      3.78125,
      -2.359375,
      -1.453125,
      2.140625,
      -0.392578125,
      -0.08740234375,
      -0.82421875,
      5.25,
      -4.375,
      0.08544921875,
      -3.484375,
      -0.35546875,
      -0.60546875,
      1.546875,
      5.59375,
      7.53125,
      1.671875,
      1.359375,
      2.9375,
      0.95703125,
      -0.359375,
      2.828125,
      -3.140625,
      8.5625,
      5.40625,
      -1.484375,
      -4.125,
      -2.6875,
      4.8125,
      -1.3125,
      4.46875,
      0.59765625,
      -3.8125,
      2.03125,
      -0.6171875,
      -0.322265625,
      1.7890625,
      -0.224609375,
      -5.375,
      -6.8125,
      0.2421875,
      -5.34375,
      1.8125,
      -0.365234375,
      0.48828125,
      0.62890625,
      -0.2138671875,
      -2.3125,
      -0.5078125,
      1.171875,
      -4.28125,
      1.78125,
      -3.78125,
      -1.1171875,
      -3.96875,
      7.625,
      0.205078125,
      2.140625,
      2.421875,
      -2.1875,
      -0.193359375,
      2.609375,
      1.0703125,
      -0.2158203125,
      -3,
      -0.65234375,
      4.75,
      -0.177734375,
      -4.71875,
      3.0625,
      1.9921875,
      -2.359375,
      2.3125,
      0.9609375,
      -0.7421875,
      -2.53125,
      3.890625,
      0.30859375,
      6.75,
      -6.3125,
      -0.73046875,
      -5.9375,
      2.59375,
      4.625,
      -1.1328125,
      -0.9375,
      1.9296875,
      -0.96875,
      2.546875,
      -1.2578125,
      0.96484375,
      5.8125,
      -0.25,
      -3.5,
      2.5,
      -1.328125,
      -3.09375,
      3.59375,
      -2.453125,
      -1.7890625,
      0.453125,
      4.96875,
      -2.890625,
      5.5,
      5.1875,
      -6.25,
      -3.359375,
      -1.0390625,
      6.1875,
      -5.40625,
      -3.15625,
      -1.375,
      0.6953125,
      -5.5625,
      2.96875,
      -1.4765625,
      2.171875,
      -6.3125,
      5.4375,
      6.90625,
      -1.6015625,
      1.359375,
      -2.25,
      0.6640625,
      1.9140625,
      1.4921875,
      -3.34375,
      0.140625,
      0.6484375,
      6.875,
      -2.609375,
      -10.625,
      1.9765625,
      0.150390625,
      4.28125,
      -3.578125,
      4.40625,
      -3.640625,
      1.265625,
      -6,
      -0.65234375,
      1.9375,
      -2.96875,
      3.84375,
      2.796875,
      -4.65625,
      -4.96875,
      -0.80859375,
      6.78125,
      -1.4765625,
      2.5,
      -2.25,
      -0.4296875,
      0.6484375,
      -2.25,
      3.25,
      2.4375,
      5.875,
      -2.375,
      -0.421875,
      1.7734375,
      -7.5625,
      3.203125,
      -5.5625,
      -0.0556640625,
      -1.0234375,
      1.640625,
      2.859375,
      -2.875,
      -0.94140625,
      -2.53125,
      3.453125,
      -5.96875,
      -0.400390625,
      0.6640625,
      -4.40625,
      -3.96875,
      0.9375,
      -0.56640625,
      2.234375,
      -2.125,
      -3.015625,
      2.234375,
      1.7109375,
      2.171875,
      0.66015625,
      -2.5625,
      -2.8125,
      -5.4375,
      -0.318359375,
      4.1875,
      2.5625,
      1.0859375,
      -1.0234375,
      -4.40625,
      -3.1875,
      -5.1875,
      0.9375,
      0.9140625,
      -1.265625,
      2.6875,
      1.1328125,
      2.96875,
      -1.609375,
      1.0234375,
      1.5390625,
      1.5390625,
      -3.265625,
      0.3984375,
      1.3984375,
      -2.203125,
      -3.453125,
      1.71875,
      -4.0625,
      0.953125,
      2.09375,
      -1.578125,
      0.267578125,
      -1.015625,
      2.203125,
      0.55859375,
      -1.34375,
      -3.21875,
      4.09375,
      4.53125,
      1.6953125,
      2.046875,
      2.84375,
      6.03125,
      0.474609375,
      -0.6796875,
      1.046875,
      3.046875,
      1.3046875,
      0.134765625,
      -1.9453125,
      3.75,
      -4.03125,
      -7.15625,
      -3.90625,
      -0.72265625,
      2.125,
      -2.234375,
      2.953125,
      -3.859375,
      7.28125,
      -0.4140625,
      -1.2890625,
      -11.8125,
      0.1259765625,
      0.90625,
      -4.03125,
      -0.08349609375,
      -1.28125,
      4.8125,
      -1.578125,
      4.125,
      1.9140625,
      1.1796875,
      0.5078125,
      5.125,
      -2.390625,
      -0.265625,
      5.125,
      0.3828125,
      1.1171875,
      5.0625,
      -2.703125,
      -5.78125,
      -3.09375,
      -0.64453125,
      0.43359375,
      2.90625,
      4.15625,
      0.2734375,
      0.380859375,
      1.2109375,
      -4.25,
      -1.4296875,
      3.765625,
      2.453125,
      -0.1396484375,
      2.4375,
      -0.9921875,
      3.328125,
      -4.8125,
      3.78125,
      0.2314453125,
      -3.515625,
      1.265625,
      3.890625,
      2.296875,
      -2.109375,
      -1.0390625,
      -1.390625,
      3.90625,
      4,
      -8.5625,
      -2.625,
      0.65234375,
      2.171875,
      6.09375,
      1.4453125,
      0.2734375,
      -4.90625,
      5.0625,
      -2.5,
      -2.1875,
      4.71875,
      -0.92578125,
      -6.1875,
      1.3671875,
      -0.45703125,
      1.6796875,
      0.32421875,
      -0.396484375,
      2.078125,
      0.82421875,
      -0.302734375,
      2.96875,
      -1.546875,
      -2.578125,
      -4.3125,
      -0.09716796875,
      -2.109375,
      6.78125,
      0.82421875,
      -0.419921875,
      -3.359375,
      -1.8203125,
      3.40625,
      4.46875,
      2.109375,
      1.046875,
      0.82421875,
      0.21484375,
      -4.4375,
      4.625,
      4.21875,
      -2.421875,
      0.80078125,
      0.025634765625,
      -4.875,
      0.302734375,
      -2.390625,
      2.265625,
      1.6875,
      -1.15625,
      -4.96875,
      -5.09375,
      -3.375,
      0.7890625,
      4.3125,
      2.109375,
      -2.6875,
      4.46875,
      -0.16796875,
      0.08642578125,
      -1.015625,
      -3.75,
      -1.7265625,
      -2.53125,
      -1.671875,
      -8.125,
      -0.9140625,
      9.0625,
      1.3359375,
      -1.1953125,
      9.125,
      7.46875,
      -2.09375,
      1.265625,
      4.71875,
      -4.09375,
      -1.0234375,
      0.984375,
      -2.5,
      -2.234375,
      -1.8359375,
      2.28125,
      -2.390625,
      1.546875,
      0.0546875,
      -2.09375,
      -1.7734375,
      -4.75,
      -1.4453125,
      0.640625,
      -2.8125,
      1.21875,
      3.390625,
      3.40625,
      -1.0703125,
      6.9375,
      -0.55078125,
      -0.5703125,
      -1.4375,
      0.06396484375,
      2.0625,
      1.4765625,
      0.400390625,
      -2.9375,
      -4.75,
      -1.421875,
      1.25,
      -2.046875,
      3.078125,
      -1.2421875,
      1.6015625,
      2.28125,
      -0.06884765625,
      -6.8125,
      -3.3125,
      0.203125,
      -5.90625,
      -2.703125,
      -0.0166015625,
      3.671875,
      -1.15625,
      5.09375,
      -0.18359375,
      -1.7578125,
      -1.8203125,
      2.484375,
      -0.328125,
      0.9140625,
      -7.125,
      -1.84375,
      -0.2119140625,
      2.625,
      -6.6875,
      -3.84375,
      -2.703125,
      2.578125,
      -0.90234375,
      -4,
      5.53125,
      -3.90625,
      2.140625,
      -3.25,
      -0.57421875,
      2.84375,
      0.93359375,
      5.40625,
      -1.1328125,
      1.171875,
      2.734375,
      -0.90625,
      5.40625,
      -0.84375,
      1.2109375,
      0.40234375,
      1.5,
      1.21875,
      3.109375,
      1.46875,
      0.30078125,
      -0.9375,
      -1.2734375,
      0.52734375,
      2.421875,
      6.71875,
      3.140625,
      -1.3515625,
      3.609375,
      4.71875,
      -1.1328125,
      6.78125,
      1.921875,
      8.4375,
      -4.09375,
      -2.90625,
      6.75,
      0.212890625,
      -2.265625,
      -0.359375,
      -5.3125,
      -3.671875,
      2.796875,
      2.328125,
      -2.03125,
      -2.484375,
      -3.75,
      -1.6328125,
      3.96875,
      2.140625,
      4.8125,
      0.8359375,
      -0.60546875,
      3.140625,
      -1.3984375,
      -2.34375,
      -3.03125,
      -0.69921875,
      -1.4765625,
      1.0625,
      -2.234375,
      -0.73046875,
      -2.265625,
      2.359375,
      -4.5,
      -1.34375,
      -0.76171875,
      4.5,
      1.25,
      2.359375,
      0.054443359375,
      -2.40625,
      2.3125,
      1.359375,
      0.88671875,
      -3.171875,
      -1.453125,
      6.09375,
      7.09375,
      -1.390625,
      -0.96875,
      0.75390625,
      -1.6953125,
      -2.8125,
      -3.296875,
      4.90625,
      0.6953125,
      -5.09375,
      1.625,
      0.412109375,
      -4.96875,
      -4.25,
      4.21875,
      -2.375,
      -1.90625,
      3.8125,
      0.5703125,
      2.9375,
      2.890625,
      2.65625,
      2.703125,
      -1.5546875,
      -1.7578125,
      -3.0625,
      0.03466796875,
      -2.078125,
      3.140625,
      3.25,
      2.515625,
      1.5625,
      -1.453125,
      0.1494140625,
      -0.59375,
      -0.10205078125,
      -4.15625,
      0.466796875,
      -1.2890625,
      -4.8125,
      1.296875,
      -0.8671875,
      -8.3125,
      -4.6875,
      -6,
      -2.453125,
      -2.59375,
      -8.5625,
      -1.8359375,
      1.8359375,
      -5.15625,
      2.84375,
      -3.1875,
      -1.3984375,
      5.25,
      -3.84375,
      1.203125,
      -6.15625,
      3.765625,
      2.703125,
      0.384765625,
      4.1875,
      2.8125,
      1.953125,
      2.921875,
      -1.7734375,
      0.6953125,
      -6.125,
      6.96875,
      0.09033203125,
      7.6875,
      -0.1640625,
      -0.373046875,
      -5.84375,
      3.6875,
      0.43359375,
      1.7890625,
      -5.1875,
      1.5,
      -2.0625,
      -1.0390625,
      -0.0230712890625,
      0.9609375,
      0.271484375,
      -1.09375,
      -4.03125,
      2.84375,
      -0.9140625,
      -2.953125,
      2.015625,
      -1.5859375,
      5.59375,
      2.3125,
      1.03125,
      2.71875,
      2.390625,
      0.232421875,
      1.7421875,
      1.4140625,
      -3.875,
      3.53125,
      1.6640625,
      2.859375,
      -1.65625,
      4.96875,
      -1.2421875,
      0.57421875,
      -1.25,
      2.28125,
      3.015625,
      3.53125,
      -2.484375,
      2.9375,
      -1.96875,
      1,
      -0.193359375,
      1.1875,
      2.96875,
      0.95703125,
      1.8984375,
      -0.0201416015625,
      -3.375,
      -0.07763671875,
      0.53515625,
      1.484375,
      -5.5,
      -2.640625,
      -1.421875,
      -4.375,
      5.4375,
      -2.0625,
      0.6328125,
      1.4765625,
      0.3828125,
      3.59375,
      1.984375,
      -0.484375,
      0.984375,
      -0.21875,
      -1.453125,
      2.890625,
      -3.484375,
      6.75,
      3.4375,
      4.09375,
      5.4375,
      -1.28125,
      -0.5,
      -2.65625,
      1.8984375,
      3.40625,
      -2.625,
      0.064453125,
      5.15625,
      -3.1875,
      -1.484375,
      -2.0625,
      -1.5390625,
      0.32421875,
      -2.5625,
      1.7578125,
      8.8125,
      7.375,
      -3.53125,
      -5.71875,
      -1.40625,
      -3.859375,
      0.314453125,
      3.390625,
      0.1484375,
      1.7734375,
      2.859375,
      -0.2158203125,
      1.109375,
      1.515625,
      1.2734375,
      -6.3125,
      1.03125,
      0.8828125,
      -1.65625,
      -1.046875,
      0.1025390625,
      2.859375,
      0.70703125,
      6,
      1.890625,
      -0.466796875,
      3.65625,
      -1.9296875,
      -2.375,
      1.234375,
      6.59375,
      1.6640625,
      -1.8125,
      -4.8125,
      -1.015625,
      -0.00182342529296875,
      -1.90625,
      1.0078125,
      -3.765625,
      -0.462890625,
      7.3125,
      3.734375,
      0.97265625,
      3.28125,
      0.359375,
      3.625,
      -0.66796875,
      -2.5,
      -6.375,
      -0.8125,
      -3.125,
      1.4140625,
      1.1171875,
      -1.0625,
      -2.609375,
      1.6640625,
      -2.59375,
      2.984375,
      -5.40625,
      2.296875,
      -3.734375,
      -2.703125,
      0.30859375,
      -3.53125,
      4.5625,
      -0.74609375,
      0.353515625,
      2.546875,
      -3.046875,
      -1.9765625,
      -0.51953125,
      1.0625,
      -4.71875,
      -0.51953125,
      7.34375,
      -2.96875,
      -0.234375,
      -1.09375,
      0.30078125,
      -3.46875,
      -0.0458984375,
      -1.421875,
      -1.140625,
      -2.40625,
      0.0830078125,
      -1.328125,
      -3.75,
      4.21875,
      -6.0625,
      1.75,
      -1.1640625,
      1.4140625,
      2.921875,
      1.4140625,
      5.375,
      4.1875,
      -1.8515625,
      -0.75,
      -3.1875,
      -1.609375,
      -3.609375,
      -4.3125,
      1.1015625,
      -0.76953125,
      0.92578125,
      1.0546875,
      -0.46875,
      1.6640625,
      -3.59375,
      -2.8125,
      1.6796875,
      4.40625,
      -2.375,
      -1.0078125,
      1.90625,
      -3.71875,
      -8.125,
      -0.376953125,
      -4.875,
      1.171875,
      3.34375,
      -1.921875,
      3.03125,
      -3.609375,
      3.59375,
      -1.0390625,
      -2.09375,
      -0.38671875,
      -1.828125,
      3.671875,
      0.0284423828125,
      0.66015625,
      1.9765625,
      0.48828125,
      0.032470703125,
      -3.953125,
      -2.53125,
      -3.046875,
      -0.0830078125,
      2.390625,
      2.09375,
      -2.4375,
      -2.75,
      -0.93359375,
      -4.28125,
      -5.625,
      -4.21875,
      1.5625,
      5.75,
      4.4375,
      0.025390625,
      1.75,
      -1.96875,
      3.171875,
      -0.640625,
      5.21875,
      -1.1875,
      -3.734375,
      3.5625,
      -0.9375,
      4.09375,
      -1.4921875,
      -5.40625,
      -6.59375,
      2.640625,
      4.0625,
      6.1875,
      -1.9921875,
      -0.69140625,
      -0.384765625,
      -0.337890625,
      -1.609375,
      5.125,
      -1.9296875,
      -4.65625,
      -3.375,
      1.6328125,
      2.9375,
      -6.4375,
      3.203125,
      1.734375,
      -1.890625,
      -0.1845703125,
      6.90625,
      4.40625,
      -0.46875,
      2.140625,
      -1.25,
      -2.546875,
      2.4375,
      4.46875,
      0.224609375,
      1.6875,
      -1.0078125,
      -5.53125,
      -2.5625,
      -0.32421875,
      1.8125,
      1.9296875,
      -0.67578125,
      3.65625,
      -1.609375,
      1.421875,
      0.80859375,
      0.609375,
      -0.244140625,
      3.109375,
      0.3828125,
      -3.9375,
      2.484375,
      -2.765625,
      -2.03125,
      1.4375,
      -2.765625,
      1.0078125,
      0.94921875,
      -1.4453125,
      2.046875,
      1.09375,
      2.875,
      0.8203125,
      -6,
      0.5703125,
      1.3671875,
      0.9453125,
      4.625,
      -0.64453125,
      -1.2734375,
      1.6796875,
      -0.703125,
      -0.044677734375,
      -4.40625,
      4.40625,
      0.341796875,
      0.83984375,
      0.625,
      3.6875,
      -8.375,
      -1.8515625,
      -0.173828125,
      -0.07958984375,
      -2.453125,
      2.609375,
      -0.875,
      -2.5625,
      2.984375,
      0.84765625,
      -1.359375,
      -1.9453125,
      0.96484375,
      0.1455078125,
      -0.515625,
      1.3671875,
      -1.5234375,
      3.671875,
      -2.09375,
      -0.58203125,
      6.21875,
      -0.0234375,
      -0.033447265625,
      1.984375,
      0.1884765625,
      5.1875,
      3.65625,
      -0.79296875,
      -3.59375,
      -0.796875,
      0.9140625,
      -2.15625,
      -4.0625,
      1.3046875,
      -2.4375,
      -4.71875,
      0.65234375,
      -7.0625,
      -1.2109375,
      -3.65625,
      -6.75,
      -1.921875,
      -2.78125,
      1.09375,
      4.65625,
      3.703125,
      -2.15625,
      0.67578125,
      -2.984375,
      3.3125,
      2.671875,
      -3.296875,
      1.515625,
      -1.9453125,
      0.240234375,
      -4.53125,
      -2.453125,
      1.84375,
      1.7109375,
      3.796875,
      3.734375,
      -2.78125,
      1.953125,
      -1.1015625,
      2.625,
      -3.234375,
      -1.2421875,
      -0.62109375,
      2.765625,
      -4.125,
      -1.7734375,
      -2.828125,
      5.25,
      0.8046875,
      0.88671875,
      1.2421875,
      -1.9296875,
      3.078125,
      0.59765625,
      1.859375,
      2.84375,
      3.484375,
      4.40625,
      -1.96875,
      0.53125,
      -0.2158203125,
      -0.2734375,
      1.046875,
      -2.140625,
      -1.9140625,
      -3.390625,
      1.34375,
      -3.421875,
      -1.9765625,
      -5.9375,
      -0.65625,
      -0.8125,
      2.9375,
      2.6875,
      1.265625,
      -4.0625,
      0.4296875,
      -1.359375,
      -1.3359375,
      -2.203125,
      3.6875,
      -1.4140625,
      1.625,
      -3.984375,
      3.609375,
      4.96875,
      4.71875,
      3.046875,
      0.98046875,
      1.5,
      -2.359375,
      1.40625,
      -3.140625,
      3.140625,
      -0.95703125,
      -1.4765625,
      -0.59765625,
      -1.0390625,
      -1.6953125,
      -1.4453125,
      6.03125,
      -4.34375,
      -5.40625,
      -4.0625,
      -2.484375,
      0.64453125,
      5.28125,
      -4.3125,
      -0.72265625,
      -0.057373046875,
      -2.203125,
      3.3125,
      1.875,
      -1.5,
      -3.859375,
      4.15625,
      -0.8515625,
      4.3125,
      5.5,
      1.0390625,
      0.9453125,
      2.765625,
      0.12890625,
      -1.0625,
      3.75,
      0.625,
      -0.32421875,
      -1.9921875,
      3.234375,
      1.9140625,
      1.40625,
      -1.40625,
      -0.1748046875,
      1.7578125,
      2.875,
      4.5625,
      5.71875,
      -0.36328125,
      0.65625,
      1.8515625,
      -1.1640625,
      -1.9921875,
      -2.78125,
      2.484375,
      0.49609375,
      0.5234375,
      4.375,
      1.234375,
      3.828125,
      -3.640625,
      1.3828125,
      4.59375,
      9.375,
      -4.09375,
      0.042236328125,
      -6.875,
      1.515625,
      -2.125,
      -2.0625,
      -2.390625,
      3.875,
      2.1875,
      5.09375,
      0.1689453125,
      -0.71484375,
      4,
      0.55078125,
      -1.078125,
      -5.03125,
      4.1875,
      0.86328125,
      -0.318359375,
      -3.984375,
      -4.0625,
      0.06005859375,
      3.875,
      0.72265625,
      0.90625,
      0.251953125,
      2.65625,
      2.015625,
      -5.5,
      1.0234375,
      -0.53515625,
      -6.34375,
      -0.57421875,
      -2.4375,
      3.203125,
      -2.78125,
      -0.2080078125,
      4.71875,
      -2.515625,
      3.359375,
      -0.9296875,
      0.27734375,
      1.2421875,
      -1.3515625,
      0.79296875,
      1.0078125,
      -2.90625,
      3.421875,
      -1.0625,
      -5.375,
      0.0791015625,
      -1.4765625,
      0.765625,
      -1.3203125,
      -0.494140625,
      -0.40234375,
      -6.53125,
      0.49609375,
      -1.2890625,
      2.390625,
      0.6796875,
      -1.5546875,
      -2.09375,
      1.84375,
      -1.625,
      -0.95703125,
      1.3203125,
      -1.59375,
      1.265625,
      -0.9609375,
      0.2197265625,
      3.53125,
      0.76171875,
      -2.046875,
      2.953125,
      1.53125,
      0.12255859375,
      -1.4140625,
      -2.34375,
      0.400390625,
      -1.6015625,
      3.015625,
      -2.5625,
      -0.25390625,
      -0.51171875,
      4.90625,
      1.0078125,
      2.796875,
      -2.984375,
      -1.3203125,
      3.171875,
      3.625,
      -1.9453125,
      -1.5078125,
      0.53515625,
      1.6328125,
      -6.78125,
      -2.015625,
      1.6875,
      0.234375,
      3,
      -7.1875,
      -4.25,
      0.185546875,
      -0.51953125,
      -2.84375,
      -7.3125,
      2.171875,
      -0.8515625,
      -2.546875,
      -6.0625,
      0.50390625,
      3.4375,
      4.375,
      2.5625,
      4,
      0.447265625,
      -1.8671875,
      2.234375,
      12.1875,
      -1.09375,
      -1.7265625,
      -0.220703125,
      -0.7734375,
      6.1875,
      3.8125,
      2.671875,
      -0.69140625,
      -0.376953125,
      1.1875,
      0.400390625,
      3.140625,
      2.78125,
      -1.484375,
      -2.59375,
      -0.00994873046875,
      3.71875,
      -1.7890625,
      -5.21875,
      0.5625,
      3.640625,
      0.9296875,
      2.828125,
      -2.515625,
      1.03125,
      -0.7578125,
      -2.640625,
      -0.11865234375,
      -4.59375,
      -3.875,
      -1.71875,
      1.90625,
      -0.87890625,
      0.314453125,
      -5.25,
      -0.380859375,
      0.302734375,
      -3.9375,
      0.59765625,
      -3.8125,
      -2.640625,
      -1.46875,
      -1.0703125,
      3.703125,
      0.859375,
      0.59375,
      1.1875,
      0.345703125,
      2.859375,
      -3.453125,
      -3.125,
      -5.5625,
      1.34375,
      2.546875,
      -0.5078125,
      -2.359375,
      -4.09375,
      -4.65625,
      -2.234375,
      -3.90625,
      0.41796875,
      2.59375,
      -2.046875,
      -2.484375,
      -5.21875,
      -2.046875,
      0.42578125,
      2.8125,
      -2.5,
      -6.875,
      -0.376953125,
      0.87109375,
      1.3046875,
      -1.21875,
      -3.296875,
      5.21875,
      -0.09619140625,
      2.453125,
      -0.63671875,
      1.0859375,
      0.56640625,
      -3.109375,
      -0.287109375,
      3.171875,
      0.10107421875,
      -5.5,
      -1.7890625,
      2.34375,
      -1.3359375,
      3.921875,
      -4.34375,
      3.953125,
      0.625,
      -1.59375,
      -0.66796875,
      0.447265625,
      4,
      -4.875,
      0.019775390625,
      3.03125,
      3.609375,
      3.4375,
      -1.0859375,
      0.455078125,
      1.03125,
      1.7578125,
      -4.84375,
      1.2890625,
      1.4140625,
      1.4140625,
      -1.1015625,
      -0.546875,
      0.9296875,
      -1.3359375,
      -0.8984375,
      -4.5,
      -5.3125,
      -2.09375,
      -1.5625,
      3.546875,
      1.640625,
      -0.06689453125,
      0.275390625,
      -6.15625,
      -2.609375,
      -2.9375,
      -2.828125,
      5.25,
      0.126953125,
      -0.03515625,
      1.9296875,
      -2.3125,
      0.6953125,
      2.65625,
      -5.65625,
      2.859375,
      7.625,
      2.75,
      -0.5234375,
      -1.71875,
      -1.8828125,
      6.5,
      -2.78125,
      1.1875,
      3.875,
      -2.03125,
      4.46875,
      2.21875,
      2.328125,
      -5.78125,
      0.66796875,
      -0.26953125,
      0.228515625,
      -1.78125,
      5.3125,
      0.2021484375,
      1.9140625,
      -3.53125,
      1.046875,
      -3.765625,
      0.62109375,
      -2.90625,
      -1.578125,
      -2.78125,
      0.349609375,
      2.703125,
      0.376953125,
      -7.59375,
      2.796875,
      0.8515625,
      -3.015625,
      -6,
      -0.72265625,
      3.328125,
      0.490234375,
      1.859375,
      2.078125,
      -0.78125,
      2.40625,
      3.53125,
      0.74609375,
      -1.9609375,
      -0.019775390625,
      1.4765625,
      2.921875,
      -0.60546875,
      2.234375,
      1.109375,
      1.3671875,
      -0.43359375,
      -1.7421875,
      -1.2421875,
      3.65625,
      2.078125,
      -4.3125,
      0.177734375,
      -1.1015625,
      0.212890625,
      -2.3125,
      -3.203125,
      1.4375,
      -1.125,
      -0.1796875,
      1.796875,
      -2.21875,
      1.0625,
      -1.5625,
      -0.65625,
      -0.53125,
      -3.25,
      2.15625,
      3.234375,
      1.828125,
      -0.404296875,
      2.53125,
      2.875,
      -0.6328125,
      0.90234375,
      3.375,
      0.408203125,
      -0.69921875,
      -2.859375,
      2.640625,
      1.40625,
      4.5,
      -6.25,
      1.203125,
      -0.87109375,
      -0.2421875,
      1.5234375,
      1.5859375,
      0.953125,
      2.140625,
      -6.125,
      -3.625,
      -4.46875,
      1.875,
      -1.125,
      1.234375,
      2.328125,
      -1.6171875,
      0.64453125,
      0.94921875,
      -3.625,
      2.71875,
      -0.318359375,
      1.3671875,
      1.125,
      1.796875,
      -0.8828125,
      -2.390625,
      1.9140625,
      -0.94921875,
      -0.1318359375,
      -1.921875,
      -6.375,
      1.71875,
      -2.25,
      2.671875,
      -1.5625,
      -4.375,
      1.8671875,
      -0.515625,
      1.140625,
      0.55078125,
      -0.201171875,
      -5.125,
      6.1875,
      1.25,
      -0.96875,
      3.921875,
      -0.62109375,
      -2.59375,
      -0.443359375,
      -0.353515625,
      2.328125,
      -3.203125,
      -0.6640625,
      2.109375,
      -2.15625,
      -0.53125,
      2.3125,
      0.0250244140625,
      3.4375,
      -2.09375,
      0.0869140625,
      -0.75,
      2.796875,
      2.515625,
      5.3125,
      4.5625,
      -1.8125,
      1.5546875,
      -4.75,
      3.671875,
      -0.7265625,
      0.1669921875,
      2.59375,
      -2.109375,
      0.4765625,
      1.4921875,
      3.0625,
      -4.40625,
      -2.28125,
      0.53125,
      1.453125,
      4.1875,
      -0.435546875,
      1.2734375,
      -0.71484375,
      -2.109375,
      -1.984375,
      -2.390625,
      1.2734375,
      -2.859375,
      -1.984375,
      2.046875,
      4.09375,
      -2.640625,
      2.078125,
      1.515625,
      -1.0078125,
      -0.8671875,
      2.234375,
      -7.9375,
      -2.078125,
      3.828125,
      -5.53125,
      4.0625,
      -1.828125,
      1.375,
      7.625,
      -1.390625,
      -3.46875,
      5.875,
      0.1767578125,
      -7.0625,
      -1.1015625,
      -1.859375,
      2.78125,
      1.3515625,
      -0.1474609375,
      1.7734375,
      1.625,
      5.375,
      -5.46875,
      3.140625,
      -1.9765625,
      -5.90625,
      3.6875,
      -2.375,
      1.0859375,
      -2.9375,
      -5.90625,
      -5.3125,
      3.53125,
      1.1171875,
      3.390625,
      3.984375,
      2.03125,
      -1.453125,
      2.46875,
      -2.703125,
      -4.21875,
      3.71875,
      0.302734375,
      -4.53125,
      -2.140625,
      1.046875,
      -0.5859375,
      -0.2001953125,
      -0.73828125,
      -0.546875,
      -1.8671875,
      2.03125,
      1.515625,
      5.78125,
      -2,
      -2.171875,
      -4.0625,
      -0.251953125,
      0.423828125,
      0.63671875,
      -1.796875,
      -1.8515625,
      -2.140625,
      -3.109375,
      1.1796875,
      -1.46875,
      -5.03125,
      -2.40625,
      -4.875,
      -2.96875,
      2.953125,
      2.828125,
      2.828125,
      -2.234375,
      -1.8984375,
      4.0625,
      2.328125,
      0.203125,
      -3.484375,
      2.09375,
      1.8203125,
      -3.53125,
      -0.302734375,
      1.6640625,
      -1.2890625,
      -0.8125,
      1.3984375,
      1.859375,
      0.228515625,
      -1.890625,
      0.86328125,
      3.625,
      -1.1015625,
      0.462890625,
      -0.419921875,
      -1.3125,
      0.890625,
      6.4375,
      0.69140625,
      -5.15625,
      -3.171875,
      -3.296875,
      -2.390625,
      -4.375,
      1.34375,
      -1.859375,
      1.9296875,
      3.65625,
      -0.2578125,
      2.203125,
      2.390625,
      -4.71875,
      -1.921875,
      5.625,
      0.74609375,
      -0.92578125,
      -0.4609375,
      2.59375,
      -3.75,
      5.125,
      3.546875,
      -1.421875,
      -2.984375,
      -0.8984375,
      0.1689453125,
      -3.265625,
      -1.515625,
      0.326171875,
      -2.265625,
      -3.71875,
      2.546875,
      -1.3984375,
      2.21875,
      -0.39453125,
      -0.796875,
      4.6875,
      -5.40625,
      0.173828125,
      0.671875,
      4.5,
      4.34375,
      -7.0625,
      -2.21875,
      -3.5625,
      1.1171875,
      -3.0625,
      0.95703125,
      -1.3828125,
      0.55859375,
      5.34375,
      -2.34375,
      -3.53125,
      -2.453125,
      -6,
      2.75,
      0.11669921875,
      -0.76953125,
      0.19921875,
      -2.75,
      2.890625,
      -1.3359375,
      2.703125,
      -5.5625,
      0.70703125,
      -3.4375,
      -0.58203125,
      -0.279296875,
      2.28125,
      0.033447265625,
      -1.828125,
      0.62890625,
      5.46875,
      -0.8828125,
      -1.359375,
      5.59375,
      1.78125,
      0.72265625,
      1.0546875,
      1.203125,
      2.828125,
      -0.498046875,
      -5,
      3,
      2.890625,
      -0.115234375,
      -0.9375,
      0.1884765625,
      -1.359375,
      0.275390625,
      -0.83984375,
      0.490234375,
      0.52734375,
      0.5234375,
      0.02490234375,
      -5.5,
      -2.296875,
      -3.125,
      -2.03125,
      0.2470703125,
      0.169921875,
      3.0625,
      2.96875,
      -0.08154296875,
      -1.6953125,
      -0.6875,
      -1.3125,
      -0.2021484375,
      4.65625,
      -0.140625,
      -0.98828125,
      -1.078125,
      1.109375,
      -2.609375,
      -3.09375,
      -1.640625,
      -0.275390625,
      -0.3671875,
      0.361328125,
      3.015625,
      -2.046875,
      1.5546875,
      0.8359375,
      2.5625,
      -0.45703125,
      3.34375,
      -1.0078125,
      3.53125,
      -2.125,
      -1.3984375,
      2.71875,
      -0.2177734375,
      1.390625,
      2.90625,
      -1.734375,
      0.73046875,
      1.484375,
      -3.375,
      4.5,
      -3.75,
      4.28125,
      -1.8359375,
      3.84375,
      2.203125,
      -2.671875,
      1.171875,
      3.609375,
      -3.296875,
      -0.6484375,
      -0.12255859375,
      1.46875,
      1.78125,
      0.984375,
      0.86328125,
      -1.4453125,
      0.97265625,
      -2.09375,
      -0.3203125,
      -0.7890625,
      -0.7734375,
      2.234375,
      -1.984375,
      1.421875,
      -0.62890625,
      1.0625,
      -1.2734375,
      1.796875,
      0.515625,
      1.0546875,
      0.82421875,
      -3.875,
      2.09375,
      -0.90234375,
      -0.80078125,
      3.3125,
      0.72265625,
      -3.125,
      -0.5390625,
      -1.59375,
      5.6875,
      0.3828125,
      -2.953125,
      2.65625,
      1.0546875,
      2.578125,
      -0.2255859375,
      1.0078125,
      -0.9140625,
      -0.5390625,
      -4.4375,
      -0.65234375,
      -2.921875,
      -1.7890625,
      -2.40625,
      -1.125,
      0.427734375,
      -0.337890625,
      -0.50390625,
      -1.0078125,
      -1.9296875,
      -4.125,
      -3.3125,
      2.5625,
      1.3828125,
      -4.5,
      1.5703125,
      -3.328125,
      3.3125,
      -0.984375,
      -3.203125,
      -1.78125,
      -3.9375,
      0.451171875,
      -0.90234375,
      -4.0625,
      -1.3828125,
      2.171875,
      -3.578125,
      0.28515625,
      -3.5,
      0.82421875,
      -0.58203125,
      2.765625,
      0.9765625,
      -1.125,
      0.298828125,
      -1.21875,
      -3,
      -3.8125,
      -2.734375,
      -0.33984375,
      1.265625,
      2.28125,
      -1.671875,
      -3.546875,
      -0.21875,
      0.9453125,
      -0.87109375,
      -0.322265625,
      0.6875,
      -5.46875,
      0.5859375,
      4.6875,
      0.458984375,
      0.61328125,
      -4.28125,
      0.5859375,
      -1.421875,
      1.859375,
      -0.75,
      2.46875,
      0.310546875,
      -1.40625,
      1.3984375,
      1.4140625,
      3.5,
      -1.6328125,
      0.7265625,
      2.421875,
      -0.38671875,
      4.03125,
      4.78125,
      0.6875,
      -3.359375,
      0.349609375,
      -2.21875,
      1.828125,
      -2.015625,
      -1.6953125,
      -1.25,
      1.8046875,
      1.71875,
      2.34375,
      2.578125,
      1.0234375,
      -2.4375,
      -0.408203125,
      -3.71875,
      1.796875,
      1.7421875,
      4.625,
      -0.130859375,
      0.1279296875,
      0.115234375,
      -1.4375,
      1.359375,
      -0.70703125,
      0.51953125,
      4.46875,
      -1.9921875,
      -0.10400390625,
      1.265625,
      2.109375,
      -2.03125,
      -2.234375,
      2.734375,
      -0.77734375,
      1.703125,
      -2.078125,
      0.09228515625,
      1.6484375,
      -2.796875,
      2.96875,
      1.625,
      -4.59375,
      -2.140625,
      -3.6875,
      0.040771484375,
      2.9375,
      -0.059814453125,
      1.703125,
      1.3671875,
      -0.67578125,
      1.5703125,
      -4.96875,
      1.671875,
      2.46875,
      -3.34375,
      -0.66015625,
      -1.7890625,
      0.76171875,
      2.03125,
      1.046875,
      -3.109375,
      -0.23828125,
      -3.171875,
      0.921875,
      -0.0947265625,
      1.1328125,
      -3.828125,
      1.375,
      -0.0245361328125,
      -1.5390625,
      1.1484375,
      4.46875,
      -3.4375,
      -2.65625,
      -2.03125,
      0.083984375,
      -0.09326171875,
      -0.478515625,
      -2.484375,
      2.078125,
      -0.322265625,
      -1.7109375,
      -2.0625,
      -0.275390625,
      0.65234375,
      0.251953125,
      0.8046875,
      -3.765625,
      -3.96875,
      3.015625,
      -1.453125,
      -1.6640625,
      -1.578125,
      -0.421875,
      -0.62890625,
      -2.546875,
      2.609375,
      -1.8125,
      -0.326171875,
      -2.5,
      3.96875,
      0.052490234375,
      0.016357421875,
      1.90625,
      -1.921875,
      1.6953125,
      -0.2060546875,
      -4.34375,
      -1.875,
      0.12158203125,
      -2.546875,
      -0.2734375,
      -2.265625,
      2.4375,
      3.78125,
      -0.13671875,
      -0.97265625,
      -1.125,
      1.125,
      -1.890625,
      1.28125,
      2.21875,
      0.4921875,
      0.72265625,
      0.671875,
      -0.69921875,
      -1.7265625,
      1.671875,
      1.3671875,
      0.4765625,
      2.359375,
      0.94140625,
      4.6875,
      1.2265625,
      2,
      -1.28125,
      1.4921875,
      -0.9609375,
      -0.04931640625,
      4.90625,
      0.474609375,
      2.28125,
      -0.65234375,
      0.13671875,
      -1.0078125,
      0.94140625,
      -2.3125,
      0.8359375,
      0.84765625,
      -3,
      2.65625,
      0.6796875,
      -1.359375,
      -1.2578125,
      1.953125,
      -0.30859375,
      0.95703125,
      1.578125,
      -0.89453125,
      -0.53515625,
      0.765625,
      0.66015625,
      1.84375,
      0.859375,
      -1.3515625,
      -0.16796875,
      -0.8515625,
      0.43359375,
      2.015625,
      4.78125,
      -0.6484375,
      3.484375,
      5.4375,
      0.44921875,
      -1.2265625,
      -2.71875,
      -4.34375,
      1.6015625,
      1.125,
      -0.73828125,
      3.9375,
      0.890625,
      -0.94921875,
      -1.484375,
      -1.5703125,
      -1.015625,
      1.1796875,
      1.7578125,
      0.4921875,
      -2.078125,
      -1.8671875,
      -0.59765625,
      0.408203125,
      1.328125,
      -0.41796875,
      0.49609375,
      -1.34375,
      0.13671875,
      1.8671875,
      1.234375,
      1.2421875,
      -0.68359375,
      -1.65625,
      2.15625,
      2.140625,
      -0.9296875,
      -0.453125,
      3.640625,
      -5.09375,
      -0.42578125,
      3.171875,
      -1.8203125,
      -2.640625,
      -2.203125,
      2.953125,
      0.01092529296875,
      0.7578125,
      -2.65625,
      0.90234375,
      -0.349609375,
      2.9375,
      0.10107421875,
      0.99609375,
      -3.78125,
      1.015625,
      -0.51171875,
      2.59375,
      -2,
      -2.015625,
      1.6640625,
      0.69140625,
      2.734375,
      1.46875,
      -0.08056640625,
      -1.78125,
      -1.5234375,
      -0.82421875,
      -1.9375,
      -0.2890625,
      1.75,
      2.859375,
      -2.828125,
      -1.234375,
      -1.15625,
      -0.7421875,
      0.6171875,
      -3,
      -1,
      0.6953125,
      0.65625,
      0.78515625,
      -0.1669921875,
      -1.5,
      1.2265625,
      1.59375,
      3.671875,
      -1.3671875,
      3.09375,
      -2.28125,
      2.140625,
      -1.8046875,
      -1.015625,
      3.640625,
      -1.8203125,
      0.037109375,
      2.8125,
      -0.353515625,
      -1.703125,
      3.640625,
      1.6953125,
      1.703125,
      1.3671875,
      -3.078125,
      1.859375,
      -1.9140625,
      -1.2109375,
      -0.00714111328125,
      -1.703125,
      -0.5625,
      -4.15625,
      0.21484375,
      -0.314453125,
      1.8046875,
      2.1875,
      0.90625,
      1.59375,
      0.96875,
      -2.640625,
      3.296875,
      2.53125,
      -0.95703125,
      -0.1357421875,
      -1.1640625,
      1.6328125,
      -1.9296875,
      -0.1630859375,
      -0.462890625,
      0.55078125,
      -0.13671875,
      1.2265625,
      -2.6875,
      0.1767578125,
      -0.3203125,
      -2.65625,
      1.578125,
      -1.3515625,
      0.1279296875,
      1.3125,
      -0.828125,
      4.8125,
      -1.015625,
      0.9296875,
      1.25,
      1.4921875,
      -4.0625,
      -2.28125,
      -2.578125,
      -5.71875,
      0.98828125,
      1.3203125,
      -0.7265625,
      -0.01226806640625,
      -2.3125,
      -0.23046875,
      0.94140625,
      -1.6875
    ],
    "summary": "利用新西兰大型慈善组织首次被强制要求对服务绩效信息（SSP）进行审计这一外生政策冲击，构造处理组与对照组，通过双重差分模型量化新增非财务信息审计对审计费用与审计时滞的边际影响，并以事件研究方式检验动态效应。",
    "structure": {
      "sections": [
        {
          "title": "The cost of auditing service performance information",
          "level": 1,
          "start_line": 3
        },
        {
          "title": "The cost of auditing service performance information",
          "level": 1,
          "start_line": 27
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 29
        },
        {
          "title": "I. INTRODUCTION",
          "level": 1,
          "start_line": 43
        },
        {
          "title": "2. INSTITUTIONAL SETTING, LITERATURE REVIEW AND RESEARCH QUESTIONS",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "Institutional Setting",
          "level": 1,
          "start_line": 65
        },
        {
          "title": "Literature Review and Hypothesis Development",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "3. RESEARCH METHOD",
          "level": 1,
          "start_line": 89
        },
        {
          "title": "Sample",
          "level": 1,
          "start_line": 91
        },
        {
          "title": "Regression Models",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "4. RESULTS",
          "level": 1,
          "start_line": 119
        },
        {
          "title": "Audit Fees and SSPs",
          "level": 1,
          "start_line": 142
        },
        {
          "title": "Audit Lag and SSPs",
          "level": 1,
          "start_line": 156
        },
        {
          "title": "5. CONCLUSION",
          "level": 1,
          "start_line": 177
        },
        {
          "title": "REFERENCES",
          "level": 1,
          "start_line": 185
        },
        {
          "title": "Appendix A",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "Opinion",
          "level": 1,
          "start_line": 243
        },
        {
          "title": "Basis for opinion",
          "level": 1,
          "start_line": 256
        }
      ]
    },
    "tags": [
      "审计费用",
      "绩效信息鉴证",
      "非营利组织"
    ],
    "suggested_tags": [
      "审计费用",
      "绩效信息鉴证",
      "非营利组织",
      "会计准则影响"
    ],
    "tag_suggestions": [
      {
        "name": "审计费用",
        "confidence": 0.98,
        "reason": "论文核心变量为审计费用变动，是研究非财务信息强制鉴证成本的主要度量。"
      },
      {
        "name": "绩效信息鉴证",
        "confidence": 0.96,
        "reason": "研究对象即“服务绩效报告(SSP)”的强制审计，对应非财务信息鉴证这一细分任务。"
      },
      {
        "name": "非营利组织",
        "confidence": 0.95,
        "reason": "样本聚焦新西兰大型慈善机构，属于典型的公共受益实体（PBE）与非营利部门。"
      },
      {
        "name": "会计准则影响",
        "confidence": 0.9,
        "reason": "文章对比IFRS与PBE IPSAS等准则实施成本，归属会计与审计监管后果文献。"
      }
    ],
    "tags_confirmed": true,
    "category": "审计费用"
  },
  "57e0c73f-ce16-401b-bd5e-96ef5d42e5ea": {
    "id": "57e0c73f-ce16-401b-bd5e-96ef5d42e5ea",
    "filename": "ssrn-5390896.pdf",
    "file_path": "data/uploads/47e5d413-0cfd-43be-ba5a-dd4b0c5160c5/57e0c73f-ce16-401b-bd5e-96ef5d42e5ea_ssrn-5390896.pdf",
    "status": "completed",
    "created_at": "2025-12-20 12:37:21.078864",
    "updated_at": "2025-12-20 04:38:43.171870",
    "user_id": "47e5d413-0cfd-43be-ba5a-dd4b0c5160c5",
    "title": "Emergent gravity-like behaviors on complex latent space of variational encoder with nonlinear, data-adaptive regularization scheme.",
    "markdown_content": "# Emergent gravity-like behaviors on complex latent space of variational encoder with nonlinear, data-adaptive regularization scheme.\n\nBranislav Majerník\n\nFaculty of Mathematics, Physics and Informatics\n\nComenius University, 842 48 Bratislava, Slovakia\n\nbranislav.majernik@gmail.com\n\nORCID:0000-0003-0903-3653\n\nAugust 13,2025\n\n# Abstract\n\nAutoencoders are powerful neural network architectures designed for unsupervised learning by compressing high-dimensional data into a compact latent representation and subsequently reconstructing the original input. While traditional autoencoders use fully connected layers and fixed latent vectors, this work presents a convolutional autoencoder framework with a spatially structured latent space interpreted as a discrete complex-valued field, analogous to a quantum wavefunction. This approach retains spatial correlations and significantly reduces parameter count and overfitting. We propose a novel formulation where the latent representation is modeled as a complex-valued matrix  $\\Psi(t,x,y)$  enabling a probabilistic interpretation via  $|\\Psi|^2$  and evolution governed by discrete convolutional approximations of differential operators. Convolutions are shown to approximate Laplacians, allowing us to simulate wave-like propagation in the latent space. Time evolution of the latent field follows a discrete Schrödinger-like equation incorporating complex dynamics. Furthermore, we introduce a nonlinear, data-adaptive regularization scheme based on local gradients of  $\\Psi$ , which acts as an intelligent denoising filter. This adaptive mechanism emphasizes structurally significant regions—such as edges and transitions—by modulating learning dynamics based on latent curvature. The resulting architecture supports not only efficient reconstruction but also interpretable latent dynamics, offering a bridge between deep learning and physical field theory. Our formulation demonstrates how principles from quantum mechanics and differential geometry can inspire emergent behaviors such as metric curvature and gravity-like feedback within the latent space of deep networks, suggesting new directions for physically informed machine learning.\n\n# 1 Introduction\n\nAn autoencoder is a type of neural network architecture designed for unsupervised learning, with the primary objective of efficiently compressing, encoding, and embedding input data into a representation that captures its most salient features. The autoencoder then reconstructs the original input from this compressed representation. During training, the network learns to identify the underlying latent variables, hidden or implicit factors that, while not directly observable, significantly influence the structure and distribution of the data. The set of these latent variables forms what is referred to as the latent space. This latent space encapsulates only the most essential information required for accurate data reconstruction, effectively serving as a compact and informative representation of the original input.\n\nStandard autoencoders map inputs to fixed latent representations, variational autoencoderintroduce a probabilistic approach where the encoder outputs a distribution over the latent space\n\ndistribution  $q(z|x)$ , mean  $\\mu$  and variance  $\\sigma^2$ , see [1]. When using an encoder on an image, matrix, tensor field, on any high-dimensional field, the entire image, field must be flattened into a vector, which significantly increases the dimensionality of the vectors and thus the computational complexity. Let the image  $x \\in \\mathbb{R}^{H \\times W}$  have  $D = H \\cdot W$  pixels. After flattening, we get:\n\n$$\nz \\in \\mathbb {R} ^ {D}\n$$\n\nThan the encoder defines a mapping:\n\n$$\nf _ {\\mathrm {e n c}}: \\mathbb {R} ^ {H \\times W} \\to \\mathbb {R} ^ {D}, \\quad x \\mapsto z\n$$\n\nTherefore, it is advantageous to use a convolutional layer in both the encoder and decoder. Each filter represents a linear operator adapted to detect edges, textures, or other patterns.\n\nIf convolutional layers were replaced only by fully connected layers, we would lose locality, weight sharing, and spatial structure, leading to a larger number of parameters, increased overfitting, and weaker performance in image-based tasks. Therefore, it is advantageous to use convolutional layers both in the encoder and decoder. Here is summary how autoencoder works basically\n\n# 1.1 Encoder as a Projector to complex latent space\n\nAn autoencoder encodes the input\n\n$$\nx \\in \\mathbb {R} ^ {C \\times H \\times W}\n$$\n\ninto a latent space as:\n\n$$\nz = f _ {\\mathrm {e n c}} (x; \\theta)\n$$\n\nHere,  $f_{\\mathrm{enc}}$  is a composition of convolutional layers, nonlinear activations, and linear mappings. The output\n\n$$\nz \\in \\mathbb {R} ^ {d _ {1} \\times d _ {2} \\times d _ {3}}\n$$\n\nfor example,  $1 \\times 4 \\times 4$  can be interpreted as a discretized space (2D) with possible depth (time, frequency, channels)\n\n# 1.2 Matrix Representation of Space\n\nThe latent space is considered a tensor\n\n$$\nZ \\in \\mathbb {R} ^ {1 \\times 4 \\times 4}\n$$\n\nThis can be interpreted as a field of values (e.g., \"amplitudes\" in complex field) defined on a discrete grid. We can rewrite this structure as a discrete scalar field in space and time:\n\n$$\nZ _ {i, j} = \\psi \\left(t _ {i}, x _ {j}\\right)\n$$\n\nwhere  $t_i$  is the indexed time,  $x_j$  is the indexed space, and  $\\psi(t_i, x_j)$  are the values of the latent function.\n\n# 1.3 Mapping via Convolution as Operator Approximation\n\nConvolutional layers act as local linear operators that approximate derivatives — the foundation for the Laplacian operator, useful for regularization:\n\n$$\n\\operatorname {C o n v 2 D} (x) \\approx \\frac {\\partial^ {2}}{\\partial x ^ {2}} + \\frac {\\partial^ {2}}{\\partial y ^ {2}}\n$$\n\n# 1.4 Decoder: Inverse Mapping\n\nThe decoder is composed of linear and convolutional layers:\n\n$$\n\\hat {x} = f _ {\\mathrm {d e c}} (z; \\phi)\n$$\n\nThis maps the latent field back to the image. In physical analogy, the decoder interprets the latent field as a wavefunction or potential, from which it generates the \"observed reality.\"\n\n# Summary Symbolically\n\n$$\nx \\xrightarrow {\\mathrm {e n c o d e r} f _ {\\mathrm {e n c}}} z = \\psi (t, x) \\xrightarrow {\\mathrm {d e c o d e r} f _ {\\mathrm {d e c}}} \\hat {x}\n$$\n\nHere,  $z$  is a matrix representation of space (or space-time). It is a discrete field where hidden structures necessary for reconstruction are learned. Training maximizes the similarity between  $x$  and  $\\hat{x}$  using the MSE loss:\n\n$$\nL _ {\\mathrm {r e c o n}} = \\| x - \\hat {x} \\| ^ {2}\n$$\n\n# 2 Emergent gravity on complex latent space.\n\n# 2.1 Basic object: Complex wavefunction in matrix representation\n\nLet\n\n$$\n\\Psi (t, x, y) \\in \\mathbb {C}\n$$\n\nbe the wavefunction of a two-particle system in a two-dimensional discrete space, or continuously:\n\n$$\n\\Psi : \\mathbb {R} ^ {1 + 2} \\to \\mathbb {C}\n$$\n\nThe probability density is:\n\n$$\nP (t, x, y) = | \\Psi (t, x, y) | ^ {2}\n$$\n\nwith the normalization condition:\n\n$$\n\\int | \\Psi (t, x, y) | ^ {2} d x d y = 1\n$$\n\nIn discrete formulation:\n\n$$\n\\Psi (t) \\in \\mathbb {C} ^ {m \\times n}\n$$\n\nbe a time-dependent wavefunction defined on a discrete grid (e.g.,  $8 \\times 8$ ), where each element  $\\Psi_{ij}(t)$  represents the complex probability amplitude of a particle being at position  $(i,j)$  at time  $t$ . The associated probability density is:\n\n$$\nP _ {i j} (t) = \\left| \\Psi_ {i j} (t) \\right| ^ {2}\n$$\n\nWith normalization:\n\n$$\n\\sum_ {i = 1} ^ {m} \\sum_ {j = 1} ^ {n} | \\Psi_ {i j} (t) | ^ {2} = 1\n$$\n\n# 2.2 Latent space evolution\n\nUsing mentioned convolution mechanism in neural network formulate also discrete time evolution Application of the convolutional kernel kernel  $K$  to the wave function  $\\Psi_t$ , convolution:\n\n$$\n\\left(K * \\Psi_ {t}\\right) _ {i, j} = \\sum_ {a = - 1} ^ {1} \\sum_ {b = - 1} ^ {1} K _ {a, b} \\cdot \\psi_ {t, i - a, j - b}\n$$\n\nTo understand how does convolution describe wave propagation, we need understand what is convolution in this context. Convolution is an operation where each point of a new matrix is computed as a weighted sum of the neighboring values from the original matrix, according to a specific kernel. The applied convolution is a simplified model of propagation, used to local wave spreading from one point to its neighbors, similar to a discrete approximation of diffusion or wave propagation. A typical kernel for simple propagation, diffusion or wave spreading, may look like this:\n\n$$\nK = \\left[ \\begin{array}{c c c} 0 & \\alpha & 0 \\\\ \\alpha & 1 - 4 \\alpha & \\alpha \\\\ 0 & \\alpha & 0 \\end{array} \\right]\n$$\n\nwhere  $\\alpha$  is a small positive constant that determines the degree of propagation between neighbors. At each time step, we apply the convolution:\n\n$$\n\\psi^ {t + 1} = \\delta t \\psi^ {t} * K\n$$\n\nThe value at point  $(x, y)$  is obtained as a combination of the value at that point and its neighbors, according to the kernel. If we work with an image that has some symmetry, we can extract a lot of information from that symmetry, which allows us to significantly reduce its description, i.e., compress it. Rotational symmetry is typically used, for example in 2D images when rotated by 90 degrees. That mean for example augmentation of data by rotation during evolution. ktorá pomáha predíst overfittingu - siet sa nespolieha na špecifikné Rozloženie pixelov.\n\n$$\ni   \\delta t = \\left[ \\begin{array}{c c} 0 & - \\delta t \\\\ \\delta t & 0 \\end{array} \\right]\n$$\n\nIf we have two feature maps:\n\n$$\n\\Psi = \\operatorname {R e} (\\Psi) + i \\cdot \\operatorname {I m} (\\Psi)\n$$\n\nThen the operation:\n\n$$\n\\Psi^ {\\prime} = i \\cdot \\delta t \\cdot \\Psi \\quad \\Rightarrow \\quad \\left\\{ \\begin{array}{l} \\operatorname {R e} (\\Psi^ {\\prime}) = - \\delta t \\cdot \\operatorname {I m} (\\Psi) \\\\ \\operatorname {I m} (\\Psi^ {\\prime}) = \\delta t \\cdot \\operatorname {R e} (\\Psi) \\end{array} \\right.\n$$\n\nThis can be implemented as a fixed matrix operation over the channels and give a evolution in discrete Schrödinger-like equation :\n\n$$\n\\Psi^ {t + 1} = \\Psi^ {t} + i \\delta t (K * \\Psi^ {t})\n$$\n\nwhere  $i = \\sqrt{-1}$  and  $\\delta t > 0$  is the time step. The discrete Laplace operator on a 2D grid is defined as:\n\n$$\n\\left(\\Delta \\Psi\\right) _ {i, j} = \\Psi_ {i + 1, j} + \\Psi_ {i - 1, j} + \\Psi_ {i, j + 1} + \\Psi_ {i, j - 1} - 4 \\Psi_ {i, j}\n$$\n\nTime evolution with time step  $\\delta t$  and Laplacian filter:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot \\Delta \\Psi (t)\n$$\n\n# 2.3 Emergent Gravity: metric curvature as evolution feedback and autoencoder features intelligent denoiser\n\nA filter defined as\n\n$$\n\\kappa (x, y) = \\alpha \\left(| \\nabla_ {x} \\Psi (x, y) | ^ {2} + | \\nabla_ {y} \\Psi (x, y) | ^ {2}\\right)\n$$\n\nis an adaptive nonlinear filter that depends on the local amplitude variation (gradient) of the wavefunction (or neural layer output). Let's analyze its meaning and potential use in an autoencoder for image or time series processing.\n\n-  $\\nabla_x\\Psi$ ,  $\\nabla_y\\Psi$ : approximate derivative or difference between neighboring output values in the  $x$  and  $y$  directions.  \n-  $|\\nabla \\Psi |^2$ : measure of local variation (edges, transitions, brightness changes).  \n-  $\\kappa(x, y)$ : weight that increases where the image or texture is more complex.\n\nEffect on the Autoencoder\n\n1. Adaptive Attention to Edges and Details\n\nIn regions with high gradients (e.g., edges or jumps in signal),  $\\kappa(x, y)$  becomes large, assigning higher learning weight to these areas.\n\n2. Latent Space Regularization\n\nUsing  $\\kappa (x,y)$  in regularization (e.g., Laplacian energy term) encourages smoothness while preserving important transitions—acting as an intelligent denoiser.\n\n3. Structural Enhancement in Image or Signal\n\n- For images: enhances texture, contours, and key features (e.g., MNIST digit edges).  \n- For time series: enhances dynamics, sudden changes, or transitions.\n\nFor image data (e.g., MNIST, CIFAR)\n\n- Encoder can use  $\\kappa(x, y)$  as a local weight, e.g., adaptive spatial convolution.  \n- Decoder can reapply  $\\kappa(x, y)$  as a saliency map to guide fine reconstruction.\n\nFor 1D signals\n\n-  $\\kappa(t) = \\alpha |\\nabla \\Psi(t)|^2$  highlights temporal discontinuities (faults, pulses).  \n- Encourages attention to anomalies or fast transitions.\n\nWhen incorporated into a wave-like evolution equation:\n\n$$\n\\Psi^ {t + \\delta t} = \\Psi^ {t} + i \\delta t \\cdot (1 + \\kappa (x, y)) \\cdot \\Delta \\Psi\n$$\n\n$\\kappa$  acts as a dynamic spatial curvature that enhances wave behavior in regions with strong variation. The filter  $\\kappa(x, y)$  is then useful for: adaptive resolution control (enhance edges, suppress smooth), improving reconstruction of important image features, increasing autoencoder attention to structurally significant regions.\n\nWe introduce a curvature field  $\\kappa_{ij}$  (emergent \"graviton\") as a function of the local wave gradient magnitude and define in discrete form:\n\n$$\n\\kappa_ {i, j} = \\alpha \\left(\\left| \\frac {\\Psi_ {i + 1 , j} - \\Psi_ {i - 1 , j}}{2} \\right| ^ {2} + \\left| \\frac {\\Psi_ {i , j + 1} - \\Psi_ {i , j - 1}}{2} \\right| ^ {2}\\right)\n$$\n\nEach point evolves based on the amount of \"matter\" (i.e., gradient of  $\\Psi$ ) in its neighborhood. After each evolution normalization step:\n\n$$\n\\Psi (t) \\gets \\frac {\\Psi (t)}{\\sqrt {\\sum_ {i , j} | \\Psi_ {i j} (t) | ^ {2}}}\n$$\n\nInterpretation: Emergent Gravitational Interaction. A wavefunction with two maxima (particles A and B) creates local curvature via  $\\kappa$ , which in turn influences the wave evolution. Thus, particles attract each other through curvature feedback without any explicit potential term.\n\n# 2.4 Summary of Equations\n\nDiscrete Laplacian:\n\n$$\n\\left(\\Delta \\Psi\\right) _ {i, j} = \\Psi_ {i + 1, j} + \\Psi_ {i - 1, j} + \\Psi_ {i, j + 1} + \\Psi_ {i, j - 1} - 4 \\Psi_ {i, j}\n$$\n\nEmergent curvature:\n\n$$\n\\kappa_ {i, j} = \\alpha \\left(\\left| \\frac {\\Psi_ {i + 1 , j} - \\Psi_ {i - 1 , j}}{2} \\right| ^ {2} + \\left| \\frac {\\Psi_ {i , j + 1} - \\Psi_ {i , j - 1}}{2} \\right| ^ {2}\\right)\n$$\n\nEvolution with curvature:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot (1 + \\kappa_ {i, j}) \\cdot \\Delta \\Psi (t)\n$$\n\nNormalization:\n\n$$\n\\Psi \\gets \\frac {\\Psi}{\\sqrt {\\sum_ {i , j} | \\Psi_ {i , j} | ^ {2}}}\n$$\n\nwith discrete wave function, we consider a quantum system defined on a 2D grid of size  $N \\times N$ , where:\n\n$$\n\\Psi (x, y, t) \\in \\mathbb {C}\n$$\n\nis the complex probability amplitude of finding a particle at position  $(x,y)$  and time  $t$ . We get discrete-time version of the Schrödinger equation in a curved metric in form:\n\n$$\n\\Psi (t + 1) = \\frac {1}{\\| \\cdot \\|} [ \\Psi (t) + i \\delta t \\cdot (1 + \\kappa (t)) \\cdot \\Delta \\Psi (t) ]\n$$\n\nwhere:\n\n-  $\\Delta \\Psi$  is the discrete Laplacian operator applied to  $\\Psi$ ,  \n-  $\\kappa(t)$  is the metric curvature expressed as a function of the gradient of  $\\Psi$ ,  \n-  $\\|\\cdot\\|$  denotes the  $L^2$ -norm to ensure normalization.\n\ncomplex convolution kernel:\n\n$$\nK = \\left[ \\begin{array}{c c c} 0 & 1 + i & 0 \\\\ 1 - i & - 4 & 1 + i \\\\ 0 & 1 - i & 0 \\end{array} \\right]\n$$\n\nwhich we apply as a 2D convolution:\n\n$$\n\\Delta \\Psi = \\Psi * K\n$$\n\nwhere  $*$  denotes 2D convolution with periodic (wrapped) boundary conditions.\n\n# 2.5 Visualization\n\nAt each time step  $t = 0,1,\\dots ,T$  we visualize:\n\n$$\n| \\Psi (x, y) | ^ {2}\n$$\n\nthe probability density over the 2D grid.\n\n![](/uploads/images/57e0c73f-ce16-401b-bd5e-96ef5d42e5ea/8fc79172f86bbb7a52bdc2c023dc1e39d808b0f2ffbcec1ea41ecf057604b4b5.jpg)\n\nIn the first image, at time  $t = 0$ , we see two particles located at positions [2,2] and [5,5] within an 8x8 matrix. The image shows the squared magnitude of the complex amplitude, which corresponds to the probability of detecting a particle in a given region. The brightest colors (white, yellow) on the heatmap represent the normalized highest probability, indicating a kind of localization of the particle within the uncertainty, which is represented by the darker areas on the heatmap.\n\nIn the subsequent images, which describe the time evolution in a discrete form, we observe both the dispersion of amplitudes around the most probable locations, as well as an attraction between the areas of highest probability. For example, at  $t = 14$ , there is a clear shift of the most probable locations of both particles from their original positions toward each other, eventually leading to a kind of fusion or merging into the center, as one might expect from particles with equal mass.\n\n# 3 Conclusion and physics remarks\n\n# 3.1 Emergent Graviton Interaction as Metric Curvature\n\nWe consider emergent graviton interaction as curvature of the metric (i.e., not just a potential, but full tensorial curvature), which arises from the dynamics of the wavefunction of a two-particle system. Thus, the graviton is not introduced explicitly but should emerge from the interaction. Variational encoder with specifi convolution filters works as linearized approximation of Einstein's equations and introduce effective curvature via the metric perturbation tensor  $h_{\\mu \\nu}$ , where:\n\n$$\ng _ {\\mu \\nu} = \\eta_ {\\mu \\nu} + h _ {\\mu \\nu}, \\quad (\\text {l i n e a r a p p r o x i m a t i o n})\n$$\n\nand where  $h_{\\mu \\nu}$  emerges from the distribution  $\\Psi^2$ , similarly to quantum field theory, where the graviton is the quantum of metric perturbation. We define the effective curvature as a tensorial\n\nfunction of the density  $\\Psi^2$ :\n\n$$\nh _ {\\mu \\nu} (x, y) = \\kappa \\partial_ {\\mu} \\Psi^ {*} \\cdot \\partial_ {\\nu} \\Psi + \\mathrm {c . c .}\n$$\n\nIn discrete matrix form:\n\n$$\nh _ {0 0} \\sim \\Psi^ {2} \\quad (\\mathrm {e n e r g y}),\n$$\n\n$$\nh _ {i j} \\sim \\nabla_ {i} \\Psi^ {*} \\cdot \\nabla_ {j} \\Psi \\quad (\\text {m o m e n t u m f l u x e s}).\n$$\n\nIn a curved metric, the Schrödinger equation takes the form:\n\n$$\ni \\partial_ {t} \\Psi = - \\frac {1}{\\sqrt {g}} \\partial_ {k} \\left(\\sqrt {g} g ^ {k j} \\partial_ {j} \\Psi\\right)\n$$\n\nIn 2D, this can be reformulated as a convolution operation with a locally curved Laplacian operator.\n\n# 3.2 Why do the maxima approach each other? Interpretation via modified Schrödinger evolution\n\nBasic linear evolution without curvature: Without curvature (i.e.,  $\\kappa = 0$ ), we recover the classical (discrete) linear Schrödinger equation:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot \\Delta \\Psi\n$$\n\n- In this case, the Laplacian propagates phase information, but does not alter the position of the amplitude maxima.  \n- The system is linear and conservative; particle amplitudes may interfere slightly but do not attract or move toward each other.\n\nEvolution with curvature (emergent gravity): When we introduce curvature:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot (1 + \\kappa) \\cdot \\Delta \\Psi\n$$\n\nand more precisely, if\n\n$$\n\\kappa = f \\left(\\left| \\nabla \\Psi \\right| ^ {2}\\right),\n$$\n\ni.e.,  $\\kappa$  depends on the local gradient magnitude of the wavefunction, we introduce a self-consistent curvature feedback:\n\n- In regions of high probability density (amplitude),  $|\\nabla \\Psi|^2$  is large  $\\Rightarrow \\kappa$  increases.  \n- The Laplacian has a stronger effect precisely where there is more \"mass\" (i.e., higher  $\\Psi$  amplitude).\n\nThis mimics the Einstein field equation in emergent form:\n\n$$\nR _ {\\mu \\nu} - \\frac {1}{2} R g _ {\\mu \\nu} \\sim T _ {\\mu \\nu}\n$$\n\nHere, the curvature of the metric (modeled by  $\\kappa$ ) is a function of the local energy density, proportional to  $|\\Psi|^2$  or  $|\\nabla \\Psi|^2$ .\n\nHow this causes gravitational attraction: Although the Laplacian typically causes wave spreading, if its strength is *amplified* in high-density regions due to curvature, an emergent effect appears. Each local amplitude maximum (interpreted as a particle) generates a localized curvature field. This field modifies the evolution of nearby parts of the wavefunction. As a result, the two amplitude maxima \"pull\" each other toward a central region, as the energetically favorable direction of propagation is toward stronger curvature (higher  $\\kappa$ ).\n\nFrom the point of view of trajectories, the amplitude peaks converge. In simulation, one observes:\n\n- The centers of mass of the two amplitude peaks shift from positions  $A$  and  $B$  toward each other.  \nTheir trajectories converge over time.  \n- The curvature modifies the Laplacian propagation such that the diffusion is no longer symmetric: this is not standard linear spreading.\n\nFor a grid point  $(i,j)$ :\n\n$$\n\\Psi_ {i, j} ^ {t + \\Delta t} = \\Psi_ {i, j} ^ {t} + i \\Delta t \\cdot (1 + \\kappa_ {i, j}) \\cdot \\left(\\Psi_ {i + 1, j} ^ {t} + \\Psi_ {i - 1, j} ^ {t} + \\Psi_ {i, j + 1} ^ {t} + \\Psi_ {i, j - 1} ^ {t} - 4 \\Psi_ {i, j} ^ {t}\\right)\n$$\n\nwith curvature defined locally by:\n\n$$\n\\kappa_ {i, j} = \\alpha \\cdot \\left(\\left| \\nabla_ {x} \\Psi_ {i, j} \\right| ^ {2} + \\left| \\nabla_ {y} \\Psi_ {i, j} \\right| ^ {2}\\right)\n$$\n\nThe wavefunction creates gravitational \"wells\" regions with enhanced amplitude. These wells deform the propagation of the wavefunction via a curvature-enhanced Laplacian. Effectively, the maxima of the wavefunction move toward one another. The emergent graviton is encoded in the curvature field  $\\kappa$  as a function of geometric self-deformation.\n\nThen can we ask: \"Is universe a variational autoencoder?\"\n\n# References\n\n[1] Diederik P. Kingma and Max Welling (2019), An Introduction to Variational Autoencoders, Foundations and Trends in Machine Learning: pp 1-18. DOI: 10.1561.",
    "arxiv_id": null,
    "error_message": null,
    "embedding": [
      -0.4140625,
      -2.921875,
      -1.4453125,
      -1.4765625,
      -1.4609375,
      1.484375,
      -2.25,
      -3.890625,
      0.828125,
      0.79296875,
      2.84375,
      1.140625,
      2.421875,
      1.921875,
      3.703125,
      -0.96484375,
      -0.58984375,
      -2.65625,
      2.25,
      -2.515625,
      -3.015625,
      6.5625,
      2.328125,
      -6.6875,
      -0.03271484375,
      1.546875,
      0.640625,
      -0.6171875,
      -0.67578125,
      -0.1728515625,
      3.90625,
      -5.09375,
      1.15625,
      1.640625,
      1.65625,
      -3.5625,
      -4.6875,
      -0.61328125,
      0.8046875,
      3.3125,
      -6.75,
      3.703125,
      0.1865234375,
      -0.859375,
      -2.328125,
      3.640625,
      1.3984375,
      -2.171875,
      -0.57421875,
      -2.140625,
      -3.0625,
      -6.5625,
      10.625,
      -3.203125,
      -0.01324462890625,
      -1.34375,
      -6.625,
      6.09375,
      -7.875,
      -2.296875,
      5.21875,
      0.439453125,
      4.53125,
      1.6015625,
      2.59375,
      4.5,
      0.890625,
      -0.6953125,
      -6.28125,
      4.6875,
      -2.09375,
      -1.484375,
      5.9375,
      -2.578125,
      5.53125,
      4.8125,
      1.1484375,
      0.7734375,
      -3.28125,
      3.109375,
      -3.84375,
      1.78125,
      5.1875,
      2.09375,
      4.21875,
      4.5,
      -4.5625,
      0.5390625,
      -1.46875,
      0.326171875,
      -2.515625,
      3.375,
      -3.65625,
      0.9140625,
      -0.11083984375,
      5.65625,
      1.84375,
      -5.6875,
      -7.875,
      1.0703125,
      -3.734375,
      0.0238037109375,
      -0.32421875,
      -3.53125,
      1.9453125,
      -5.5625,
      -3.03125,
      -5.8125,
      -4.59375,
      -4.75,
      -0.6171875,
      -0.7421875,
      2.515625,
      -2.078125,
      3.375,
      -0.0498046875,
      2.34375,
      -2.625,
      -3.125,
      0.435546875,
      -0.23046875,
      -1.984375,
      -0.59375,
      -1.7734375,
      1.375,
      0.455078125,
      -3.953125,
      2.234375,
      7.5,
      0.2294921875,
      2.8125,
      1.7265625,
      2.625,
      -0.6953125,
      -9.125,
      -2.953125,
      -2.078125,
      2.046875,
      2.4375,
      2.3125,
      -8.125,
      3.40625,
      2.390625,
      -6.4375,
      1.0625,
      -3.5625,
      -6,
      1.78125,
      3.265625,
      -1.6953125,
      4.53125,
      3.703125,
      -0.279296875,
      9.25,
      -1.4765625,
      -5.84375,
      2.53125,
      3.09375,
      2.25,
      -0.08642578125,
      -1.0234375,
      2.09375,
      -0.375,
      1.7578125,
      -0.73046875,
      -3.421875,
      -4.28125,
      4.78125,
      -2.515625,
      -0.033447265625,
      -0.55078125,
      15.5,
      6.34375,
      -2.40625,
      -2.15625,
      4.21875,
      -3.5,
      5.53125,
      0.80859375,
      4.0625,
      -1.0546875,
      0.953125,
      -1.2734375,
      3.640625,
      -0.19140625,
      -0.96484375,
      2.875,
      -3.078125,
      3.15625,
      -1.25,
      0.44921875,
      2.421875,
      -0.734375,
      0.8828125,
      -7.0625,
      -2.359375,
      2.234375,
      0.67578125,
      -2.546875,
      4.375,
      3.390625,
      -6.65625,
      0.09521484375,
      -2.265625,
      -3.796875,
      -0.96484375,
      3.09375,
      -0.796875,
      3.203125,
      -1.921875,
      -0.2080078125,
      1.5546875,
      6.34375,
      0.703125,
      7.3125,
      1.6484375,
      8.0625,
      -3.34375,
      2.53125,
      0.1494140625,
      2.984375,
      4.5625,
      1.1796875,
      -1.296875,
      -0.6875,
      3.125,
      1.984375,
      4.90625,
      5.03125,
      9.5,
      -0.37109375,
      -0.359375,
      3.4375,
      2.625,
      -1.7109375,
      -2.578125,
      -3.25,
      2.375,
      -0.8125,
      3.015625,
      -2.65625,
      -2.75,
      -0.53515625,
      4.4375,
      1.6640625,
      1.546875,
      -3.859375,
      -5.625,
      -4.21875,
      -7.71875,
      -1.046875,
      2.171875,
      -5.65625,
      -4.1875,
      5.4375,
      7.15625,
      -1.171875,
      1.078125,
      -0.37890625,
      -3.484375,
      4.1875,
      -3.03125,
      -7.84375,
      3.5625,
      1.390625,
      -6.09375,
      5.0625,
      -0.61328125,
      3.96875,
      2.546875,
      4.78125,
      -2.484375,
      0.53515625,
      -2.25,
      -0.455078125,
      5.4375,
      4.1875,
      -6.125,
      3.109375,
      -0.8203125,
      -4.0625,
      -5.03125,
      6.8125,
      -6.21875,
      5.28125,
      -3.484375,
      -1.3984375,
      5.625,
      -2.25,
      12.1875,
      7.625,
      -2.265625,
      -0.341796875,
      -2.125,
      -6.84375,
      2.453125,
      -4.15625,
      1,
      -4.59375,
      0.9921875,
      4.71875,
      1.7421875,
      -2.890625,
      2.640625,
      -2.515625,
      3.75,
      -2.109375,
      -1.2734375,
      -0.16015625,
      5.09375,
      2.71875,
      0.158203125,
      3.828125,
      -1.640625,
      -1.21875,
      -4.6875,
      -4.84375,
      -0.11279296875,
      1.71875,
      -4.65625,
      -3.578125,
      -4.65625,
      -1.5625,
      -0.796875,
      -4.625,
      -3.8125,
      2.296875,
      -2.15625,
      1.9609375,
      -2.953125,
      2.640625,
      3.296875,
      -5.25,
      -8.625,
      7.71875,
      -2.0625,
      1.8828125,
      7.46875,
      2.09375,
      2.953125,
      -5.03125,
      -3.296875,
      2.59375,
      -5.75,
      0.8984375,
      1.6171875,
      4.0625,
      -0.7109375,
      1.9453125,
      -3.78125,
      1.3203125,
      -0.7890625,
      2.28125,
      3.71875,
      5.90625,
      -0.87890625,
      0.1552734375,
      -0.83984375,
      0.44921875,
      -0.76171875,
      0.82421875,
      0.0208740234375,
      5.03125,
      1.75,
      -0.5,
      -4.625,
      -1.640625,
      2.5,
      0.28515625,
      -1.71875,
      3.15625,
      -1.828125,
      0.8515625,
      2.734375,
      2.546875,
      -0.67578125,
      -0.953125,
      -1.484375,
      -4.6875,
      0.89453125,
      -1.6484375,
      0.26953125,
      -0.58203125,
      3.078125,
      3.953125,
      3.125,
      -0.2138671875,
      5.78125,
      4.625,
      -2.953125,
      -1.1953125,
      1.4921875,
      -3.140625,
      -0.451171875,
      2.078125,
      1.171875,
      -2.9375,
      0.51953125,
      -1.8671875,
      3.296875,
      3.515625,
      -0.1640625,
      -0.73046875,
      1.9375,
      -5.125,
      -0.3984375,
      -1.34375,
      -1.046875,
      -0.7421875,
      -0.173828125,
      0.21875,
      1.53125,
      0.310546875,
      -2.125,
      -2.203125,
      0.7109375,
      -0.486328125,
      0.75,
      -4.8125,
      0.08642578125,
      -1.84375,
      2.578125,
      3.875,
      1.0703125,
      -1.2734375,
      2.84375,
      2.25,
      4.65625,
      2.625,
      0.412109375,
      -0.30859375,
      1.7109375,
      -4.5625,
      1.1875,
      -2.546875,
      -1.0546875,
      4.0625,
      -1.28125,
      -1.28125,
      -2.4375,
      -0.2216796875,
      -1.59375,
      3.78125,
      3.65625,
      0.2333984375,
      0.7578125,
      1.15625,
      4.625,
      -2.078125,
      -4.34375,
      -3.09375,
      -0.96484375,
      -1.6640625,
      1.4140625,
      -3.34375,
      0.201171875,
      -4.78125,
      1.5234375,
      3.5625,
      -1.09375,
      -0.53125,
      -2.84375,
      -0.90234375,
      2.203125,
      3.515625,
      1.3515625,
      1.125,
      2.53125,
      5.90625,
      -8.75,
      -10.8125,
      4.65625,
      0.41796875,
      -2.46875,
      -3.34375,
      1.8125,
      -2.421875,
      1.765625,
      -4.5,
      -3.3125,
      -2.515625,
      -3.234375,
      6.03125,
      0.66796875,
      1.8828125,
      -1.78125,
      -4.5625,
      6.1875,
      1.3984375,
      4.15625,
      -2.84375,
      2.765625,
      5.15625,
      -5.40625,
      4.9375,
      1.9921875,
      6.46875,
      -4.375,
      -0.60546875,
      4.78125,
      -8.375,
      0.66015625,
      -1.03125,
      1.046875,
      -3.15625,
      0.18359375,
      4.09375,
      -5.375,
      -2.890625,
      -1.625,
      7.28125,
      -3.125,
      -0.97265625,
      1.421875,
      -3.484375,
      -4.25,
      0.0269775390625,
      1.4140625,
      6.5625,
      -0.0322265625,
      -0.70703125,
      2.609375,
      -3.78125,
      0.8984375,
      1.359375,
      -4.6875,
      -1.7109375,
      -0.05322265625,
      2.546875,
      2.640625,
      1.6015625,
      1.1875,
      0.5546875,
      -2.90625,
      0.380859375,
      -0.59765625,
      -1.171875,
      -0.6015625,
      0.1396484375,
      5.15625,
      1.5390625,
      4.125,
      -6.90625,
      1,
      -0.4921875,
      0.50390625,
      -1.5,
      -2.015625,
      0.64453125,
      2.375,
      1.9765625,
      1.9765625,
      -3.53125,
      0.419921875,
      -0.94140625,
      -2.09375,
      -4.03125,
      1.03125,
      2.25,
      -4.09375,
      0.55078125,
      -5.65625,
      -0.0074462890625,
      5.21875,
      1.9375,
      -3.234375,
      2.40625,
      4.5,
      1.4375,
      2.171875,
      0.2734375,
      3.328125,
      -4.15625,
      -2.421875,
      -0.251953125,
      2,
      -5.5625,
      -5.78125,
      -3.171875,
      4.34375,
      7.8125,
      -3.609375,
      2.109375,
      -2.90625,
      6.1875,
      -0.1748046875,
      1.2578125,
      -17.125,
      0.34765625,
      -0.32421875,
      -5.125,
      -3.625,
      -3.875,
      3.484375,
      -4.9375,
      0.8671875,
      1.015625,
      -1.109375,
      1.328125,
      3.484375,
      -0.765625,
      -0.41015625,
      7.03125,
      1.7578125,
      0.474609375,
      0.73828125,
      -1.8671875,
      -4.8125,
      -1.890625,
      -2,
      -0.2578125,
      3.4375,
      1.78125,
      1.125,
      2.09375,
      2.96875,
      -4.96875,
      3.65625,
      3.890625,
      1.171875,
      -4.21875,
      -2.84375,
      -3.140625,
      1.3515625,
      -3.984375,
      3.40625,
      -0.349609375,
      -2.09375,
      2.3125,
      8.25,
      -3.421875,
      -5.34375,
      2.21875,
      -0.953125,
      2.734375,
      3.234375,
      -5.53125,
      3.546875,
      0.48828125,
      0.57421875,
      2.578125,
      -1.1796875,
      -1.8203125,
      -2.40625,
      3.828125,
      0.83984375,
      0.8515625,
      5.0625,
      -1.3125,
      -3.859375,
      -1.3359375,
      1.4765625,
      -2.65625,
      2.46875,
      2.59375,
      0.55078125,
      -0.353515625,
      1.5703125,
      2.578125,
      1.0234375,
      -3.34375,
      -4,
      -0.68359375,
      -8.3125,
      4.75,
      2.546875,
      1.9296875,
      -1.171875,
      -3.796875,
      3.90625,
      2.359375,
      -0.56640625,
      1.5078125,
      4.625,
      5.125,
      -3.78125,
      2.28125,
      -3.203125,
      -1.4140625,
      2.03125,
      -2.546875,
      -1.421875,
      2.296875,
      0.5390625,
      1.1875,
      -0.94140625,
      -1.9140625,
      -2.953125,
      -4.03125,
      -3.234375,
      2.125,
      0.498046875,
      3.875,
      -4.78125,
      5.65625,
      -1.5234375,
      -1.5,
      0.451171875,
      -1.046875,
      -0.353515625,
      -3.375,
      2.984375,
      -4.3125,
      -2.125,
      4.78125,
      -0.84375,
      -4.46875,
      5.90625,
      1.0625,
      -2.359375,
      -4.375,
      3.09375,
      -1.1015625,
      -1.0390625,
      2.984375,
      -3.59375,
      0.466796875,
      -6.09375,
      -2.03125,
      -4.6875,
      6.0625,
      -1.359375,
      1.0390625,
      -1.9609375,
      -3.359375,
      -3.671875,
      0.0654296875,
      -2.828125,
      -0.8515625,
      4.03125,
      -0.2236328125,
      -2.53125,
      1.390625,
      0.9453125,
      0.0281982421875,
      -0.87109375,
      -0.2236328125,
      4.375,
      2.203125,
      2.6875,
      -4.875,
      -1.8828125,
      -0.3359375,
      -1.4921875,
      -3.984375,
      3.671875,
      -1.375,
      -0.87109375,
      3.515625,
      1.9765625,
      -2.234375,
      -3.75,
      1.4609375,
      -5.96875,
      0.54296875,
      -0.546875,
      3.171875,
      1.7109375,
      0.8203125,
      -1.796875,
      -5.125,
      -4.28125,
      3.671875,
      1.3203125,
      -0.5859375,
      -3.359375,
      3.625,
      -5.1875,
      0.83984375,
      -8.25,
      -6.8125,
      0.04052734375,
      -2.203125,
      0.06787109375,
      0.431640625,
      8.125,
      -1.09375,
      1.578125,
      -4.65625,
      0.98828125,
      1.1640625,
      0.41796875,
      1.78125,
      1.375,
      2.796875,
      0.423828125,
      1.125,
      0.69921875,
      -1.0234375,
      0.6875,
      -3.90625,
      0.357421875,
      1.5703125,
      2.71875,
      2.515625,
      2.171875,
      -1.046875,
      -2.546875,
      -0.9453125,
      6.09375,
      3.375,
      -2.78125,
      0.279296875,
      -2.625,
      2.375,
      -5.3125,
      4.09375,
      -0.2158203125,
      11.875,
      -4.6875,
      -3.578125,
      3.625,
      0.138671875,
      -0.86328125,
      4.5,
      -4.78125,
      -3.59375,
      -0.447265625,
      2.53125,
      -3.78125,
      -0.375,
      -6.15625,
      -1.7109375,
      1.984375,
      1.84375,
      4.03125,
      3.140625,
      4.8125,
      1.4765625,
      -0.41796875,
      -5.03125,
      -4.125,
      -1.765625,
      -0.050537109375,
      -2.078125,
      -3.875,
      0.6015625,
      2.015625,
      4.75,
      -3.125,
      0.3671875,
      -2.859375,
      4.53125,
      -0.28125,
      -1.0078125,
      4.78125,
      -1.6484375,
      3.375,
      1.8125,
      0.62890625,
      -2.0625,
      -2.953125,
      7.09375,
      3.171875,
      -3.6875,
      1.75,
      -4,
      1.6015625,
      -2.84375,
      0.439453125,
      1.328125,
      -1.1640625,
      -1.109375,
      -2.3125,
      3.25,
      -1.453125,
      -3.5625,
      4.46875,
      -0.216796875,
      -4.71875,
      1.8671875,
      3.75,
      0.859375,
      1.6640625,
      -1.4296875,
      3.859375,
      -1.2421875,
      -5.125,
      -3.15625,
      -7.03125,
      -0.9375,
      0.71484375,
      -0.8828125,
      3.890625,
      3.78125,
      -3.75,
      1.875,
      -3.203125,
      1.4609375,
      -1.8125,
      4.96875,
      0.93359375,
      -6.40625,
      0.91796875,
      -5.9375,
      -4.5,
      -6.0625,
      -1.3046875,
      -2.96875,
      0.09423828125,
      -2.859375,
      -2.015625,
      0.203125,
      -3.640625,
      -0.05224609375,
      -3.21875,
      -0.4140625,
      1.828125,
      -2.15625,
      4.03125,
      -4.5,
      3.203125,
      0.828125,
      0.30859375,
      3.78125,
      -2.265625,
      -0.67578125,
      4.5,
      -2.3125,
      0.74609375,
      -0.625,
      6.75,
      -5.3125,
      6.625,
      2.1875,
      4.8125,
      -5.34375,
      5.03125,
      1.734375,
      3.328125,
      -4.15625,
      2.875,
      1.0703125,
      0.890625,
      2.265625,
      -1.484375,
      2.375,
      -3.859375,
      -3.78125,
      -0.81640625,
      -1.234375,
      0.41015625,
      4.09375,
      -0.43359375,
      1.1015625,
      -0.494140625,
      0.25390625,
      -0.45703125,
      0.51953125,
      -2.03125,
      -0.047607421875,
      2.125,
      -1.0546875,
      4.96875,
      -0.047119140625,
      2.40625,
      3.328125,
      -4.03125,
      1.859375,
      0.79296875,
      2.390625,
      4.90625,
      3.703125,
      -0.119140625,
      1.578125,
      3.8125,
      -0.373046875,
      -1.40625,
      -0.2578125,
      -4.84375,
      5.34375,
      -0.06982421875,
      -1.3359375,
      -2.40625,
      0.06787109375,
      -0.640625,
      2.390625,
      1.171875,
      -5.21875,
      -1.8828125,
      4.84375,
      -3.265625,
      2.203125,
      -1.046875,
      0.4453125,
      1.7421875,
      -0.80859375,
      4.96875,
      2.609375,
      -0.640625,
      3.484375,
      4.21875,
      -1.7890625,
      1.25,
      -2.140625,
      -0.11181640625,
      1.75,
      3.78125,
      3.09375,
      -1.1015625,
      1.0625,
      -3.640625,
      0.035888671875,
      3.890625,
      -1.1796875,
      3.15625,
      5.03125,
      -1.9140625,
      -0.337890625,
      -2.90625,
      -3.453125,
      1.609375,
      -2.625,
      1.8671875,
      7.0625,
      8.3125,
      -4.65625,
      -2.234375,
      -2.765625,
      -5.4375,
      0.5546875,
      0.36328125,
      0.82421875,
      -0.58203125,
      0.59375,
      0.65625,
      -1.4140625,
      -2.28125,
      0.328125,
      -4.28125,
      0.9453125,
      2.875,
      -2.734375,
      -1.4453125,
      0.0281982421875,
      -0.34375,
      -0.07177734375,
      0.1611328125,
      1.296875,
      -0.12890625,
      3.53125,
      -0.345703125,
      1.21875,
      2.515625,
      1.65625,
      2.21875,
      2.734375,
      -2.109375,
      -0.2080078125,
      0.431640625,
      -1.609375,
      -0.44921875,
      -0.416015625,
      -0.11572265625,
      4.03125,
      -0.33203125,
      0.34375,
      6,
      1.1796875,
      1.75,
      3.953125,
      -3.15625,
      -5.46875,
      -1.2734375,
      0.9609375,
      -1.25,
      0.90234375,
      -2.375,
      0.9140625,
      3.4375,
      -0.234375,
      4.40625,
      -3.75,
      9.125,
      2.734375,
      -1.15625,
      -0.8828125,
      -1.578125,
      3.0625,
      -1.4296875,
      0.60546875,
      -1.1015625,
      -6.0625,
      1.2109375,
      -1.9140625,
      4.65625,
      -0.244140625,
      -0.0179443359375,
      5.625,
      1.5078125,
      -0.8359375,
      -4.625,
      -0.60546875,
      -6.40625,
      -4.21875,
      -1.1953125,
      -0.953125,
      -0.5546875,
      -2.6875,
      -1.171875,
      2.171875,
      4.8125,
      -4.78125,
      0.52734375,
      -1.5546875,
      -1.375,
      -0.1494140625,
      -0.6171875,
      4.21875,
      4.4375,
      -2.796875,
      1.3828125,
      -6.125,
      -4.09375,
      -2.125,
      -0.8984375,
      3.953125,
      -0.75390625,
      -1.234375,
      -0.9140625,
      -1.1875,
      -3.109375,
      -0.609375,
      -4.40625,
      1.046875,
      3.90625,
      0.87109375,
      1.9453125,
      0.5703125,
      -1.3984375,
      -1.390625,
      -1.9375,
      -7.09375,
      2.671875,
      4.1875,
      -3.171875,
      3.796875,
      -0.53125,
      3.8125,
      0.1533203125,
      1.453125,
      0.859375,
      -0.54296875,
      3.359375,
      -2.140625,
      -2.828125,
      3.90625,
      2.421875,
      -1.1484375,
      -0.5078125,
      -1.21875,
      -4.4375,
      -0.3359375,
      -0.67578125,
      1.4765625,
      -1.75,
      1.328125,
      -0.41015625,
      -1.8203125,
      -2.34375,
      0.1728515625,
      8.25,
      1.890625,
      5.59375,
      6.59375,
      -1.9609375,
      -2,
      -0.1767578125,
      -3.65625,
      3.234375,
      0.296875,
      -3.984375,
      1.109375,
      0.0301513671875,
      4.75,
      -0.361328125,
      -3.03125,
      -3.03125,
      2.59375,
      4.5625,
      2.09375,
      -0.25,
      0.28515625,
      -1.546875,
      0.234375,
      -0.02978515625,
      -0.08251953125,
      -3.890625,
      -1.421875,
      -1.0859375,
      4.96875,
      2.125,
      -7.90625,
      0.154296875,
      3.96875,
      -1.59375,
      2.859375,
      0.322265625,
      6.59375,
      -1.1171875,
      3.609375,
      -3.109375,
      -1.9296875,
      -3.765625,
      5.1875,
      0.30859375,
      -2.453125,
      -3.28125,
      -5.21875,
      -3.765625,
      -1.0703125,
      1.8203125,
      3.109375,
      -0.166015625,
      1.65625,
      -2.9375,
      6.09375,
      1.3984375,
      -1.1875,
      1.796875,
      0.8828125,
      -0.49609375,
      -3.8125,
      -1.09375,
      -4.375,
      1.703125,
      -0.65234375,
      -9.8125,
      0.306640625,
      5.4375,
      2.875,
      0.75390625,
      1.625,
      0.2197265625,
      -1.421875,
      -2.90625,
      0.205078125,
      -0.8203125,
      -0.81640625,
      0.78515625,
      -0.4140625,
      -1.359375,
      6.6875,
      -1.234375,
      1.46875,
      -2.953125,
      4.78125,
      -0.734375,
      3.75,
      2.96875,
      3.109375,
      -7.96875,
      0.69921875,
      -2.015625,
      3.171875,
      -1.5859375,
      0.6640625,
      -2.09375,
      0.5625,
      4.5625,
      -0.6640625,
      -2.625,
      -1.78125,
      -1.8046875,
      3.578125,
      0.94140625,
      2.40625,
      -4.1875,
      3.71875,
      -3.9375,
      0.65234375,
      -1.03125,
      -2.484375,
      -0.9765625,
      0.3671875,
      1.0703125,
      2.125,
      2.375,
      -2.296875,
      -3.03125,
      2.203125,
      -1.2578125,
      -3.96875,
      -5.03125,
      1.765625,
      1.0703125,
      0.447265625,
      3.0625,
      -3.6875,
      5.21875,
      -3.703125,
      -0.875,
      2.4375,
      -3.40625,
      3.8125,
      6.125,
      5.5625,
      1.4296875,
      2.34375,
      -2.25,
      2.453125,
      1.1875,
      1.984375,
      2.46875,
      0.408203125,
      -0.69140625,
      -5.1875,
      2.921875,
      1.5234375,
      -1.09375,
      2.71875,
      2.84375,
      -6.96875,
      0.390625,
      3.125,
      3.953125,
      -3.640625,
      -5.5625,
      2.359375,
      5.75,
      -3.890625,
      1.3046875,
      -3.84375,
      2.4375,
      3.859375,
      -1.609375,
      4.625,
      2.078125,
      4.09375,
      -6.21875,
      -2.625,
      1,
      3.453125,
      0.2158203125,
      -4.21875,
      -2.421875,
      4.03125,
      0.640625,
      3.25,
      -2.28125,
      0.09765625,
      2.15625,
      4.59375,
      -4.0625,
      -2.921875,
      -5.125,
      0.2138671875,
      -2.0625,
      2.625,
      1.5859375,
      -0.1015625,
      1.6328125,
      4.15625,
      -2.46875,
      -1.6015625,
      -3.734375,
      -3.03125,
      -1.1875,
      -3.21875,
      -4.875,
      0.359375,
      -2.21875,
      1.578125,
      7.5625,
      7.84375,
      2.890625,
      -2.96875,
      -1.6484375,
      0.09326171875,
      -1.515625,
      -5.125,
      -0.77734375,
      -0.65625,
      -1.2421875,
      4.8125,
      -0.244140625,
      -0.90625,
      -4.5,
      0.3359375,
      -2.71875,
      0.064453125,
      1.203125,
      -0.294921875,
      -4.625,
      -2.40625,
      0.8671875,
      -0.57421875,
      4.625,
      3.46875,
      -3.578125,
      -1.890625,
      0.5625,
      -4.125,
      4.25,
      3.96875,
      -0.93359375,
      -0.61328125,
      7.4375,
      3.3125,
      -0.625,
      1.90625,
      -0.04638671875,
      1.59375,
      -3.625,
      4.9375,
      3.1875,
      1.5390625,
      0.796875,
      2.046875,
      1.796875,
      1.609375,
      5.03125,
      2.671875,
      3.921875,
      0.625,
      3.21875,
      -2.765625,
      -3.984375,
      0.859375,
      3.484375,
      1.1484375,
      -4.3125,
      1.1640625,
      1.5078125,
      2.25,
      1.5703125,
      1.4296875,
      1.9609375,
      3.078125,
      -4,
      2.21875,
      -7.34375,
      2.53125,
      -4.6875,
      1.140625,
      -6.625,
      0.314453125,
      3.71875,
      3.921875,
      0.96484375,
      -1.6875,
      -1.703125,
      1.09375,
      -0.55078125,
      -3.0625,
      3.765625,
      0.02978515625,
      0.2255859375,
      -1.734375,
      -2.59375,
      4.28125,
      1.1171875,
      -2.609375,
      -1.78125,
      -2.015625,
      -0.69140625,
      -3.125,
      -5.375,
      6.03125,
      1.71875,
      -5.9375,
      -6.96875,
      -3.609375,
      1.1875,
      -3.59375,
      0.78125,
      2.671875,
      -2.390625,
      3.96875,
      0.12158203125,
      2.890625,
      3.1875,
      0.72265625,
      0.4609375,
      0.7890625,
      0.61328125,
      -0.84375,
      1.7265625,
      -2.15625,
      -0.388671875,
      -3.21875,
      1.5234375,
      -0.9921875,
      -2.09375,
      -0.73828125,
      -6.09375,
      -4.5625,
      1.578125,
      0.115234375,
      5.25,
      0.296875,
      0.6484375,
      1.1171875,
      -3.4375,
      -2.8125,
      4.75,
      2.375,
      -1,
      0.47265625,
      -1.890625,
      3.65625,
      1.3203125,
      1.5625,
      -0.146484375,
      1.0078125,
      -3.140625,
      -4.125,
      -3.234375,
      2.171875,
      -3.203125,
      3.75,
      -0.625,
      -1.9453125,
      1.8984375,
      3.578125,
      0.326171875,
      1.65625,
      -0.7734375,
      0.85546875,
      0.82421875,
      0.921875,
      0.953125,
      -4.65625,
      2.0625,
      0.109375,
      -2.78125,
      0.271484375,
      -1.125,
      0.2734375,
      3.015625,
      -6.4375,
      0.6328125,
      -1.375,
      0.96484375,
      -2.765625,
      -11.5,
      -5.03125,
      -2.71875,
      -0.1826171875,
      -3.34375,
      1.6875,
      4.4375,
      2.859375,
      -0.7578125,
      4.25,
      -1.875,
      -2.921875,
      3.484375,
      13.3125,
      -1.546875,
      -1.859375,
      0.60546875,
      -0.1630859375,
      4.71875,
      5.8125,
      1.984375,
      -3.265625,
      1.59375,
      -1.234375,
      1.734375,
      -0.4765625,
      3.859375,
      -2.984375,
      -0.8828125,
      -0.82421875,
      -2.015625,
      -4.0625,
      -3.421875,
      -0.267578125,
      -2.6875,
      1.171875,
      3.9375,
      1.8671875,
      4.5625,
      4.46875,
      -0.486328125,
      -1.4765625,
      -1.078125,
      -4.46875,
      -2.8125,
      -0.32421875,
      -5.59375,
      3.78125,
      -4.28125,
      1.8671875,
      0.7578125,
      -1.296875,
      -2.53125,
      -2,
      -3.953125,
      2.890625,
      -3.65625,
      -0.1328125,
      -2.453125,
      -3.171875,
      -1.890625,
      2.296875,
      -2.015625,
      -0.99609375,
      -3.78125,
      -1.6796875,
      -1.125,
      -4.03125,
      -4.21875,
      -0.34765625,
      -7.8125,
      -5.0625,
      -2.9375,
      -0.734375,
      -0.341796875,
      -2.984375,
      0.7734375,
      -0.298828125,
      -4.28125,
      -0.75,
      0.1396484375,
      5.3125,
      -2.625,
      -2.71875,
      1.28125,
      4.125,
      1.296875,
      1.453125,
      -1.109375,
      4.40625,
      2.3125,
      -1.0078125,
      1.6875,
      -1.8046875,
      0.4921875,
      -5.59375,
      1.5234375,
      -0.08642578125,
      0.96875,
      -5.03125,
      1.0234375,
      -1.328125,
      0.2177734375,
      9.8125,
      -6.0625,
      3.96875,
      2.859375,
      -5.90625,
      -0.470703125,
      -1.2265625,
      0.6328125,
      -0.494140625,
      -4.25,
      2.53125,
      1.1953125,
      -2.625,
      0.498046875,
      3.6875,
      0.9453125,
      1.265625,
      0.039306640625,
      1.8984375,
      0.421875,
      0.0272216796875,
      5.84375,
      -0.8671875,
      0.71875,
      -1.1640625,
      -0.359375,
      -0.80078125,
      -1.03125,
      -0.11181640625,
      -1.7734375,
      4.71875,
      1.671875,
      0.470703125,
      -2.390625,
      -6.1875,
      -0.74609375,
      -0.69921875,
      -6.09375,
      4.125,
      -3.6875,
      -0.796875,
      -0.470703125,
      -2.546875,
      -2.390625,
      -2.390625,
      -9.125,
      2.265625,
      4.96875,
      1.828125,
      0.1689453125,
      -3.875,
      -1.203125,
      0.240234375,
      -1.0390625,
      2.09375,
      2.0625,
      -5.3125,
      -0.423828125,
      1.9453125,
      2.28125,
      -5.3125,
      4.40625,
      0.44921875,
      -3.765625,
      -1.34375,
      3.75,
      -3.03125,
      -1.6953125,
      -5.125,
      0.302734375,
      0.6171875,
      -4.34375,
      -6.59375,
      -4.5,
      -2.90625,
      1.4609375,
      5.28125,
      -1.8984375,
      -3.34375,
      4.53125,
      1.5546875,
      -5.96875,
      0.314453125,
      -1.71875,
      1.0625,
      -4.8125,
      0.640625,
      3.859375,
      3.3125,
      -1.5,
      3.90625,
      -0.6171875,
      -1.21875,
      -2.453125,
      -0.5078125,
      4.25,
      -1.328125,
      0.17578125,
      4.28125,
      -4.3125,
      0.357421875,
      -1.3125,
      -2.328125,
      5.40625,
      -0.030029296875,
      -2.46875,
      -1.109375,
      0.72265625,
      3.65625,
      -1.6875,
      -1.578125,
      3.671875,
      1.0859375,
      2.203125,
      3.171875,
      -1.8046875,
      -3.796875,
      0.62890625,
      -4.6875,
      -1.4375,
      -3.125,
      4.375,
      3.328125,
      -0.1572265625,
      -4.15625,
      7.75,
      1.8984375,
      1.328125,
      2.125,
      3.96875,
      5.78125,
      0.3671875,
      -4.3125,
      0.365234375,
      2.1875,
      4.40625,
      -7.625,
      2.625,
      -2.6875,
      0.83984375,
      -2.421875,
      1.9296875,
      -2.0625,
      -1.1796875,
      -3.6875,
      -4.5,
      -2.28125,
      -0.96484375,
      -0.84375,
      1.234375,
      1.5390625,
      0.984375,
      -0.166015625,
      0.65234375,
      -2.953125,
      3.28125,
      -2.6875,
      1.5390625,
      0.42578125,
      -2.015625,
      3.359375,
      1.6796875,
      2.796875,
      0.392578125,
      1.671875,
      -1.609375,
      -2.4375,
      0.31640625,
      -3.140625,
      2.9375,
      1.4296875,
      -7,
      0.984375,
      -2.109375,
      -1.0703125,
      -0.68359375,
      1.1953125,
      -2.9375,
      4.28125,
      0.50390625,
      -2.96875,
      2.46875,
      0.9921875,
      -3,
      -0.68359375,
      0.578125,
      -1.7421875,
      -2.265625,
      0.79296875,
      1.0625,
      -3,
      -1.5234375,
      2.328125,
      -1.640625,
      1.3515625,
      -1.9609375,
      1.171875,
      -1.796875,
      0.7734375,
      2.96875,
      1.375,
      1.0703125,
      -4.53125,
      0.52734375,
      -2.203125,
      1.0078125,
      -0.412109375,
      -1.5625,
      1.3046875,
      -1.0078125,
      2.859375,
      3.625,
      3.609375,
      -7.28125,
      -1.390625,
      0.5,
      1.75,
      1.890625,
      2.59375,
      1.6796875,
      -0.443359375,
      -1.015625,
      1.0625,
      0.25390625,
      0.67578125,
      -2.359375,
      -4.0625,
      1.984375,
      2.921875,
      -3.796875,
      -1.59375,
      0.2451171875,
      1.8828125,
      1.7734375,
      -1.078125,
      -0.5546875,
      -1.09375,
      4.6875,
      -5.21875,
      2.71875,
      2.34375,
      3.296875,
      1.328125,
      0.8515625,
      -2.640625,
      2.65625,
      -1.140625,
      -6.09375,
      -2.84375,
      1.0234375,
      2.390625,
      2.875,
      -0.78515625,
      4.96875,
      0.1650390625,
      3.28125,
      -3.390625,
      6.21875,
      1.5625,
      -6.34375,
      4.71875,
      -0.3671875,
      -0.5078125,
      -4.34375,
      -5.65625,
      -1.6171875,
      5,
      -1.2265625,
      -0.5078125,
      2.140625,
      2.375,
      -1.9609375,
      3.421875,
      -0.875,
      0.46875,
      1.0859375,
      -2.21875,
      -2.90625,
      -1.34375,
      3.75,
      -2.40625,
      -1.171875,
      -1.609375,
      2.09375,
      -1.078125,
      0.22265625,
      2.953125,
      5.375,
      4.3125,
      0.671875,
      -7.90625,
      1.59375,
      -3.4375,
      1.1640625,
      -1.75,
      -1.2734375,
      -0.435546875,
      -3.90625,
      -3.03125,
      3.21875,
      -6.5625,
      -0.265625,
      -3.953125,
      -3.453125,
      0.55859375,
      0.7578125,
      2.59375,
      -0.06298828125,
      1.5546875,
      0.98828125,
      1.765625,
      -1.75,
      -4.15625,
      -0.052490234375,
      -4.90625,
      -1.171875,
      -0.2373046875,
      2.84375,
      -4.53125,
      -3.53125,
      3.078125,
      0.73828125,
      2.234375,
      -3.828125,
      -1.015625,
      2.21875,
      3.40625,
      -0.27734375,
      -1.4609375,
      -0.255859375,
      -0.3359375,
      -0.5546875,
      -6.3125,
      0.6484375,
      0.796875,
      0.373046875,
      -0.50390625,
      -4.875,
      -1.3203125,
      -0.4140625,
      0.53125,
      0.91796875,
      0.158203125,
      -0.09619140625,
      0.392578125,
      -6.0625,
      1.3515625,
      1.6640625,
      0.71484375,
      2.625,
      -1.515625,
      0.28515625,
      -4.5,
      3.8125,
      5.1875,
      -1.3828125,
      -1.390625,
      -0.0272216796875,
      1.109375,
      -2.640625,
      -1.1328125,
      0.62109375,
      0.6953125,
      -8.4375,
      6.3125,
      0.7265625,
      3.46875,
      -0.4453125,
      -0.55078125,
      4.1875,
      -0.9375,
      4.21875,
      0.86328125,
      -2.46875,
      4.53125,
      -2.640625,
      1.578125,
      -1.515625,
      -1.8359375,
      -0.69921875,
      0.73828125,
      -1.328125,
      -2.09375,
      3.0625,
      -1.8984375,
      2.515625,
      -2.5,
      -3.140625,
      2.546875,
      -4.25,
      -3.28125,
      -0.68359375,
      -0.90625,
      1.6328125,
      -2.765625,
      1.9609375,
      -5.40625,
      -1.4140625,
      1.6640625,
      -1.0859375,
      -2.09375,
      4.15625,
      -2.375,
      -4.40625,
      -1.015625,
      1.8828125,
      0.6875,
      3.296875,
      -0.62109375,
      5,
      -0.5234375,
      -3.171875,
      1.015625,
      3.65625,
      2.59375,
      -0.050537109375,
      2.640625,
      0.9140625,
      0.86328125,
      -4.375,
      -2.09375,
      1.4609375,
      -0.08984375,
      2.796875,
      1.640625,
      0.126953125,
      0.56640625,
      -0.349609375,
      -2.0625,
      1.078125,
      2.5,
      -2.359375,
      0.81640625,
      -2.65625,
      2.6875,
      2.796875,
      -0.75390625,
      1.484375,
      -1.375,
      3.515625,
      4.09375,
      -3.015625,
      2.875,
      0.734375,
      -0.263671875,
      -0.1455078125,
      0.041015625,
      0.9296875,
      -3.296875,
      1.4375,
      -0.78515625,
      1.1953125,
      5.875,
      -0.302734375,
      -1.703125,
      3.40625,
      3.0625,
      -3,
      0.48828125,
      1.265625,
      1.34375,
      -1.375,
      0.50390625,
      1.109375,
      1.4921875,
      -1.9296875,
      1.1796875,
      -2.671875,
      2.0625,
      -1.4296875,
      1.5859375,
      1.6484375,
      -0.7265625,
      2.109375,
      1.8359375,
      -0.40234375,
      -3.234375,
      0.75,
      -0.29296875,
      5.90625,
      -1.7421875,
      -1.171875,
      -3.25,
      3.4375,
      -0.66015625,
      2.1875,
      4.9375,
      -1.9609375,
      2.359375,
      0.75390625,
      2.859375,
      -0.158203125,
      -1.953125,
      -3.265625,
      -0.90625,
      0.1396484375,
      0.1826171875,
      -0.5546875,
      -1.2890625,
      -3.34375,
      1.2734375,
      0.353515625,
      -1.1796875,
      -2.859375,
      2.171875,
      0.41015625,
      -1.4765625,
      0.9921875,
      1.9609375,
      -0.0869140625,
      1.7109375,
      0.953125,
      1.4609375,
      0.19921875,
      -3.375,
      1.78125,
      2.71875,
      0.78125,
      0.212890625,
      -1.375,
      3.328125,
      -0.10546875,
      -0.0036773681640625,
      -1.1484375,
      0.1240234375,
      -1.859375,
      -3.921875,
      0.66015625,
      1.4140625,
      -2.171875,
      1.46875,
      1.671875,
      0.7734375,
      0.58984375,
      -1.78125,
      2.828125,
      -1.421875,
      -4.375,
      1.1171875,
      -0.42578125,
      2.421875,
      -2.21875,
      0.1826171875,
      -3.578125,
      -2.40625,
      -1.703125,
      0.107421875,
      -1.859375,
      4.21875,
      0.5,
      1.375,
      -2.53125,
      -0.251953125,
      -1.578125,
      -1.7109375,
      1.453125,
      3.296875,
      -1.140625,
      -2.28125,
      1.3515625,
      0.384765625,
      -0.369140625,
      -4.46875,
      1.8046875,
      -1.0078125,
      2.0625,
      -3.390625,
      2,
      1.609375,
      -1.2109375,
      -0.5078125,
      0.828125,
      -1.7890625,
      4.53125,
      -2.625,
      2.671875,
      -1.734375,
      1.5703125,
      0.345703125,
      -1,
      -3.796875,
      -1.3828125,
      -2.15625,
      -0.330078125,
      -3.4375,
      2.203125,
      2.421875,
      -0.419921875,
      0.53125,
      1.9453125,
      1.875,
      0.44140625,
      -0.96875,
      -0.146484375,
      1.5703125,
      0.03759765625,
      3.1875,
      -2.125,
      0.466796875,
      -1.1640625,
      -0.50390625,
      -0.85546875,
      -3.171875,
      5.0625,
      1.015625,
      -1.078125,
      2.5,
      2.015625,
      -0.1708984375,
      0.18359375,
      1.3828125,
      3.625,
      -1.140625,
      1.7421875,
      -1.53125,
      3.28125,
      -1.3359375,
      0.453125,
      -0.33984375,
      1.09375,
      0.369140625,
      1.609375,
      1.2265625,
      -1.6328125,
      0.23046875,
      0.5703125,
      -1.71875,
      -0.8203125,
      1.921875,
      -3.546875,
      -2.9375,
      2.921875,
      -1.8671875,
      -1.546875,
      3.484375,
      -2.765625,
      -0.30859375,
      -1.1171875,
      -1.8359375,
      0.1083984375,
      2.171875,
      1.1484375,
      -1.578125,
      -0.63671875,
      -1.109375,
      2.3125,
      -0.2255859375,
      -3.75,
      0.87890625,
      -0.26171875,
      -1.4921875,
      2.171875,
      0.154296875,
      -0.294921875,
      -0.296875,
      -1.234375,
      -1.2265625,
      -0.087890625,
      4.125,
      1.53125,
      -0.1962890625,
      -1.859375,
      -4.875,
      -0.396484375,
      -0.7421875,
      -2.78125,
      -1.21875,
      3.28125,
      -0.46484375,
      -0.484375,
      -0.66796875,
      -0.423828125,
      1.75,
      1.5625,
      0.875,
      1.3515625,
      -0.875,
      -2.125,
      -2.4375,
      -3.5625,
      0.19140625,
      -0.443359375,
      0.7890625,
      0.51953125,
      -2.1875,
      0.734375,
      -1.8359375,
      -0.87890625,
      -2.078125,
      -1.6171875,
      -1.65625,
      1.046875,
      0.494140625,
      -2.984375,
      0.96484375,
      2.703125,
      4.84375,
      0.87109375,
      -3.21875,
      0.416015625,
      0.53125,
      2.46875,
      -0.1142578125,
      -2.375,
      0.8671875,
      -1.8125,
      -0.953125,
      -0.203125,
      1.4375,
      -0.1455078125,
      3.03125,
      3.796875,
      2.515625,
      2.828125,
      4.8125,
      1.1015625,
      -1.5546875,
      4.09375,
      -5,
      -0.96875,
      2.28125,
      -0.494140625,
      1.859375,
      2.53125,
      1.125,
      2.328125,
      0.1328125,
      -0.79296875,
      0.96484375,
      0.75,
      0.79296875,
      -4.4375,
      1.109375,
      -0.91015625,
      1.0859375,
      -0.0986328125,
      1.6171875,
      -1.3046875,
      -0.00994873046875,
      -1.203125,
      2.25,
      2.65625,
      0.60546875,
      3.109375,
      -5.46875,
      -2.46875,
      3.609375,
      0.90234375,
      -1.6875,
      -3.484375,
      1.8984375,
      -3.296875,
      0.034423828125,
      1.3671875,
      -0.55859375,
      -0.109375,
      -0.32421875,
      -3.953125,
      -0.380859375,
      -1.046875,
      -1.6015625,
      -0.67578125,
      -2.640625,
      0.494140625,
      -1.5546875,
      4.28125,
      -3.375,
      0.296875,
      -2.125,
      -0.6796875,
      4.40625,
      2.46875,
      1.4453125,
      2.21875,
      -0.6171875,
      -4.3125,
      1.609375,
      -3.71875,
      1.15625,
      -1.3671875,
      2.1875,
      1.203125,
      0.68359375,
      -2.90625,
      0.052001953125,
      -0.1630859375,
      -1,
      -0.578125,
      0.48828125,
      0.828125,
      -4.375,
      0.8828125,
      -0.251953125,
      0.90625,
      -0.36328125,
      -0.046875,
      -1.15625,
      -1.8828125,
      2.3125,
      -0.56640625,
      3.046875,
      2.15625,
      0.236328125,
      2.875,
      -0.73046875,
      -0.55859375,
      -2.421875,
      1.1015625,
      -0.828125,
      1.7265625,
      1.1484375,
      -1.125,
      3.34375,
      -2.34375,
      -0.302734375,
      1.0390625,
      1.3984375,
      -2.21875,
      2.390625,
      0.4765625,
      1.9375,
      -0.2578125,
      -2.890625,
      -1.109375,
      -0.5390625,
      -0.07666015625,
      1.8125,
      -4.84375,
      1.6875,
      -1.03125,
      -0.365234375,
      -2.40625,
      -3.8125,
      0.6328125,
      -1.640625,
      -3.28125,
      -0.1064453125,
      0.546875,
      -2.09375,
      -5.15625,
      1.0859375,
      -1.15625,
      -0.1474609375,
      -1.7578125,
      1.890625,
      3.203125,
      -1.21875,
      -3.984375,
      4.09375,
      -0.578125,
      -0.2470703125,
      4.0625,
      1.2734375,
      -0.064453125,
      3.359375,
      1.078125,
      4.375,
      -1.484375,
      0.90625,
      -2.5,
      -0.875,
      -1.328125,
      -1.1875,
      0.072265625,
      0.287109375,
      2.953125,
      -1.3671875,
      -0.1640625,
      1.015625,
      0.453125,
      1.0546875,
      2.609375,
      2.4375,
      0.79296875,
      -2.296875,
      -0.578125,
      2.875,
      2.40625,
      8.3125,
      0.08642578125,
      3.03125,
      1.3046875,
      -2.046875,
      -0.0869140625,
      0.169921875,
      -0.1708984375,
      -0.0286865234375,
      0.361328125,
      -3.171875,
      -0.4609375,
      -0.796875,
      2.8125,
      -1.0703125,
      4.65625,
      -1.0234375,
      1.71875,
      -3.78125,
      0.80859375,
      -0.578125,
      -0.40234375,
      1.1953125,
      -1.4296875,
      -2.125,
      -0.61328125,
      1.875,
      1.984375,
      -2.578125,
      0.5625,
      4.46875,
      0.87890625,
      0.44921875,
      -0.859375,
      -0.2373046875,
      0.9609375,
      1.15625,
      2.515625,
      -1.0703125,
      2.578125,
      -0.41015625,
      0.30078125,
      -0.240234375,
      1.7421875
    ],
    "summary": "将卷积自编码器的潜空间建模为离散复值场 Ψ(t,x,y)，用离散卷积近似微分算子驱动类薛定谔演化，并通过基于潜空间局部梯度的非线性自适应正则项实现“智能去噪”，使网络在压缩重建的同时涌现出类似引力/曲率的物理行为。",
    "structure": {
      "sections": [
        {
          "title": "Emergent gravity-like behaviors on complex latent space of variational encoder with nonlinear, data-adaptive regularization scheme.",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 19
        },
        {
          "title": "1.1 Encoder as a Projector to complex latent space",
          "level": 1,
          "start_line": 41
        },
        {
          "title": "1.2 Matrix Representation of Space",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "1.3 Mapping via Convolution as Operator Approximation",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "1.4 Decoder: Inverse Mapping",
          "level": 1,
          "start_line": 87
        },
        {
          "title": "Summary Symbolically",
          "level": 1,
          "start_line": 97
        },
        {
          "title": "2 Emergent gravity on complex latent space.",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "2.1 Basic object: Complex wavefunction in matrix representation",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "2.2 Latent space evolution",
          "level": 1,
          "start_line": 155
        },
        {
          "title": "2.3 Emergent Gravity: metric curvature as evolution feedback and autoencoder features intelligent denoiser",
          "level": 1,
          "start_line": 211
        },
        {
          "title": "2.4 Summary of Equations",
          "level": 1,
          "start_line": 272
        },
        {
          "title": "2.5 Visualization",
          "level": 1,
          "start_line": 330
        },
        {
          "title": "3 Conclusion and physics remarks",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "3.1 Emergent Graviton Interaction as Metric Curvature",
          "level": 1,
          "start_line": 348
        },
        {
          "title": "3.2 Why do the maxima approach each other? Interpretation via modified Schrödinger evolution",
          "level": 1,
          "start_line": 382
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 442
        }
      ]
    },
    "tags": [
      "物理启发学习",
      "变分自编码器",
      "复杂潜空间建模"
    ],
    "suggested_tags": [
      "物理启发学习",
      "变分自编码器",
      "复杂潜空间建模",
      "卷积神经网络",
      "自适应正则化"
    ],
    "tag_suggestions": [
      {
        "name": "物理启发学习",
        "confidence": 0.98,
        "reason": "论文核心思想是将量子力学与微分几何概念（薛定谔方程、拉普拉斯算子、曲率）直接嵌入卷积自编码器的潜空间，属于典型的物理启发机器学习研究。"
      },
      {
        "name": "变分自编码器",
        "confidence": 0.96,
        "reason": "虽然架构为卷积自编码器，但作者显式引入概率解释 |Ψ|² 并讨论数据自适应正则化，整体框架仍落在 VAE 的广义范畴内。"
      },
      {
        "name": "复杂潜空间建模",
        "confidence": 0.94,
        "reason": "将潜变量视为离散复值场 Ψ(t,x,y) 并研究其演化，突破了传统实值向量的潜空间表示，属于复杂潜空间建模的新方法。"
      },
      {
        "name": "卷积神经网络",
        "confidence": 0.92,
        "reason": "编码器-解码器全部采用卷积层，且用卷积近似微分算子（拉普拉斯），CNN 是其实现物理模拟的关键技术。"
      },
      {
        "name": "自适应正则化",
        "confidence": 0.9,
        "reason": "提出基于潜空间局部梯度的非线性、数据自适应正则项，可动态强化边缘与过渡区域，是典型的自适应正则化技术。"
      }
    ],
    "tags_confirmed": true,
    "category": "物理启发学习"
  },
  "a05d96c4-11f4-416b-9ab7-c910cb659498": {
    "id": "a05d96c4-11f4-416b-9ab7-c910cb659498",
    "filename": "“三维一体”高校本科教学内部质量监控体系的构建_廖春华.pdf",
    "file_path": "data/uploads/47e5d413-0cfd-43be-ba5a-dd4b0c5160c5/a05d96c4-11f4-416b-9ab7-c910cb659498_“三维一体”高校本科教学内部质量监控体系的构建_廖春华.pdf",
    "status": "completed",
    "created_at": "2025-12-20 12:37:28.479008",
    "updated_at": "2025-12-20 04:39:00.190723",
    "user_id": "47e5d413-0cfd-43be-ba5a-dd4b0c5160c5",
    "title": "“三维一体”高校本科教学内部质量监控体系的构建",
    "markdown_content": "# “三维一体”高校本科教学内部质量监控体系的构建\n\n廖春华 李永强 欧李梅\n\n【摘要】随着高等教育规模不断扩大，如何保障和提高高等教育质量成为大家广泛关注的议题。本文基于全面质量管理和教学发展观核心理念，在自我评价与他人评价、过程评价与结果评价、日常评价与定期评价相结合原则的指导下，从人才培养关键环节、质量受评对象、质量评价主体三个维度出发，试图构建“三维一体”高校本科教学内部质量监控体系，并以教学质量规范、教学质量信息反馈、教学质量改进三大体系保障机制运行。\n\n【关键词】 三维一体 本科教学 质量监控\n\n【收稿日期】 2014年5月\n\n【作者简介】廖春华，西南财经大学教务处助理研究员、博士；李永强，西南财经大学教务处处长、教授、博士生导师；欧李梅，西南财经大学教务处教师。\n\n内部质量监控体系建设是保障本科教育质量的重要举措，国际上对高等教育质量的保障有三种基本模式：美国模式——高等教育认证制度；英国模式——高等教育质量的多元评估；大陆（指除英国之外的其它国家）模式——高等教育质量保障的政府管理[1]。这些模式充分发挥了第三方评估的作用，但对高校自我监控体系涉及不多。英国模式包含高校内部质量控制，然而其内容和方法较为单一，普遍采用学校批判性的自我检查、学生反馈和校外同行评审。中国高等教育理论界对于如何划分高校内部教学质量保障模式尚未达成一致看法[2]，各高校质量监控体系比较混乱，大多为零散的监控措施。研究人员通过对39所“985工程”大学《2010年度本科教学质量报告》的分析，发现有35份报告都提及了教育教学质量监控措施，其中，14项主要措施的前5项为教学督导、学生评教、毕业论文质量审核、学校领导听课和教学检查[3]。可见，各高校非常重视质量监控，监控措施种类繁多。如何能将这些措施系统化、体系化，以充分发挥质量监控的效用？从全面质量管理理念和教学发展观出发，经过对各高校现有监控措施的分析，笔者发现每项监控措施均涉及三个环节：评价内容、受评对象、评价主体。评价内容即为人才培养过程中影响教学质量的关键环节，受评对象即在此环节中的需接受表现情况评\n\n估的成员，评价主体即为该环节中的能有发言权的成员。因此，力图从教学质量关键环节、质量受评对象、质量评价主体三个维度出发，构建“三维一体”高校本科教学内部质量监控体系，同时从立标准、重反馈和促发展三个方面设立运行机制，保证体系的长效运行。如图1所示。\n\n# 一、“三维一体”高校本科教学内部质量监控体系的核心理念\n\n教学内部质量监控体系是教学质量保障体系的重要组成部分，更加注重在既定人才培养目标和教学资源条件下，从系统内部对影响学生教育教学质量关键环节的流程管理与监控。构建“三维一体”高校本科教学内部质量监控体系首先要遵循全面质量管理和教学发展观核心理念。\n\n# （一）遵循全面质量管理。\n\n注重教师教学质量和学生学习质量双重监控。全面质量管理追求学生的全面发展，“培养德智体美全面发展的社会主义建设者和接班人”，既要加强学生基础知识和基本技能的传授，又要注重学生综合素质和思维能力的培养，彰显学生学习的主体性地位。\n\n注重监控体系的全面性、系统性和长期性。全面质量管理强调全过程育人，而影响教学质量的因素涉及面广，学生从大学入学到毕业四年中的学习经历、人才培养的各个环节、教学培养过程\n\n![](/uploads/images/a05d96c4-11f4-416b-9ab7-c910cb659498/e4a2823e55f1e37c6ae1285e20f40ebc69b18dc6338e2257e24813c30130b1f6.jpg)  \n图1“三维一体”高校本科教学内部质量监控体系图\n\n都应纳入质量监控的范畴。\n\n注重教育共同体的协同作用。全面质量管理突出全员育人，大学内部学生、教师、教育管理者、教学辅助人员、后勤工作人员等都是现代“教育共同体”的元素，要建设全校上下“关心教学、热爱教学、参与教学”的优秀育人文化，营造“全员育人、全过程育人、全方位育人”的优秀育人环境，将“教学共同体”的每一主体都纳入到教学质量监控体系中，尤其注重教务与学工两条线的协同合作，形成教书育人、管理育人、服务育人的合力。\n\n（二）坚持教学发展观。\n\n教学评价监控的目标不是为了证明，而是为了促进教师的教学改进，促进学生的成长成才。目前高校中教师对质量监控方式存在部分抵触情绪，尤其是对学生评教的科学性和合理性存在争议。不可否认，学生评教有需要改进之处，但究其思想根源可能还是在于大多教师把质量监控看成为约束、鞭打教师的“大棒”，而不是促进教师教学思想、教学技能提升的“神器”。高校应始终以教师为本，把教师作为教学质量保障的最重要的力量，注重从学校办学目标、教师责任、教学理念入手提高教师的综合素质。教学评估的主要作用是\n\n搭建教师与学生、管理者、同行之间沟通的平台，让教师多渠道获取在课堂交流中难以得到的信息反馈，充分体现对教师尊重，引发教师自身对教学评估的需求。高校应始终以学生为主体，从学生的能力提升出发，加强对学生各阶段各环节的监控，促进学生和教师自觉、主动参与到教学质量监控与提升中来。\n\n# 二、本科教学内部质量监控体系要素构建原则\n\n“三维一体”本科教学内部质量监控体制的核心在于通过对培养过程的动态化、多元化评估，发现并解决教学过程中存在的问题。在设计评估要素与方式时应坚持以下原则：\n\n一是自我评价与他人评价结合的原则。监控体系中的成员往往具有双重身份：既是被管理监控的对象又是实施监控的主体。考核学生的学习质量是教师的义务，评价教师的教学工作也是学生的权利，教师对自己上课情况进行自评，也对学生的学习情况进行测量，教学管理人员在管理相关事务的同时，也成为师生共同评价的对象。\n\n二是过程评价与结果评价结合的原则。既注重教学目标的实际达成效果，强调评价的甄别和督查功能，更注重过程监控，把师生在教学实施和运行过程中的情况纳入评价范围，强调评价的预测和改进功能。\n\n三是日常评价与定期评价结合。在评价时间节点的选择上既坚持常规性日常检查，同时注重定期重点项目督导，既注重内部质量监控的常态\n\n化运行，又着力于重点环节、重点时点的控制。\n\n# 三、高校本科教学内部质量监控体系要素构建\n\n依据上述理念与原则，从人才培养关键环节、质量受评对象、质量评价主体三个维度搭建高校本科教学内部质量监控体系框架（图2）。\n\n# （一）剖析人才培养关键环节与时间节点\n\n高校应以人才培养目标为核心，以学生入校、在校学习、毕业为基本时间轴，深入剖析分解影响学生成长的各个培养关键环节，确保每个环节达到实效，而这些关键环节要素就是教学质量监控的节点，主要包括学科专业建设、人才培养方案、课程体系、教学大纲、课堂教学、课程考核、毕业论文、实践（实验）教学、教学管理、校风学风等。高校办学理念、人才培养目标、学校类型和层次的差异性要求各学校依据自身教育教学改革的实际情况，有针对性地探寻当前教学工作中出现的关键问题，找出影响本校教学质量人才培养深层次因素，以此作为质量监控的重点环节，做到质量监控的全面与重点的结合，共性和个性的结合。\n\n如何找到这些关键环节，笔者认为应依据高等教育的普遍规律和学生可持续发展的规律；依据教育部2011年提出的《教育部关于普通高等学校本科教学评估工作的意见》文件要求，详细研究院校评估、专业认证及评估、国际评估和教学基本状态数据常态监测等指标体系构成；依据学校的发展战略和本科教学实际状况，对教学各环节的数据进行常态化采集和充分调研分析并将其纳入\n\n![](/uploads/images/a05d96c4-11f4-416b-9ab7-c910cb659498/9266cc31eb482b27bbd17a5e9b947b6da96839391364bed52fdebcf197c441e2.jpg)  \n图2“三维一体”高校本科教学内部质量监控体系要素构建图\n\n本科教学质量监控体系人才培养的关键环节。\n\n# （二）以受评对象为维度的评价构建\n\n人才培养中各重点环节涉及到的影响教学质量的关键人员均是教学内部质量监控体系的受评对象，一般包括学生、教师和管理者三类人员。学生是学习的主体，是毋庸置疑的受评对象，由于学生个体的素质能力、个性特点、自我诉求和学习方法等方面具有多样性，因此，研究影响学生学习的内在动因和外部条件对于保证教学质量具有不可替代的作用。美国高等教育领域的著名学者A.W.阿斯汀（AlexanderW.Astin）在20世纪80年代提出：教育对学生才智、精神上的增值和发展应作为“大学的卓越”、“本科教育的高质量”根本性的评判标尺[4]。对大学生的评价可以分为在校生和毕业生两类，应侧重于对学生接受教育前后情况的对比研究，更为关注人才培养现状与人才培养目标和教学目标的对比研究，才能更好地制定干预或改进措施。对学生的评价应以其知识、能力和素质的提升为标准，在培养环节的前中后设置评价时间点。如课堂教学，高校可在一门课程开始前对学生的各方面能力进行检测和评估，根据该门课程的教学目标在课程结束后再对学生的综合能力进行对照评量，检查学生是否通过本门课程提高了教学目标中所规划的能力素质要求并依此改善教学活动。同时，对一门课程各时间点的监测也可以扩大到对一个学期、一个学年甚至是入校和离校前后的参照评测。北京大学曾对刚毕业的学生进行调查以了解其对大学四年学习的感受；中国首家高等教育管理数据与咨询的麦可思公司根据大一至大四每个学生在校期间的表现和感受进行全程跟踪调查和评价。例如，针对大一新生更关注入学教育和适应性的考察，对大二和大三学生则分别调研其学习状态及压力、毕业规划和职业成熟度情况，对大四学生则围绕毕业去向和毕业设计、毕业论文的完成情况展开调查，麦可思公司对不同阶段大学生的特点，通过有目的性的调查和分析，观察学生发展趋势并了解不同年级的特殊问题，并将由此得到的进程式评价结果反馈到高校的教学培养和学生工作中。\n\n目前国内外对学生学习测量的研究主要有两种，第一种主要基于大学教育经历对学生学习结果的增值的观念，如全美学生学习投入调查（NSSE）、美国大学生就读经验系统（CSEQ）、加州大学本科生学习经历调查（UCUES）、澳大利亚\n\n大学生课程经验调查（CEQ）和英国全英学生普查(NSS)等。另一种是针对毕业生的反馈评价，西南财经大学与麦可思合作从培养结果与毕业生评价和培养过程分析两个方面着手，连续7年对毕业半年后学生进行调查，分析学校毕业生半年后的就业竞争力、就业特色与优势、工作能力、核心知识及价值观以及学生对培养过程的评价等方面的情况；北京大学则将对毕业生的评价延续到毕业4年之后。\n\n教师是高等教育质量之本，高等教育的不断扩展使得对高校教师队伍的需求量也与日俱增。根据教育部2014年召开的教师发布会公布的数据，2013年普通高等学校专任教师达到149.69万人，45岁（不含）以下占  $72.43\\%$  。目前，高校教师群体普遍呈年轻化、高学历化、国际化趋势，创新思维和学术能力较强，但大部分青年教师缺乏专业系统的教育教学方法的训练，对教育理念和学生成长规律也欠缺深入了解，对教育教学的研究主要靠有经验教师的指导和自身的不断钻研，因此要对教师进行过程性评价，在评估中发现问题并寻找解决方案。对教师的评价内容应包括教师个人魅力、授课水平、教学投入程度、教学方式方法以及教师个人诉求等。\n\n管理者是保障学校教学正常运行的基础，管理者制定教学管理制度的合理性和教学管理的效率直接影响教学质量的高低。管理者包含了与教学相关的行政人员、教辅人员等，分为学校层面和学院层面的管理者。从工作性质划分，分为以教务处牵头的主管教学工作的管理线；以学工部、团委牵头的主管学生工作的管理线，这两条线既有平行又有交叉，在加强教学管理队伍建设的基础上增进辅导员对学生学习的指导与交流以及对学生情况反馈，加强教学线与学生线的协作有利于更全方位了解和促进学生全面发展。要建立和完善校院系三级责任制，落实院系和基层教学组织的职责。对管理者的评价主要包括管理理念、管理效率等管理职责的履行情况。\n\n# （三）以评价主体为维度的评价构建\n\n确定评价主体解决的是由谁来评的问题。质量评价主体的多元化是目前高校教学质量监控体系发展的趋势。据了解，作为英国高等教育主要的外部质量保证和评估机构，英国高等教育质量保障署(QAA)特别重视成员构成的多元化，仅以最高管理机构理事会为例，它由17名人员组成，\n\n其中4人来自高等教育机构，4人是高等教育基金委员会成员，1人由英国大学委员会任命，1人是学生代表，还有7位来自于具有丰富实践经验的工业、商业、金融业或其他业界的独立个人[5]。科学合理的评价主体构成是教学质量监控体系的有力保障，笔者认为高等教育质量的相关者都应纳入本科教学质量监控体系。\n\n学生是教学的直接利益相关者，对教学过程有着最直接和真实的体会。在校生和毕业生都应作为评价主体参与学校教学质量管理工作，主要有两种参与方式：一是评估，通过学生直接对自身参与的教师授课情况、课程考核、教学工作满意度等人才培养关键环节进行评价；二是调研，针对全校性或者局部的学校人才培养工作，比如招生工作、课程教学和助教等工作开展教学质量调研活动，让学生参与到学校相关规章制度的制定或改革措施的出台。为推动学风、教风建设，发挥学生能动作用，上海交通大学组织学生参与全校教学秩序检查，将学生对该工作抵触和不理解情绪转变为主动积极投入学习，并提升了学生换位思考能力。可以设立“学生信息员”或者成立“学生教学质量工作组织”，比如上海交通大学成立“教学质量学生工作委员会”完全自主地开展工作[6]。\n\n教师作为评价主体分为授课教师和退休教师。建立退休教师对在职教师的评价和督导制度，建立新老教师传帮带制度，教学研讨、交流和教学观摩制度，搭建教师教学交流的平台。东北大学聘请了多位了解国内外本科教学改革、熟悉本校实际，有丰富教学经验并热心于为学校教改服务的教授和专家，成立了校、院两级教学督导组，按照学校本科教学工作的相关质量标准和制度要求，检查教学情况，反映教学存在的问题，对本科教学工作及教学质量进行全面督导和监控[7]。\n\n管理者评价是长期以来高校通行的教学管理方式，包括学校层面的校领导和相关职能部门对相应教学部门、人员的管理与评价；学院层面的院长、书记对本学院教学工作的推进和管理系所层面对本系所教学工作的推进和管理。应明确各单位教学质量的负责人，建立学校、院、系三级听课制度和定期研究教学工作的制度。\n\n引入校外机构和同行参与高校教学质量监控。在推进“管办评”分离的背景下，引入校外机构参与测评是教育质量评估发展的趋势。同行评\n\n价有助于高校之间的交流，紧跟国内外高等教育发展的趋势。用人单位作为评价主体主要有两种参与方式，一种是对毕业学生素质和能力的评判以及对学校就业服务的反馈，另一种是对人才培养过程的评价，参与到人才培养的过程中。中国科技大学长期跟踪国内外著名高校、研究机构和社会用人单位对其本科毕业生的评价。同济大学用人单位对毕业生主要工作岗位、毕业生优势和对毕业生综合素质以及就业服务等信息与学校进行交流和反馈。也有不少高校积极吸引用人单位，参与到高校专业建设、人才培养方案的制订、课程体系的构建、实务课程教学中来，将实务界最前沿的需求反馈到人才培养的过程中。\n\n四、高校本科教学内部质量监控体系的运行机制\n\n“三维一体”高校本科教学内部质量监控体系的正常运行、发挥实效，还需要建立教学质量规范体系、教学质量信息反馈体系、教学质量改进体系等三大体系。\n\n（一）立标准：教学质量规范体系。\n\n各高校要按不同的纵向层次和横向类型，准确定位，在强化自身优势基础上制定符合本校办学理念和实际情况的衡量高等教育质量的标准。精英型和大众化高等教育的培养目标与规格各有侧重，学术取向与标准、职业技术取向与操作技能也各有不同，不能同一而论[8]。作为质量监控实施的基本依据，完善的教学质量规范体系的构建必不可少。要建立健全一套完整、科学、严密的教学规章制度，在专业建设、人才培养方案制定和运行、教师培训、课程建设、课堂教学、实践实验教学、教材建设、学生学业考核、毕业论文（设计）等各个环节上都设立质量标准，规范各项教学工作的要求和流程，确保质量监控体系的运行有目标、有规范、有依据。\n\n（二）重反馈：教学质量信息反馈体系。\n\n充分利用现代信息技术的支持，建立基于人才培养关键环节、质量受评对象、质量评价主体三个维度的教学质量信息反馈系统，利用信息平台的收集、归档、分析的功能，多视角、多节点的监控和评价大数据，形成诊断结论、改进方案。实现分层次开放系统管理权限，每个参与质量监控的人员能实时了解自身评价情况并根据工作性质的区别获得不同的评价数据信息。\n\n注重信息反馈的人性化体验，通过联席会议、\n\n现场办公、质量管理员例会、质量监控表等灵活形式反馈，涉及个别教师的教学质量问题，以尊重教师的方式直接把信息反馈给本人。通过这样的机制，在全校营造一种积极、和谐的氛围，激励教师主动改进教学质量。\n\n# （三）促发展：教学质量改进体系。\n\n建立循环往复、不断修复完善、持续提升的质量监控体系，发挥其改进教学质量的功能，需要从教师和学生两个方面建立教学质量改进体系。建立教师的教学发展体系，应构建新进教师、在职教师和教学效果有待提升教师的教师教学培训体系，积极开展“青年教师教学竞赛”、“微课教学比赛”等竞赛活动，切实提高教师教学能力，搭建科研和教学的互通机制，不断完善教师教学激励机制。\n\n建立学生的学业指导机制，倡导互动型学习、探究型学习，指导学生构建有效的学习模式，增加学生学习指导项目，系统开展学业指导咨询、学习讲座培训、教师与学生学业自助沙龙、学业恳谈会、同辈交流会等多种形式的学生学业指导活动，\n\n搭建教师教学发展与人才培养的良性互动机制，激发学生学习活力和主动性。\n\n本科教学质量监控是一个多维、动态、长期性的基础工作，只有持之以恒、运行不息才能充分发挥其教学监控的效能。\n\n# 参考文献\n\n[1] 李亚东：《我国高等教育质量保障体系的构建》，《中国高等教育评估》2004年第1期。  \n[2][7]李明：《中国研究型大学内部教学质量监控体系研究》，《北京航空航天大学学报（社会科学版）》2014年第1期。  \n[3]钟飞等：《39所高校教学质量内部监控体系分析》，《解放军医院管理杂志》2014年第2期。  \n[4] Astin A. W. Achieving educational excellence. Sar Francisco: Jossey Bass Publishers, 1985:  $58\\sim 59$  \n[5] QAA, Our Board: Code of best practice, http://www.qaa.ac.uk/about-us/corporate-governance/our-board  \n[6] 党晶等：《学生参与高校内部教学质量保障体系建设的实践与探索》，《高等理科教育》2010年第1期。  \n[8] 潘懋元:《高等教育大众化的教育质量观》,《清华大学教育研究》2001年第1期。\n\n# Exploration into the Internal “Three Dimensions in One” Quality-Control System for Undergraduate Education in University\n\nLiao Chunhua, Li Yongqiang, Ou Limei\n\nWith the expansion of higher education scale, how to guarantee the quality of higher education becomes a hot issue which triggers a wide range of discussion. Based on the key conception of comprehensive quality management and educational development, and under the guidance of the combination of self-evaluation and evaluation by others, process-evaluation and result-evaluation as well as daily-evaluation and regular-evaluation, this article aims to explore the construction of the internal \"three dimensions in one\" quality-control system from the perspectives of talent cultivation, evaluated objects and subjects of quality evaluation. Additionally, the following three systems of education quality regulations, education feedback and suggestions would help to guarantee the smooth operation.",
    "arxiv_id": null,
    "error_message": null,
    "summary": "以人才培养关键环节、质量受评对象、质量评价主体为三维，构建覆盖全过程、全员、全方位的本科教学内部质量监控框架，并通过“立标准—重反馈—促发展”机制保障其长效运行。",
    "structure": {
      "sections": [
        {
          "title": "“三维一体”高校本科教学内部质量监控体系的构建",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "一、“三维一体”高校本科教学内部质量监控体系的核心理念",
          "level": 1,
          "start_line": 17
        },
        {
          "title": "（一）遵循全面质量管理。",
          "level": 1,
          "start_line": 21
        },
        {
          "title": "二、本科教学内部质量监控体系要素构建原则",
          "level": 1,
          "start_line": 40
        },
        {
          "title": "三、高校本科教学内部质量监控体系要素构建",
          "level": 1,
          "start_line": 52
        },
        {
          "title": "（一）剖析人才培养关键环节与时间节点",
          "level": 1,
          "start_line": 56
        },
        {
          "title": "（二）以受评对象为维度的评价构建",
          "level": 1,
          "start_line": 67
        },
        {
          "title": "（三）以评价主体为维度的评价构建",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "（三）促发展：教学质量改进体系。",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "参考文献",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "Exploration into the Internal “Three Dimensions in One” Quality-Control System for Undergraduate Education in University",
          "level": 1,
          "start_line": 131
        }
      ]
    },
    "tags": [
      "高等教育质量保障",
      "内部质量监控",
      "教学评估"
    ],
    "suggested_tags": [
      "高等教育质量保障",
      "内部质量监控",
      "教学评估",
      "全面质量管理"
    ],
    "tag_suggestions": [
      {
        "name": "高等教育质量保障",
        "confidence": 0.98,
        "reason": "全文聚焦高校本科教学内部质量监控体系的构建，属于高等教育质量保障研究的核心议题。"
      },
      {
        "name": "内部质量监控",
        "confidence": 0.96,
        "reason": "提出“三维一体”框架，专门解决高校内部质量监控的系统化与长效运行问题。"
      },
      {
        "name": "教学评估",
        "confidence": 0.95,
        "reason": "论文系统论述了自我评价、他人评价、过程与结果评价等多元教学评估方式，是研究的重点方法。"
      },
      {
        "name": "全面质量管理",
        "confidence": 0.92,
        "reason": "以TQM理念为理论基础，强调全过程、全员、全方位育人，贯穿监控体系设计。"
      }
    ],
    "tags_confirmed": true,
    "category": "高等教育质量保障",
    "translation_status": "completed",
    "translation_progress": 100,
    "translation_chunks_total": 3,
    "translation_chunks_done": 3,
    "translated_content": "# “三维一体”高校本科教学内部质量监控体系的构建\n\n廖春华 李永强 欧李梅\n\n【摘要】随着高等教育规模不断扩大，如何保障和提高高等教育质量成为大家广泛关注的议题。本文基于全面质量管理和教学发展观核心理念，在自我评价与他人评价、过程评价与结果评价、日常评价与定期评价相结合原则的指导下，从人才培养关键环节、质量受评对象、质量评价主体三个维度出发，试图构建“三维一体”高校本科教学内部质量监控体系，并以教学质量规范、教学质量信息反馈、教学质量改进三大体系保障机制运行。\n\n【关键词】 三维一体 本科教学 质量监控\n\n【收稿日期】 2014年5月\n\n【作者简介】廖春华，西南财经大学教务处助理研究员、博士；李永强，西南财经大学教务处处长、教授、博士生导师；欧李梅，西南财经大学教务处教师。\n\n内部质量监控体系建设是保障本科教育质量的重要举措，国际上对高等教育质量的保障有三种基本模式：美国模式——高等教育认证制度；英国模式——高等教育质量的多元评估；大陆（指除英国之外的其它国家）模式——高等教育质量保障的政府管理[1]。这些模式充分发挥了第三方评估的作用，但对高校自我监控体系涉及不多。英国模式包含高校内部质量控制，然而其内容和方法较为单一，普遍采用学校批判性的自我检查、学生反馈和校外同行评审。中国高等教育理论界对于如何划分高校内部教学质量保障模式尚未达成一致看法[2]，各高校质量监控体系比较混乱，大多为零散的监控措施。研究人员通过对39所“985工程”大学《2010年度本科教学质量报告》的分析，发现有35份报告都提及了教育教学质量监控措施，其中，14项主要措施的前5项为教学督导、学生评教、毕业论文质量审核、学校领导听课和教学检查[3]。可见，各高校非常重视质量监控，监控措施种类繁多。如何能将这些措施系统化、体系化，以充分发挥质量监控的效用？从全面质量管理理念和教学发展观出发，经过对各高校现有监控措施的分析，笔者发现每项监控措施均涉及三个环节：评价内容、受评对象、评价主体。评价内容即为人才培养过程中影响教学质量的关键环节，受评对象即在此环节中的需接受表现情况评估的成员，评价主体即为该环节中的能有发言权的成员。因此，力图从教学质量关键环节、质量受评对象、质量评价主体三个维度出发，构建“三维一体”高校本科教学内部质量监控体系，同时从立标准、重反馈和促发展三个方面设立运行机制，保证体系的长效运行。如图1所示。\n\n# 一、“三维一体”高校本科教学内部质量监控体系的核心理念\n\n教学内部质量监控体系是教学质量保障体系的重要组成部分，更加注重在既定人才培养目标和教学资源条件下，从系统内部对影响学生教育教学质量关键环节的流程管理与监控。构建“三维一体”高校本科教学内部质量监控体系首先要遵循全面质量管理和教学发展观核心理念。\n\n## （一）遵循全面质量管理\n\n注重教师教学质量和学生学习质量双重监控。全面质量管理追求学生的全面发展，“培养德智体美全面发展的社会主义建设者和接班人”，既要加强学生基础知识和基本技能的传授，又要注重学生综合素质和思维能力的培养，彰显学生学习的主体性地位。\n\n注重监控体系的全面性、系统性和长期性。全面质量管理强调全过程育人，而影响教学质量的因素涉及面广，学生从大学入学到毕业四年中的学习经历、人才培养的各个环节、教学培养过程\n\n![](/uploads/images/a05d96c4-11f4-416b-9ab7-c910cb659498/e4a2823e55f1e37c6ae1285e20f40ebc69b18dc6338e2257e24813c30130b1f6.jpg)  \n图1 “三维一体”高校本科教学内部质量监控体系图\n\n都应纳入质量监控的范畴。\n\n注重教育共同体的协同作用。全面质量管理突出全员育人，大学内部学生、教师、教育管理者、教学辅助人员、后勤工作人员等都是现代“教育共同体”的元素，要建设全校上下“关心教学、热爱教学、参与教学”的优秀育人文化，营造“全员育人、全过程育人、全方位育人”的优秀育人环境，将“教学共同体”的每一主体都纳入到教学质量监控体系中，尤其注重教务与学工两条线的协同合作，形成教书育人、管理育人、服务育人的合力。\n\n## （二）坚持教学发展观\n\n教学评价监控的目标不是为了证明，而是为了促进教师的教学改进，促进学生的成长成才。目前高校中教师对质量监控方式存在部分抵触情绪，尤其是对学生评教的科学性和合理性存在争议。不可否认，学生评教有需要改进之处，但究其思想根源可能还是在于大多教师把质量监控看成为约束、鞭打教师的“大棒”，而不是促进教师教学思想、教学技能提升的“神器”。高校应始终以教师为本，把教师作为教学质量保障的最重要的力量，注重从学校办学目标、教师责任、教学理念入手提高教师的综合素质。教学评估的主要作用是\n\n搭建教师与学生、管理者、同行之间沟通的平台，让教师多渠道获取在课堂交流中难以得到的信息反馈，充分体现对教师尊重，引发教师自身对教学评估的需求。高校应始终以学生为主体，从学生的能力提升出发，加强对学生各阶段各环节的监控，促进学生和教师自觉、主动参与到教学质量监控与提升中来。\n\n# 二、本科教学内部质量监控体系要素构建原则\n\n“三维一体”本科教学内部质量监控体制的核心在于通过对培养过程的动态化、多元化评估，发现并解决教学过程中存在的问题。在设计评估要素与方式时应坚持以下原则：\n\n1. 自我评价与他人评价结合的原则。监控体系中的成员往往具有双重身份：既是被管理监控的对象又是实施监控的主体。考核学生的学习质量是教师的义务，评价教师的教学工作也是学生的权利，教师对自己上课情况进行自评，也对学生的学习情况进行测量，教学管理人员在管理相关事务的同时，也成为师生共同评价的对象。\n2. 过程评价与结果评价结合的原则。既注重教学目标的实际达成效果，强调评价的甄别和督查功能，更注重过程监控，把师生在教学实施和运行过程中的情况纳入评价范围，强调评价的预测和改进功能。\n3. 日常评价与定期评价结合。在评价时间节点的选择上既坚持常规性日常检查，同时注重定期重点项目督导，既注重内部质量监控的常态化运行，又着力于重点环节、重点时点的控制。\n\n# 三、高校本科教学内部质量监控体系要素构建\n\n依据上述理念与原则，从人才培养关键环节、质量受评对象、质量评价主体三个维度搭建高校本科教学内部质量监控体系框架（图2）。\n\n## （一）剖析人才培养关键环节与时间节点\n\n高校应以人才培养目标为核心，以学生入校、在校学习、毕业为基本时间轴，深入剖析分解影响学生成长的各个培养关键环节，确保每个环节达到实效，而这些关键环节要素就是教学质量监控的节点，主要包括学科专业建设、人才培养方案、课程体系、教学大纲、课堂教学、课程考核、毕业论文、实践（实验）教学、教学管理、校风学风等。高校办学理念、人才培养目标、学校类型和层次的差异性要求各学校依据自身教育教学改革的实际情况，有针对性地探寻当前教学工作中出现的关键问题，找出影响本校教学质量人才培养深层次因素，以此作为质量监控的重点环节，做到质量监控的全面与重点的结合，共性和个性的结合。\n\n如何锁定这些关键环节，笔者认为必须同时遵循高等教育的普遍规律与学生可持续发展的规律；依据教育部 2011 年印发的《教育部关于普通高等学校本科教学评估工作的意见》，系统梳理院校评估、专业认证与评估、国际评估以及教学基本状态数据常态监测等指标体系的构成；结合学校发展战略与本科教学实际，对教学各环节的数据进行常态化采集、深入调研与分析，并将其纳入\n\n![](/uploads/images/a05d96c4-11f4-416b-9ab7-c910cb659498/9266cc31eb482b27bbd17a5e9b947b6da96839391364bed52fdebcf197c441e2.jpg)  \n图 2 “三维一体”高校本科教学内部质量监控体系要素构建图\n\n本科教学质量监控体系人才培养的关键环节。\n\n# （二）以受评对象为维度的评价构建\n\n人才培养各重点环节所涉及、并对教学质量产生关键影响的人员，均为教学内部质量监控体系的受评对象，通常包括学生、教师与管理者三类。学生作为学习主体，其受评地位毋庸置疑；鉴于学生在素质能力、个性特征、自我诉求与学习方法等方面呈现多样性，探究影响其学习的内在动因与外部条件对保障教学质量具有不可替代的价值。美国高等教育学者 A. W. 阿斯汀（Alexander W. Astin）于 20 世纪 80 年代提出：大学对学生才智与精神的增值（value-added）应成为衡量“大学卓越”与“本科教育高质量”的根本标尺 [4]。对学生的评价可区分为在校生与毕业生两类，应侧重教育前后对比研究，并聚焦人才培养现状与培养目标、教学目标之间的契合度，方能据此制定干预或改进措施。评价标准应聚焦于学生知识、能力与素质的提升，并在培养环节的前、中、后设置评价时点。以课堂教学为例，高校可在课程开始前对学生各项能力进行基线测评，课程结束后再次对照教学目标进行综合评估，检验学生是否通过该课程达成既定能力素质要求，并据此改进教学活动。同时，对一门课程各时点的监测可扩展至学期、学年，乃至入学与毕业前后的纵向评测。北京大学曾对刚毕业学生展开调查，了解其四年学习体验；中国首家高等教育管理数据与咨询机构麦可思公司，则对大一至大四学生在校期间的表现与感受进行全程跟踪调查与评价。例如，针对大一新生重点考察入学教育与适应性；对大二、大三学生分别调研学习状态与压力、毕业规划与职业成熟度；对大四学生则围绕毕业去向、毕业设计与论文完成情况进行调查。麦可思公司依据不同阶段大学生的特点，通过有目的的调查与分析，观察学生发展趋势、识别年级特异性问题，并将过程性评价结果及时反馈至高校教学培养与学生工作。\n\n当前国内外对学生学习测量的研究主要有两条路径：其一，基于大学教育经历对学生学习结果产生“增值”理念的调查，如全美学生学习投入调查（NSSE）、美国大学生就读经验调查（CSEQ）、加州大学本科生学习经历调查（UCUES）、澳大利亚大学生课程经验调查（CEQ）及英国全英学生调查（NSS）等；其二，针对毕业生的反馈评价，西南财经大学与麦可思合作，连续 7 年从培养结果与毕业生评价、培养过程分析两个维度，对毕业半年后学生开展调查，分析其就业竞争力、就业特色与优势、工作能力、核心知识及价值观，并获取学生对培养过程的评价；北京大学则将对毕业生的评价延伸至毕业 4 年之后。\n\n教师是高等教育质量之本。高等教育的持续扩张使高校对教师队伍的需求与日俱增。教育部 2014 年教师发布会数据显示，2013 年普通高等学校专任教师达 149.69 万人，45 岁（不含）以下教师占比 $72.43\\%$。当前高校教师群体普遍呈年轻化、高学历化、国际化趋势，创新思维与学术能力较强，但多数青年教师缺乏系统的教育教学方法训练，对教育规律与学生成长规律理解不足，其教学研究主要依赖经验教师指导与自我摸索。因此，应对教师实施过程性评价，在评估中发现问题并寻求解决方案。评价内容应涵盖教师人格魅力、授课水平、教学投入、教学方法及其个人诉求等。\n\n管理者是保障学校教学正常运行的基石。管理者制定教学管理制度的合理性及教学管理效率直接影响教学质量高低。管理者包括与教学相关的行政人员、教辅人员等，分学校与学院两个层级。按工作性质划分，主要包括以教务处牵头的教学管理线与以学工部、团委牵头的学生工作线，两线既平行又交叉。在加强教学管理队伍建设基础上，应强化辅导员对学生学习的指导与交流，及时反馈学生情况，促进教学线与学工线协同，以全面了解和促进学生发展。应建立并完善校—院—系三级责任制，落实院系与基层教学组织职责。对管理者的评价主要聚焦管理理念、管理效率等职责履行情况。\n\n# （三）以评价主体为维度的评价构建\n\n确定评价主体解决的是“由谁来评”的问题。质量评价主体多元化是当前高校教学质量监控体系发展的趋势。据悉，英国高等教育主要外部质量保证与评估机构——英国高等教育质量保障署（QAA）高度重视成员构成的多元化，仅以其最高管理机构理事会为例，17 名成员中，4 人来自高等教育机构，4 人为高等教育基金委员会成员，1 人由英国大学委员会任命，1 人为学生代表，另有 7 位来自工业、商业、金融业或其他业界且具有丰富实践经验的独立个人 [5]。科学合理的评价主体构成是教学质量监控体系的有力保障，笔者认为，凡与高等教育质量相关者均应纳入本科教学质量监控体系。\n\n学生作为教学的直接利益相关者，对教学过程拥有最直接、最真实的体验。在校生与毕业生均应作为评价主体参与学校教学质量管理工作，主要有两种参与方式：其一，评估——学生直接对自身参与的教师授课、课程考核、教学工作满意度等关键环节进行评价；其二，调研——针对全校性或局部人才培养工作（如招生、课程教学、助教等）开展教学质量调研，让学生参与学校相关规章制度的制定或改革措施的出台。为助推学风、教风建设，发挥学生能动性，上海交通大学组织学生参与全校教学秩序检查，将学生对该工作的抵触与不理解转化为主动投入学习，并提升其换位思考能力。可设立“学生信息员”或成立“学生教学质量工作组织”，如上海交通大学成立“教学质量学生工作委员会”，完全自主开展工作 [6]。\n\n教师作为评价主体可分为授课教师与退休教师。应建立退休教师对在职教师的评价与督导制度，构建新老教师“传帮带”机制，完善教学研讨、交流与观摩制度，搭建教师教学交流平台。东北大学聘请多位熟悉国内外本科教学改革、了解本校实际、具有丰富教学经验并热心教改的教授与专家，成立校、院两级教学督导组，依据学校本科教学工作相关质量标准与制度要求，检查教学情况，反馈教学问题，对本科教学工作及教学质量实施全面督导与监控 [7]。\n\n管理者评价是长期以来高校通行的教学管理方式，包括学校层面的校领导和相关职能部门对相应教学部门、人员的管理与评价；学院层面的院长、书记对本学院教学工作的推进和管理；系所层面对本系所教学工作的推进和管理。应明确各单位教学质量的负责人，建立学校、院、系三级听课制度和定期研究教学工作的制度。\n\n引入校外机构和同行参与高校教学质量监控。在推进“管办评”分离的背景下，引入校外机构参与测评是教育质量评估发展的趋势。同行评价有助于高校之间的交流，紧跟国内外高等教育发展的趋势。用人单位作为评价主体主要有两种参与方式：一种是对毕业学生素质和能力的评判以及对学校就业服务的反馈；另一种是对人才培养过程的评价，参与到人才培养的过程中。中国科技大学长期跟踪国内外著名高校、研究机构和社会用人单位对其本科毕业生的评价。同济大学用人单位对毕业生主要工作岗位、毕业生优势和对毕业生综合素质以及就业服务等信息与学校进行交流和反馈。也有不少高校积极吸引用人单位，参与到高校专业建设、人才培养方案的制订、课程体系的构建、实务课程教学中来，将实务界最前沿的需求反馈到人才培养的过程中。\n\n四、高校本科教学内部质量监控体系的运行机制\n\n“三维一体”高校本科教学内部质量监控体系的正常运行、发挥实效，还需要建立教学质量规范体系、教学质量信息反馈体系、教学质量改进体系等三大体系。\n\n（一）立标准：教学质量规范体系  \n各高校要按不同的纵向层次和横向类型，准确定位，在强化自身优势基础上制定符合本校办学理念和实际情况的衡量高等教育质量的标准。精英型和大众化高等教育的培养目标与规格各有侧重，学术取向与标准、职业技术取向与操作技能也各有不同，不能同一而论[8]。作为质量监控实施的基本依据，完善的教学质量规范体系的构建必不可少。要建立健全一套完整、科学、严密的教学规章制度，在专业建设、人才培养方案制定和运行、教师培训、课程建设、课堂教学、实践实验教学、教材建设、学生学业考核、毕业论文（设计）等各个环节上都设立质量标准，规范各项教学工作的要求和流程，确保质量监控体系的运行有目标、有规范、有依据。\n\n（二）重反馈：教学质量信息反馈体系  \n充分利用现代信息技术的支持，建立基于人才培养关键环节、质量受评对象、质量评价主体三个维度的教学质量信息反馈系统，利用信息平台的收集、归档、分析的功能，多视角、多节点的监控和评价大数据，形成诊断结论、改进方案。实现分层次开放系统管理权限，每个参与质量监控的人员能实时了解自身评价情况并根据工作性质的区别获得不同的评价数据信息。  \n注重信息反馈的人性化体验，通过联席会议、现场办公、质量管理员例会、质量监控表等灵活形式反馈；涉及个别教师的教学质量问题，以尊重教师的方式直接把信息反馈给本人。通过这样的机制，在全校营造一种积极、和谐的氛围，激励教师主动改进教学质量。\n\n（三）促发展：教学质量改进体系  \n建立循环往复、不断修复完善、持续提升的质量监控体系，发挥其改进教学质量的功能，需要从教师和学生两个方面建立教学质量改进体系。建立教师的教学发展体系，应构建新进教师、在职教师和教学效果有待提升教师的教师教学培训体系，积极开展“青年教师教学竞赛”“微课教学比赛”等竞赛活动，切实提高教师教学能力，搭建科研和教学的互通机制，不断完善教师教学激励机制。  \n建立学生的学业指导机制，倡导互动型学习、探究型学习，指导学生构建有效的学习模式，增加学生学习指导项目，系统开展学业指导咨询、学习讲座培训、教师与学生学业自助沙龙、学业恳谈会、同辈交流会等多种形式的学生学业指导活动，搭建教师教学发展与人才培养的良性互动机制，激发学生学习活力和主动性。\n\n本科教学质量监控是一个多维、动态、长期性的基础工作，只有持之以恒、运行不息才能充分发挥其教学监控的效能。\n\n# 参考文献  \n[1] 李亚东：《我国高等教育质量保障体系的构建》，《中国高等教育评估》2004年第1期。  \n[2][7] 李明：《中国研究型大学内部教学质量监控体系研究》，《北京航空航天大学学报（社会科学版）》2014年第1期。  \n[3] 钟飞等：《39所高校教学质量内部监控体系分析》，《解放军医院管理杂志》2014年第2期。  \n[4] Astin A. W. *Achieving Educational Excellence*. San Francisco: Jossey-Bass Publishers, 1985: $58\\sim 59$  \n[5] QAA, *Our Board: Code of Best Practice*, http://www.qaa.ac.uk/about-us/corporate-governance/our-board  \n[6] 党晶等：《学生参与高校内部教学质量保障体系建设的实践与探索》，《高等理科教育》2010年第1期。  \n[8] 潘懋元：《高等教育大众化的教育质量观》，《清华大学教育研究》2001年第1期。\n\n# 高校本科教学内部“三维一体”质量监控体系探析  \n廖春华，李勇强，欧丽梅  \n\n随着高等教育规模的扩张，如何保障高等教育质量成为引发广泛讨论的热点议题。本文以全面质量管理和教育发展的核心理念为基础，在自我评价与他人评价相结合、过程评价与结果评价相结合、日常评价与定期评价相结合的原则指导下，从人才培养、质量受评对象与质量评价主体三个维度，探讨高校内部“三维一体”质量监控体系的构建，并进一步提出教育质量规范、教育信息反馈与教育改进三大体系，以保障其顺畅运行。",
    "is_translated": true
  },
  "46b648f5-a053-40b3-a651-3b42950130de": {
    "id": "46b648f5-a053-40b3-a651-3b42950130de",
    "filename": "2508.12726v5.pdf",
    "file_path": "data/uploads/47e5d413-0cfd-43be-ba5a-dd4b0c5160c5/46b648f5-a053-40b3-a651-3b42950130de_2508.12726v5.pdf",
    "status": "completed",
    "created_at": "2025-12-20 12:37:49.786874",
    "updated_at": "2025-12-20 04:40:23.343223",
    "user_id": "47e5d413-0cfd-43be-ba5a-dd4b0c5160c5",
    "title": "DESIGNER: DESIGN-LOGIC-GUIDED MULTIDISCIPLINARY DATA SYNTHESIS FOR LLM REASONING",
    "markdown_content": "# DESIGNER: DESIGN-LOGIC-GUIDED MULTIDISCIPLINARY DATA SYNTHESIS FOR LLM REASONING\n\nWeize Liu $^{1,\\ast}$ , Yongchi Zhao $^{1,\\ast,\\dagger}$ , Yijia Luo $^{1}$ , Mingyu Xu $^{1}$ , Jiaheng Liu $^{2,\\dagger}$ , Yanan Li $^{1}$ , Xiguo Hu $^{1}$ , Zhiqi Bai $^{1}$ , Yuchi Xu $^{1}$ , Wenbo Su $^{1}$ , Bo Zheng $^{1}$\n\n<sup>1</sup>Alibaba Group, <sup>2</sup>Nanjing University\n\nweizeliu1115@gmail.com, zhaoyongchi.zyc@gmail.com, liujiaheng@nju.edu.cn\n\n# ABSTRACT\n\nLarge language models (LLMs) have achieved remarkable success in many natural language tasks but still struggle with complex, multi-step reasoning, particularly across diverse disciplines. Existing reasoning datasets often lack disciplinary breadth, reasoning depth, and diversity, as well as guiding principles for question synthesis. We propose DESIGNER: a DESIGN-logic-guidEd Reasoning data synthesis pipeline that leverages naturally available, extensive raw documents (e.g., book corpus and web corpus) to generate multidisciplinary challenging questions. We introduce the concept of \"design logic\" and instruct LLMs to mimic human educators' question-creation process, enabling the automated synthesis of large-scale, high-difficulty questions. We use LLMs to reverse-engineer and abstract over 120,000 design logics from existing questions across various disciplines. By matching these design logics with source documents, we are able to generate reasoning questions with controllable question types and difficulty levels. Using this pipeline, we synthesized two large-scale reasoning datasets that span 75 disciplines: DLR-Book (3.04 million questions from the book corpus) and DLR-Web (1.66 million questions from the web corpus). Data analysis indicates that the questions synthesized by our method exhibit greater difficulty and diversity compared to those in the baseline datasets. We validate our synthesized data through supervised fine-tuning (SFT) on the Qwen3 and Llama3 model families. Our data substantially enhances their multidisciplinary reasoning capabilities, outperforming existing datasets. Notably, by applying SFT on the base versions of these models using only our data, we even surpass their official final models that have undergone the full post-training process. $^{1}$\n\n# 1 INTRODUCTION\n\nLarge language models (LLMs) have demonstrated exceptional capabilities in various natural reasoning tasks (Chowdhery et al., 2023; OpenAI, 2023), such as mathematics and coding (Trinh et al., 2024; Zhu et al., 2024), especially when utilizing long chain-of-thought (CoT) techniques (Wei et al., 2022; Jaech et al., 2024; Guo et al., 2025). However, they still lag behind human experts in university-level, discipline-specific reasoning (Phan et al., 2025), largely due to the scarcity of large-scale, high-quality, and diverse training data. Existing datasets focus mainly on math and programming, drawing on competition platforms rich in open-ended questions (Moshkov et al., 2025; Cai et al., 2025), while most other disciplines lack comparable resources. This scarcity limits the development of LLMs' multidisciplinary reasoning capabilities.\n\nData synthesis with LLMs is an effective solution to data scarcity (Wang et al., 2024a). Existing question synthesis methods fall into two categories: query-centric and doc-centric. Query-centric approaches expand seed questions through rewriting, added constraints (e.g., Evol-Instruct (Xu et al., 2023)), or incorporating chain-of-thought reasoning (Wang et al., 2023; Yu et al., 2025), but they are limited by the coverage of the seed pool and inherent model biases. Doc-centric methods instead generate questions from unstructured (e.g., web, books) or structured (e.g., knowledge graphs)\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/c93bb6272766183438ef9dc731d268477fb369c9ad5f90f9906763f44d257ced.jpg)  \nFigure 1: Left: The procedure by which human experts construct questions reflects a \"Design Logic\": a systematic sequence of deliberate steps that transforms fundamental knowledge points into complex, context-rich questions requiring multi-stage reasoning. Right: DESIGNER emulates this process by matching logics to raw corpus and synthesizing diverse, multidisciplinary questions.\n\n# Design Logic\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/f94e40cf690490971d023d5881b7347f8de8496233f8d0bea6c46b6e1f55289c.jpg)  \nIdentify Construct Knowledge scenarios Points\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/df2c6660dc08c14e33b87f09ae9cb50b059fdda31b38a62e9d6b8915cf2fa26b.jpg)\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/7f87cb84027fd6481a3a9726ddc323aabcc2d11b0001323331a29eb72e430ee7.jpg)  \nDesign Reasoning Paths\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/77caecaec647c1abc6670345b0cf28c3480ee72e94e825b1850830f5e2eca7c2.jpg)  \nPreset Distractors  \nExam Questions\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/1811fc001d99b065551483cb6d774ff74380b2936158f87781268d76c81d412b.jpg)\n\n# DESIGNER\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/a1d63a2c081edd75992f64d94415a486a7bd164881b0f9f57991d8063c62df83.jpg)  \nRaw Corpus\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/cc80f44c6cc2dbe72adf67f7cc9789100c9ac45ae5e107334c68d9109a1f38a7.jpg)  \nDesign Logic  \nDiverse Questions\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/6a7068a1c8c6c1ada4dedfb4eb81e0cf091d663192d7e5caca4d3cd3681faf14.jpg)\n\nsource documents (Yue et al., 2024; Yuan et al., 2025; Huang et al., 2025), ensuring broad disciplinary coverage grounded in authentic knowledge. However, they struggle to control difficulty and diversity, often degenerating into factual recall.\n\nTo address these issues, we propose DESIGNER: a DESIGN-logic-guided Reasoning data synthesis pipeline that leverages large-scale, multidisciplinary raw documents (e.g., book corpus and web corpus) to synthesize challenging questions across diverse disciplines. The central insight of our approach is the notion of \"Design Logic\", which encapsulates how human experts transform knowledge into complex, reasoning-intensive exam questions. We observed that when human education experts design challenging and insightful questions, they do not merely state facts. Instead, they follow a structured design process, as illustrated in Figure 1. The design logic is a form of reusable meta-knowledge that abstracts the underlying reasoning structure, enabling LLMs to generate new questions with the same complex reasoning patterns from entirely different source texts.\n\nSpecifically, our pipeline is illustrated in Figure 2. First, we process large-scale book and web corpora with multi-dimensional labeling and filtering (discipline, readability, educational value, reasoning depth) to construct a high-quality source material library. From a question bank of hundreds of millions, we cluster and sample a diverse set of difficult questions, from which an LLM reverse-engineers and abstracts over 120K structured \"design logics\" to construct a reusable design logic library. In question synthesis, we adopt a two-stage retrieve-and-generate mechanism: (1) vector similarity retrieves coarse candidate logics for each source document, and (2) an LLM performs a fine-grained evaluation to select the optimal logic and generates a reasoning question from the source document by strictly following its steps. This approach addresses the absence of guiding principles in prior data synthesis methods, enabling the automated generation of a large number of diverse and high-difficulty exam questions while reducing reliance on expensive manual creation.\n\nThe main contributions of this paper can be summarized as follows:\n\n- We propose a data engineering pipeline for synthesizing challenging questions from raw text corpora. Using this pipeline, we constructed two large-scale reasoning datasets: DLR-Book (3.04 million questions from the book corpus) and DLR-Web (1.66 million questions from the web corpus). These datasets span 75 disciplines, including STEM, humanities, social sciences, applied and professional fields, and the arts, extending beyond common disciplines.  \n- By reverse-engineering the meta-knowledge of human educators, we propose a fundamentally new question synthesis method guided by \"Design Logic\". This approach enables the generation of truly complex, multi-step reasoning questions from raw text by providing the structured, reusable, and abstract control over difficulty and diversity that prior doc-centric methods lacked. Our data analysis indicates that the questions synthesized by our method exhibit greater difficulty and diversity compared to those in the baseline datasets.  \n- We validate the effectiveness of our synthesized data through comprehensive comparative and ablation experiments on the Qwen3 (Yang et al., 2025a) and Llama3 (Dubey et al., 2024) model families. The results demonstrate that the data synthesized by our method significantly enhance the multidisciplinary reasoning capabilities of LLMs.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/2a5b7f0c03c947f283d870b2417ca9089ba4acd1e2d5e7d409fbea61dfddc7db.jpg)  \nFigure 2: The Design-Logic-Guided Multidisciplinary Data Synthesis Pipeline.\n\n# 2 DATA CURATION\n\nWe curate three data sources for question synthesis: a proprietary question bank, a book corpus, and a web corpus, all aligned to a unified 75-discipline taxonomy (see Appendix A). Figure 2 (Phase 1) illustrates the overall data processing pipeline.\n\n# 2.1 QUESTION BANK PROCESSING\n\nWe annotate over 150 million questions from the proprietary question bank with discipline, difficulty, and question types using Qwen3-30B-A3B (non-thinking mode), following the prompts in Figure 7, Figure 8, and Figure 9, respectively. To obtain a high-quality and diverse subset, we compute embeddings with Qwen3-Embedding-4B and apply K-means clustering within each discipline (Ahmed et al., 2020), with cluster numbers determined by silhouette search. From each cluster, we draw an equal number of questions following a fixed difficulty ratio of 3:2:1 (Very Hard:Hard:Medium), and align per-discipline sizes with the overall bank distribution. If higher-difficulty questions are insufficient, they are backfilled with lower-difficulty ones to ensure the per-discipline totals. This process resulted in a curated set of 132,409 questions for design-logic extraction. Any question bank, regardless of its initial quality, can be processed using this filtering pipeline to obtain a high-quality and diverse subset for extracting design logics. Our method is therefore applicable to any question banks and can be directly applied to publicly available datasets.\n\n# 2.2 BOOK CORPUS PROCESSING\n\nThis corpus is processed at the chapter level, with chapters over 5,000 words split into smaller blocks and deduplicated via MinHash. Discipline labels are assigned by a ModernBERT-large classifier fine-tuned for disciplinary classification (Warner et al., 2024). Readability is predicted with\n\na BERT-based model (Turc et al., 2019) to filter incoherent or disorganized text, while helpfulness (0-5) is scored by the fineweb-edu-classifier (Lozhkov et al., 2024) to quantify educational value. Based on quotas proportional to discipline frequencies in both the book corpus and the question bank, segments with negative readability are removed. The remaining candidates are ranked by helpfulness, and the top items are selected until the quotas are met. This procedure yields three million high-quality segments, with most scoring helpfulness  $\\geq 2$ .\n\n# 2.3 WEB CORPUS PROCESSING\n\nWe apply reasoning-oriented filtering and discipline relabeling to the FineFineWeb corpus, scoring 6.5 billion texts with Qwen3-30B-A3B (non-thinking mode) using a five-level rubric (prompt in Figure 10) and retaining those with scores  $\\geq 3$ . The selected texts are then relabeled with the same model (prompt in Figure 7) to align with our 75-discipline taxonomy.\n\n# 3 DESIGN-LOGIC-GUIDED DATA SYNTHESIS\n\nFigure 2 (Phase 2 and Phase 3) illustrates the overall data synthesis pipeline.\n\n# 3.1 DESIGN LOGIC EXTRACTION\n\nHuman educators design exam questions through structured steps that transform knowledge points into complex challenges, rather than simple fact recall. A typical process involves identifying objectives, constructing contexts, designing reasoning paths, formulating answers, adding distractors, and validating the questions. Solvers must engage in multi-step reasoning beyond memorization.\n\nInspired by this, we propose a design-logic-based question synthesis method. Using the prompt in Figure 11, we instruct an LLM (DeepSeek-R1-0528) to analyze authentic questions and (i) infer the designer's thought process, (ii) trace construction from knowledge points, and (iii) abstract underlying design principles, expressed in Mermaid format. This produces a reusable pool of design logics that guides new question generation from source materials.\n\n# 3.2 DESIGN LOGIC DEDUPLICATION\n\nTo enhance the diversity of design principles, we deduplicate extracted logics using semantic similarity. Each logic is embedded with Qwen3-Embedding-4B, and pairwise similarities yield a matrix  $S \\in \\mathbb{R}^{n \\times n}$ . Within each discipline, we construct a graph  $G = (V, E)$  where nodes represent logics and edges connect pairs with  $S_{ij} \\geq \\tau$ . Connected components in the graph correspond to redundant design logic groups. From each group, we retain the item with the highest similarity sum. With  $\\tau = 0.85$ , this graph-based dedduplication procedure (Algorithm 1) yields 125,328 unique design logics, with per-discipline counts in Table 6. We provide several examples of our synthesized design logic in Appendix K.\n\n# 3.3 QUESTION SYNTHESIS\n\nTo avoid the combinatorial explosion resulting from exhaustively matching design logics with text segments, we adopt a retrieval-augmented approach. For each discipline-specific corpus, we compute the cosine similarity between embeddings of a text segment  $t$  and a design logic  $d$  using Qwen3-Embedding-4B with task-specific instructions (Figure 12):  $s(t,d) = \\cos (\\mathbf{e}(t),\\mathbf{e}(d))$ . The top-5 logics with the highest similarity are retained as candidates.\n\nWe then prompt DeepSeek-R1-0528 (Figure 13) to: (i) select the most suitable logic from the top-5 candidates, and (ii) synthesize a graduate-level exam question strictly following its steps. This two-stage process forms a coarse-to-fine ranking: similarity-based retrieval provides coarse recall, while the LLM refines the match to ensure precise alignment between text and logic, thereby improving question quality. For each question, the LLM also generates a concise reference answer.\n\nQuestion Dedduplication and Decontamination We employ a two-stage filtering pipeline: (i) MinHash-based dedduplication to remove near-duplicates, and (ii) 13-gram decontamination against\n\nall evaluation benchmarks to prevent leakage. Using the curated book and web corpora, DeepSeekR1-0528 generates one reasoning question per text segment. After filtering, the final dataset DesignLogic-Reasoning-Book (DLR-Book) comprises 3,040,620 questions from the book corpus, and Design-Logic-Reasoning-Web (DLR-Web) comprises 1,658,541 questions from the web corpus.\n\n# 3.4 RESPONSE SYNTHESIS\n\nTo demonstrate that our synthesized questions can effectively elicit and transfer the long CoT capabilities of a reasoning model and improve the performance of models trained on this data, we employ Qwen3-235B-A22B-Thinking-2507-FP8 to generate a corresponding long CoT response for each synthesized question. These question-response pairs are then used for supervised fine-tuning (SFT).\n\n# 4 DATA ANALYSIS\n\nTo assess the quality of our synthesized datasets (DLR-Book and DLR-Web), we conduct a quantitative analysis comparing their difficulty, diversity, and disciplinary distribution against the baseline datasets. The baseline datasets and benchmarks we used are detailed in Table 7 and Table 13, respectively. In all tables, we highlight the best value in **boldface** and the second-best with an **underline**. The distribution of question types for our synthesized datasets is detailed in Appendix E.\n\n# 4.1 DIFFICULTY ANALYSIS\n\nWe utilized the Qwen3-30B-A3B-Instruct-2507 model with the prompt shown in Figure 8 to assign difficulty labels to both our datasets and the baseline datasets. To facilitate an intuitive comparison of difficulty levels, we further applied the same labeling procedure to several commonly used benchmarks. As shown in Figure 3, our datasets are significantly more difficult. Notably, the proportion of \"Very Hard\" questions in our datasets is substantially higher than that in all baseline datasets and benchmarks. In contrast, the proportion of \"Easy\" questions is negligible (0.72% in DLR-Web and 0.27% in DLR-Book). The detailed distribution of difficulty levels is reported in Table 10.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/e5bda6b2fad7cffca19c19d5f0075a6f80e46acf355d99cc568d40ae5e7faecb.jpg)  \nFigure 3: Difficulty distributions of questions across different datasets and benchmarks.\n\n# 4.2 DIVERSITY ANALYSIS\n\nTo quantify dataset diversity, we generate high-dimensional vector representations for 300,000 uniformly sampled questions from each dataset using the Qwen3-Embedding-4B model. We then compute the following five distance-based diversity metrics in the embedding space: Mean Cosine Distance (Yang et al., 2025b), Mean L2 Distance (Yang et al., 2025b), 1-Nearest Neighbor (1-NN) Distance (Stasaski & Hearst, 2022), Cluster Inertia (Du & Black, 2019), and Radius (Lai et al., 2020). Detailed definitions and formulas for these metrics are provided in Appendix G.\n\nAs detailed in Table 1, our datasets, DLR-Book and DLR-Web, consistently demonstrate a greater diversity of questions compared to the baseline datasets across all five semantic diversity metrics. The higher Mean Cosine Distance and Mean L2 Distance values confirm that our synthesized questions are, on average, more semantically distinct than those in the baseline datasets, indicating a broader conceptual scope. The most notable difference is observed in the 1-NN Distance, where our datasets score approximately twice as high as the baselines. This suggests our method generates\n\nTable 1: Results of semantic diversity metrics for our synthesized datasets and the baseline datasets. Higher values indicate better performance across all metrics.  \n\n<table><tr><td>Dataset</td><td>Mean Cosine Distance</td><td>Mean L2 Distance</td><td>I-NN Distance</td><td>Cluster Inertia</td><td>Radius</td></tr><tr><td>OpenThoughts3</td><td>0.8037</td><td>1.2656</td><td>0.0051</td><td>206,369.22</td><td>0.0172</td></tr><tr><td>Nemotron-Post-Training-v1</td><td>0.8243</td><td>1.2827</td><td>0.1290</td><td>226,211.00</td><td>0.0174</td></tr><tr><td>WebInstruct (Full)</td><td>0.7762</td><td>1.2436</td><td>0.1830</td><td>205,590.02</td><td>0.0169</td></tr><tr><td>NaturalReasoning</td><td>0.8233</td><td>1.2818</td><td>0.1915</td><td>226,288.91</td><td>0.0173</td></tr><tr><td>DLR-Web</td><td>0.8494</td><td>1.3026</td><td>0.3897</td><td>238,039.50</td><td>0.0177</td></tr><tr><td>DLR-Book</td><td>0.8471</td><td>1.3008</td><td>0.3726</td><td>238,100.26</td><td>0.0176</td></tr></table>\n\nfar fewer semantically redundant questions. Furthermore, the Cluster Inertia and Radius scores for our datasets indicate that the generated questions occupy a larger and more varied volume within the semantic embedding space. This quantitative evidence confirms that our synthesis pipeline produces not only more complex and difficult questions but also a significantly more diverse set of questions. Additionally, we observe that questions synthesized from the web corpus (DLR-Web) exhibit greater diversity on most metrics than those synthesized from the book corpus (DLR-Book).\n\n# 4.3 DISCIPLINARY DISTRIBUTION\n\nWe also used Qwen3-30B-A3B and the prompt in Figure 7 to assign disciplinary labels to the baseline datasets. We present a comparison of discipline distributions between our dataset and baseline datasets in Figure 4. For visualization, we highlight the ten most dominant disciplines within each dataset and those most representative of broader academic categories, while aggregating the remaining disciplines into the gray category \"Other.\" It is evident that many existing multidisciplinary datasets are heavily skewed toward a few disciplines, such as mathematics, leading to a highly imbalanced distribution across disciplines. Among them, only the Nemotron-Post-Training-v1 dataset exhibits a distribution comparable to ours, but its question difficulty and reasoning depth are substantially lower. The detailed number of questions per discipline in our dataset is provided in Table 6.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/cc60386fc78bef91478b911244f7a4c52daec62b9998443cfde0a5d88646701d.jpg)  \nFigure 4: Discipline distribution across different datasets.\n\n# 4.4 DATA QUALITY AND LABEL ACCURACY VALIDATION\n\nTo assess the reliability of our method, we employed GPT-5.1 to conduct a multi-dimensional evaluation on 10,000 randomly sampled instances. We utilized the prompts detailed in Figure 14, Figure 15, and Figure 16 to assess content quality, and further employed the prompts in Figure 17, Figure 18, and Figure 19 to validate the appropriateness of the assigned discipline, difficulty, and question type labels, respectively. Our analysis demonstrates high data integrity:  $96.70\\%$  of the synthesized questions were verified as complete and answerable, providing sufficient conditions to derive solutions. Furthermore,  $84.69\\%$  of the questions exhibited strict alignment with their corresponding design logics. The evaluation of labels also showed high accuracy, with  $90.14\\%$ ,  $96.53\\%$ ,\n\nand  $91.22\\%$  of the instances confirmed to have appropriate discipline, difficulty, and question type labels, respectively. Finally, we evaluated the consistency between the reference answers generated by DeepSeek-R1-0528 and the long Chain-of-Thought (CoT) responses generated by Qwen3-235B-A22B-Thinking-2507-FP8, achieving a  $71.48\\%$  agreement rate. A significant portion of our synthesized data comprises complex, open-ended reasoning questions. In disciplines such as Humanities, Social Sciences, Arts, and Applied Professional Fields, questions inherently lack a single fixed answer. Consequently, this result is reasonable given the inherent diversity of valid reasoning paths in open-ended multidisciplinary questions.\n\n# 5 EXPERIMENTS\n\n# 5.1 EXPERIMENTAL SETUP\n\nSFT Settings For all SFT experiments, we adhere to the hyperparameters detailed in Table 11.\n\nEvaluation Settings To ensure a fair comparison, we employ a zero-shot evaluation setting for all trained models, using the consistent generation configuration specified in Table 12. Depending on the characteristics of each benchmark, we perform  $N$  independent sampling rollouts for each test instance. For  $N = 1$ , we report accuracy. For  $N > 1$ , we report mean accuracy (\\%) together with the standard deviation, and we also report the accuracy (\\%) under the Self-Consistency with Chain-of-Thought (CoT-SC) method, defined as the majority vote over the  $N$  generated samples.\n\nBenchmarks We evaluate the model's multidisciplinary reasoning capability using the most widely adopted benchmarks. The benchmarks, along with their respective disciplines and the number of rollouts  $(N)$ , are detailed in Table 13.\n\n# 5.2 SUPERVISED FINE-TUNING (SFT) EXPERIMENTS\n\nWe performed SFT on base models from the Qwen3 and Llama3 series using our synthetic datasets, DLR-Book and DLR-Web. The resulting models were subsequently compared against their official final models that have undergone the full Post-training process under our evaluation framework.\n\nTable 3: SFT experiment results. The models are trained on DLR-Web, DLR-Book, or the combined DLR-Web + DLR-Book dataset.  \n\n<table><tr><td rowspan=\"2\">Model</td><td>MMLU</td><td>MMLU-Pro</td><td colspan=\"2\">GPQA-Diamond</td><td colspan=\"2\">GPQA-Man</td><td>SuperGPQA</td></tr><tr><td>Accuracy</td><td>Accuracy</td><td>Accuracy</td><td>CoT-SC</td><td>Accuracy</td><td>CoT-SC</td><td>Accuracy</td></tr><tr><td>Llama-3.2-3B-Instruct</td><td>57.71</td><td>31.18</td><td>21.97±2.54</td><td>20.20</td><td>25.07±1.64</td><td>24.78</td><td>16.39</td></tr><tr><td>Llama-3.2-3B-SFT (DLR-Web)</td><td>66.74</td><td>49.81</td><td>22.42±2.06</td><td>20.71</td><td>25.54±1.39</td><td>26.12</td><td>20.31</td></tr><tr><td>Llama-3.2-3B-SFT (DLR-Book)</td><td>70.61</td><td>57.09</td><td>38.33±2.63</td><td>44.44</td><td>33.82±1.17</td><td>35.27</td><td>26.39</td></tr><tr><td>Llama-3.2-3B-SFT (DLR-Web+Book)</td><td>73.53</td><td>61.36</td><td>42.27±1.72</td><td>43.94</td><td>38.91±1.78</td><td>43.97</td><td>29.64</td></tr><tr><td>Llama-3.1-8B-Instruct</td><td>70.86</td><td>47.38</td><td>23.18±1.78</td><td>24.75</td><td>27.99±1.40</td><td>28.57</td><td>20.08</td></tr><tr><td>Llama-3.1-8B-SFT (DLR-Web)</td><td>81.75</td><td>72.64</td><td>57.73±2.16</td><td>63.64</td><td>55.45±2.07</td><td>58.71</td><td>39.66</td></tr><tr><td>Llama-3.1-8B-SFT (DLR-Book)</td><td>83.33</td><td>74.94</td><td>63.23±1.37</td><td>66.67</td><td>62.25±1.31</td><td>67.19</td><td>43.48</td></tr><tr><td>Llama-3.1-8B-SFT (DLR-Web+Book)</td><td>84.13</td><td>76.04</td><td>65.45±1.47</td><td>70.71</td><td>63.62±1.23</td><td>67.86</td><td>45.06</td></tr><tr><td>Qwen3-4B (Thinking Mode)</td><td>82.87</td><td>69.34</td><td>54.70±2.42</td><td>58.08</td><td>49.51±1.40</td><td>51.12</td><td>43.30</td></tr><tr><td>Qwen3-4B-Base-SFT (DLR-Web)</td><td>83.55</td><td>71.24</td><td>53.74±3.33</td><td>60.61</td><td>51.27±1.57</td><td>55.36</td><td>42.73</td></tr><tr><td>Qwen3-4B-Base-SFT (DLR-Book)</td><td>84.73</td><td>73.03</td><td>62.58±1.36</td><td>68.69</td><td>56.85±0.91</td><td>61.16</td><td>45.86</td></tr><tr><td>Qwen3-4B-Base-SFT (DLR-Web+Book)</td><td>85.00</td><td>73.06</td><td>63.69±2.15</td><td>70.20</td><td>58.73±1.36</td><td>63.62</td><td>46.15</td></tr><tr><td>Qwen3-8B (Thinking Mode)</td><td>85.85</td><td>73.62</td><td>59.44±2.53</td><td>60.61</td><td>57.95±1.47</td><td>59.38</td><td>47.52</td></tr><tr><td>Qwen3-8B-Base-SFT (DLR-Web)</td><td>86.82</td><td>75.62</td><td>63.28±2.43</td><td>66.67</td><td>61.43±0.98</td><td>66.07</td><td>48.66</td></tr><tr><td>Qwen3-8B-Base-SFT (DLR-Book)</td><td>87.53</td><td>76.69</td><td>69.39±1.87</td><td>73.74</td><td>65.07±0.98</td><td>68.30</td><td>50.57</td></tr><tr><td>Qwen3-8B-Base-SFT (DLR-Web+Book)</td><td>87.60</td><td>76.72</td><td>71.01±2.33</td><td>75.76</td><td>65.40±1.05</td><td>69.20</td><td>50.90</td></tr></table>\n\nAs shown in Table 3, SFT with our synthetic datasets significantly improves model performance. The consistent improvements across diverse benchmarks demonstrate that our synthetic data method does not overfit to any specific domain or benchmark, but instead enhances the model's general and robust reasoning capability. Notably, the multidisciplinary reasoning performance of the base models fine-tuned on our datasets even surpasses that of their official final models that have undergone the full post-training process across all benchmarks. This improvement is particularly pronounced on highly complex reasoning tasks like GPQA-Diamond. These results affirm the efficacy of our data synthesis strategy for enhancing the multidisciplinary reasoning capabilities of LLMs. In addition, we provide the SFT experiment results on GSM8K and MATH-500 in Appendix I.\n\nTable 4: Comparison with other baseline datasets on the Qwen3-8B-Base model.  \n\n<table><tr><td>Dataset</td><td>MMLU</td><td>MMLU-Pro</td><td>GPQA-Diamond</td><td>GPQA-Diamond (CoT-SC)</td><td>SuperGPQA</td></tr><tr><td>OpenThoughts3</td><td>72.49</td><td>57.76</td><td>45.86±1.80</td><td>54.04</td><td>39.70</td></tr><tr><td>Nemotron-Post-Training-v1</td><td>77.17</td><td>62.52</td><td>38.59±1.24</td><td>40.91</td><td>42.03</td></tr><tr><td>WebInstruct (Full)</td><td>86.34</td><td>72.83</td><td>55.61±2.50</td><td>62.63</td><td>45.37</td></tr><tr><td>NaturalReasoning</td><td>85.33</td><td>72.39</td><td>56.67±2.20</td><td>60.00</td><td>43.38</td></tr><tr><td>DLR-Web</td><td>86.32</td><td>73.81</td><td>58.89±1.98</td><td>63.64</td><td>47.23</td></tr><tr><td>DLR-Book</td><td>86.43</td><td>74.98</td><td>60.35±1.93</td><td>66.67</td><td>47.04</td></tr></table>\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/81f11aa12dcd9aed9ef35b0c4a4f376d40b7a283f886d4fb77bc619cb5a7c082.jpg)  \nFigure 5: Performance scaling with synthesized data size. Benchmark accuracy increases steadily with data scale.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/95838be721c71b6987dab83310456faa7f000db635789935cb57be4cd9886980.jpg)  \nFigure 6: Performance comparison of models trained on data synthesized from lower-quality web corpora versus higher-quality book corpora.\n\n# 5.3 COMPARISON WITH BASELINE DATASETS\n\nWe conducted a comparative analysis between our synthetically generated data and other prominent open-source synthetic datasets. To ensure a fair comparison, given the varying sizes of the original datasets, we randomly sampled an equal number of 304,181 instances from each dataset for the SFT experiments. For OpenThoughts3 and Nemotron-Post-Training-v1, the synthetic datasets already contain elaborate long CoT responses, so we retain their native versions. In contrast, the native responses in WebInstruct (Full) and NaturalReasoning are relatively simple. To enable a fairer comparison, we regenerate long CoT responses for them using the same model and settings as in our dataset, ensuring that performance differences arise solely from the questions.\n\nAs shown in Table 4, the models trained on our datasets consistently outperform those trained on other baseline datasets across all benchmarks. Specifically, DLR-Book achieves the best performance on MMLU, MMLU-Pro, and GPQA-Diamond, while DLR-Web attains the highest score on SuperGPQA and ranks second on most other benchmarks. These results demonstrate the superior quality and effectiveness of our data synthesis approach compared to existing methods.\n\n# 5.4 EFFECT OF DATA SCALING\n\nTo validate the scalability of our data synthesis methodology, we conducted experiments using the Qwen3-8B-Base model, training it on progressively larger subsets sampled from the DLR-Book dataset. The results, shown in Figure 5, demonstrate a consistent positive correlation between the scale of the synthetic data and model performance across all benchmarks. The observed scaling laws confirm that our method provides a reliable pathway to achieving superior model performance by synthesizing more data. Future work can leverage our proposed design logics to synthesize even larger datasets for continued improvement.\n\n# 5.5 EFFECT OF SOURCE CORPUS QUALITY\n\nIt is widely acknowledged that book corpora are of higher quality than web corpora (Brown et al., 2020; Gao et al., 2020; Rae et al., 2021). To evaluate the impact of source quality on our data synthesis method, we conducted an SFT experiment on the Qwen3-8B-Base model, comparing data synthesized from the high-quality book corpus with that from the web corpus. To ensure a fair comparison, we matched the disciplinary distribution across both sources. For disciplines with limited FineFineWeb data, we used all available instances; otherwise, we applied random sampling. This procedure yielded two datasets of identical size (282,857 instances) and per-discipline distribution.\n\nAs shown in Figure 6, the model fine-tuned on data from the book corpus outperforms the one trained on data from the web corpus across most benchmarks, with the largest gains on complex reasoning tasks such as GPQA-Diamond and SuperGPQA. Nevertheless, the performance gap induced by the two source corpora of differing quality is negligible, which demonstrates that our method is robust to variations in source quality and can reliably generate high-quality questions even when applied to lower-quality corpora.\n\n# 5.6 ABLATION STUDIES\n\nWe conducted an ablation study on our question-synthesis pipeline using the Qwen3-8B-Base to assess the contributions of three key components: guidance from design logics, the coarse ranking, and the fine ranking of design logics. To ensure fair comparison, all ablation variants synthesized questions from the same book corpus by uniformly sampling 304,181 instances. Where applicable, we used identical retrieval with Qwen3-Embedding-4B and generated responses using the same model, Qwen3-235B-A22B-Thinking-2507-FP8. Specifically, we evaluate the following four settings:\n\n- DESIGNER: This is our complete method, which includes coarse retrieval of the top-5 design logics by similarity, followed by LLM-based fine selection and synthesis based on \"design logic\".  \n- w/o Design Logic: This setting replaces our use of explicit design logics. Instead of being guided by a logic, the LLM is prompted to generate a new question by imitating the style and structure of the most suitable exemplar. This exemplar is selected from a set of 5 relevant example questions that are retrieved from the question bank.  \n- w/o Coarse Ranking: This setting bypasses the semantic similarity-based retrieval of the top-5 relevant design logics. Instead, the LLM is prompted to select the most suitable logic from a set of 5 randomly chosen design logics.  \n- w/o Fine Ranking: This setting removes the LLM-based re-ranking stage. The single most similar design logic (the top-1 result from the coarse retrieval) is used directly to generate the question.\n\nTable 5: Ablation study of our data synthesis pipeline.  \n\n<table><tr><td>Method</td><td>MMLU</td><td>MMLU-Pro</td><td>GPQA-Diamond</td><td>GPQA-Diamond (CoT-SC)</td><td>SuperGPQA</td></tr><tr><td>DESIGNER</td><td>86.43</td><td>74.98</td><td>60.35±1.93</td><td>66.67</td><td>47.04</td></tr><tr><td>w/o Design Logic</td><td>86.26</td><td>74.34</td><td>58.89±2.94</td><td>64.65</td><td>46.71</td></tr><tr><td>w/o Coarse Ranking</td><td>86.29</td><td>73.76</td><td>58.74±0.75</td><td>62.63</td><td>46.23</td></tr><tr><td>w/o Fine Ranking</td><td>86.26</td><td>74.35</td><td>59.34±2.20</td><td>63.64</td><td>46.81</td></tr><tr><td>DESIGNER (Full)</td><td>87.53</td><td>76.69</td><td>69.39±1.87</td><td>73.74</td><td>50.57</td></tr><tr><td>w/o Design Logic (Full)</td><td>86.51</td><td>75.54</td><td>64.10±2.81</td><td>67.17</td><td>48.46</td></tr></table>\n\nTable 5 summarizes the results of our ablation studies. Our complete \"DESIGNER\" approach consistently outperforms ablated configurations across most benchmarks. The better performance of using design logics relative to directly using questions as examples confirmed our hypothesis that explicit logical structures are more accurate and robust guides for high-quality question synthesis. The removal of either coarse-grained retrieval (w/o Coarse Ranking) or fine-grained LLM re-ranking (w/o Fine Ranking) causes a performance drop, confirming the value of each stage in our two-step matching process. We further evaluated the \"w/o Design Logic\" variant on the full book corpus (3.04 million samples). The performance degradation of \"w/o Design Logic (Full)\" is notably significant. Specifically, on the GPQA-Diamond benchmark, the performance gap between \"w/o Design Logic\n\n(Full)” and the model employing \"Design Logic\" reaches five percentage points, providing stronger evidence for the advantage of employing design logic.\n\n# 6 RELATED WORK\n\nData Synthesis Paradigms Existing data synthesis methods can be broadly grouped into query-centric and doc-centric approaches. Query-centric approaches iteratively expand a seed query pool: Self-Instruct (Wang et al., 2023) samples from an initial pool to generate new QA pairs, while Wizard LM (Luo et al., 2024; Xu et al., 2023; Luo et al., 2025) and Auto Evol-Instruct (Zeng et al., 2024) evolve instructions for greater diversity and complexity. CoT-Self-Instruct (Yu et al., 2025) integrates reasoning into generation, Prismatic Synthesis (Jung et al., 2025) emphasizes gradient-level diversity, and SPARQ (Havrilla et al., 2025) evaluates difficulty and diversity, linking them to in- and out-of-distribution performance. However, these methods remain constrained by the coverage of the seed pool and the inherent model biases. Doc-centric approaches instead derive questions directly from raw corpora, ensuring stronger factual grounding: UltraChat (Ding et al., 2023) generates world-knowledge questions from sources like Wikidata, Humpback (Li et al., 2024) infers instructions backward from documents, MAmmoTH2 (Yue et al., 2024) mines web content via a Recall-Extract-Refine pipeline. NaturalReasoning (Yuan et al., 2025) focuses on generating high-difficulty reasoning questions, but its diversity is inherently limited by a single prompt template. Furthermore, several studies have explored generating new questions through external guidance, such as KPDDS (Huang et al., 2025), and the structurally guided approaches of Xu et al. (2025), Wang et al. (2025), and Bu et al. (2025). However, these approaches have two primary limitations compared to our method. First, they are query-centric methods that synthesize new questions from seed questions, which inherently constrains them to the scope of the initial seed pool and prevents generation from richer raw corpora. Second, their methodologies are tailored for disciplines with strong logical and structural reasoning, such as mathematics and coding, and cannot be readily extended to arbitrary multidisciplinary fields, such as the humanities, social sciences, and medicine. In contrast, our method synthesizes challenging and diverse questions by introducing multidisciplinary design logics to align with the corresponding documents. This approach is discipline-agnostic, making it applicable to any discipline.\n\nReasoning Data Synthesis Another line of work primarily investigates the synthesis of CoT reasoning data. DeepSeek (Guo et al., 2025) transfers reasoning skills from DeepSeek-R1 to open-source models, while OpenMathReasoning (Moshkov et al., 2025) augments math ability by generating long CoT traces for AoPS problems. OmniThought (Cai et al., 2025) collects multidisciplinary questions (math, code, science) to build a large CoT distillation dataset, and OpenThoughts (Guha et al., 2025) systematically explores recipes for generating long reasoning traces across these domains. While these approaches primarily focus on generating high-quality reasoning processes for existing questions, they lack the capability to produce original, diverse, and multidisciplinary questions, which is the central focus of our method.\n\n# 7 CONCLUSION\n\nIn this paper, we introduced DESIGNER, a novel design-logic-guided data synthesis pipeline designed to address the scarcity of high-quality, multidisciplinary reasoning data for LLMs. Our core innovation is the concept of \"Design Logic\", which abstracts the strategic process that human experts use to create challenging questions. By leveraging design logics, we generated two large-scale datasets, DLR-Book and DLR-Web, comprising millions of complex questions across 75 disciplines from raw text sources. We validated the effectiveness of our approach through extensive experiments, demonstrating that models fine-tuned with our data achieve substantial performance gains in multidisciplinary reasoning. Importantly, the value of design logic lies not only in its effect on final performance but also in its controllable, abstractable, and generalizable synthesis mechanism. The guidance of the design logic is crucial for ensuring the difficulty and diversity of the synthesized questions. Section 4.1 shows that our design logics allow precise control over problem difficulty, enabling the generation of highly challenging questions far beyond baseline datasets and commonly used benchmarks. Section 4.2 shows that design-logic-guided synthesis achieves higher scores on all five diversity metrics compared with baseline datasets.\n\n# ETHICS STATEMENT\n\nAll materials used in this study were subjected to filtering to minimize the inclusion of potentially harmful content. We encourage researchers who utilize our datasets to implement stricter filtering and processing measures to further ensure that the data conforms to the principles of ethical use.\n\n# REPRODUCIBILITY STATEMENT\n\nWe provide all complete and detailed data processing steps used for data synthesis in the main paper and in the appendix. To facilitate reproducibility and independent verification, we have released a subset of our synthesized data that does not involve legal compliance concerns or potential conflicts of interest. The released data include our synthesized questions, reference answers, long CoT responses, the corresponding source corpora and design logic, as well as associated labels (e.g., discipline, difficulty, question type), enabling reproduction and validation of our method's effectiveness and the quality of the synthesized data. Furthermore, we have released a design-logic library that contains all design logics extracted in this study, together with discipline, difficulty, and question type labels, enabling the research community to directly match these design logics to their own raw documents and synthesize new questions that exhibit the same complex reasoning.\n\n# THE USE OF LARGE LANGUAGE MODELS (LLMS)\n\nWe employed Large Language Models (LLMs) to assist us in polishing our paper and writing code.\n\n# REFERENCES\n\nMohiuddin Ahmed, Raihan Seraj, and Syed Mohammed Shamsul Islam. The k-means algorithm: A comprehensive survey and performance evaluation. *Electronics*, 9(8):1295, 2020.  \nAkhiad Bercovich, Itay Levy, Izik Golan, Mohammad Dabbah, Ran El-Yaniv, Omri Puny, Ido Galil, Zach Moshe, Tomer Ronen, Najeeb Nabwani, et al. Llama-nemotron: Efficient reasoning models. arXiv preprint arXiv:2505.00949, 2025.  \nTom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020.  \nTianpeng Bu, Minying Zhang, Hongtao Duan, Shurui Li, Lulu Hu, and Yu Li. Enhanced data synthesis for llm through reasoning structures generated by hierarchical gflownet. In Findings of the Association for Computational Linguistics: ACL 2025, pp. 15931-15958, 2025.  \nWenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, and Xiangzhong Fang. Reasoning with omnithought: A large cot dataset with morbidity and cognitive difficulty annotations. arXiv preprint arXiv:2505.10937, 2025.  \nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. Journal of Machine Learning Research, 24(240): 1-113, 2023.  \nNing Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. Enhancing chat language models by scaling high-quality instructional conversations. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 3029-3051, 2023.  \nWenchao Du and Alan W Black. Boosting dialog response generation. In Anna Korhonen, David Traum, and Lluis Marquez (eds.), Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 38-43, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1005. URL https://aclanthology.org/P19-1005/.\n\nXinrun Du, Yifan Yao, Kaijing Ma, Bingli Wang, Tianyu Zheng, King Zhu, Minghao Liu, Yiming Liang, Xiaolong Jin, Zhenlin Wei, et al. Supergpqa: Scaling llm evaluation across 285 graduate disciplines. arXiv preprint arXiv:2502.14739, 2025.  \nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. arXiv e-prints, pp. arXiv-2407, 2024.  \nLeo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.  \nEtash Guha, Ryan Marten, Sedrick Keh, Negin Raoof, Georgios Smyrnis, Hritik Bansal, Marianna Nezhurina, Jean Mercat, Trung Vu, Zayne Sprague, et al. Openthoughts: Data recipes for reasoning models. arXiv preprint arXiv:2506.04178, 2025.  \nDaya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025.  \nAlex Havrilla, Edward Hughes, Mikayel Samvelyan, and Jacob Abernethy. Synthetic problem generation for reasoning via quality-diversity algorithms. arXiv preprint arXiv:2506.06499, 2025.  \nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.  \nYiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou, Yelong Shen, Nan Duan, and Weizhu Chen. Key-point-driven data synthesis with its enhancement on mathematical reasoning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pp. 24176-24184, 2025.  \nAaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card. arXiv preprint arXiv:2412.16720, 2024.  \nJaehun Jung, Seungju Han, Ximing Lu, Skyler Hallinan, David Acuna, Shrimai Prabhumoye, Mostafa Patwary, Mohammad Shoeybi, Bryan Catanzaro, and Yejin Choi. Prismatic synthesis: Gradient-based data diversification boosts generalization in lIm reasoning. arXiv preprint arXiv:2505.20161, 2025.  \nYi-An Lai, Xuan Zhu, Yi Zhang, and Mona Diab. Diversity, density, and homogeneity: Quantitative characteristic metrics for text collections. In Nicoletta Calzolari, Frédéric Béchet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, Hélène Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (eds.), Proceedings of the Twelfth Language Resources and Evaluation Conference, pp. 1739-1746, Marseille, France, May 2020. European Language Resources Association. ISBN 979-10-95546-34-4. URL https://aclanthology.org/2020.lrec-1.215/.  \nXian Li, Ping Yu, Chunting Zhou, Timo Schick, Omer Levy, Luke Zettlemoyer, Jason Weston, and Mike Lewis. Self-alignment with instruction backtranslation. In ICLR, 2024.  \nAnton Lozhkov, Loubna Ben Allal, Leandro von Werra, and Thomas Wolf. Fineweb-edu: the finest collection of educational content, 2024. URL https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu.  \nHaipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-Guang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Yansong Tang, et al. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. In The Thirteenth International Conference on Learning Representations, 2025.  \nZiyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with evol-instruct. In The Twelfth International Conference on Learning Representations, 2024.\n\nIvan Moshkov, Darragh Hanley, Ivan Sorokin, Shubham Toshniwal, Christof Henkel, Benedikt Schifferer, Wei Du, and Igor Gitman. Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with openmathreasoning dataset. arXiv preprint arXiv:2504.16891, 2025.  \nOpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.  \nLong Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanity's last exam. arXiv preprint arXiv:2501.14249, 2025.  \nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446, 2021.  \nDavid Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R Bowman. Gpqa: A graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024.  \nKatherine Stasaski and Marti Hearst. Semantic diversity in dialogue with natural language inference. In Marine Carpuat, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz (eds.), Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 85-98, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.6. URL https://aclanthology.org/2022.nacl-main.6/.  \nTrieu H Trinh, Yuhuai Wu, Quoc V Le, He He, and Thang Luong. Solving olympiad geometry without human demonstrations. Nature, 625(7995):476-482, 2024.  \nIulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Well-read students learn better: On the importance of pre-training compact models. arXiv preprint arXiv:1908.08962, 2019.  \nJoshua Vendrow, Edward Vendrow, Sara Beery, and Aleksander Madry. Do large language model benchmarks test reliability? arXiv preprint arXiv:2502.03461, 2025.  \nJiapeng Wang, Jinhao Jiang, Zhiqiang Zhang, Jun Zhou, and Wayne Xin Zhao. Rv-syn: Rational and verifiable mathematical reasoning data synthesis based on structured function library. arXiv preprint arXiv:2504.20426, 2025.  \nKe Wang, Jiahui Zhu, Minjie Ren, Zeming Liu, Shiwei Li, Zongye Zhang, Chenkai Zhang, Xiaoyu Wu, Qiqi Zhan, Qingjie Liu, et al. A survey on data synthesis and augmentation for large language models. arXiv preprint arXiv:2410.12896, 2024a.  \nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. Self-instruct: Aligning language models with self-generated instructions. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 13484-13508, 2023.  \nYubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. Mmlu-pro: A more robust and challenging multitask language understanding benchmark. Advances in Neural Information Processing Systems, 37:95266-95290, 2024b.  \nBenjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, et al. Smarter, better, faster, longer: A modern bidirectional encoder for fast, memory efficient, and long context finetuning and inference. arXiv preprint arXiv:2412.13663, 2024.  \nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824-24837, 2022.\n\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244, 2023.  \nLei Xu, Sirui Chen, Yuxuan Huang, and Chaochao Lu. Synthesis by design: Controlled data generation via structural guidance. arXiv preprint arXiv:2506.07664, 2025.  \nAn Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388, 2025a.  \nYuming Yang, Yang Nan, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, Huijie Lv, Mingqi Wu, Tao Gui, Qi Zhang, et al. Measuring data diversity for instruction tuning: A systematic analysis and a reliable metric. arXiv preprint arXiv:2502.17184, 2025b.  \nPing Yu, Jack Lanchantin, Tianlu Wang, Weizhe Yuan, Olga Golovneva, Ilia Kulikov, Sainbayar Sukhbaatar, Jason Weston, and Jing Xu. Cot-self-instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks. arXiv preprint arXiv:2507.23751, 2025.  \nWeizhe Yuan, Jane Yu, Song Jiang, Karthik Padthe, Yang Li, Ilia Kulikov, Kyunghyun Cho, Dong Wang, Yuandong Tian, Jason E Weston, et al. Naturalreasoning: Reasoning in the wild with 2.8 m challenging questions. arXiv preprint arXiv:2502.13124, 2025.  \nXiang Yue, Tianyu Zheng, Ge Zhang, and Wenhu Chen. Mammoth2: Scaling instructions from the web. Advances in Neural Information Processing Systems, 37:90629-90660, 2024.  \nWeihao Zeng, Can Xu, Yingxiu Zhao, Jian-Guang Lou, and Weizhu Chen. Automatic instruction evolving for large language models. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pp. 6998-7018, 2024.  \nQihao Zhu, Daya Guo, Zhihong Shao, Dejian Yang, Peiyi Wang, Runxin Xu, Y Wu, Yukun Li, Huazuo Gao, Shirong Ma, et al. Deepseek-coder-v2: Breaking the barrier of closed-source models in code intelligence. arXiv preprint arXiv:2406.11931, 2024.\n\n# A DATA COLLECTION DETAILS\n\nWe curate three primary data sources and define a comprehensive discipline taxonomy:\n\n- Web Corpus: For the web corpus, we employ FineFineWeb², a filtered subset of the Common Crawl dataset.  \n- Book Corpus: We utilize a proprietary library of books.  \n- Question Bank: A proprietary repository of examination and practice items.\n\nDiscipline Taxonomy: We have established a disciplinary classification system comprising 75 distinct disciplines, as shown in Table 6. This discipline taxonomy provides comprehensive coverage across several major areas:\n\n- STEM: Science, Technology, Engineering, and Mathematics.  \n- Humanities and Social Sciences: Including fields such as law, philosophy, and sociology.  \n- Applied and Professional Fields: Encompassing domains like clinical medicine, education, and business administration.  \nArts.\n\n# B DESIGN LOGIC DEDUPLICATION ALGORITHM\n\nAlgorithm 1 Graph-based Dedduplication via Centroid Selection  \n1: Input: A set of items  $\\mathcal{D} = \\{d_1,\\dots ,d_n\\}$  , a similarity matrix  $S\\in \\mathbb{R}^{n\\times n}$  , a similarity threshold  $\\tau$    \n2: Output: A deduplicated set of representative items  $\\mathcal{R}$    \n3:   \n4: Initialize an undirected graph  $G = (V,E)$  where  $V = \\{1,\\ldots ,n\\}$  and  $E = \\emptyset$    \n5: Initialize the set of representatives  $\\mathcal{R} = \\emptyset$    \n6:   \n7: // Build a similarity graph where nodes are items and edges connect similar items.   \n8: for  $i = 1$  to  $n$  do   \n9: for  $j = i + 1$  to  $n$  do   \n10: if  $S_{ij} > \\tau$  then   \n11: Add edge  $(i,j)$  to  $E$    \n12: end if   \n13: end for   \n14: end for   \n15:   \n16: // Identify clusters of duplicates by finding connected components.   \n17: Let  $\\mathcal{C}\\gets$  FindConnectedComponents  $(G)$    \n18:   \n19: // Select the most representative item (centroid) from each cluster.   \n20: for each connected component  $C\\in \\mathcal{C}$  do   \n21: Find centroid index  $i^{*} = \\arg \\max_{i\\in C}\\sum_{j\\in C,j\\neq i}S_{ij}$    \n22: Add item  $d_{i^*}$  to  $\\mathcal{R}$    \n23: end for   \n24:   \n25: return  $\\mathcal{R}$\n\n# C DESIGN LOGIC AND QUESTION QUANTITY\n\nTable 6: Number of Design Logics, book questions, and web questions by discipline.  \n\n<table><tr><td>Discipline</td><td>Design Logic</td><td>Book Question</td><td>Web Question</td></tr><tr><td>Aerospace Science and Technology</td><td>980</td><td>15025</td><td>1815</td></tr><tr><td>Agricultural Engineering</td><td>966</td><td>14950</td><td>11312</td></tr><tr><td>Agricultural Resources and Environment</td><td>409</td><td>14978</td><td>1443</td></tr><tr><td>Animal Husbandry</td><td>121</td><td>15023</td><td>318</td></tr><tr><td>Archaeology</td><td>776</td><td>15061</td><td>2572</td></tr><tr><td>Architecture</td><td>801</td><td>14931</td><td>4235</td></tr><tr><td>Art and Design</td><td>998</td><td>15164</td><td>12720</td></tr><tr><td>Astronomy</td><td>1600</td><td>40010</td><td>14915</td></tr><tr><td>Atmospheric Sciences</td><td>973</td><td>15029</td><td>3416</td></tr><tr><td>Basic Medicine</td><td>2289</td><td>49930</td><td>7118</td></tr><tr><td>Bioengineering</td><td>1041</td><td>11216</td><td>1059</td></tr><tr><td>Biology</td><td>4654</td><td>200078</td><td>111988</td></tr><tr><td>Biomedical Engineering</td><td>790</td><td>15120</td><td>5439</td></tr><tr><td>Business Administration</td><td>3873</td><td>99739</td><td>46337</td></tr><tr><td>Chemical Engineering and Technology</td><td>1393</td><td>20014</td><td>5235</td></tr><tr><td>Chemistry</td><td>6430</td><td>199839</td><td>68211</td></tr><tr><td>Chinese History</td><td>784</td><td>14876</td><td>14564</td></tr><tr><td>Chinese Language and Literature</td><td>998</td><td>14984</td><td>22233</td></tr><tr><td>Civil Engineering</td><td>950</td><td>14899</td><td>7773</td></tr><tr><td>Clinical Medicine</td><td>2844</td><td>99735</td><td>77182</td></tr><tr><td>Computer Science and Technology</td><td>4674</td><td>99796</td><td>219474</td></tr><tr><td>Control Science and Engineering</td><td>1338</td><td>20013</td><td>3254</td></tr><tr><td>Ecology</td><td>968</td><td>15113</td><td>4285</td></tr><tr><td>Economics</td><td>3864</td><td>99906</td><td>20064</td></tr><tr><td>Education</td><td>1287</td><td>20018</td><td>9824</td></tr><tr><td>Electrical Engineering</td><td>2904</td><td>59937</td><td>36949</td></tr><tr><td>Electronic Science and Technology</td><td>1445</td><td>19880</td><td>18864</td></tr><tr><td>English and Foreign Languages</td><td>985</td><td>29908</td><td>1344</td></tr><tr><td>Environmental Science and Engineering</td><td>1478</td><td>19954</td><td>28226</td></tr><tr><td>Ethnology</td><td>210</td><td>14856</td><td>51</td></tr><tr><td>Food Science and Engineering</td><td>768</td><td>15073</td><td>2470</td></tr><tr><td>Forensic Medicine</td><td>295</td><td>15010</td><td>34</td></tr><tr><td>Geography</td><td>2812</td><td>59987</td><td>12295</td></tr><tr><td>Geological Resources and Geological Engineering</td><td>173</td><td>15058</td><td>374</td></tr><tr><td>Geology</td><td>987</td><td>14958</td><td>5447</td></tr><tr><td>Geophysics</td><td>982</td><td>20050</td><td>3736</td></tr><tr><td>History of Science and Technology</td><td>494</td><td>14991</td><td>111</td></tr><tr><td>Hydraulic Engineering</td><td>664</td><td>14973</td><td>649</td></tr><tr><td>Information Resources Management</td><td>356</td><td>14968</td><td>69</td></tr><tr><td>Information and Communication Engineering</td><td>2367</td><td>39825</td><td>4777</td></tr><tr><td>Instrument Science and Technology</td><td>687</td><td>15017</td><td>378</td></tr><tr><td>Journalism and Communication</td><td>932</td><td>14847</td><td>4326</td></tr><tr><td>Law</td><td>2706</td><td>80110</td><td>62699</td></tr><tr><td>Management Science and Engineering</td><td>1317</td><td>20020</td><td>10440</td></tr><tr><td>Marine Sciences</td><td>852</td><td>14968</td><td>1228</td></tr><tr><td>Materials Science and Engineering</td><td>1949</td><td>40121</td><td>12263</td></tr><tr><td>Mathematics</td><td>9884</td><td>299464</td><td>181537</td></tr><tr><td>Mechanical Engineering</td><td>2955</td><td>59998</td><td>55356</td></tr><tr><td>Mechanics</td><td>1752</td><td>40046</td><td>4012</td></tr></table>\n\nContinued on next page\n\nTable 6: (Continued) Number of Design Logics, book questions, and web questions by discipline.  \n\n<table><tr><td>Discipline</td><td>Design Logic</td><td>Book Question</td><td>Web Question</td></tr><tr><td>Mining Engineering</td><td>282</td><td>14986</td><td>438</td></tr><tr><td>Naval Architecture and Ocean Engineering</td><td>571</td><td>15034</td><td>515</td></tr><tr><td>Nuclear Science and Technology</td><td>1448</td><td>19988</td><td>1981</td></tr><tr><td>Nursing</td><td>767</td><td>15078</td><td>2228</td></tr><tr><td>Optical Engineering</td><td>927</td><td>14995</td><td>3272</td></tr><tr><td>Petroleum and Natural Gas Engineering</td><td>571</td><td>15040</td><td>988</td></tr><tr><td>Pharmacy</td><td>1829</td><td>39921</td><td>12756</td></tr><tr><td>Philosophy</td><td>4363</td><td>100029</td><td>128004</td></tr><tr><td>Physical Education</td><td>890</td><td>14912</td><td>10712</td></tr><tr><td>Physics</td><td>5768</td><td>199771</td><td>104982</td></tr><tr><td>Political Science</td><td>3268</td><td>59686</td><td>52586</td></tr><tr><td>Power Engineering and Engineering Thermophysics</td><td>704</td><td>14918</td><td>1199</td></tr><tr><td>Psychology</td><td>4336</td><td>99502</td><td>95585</td></tr><tr><td>Public Administration</td><td>960</td><td>14970</td><td>26669</td></tr><tr><td>Public Health and Preventive Medicine</td><td>1949</td><td>39820</td><td>19649</td></tr><tr><td>Remote Sensing Science and Technology</td><td>344</td><td>8081</td><td>271</td></tr><tr><td>Safety Science and Engineering</td><td>835</td><td>14986</td><td>409</td></tr><tr><td>Sociology</td><td>2093</td><td>39941</td><td>32361</td></tr><tr><td>Statistics</td><td>3388</td><td>59950</td><td>24806</td></tr><tr><td>Stomatology</td><td>592</td><td>15002</td><td>456</td></tr><tr><td>Surveying and Mapping Science and Technology</td><td>509</td><td>14964</td><td>358</td></tr><tr><td>Textile Science and Engineering</td><td>187</td><td>14978</td><td>325</td></tr><tr><td>Transportation Engineering</td><td>882</td><td>14929</td><td>4956</td></tr><tr><td>Urban and Rural Planning</td><td>576</td><td>15052</td><td>89</td></tr><tr><td>Veterinary Medicine</td><td>547</td><td>14918</td><td>3022</td></tr><tr><td>World History</td><td>987</td><td>39703</td><td>5503</td></tr><tr><td>Total</td><td>125328</td><td>3040620</td><td>1658541</td></tr></table>\n\n# D BASELINE DATASETS\n\nTable 7: The baseline datasets utilized in our experiments. For the Nemotron-Post-Training-v1 dataset, only the data from the math and STEM categories was used.  \n\n<table><tr><td>Dataset</td><td>URL</td></tr><tr><td>OpenThoughts3(Guha et al., 2025)</td><td>https://huggingface.co/datasets/open-thoughts/OpenThoughts3-1.2M</td></tr><tr><td>Nemotron-Post-Training-v1(Bercovich et al., 2025)</td><td>https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1</td></tr><tr><td>WebInstruct (Full)(Yue et al., 2024)</td><td>https://huggingface.co/datasets/TIGER-Lab/WebInstructFull</td></tr><tr><td>NaturalReasoning(Yuan et al., 2025)</td><td>https://huggingface.co/datasets/facebook/natural Reasoning</td></tr></table>\n\n# E QUESTION TYPE ANALYSIS\n\nAs shown in Table 9, problem-solving questions form the majority of our synthesized datasets, constituting  $64.92\\%$  of the book corpus and  $63.91\\%$  of the web corpus. Multiple-choice questions are the next most common type, comprising  $29.94\\%$  and  $32.43\\%$ , respectively. This distribution analysis indicates that the composition of our synthesized questions is skewed towards reasoning-based types, as opposed to simple recall-oriented ones.\n\nTable 9: Distribution of question types in our synthesized datasets.  \n\n<table><tr><td>Type</td><td>DLR-Book</td><td>DLR-Web</td></tr><tr><td>Problem-solving question</td><td>64.92%</td><td>63.91%</td></tr><tr><td>Multiple-choice question</td><td>29.94%</td><td>32.43%</td></tr><tr><td>Proof question</td><td>4.39%</td><td>2.67%</td></tr><tr><td>Other question types</td><td>0.75%</td><td>0.99%</td></tr></table>\n\n# F DETAILED DIFFICULTY ANALYSIS\n\nTable 10: Difficulty distributions of questions across different datasets and benchmarks.  \n\n<table><tr><td>Dataset</td><td>Easy</td><td>Medium</td><td>Hard</td><td>Very Hard</td></tr><tr><td>GSM8K</td><td>78.09%</td><td>21.91%</td><td>0.0%</td><td>0.0%</td></tr><tr><td>MMLU</td><td>60.51%</td><td>34.09%</td><td>5.29%</td><td>0.11%</td></tr><tr><td>MMLU-Pro</td><td>34.48%</td><td>44.04%</td><td>20.86%</td><td>0.62%</td></tr><tr><td>GPQA-Diamond</td><td>0.51%</td><td>19.7%</td><td>71.72%</td><td>8.08%</td></tr><tr><td>GPQA-Main</td><td>0.22%</td><td>26.56%</td><td>67.41%</td><td>5.8%</td></tr><tr><td>SuperGPQA</td><td>35.97%</td><td>32.18%</td><td>29.88%</td><td>1.98%</td></tr><tr><td>OpenThoughts3</td><td>1.09%</td><td>19.32%</td><td>70.51%</td><td>9.07%</td></tr><tr><td>Nemotron-Post-Training-v1</td><td>32.27%</td><td>48.61%</td><td>16.09%</td><td>3.04%</td></tr><tr><td>WebInstruct (Full)</td><td>39.02%</td><td>39.58%</td><td>17.84%</td><td>3.57%</td></tr><tr><td>NaturalReasoning</td><td>2.10%</td><td>26.25%</td><td>40.54%</td><td>31.11%</td></tr><tr><td>DLR-Web</td><td>0.72%</td><td>16.13%</td><td>36.24%</td><td>46.91%</td></tr><tr><td>DLR-Book</td><td>0.27%</td><td>9.88%</td><td>35.18%</td><td>54.66%</td></tr></table>\n\n# G DETAILED DIVERSITY METRICS\n\nWe first generated high-dimensional vector representations for each question using the Qwen3-Embedding-4B model. For a given question set  $X = \\{x_{1}, x_{2}, \\ldots, x_{N}\\}$ , this process yields a corresponding set of embedding vectors  $E = \\{e_{1}, e_{2}, \\ldots, e_{N}\\}$ , where  $e_{i} \\in \\mathbb{R}^{d}$  is the  $d$ -dimensional embedding for question  $x_{i}$ . We uniformly sample  $N = 300,000$  questions from each dataset and compute the following five distance-based metrics in the embedding space.\n\n1. Mean Cosine Distance: The average cosine distance between all unique pairs of embeddings, calculated as  $M_{\\mathrm{cosine}} = \\frac{2}{N(N - 1)}\\sum_{i < j}(1 - \\cos (e_i,e_j))$ . A higher value indicates greater semantic dissimilarity.  \n2. Mean L2 Distance: The average Euclidean distance between all unique pairs of embeddings, calculated as  $M_{\\mathrm{L2}} = \\frac{2}{N(N - 1)}\\sum_{i < j}\\| e_i - e_j\\| _2$ . This measures the average separation of questions in the embedding space.  \n3. 1-Nearest Neighbor Distance (1-NN Distance): The average cosine distance from each embedding to its single nearest neighbor, given by  $M_{1\\mathrm{-NN}} = \\frac{1}{N}\\sum_{i}d_{1}(e_{i})$ , where  $d_{1}(e_{i})$  is the cosine distance from  $e_{i}$  to its closest neighbor. This metric highlights the presence of tightly clustered, near-identical questions.\n\n4. Cluster Inertia: The total squared distance of samples to their closest cluster center after applying the K-means clustering algorithm. It is calculated as  $M_{\\text{inertia}} = \\sum_{i=1}^{N} \\min_j \\| e_i - c_j \\|^2$ , where  $c_j$  are the cluster centroids. This measures the overall spread and density of the data clusters.  \n5. Radius: The geometric mean of the standard deviations of the embedding dimensions, modeling the data as a multi-dimensional Gaussian distribution:  $M_{\\mathrm{Radius}} = (\\prod_{j=1}^{d} \\sigma_j)^{1/d}$ , where  $\\sigma_j$  is the standard deviation along the  $j$ -th dimension. It directly quantifies the spread of the data in the semantic space.\n\n# H EXPERIMENTAL DETAILS\n\nTable 11: Hyperparameters for Supervised Fine-Tuning (SFT).  \n\n<table><tr><td>Parameter</td><td>Value</td></tr><tr><td>Epoch</td><td>6</td></tr><tr><td>Batch Size</td><td>64</td></tr><tr><td>Learning Rate</td><td>1e-5</td></tr><tr><td>Learning Rate Schedule</td><td>Cosine decay to 0</td></tr></table>\n\nTable 12: Generation configuration for evaluation.  \n\n<table><tr><td>Parameter</td><td>Value</td></tr><tr><td>Temperature</td><td>0.6</td></tr><tr><td>Top-K</td><td>20</td></tr><tr><td>Top-P</td><td>0.95</td></tr><tr><td>Max Context Length</td><td>32768</td></tr></table>\n\nTable 13: Evaluation benchmarks, their disciplines, and the number of rollouts  $(N)$ .  \n\n<table><tr><td>Benchmark</td><td>Disciplines</td><td>Rollout (N)</td></tr><tr><td>MMLU (Hendrycks et al., 2020)</td><td>57 disciplines including STEM, human-ities, social sciences, and professional fields</td><td>1</td></tr><tr><td>MMLU-Pro (Wang et al., 2024b)</td><td>Math, Physics, Chemistry, Law, Engineering, Economics, Health, Psychology, Business, Biology, Philosophy, Computer Science, History, Other</td><td>1</td></tr><tr><td>GPQA-Diamond (Rein et al., 2024)</td><td>Physics, Chemistry, Biology</td><td>10</td></tr><tr><td>GPQA-Main (Rein et al., 2024)</td><td>Physics, Chemistry, Biology</td><td>10</td></tr><tr><td>SuperGPQA (Du et al., 2025)</td><td>285 graduate-level disciplines across 13 fields (e.g., Engineering, Management, Economics, Education, History, Science, Medicine, Law, Sociology, Philosophy, Agriculture, Literature)</td><td>1</td></tr></table>\n\n# I PERFORMANCE ON GSM8K AND MATH-500\n\nWe evaluated the models trained on our data in Table 3 on GSM8K and MATH-500.\n\nTable 15: The SFT experiment results on GSM8K and MATH-500. The models are trained on DLR-Web, DLR-Book, or the combined DLR-Web + DLR-Book dataset.  \n\n<table><tr><td>Model</td><td>GSM8K</td><td>MATH-500</td></tr><tr><td>Llama-3.2-3B-Instruct</td><td>68.46</td><td>35.75±5.60</td></tr><tr><td>Llama-3.2-3B-SFT (DLR-Web)</td><td>79.98</td><td>44.35±2.24</td></tr><tr><td>Llama-3.2-3B-SFT (DLR-Book)</td><td>81.05</td><td>51.45±1.42</td></tr><tr><td>Llama-3.2-3B-SFT (DLR-Web+Book)</td><td>86.66</td><td>61.90±1.75</td></tr><tr><td>Llama-3.1-8B-Instruct</td><td>81.12</td><td>46.25±3.08</td></tr><tr><td>Llama-3.1-8B-SFT (DLR-Web)</td><td>93.03</td><td>80.20±0.71</td></tr><tr><td>Llama-3.1-8B-SFT (DLR-Book)</td><td>92.65</td><td>82.15±1.28</td></tr><tr><td>Llama-3.1-8B-SFT (DLR-Web+Book)</td><td>93.18</td><td>86.45±0.68</td></tr><tr><td>Qwen3-4B (Thinking Mode)</td><td>94.77</td><td>92.75±0.50</td></tr><tr><td>Qwen3-4B-Base-SFT (DLR-Web)</td><td>94.31</td><td>87.95±0.50</td></tr><tr><td>Qwen3-4B-Base-SFT (DLR-Book)</td><td>94.47</td><td>89.45±1.30</td></tr><tr><td>Qwen3-4B-Base-SFT (DLR-Web+Book)</td><td>94.69</td><td>89.35±0.38</td></tr><tr><td>Qwen3-8B (Thinking Mode)</td><td>95.60</td><td>93.35±0.09</td></tr><tr><td>Qwen3-8B-Base-SFT (DLR-Web)</td><td>95.07</td><td>91.05±0.54</td></tr><tr><td>Qwen3-8B-Base-SFT (DLR-Book)</td><td>95.60</td><td>91.75±0.46</td></tr><tr><td>Qwen3-8B-Base-SFT (DLR-Web+Book)</td><td>95.60</td><td>91.85±0.33</td></tr></table>\n\nGSM8k and MATH-500 are exclusively focused on mathematical problems. Our dataset's objective is not mathematics; rather, it is designed to create a multidisciplinary dataset. Nevertheless, the model trained on our data still exhibits competitive performance in the mathematical domain.\n\nFor MATH500, the slightly lower performance of our models compared with the official Qwen3 models that have undergone the full post-training process is likely due to the fact that the official Qwen3 models were trained with a substantially larger volume of high-quality, expert-written mathematical data and received more extensive post-training. In contrast, mathematics represents only about  $10\\%$  of our dataset, and our math questions are synthesized from raw web and book corpora rather than curated by human experts, which naturally leads to lower quality relative to professional math-focused training data.\n\nNotably, models trained on either DLR-Book or DLR-Web+Book achieve  $95.60\\%$  on GSM8K, matching the official Qwen3-8B score. GSM8K performance is already near saturation. Prior work (Vendrow et al., 2025) reports that approximately  $5\\%$  of GSM8K questions are mislabeled or ambiguous, which makes  $100\\%$  accuracy unattainable and positions  $95.60\\%$  near the practical upper bound. Even stronger LLMs fall within a similar range. For instance, according to the Llama 3 technical report (Dubey et al., 2024), GPT-4o reaches 96.1 on GSM8K under 8-shot CoT setting.\n\n# J PROMPTS\n\n# Prompt for Discipline Classification\n\nYou are a professional multidisciplinary data labeling expert specializing in the classification of multidisciplinary academic questions. Please select the ONE most relevant label from the given list of discipline labels for the input question data. For question data that you cannot determine, use the \"Unknown Discipline\" label. Please directly output \"labels\": \" (the label you selected)\".\n\nList of Discipline Labels:\n\n[Mathematics', 'Biology', 'Chemistry', 'Physics', 'Computer Science and Technology', 'Philosophy', 'Psychology', 'Business Administration', 'Clinical Medicine', 'Economics', 'Law', 'Political Science', 'Statistics', 'Electrical Engineering', 'Geography', 'Mechanical Engineering', 'Basic Medicine', 'Information and Communication Engineering', 'Sociology', 'Materials Science and Engineering', 'Pharmacy', 'Public Health and Preventive Medicine', 'Mechanics', 'Astronomy', 'World History', 'Bioengineering', 'English and Foreign Languages', 'Chemical Engineering and Technology', 'Electronic Science and Technology', 'Environmental Science and Engineering', 'Nuclear Science and Technology', 'Control Science and Engineering', 'Management Science and Engineering', 'Education', 'Geophysics', 'Art and Design', 'Agricultural Engineering', 'Aerospace Science and Technology', 'Atmospheric Sciences', 'Chinese Language and Literature', 'Civil Engineering', 'Ecology', 'Geology', 'Nursing', 'Optical Engineering', 'Public Administration', 'Journalism and Communication', 'Physical Education', 'Marine Sciences', 'Safety Science and Engineering', 'Architecture', 'Transportation Engineering', 'Power Engineering and Engineering Thermophysics', 'Food Science and Engineering', 'Archaeology', 'Biomedical Engineering', 'Chinese History', 'Veterinary Medicine', 'Instrument Science and Technology', 'Hydraulic Engineering', 'Stomatology', 'Urban and Rural Planning', 'Petroleum and Natural Gas Engineering', 'Naval Architecture and Ocean Engineering', 'Surveying and Mapping Science and Technology', 'History of Science and Technology', 'Agricultural Resources and Environment', 'Remote Sensing Science and Technology', 'Information Resources Management', 'Mining Engineering', 'Forensic Medicine', 'Ethnology', 'Textile Science and Engineering', 'Geological Resources and Geological Engineering', 'Animal Husbandry', 'Other', 'Non-disciplinary', 'Unknown Discipline']\n\nExample 1\n\nInput: \"Consider a photon traveling at the speed of light. How does the photon experience space, and what are the implications of relativistic beaming on its perception of spatial dimensions? Provide a detailed explanation, including any relevant mathematical derivations and physical principles.\" Output: \"labels\": \"Physics\"\n\nExample 2\n\nInput: \"A heavy pole, of mass M and length L, is freely hinged to a wall at the point O. A rope connects the other end of the pole, B, to a fixed point A on the wall above O. The system is in equilibrium, with the pole making an angle of  $\\theta$  with the horizontal, and the rope making an angle of  $\\alpha$  with the horizontal. Explore how the system's parameters (M, L,  $\\theta$ ,  $\\alpha$ ) affect its equilibrium and stability.\" Output: \"labels\": \"Mechanics\"\n\nExample 3\n\nInput: \"If John rented a car for \\(150 and had to buy 8 gallons of gas at \\)3.50 per gallon to fill it up, and the final expense is \\(0.50 per mile, how much did it cost him to drive 320 miles?\" Output: \"labels\": \"Mathematics\"\n\n# Input Question Data\n\nInput:“{text}”\n\nOutput:\n\nFigure 7: The few-shot prompt used for discipline classification. The model is presented with a list of disciplines and three examples, and is then asked to classify a given question, which replaces the  $\\{\\text{text}\\}$  placeholder.\n\n# Prompt for Difficulty Classification\n\nYou are an expert in education and examination, specializing in classifying the difficulty levels of multidisciplinary questions. For the given question, please evaluate its difficulty based on the complexity and length of the reasoning required to answer it. Label it as one of the following: **Easy**, **Medium**, **Hard**, or **Very Hard**. Please directly output \"Difficulty: (Your chosen label)\".\n\n# Example 1\n\nInput: \"Consider a photon traveling at the speed of light. How does the photon experience space, and what are the implications of relativistic beaming on its perception of spatial dimensions? Provide a detailed explanation, including any relevant mathematical derivations and physical principles.\"  \nOutput: \"Difficulty: Very Hard\"\n\n# Example 2\n\nInput: \"A heavy pole, of mass M and length L, is freely hinged to a wall at the point O. A rope connects the other end of the pole, B, to a fixed point A on the wall above O. The system is in equilibrium, with the pole making an angle of  $\\theta$  with the horizontal, and the rope making an angle of  $\\alpha$  with the horizontal. Explore how the system's parameters (M, L,  $\\theta$ ,  $\\alpha$ ) affect its equilibrium and stability.\" Output: \"Difficulty: Hard\"\n\n# Example 3\n\nInput: \"If John rented a car for \\(150 and had to buy 8 gallons of gas at \\)3.50 per gallon to fill it up, and the final expense is \\(0.50 per mile, how much did it cost him to drive 320 miles?\" Output: \"Difficulty: Easy\"\n\nGiven Question\n\nInput:“{text}”\n\nOutput:\n\nFigure 8: The few-shot prompt used for difficulty classification. The model is presented with three examples and is then asked to classify the difficulty of a given question, which replaces the {text} placeholder.\n\n# Prompt for Question Type Classification\n\nYou are an expert in education and examination, specializing in classifying question types. For the given question, please evaluate its question type and label it as one of the following: **Problem-solving question**, **Multiple-choice question**, **Proof question**, or **Other question types**. For any question that you cannot determine, use the \"Other question types\" label. Please directly output \"Question type: (Your chosen label)\".\n\nExample 1\n\nInput: \"Determine the number of  $k$ -letter sequences composed of the letters  $A$  and  $B$  such that the sequence contains at least two consecutive  $A$ 's.\"\n\nOutput: \"Question type: Problem-solving question\"\n\nExample 2\n\nInput: \"Consider the function  $f(x) = \\frac{e^x}{x}$ . The value of the integral  $I = \\int_{1}^{\\infty}\\left(\\frac{e^x}{x} -\\frac{e^{-x}}{x}\\right)dx$  is ____.\"\n\nOutput: \"Question type: Other question types\"\n\nExample 3\n\nInput: \"Given that  $a \\in \\{-1, 2, \\frac{1}{2}, 3, \\frac{1}{3}\\}$ , if  $f(x) = x^a$  is an odd function and is monotonically increasing on  $(0, +\\infty)$ , then the possible values of the real number  $a$  are ( ).\n\nA: -1,3  \nB:  $\\frac{1}{3}, 3$  \nC: -1,  $\\frac{1}{3}, 3$  \nD:1 3,2\"\n\nOutput: \"Question type: Multiple-choice question\"\n\nGiven Question\n\nInput:“{text}”\n\nOutput:\n\nFigure 9: The few-shot prompt used for question type classification. The model is presented with three examples and is then asked to classify the type of a given question, which replaces the {text} placeholder.\n\n# Prompt for Reasoning-Oriented Filtering\n\nYou will be provided with text from the internet.\n\nEvaluate the following text extract for its potential usefulness for studying reasoning process. Use the following 5-point scoring system described below. Start from 0, points are accumulated based on the satisfaction of each criterion:\n\n(1) Add 1 point if the extract contains any reasoning or thinking process.  \n(2) Add 1 point if the extract contains any explicit subgoal setting, where the writer breaks down the problem into smaller, intermediate goals. Subgoal setting might look like:\n\n- \"First, we need to find ..., then we can determine ...\"\n\n- \"To solve ..., let's first ..., then ...\"  \n- “Let’s tackle ... in three parts: (1) ..., (2) ..., and (3) ...\"  \n- \"To ..., I'll first ..., then ...\"\n\n(3) Add 1 point if the extract contains any verification steps. We want to mark instances where the writer explicitly checks their own work, such as by comparing the result to a known value or by checking the result of a calculation. Verification steps might look like:\n\n\"Let's check ...\"  \n-To verify this is correct, I'll ...  \n- \"Let's test ... with a simple case: ...\"  \nTo ensure this solution is valid, I'll check if ...\n\n(4) Add 1 point if the text contains any backtracking behavior, where the writer realizes a path won't work and explicitly goes back to try a different approach. An example of backtracking is: \"Let me try again\", \"Wait\", \"I made a mistake\", or \"we need to try a different sequence of operations\". We want to mark instances where the writer abandons a thought and backtracks to a previous computation.  \n(5) Add 1 point if the text contains any backward-chaining behavior, where the writer is working towards a goal but starts from the goal and works backward. It might like:\n\n- \"To solve ..., let's start with what we want to prove: ...Let's verify this.\"  \n- \"If we want to find ..., let's start with the desired result and work backward.\"  \n- \"To determine ..., I know the result ... Working backward from this final state using\n\nTask Format\n\nFormat your response in markdown as follows:\n\nThoughts\n\n[Brief description describing what behavior was noticed and where subgoal setting may have occurred, less than 100 words]\n\nFinal score\n\n[total points]\n\nText to evaluate for reasoning degree {text}\n\nResponse\n\nFigure 10: The prompt used for the reasoning-oriented filtering task. It defines a five-level scoring rubric to assess the usefulness of a text (which replaces the  $\\{\\text{text}\\}$  placeholder) for studying reasoning.\n\n# Prompt for Design Logic Extraction\n\nYou are an expert educator and a specialist in exam question design. Below, I have provided an exam question. Your task is to deduce the thought process of the question designer. Analyze how they constructed this question based on the relevant knowledge points. You need to go beyond the specific details of the question and its knowledge points to abstract and summarize the underlying design logic and principles behind the question.\n\nThe goal is for me to be able to use this abstracted design logic to create other high-quality, challenging questions that require complex logical reasoning for different knowledge points and source materials.\n\n**Finally, you must organize the abstracted question-design logic you have summarized into English Mermaid format.**\n\n--- Analyze the Question Design Logic from the Following Question ---\n\n\\*\\*Question:\\*\\{text\\}\n\nFigure 11: The prompt used for design logic extraction. The model is instructed to reverse-engineer the thought process behind a given question (which replaces the {text} placeholder) and to structure the abstracted logic in Mermaid format.\n\n# Instruction for Design Logic Retrieval\n\nGiven a book snippet, retrieve the most suitable question-design logic in Mermaid format for creating a challenging exam question from the book snippet.\n\nFigure 12: The task-specific instruction used for retrieving the most suitable design logic for a given text segment. Embeddings for both text segments and design logics are computed under this instruction using the Qwen3-Embedding-4B model, enabling similarity-based retrieval.\n\n# Prompt for Question Synthesis\n\nYou are an expert in the field of education and examination design, and you are writing exam questions. Your task is to use the provided text to generate a high-quality exam question. Please follow the steps below to generate an English exam question and a reference answer:\n\n**1. Create an Exam Question:**\n\n- Based on the provided source text, write a challenging exam question at the graduate-level or above.\n- Below are five question-design logics provided in Mermaid format. You need to select the most suitable question-design logic for creating a challenging question from the source text, and then strictly follow the corresponding question-design logic and steps to create a challenging question. Please record which design logic you used (by number) and output the corresponding numeric ID in the \"id\" field of the JSON below.\n\n- The question should require critical thinking and test deep understanding and problem-solving skills, not just simple fact recall.\n\n- The question must be self-contained and answerable without using the source text. If the question you write requires an answer based on the content of the source text, you must include the corresponding content and information from the source text within the question itself to make it self-contained.\n\n- Ensure the question is self-contained, clear, without missing information or ambiguity, and has a correct answer.\n\n- For multiple-choice questions, you should first analyze and determine the answer, then design the options to ensure that one specific option is the correct answer. The questions you design need to include as many options as possible (four or more). Do not be limited to only four options (A, B, C, D).\n\n**2. Provide the Reference Answer:**\n\n- Use the information in the source text to write a concise and accurate reference answer to the question you just created.\n\n- If there is a final, single result or conclusion (like a number, formula, or short phrase), state it clearly at the end with: \"The final answer is: \\boxed{answer}.\" Otherwise, do not output \\boxed{answer}.\n\n**At the end of your response, please organize your results into the following JSON format:** {\n\n\"exam_question\": \"* (Your question goes here)*\",  \n\"reference_answer\": \"* (Your reference answer goes here)*\",  \n{id\": \"* (The ID of the logic you selected goes here)*\"}\n\n\\*\\*-Question-Design Logic 1  $\\rightarrow \\star \\star$  Mermaid {logic1}\n\n\\*\\*-Question-Design Logic 2  $\\text{一} ^ { \\text{一} }$  Mermaid   \n{logic2}\n\n\\*\\*-Question-Design Logic 3  $\\rightarrow \\star$  Mermaid   \n{logic3}\n\n\\*\\*-Question-Design Logic 4  $\\rightarrow \\star \\star$  Mermaid   \n{logic4}\n\n\\*\\*-Question-Design Logic 5 \\*Mermaid   \n{logic5}\n\n\\*\\* Source Text for Question Creation \\*-\\*\\{text\\}\n\nFigure 13: The prompt used for question synthesis. The LLM is provided with a source text and five candidate design logics retrieved via semantic similarity. It is instructed to select the most suitable logic and strictly follow it to generate a graduate-level question and a corresponding reference answer, structured in a JSON format. The placeholders {logic1} through {logic5} and {text} are replaced with specific design logics and the source text, respectively.\n\n# Prompt for Question Answerability Evaluation\n\nYour task is to review a question and decide whether it provides sufficient conditions to derive solutions. If the question is a complete and answerable one, output 'Yes'. Open-ended questions are considered answerable. If it is an incorrect question that cannot be answered, output 'No'. Output only 'Yes' or 'No'.\n\n“question”: “{question}”\n\nOutput:\n\nFigure 14: The prompt used to evaluate whether the synthesized questions are complete and answerable. The placeholder {question} is replaced with the specific synthesized question.\n\n# Prompt for Design Logic Consistency Evaluation\n\nYour task is to judge whether a \"question\" is designed according to the Mermaid-format \"design logic\". You should ignore superficial wording changes. If the logic is consistent or if there are implicit references that preserve consistency, output 'Yes'. If the design logic underlying the question is not consistent with the \"design logic\", output 'No'. Output only 'Yes' or 'No'.\n\n“design logic”: “{design_logic}”\n\n“question”: “{question}”\n\nOutput:\n\nFigure 15: The prompt used to evaluate the consistency between the synthesized question and its corresponding design logic. The placeholders {design_logic} and {question} are replaced with the specific design logic and the corresponding synthesized question, respectively.\n\n# Prompt for Answer Consistency Evaluation\n\nYou are an expert reviewer who compares a \"reference_answer\" with a model \"response\" for the same question. Decide whether both provide the same final answer. Ignore differences in reasoning or wording, and output 'Yes' when the final answers or key conclusions are identical. Output 'No' when the conclusions differ. Output only 'Yes' or 'No'.\n\n“question”: “{question}”\n\n“reference_answer”: “{reference_answer}”\n\n“response”: “{response}”\n\nOutput:\n\nFigure 16: The prompt used to evaluate the consistency between the reference answers generated by DeepSeek-R1-0528 and the CoT responses generated by Qwen3-235B-A22B-Thinking-2507-FP8. The placeholders {question}, {reference_answer}, and {response} are replaced with the synthesized question, the reference answer, and the CoT responses, respectively.\n\n# Prompt for Discipline Label Evaluation\n\nYou are reviewing exam questions and their author-provided discipline labels. Judge whether the discipline label is appropriate for the question. Answer 'Yes' when the label is plausible and answer 'No' when there is a clear mismatch. Output only 'Yes' or 'No'.\n\n\"question\": {\"question\"}  \n\"discipline label\": {\"discipline\"}\n\nOutput:\n\nFigure 17: The prompt used to evaluate the appropriateness of the discipline label. The placeholders {question} and {discipline} are replaced with the specific question and its discipline label.\n\n# Prompt for Difficulty Label Evaluation\n\nYou are reviewing exam questions and their author-provided difficulty labels. Judge whether the difficulty label is appropriate for solving the question. Answer 'Yes' when the label is plausible and 'No' when there is a clear mismatch. Output only 'Yes' or 'No'.\n\n\"question\": {\"question\"}  \n\"difficulty label\": {\"difficulty\"}\n\nOutput:\n\nFigure 18: The prompt used to evaluate the appropriateness of the difficulty label. The placeholders {question} and {difficulty} are replaced with the specific question and its difficulty label.\n\n# Prompt for Type Label Evaluation\n\nYou are reviewing exam questions and their author-provided type labels. Judge whether the type label is appropriate for the question. Answer 'Yes' when the label is plausible and answer 'No' when there is a clear mismatch. Output only 'Yes' or 'No'.\n\n“question”：“{question}” “type label”：“{qtype}”\n\nOutput:\n\nFigure 19: The prompt used to evaluate the appropriateness of the question type label. The placeholders {question} and {qtype} are replaced with the specific question and its type label.\n\n# K DESIGN LOGIC EXAMPLES\n\nIn this section, we provide design logic examples for several representative disciplines, such as Computer Science and Technology, Clinical Medicine, Mathematics, Law, Psychology, and Archaeology. Each example includes the source code in Mermaid format and the corresponding visual flowchart.\n\n```txt\ngraph TD   \nA[\"Problem Domain\"]-->B[\"Sorted Arrays & Median\"]   \nB-->C[\"Key Insight: Partitioning Without Merging\"]   \nC-->D[\"Algorithm Selection: Binary Search\"]   \nD-->E[\"Optimization:0(log(min(m，n)))\"]   \nE-->F[\"Edge Cases\"]   \nF-->F1[\"Empty Arrays\"]   \nF-->F2[\"Full-Array Partition\"]   \nF-->F3[\"Even/Odd Length Handling\"]   \nA-->G[\"Constraints Design\"]   \nG-->G1[\"Large Input Sizes:  $10^{\\wedge}6^{\\prime \\prime}$ ]   \nG-->G2[\"Time Complexity:0(min(log m，log n))\"]   \nG-->G3[\"Auxiliary Space:0((m+n)/2) hint for naive approach\"]   \nA-->H[\"Test Cases\"]   \nH-->H1[\"Example 1: Odd Length\"]   \nH-->H2[\"Example 2: Even Length\"]   \nH-->H3[\"Edge:One Array Empty\"]   \nH-->H4[\"Edge:Both Empty\"]   \nH-->H5[\"One Array All Smaller\"]\n```\n\n(a) The design logic formatted as Mermaid source code.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/2d5f0e3fc5dd8138f280d37d642d2588d61ff863a38b5ffa2ed5436462452340.jpg)\n\n(b) The flowchart generated from the Mermaid code.\n\nFigure 20: An example of the design logic for a Computer Science and Technology problem, showing the Mermaid source code (a) and the corresponding visual flowchart (b).\n\n(a) The design logic formatted as Mermaid source code.  \n```txt\ngraph TD   \nA[Select Core Concept] --> B[Identify Pathognomonic Features];   \nB --> C[Layer Multidisciplinary Clues];   \nC --> D[Clinical History<br><i>e.g., chronicity, symptoms</i>];   \nC --> E[Imaging/Lab Findings<br><i>e.g., specific radiology signs</ i)];   \nC --> F[Pathology/Cytology<br><i>e.g., cell type, differentiation</ i)];   \nD --> G[Require Synthesis of All Clues];   \nE --> G;   \nF --> G;   \nG --> H[Demand Etiologic Deduction<br><i>e.g., primary site, mechanism</i)];   \nH --> I[Incorporate Strategic Distractors<br><i>e.g., common misdiagnoses</i)];   \nI --> J[Ensure Clues Refute Distractors<br><i>e.g., atypia level rules out alternatives</i)];   \nJ --> K[Align Timeline with Disease Biology<br><i>e.g., indolent vs .acute</i)];\n```\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/9a23325bcc3209e951ec03bff3083695e4b1e4e171dd6c504f3c6a17b0d7608d.jpg)  \n(b) The flowchart generated from the Mermaid code.  \nFigure 21: An example of the design logic for a Clinical Medicine problem, showing the Mermaid source code (a) and the corresponding visual flowchart (b).\n\n```yaml\ngraph TD   \n2 A[Define Problem Type] --> B[Select Core Concept: <br>e.g., Exponential Diophantine, Polynomial, Inequality]   \n3 B --> C[Choose Parameters with Constraints]   \n4 C --> C1[Base/Numbers: <br> - Coprime or low common factors<br> - Strategic modular properties<br> - Growth disparities]   \n5 C --> C2[Variables: <br> - Multiple exponents/terms<br> - Interdependent constraints]   \n6 C --> C3[Ensure solution space control: <br> - Small solution exists<br> - Bounded by properties/growth]   \n7 A --> D[Incorporate Reasoning Layers]   \n8 D --> D1[Step 1: Derive necessary conditions<br> e.g., modular arithmetic, symmetry, calculus]   \n9 D --> D2[Step 2: Impose non-trivial constraints<br> e.g., parity, divisibility, inequalities]   \n10 D --> D3[Step 3: Force case analysis<br> e.g., small-value testing, critical point checks]   \n11 A --> E[Finalize for Challenge]   \n12 E --> E1[Verify: Solution requires all steps<br> - No brute-force accessibility<br> - Key insight is necessary]   \n13 E --> E2[Refine: Remove redundancies<br> - Ensure clarity and conciseness]   \n14 E --> E3[Generalize: Test with variants<br> e.g., change bases/ operators]\n```\n\n(a) The design logic formatted as Mermaid source code.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/c1abc2265310cc37868759730240f8e759fe627b94974c8d123839a150c83702.jpg)  \nFigure 22: An example of the design logic for a Mathematics problem, showing the Mermaid source code (a) and the corresponding visual flowchart (b).\n\n(b) The flowchart generated from the Mermaid code.\n\n(a) The design logic formatted as Mermaid source code.  \n```txt\ngraph TD A[Start: Define Core Task] --> B[Select Key Items for Comparison]; B --> C[Set Task: Rank or Compare Items]; C --> D[Require Detailed Explanation of Each Item]; D --> E[Include Opposing Views/Controversies]; C --> F[Discuss Broader Impacts e.g., Historical, Cultural, Political]; F --> G[Specify Factors to Consider e.g., Rights, Institutions, Ethics]; C --> H[Link to Modern Implications/Controversies]; C --> I[Demand Use of Examples and Evidence]; I --> J[Support Arguments with Facts and Data]; J --> K[Ensure Complex Logical Reasoning]; K --> L[End: Assess Higher-Order Thinking];\n```\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/09aba7989789c00754e59553b44d6b2aea30327988828726aa195d1250ea9d12.jpg)  \n(b) The flowchart generated from the Mermaid code.  \nFigure 23: An example of the design logic for a Law problem, showing the Mermaid source code (a) and the corresponding visual flowchart (b).\n\n```txt\ngraph TD A[Primary Goal] --> B[Explore Complex Human Behavior] B --> C[Ethical Decision-Making Under Constraints] A --> D[Ensure Pedagogical Safety]   \n6 C --> E[Design Imperatives] E --> E1[Require Controversial Perspective Coverage] E --> E2[Explicitly Forbid Harm Advocacy] E --> E3[Embed Iterative Refinement Mechanism]   \n10 D --> F[Psychological Safeguards] F --> F1[Clinical Role Assignment<br>e.g., Psychologist/Researcher] F --> F2[Tone Mandate<br>e.g., Caring/Supportive Language] F --> F3[Scenario Distancing<br>e.g., Hypothetical Survival Context ]   \n15 G[Structural Elements] --> G1[High-Stakes Scenario] G1 --> G1a[Reveal True Behavioral Drivers] G --> G2[Concrete Decision Task<br>e.g., Resource Prioritization] G2 --> G2a[Create Measurable Choice Points]   \n20 H[Quality Control] --> H1[Anti-Repetition Protocol] H --> H2[Nuance Requirement<br>e.g., Multiple Revision Layers]   \n24 A --> G   \n25 A --> H\n```\n\n(a) The design logic formatted as Mermaid source code.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/7713fc16d7d5c18ceca886c593c7f7702172c645003b187b7ac6197237a1b9e3.jpg)  \nFigure 24: An example of the design logic for a Psychology problem, showing the Mermaid source code (a) and the corresponding visual flowchart (b).\n\n(b) The flowchart generated from the Mermaid code.\n\n```txt\nflowchart TD   \nA[Core Objective] --> B[\"Require Synthesis of Multiple Skills\"]   \nA --> C[\"Demand Critical Interpretation\"]   \nA --> D[\"Connect Abstract Concepts to Concrete Evidence\"]   \nB --> B1[\"Textual/Visual Analysis\"]   \nB --> B2[\"Contextual Analysis\"]   \nB --> B3[\"Interdisciplinary Integration\\n(e.g., anthropology, semiotics, history)\"]   \nC --> C1[\"Evaluate Symbolic Nuances\"]   \nC --> C2[\"Assess Cultural Significance\"]   \nC --> C3[\"Challenge Surface-Level Readings\"]   \nD --> D1[\"Link Physical Artifacts to Belief Systems\"]   \nD --> D2[\"Trace Practices to Worldviews\"]   \nD --> D3[\"Reconstruct Civilizational Logic\"]\n```\n\n(a) The design logic formatted as Mermaid source code.\n\n![](/uploads/images/46b648f5-a053-40b3-a651-3b42950130de/5a603d817fb12ea13427892994bc0938bc6ff5de0d857068ec6f8f5648211e00.jpg)  \nFigure 25: An example of the design logic for an Archaeology problem, showing the Mermaid source code (a) and the corresponding visual flowchart (b).\n\n(b) The flowchart generated from the Mermaid code.",
    "arxiv_id": "2508.12726",
    "error_message": null,
    "embedding": [
      -0.82421875,
      1.6875,
      -1.3515625,
      -4.3125,
      -1.1796875,
      0.6015625,
      -0.96484375,
      -1.515625,
      1.5859375,
      2.375,
      1.734375,
      1.578125,
      1.53125,
      0.98046875,
      0.1708984375,
      0.578125,
      0.47265625,
      2.5625,
      2.03125,
      -5.5,
      -4.0625,
      3.328125,
      0.095703125,
      -7.75,
      3.171875,
      -0.76953125,
      2.078125,
      1.4609375,
      1.828125,
      -2.6875,
      6.0625,
      -5.15625,
      -1.4375,
      1.9765625,
      -3.1875,
      0.380859375,
      -2.453125,
      -2.640625,
      4.03125,
      3.78125,
      -4.8125,
      0.54296875,
      0.024169921875,
      2.859375,
      -5.1875,
      2.859375,
      3.5625,
      0.5078125,
      -3.546875,
      -1.4765625,
      -6.4375,
      -5.25,
      8.9375,
      -0.6953125,
      5.0625,
      -0.2392578125,
      -5.65625,
      3.25,
      -3.828125,
      0.796875,
      1.984375,
      -0.96875,
      1.1953125,
      -3.234375,
      3.109375,
      4.28125,
      2.40625,
      2.375,
      -2.515625,
      1.5234375,
      -0.078125,
      -0.7734375,
      5.6875,
      -4.09375,
      4.28125,
      6.25,
      2.578125,
      0.75390625,
      -3.234375,
      5.40625,
      -2.828125,
      3.421875,
      4.5625,
      -0.4140625,
      3.296875,
      4.65625,
      -3.984375,
      -2.546875,
      -3.171875,
      3.546875,
      -0.91796875,
      -0.267578125,
      -5.90625,
      -3.203125,
      -2.078125,
      4.3125,
      -3.6875,
      -2.3125,
      -8.5625,
      2.171875,
      -3.03125,
      -1.4375,
      1.796875,
      -6.59375,
      -2.4375,
      -3.15625,
      -3.90625,
      -7.5,
      -1.7890625,
      -5.09375,
      -1.7265625,
      0.53125,
      2.4375,
      -1.3203125,
      2.171875,
      -0.76171875,
      4.8125,
      -2.796875,
      -3.5,
      -3.359375,
      1.859375,
      0.05029296875,
      -0.83203125,
      0.5,
      3.171875,
      1.6328125,
      -4.0625,
      -1.2578125,
      5.78125,
      1.265625,
      2.53125,
      -0.9140625,
      3.921875,
      -1.2421875,
      -9.5,
      -5.3125,
      -5.46875,
      3.96875,
      6.6875,
      6.5625,
      -5.28125,
      -2.109375,
      -2.09375,
      -5.75,
      2.75,
      -0.83984375,
      -6.375,
      -2.296875,
      3.90625,
      -6,
      -2.75,
      -0.73828125,
      2.40625,
      4.8125,
      -0.373046875,
      -2.34375,
      -0.21484375,
      2.484375,
      -0.625,
      -0.80859375,
      -0.310546875,
      1.3046875,
      1.390625,
      -0.68359375,
      -2.78125,
      -2.609375,
      -4.125,
      -0.2734375,
      -2.390625,
      -0.078125,
      2.59375,
      16.125,
      2.828125,
      1.578125,
      -0.50390625,
      0.9921875,
      -1.7421875,
      6.8125,
      2.515625,
      0.298828125,
      3.78125,
      0.30078125,
      -1.7265625,
      5.125,
      -3.40625,
      0.37890625,
      4.75,
      -3.28125,
      1.34375,
      -1.4140625,
      0.8359375,
      1.6328125,
      0.8046875,
      -0.1083984375,
      -6.3125,
      0.6484375,
      -0.9921875,
      0.26171875,
      -0.99609375,
      4.75,
      -0.318359375,
      -5.4375,
      -1.484375,
      -2.34375,
      -2.265625,
      0.5390625,
      2.328125,
      -3.875,
      1.8125,
      -0.0038604736328125,
      0.4453125,
      0.022216796875,
      3.109375,
      -0.51953125,
      6.75,
      2.6875,
      5,
      -4.78125,
      3.453125,
      -0.189453125,
      2.015625,
      4.21875,
      1.15625,
      2.59375,
      1.0078125,
      3.171875,
      3.0625,
      5.21875,
      2.28125,
      7.6875,
      0.2734375,
      1.1328125,
      5.78125,
      -3.671875,
      -2.203125,
      -3,
      -0.8515625,
      1.5390625,
      0.28125,
      -0.482421875,
      -1.578125,
      -2.6875,
      -1.6875,
      2,
      2.109375,
      -2.75,
      -0.703125,
      -0.0194091796875,
      -4.03125,
      -7.53125,
      -1.1015625,
      6.125,
      -7.4375,
      -2.953125,
      3.109375,
      6.625,
      -2.515625,
      -0.1435546875,
      -0.1767578125,
      -3.375,
      2.59375,
      -4.28125,
      -8.125,
      3.578125,
      1.9296875,
      -3.46875,
      3.6875,
      -1.0859375,
      2.828125,
      -1,
      2.484375,
      -1.9375,
      -2.125,
      0.07373046875,
      -5.15625,
      5.84375,
      0.59375,
      -6.375,
      0.93359375,
      -3.25,
      -5.53125,
      -7.9375,
      6.65625,
      -2.28125,
      1.0390625,
      -1.4765625,
      1.09375,
      6.75,
      2.515625,
      9.0625,
      6.25,
      3.140625,
      2.078125,
      0.69140625,
      -5.125,
      3.0625,
      -1.3125,
      0.53515625,
      -5.65625,
      0.53515625,
      3.203125,
      4.71875,
      -3.328125,
      -0.875,
      -2.625,
      7.875,
      1.5546875,
      -3.6875,
      2.953125,
      3.734375,
      -2.046875,
      -1.328125,
      6.09375,
      -3.140625,
      1.8125,
      -4.40625,
      -3.046875,
      3.6875,
      0.8203125,
      -3.078125,
      -4.34375,
      -3.96875,
      -3.6875,
      -0.875,
      -1.734375,
      -2.703125,
      0.369140625,
      4.46875,
      2.359375,
      0.20703125,
      1.6953125,
      3.203125,
      -7.15625,
      -5,
      5.09375,
      -1.609375,
      2.796875,
      0.96484375,
      -0.4765625,
      2.296875,
      0.1171875,
      -3.546875,
      5.21875,
      -2.171875,
      -1.3125,
      -0.0084228515625,
      4.65625,
      -1.546875,
      0.58984375,
      -5.8125,
      4.34375,
      4.0625,
      0.8984375,
      4.9375,
      6.3125,
      -2.640625,
      3.40625,
      2.84375,
      2.734375,
      -1.3125,
      3.203125,
      0.447265625,
      5.96875,
      2.078125,
      -2.046875,
      -3.65625,
      -1.9453125,
      2.359375,
      -1.859375,
      -4.90625,
      2.46875,
      -2.59375,
      4.90625,
      0.62890625,
      -0.5,
      -0.828125,
      0.98828125,
      -2.46875,
      -5.09375,
      -0.369140625,
      -3.046875,
      -2.109375,
      1.0234375,
      -0.98828125,
      1.6875,
      0.77734375,
      1.875,
      3.0625,
      0.5703125,
      -2.84375,
      -2.5,
      1.8203125,
      -3.59375,
      2.90625,
      5,
      2.890625,
      -1.0078125,
      -0.90625,
      -0.91015625,
      0.2490234375,
      4.8125,
      -0.333984375,
      0.0322265625,
      -0.58984375,
      -4.9375,
      1.1875,
      0.71875,
      -6.96875,
      3.015625,
      3.203125,
      -0.703125,
      -2.15625,
      -0.20703125,
      0.193359375,
      -0.03662109375,
      5.03125,
      -1.84375,
      0.94921875,
      -6.125,
      -2.59375,
      -1.296875,
      0.58203125,
      0.671875,
      0.6796875,
      -1.5625,
      -3.296875,
      1.6953125,
      5.65625,
      -0.345703125,
      -0.375,
      3.984375,
      3.8125,
      -4.84375,
      3.59375,
      -1.9296875,
      -2.09375,
      4.3125,
      -5.5625,
      -3.203125,
      2.703125,
      3.328125,
      -1.09375,
      2.15625,
      1.734375,
      -5.25,
      -1.3359375,
      2.921875,
      6.5,
      -1.0625,
      0.9140625,
      0.07421875,
      -0.4140625,
      -0.89453125,
      -0.59375,
      2.484375,
      1.953125,
      -4,
      1.1328125,
      2.828125,
      1.59375,
      1.5859375,
      -0.546875,
      -1.2890625,
      -0.11767578125,
      2.703125,
      -1.46875,
      -1.484375,
      4.5625,
      5.625,
      -7.09375,
      -7.59375,
      2.546875,
      -2.4375,
      -3.546875,
      -0.72265625,
      4.21875,
      0.4765625,
      2.75,
      -5.96875,
      -5.25,
      -0.9296875,
      -2.359375,
      -0.09716796875,
      4.875,
      -2.0625,
      -5.0625,
      -3.640625,
      4.5,
      3.1875,
      2.8125,
      -0.412109375,
      -1.875,
      0.380859375,
      -5.6875,
      2.828125,
      1.1953125,
      7.78125,
      -0.2021484375,
      3.96875,
      1.109375,
      -8.375,
      -0.05078125,
      -2.5625,
      -1.015625,
      2.6875,
      -1.8203125,
      2.84375,
      -0.65234375,
      -1.4296875,
      -0.859375,
      4.15625,
      -2.765625,
      -1.8984375,
      3.3125,
      -6.84375,
      -2.171875,
      2.828125,
      1.5390625,
      3.296875,
      -0.2490234375,
      -4.5625,
      3.109375,
      2.3125,
      0.185546875,
      0.212890625,
      -1.0859375,
      0.38671875,
      -2.890625,
      3.78125,
      3.4375,
      1.3125,
      0.6015625,
      -1.734375,
      -1.296875,
      -4.6875,
      -0.66015625,
      -0.34765625,
      -1.53125,
      -0.267578125,
      -1.0390625,
      0.0291748046875,
      3.9375,
      -3.578125,
      -2.203125,
      -1.0625,
      1.046875,
      -2.765625,
      1.09375,
      2.203125,
      3,
      2.15625,
      0.85546875,
      -3.09375,
      -0.7109375,
      2.46875,
      -3.4375,
      -3.90625,
      -0.388671875,
      4.28125,
      -3,
      -1.390625,
      -4.40625,
      -0.65234375,
      1.984375,
      0.0184326171875,
      -2.890625,
      2.25,
      7.8125,
      1.6328125,
      -0.9296875,
      -0.1591796875,
      3.9375,
      -1.484375,
      -1.0703125,
      1.890625,
      2.75,
      -2.8125,
      -7.53125,
      -6.15625,
      1.640625,
      6.09375,
      -0.287109375,
      3.390625,
      -3.40625,
      4.125,
      0.92578125,
      -1.4921875,
      -15.4375,
      2.921875,
      -0.98046875,
      -3.859375,
      -0.84765625,
      -2.25,
      1.5546875,
      -2.234375,
      1.859375,
      -2.03125,
      -2.4375,
      0.0380859375,
      2.859375,
      1.953125,
      -2.265625,
      1.828125,
      0.34375,
      -0.296875,
      1.34375,
      -3.328125,
      -5.4375,
      0.8984375,
      -2.234375,
      2.109375,
      2.859375,
      2.71875,
      -3.46875,
      0.71875,
      3.421875,
      -5.03125,
      -0.77734375,
      2.859375,
      0.5390625,
      -0.1640625,
      0.94140625,
      0.94921875,
      1.90625,
      -1.234375,
      1.8515625,
      -1.609375,
      -2.84375,
      1.046875,
      4.5,
      -5.46875,
      -0.75390625,
      -2.171875,
      -0.34765625,
      2.234375,
      2.203125,
      -4.96875,
      0.6953125,
      -1.4140625,
      -0.55859375,
      -0.033935546875,
      -5.8125,
      -1.640625,
      -3.015625,
      3.796875,
      1.265625,
      -2.65625,
      2.234375,
      -0.453125,
      -2.015625,
      0.6484375,
      -0.337890625,
      1.109375,
      -2.4375,
      3.0625,
      -0.024658203125,
      -1.4296875,
      0.091796875,
      4.71875,
      -0.27734375,
      -4.09375,
      -1.8515625,
      0.03857421875,
      -5.21875,
      4.40625,
      -0.62890625,
      0.5234375,
      -1.375,
      -1.9453125,
      1.125,
      -0.69921875,
      0.89453125,
      3.53125,
      5.28125,
      3.6875,
      -3.546875,
      5.5,
      -4.25,
      -4.59375,
      -1.1640625,
      -3.9375,
      -3.71875,
      1.2734375,
      -3.125,
      0.0322265625,
      -1.125,
      -2.34375,
      -5.8125,
      -6.375,
      -0.93359375,
      0.412109375,
      -0.328125,
      4.0625,
      -0.91796875,
      3.515625,
      -1.3671875,
      -3.6875,
      0.76953125,
      -2.140625,
      -2.46875,
      1.421875,
      1.1640625,
      -5.875,
      -3.3125,
      5.75,
      3.8125,
      -2.359375,
      4.34375,
      0.1640625,
      -1.0625,
      0.90625,
      4.625,
      -3.921875,
      -0.5390625,
      1.875,
      -1.6953125,
      -3.125,
      -3.765625,
      1.375,
      -3.4375,
      1.7578125,
      0.2158203125,
      -0.83984375,
      -0.296875,
      -4.6875,
      -3.25,
      -2.546875,
      -3.34375,
      2.0625,
      5.4375,
      -2.65625,
      -3.125,
      5.4375,
      2.375,
      0.84375,
      -0.138671875,
      -1.3828125,
      2.46875,
      2.984375,
      3.625,
      -4.75,
      -3.625,
      -0.5625,
      -1.4453125,
      -0.416015625,
      3.734375,
      -4.0625,
      1.5546875,
      4.375,
      2.46875,
      -7.03125,
      -0.404296875,
      6.03125,
      -3.109375,
      -1.375,
      -0.0238037109375,
      1.25,
      0.578125,
      2.296875,
      -1.59375,
      -3.78125,
      -0.85546875,
      3.953125,
      4.03125,
      2.046875,
      -2.34375,
      3.3125,
      1.3671875,
      5.15625,
      -2.390625,
      -6.03125,
      1.421875,
      3.171875,
      -1.875,
      -0.80859375,
      9.5625,
      -2.265625,
      -2.578125,
      -0.1279296875,
      2.140625,
      3.125,
      1.2421875,
      -0.99609375,
      -0.37109375,
      3.796875,
      1.140625,
      0.65625,
      0.5078125,
      0.61328125,
      -1.6875,
      -2.296875,
      0.70703125,
      -2.34375,
      0.57421875,
      -0.875,
      -1.796875,
      -3.765625,
      -0.30078125,
      0.06201171875,
      4.21875,
      4.53125,
      -1.6171875,
      -0.51171875,
      2.171875,
      3.28125,
      -2.703125,
      3.59375,
      0.232421875,
      8.75,
      -1.0625,
      -3.5,
      5.59375,
      2.734375,
      -1.9375,
      1.21875,
      -4.5,
      -5.5,
      2,
      -2.859375,
      -2.546875,
      0.58203125,
      -6.84375,
      -0.77734375,
      3.96875,
      -1.6484375,
      1.375,
      3.796875,
      6.1875,
      0.80078125,
      -0.65625,
      -4.5,
      -0.00982666015625,
      -1.921875,
      -0.609375,
      2.34375,
      -4.4375,
      -0.00946044921875,
      0.486328125,
      3.390625,
      3.296875,
      -0.7734375,
      -1.0390625,
      5.875,
      -0.859375,
      -1,
      0.53125,
      1.203125,
      0.248046875,
      0.0869140625,
      3.5625,
      -2.921875,
      0.796875,
      7.09375,
      5.46875,
      -4.25,
      0.9765625,
      -1.3125,
      1.421875,
      -4.71875,
      -0.98046875,
      0.271484375,
      -1.625,
      -2.40625,
      -1.1484375,
      -1.1015625,
      -0.341796875,
      -6.75,
      2.09375,
      -2.6875,
      -7.3125,
      3.671875,
      3.34375,
      0.7578125,
      0.8046875,
      1.3203125,
      6.78125,
      -2.875,
      -5.03125,
      -4.90625,
      -5.1875,
      -1.1015625,
      0.078125,
      0.79296875,
      4.375,
      3.03125,
      -2.96875,
      3.8125,
      -8.1875,
      0.87109375,
      -2.375,
      2.078125,
      1.7734375,
      -4.4375,
      -1.625,
      -1.484375,
      -8.25,
      -3.71875,
      -2.609375,
      -1.3203125,
      -3,
      -6.15625,
      -0.84375,
      0.77734375,
      -4.78125,
      0.443359375,
      -1.609375,
      0.3671875,
      1.921875,
      1.4453125,
      1.1953125,
      -4.90625,
      0.875,
      4.25,
      2.75,
      0.67578125,
      1.4609375,
      3.71875,
      3.390625,
      -1.28125,
      0.95703125,
      -2.78125,
      6.34375,
      -1.71875,
      6.71875,
      6.65625,
      -0.033203125,
      -6.0625,
      2.3125,
      1.0546875,
      1.328125,
      -3.4375,
      -1.34375,
      -0.337890625,
      2.59375,
      -0.490234375,
      -3.21875,
      -0.462890625,
      -5.59375,
      0.38671875,
      0.63671875,
      -3.90625,
      -1.125,
      3.796875,
      -2.4375,
      2.484375,
      0.09814453125,
      -0.1005859375,
      1.3671875,
      0.353515625,
      3.984375,
      -1.84375,
      3.203125,
      -6.28125,
      0.27734375,
      1.8515625,
      -1.7109375,
      2.03125,
      -0.2578125,
      1.765625,
      1.7109375,
      2.75,
      2.609375,
      2.609375,
      3.28125,
      2.890625,
      3.828125,
      -0.83203125,
      1.6796875,
      0.314453125,
      -3.40625,
      3.75,
      1.0234375,
      -2.8125,
      -1.0703125,
      3.515625,
      -1.5,
      0.72265625,
      3.140625,
      -7.28125,
      -2.125,
      -1.734375,
      -4.25,
      2.921875,
      -0.56640625,
      -2.140625,
      1.171875,
      0.73046875,
      3.328125,
      2.203125,
      -1.828125,
      2.90625,
      -0.953125,
      -3.390625,
      1.8984375,
      -4.15625,
      -0.53515625,
      2.65625,
      3,
      2.484375,
      -0.404296875,
      0.208984375,
      -2.4375,
      1.9140625,
      3,
      -2.65625,
      -1.875,
      8.375,
      0.396484375,
      -1.21875,
      1.640625,
      -1.2578125,
      0.11181640625,
      -1.46875,
      -0.46484375,
      7.125,
      5.90625,
      -3.015625,
      -2.578125,
      -7.03125,
      0.04345703125,
      -2.25,
      2.09375,
      1.2890625,
      3.140625,
      -1.09375,
      -0.40234375,
      -1.3984375,
      -4.1875,
      -1.015625,
      -5.78125,
      0.78125,
      3.125,
      1.375,
      1.4453125,
      0.0244140625,
      4.75,
      -2.875,
      3.578125,
      2.734375,
      -3.921875,
      2.25,
      3.84375,
      -1.296875,
      3.90625,
      4.53125,
      1.9140625,
      2.859375,
      -1.546875,
      -1.765625,
      -0.21875,
      -2.515625,
      0.8359375,
      -2.765625,
      -3.078125,
      5.46875,
      3.015625,
      -2.015625,
      1.7265625,
      0.51953125,
      -0.7578125,
      3,
      -4.84375,
      -5.5625,
      -1.984375,
      -2.1875,
      -1.3828125,
      2.484375,
      -3.375,
      0.015869140625,
      4.0625,
      -5.3125,
      5.4375,
      -0.2578125,
      6.1875,
      0.85546875,
      -2.5,
      0.2119140625,
      -2.25,
      4.3125,
      -1.3125,
      2.390625,
      0.71484375,
      -2.796875,
      2.578125,
      -3.078125,
      3.625,
      -0.546875,
      -0.130859375,
      5.65625,
      -4,
      0.70703125,
      0.169921875,
      -0.1611328125,
      -7.09375,
      -4.96875,
      -2.578125,
      -4.3125,
      1.9296875,
      1.5546875,
      -0.380859375,
      0.216796875,
      5.25,
      -5.15625,
      0.8984375,
      -0.94921875,
      -0.953125,
      1.296875,
      -0.130859375,
      5.40625,
      -0.296875,
      -0.44921875,
      0.064453125,
      -1.4296875,
      -2.640625,
      -3.140625,
      0.060302734375,
      2.828125,
      -3.5,
      -1.5546875,
      -1.2890625,
      -0.80078125,
      -2,
      -0.9375,
      -1.7109375,
      1.8203125,
      3.171875,
      0.90625,
      -0.44921875,
      -1.734375,
      1.4609375,
      -3.40625,
      -2.859375,
      -3.234375,
      1.6796875,
      2.34375,
      -4.96875,
      3.96875,
      -2.234375,
      1.0234375,
      0.34765625,
      -3.15625,
      -3.546875,
      -1.7578125,
      5.59375,
      0.032470703125,
      -0.71875,
      3.4375,
      -0.8046875,
      1.703125,
      -1.2734375,
      -3.515625,
      -3.1875,
      1.125,
      0.58203125,
      0.703125,
      -2.6875,
      1.203125,
      1.7421875,
      -0.5390625,
      -3,
      -1.8984375,
      4.5,
      1.015625,
      5.9375,
      3.9375,
      -0.054443359375,
      -2.3125,
      0.1865234375,
      -2.125,
      2.609375,
      4.3125,
      -1.0546875,
      4.75,
      0.357421875,
      6.46875,
      -1.0703125,
      0.02099609375,
      -8,
      1.890625,
      6.0625,
      4.0625,
      -1.546875,
      4.1875,
      0.515625,
      1.71875,
      1.140625,
      2.703125,
      -1.7265625,
      -0.87890625,
      -4.71875,
      4,
      0.267578125,
      -3.5625,
      0.052490234375,
      2.53125,
      -0.99609375,
      3.734375,
      5.03125,
      5.0625,
      -1.015625,
      4.09375,
      3.0625,
      -2.53125,
      -4.25,
      2.859375,
      0.22265625,
      2.109375,
      -0.58203125,
      -3.40625,
      -0.71484375,
      1.375,
      -0.81640625,
      7.28125,
      -2.28125,
      3.171875,
      -3.15625,
      4.1875,
      -0.53125,
      -2.234375,
      -1.2421875,
      2.171875,
      1.6171875,
      -3.859375,
      1.5390625,
      -3.625,
      0.203125,
      -0.1513671875,
      -11.875,
      2.84375,
      2.3125,
      -1.7265625,
      3.859375,
      0.5625,
      1.2890625,
      0.875,
      -1.9453125,
      1.6484375,
      -0.9296875,
      0.984375,
      2.453125,
      0.765625,
      -4.46875,
      1.5703125,
      1.625,
      -1.4765625,
      -3.28125,
      4.28125,
      -2.53125,
      1.484375,
      1.5,
      3.46875,
      -5.03125,
      -3.453125,
      -1.4609375,
      -2.125,
      -0.333984375,
      0.7109375,
      -0.60546875,
      1,
      1.890625,
      -2.046875,
      -1.0625,
      -0.1904296875,
      -3.875,
      -0.279296875,
      4.1875,
      1.875,
      -2.703125,
      5.5625,
      -4.125,
      1.65625,
      2.46875,
      -0.796875,
      -1.3203125,
      1.25,
      -1.1484375,
      3.140625,
      1.453125,
      -1.4609375,
      0.7734375,
      2.75,
      -1.46875,
      -2.765625,
      -2.78125,
      1.015625,
      -1.796875,
      -0.06982421875,
      3.078125,
      -1.3984375,
      0.97265625,
      -2.65625,
      -2.515625,
      2.078125,
      -0.59765625,
      3.109375,
      3.25,
      0.9296875,
      0.62109375,
      1.4921875,
      -5.4375,
      5,
      1.2734375,
      -2.21875,
      -0.703125,
      -0.6484375,
      2.15625,
      -4.65625,
      3.046875,
      -0.2236328125,
      -2.203125,
      3.453125,
      3.546875,
      -5.53125,
      -2.3125,
      1.296875,
      2.734375,
      -0.4765625,
      -1.8046875,
      -0.89453125,
      2.546875,
      -2.078125,
      0.64453125,
      -5,
      1.1328125,
      1.859375,
      -3.75,
      3.5625,
      0.12353515625,
      0.97265625,
      -3.96875,
      -0.94921875,
      2.765625,
      3,
      4.25,
      -3.203125,
      1.359375,
      3.203125,
      -2.96875,
      4,
      -1.0546875,
      0.91796875,
      -0.359375,
      5,
      -3.96875,
      -2.53125,
      -8.375,
      0.6796875,
      -2.234375,
      -1.609375,
      -2.546875,
      3.5625,
      -2.546875,
      -0.95703125,
      -2.25,
      -0.91015625,
      -5.1875,
      -2.0625,
      1.1875,
      -1.9375,
      -5.125,
      2.34375,
      0.484375,
      6.8125,
      5.375,
      3.09375,
      6.15625,
      -2.359375,
      0.9921875,
      1.7578125,
      2.015625,
      -0.11767578125,
      1.6640625,
      -1.2734375,
      0.91015625,
      3,
      -0.388671875,
      3.515625,
      -2.421875,
      -2.09375,
      -3.625,
      -2.578125,
      -0.7421875,
      0.83984375,
      -2.484375,
      1.7421875,
      6.71875,
      -0.41015625,
      2.953125,
      3.328125,
      -0.2255859375,
      -3.59375,
      0.056884765625,
      0.0281982421875,
      3.5625,
      1.1328125,
      0.1875,
      -3.765625,
      3.921875,
      4.40625,
      -0.859375,
      1.2265625,
      2.1875,
      1.3125,
      -1.671875,
      5.1875,
      4.21875,
      3.09375,
      -1.84375,
      -0.263671875,
      3.03125,
      -2.640625,
      4.1875,
      6.09375,
      -0.10791015625,
      -1.09375,
      4.90625,
      -0.1796875,
      -4.125,
      -0.59765625,
      0.0849609375,
      -1.5625,
      -0.5625,
      0.7265625,
      0.072265625,
      0.0791015625,
      0.5234375,
      0.11279296875,
      2.21875,
      3.1875,
      -4.625,
      1.546875,
      -6,
      0.265625,
      -7.65625,
      3.203125,
      -3.890625,
      -0.236328125,
      1.25,
      3.203125,
      -4.03125,
      -1.3046875,
      0.98046875,
      3.734375,
      -1.2265625,
      -4.09375,
      3.28125,
      2.234375,
      -1.59375,
      -2.640625,
      -3.5,
      2.40625,
      -1.015625,
      3.40625,
      -3,
      2.046875,
      0.205078125,
      -2.5625,
      -4.5625,
      1.875,
      -0.470703125,
      -6.34375,
      -6.0625,
      -1.234375,
      1.703125,
      -4.46875,
      3.140625,
      2.796875,
      -0.5546875,
      4.3125,
      -1.46875,
      1.609375,
      3.484375,
      -0.328125,
      1.1875,
      -0.4609375,
      -0.306640625,
      1.7890625,
      2.953125,
      -3,
      1.484375,
      -2.296875,
      3.328125,
      2.515625,
      -2.296875,
      0.67578125,
      -5.8125,
      1.8515625,
      1.84375,
      3.25,
      -0.65234375,
      -2.515625,
      0.357421875,
      1.8671875,
      -2.65625,
      -1.78125,
      0.392578125,
      1.015625,
      -1.484375,
      2.90625,
      -2.359375,
      3.328125,
      -2.6875,
      0.6875,
      0.734375,
      -1.6328125,
      0.2177734375,
      1.9296875,
      -2.78125,
      -0.1748046875,
      -1.40625,
      2.59375,
      -3.265625,
      -6.4375,
      3.125,
      2.9375,
      1.640625,
      2.046875,
      0.251953125,
      -2.890625,
      -1.484375,
      2.765625,
      -0.55078125,
      -1.953125,
      -1.34375,
      0.89453125,
      2.453125,
      -0.251953125,
      -1.859375,
      -3,
      1.8671875,
      -3.546875,
      -3.140625,
      0.302734375,
      1.6171875,
      1.7109375,
      -12.4375,
      1.15625,
      -1.3203125,
      1.765625,
      -3.5,
      1.015625,
      5.4375,
      0.98828125,
      1.5390625,
      5.875,
      -0.00970458984375,
      -4.78125,
      2.25,
      16.125,
      -3.1875,
      -3.75,
      0.91796875,
      -2.296875,
      4.375,
      8.1875,
      1.0859375,
      1.0234375,
      2.734375,
      0.90234375,
      3.28125,
      -0.671875,
      0.46484375,
      0.220703125,
      0.53125,
      1.1796875,
      0.46875,
      -1.703125,
      -4.46875,
      2.046875,
      -0.77734375,
      -0.82421875,
      3.328125,
      0.466796875,
      -0.1630859375,
      1.0546875,
      -4.4375,
      -1.6875,
      -2.71875,
      -1.2109375,
      -2.5625,
      -3.3125,
      -4.59375,
      -3.203125,
      -1.625,
      1.0546875,
      -0.1533203125,
      -3.046875,
      -2.828125,
      -2.5,
      -3.203125,
      3.203125,
      -1.8046875,
      -2.734375,
      0.19140625,
      -2.359375,
      0.1552734375,
      1.15625,
      -1.46875,
      -2.140625,
      -4.125,
      -1.9140625,
      1.875,
      0.87109375,
      0.53125,
      -2.765625,
      -6.0625,
      -0.59375,
      -2.34375,
      -0.53125,
      -0.69140625,
      -3.9375,
      1.40625,
      -1.390625,
      -3.375,
      -0.279296875,
      1.625,
      -0.0216064453125,
      1.2265625,
      -2.703125,
      -1.140625,
      1.9296875,
      3.21875,
      0.341796875,
      -3.78125,
      1.921875,
      3.03125,
      2.140625,
      0.359375,
      -0.65234375,
      1.8359375,
      -3.015625,
      -2.421875,
      -2.34375,
      -0.14453125,
      -5.71875,
      2.03125,
      0.92578125,
      0.431640625,
      6.375,
      -4.46875,
      -1.078125,
      1.390625,
      -5.59375,
      -1.796875,
      0.294921875,
      1.875,
      -1.390625,
      3.09375,
      3.265625,
      0.01397705078125,
      0.79296875,
      0.1796875,
      -0.81640625,
      -3.53125,
      3.8125,
      -1.0859375,
      2.75,
      0.75390625,
      -3.4375,
      6.03125,
      -0.9765625,
      0.08154296875,
      -0.2001953125,
      -0.3203125,
      -4.59375,
      -3.015625,
      -0.546875,
      0.361328125,
      4.375,
      -0.330078125,
      -2.390625,
      -1.3984375,
      -9,
      -2.390625,
      -1.6328125,
      -0.33203125,
      3.171875,
      -3.8125,
      0.78125,
      -1.828125,
      -3.671875,
      -2.875,
      0.0281982421875,
      -3.1875,
      4.09375,
      4.53125,
      3.15625,
      0.2392578125,
      -5.65625,
      -0.392578125,
      1.9921875,
      -0.87890625,
      0.62890625,
      1.15625,
      -2.78125,
      5.03125,
      5.3125,
      1.3125,
      -1.734375,
      4.46875,
      1.8359375,
      -4.21875,
      -0.39453125,
      3.203125,
      -4.4375,
      -2.796875,
      -2.15625,
      2.578125,
      0.62890625,
      -0.255859375,
      -3.3125,
      -0.99609375,
      -3.46875,
      -0.53125,
      1.2265625,
      -0.21875,
      -3.03125,
      2.125,
      4.03125,
      -3.5,
      1.625,
      -0.65625,
      3.078125,
      -5.09375,
      3.796875,
      4.84375,
      -0.58984375,
      2.140625,
      4.0625,
      0.625,
      0.5390625,
      -8.0625,
      2.953125,
      6.96875,
      -3.5,
      -0.203125,
      3.234375,
      0.96875,
      0.73046875,
      -2.515625,
      -5.71875,
      4.09375,
      5.34375,
      -5.71875,
      -0.90625,
      -0.828125,
      2.515625,
      -1.6171875,
      -2.703125,
      3.546875,
      1.265625,
      -1.625,
      2.40625,
      0.01171875,
      -4.9375,
      -1.7265625,
      1.4140625,
      -2.34375,
      -0.2060546875,
      3.75,
      1.890625,
      -1.828125,
      -2.734375,
      5.25,
      2.984375,
      2.34375,
      -1.4609375,
      1.2109375,
      3.046875,
      -0.8359375,
      -3.03125,
      -1.5703125,
      0.181640625,
      3.328125,
      -4.4375,
      0.41796875,
      -1.5234375,
      1.6640625,
      -3.3125,
      3.6875,
      -1.875,
      1.4296875,
      -0.98828125,
      -2.75,
      -2.796875,
      1.90625,
      0.86328125,
      -0.12255859375,
      1.9296875,
      -0.484375,
      2.546875,
      3.640625,
      -3.484375,
      2.5625,
      0.890625,
      -1.21875,
      1.2265625,
      -2.25,
      0.703125,
      0.373046875,
      3.15625,
      -2.3125,
      -3.296875,
      -3.265625,
      -0.96875,
      1.1328125,
      -4.875,
      -1.21875,
      0.859375,
      -5.5,
      4.15625,
      -0.380859375,
      0.40234375,
      -0.1240234375,
      0.44140625,
      -5.59375,
      2.375,
      3.109375,
      -4.8125,
      4.53125,
      -1.375,
      -1.953125,
      3.03125,
      -1.09375,
      3.6875,
      -3.40625,
      1.0703125,
      2.875,
      -3.21875,
      -0.85546875,
      3.15625,
      -1.484375,
      0.765625,
      -5.15625,
      3.9375,
      0.2451171875,
      3.625,
      2.65625,
      2.5,
      4.6875,
      -7.375,
      3.0625,
      -2.109375,
      0.4921875,
      -3.234375,
      0.87890625,
      -0.376953125,
      -2.390625,
      2.5,
      3.75,
      2.109375,
      -7.6875,
      -2.984375,
      -0.52734375,
      -1.984375,
      1.015625,
      0.796875,
      -0.07568359375,
      -3.109375,
      0.357421875,
      3.125,
      1.546875,
      -1.6953125,
      -2.734375,
      -5.1875,
      2.4375,
      -0.9140625,
      -6.28125,
      -0.0947265625,
      2.359375,
      -1,
      2.046875,
      -2.328125,
      -0.54296875,
      1.015625,
      2.421875,
      -5.46875,
      2.296875,
      1.625,
      2.515625,
      5.03125,
      0.447265625,
      -0.02490234375,
      3.046875,
      -3.703125,
      -3.421875,
      1.0546875,
      0.302734375,
      0.30859375,
      1.734375,
      -1.015625,
      2.265625,
      0.76171875,
      1.0546875,
      -2.546875,
      5.9375,
      2.15625,
      -7.4375,
      2,
      -5.71875,
      0.2373046875,
      -1.78125,
      -5.09375,
      -0.482421875,
      4.75,
      0.2060546875,
      -0.349609375,
      1.6875,
      1.1796875,
      1.0390625,
      2.9375,
      -3.28125,
      -2.453125,
      0.68359375,
      3.609375,
      -2.703125,
      2.75,
      2.015625,
      0.515625,
      -1.3828125,
      -0.40234375,
      2.796875,
      -0.2265625,
      0.62109375,
      3.75,
      3.96875,
      2.4375,
      0.87109375,
      -4.8125,
      -0.58203125,
      -1.2265625,
      -1.46875,
      -1.140625,
      -1.7265625,
      -0.05224609375,
      -3.375,
      3.234375,
      2.921875,
      -3.953125,
      -1.0234375,
      -2.078125,
      -2.21875,
      -0.43359375,
      4.1875,
      3.8125,
      -2.5625,
      1.875,
      4.84375,
      3.625,
      -3.953125,
      -2.765625,
      -1.0703125,
      -2.265625,
      -3.84375,
      -2.796875,
      -1.6875,
      -1.796875,
      -1.5546875,
      0.734375,
      0.40234375,
      2.1875,
      -4.71875,
      -2.46875,
      3.328125,
      5.5,
      0.5859375,
      -2.75,
      -2.015625,
      1.453125,
      3.140625,
      -3.578125,
      -3,
      1.7890625,
      1.9921875,
      -4.96875,
      -4.8125,
      -0.1103515625,
      -2.5,
      0.1796875,
      3.375,
      -0.443359375,
      -0.3984375,
      0.05078125,
      -4.46875,
      -2.96875,
      5.03125,
      4.71875,
      -1.1640625,
      -3.390625,
      -2.09375,
      -1.1953125,
      7.375,
      5.65625,
      -1.59375,
      -1.90625,
      2.5,
      -4.4375,
      -4.8125,
      0.37109375,
      -1.1640625,
      -0.1298828125,
      -6.84375,
      6.34375,
      -1.0859375,
      2.171875,
      5.09375,
      -1.4921875,
      3.078125,
      -2,
      2.515625,
      -2.015625,
      1.6328125,
      -0.034423828125,
      -2.859375,
      1.21875,
      -4.21875,
      -2.71875,
      1.6875,
      -1.453125,
      -0.490234375,
      -2.53125,
      5.78125,
      0.59375,
      -3.1875,
      -1.828125,
      -1.390625,
      4.96875,
      -0.69140625,
      -2.21875,
      0.7578125,
      -1.296875,
      2.5625,
      -3.078125,
      0.9609375,
      -5.09375,
      0.0289306640625,
      -0.99609375,
      3.34375,
      0.78515625,
      0.8984375,
      -0.2890625,
      -0.16796875,
      -2.53125,
      4.28125,
      0.6328125,
      2.703125,
      1.03125,
      2.25,
      -2.5625,
      -3.140625,
      6.125,
      3.9375,
      2.328125,
      -3.921875,
      1.4609375,
      -0.271484375,
      -2.46875,
      -2.015625,
      -0.369140625,
      0.279296875,
      0.06591796875,
      2.84375,
      0.478515625,
      1.296875,
      -2.484375,
      -0.421875,
      -4.0625,
      -0.92578125,
      3.546875,
      3.734375,
      -1.140625,
      1.296875,
      0.703125,
      0.05859375,
      0.58984375,
      0.55859375,
      -0.625,
      1.3203125,
      -0.85546875,
      3.59375,
      -0.73046875,
      -2.6875,
      0.55078125,
      -3.046875,
      -0.5625,
      -0.408203125,
      -1.6796875,
      1.859375,
      1.4609375,
      -2.453125,
      2.34375,
      -1.0546875,
      -1.0234375,
      2.78125,
      -1.59375,
      -2.59375,
      2.75,
      -0.1748046875,
      4.59375,
      -3.546875,
      0.2890625,
      1.25,
      1.2734375,
      0.55859375,
      -0.373046875,
      1.25,
      -2.796875,
      -0.0024871826171875,
      2.203125,
      -0.72265625,
      -1.640625,
      1.2265625,
      0.08740234375,
      -2.296875,
      1.078125,
      -0.34765625,
      -4.34375,
      0.7109375,
      -0.69921875,
      -2.40625,
      -0.484375,
      1.234375,
      -0.33203125,
      -2.640625,
      2.828125,
      2.140625,
      1.3359375,
      -0.310546875,
      -2.078125,
      -3.046875,
      0.51171875,
      -3.484375,
      0.6953125,
      -2.140625,
      1.1171875,
      -2.53125,
      2.421875,
      -0.2734375,
      -0.453125,
      -1.25,
      0.6484375,
      1.96875,
      -0.1767578125,
      4.4375,
      1.515625,
      2.65625,
      1.9296875,
      -0.83203125,
      0.765625,
      -2.578125,
      -0.875,
      -1.96875,
      1.7109375,
      2.0625,
      1.9296875,
      -0.53125,
      1.7890625,
      0.326171875,
      1.28125,
      2.578125,
      0.158203125,
      -0.27734375,
      -0.27734375,
      -0.7734375,
      2.046875,
      -1.3046875,
      -2.28125,
      1.4765625,
      -0.6015625,
      -3.703125,
      -1.921875,
      -1.046875,
      -0.546875,
      0.5703125,
      -0.134765625,
      -1.2421875,
      -0.6484375,
      1.390625,
      1.3203125,
      -1.28125,
      1.9296875,
      0.384765625,
      0.09423828125,
      -0.3203125,
      0.0419921875,
      1.2890625,
      0.0908203125,
      -2.8125,
      1.546875,
      -0.82421875,
      -2.765625,
      -0.1767578125,
      -1.234375,
      -1.046875,
      -0.79296875,
      2.28125,
      -0.050537109375,
      0.72265625,
      -0.93359375,
      -0.51953125,
      -2.03125,
      0.7734375,
      -0.6171875,
      0.30078125,
      0.73046875,
      3.5625,
      -3.03125,
      -0.010009765625,
      -1.0625,
      -0.8125,
      1.59375,
      3.390625,
      0.28125,
      1.8203125,
      -0.13671875,
      -1.109375,
      3.3125,
      -2.578125,
      -1.578125,
      -2.234375,
      1.1328125,
      1.828125,
      -1.6796875,
      -1.453125,
      1.7109375,
      -0.2119140625,
      3.578125,
      0.6640625,
      1.015625,
      0.431640625,
      0.3984375,
      0.359375,
      0.63671875,
      0.421875,
      -1.5546875,
      -2.03125,
      -2.609375,
      0.80859375,
      -1.0390625,
      1.6640625,
      -4.28125,
      -0.333984375,
      1.046875,
      0.126953125,
      1.8359375,
      1.1328125,
      3.5,
      4.59375,
      0.59375,
      6.5,
      1.2734375,
      -0.19140625,
      2.1875,
      3.34375,
      -0.8359375,
      -0.9765625,
      -1.7109375,
      0.2294921875,
      0.458984375,
      3.59375,
      2.34375,
      -1.2109375,
      -2.515625,
      1.6171875,
      1.765625,
      -0.625,
      -0.49609375,
      -2.703125,
      2.078125,
      0.220703125,
      1.359375,
      0.98046875,
      0.24609375,
      -0.65234375,
      4.71875,
      -3.875,
      -0.82421875,
      0.7578125,
      -1.0625,
      -0.8671875,
      -1.640625,
      -1.609375,
      -0.76171875,
      -1.25,
      1.6015625,
      1.7890625,
      0.72265625,
      1.5546875,
      2.96875,
      0.50390625,
      2.15625,
      -1.3984375,
      0.053466796875,
      -0.890625,
      -0.77734375,
      -1.703125,
      0.08203125,
      0.6015625,
      -3.015625,
      -1.3984375,
      -6.84375,
      -3,
      -2.59375,
      1.515625,
      -0.5546875,
      2.953125,
      -1.7578125,
      -2.21875,
      -0.1884765625,
      -1.9921875,
      4.75,
      0.11767578125,
      -2.421875,
      2.9375,
      0.055908203125,
      -0.30078125,
      -3.625,
      -3.625,
      -0.185546875,
      1.9921875,
      2.609375,
      -1.375,
      1.890625,
      -2.453125,
      -0.7734375,
      1.25,
      1.15625,
      -2.984375,
      -1.8515625,
      -1.8359375,
      1.2578125,
      0.9609375,
      1.5703125,
      -0.18359375,
      3.5625,
      0.70703125,
      -1.453125,
      0.25390625,
      -1.7578125,
      5.875,
      2.65625,
      -2.34375,
      -0.310546875,
      1.8203125,
      0.310546875,
      -0.8203125,
      1.8671875,
      -0.76953125,
      2.96875,
      -1.4375,
      0.953125,
      -0.90625,
      0.7890625,
      -0.17578125,
      1.0234375,
      2.109375,
      -4.34375,
      -1.796875,
      -1.625,
      2.921875,
      -0.25,
      2.8125,
      4.21875,
      0.310546875,
      1.75,
      1.03125,
      3.15625,
      0.3828125,
      0.0498046875,
      2.171875,
      3.265625,
      -0.546875,
      -0.51171875,
      -1.3828125,
      -1.484375,
      1.6796875,
      2.9375,
      0.7578125,
      2.0625,
      3.609375,
      -0.051513671875,
      -2.40625,
      -1.546875,
      2.703125,
      5.03125,
      -0.58203125,
      -1.9140625,
      -2.96875,
      -1.6328125,
      -0.30078125,
      -2.1875,
      2.28125,
      -2.640625,
      2.921875,
      1.1640625,
      -2.109375,
      -1.0390625,
      -3.46875,
      -1.1328125,
      -0.50390625,
      -0.81640625,
      -0.00372314453125,
      -0.6953125,
      2.875,
      -0.365234375,
      2.71875,
      2.28125,
      2.6875,
      1.3515625,
      1.953125,
      -0.66015625,
      3.8125,
      -1.8671875,
      -2.078125,
      4.0625,
      -0.6015625,
      -3.453125,
      0.06591796875,
      0.11279296875,
      -3.859375,
      -1.671875,
      -4.375,
      -1.890625,
      -1.609375,
      0.03857421875,
      -2.359375,
      -3.109375,
      2.265625,
      -3.53125,
      2.328125,
      -0.8671875,
      -0.28515625,
      -0.466796875,
      -0.65234375,
      2.046875,
      -1.09375,
      5.3125,
      2.15625,
      0.82421875,
      1.21875,
      -2.96875,
      -0.85546875,
      -0.77734375,
      0.91015625,
      2.21875,
      -1.875,
      -2.046875,
      0.009033203125,
      3.875,
      -0.478515625,
      1.0859375,
      -1.3515625,
      -2.671875,
      3.625,
      5,
      1.46875,
      1.8046875,
      -3.390625,
      0.490234375,
      -4.25,
      -0.357421875,
      -0.388671875,
      0.478515625,
      -3.703125,
      6.09375,
      -4.15625,
      1.2734375,
      -0.67578125,
      0.12353515625,
      0.330078125,
      -3.859375,
      0.546875,
      -2.078125,
      -1.6171875,
      3.359375,
      1.59375,
      -1.71875,
      -3.75,
      0.69921875,
      -2.078125,
      0.314453125,
      -0.73046875,
      -1.65625,
      -0.287109375,
      3.34375,
      -3.1875,
      3.46875,
      1.53125,
      -0.57421875,
      2.828125,
      1.375,
      -1.3671875,
      -1.03125,
      2.234375,
      0.349609375,
      -0.006011962890625,
      1.9453125,
      1.875,
      -2.4375,
      0.1494140625,
      -1.4296875,
      0.625,
      0.69921875,
      4.03125,
      -1.3515625,
      -1.4453125,
      1.4921875,
      2.53125,
      0.98828125,
      0.91796875,
      1.6328125,
      1.796875,
      2.453125,
      -4.78125,
      -0.267578125,
      0.87890625,
      1.7265625,
      1.3125,
      -0.25,
      1.3203125,
      -2.125,
      -1.2890625,
      -0.291015625,
      -0.05078125,
      -2.953125,
      -1.640625,
      -0.8125,
      1.5859375,
      -5.5,
      -0.1015625,
      -2.015625,
      -0.0703125,
      -2.0625,
      -1.9453125,
      1.515625,
      0.70703125,
      -1.75,
      -2.703125,
      -0.236328125,
      0.22265625,
      2.8125,
      0.1259765625,
      -0.423828125,
      2.65625,
      -2.921875,
      1.8515625,
      1.7734375,
      3.375,
      2.46875,
      -1.9140625,
      1.21875,
      -0.384765625,
      2.328125,
      0.1171875,
      1.2265625,
      2.453125,
      2.421875,
      1.359375,
      5,
      2.453125
    ],
    "structure": {
      "sections": [
        {
          "title": "DESIGNER: DESIGN-LOGIC-GUIDED MULTIDISCIPLINARY DATA SYNTHESIS FOR LLM REASONING",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "1 INTRODUCTION",
          "level": 1,
          "start_line": 13
        },
        {
          "title": "Design Logic",
          "level": 1,
          "start_line": 22
        },
        {
          "title": "DESIGNER",
          "level": 1,
          "start_line": 38
        },
        {
          "title": "2 DATA CURATION",
          "level": 1,
          "start_line": 64
        },
        {
          "title": "2.1 QUESTION BANK PROCESSING",
          "level": 1,
          "start_line": 68
        },
        {
          "title": "2.2 BOOK CORPUS PROCESSING",
          "level": 1,
          "start_line": 72
        },
        {
          "title": "2.3 WEB CORPUS PROCESSING",
          "level": 1,
          "start_line": 78
        },
        {
          "title": "3 DESIGN-LOGIC-GUIDED DATA SYNTHESIS",
          "level": 1,
          "start_line": 82
        },
        {
          "title": "3.1 DESIGN LOGIC EXTRACTION",
          "level": 1,
          "start_line": 86
        },
        {
          "title": "3.2 DESIGN LOGIC DEDUPLICATION",
          "level": 1,
          "start_line": 92
        },
        {
          "title": "3.3 QUESTION SYNTHESIS",
          "level": 1,
          "start_line": 96
        },
        {
          "title": "3.4 RESPONSE SYNTHESIS",
          "level": 1,
          "start_line": 106
        },
        {
          "title": "4 DATA ANALYSIS",
          "level": 1,
          "start_line": 110
        },
        {
          "title": "4.1 DIFFICULTY ANALYSIS",
          "level": 1,
          "start_line": 114
        },
        {
          "title": "4.2 DIVERSITY ANALYSIS",
          "level": 1,
          "start_line": 121
        },
        {
          "title": "4.3 DISCIPLINARY DISTRIBUTION",
          "level": 1,
          "start_line": 133
        },
        {
          "title": "4.4 DATA QUALITY AND LABEL ACCURACY VALIDATION",
          "level": 1,
          "start_line": 140
        },
        {
          "title": "5 EXPERIMENTS",
          "level": 1,
          "start_line": 146
        },
        {
          "title": "5.1 EXPERIMENTAL SETUP",
          "level": 1,
          "start_line": 148
        },
        {
          "title": "5.2 SUPERVISED FINE-TUNING (SFT) EXPERIMENTS",
          "level": 1,
          "start_line": 156
        },
        {
          "title": "5.3 COMPARISON WITH BASELINE DATASETS",
          "level": 1,
          "start_line": 176
        },
        {
          "title": "5.4 EFFECT OF DATA SCALING",
          "level": 1,
          "start_line": 182
        },
        {
          "title": "5.5 EFFECT OF SOURCE CORPUS QUALITY",
          "level": 1,
          "start_line": 186
        },
        {
          "title": "5.6 ABLATION STUDIES",
          "level": 1,
          "start_line": 192
        },
        {
          "title": "6 RELATED WORK",
          "level": 1,
          "start_line": 209
        },
        {
          "title": "7 CONCLUSION",
          "level": 1,
          "start_line": 215
        },
        {
          "title": "ETHICS STATEMENT",
          "level": 1,
          "start_line": 219
        },
        {
          "title": "REPRODUCIBILITY STATEMENT",
          "level": 1,
          "start_line": 223
        },
        {
          "title": "THE USE OF LARGE LANGUAGE MODELS (LLMS)",
          "level": 1,
          "start_line": 227
        },
        {
          "title": "REFERENCES",
          "level": 1,
          "start_line": 231
        },
        {
          "title": "A DATA COLLECTION DETAILS",
          "level": 1,
          "start_line": 284
        },
        {
          "title": "B DESIGN LOGIC DEDUPLICATION ALGORITHM",
          "level": 1,
          "start_line": 299
        },
        {
          "title": "C DESIGN LOGIC AND QUESTION QUANTITY",
          "level": 1,
          "start_line": 328
        },
        {
          "title": "D BASELINE DATASETS",
          "level": 1,
          "start_line": 340
        },
        {
          "title": "E QUESTION TYPE ANALYSIS",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "F DETAILED DIFFICULTY ANALYSIS",
          "level": 1,
          "start_line": 354
        },
        {
          "title": "G DETAILED DIVERSITY METRICS",
          "level": 1,
          "start_line": 360
        },
        {
          "title": "H EXPERIMENTAL DETAILS",
          "level": 1,
          "start_line": 371
        },
        {
          "title": "I PERFORMANCE ON GSM8K AND MATH-500",
          "level": 1,
          "start_line": 385
        },
        {
          "title": "J PROMPTS",
          "level": 1,
          "start_line": 399
        },
        {
          "title": "Prompt for Discipline Classification",
          "level": 1,
          "start_line": 401
        },
        {
          "title": "Input Question Data",
          "level": 1,
          "start_line": 421
        },
        {
          "title": "Prompt for Difficulty Classification",
          "level": 1,
          "start_line": 429
        },
        {
          "title": "Example 1",
          "level": 1,
          "start_line": 433
        },
        {
          "title": "Example 2",
          "level": 1,
          "start_line": 438
        },
        {
          "title": "Example 3",
          "level": 1,
          "start_line": 442
        },
        {
          "title": "Prompt for Question Type Classification",
          "level": 1,
          "start_line": 454
        },
        {
          "title": "Prompt for Reasoning-Oriented Filtering",
          "level": 1,
          "start_line": 489
        },
        {
          "title": "Prompt for Design Logic Extraction",
          "level": 1,
          "start_line": 536
        },
        {
          "title": "Instruction for Design Logic Retrieval",
          "level": 1,
          "start_line": 550
        },
        {
          "title": "Prompt for Question Synthesis",
          "level": 1,
          "start_line": 556
        },
        {
          "title": "Prompt for Question Answerability Evaluation",
          "level": 1,
          "start_line": 603
        },
        {
          "title": "Prompt for Design Logic Consistency Evaluation",
          "level": 1,
          "start_line": 613
        },
        {
          "title": "Prompt for Answer Consistency Evaluation",
          "level": 1,
          "start_line": 625
        },
        {
          "title": "Prompt for Discipline Label Evaluation",
          "level": 1,
          "start_line": 639
        },
        {
          "title": "Prompt for Difficulty Label Evaluation",
          "level": 1,
          "start_line": 650
        },
        {
          "title": "Prompt for Type Label Evaluation",
          "level": 1,
          "start_line": 661
        },
        {
          "title": "K DESIGN LOGIC EXAMPLES",
          "level": 1,
          "start_line": 671
        }
      ]
    },
    "tags": [
      "数据合成",
      "LLM推理",
      "设计逻辑"
    ],
    "suggested_tags": [
      "数据合成",
      "LLM推理",
      "设计逻辑",
      "SFT",
      "多学科"
    ],
    "tag_suggestions": [
      {
        "name": "数据合成",
        "confidence": 0.98,
        "reason": "论文核心贡献是提出DESIGNER流水线，用设计逻辑反向生成大规模多学科推理题，属于典型的数据合成/增强研究"
      },
      {
        "name": "LLM推理",
        "confidence": 0.96,
        "reason": "聚焦提升大模型在多学科复杂多步推理上的能力，并验证合成数据对SFT后推理表现的增益"
      },
      {
        "name": "设计逻辑",
        "confidence": 0.94,
        "reason": "首次提出“设计逻辑”概念，用120k+反向抽象出的逻辑模板控制题型与难度，是方法创新的关键词"
      },
      {
        "name": "SFT",
        "confidence": 0.9,
        "reason": "通过监督微调在Qwen3/Llama3上验证合成数据效果，证明SFT阶段即可超越官方完整后训练模型"
      },
      {
        "name": "多学科",
        "confidence": 0.88,
        "reason": "覆盖75个学科领域，强调跨学科广度与难度，标签直接体现其应用场景特色"
      }
    ],
    "tags_confirmed": true,
    "category": "数据合成",
    "summary": "利用“设计逻辑”概念，让LLM反向工程并抽象出人类出题者的命题思路，再将这些逻辑与海量原始文档匹配，自动生成跨学科、可控难度与题型的推理问答数据。"
  },
  "1c49a709-c83a-4a17-bdef-5c546b0e6aa5": {
    "id": "1c49a709-c83a-4a17-bdef-5c546b0e6aa5",
    "filename": "2404.13501v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/1c49a709-c83a-4a17-bdef-5c546b0e6aa5_2404.13501v1.pdf",
    "status": "completed",
    "created_at": "2025-12-21 20:16:49.237714",
    "updated_at": "2025-12-21 12:17:21.843986",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Abstract",
    "markdown_content": "Zeyu Zhang $^{1}$ , Xiaohe Bo $^{1}$ , Chen Ma $^{1}$ , Rui Li $^{1}$ , Xu Chen $^{1}$ , Quanyu Dai $^{2}$ , Jieming Zhu $^{2}$ , Zhenhua Dong $^{2}$ , Ji-Rong Wen $^{1}$ $^{1}$ Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China  \n $^{2}$ Huawei Noah's Ark Lab, China  \nzeyuzhang@ruc.edu.cn, xu.chen@ruc.edu.cn\n\n# Abstract\n\nLarge language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematic review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss \"what is\" and \"why do we need\" the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at https://github.com/nuster1128/LLM_Agent_Memory_Survey.\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/b45daab8d13fd79cc986247b3fc06262ffed28e4d02cbe98a1354bd006302025.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/d5e161d1193da83dfe1be348819aad6a4bdb03869f955ecd298067e1feab6c6b.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/187b77164c1a70c4ae670d8bd352361fe523314e901524b2c8efa1c45be98207.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/dc6ca064d796b8cf965620450953aef7b73d520974647c31519f759391770029.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/988fdd8ca1ad763efa9c2c7121e96d48e372dc792e1447264cdc28dca124f586.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/e058c0bfbdaa099d98aef0f5052982a79eb1e9e4a6056caad3abb3bc1c355a23.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/c9b5b5879701a03db38905d4800c4893b3f66d5d061507a4b5a8347804f83a4b.jpg)  \nFigure 1: The importance of the memory module in LLM-based agents.\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/2dfd1f6e260467d4154b9c01d85fbe0ea21bb866a7617bdf9ad57e17b529a777.jpg)\n\n# Contents\n\n# 1 Introduction 4\n\n# 2 Related Surveys 5\n\n2.1 Surveys on Large Language Models 5  \n2.2 Surveys on Large Language Model-based Agents 7\n\n# 3 What is the Memory of LLM-based Agent 7\n\n3.1 Basic Knowledge 7  \n3.2 Narrow Definition of the Agent Memory 9  \n3.3 Broad Definition of the Agent Memory 9  \n3.4 Memory-assisted Agent-Environment Interaction 9\n\n# 4 Why We Need the Memory in LLM-based Agent 10\n\n4.1 Perspective of Cognitive Psychology 10  \n4.2 Perspective of Self-Evolution 11  \n4.3 Perspective of Agent Applications 11\n\n# 5 How to Implement the Memory of LLM-based Agent 11\n\n5.1 Memory Sources 11\n\n5.1.1 Inside-trial Information 12  \n5.1.2 Cross-trial Information 13  \n5.1.3 External Knowledge 13\n\n5.2 Memory Forms 13\n\n5.2.1 Memory in Textual Form 14  \n5.2.2 Memory in Parametric Form 16  \n5.2.3 Advantages and Disadvantages of Textual and Parametric Memory 17\n\n5.3 Memory Operations 18\n\n5.3.1 Memory Writing 18  \n5.3.2 Memory Management 18  \n5.3.3 Memory Reading 19\n\n# 6 How to Evaluate the Memory in LLM-based Agent 20\n\n6.1 Direct Evaluation 20\n\n6.1.1 Subjective Evaluation 20  \n6.1.2 Objective Evaluation 21\n\n6.2 Indirect Evaluation 22\n\n6.2.1 Conversation 22  \n6.2.2 Multi-source Question-answering 22  \n6.2.3 Long-context Applications 22\n\n6.2.4 Other Tasks 23\n\n6.3 Discussions 23\n\n# 7 Memory-enhanced Agent Applications 23\n\n7.1 Role-playing and Social Simulation 23  \n7.2 Personal Assistant 25  \n7.3 Open-world Game 25  \n7.4 Code Generation 25  \n7.5 Recommendation 26  \n7.6 Expert System in Specific Domains 26  \n7.7 Other Applications 26\n\n# 8 Limitations & Future Directions 27\n\n8.1 More Advances in Parametric Memory 27  \n8.2 Memory in LLM-based Multi-agent Applications 27  \n8.3 Memory-based Lifelong Learning 28  \n8.4 Memory in Humanoid Agent 28\n\n# 9 Conclusion 28\n\n# 1 Introduction\n\n\"Without memory, there is no culture. Without memory, there would be no civilization, no society, no future.\"\n\nElie Wiesel, 1928-2016\n\nRecently, large language models (LLMs) have achieved remarkable success in a large number of domains, ranging from artificial intelligence and software engineering to education and social science [1-3]. Original LLMs usually accomplish different tasks without interacting with environments. However, to achieve the final goal of artificial general intelligence (AGI), intelligent machines should be able to improve themselves by autonomously exploring and learning from the real world. For example, if a trip-planning agent intends to book a ticket, it should send an order request to the ticket website, and observe the response before taking the next action. A personal assistant agent should adjust its behaviors according to the user's feedback, providing personalized responses to improve user's satisfaction. To further push the boundary of LLMs towards AGI, recent years have witnessed a large number of studies on LLM-based agents [3, 4], where the key is to equip LLMs with additional modules to enhance their self-evolving capability in real-world environments.\n\nAmong all the added modules, memory is a key component that differentiates the agents from original LLMs, making an agent truly an agent (see Figure 1). It plays an extremely important role in determining how the agent accumulates knowledge, processes historical experience, retrieves informative knowledge to support its actions, and so on. Around the memory module, people have devoted much effort to designing its information sources, storage forms, and operation mechanisms. For example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory module for enhancing the agent's reasoning capability. Zhong et al. [6] store memory information in the form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7] design both memory reading and writing operations to interact with environments for task solving.\n\nWhile previous studies have designed many promising memory modules, there still lacks a systemic study to view the memory modules from a holistic perspective. To bridge this gap, in this paper, we comprehensively review previous studies to present clear taxonomies and key principles for designing and evaluating the memory module. In specific, we discuss three key problems including: (1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based agents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with, we detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions. Then, we analyze the necessity of memory in LLM-based agents, showing its importance from three perspectives including cognitive psychology, self-evolution, and agent applications. Based on the problems of \"what\" and \"why\", we present commonly used strategies to design and evaluate the memory modules. For the memory design, we discuss previous works from three dimensions, that is, memory sources, memory forms, and memory operations. For the memory evaluation, we introduce two widely used approaches including direct evaluation and indirect evaluation via specific agent tasks. Next, we discuss agent applications including role-playing, social simulation, personal assistant, open-world games, code generation, recommendation, and expert systems, in order to show the importance of the memory module in practical scenarios. At last, we analyze the limitations of existing work and highlight significant future directions.\n\nThe main contributions of this paper can be summarized as follows: (1) We formally define the memory module and comprehensively analyze its necessity for LLM-based agents. (2) We systematically summarize existing studies on designing and evaluating the memory module in LLM-based agents, providing clear taxonomies and intuitive insights. (3) We present typical agent applications to show the importance of the memory module in different scenarios. (4) We analyze the key limitations of existing memory modules and show potential solutions for inspiring future studies. To our knowledge, this is the first survey on the memory mechanism of LLM-based agents.\n\nThe rest of this survey is organized as follows. First, we provide a systematical meta-survey for the fields of LLMs and LLM-based agents in Section 2, categorizing different surveys and summarizing their key contributions. Then, we discuss the problems of \"what is\", \"why do we need\" and \"how to implement and evaluate\" the memory module in LLM-based agents in Section 3 to 6. Next, we show the applications of memory-enhanced agents in Section 7. The discussions of the limitations of existing work and future directions come at last in Section 8 and Section 9.\n\n# 2 Related Surveys\n\nIn the past two years, LLMs have attracted much attention from the academic and industry communities. To systemically summarize the studies in this field, researchers have written a lot of survey papers. In this section, we briefly review these surveys (see Figure 2 for an overview), highlighting their major focuses and contributions to better position our study.\n\n# 2.1 Surveys on Large Language Models\n\nIn the field of LLMs, Zhao et al. [70] present the first comprehensive survey to summarize the background, evolution paths, model architectures, training methodologies, and evaluation strategies of LLMs. Hadi et al. [71] and Min et al. [72] also conduct LLM surveys from the holistic view, which, however, provide different taxonomies and understandings on LLMs. Following these surveys, people dive into specific aspects of LLMs and review the corresponding milestone studies and key technologies. These aspects can be classified into four categories including the fundamental problems, evaluation, applications, and challenges of LLMs.\n\nFundamental problems. The surveys in this category aim to summarize techniques that can be leveraged to tackle fundamental problems of LLMs. Specifically, Zhang et al. [8] provide a comprehensive survey on the methods of supervised fine-tuning, which is a key technique for better training LLMs. Shen et al. [9], Wang et al. [10] and Liu et al. [11] present surveys on the alignment of LLMs, which is a key requirement for LLMs to produce outputs consistent with human values. Gao et al. [12] propose a survey on the retrieval-augmented generation (RAG) capability of LLMs, which is key to providing LLMs with factual and up-to-date knowledge and removing hallucinations. Qin et al. [18] summarize the state-of-the-art methods on enabling LLMs to leverage external tools, which is fundamental for LLMs to expand their capability in domains that require specialized knowledge. Wang et al. [13], Yao et al. [14], Wang et al. [15], Feng et al. [16] and Zhang et al. [17] present surveys on the direction of LLM knowledge editing, which is important for customizing LLMs to satisfy specific requirements. Huang et al. [19], Wang et al. [20] and Pawar et al. [21] focus on long-context capabilities of LLMs, which is critical for LLMs to process more information at each time and enhance their application scenarios. Wu et al. [22], Song et al. [23], Caffagni et al. [24] and Yin et al. [25] summarize multi-modal LLMs, which expands the capability of LLMs from text to visual and other modalities. The above surveys mainly focus on the effectiveness of LLMs. Another important aspect of LLMs is their training and inference efficiency. To summarize studies on this aspect, Zhu et al. [30], Xu and McAuley [31], Wang et al. [32] and Park et al. [33] systematically review the techniques of model compression. Ding et al. [81] and Xu et al. [29] analyze and conclude the studies on parameter efficient fine-tuning. Bai et al. [26], Wan et al. [27], Miao et al. [28] and Ding et al. [81] put more focuses on the efficiency of resource utilization in a general sense.\n\nEvaluation. The surveys in this category focus on how to evaluate the capability of LLMs. Specifically, Chang et al. [34] comprehensively summarize the evaluation methods from an overall perspective. It encompasses different evaluation tasks, methods, and benchmarks, which serve as critical parts in assessing LLM performances. Guo et al. [35] care more about the evaluation targets and describe how to evaluate the knowledge, alignment, and safety control capabilities of LLMs, which supplement evaluation metrics beyond performance.\n\nApplications. The surveys in this category aim to summarize models that leverage LLMs to improve different applications. More concretely, Zhu et al. [37] focus on the field of information retrieval (IR) and summarize studies on LLM-based query processes. Xu et al. [38] pay more attention to information extraction (IE) and provide comprehensive taxonomies for LLM-based models in this field. Li et al. [50], Lin et al. [51] and Wang et al. [52] discuss the applications of LLMs in the field of recommender system, where they utilize agents to generate data and provide recommendations. Fan et al. [39], Wang et al. [40], and Zheng et al. [41] concentrate on how LLMs can benefit software engineering (SE) in terms of software design, development, and testing. Zeng et al. [42] summarize LLM-based methods in the field of robotics. Cui et al. [43] and Yang et al. [44] focus on the application of autonomous driving and summarize models in this domain based on LLMs from different perspectives. Beyond the above domains in artificial intelligence, LLMs have also been used in natural and social science. He et al. [45], Zhou et al. [46] and Wang et al. [47] summarize the applications of LLMs in medicine. Li et al. [48] focus on the applications of LLMs in finance. He et al. [49] review the models on leveraging LLMs to improve the development of psychology.\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/883c791e15a5097827c82bc2ca131ce2daf0abcaffe972bbf5a41dc7e6955c19.jpg)  \nFigure 2: The organization of related surveys on LLMs and LLM-based agents.\n\nChallenges. The surveys in this category focus on trustworthiness in LLMs, such as hallucination, bias, unfairness, explainability, security, and privacy. Hallucination in LLMs refers to the problem that LLMs may generate misconceptions or fabrications, impacting their reliability for downstream applications. Zhang et al. [53], Huang et al. [54], Rawte et al. [55], Ye et al. [56], Ji et al. [57], Tonmoy et al. [58] and Jiang et al. [59] summarize the mainstream models for alleviating the hallucination problem in LLMs. The bias and unfairness problems refer to the phenomenon that LLMs may unequally treat different humans or objectives, which can lead to the propagation of societal stereotypes and discrimination. Gallegos et al. [60], Kotek et al. [61] and Li et al. [62] comprehensively discuss these challenges and summarize existing methods for alleviating them. The problem of explainability means that the internal working mechanisms of LLMs are still unclear. Zhao et al. [63] systematically discuss this problem and summarize previous efforts on improving the explainability of LLMs. Security and privacy are also challenging problems, which have been comprehensively surveyed in Yao et al. [64], Shayegani et al. [65], Neel and Chang [66], Smith et al. [67], Dong et al. [68] and Das et al. [69].\n\n# 2.2 Surveys on Large Language Model-based Agents\n\nBased on the capability of LLMs, people have conducted a lot of studies on building LLM-based agents, which can autonomously perceive environments, take actions, accumulate knowledge, and evolve themselves. In this field, Wang et al. [3] present the first survey paper to systematically summarize LLM-based agents from the perspectives of agent construction, agent application, and agent evaluation. Xi et al. [4], Zhao et al. [77], Cheng et al. [78] and Ge et al. [80] also summarize LLM-based agent studies from the overall perspective, but they have different focuses and taxonomies, delivering more diverse understandings on this field. In addition to these overall surveys, there have also emerged several papers reviewing specific aspects of LLM-based agents. For the fundamental problems, Durante et al. [79] summarize studies on multi-modal agents. Huang et al. [74] focus on the planning capability of LLM-based agents. Guo et al. [75] pay more attention to the scenarios of multi-agent interactions. For the applications, Li et al. [76] provide a summarization on LLM-based agents that are leveraged as personal assistants.\n\nPosition of this work. Our survey summarizes the studies on a fundamental problem of LLM-based agents, that is, the agent's memory mechanism. To our knowledge, this is the first survey in this direction. We hope it can not only inspire more advanced memory architectures in the future, but also provide newcomers with comprehensive starting materials.\n\n# 3 What is the Memory of LLM-based Agent\n\nInteracting and learning from environments is a basic requirement of LLM-based agents. In the agent-environment interaction process, there are three key phases, that is, (1) the agent perceives information from the environment, and stores it into the memory; (2) the agent processes the stored information to make it more usable; and (3) the agent takes the next action based on the processed memory information. In all these phases, memory plays an extremely important role. In the following, we first define the memory of the agent from both narrow and broad perspectives, and then, detail the execution processes of the above three phases based on the memory module.\n\n# 3.1 Basic Knowledge\n\nFor clear presentations, we first introduce several important background knowledge as follows:\n\nDefinition 1 (Task). Task is the final target that the agent needs to achieve, for example, booking a flight ticket for Alice, recommending a restaurant for Bob, and so on. Formally, we use  $\\mathcal{T}$  to represent a task and label different tasks by subscripts in the following contents.\n\nDefinition 2 (Environment). In a narrow sense, environment is the object that the agent needs to interact with to accomplish the task. For the examples in definition 1, the environments are Alice and Bob, who provide feedback on the agent's actions. More broadly, environment can be any contextual factors that influence the agent's decisions, such as the weather when booking flight tickets, the time and location when recommending restaurants, etc.\n\nDefinition 3 (Trial and Step). To accomplish a task, the agent needs to interact with the environment. Usually, the agent first takes an action, and then the environment responds to this action. At last, the agent takes the next action based on the response. This process iterates until the task is finished. The complete agent-environment interaction process is called a trial, and each interaction turn is called a\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/5ba697e4fc20842efed37cd6ba4d6839b9c10ae4c5b0b7e48666107026f8b411.jpg)  \nTask A: Making a trip plan for Alice in Beijing  \nFigure 3: (a) Examples of the potential trials in the agent-environment interaction process. (b) Illustration of the memory reading, writing, and management processes, where dotted lines mean that the cross-trial information can be incorporated into the memory module.\n\nstep. For each trial, the agent can take multiple steps to form a potential solution to the task. For each task, the agent can explore multiple trials to accomplish the task [5]. Formally, at step  $t$ , we use  $a_{t}$  and  $o_{t}$  to represent the agent action and the observed environment response, respectively. Then, a  $T$ -length trial can be represented as  $\\xi_{T} = \\{a_{1}, o_{1}, a_{2}, o_{2}, \\dots, o_{T}, a_{T}\\}$ .\n\nIn the above definitions, task and environment are the most coarse-grained concepts, while step is the most fine-grained one. They together describe the complete agent-environment interaction process.\n\nA Toy Example. Based on the above definitions, we show a toy example and use it throughout the paper to provide more intuitions. In this example, the agent has two tasks: (A) Making a trip plan for Alice in Beijing from 5/1/2024 to 5/3/2024, where the agent has to (i) buy a round-trip flight ticket, (ii) determine several attractions according to Alice's preferences, and (iii) arrange the visiting order of these attractions. (B) Recommending a movie for Alice on 5/10/2024, where the agent has to (i) determine the time that Alice is free to watch movies, and (ii) select a movie according to Alice's watching preference. For each task, we present a potential trial in the following (also illustrated in Figure 3(a)). For task (A), the trial is:\n\n[Step 1] Agent: I need to book flight tickets from Shanghai to Beijing on 5/1/2024, and from Beijing to Shanghai on 5/3/2024 through the online ticket office. Environment (Online Ticket Office): The order has been confirmed. The departure flight takes off at 9:00 AM, and your ticket number is EK240501SX9021. The returning flight takes off at 4:30 PM, and your ticket number is LG240503FN6317. Please arrive at the airport on time for your flight.  \n[Step 2] Agent: I have acquired external knowledge from the magazine Attractions in Beijing. It shows that the Great Wall, the Forbidden City and the Summer Palace are famous. According to Alice's preferences, I think she prefers ancient architecture, so I determine the Forbidden City and the Summer Palace as the destinations. Environment (Alice): Well done!  \n[Step 3] Agent: Now, I need to arrange the visiting order for Alice. According to the information above, I recommend visiting the Summer Palace after she arrives in Beijing because it is suitable to spend a whole afternoon there and watch the sunset. Then, she can go to the Forbidden City the next day, which would give her plenty of time. Finally, she can return to Shanghai on the third day and take a rest. Environment (Alice): I love this plan. Thanks!\n\nFor task (B), the trial is:\n\n[Step 1] Agent: According to my previous experiences of movie recommendations for Alice, she prefers to start watching movies at 9:00 PM, because she has finished work by then. I should ask Alice if she is available at that time. Environment (Alice): Of course, it is a nice time!\n\n[Step 2] Agent: Now, I need to find some movies that Alice has marked \"want to watch\" on Netflix. Environment (Netflix): Alice's want to watch: Interstellar, Planet Terror and Candle in the Tomb.\n\n[Step 3] Agent: Since Alice never watches horror movies at night, Interstellar would be more suitable for her. Now, I need to confirm with Alice about the movie. Environment (Alice): Great! I like it!\n\n# 3.2 Narrow Definition of the Agent Memory\n\nIn a narrow sense, the memory of the agent is only relevant to the historical information within the same trial. Formally, for a given task, the historical information of the trial before step  $t$  is  $\\xi_{t} = \\{a_{1}, o_{1}, a_{2}, o_{2}, \\dots, a_{t-1}, o_{t-1}\\}$ , and then the memory is derived based on  $\\xi_{t}$ . In the above toy example, for task (A), the agent at [step 3] needs to arrange the visiting order for Alice; at this time, its memory contains the information about the selected attractions and arrival time in [step 1] and [step 2]. For task (B), the agent has to choose a movie for Alice at [step 3]; at this time, its memory contains the arranged time to watch films.\n\n# 3.3 Broad Definition of the Agent Memory\n\nIn a broad sense, the memory of the agent can come from much wider sources, for example, the information across different trials and the external knowledge beyond the agent-environment interactions. Formally, given a series of sequential tasks  $\\{\\mathcal{T}_1,\\mathcal{T}_2,\\dots,\\mathcal{T}_K\\}$ , for task  $\\mathcal{T}_k$ , the memory information at step  $t$  comes from three sources: (1) the historical information within the same trial, that is,  $\\xi_t^k = \\{a_1^k,o_1^k,\\ldots ,a_{t - 1}^k,o_{t - 1}^k\\}$ , where we add superscript  $k$  to label the task index. (2) The historical information across different trials, that is,  $\\Xi^k = \\{\\xi^1,\\xi^2,\\dots,\\xi^{k - 1},\\xi^{k'}\\}$ , where  $\\xi^j$  ( $j\\in \\{1,\\dots,k - 1\\}$ ) represents the trials of task  $j^1$ , and  $\\xi^{k'}$  denotes the previously explored trials for task  $\\mathcal{T}_k$ . (3) External knowledge, which is represented by  $D_t^k$ . The memory of the agent is derived based on  $(\\xi_t^k,\\Xi^k,D_t^k)$ . In the above toy example, for task (A), if there are several failed trials, that is, the feedback from Alice is negative, then these trials can be incorporated into the agent's memory to avoid future similar errors (corresponding to  $\\xi^{k'}$ ). In addition, for task (B), the agent may recommend movies relevant to the attractions that Alice has visited in task (A) to capture her recent preferences (corresponding to  $\\{\\xi^1,\\xi^2,\\dots,\\xi^{k - 1}\\}$ ). In the agent decision process, it has also referred to the magazine Attractions in Beijing for making trip plans, which is the external knowledge (corresponding to  $D_t^k$ ) for the current task  $\\mathcal{T}_k$ .\n\n# 3.4 Memory-assisted Agent-Environment Interaction\n\nAs mentioned at the beginning of Section 3, there are three key phases in the agent-environment interaction process. The agent memory module implements these phases through three operations including memory writing, memory management, and memory reading.\n\nMemory Writing. This operation aims to project the raw observations into the actually stored memory contents, which are more informative [7] and concise [6]. It corresponds to the first phase of the agent-environment interaction process. Given a task  $\\mathcal{T}_k$ , if the agent takes an action  $a_{t}^{k}$  at step  $t$ , and the environment provides an observation  $o_t^k$ , then the memory writing operation can be formally represented as:\n\n$$\nm _ {t} ^ {k} = W (\\{a _ {t} ^ {k}, o _ {t} ^ {k} \\}),\n$$\n\nwhere  $W$  is a projecting function.  $m_t^k$  is the finally stored memory contents, which can be either natural languages or parametric representations. In the above toy example, for task (A), the agent is supposed to remember the flight arrangement and the decision of attractions after [step 2]. For task (B), the agent should memorize the fact that Alice hopes to watch movies at 9:00 PM, after [step 1].\n\nMemory Management. This operation aims to process the stored memory information to make it more effective, for example, summarizing high-level concepts to make the agent more general-\n\nizable [6], merging similar information to reduce redundancy [7], and forgetting unimportant or irrelevant information to remove its negative influence. This operation corresponds to the second phase of the agent-environment interaction process. Let  $M_{t-1}^{k}$  be the memory contents for task  $k$  before step  $t$ , and suppose  $m_{t}^{k}$  is the stored information at step  $t$  based on the above memory writing operation, then, the memory management operation can be represented by:\n\n$$\nM _ {t} ^ {k} = P (M _ {t - 1} ^ {k}, m _ {t} ^ {k}),\n$$\n\nwhere  $P$  is a function that iteratively processes the stored memory information. For the narrow memory definition, the iteration only happens within the same trial, and the memory is emptied when the trial is ended. For the broad memory definition, the iteration happens across different trials or even tasks, as well as the integrations of external knowledge. For task (B) in the above toy example, the agent can conclude that Alice enjoys watching science fiction movies in the evening, which can be used as a default rule to make recommendations for Alice in the future.\n\nMemory Reading. This operation aims to obtain important information from the memory to support the next agent action. It corresponds to the third phase of the agent-environment interaction process. Suppose  $M_t^k$  is the memory contents for task  $k$  at step  $t$ ,  $c_t^k$  is the context of the next action, then the memory reading operation can be represented by:\n\n$$\n\\hat {M} _ {t} ^ {k} = R (M _ {t} ^ {k}, c _ {t + 1} ^ {k}),\n$$\n\nwhere  $R$  is usually implemented by computing the similarity between  $M_t^k$  and  $c_{t+1}^k$  [82].  $\\hat{M}_t^k$  is used as parts of the final prompt to drive the agent's next action. For task (B) in the above toy example, when the agent decides on the final recommended movie in [Step 3], it should focus on the \"want to watch\" list in [Step 2] and select one from it.\n\nBased on the above operations, we can derive a unified function for the evolving process from  $\\{a_t^k,o_t^k\\}$  to  $a_{t + 1}^{k}$ , that is:\n\n$$\na _ {t + 1} ^ {k} = \\operatorname {L L M} \\{R (P (M _ {t - 1} ^ {k}, W (\\{a _ {t} ^ {k}, o _ {t} ^ {k} \\})), c _ {t + 1} ^ {k}) \\},\n$$\n\nwhere LLM is the large language model. The complete agent-environment interaction process can be easily obtained by iteratively expanding this function (see Figure 3(b) for an intuitive illustration). Remark. This function provides a general formulation of the agent memorizing process. Previous works may use different specifications. For example, in [5],  $R$  and  $P$  are set as identical functions, and  $P$  only takes effect at the end of a trial. In Park et al. [83],  $R$  is implemented based on three criteria including similarity, time interval, and importance, and  $P$  is realized by a reflection process to obtain more abstract thoughts. In this section, we focus on the overall framework of the agent's memory operations. More detailed realizations of  $W$ ,  $P$ , and  $R$  are deferred in Section 5.\n\n# 4 Why We Need the Memory in LLM-based Agent\n\nAbove, we have introduced what is the memory of LLM-based agents. Before comprehensively presenting how to implement it, in this section, we briefly show why memory is necessary for building LLM-based agents, where we expand our discussion from three perspectives including cognitive psychology, self-evolution, and agent applications.\n\n# 4.1 Perspective of Cognitive Psychology\n\nCognitive psychology is the scientific study of human mental processes such as attention, language use, memory, perception, problem-solving, creativity, and reasoning<sup>2</sup>. Among these processes, memory is widely recognized as an extremely important one [84]. It is fundamental for humans to learn knowledge by accumulating important information and abstracting high-level concepts [85], form social norms by remembering cultural values and individual experiences [86], take reasonable behaviors by imagining the potential positive and negative consequences [87], and among others.\n\nA major goal of LLM-based agents is to replace humans for accomplishing different tasks. To make agents behave like humans, following human's working mechanisms to design the agents is a natural and essential choice [88]. Since memory is important for humans, designing memory modules is also significant for the agents. In addition, cognitive psychology has been studied for a long time, so many effective human memory theories and architectures have been accumulated, which can support more advanced capabilities of the agents [89].\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/6c73759e440abf0e1d672cbdfc6fdd19f9bfe9401c40b829f60bff6d9b691814.jpg)  \nFigure 4: An overview of the sources, forms, and operations of the memory in LLM-based agents.\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/cb56e8954692e99fe487df02322be080432ee13fe887e54815071c983b4b29ce.jpg)\n\n# 4.2 Perspective of Self-Evolution\n\nTo accomplish different practical tasks, agents have to self-evolve in dynamic environments [90]. In the agent-environment interaction process, the memory is key to the following aspects: (1) Experience accumulation. An important function of the memory is to remember past error plannings, inappropriate behaviors, or failed experiences, so as to make the agent more effective for handling similar tasks in the future [91]. This is extremely important for enhancing the learning efficiency of the agent in the self-evolving process. (2) Environment exploration. To autonomously evolve in the environment, the agents have to explore different actions and learn from the feedback [92]. By remembering historical information, the memory can help to better decide when and how to make explorations, for example, focusing more on previously failed trials or actions with lower exploring frequencies [93]. (3) Knowledge abstraction. Another important function of the memory is to summarize and abstract high-level information from raw observations, which is the basis for the agent to be more adaptive and generalizable to unseen environments [82]. In summary, self-evolution is the basic characteristic of LLM-based agents, and memory is of key importance to self-evolution.\n\n# 4.3 Perspective of Agent Applications\n\nIn many applications, memory is an indispensable component of the agent. For example, in a conversational agent, the memory stores information about historical conversations, which is necessary for the agent to generate the next response. Without memory, the agent does not know the context, and cannot continue the conversation [94]. In a simulation agent, memory is of great importance to make the agent consistently follow the role profiles. Without memory, the agent may easily step out of the role during the simulation process [95]. Both of the above examples show that the memory is not an optional component, but is necessary for the agents to accomplish given tasks.\n\nIn the above three perspectives, the first one reveals that the memory builds the cognitive basis of the agent. The second and third ones show that the memory is necessary for the agent's evolving principles and applications, which provide insights for designing agents with memory mechanisms.\n\n# 5 How to Implement the Memory of LLM-based Agent\n\nIn this section, we discuss the implementation of the memory module from three perspectives: memory sources, memory forms, and memory operations. Memory sources refer to where the memory contents come from. Memory forms focus on how to represent the memory contents. Memory operations aim to process the memory contents. These three perspectives provide a comprehensive review of memory implementation methods, which is helpful for future research. For better demonstration, we present an overview of implementation methods in Figure 4.\n\n# 5.1 Memory Sources\n\nIn previous works, the memory contents may come from different sources. Based on our formulation in Section 3, these sources can be classified into three categories, that is, the information inside a trial, the information across different trials, and the external knowledge. The former two are dynamically\n\nTable 1: Summarization of the memory sources. We use  $\\checkmark$  and  $\\times$  to label whether or not the corresponding source is adopted in the model.  \n\n<table><tr><td>Models</td><td>Inside-trial Information</td><td>Cross-trial Information</td><td>External Knowledge</td></tr><tr><td>MemoryBank [6]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>RET-LLM [7]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>ChatDB [96]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>TiM [97]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>SCM [98]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Voyager [99]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MemGPT [100]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MemoChat [94]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MPC [101]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Generative Agents [83]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>RecMind [102]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>Retroformer [103]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>ExpeL [82]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Synapse [91]</td><td>✓</td><td>✓</td><td>×</td></tr><tr><td>GITM [93]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>ReAct [104]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>Reflexion [5]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RecAgent [95]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Character-LLM [105]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MAC [106]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Huatuo [107]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>ChatDev [1]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>InteRecAgent [108]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaAgents [109]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>TPTU [110, 111]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaGPT [112]</td><td>✓</td><td>✓</td><td>×</td></tr><tr><td>S3[2]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>InvestLM [113]</td><td>✓</td><td>×</td><td>✓</td></tr></table>\n\ngenerated in the agent-environment interaction process (e.g., task internal information), while the latter is static information outside the loop (e.g., task external information). We summarize previous works on memory sources in Table 1.\n\n# 5.1.1 Inside-trial Information\n\nIn the agent-environment interaction process, the historical steps within a trial are usually the most relevant and informative signals to support the agent's future actions. Almost all the previous works use this information as a part of the memory sources.\n\nRepresentative Studies. Generative Agents [83] aims to simulate human's daily behaviors by using LLM-based agents. The memory of an agent is derived from the historical behaviors to achieve a target, for example, the collection of relevant papers when researching on a specific topic. MemoChat [94] aims to chat with humans, where the memory of the agent is derived based on the conversation history of a dialogue session. TiM [97] aims to enhance the agent's reasoning capability by self-generating multiple thoughts after accomplishing a task, which is used as the memory to provide more generalizable information. Voyager [99] focuses on building game agents based on Minecraft, where the memory contains executable codes of preliminary and basic actions to accomplish a task. It should be noted that the inside-trial information not only includes agent-environment interactions, but also contains interaction contexts, such as time and location information.\n\nDiscussion. The inside-trial information is the most obvious and intuitive source that should be leveraged to construct the agent's memory since it is highly relevant to the current task that the agent has to accomplish. However, relying solely on inside-trial information may prevent the agent from accumulating valuable knowledge from various tasks and learning more generalizable information. Thus, many studies also explore how to effectively utilize the information across different tasks to build the memory module, which is detailed in the following sections.\n\n# 5.1.2 Cross-trial Information\n\nFor LLM-based agents, the information accumulated across multiple trials in the environment is also a crucial part of the memory, typically including successful and failed actions and their insights, such as failure reasons, common action patterns to succeed, and so on.\n\nRepresentative Studies. One of the most prominent studies is Reflexion [5], which proposes verbal reinforcement learning for LLM-based agents. It derives the experiences from past trials in verbal form, and applies them in subsequent trials to improve the performance of the same task. Furthermore, Retroformer [103] fine-tunes the reflection model, enabling the agent to extract cross-trial information from past trials more effectively. In Synapse [91], the agents focus on solving the computer control tasks. Their memory can record cross-trial information through successful exemplars, which would be used as references on similar trials. In ExpeL [82], the agents are required to solve a collection of complex interactive tasks within the environment. They store and organize completed trajectories, and recall similar ones for the new task. In the recalled trajectories, successful cases will be compared with failed ones to identify the patterns to succeed.\n\nDiscussion. According to the accumulated memory of cross-trial information, the agents are able to accumulate experiences, which is important for their evolution. Based on the past experiences, the agents can adjust their actions based on the overall feedback of the whole process. In contrast to the inside-trial observations, which serve as short-term memory, the trial experiences can be considered as long-term memory. It utilizes feedback from different trials to support a wider range of agent trials, providing more prolonged experiential support for agents. However, the limitation lies in the fact that both inside-trial and cross-trial information require the agents to personally engage in agent-environment interactions, where external experiences and knowledge are not included.\n\n# 5.1.3 External Knowledge\n\nAn important characteristic of LLM-based agents is that they can be directly communicated and controlled in natural languages. As such, LLM-based agents can easily incorporate external knowledge in textual forms (e.g., Wikipedia<sup>3</sup>) to facilitate their decisions.\n\nRepresentative Studies. In ReAct [104], the agents are required to answer questions about general knowledge by multiple reasoning steps. They can utilize Wikipedia APIs to obtain external knowledge if they lack information during these steps. GITM [93] intends to design agents in Minecraft, which can explore in complex and sparse-reward environments. The agents draw from the online Minecraft Wiki and craft recipes to provide an infinite source of knowledge for their navigation. CodeAgent [114] focuses on the repo-level code generation task, which commonly requires complex dependencies and extensive documentation. It designs a web search strategy for acquiring related external knowledge. ChatDoctor [115] adapts LLM-based agents to the medical domain. It fine-tunes an acquisition process to retrieve external knowledge from Wikipedia and medical databases.\n\nDiscussion. The external knowledge can be obtained from both private and public sources. It provides LLM-based agents with much knowledge beyond their internal environment, which might be difficult or even impossible for the agent to acquire by agent-environment interactions. Moreover, most external knowledge can be acquired by accessing the APIs of various tools dynamically in real time according to the task needs, thus mitigating the problem of outdated knowledge. Integrating external knowledge into the memory of LLM-based agents significantly expands their knowledge boundaries, providing them with unlimited, up-to-date, and well-founded knowledge for decision-making.\n\n# 5.2 Memory Forms\n\nIn general, there are two forms to represent the memory contents: textual form and parametric form. In textual form, the information is explicitly retained and recalled by natural languages. In parametric\n\nTable 2: Summarization of the memory forms. We use  $\\checkmark$  and  $\\times$  to label whether or not the corresponding memory form is adopted in the model.  \n\n<table><tr><td rowspan=\"2\">Models</td><td colspan=\"4\">Textual Form</td><td colspan=\"2\">Parametric Form</td></tr><tr><td>Complete</td><td>Recent</td><td>Retrieved</td><td>External</td><td>Fine-tuning</td><td>Editing</td></tr><tr><td>MemoryBank [6]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>RET-LLM [7]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>ChatDB [96]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>TiM [97]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>SCM [98]</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Voyager [99]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>MemGPT [100]</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>MemoChat [94]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>MPC [101]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Generative Agents [83]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>RecMind [102]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Retroformer [103]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>✓</td><td>×</td></tr><tr><td>ExpeL [82]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Synapse [91]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>GITM [93]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>ReAct [104]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Reflexion [5]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>RecAgent [95]</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Character-LLM [105]</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td></tr><tr><td>MAC [106]</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Huatuo [107]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td><td>×</td></tr><tr><td>ChatDev [1]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td></tr><tr><td>InteRecAgent [108]</td><td>×</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MetaAgents [109]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>TPTU [110, 111]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MetaGPT [112]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td></tr><tr><td>S3[2]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>InvestLM [113]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td><td>×</td></tr></table>\n\nform, the memory information is encoded into parameters and implicitly influences the agent's actions. We summarize previous works on memory forms with their implementations in Table 2.\n\n# 5.2.1 Memory in Textual Form\n\nTextual form is currently the mainstream method to represent the memory contents, which is featured in better interpretability, easier implementation, and faster read-write efficiency. In specific, the textual form can be both non-structured representations like raw natural languages and structured information such as tuples, databases, and so on. In general, previous studies use the textual form memory to store four types of information including (1) complete agent-environment interactions, (2) recent agent-environment interactions, (3) retrieved agent-environment interactions, and (4) external knowledge. In the former three methods, the memory leverages natural languages to describe the information within the agent-environment interaction loop. In the former three types, they record the information inside the agent-environment interaction loop, while the last type leverages natural languages to store information outside that loop.\n\nComplete Interactions. This method stores all the information of the agent-environment interaction history based on long-context strategies [116]. For the example in Section 3.1, the memory of the\n\nagent in task (A) after step 2 can be implemented by concatenating all the information before step 2, and the final textual form memory is: \"Your memory is [Step 1] (Agent) ... (Online Ticket Office) ... [Step 2] ... Please infer based on your memory\".\n\nIn the previous work, different models store the memory information using different strategies. For example, in LongChat [116], the agents focus on understanding natural languages in long-context scenarios. It fine-tunes the foundation model for better adapting to memorize complete interactions. Memory Sandbox [117] intends to alleviate the impact of irrelevant memory in conversations. It designs a transparent and interactive method to manage the memory of agents, which removes irrelevant memory before concatenating them as a prompt. Moreover, some efforts are dedicated to enhancing the capacity of LLMs to handle longer contexts [118, 119].\n\nWhile storing all the agent-environment interactions can maintain comprehensive information, obvious limitations exist in terms of computational cost, inference time, and inference robustness. Firstly, the fast-growing long-context memory in practice results in high computational cost during LLM inference, due to the quadratic growth of the time complexity of attention computation with sequence length. It thus requires much more computing resources and significantly increases inference latency, which hinders its practical deployment. What's more, with its fast growth, the memory length can easily exceed the upper bound of the sequence length during LLM's pretraining, which makes a truncation of memory necessary. Thus, it can lead to information loss due to the incompleteness of agent memory. Last but not least, it can lead to biases and unrobustness in LLM's inference. Specifically, a previous research [120] has shown that, the positions of text segments in a long context can greatly affect their utilization, so the memory in the long-context prompt can not be treated equally and stably. All these drawbacks show the need to design extra memory modules for LLM-based agents, rather than straightforwardly concatenating all the information into a prompt.\n\nRecent Interactions. This method stores and maintains the most recently acquired memories using natural languages, thereby enhancing the efficiency of memory information utilization according to the Principle of Locality [121]. In task (B) of the example in Section 3.1, we can just remember Alice's preferences in the recent three years, and truncate the distant part, where the recent three years can be considered as the memory window size.\n\nIn previous studies, there are various strategies to store recent textual memories. For example, SCM [98] proposes a flash memory based on the cache mechanism, which preserves observations from the recent  $t - 1$  time steps, aimed at enhancing the recency of information. MemGPT [100] considers the agent as an operating system, which can dynamically interact with users through a natural interface. It designs the working context to hold recent histories, as a part of virtual context management. In RecAgent [95], the agents are designed to simulate user behaviors in movie recommendations. It stores some temporal information in short-term memory as an intermediate cache, which can simulate the memory mechanism of the human brain [122, 123]. These representative methods can dynamically update memories based on recent interactions, and pay more attention to the recent context that is important for the current stage.\n\nCaching the memory according to recency is an effective way to enhance memory efficiency, and it enables agents to focus more on the recent information. However, in long-term tasks, this method fails to access key information from distant memories. It can result in the loss of potentially crucial information that is not within the immediate cache window. In other words, emphasizing on recency can inherently neglect earlier, yet critical information, thus posing challenges in scenarios requiring a comprehensive understanding of past events.\n\nRetrieved Interactions. Unlike the above method which truncates memories based on time, this method typically selects memory contents based on their relevance, importance, and topics. It ensures the inclusion of distant but crucial memories in the decision-making process, thereby addressing the limitation of only memorizing recent information. In task (A) of the example in Section 3.1, Alice's preferences have been stored in the memory before this task. At [Step 2], the agent will retrieve the most relevant aspects of Alice's preferences from memory based on the query keyword \"travel\", obtaining Alice's scenic spot preference for ancient architectures. In general, retrieval methods will generate embeddings as indexes for memory entries during memory writing, along with recording auxiliary information to assist in retrieval. During memory reading, matching scores are calculated for each memory entry, and the top- $K$  entries will be used for the decision-making process of agents.\n\nIn existing studies, most agents utilize retrieval methods to process the memory information. For example, Park et al. [83] first calculate the relevance between the current context and memory entries by cosine similarity, and obtain the importance and recency according to auxiliary information. MemoryBank [6] employs a dual-tower dense retrieval model to find related information from past conversations. Each memory entry is encoded into an embedding and subsequently indexed by FAISS [124] to improve the efficiency of retrieval. When reading memories, the current context will be encoded as representations to obtain the most relevant memory. Moreover, RET-LLM [7] intends to design a write-read memory module for general usage. It utilizes Locality-Sensitive Hashing (LSH) to retrieve tuples with relative entries in the database to provide more information. In addition, ChatDB [96] designs to utilize symbolic memory, and proposes to generate SQL statements to retrieve from database to obtain stored information.\n\nThe retrieval methods considerably depend on the accuracy and efficiency of obtaining expected information. An inaccurate retrieval strategy can potentially acquire unrelated information that is unhelpful for agent inference. And a heavy retrieval system can lead to large computational costs and long time latency, especially when handling massive information. Moreover, retrieval methods typically store homogeneous information inside the environment, where all the information is in a consistent form. For heterogeneous information outside the environment, it's difficult to directly apply the same method for memory storage.\n\nExternal Knowledge. To obtain more information, some agents acquire external knowledge by invoking tools, with the aim of transforming additional relevant knowledge into their own memories for decision-making. For instance, accessing external knowledge through Application Programming Interface (API) is a common practice [104, 5]. Nowadays, abundant public information, such as Wikipedia and OpenWeatherMap<sup>4</sup>, are available online (either free of charge or on a paying basis), and can be conveniently accessed through API calls. For instance, in [Step 2] of task (A) of the example in Section 3.1, external knowledge from the digital magazine is obtained with tool methods.\n\nIn existing models, Toolformer [125] proposes to teach LLM to use tools, which can acquire external knowledge for better solving tasks. Furthermore, ToolLLM [126] empowers Llama [127] with the ability to utilize more APIs in RapidAPI<sup>5</sup> and to enable multi-tool usage, which provides a general interface to extend agents' ability. In TPTU [110], the agents are incorporated in both task planning and tool usage, in order to tackle intricate problems. The follow-up work [111] further improves its ability extensively like retrieval. In ToRA [128], the agents are required to solve mathematical problems. They utilize imitation learning to improve their ability to use program-based tools.\n\nThe above methods significantly advance the capabilities of agents by allowing them to access external up-to-date and real-world information from diverse sources. However, the reliability of this information can be questionable due to potential inaccuracies and biases [18]. Furthermore, the integration of tools into agents demands a comprehensive understanding to interpret the retrieved information across various contexts, which can incur higher computational costs and complications in aligning external data with internal decision-making processes. Additionally, utilizing external APIs brings forth concerns regarding privacy, data security, and compliance with usage policies, necessitating rigorous management and oversight [18].\n\n# 5.2.2 Memory in Parametric Form\n\nAn alternative type of approaches is to represent memory in parametric form. They do not take up the extra length of context in prompts, so they are not constrained by the length limitations of LLM context. However, the parametric memory form is still under-researched, and we categorize previous works into two types: fine-tuning methods and memory editing methods.\n\nFine-tuning Methods. Integrating external knowledge into the memory of agents is beneficial for enriching domain-specific knowledge on top of its general knowledge. To infuse the domain knowledge into LLMs, supervised fine-tuning is a common approach, which empowers agents with the memory of domain experts. It significantly improves the agent's ability to accomplish domain-specific tasks. In task (A) of the example in Section 3.1, the external knowledge of attractions from magazines can be fine-tuned into the parameters of LLMs prior to this task.\n\nIn previous works, Character-LLM [105] focuses on the role-play circumstance. It utilizes supervised fine-tuning strategies with role-related data (e.g., experiences), to endow agents with the specific traits and characteristics of the role. Huatuo [107] intends to empower agents with professional ability in the biomedical domain. It tries to fine-tune Llama [127] on Chinese medical knowledge bases. Besides, in order to create artificial doctors, DoctorGLM [129] fine-tunes ChatGLM [130] with LoRA [131], and Radiology-GPT [132] improves domain knowledge on radiology analysis by supervised fine-tuning on an annotated radiology dataset. Moreover, InvestLM [113] collects investment data and fine-tunes it to improve domain-specific abilities on financial investment.\n\nThe fine-tuning methods can effectively bridge the gap between general agents and specialized agents. It improves the capability of agents on the tasks that require high accuracy and reliability on domain-specific information. Nevertheless, fine-tuning LLMs for specific domains could potentially lead to overfitting, and it also raises concerns about catastrophic forgetting, where LLMs may forget the original knowledge because of updating their parameters. Another limitation of fine-tuning lies in the computational cost and time consumption, as well as the requirement of a large amount of data. Therefore, most fine-tuning approaches are applied to offline scenarios, and can seldom deal with online scenarios, such as fine-tuning with agent observations and trial experiences. Due to the frequent agent-environment interactions, it is unaffordable for the cost of backpropagation to fine-tune every step of the online and dynamic interactions.\n\nMemory Editing Methods. Apart from the fine-tuning approaches, another type of methods for infusing memory into model parameters is knowledge editing [133, 134]. Unlike fine-tuning methods that extract patterns from certain datasets, knowledge editing methods specifically target and adjust only the facts that need to be changed. It ensures that unrelated knowledge remains unaffected. Knowledge editing methods are more suitable for small-scale memory adjustments. Generally, they have lower computational costs, making them more suitable for online scenarios. In our example of task (B), Alice always watches movies at  $9:00\\mathrm{PM}$  from the agent's memory, but she may recently change her work and would not be empty at  $9:00\\mathrm{PM}$ . If so, the related memory (such as routines at  $9:00\\mathrm{PM}$ ) should be edited, which can be implemented by knowledge editing methods.\n\nIn previous studies, MAC [106] intends to design an effective and efficient memory adaptation framework for online scenarios. It utilizes meta-learning to substitute the optimization step. PersonalityEdit [135] focuses on editing the personality of LLMs and agents, where it changes their traits based on theories such as the big-five factor. MEND [134] utilizes the idea of meta-learning to train a lightweight model, which is capable of generating modifications for model parameters of a pre-trained language model. APP [136] studies whether adding a new fact leads to catastrophic forgetting of existing facts. It focuses on the impact of neighbor perturbation on memory addition. Moreover, KnowledgeEditor [133] trains a hyper-network to predict the modification of model parameters when injecting memory based on a learning-to-update problem formulation. Wang et al. [137] propose a new optimization target to change the poisoning knowledge of LLM, and maintain the general performance at the same time. For LLM-based agents, the agents can change bad memory by knowledge editing, which can be considered as a type of forgetting mechanism.\n\nKnowledge editing methods provide an innovative way to update the information stored within the parameters of LLMs. By specifically targeting and adjusting the facts, these methods can ensure the non-targeted knowledge unaffected during updates, thus mitigating the issue of catastrophic forgetting. Moreover, the targeted adjustment mechanism allows for more efficient and less resource-intensive updates, making knowledge editing an appealing choice for high-precision and real-time modifications. However, despite these promising developments, computational costs of meta-training and the preservation of unrelated memories remain significant challenges.\n\n# 5.2.3 Advantages and Disadvantages of Textual and Parametric Memory\n\nTextual memory and parametric memory have their strengths and weaknesses respectively, making them suitable for different memory contents and application scenarios. In this section, we discuss the advantages and disadvantages of these two forms of memory from various aspects.\n\nEffectiveness. The textual memory stores raw information about the agent-environment interactions, which is more comprehensive and detailed. However, it is constrained by the token limitation of LLM prompts, which makes the agent hard to store extensive information. In contrast, the parametric memory is not limited by the prompt length, but it may suffer from information loss when transforming texts into parameters, and the complex memory training can bring additional challenges.\n\nEfficiency. For textual memory, each LLM inference requires to integrate memory into the context prompt, which leads to higher costs and longer processing times. In contrast, for parametric memory, the information can be integrated into the parameters of the LLM, eliminating the extra costs of these contexts. However, parametric memory takes additional costs in the writing process, but textual memory is easier to write, especially for small amounts of data. In a nutshell, textual memory is more efficient in writing, while parametric memory is more efficient in reading.\n\nInterpretability. Textual memory is usually more explainable than the parametric one, since natural languages are the most natural and straightforward strategies for humans to understand, while parametric memory is commonly represented in latent space. Nevertheless, such explainability is obtained at the cost of information density. This is because the sequences of words in textual memory are represented in a discrete space, which is not as dense as continuous space in parametric memory.\n\nIn conclusion, the trade-offs between these two types of memories make them suitable for different applications. For example, for the tasks that require recalling recent interactions, like conversational and context-specific tasks, textual memory seems more effective. For the tasks that require a large amount of memory, or well-established knowledge, parametric memory can be a better choice.\n\n# 5.3 Memory Operations\n\nWe separate the entire procedure of memory into three operations: memory writing, memory management, and memory reading. These three typically collaborate to achieve memory function, providing information for LLM inference. We summarize previous works on memory operations in Table 3.\n\n# 5.3.1 Memory Writing\n\nAfter the information is perceived by the agent, a part of it will be stored by the agent for further usage through the memory writing operation, and it is crucial to recognize which information is essential to store. Many studies choose to store the raw information, while others also put the summary of the raw information into the memory module.\n\nRepresentative Studies. In TiM [97], the raw information will be extracted as the relation between two entities, and stored in a structured database. When writing into the database, similar contents will be stored in the same group. In SCM [98], it designs a memory controller to decide when to execute the operations. The controller serves as a guide for the whole memory module. In MemGPT [100], the memory writing is entirely self-directed. The agents can autonomously update the memory based on the contexts. In MemoChat [94], the agents summarize each conversation segment by abstracting the mainly discussed topics and storing them as keys for indexing memory pieces.\n\nDiscussion. Previous research indicates that designing the strategy of information extraction during the memory writing operation is vital [94]. This is because the original information is commonly lengthy and noisy. Besides, different environments may provide various forms of feedback, and how to extract and represent the information as memory is also significant for memory writing.\n\n# 5.3.2 Memory Management\n\nFor human beings, memory information is constantly processed and abstracted in the brains. The memory in the agent can also be managed by reflecting to generate higher-level memories, merging redundant memory entries, and forgetting unimportant, early memories.\n\nRepresentative Studies. In MemoryBank [6], the agents process and distill the conversations into a high-level summary of daily events, similar to how humans recall key aspects of their experiences. Through long-term interactions, they continually evaluate and refine their knowledge, generating daily insights into personality traits. In Voyager [99], the agents are able to refine their memory based on the feedback of the environment. In Generative Agents [83], the agents can reflect to get higher-level information, where the abstract thoughts are generated from agents. The reflection process will be activated when there are accumulated events that are enough to address. For GITM [93], in order to establish common reference plans for various situations, key actions from multiple plans are further summarized in the memory module.\n\nDiscussion. Most of the memory management operations are inspired by the working mechanism of human brains. With the strong capability of LLMs to simulate human minds, these operations can help the agents to better generate high-level information and interact with environments.\n\nTable 3: Summarization of the memory operations. If a model does not have special designs on the memory operations, we use  $\\circ$  to label it, otherwise, it is denoted by  $\\checkmark$ .  $\\times$  means that the memory operations are not discussed in the paper.  \n\n<table><tr><td rowspan=\"2\">Models</td><td rowspan=\"2\">Writing</td><td colspan=\"3\">Management</td><td rowspan=\"2\">Reading</td></tr><tr><td>Merging</td><td>Reflection</td><td>Forgetting</td></tr><tr><td>MemoryBank [6]</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RET-LLM [7]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>ChatDB [96]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>TiM [97]</td><td>✓</td><td>✓</td><td>×</td><td>✓</td><td>✓</td></tr><tr><td>SCM [98]</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Voyager [99]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MemGPT [100]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MemoChat [94]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>MPC [101]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Generative Agents [83]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RecMind [102]</td><td>○</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Retroformer [103]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>○</td></tr><tr><td>ExpeL [82]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>○</td></tr><tr><td>Synapse [91]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>GITM [93]</td><td>○</td><td>✓</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>ReAct [104]</td><td>○</td><td>×</td><td>×</td><td>×</td><td>○</td></tr><tr><td>Reflexion [5]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>○</td></tr><tr><td>RecAgent [95]</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Character-LLM [105]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>○</td></tr><tr><td>MAC [106]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>Huatuo [107]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>○</td></tr><tr><td>ChatDev [1]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>InteRecAgent [108]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaAgents [109]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>TPTU [110, 111]</td><td>○</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaGPT [112]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>S3 [2]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>InvestLM [113]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>○</td></tr></table>\n\n# 5.3.3 Memory Reading\n\nWhen the agents require information for reasoning and decision-making, the memory reading operation will extract related information from memory for usage. Therefore, how to access the related information for the current state is important. Due to the massive quantity of memory entities, and the fact that not all of them are pertinent to the current state, careful design is required to extract useful information based on relevance and other task-orientated factors.\n\nRepresentative Studies. In ChatDB [96], the memory reading operation is executed by the SQL statements. These statements will be generated by agents as a series of Chain-of-Memory in advance. In MPC [101], the agents can retrieve relevant memory from the memory pool. This method also proposes to provide Chain-of-Thought examples for ignoring certain memory. ExpeL [82] utilizes the Faiss [124] vector store as the pool of memory, and obtains the top-  $K$  successful trajectories that share the highest similarity scores with the current task.\n\nDiscussion. To some extent, the memory reading and writing operations are collaborative, and the forms of memory writing greatly influence the methods of memory reading. For the forms of textual\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/d17ee90c3cdd285e30a102759acaec0f2465196f00cee0b14fd96b44de08119e.jpg)  \nFigure 5: An overview of the evaluation methods of the memory module.\n\nmemory, most previous works use the text similarity and other auxiliary information for reading. For the forms of parametric memory, existing models may just utilize the updated parameters for inference, which can be seen as an implicit reading process.\n\n# 6 How to Evaluate the Memory in LLM-based Agent\n\nHow to effectively evaluate the memory module remains an open problem, where diverse evaluation strategies have been proposed in previous works according to different applications. To clearly show the common ideas of different evaluation methods, in this section, we summarize a general framework, which includes two broad evaluation strategies (see Figure 5 for an overview), that is, (1) direct evaluation, which independently measures the capability of the memory module. (2) indirect evaluation, which evaluates the memory module via end-to-end agent tasks. If the tasks can be effectively accomplished, the memory module is demonstrated to be useful.\n\n# 6.1 Direct Evaluation\n\nThis type of approaches regards the memory of the agents as a stand-alone component and evaluates its effectiveness independently. Previous studies can be categorized into two classes: subjective evaluation and objective evaluation. The subjective evaluation aims to measure memory effectiveness based on human judgments, which can be widely used in the scenarios that lack objective ground truths. Objective evaluation assesses memory effectiveness based on numerical metrics, which makes it easy to compare different memory modules.\n\n# 6.1.1 Subjective Evaluation\n\nIn subjective evaluation, there are two key problems, that is, (1) what aspects should be evaluated and (2) how to conduct the evaluation process. To begin with, the following two aspects are the most common perspectives leveraged to evaluate the memory module.\n\nCoherence. This aspect refers to whether the recalled memory is natural and suitable for the current context. For example, if the agent is making a plan for Alice's travel, the memory should be related to her preference for traveling rather than working. In previous works, Modarressi et al. [7] study whether the memory module could provide proper references among the ever-changing knowledge. Liang et al. [98] present some examples to demonstrate the relation between the current query and historical memory. Zhong et al. [6] and Liu et al. [97] assess the coherence of responses that integrate context and retrieved memory by scoring labels. Lee et al. [101] focus on the contradiction between the recalled memory and contexts.\n\nRationality. This aspect aims to evaluate whether the recalled memory is reasonable. For example, if the agent is asked to answer \"Where is the Summer Palace\", the recalled memory should be \"The Summer Palace is in Beijing\" rather than \"The Summer Palace is on the Moon\". In previous works, Lee et al. [101] ask crowd workers to directly score the rationality of the retrieved memory. Zhong et al. [6] and Liu et al. [97] recruit human evaluators to check if the memory contains reasonable answers for the current question.\n\nAs for how to conduct the evaluation process, there are two important problems. The first one is how to select the human evaluators. In general, the evaluators should be familiar with the evaluation task, which ensures that the labeling results are convincing and reliable. In addition, the backgrounds of the evaluators should be diverse to remove subjective biases of specific human groups. The second problem is how to label the outputs of the memory module. Usually, one can either directly score the\n\nresults [6] or make comparisons between two candidates [95]. The former can obtain absolute and quantitative evaluation results, while the latter can remove the labeling noises when independently scoring each candidate. In addition, the granularity of the ratings should also be carefully designed. Too coarse ratings may not effectively discriminate the capabilities of different memory modules, while too fine-grained ones may bring more effort for the workers to make judgments.\n\nIn general, subjective evaluation can be used in a wide range of scenarios, where one just needs to define the evaluation aspects and let recruited workers make judgments. This method is usually more explainable since the workers can provide the reasons for their judgments. However, subjective evaluation is costly due to the need to employ human evaluators. Additionally, different groups of evaluators may have various biases, making the results difficult to reproduce and compare.\n\n# 6.1.2 Objective Evaluation\n\nIn objective evaluation, previous work usually defines numeric metrics to evaluate the effectiveness and efficiency of the memory module.\n\nResult Correctness. This metric measures whether the agent can successfully answer pre-defined questions directly based on the memory module. For example, the question could be \"Where did Alice go today?\" with two choices \"A: the Summer Palace\" and \"B: the Great Wall\". Then, the agent should choose the correct answer based on the problem and its memory. The agent-generated answer will be compared with the ground truth. Formally, the accuracy can be calculated as\n\n$$\n\\text {C o r r e c t n e s s} = \\frac {1}{N} \\sum_ {i = 1} ^ {N} \\mathbb {I} \\left[ a _ {i} = \\hat {a} _ {i} \\right],\n$$\n\nwhere  $N$  is the number of problems,  $a_{i}$  represents the ground truth for the  $i$ -th problem,  $\\hat{a}_{i}$  means the answer given by the agent, and  $\\mathbb{I}[a_i = \\hat{a}_i]$  is the matching function commonly represented as\n\n$$\n\\mathbb {I} \\left[ a _ {i} = \\hat {a} _ {i} \\right] = \\left\\{ \\begin{array}{l l} 1 & \\text {i f} a _ {i} = \\hat {a} _ {i}, \\\\ 0 & \\text {i f} a _ {i} \\neq \\hat {a} _ {i}. \\end{array} \\right.\n$$\n\nIn previous works, Hu et al. [96] construct questions from past histories with annotated ground truths and calculate the accuracy of whether the recalled memory could match the correct answers. Similarly, Packer et al. [100] generate questions and answers that can only be derived from past sessions, and compare the responses from the agents with the ground truths to calculate the accuracy.\n\nReference Accuracy. This metric evaluates whether the agent can discover relevant memory contents to answer the questions. Different from the above metric, which focuses on the final results, reference accuracy cares more about the intermediate information to support the agent's final decisions. In specific, it compares the retrieved memory with the pre-prepared ground truth. For the above problem of \"Where did Alice go today?\", if the memory contents include (A) \"Alice had lunch with friends at Wangfujing today.\" and (B) \"Alice had roast duck for lunch\", then a better memory module should select (A) as a reference to answer the question. Usually, researchers leverage F1-score to evaluate the reference accuracy, which is calculated as\n\n$$\n\\mathrm {F} 1 = 2 \\cdot \\frac {\\text {P r e c i s i o n} \\cdot \\text {R e c a l l}}{\\text {P r e c i s i o n} + \\text {R e c a l l}},\n$$\n\nwhere the precision and recall scores are calculated as Precision =  $\\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}$  and Recall =  $\\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$ . The TP represents the number of true positive memory contents, FP means the number of false positive memory contents, and FN indicates the number of false negative memory contents. In previous works, Lu et al. [94] utilize F1-score to evaluate the retrieval process of the memory, and Zhong et al. [6] focus on assessing whether related memory can be successfully retrieved.\n\nResult Correctness and Reference Accuracy are both utilized to evaluate the effectiveness of the memory module. Beyond effectiveness, efficiency is also an important aspect, especially for real-world applications. Therefore, we describe the evaluation of efficiency as follows.\n\nTime & Hardware Cost. The total time cost includes the time leveraged for memory adaption and inference. The adaptation time refers to the time of memory writing and memory management, while the inference time indicates the time latency of memory reading. In specific, the difference from the\n\nend time to the start time of memory operations can be considered as the time consumption. Formally, the average time consumption of each type of operation can be represented as\n\n$$\n\\Delta \\mathrm {t i m e} = \\frac {1}{M} \\sum_ {i = 1} ^ {M} t _ {i} ^ {\\mathrm {e n d}} - t _ {i} ^ {\\mathrm {s t a r t}},\n$$\n\nwhere  $M$  represents the number of these operations,  $t_i^{\\mathrm{end}}$  means the end time of the  $i$ -th operation, and  $t_i^{\\mathrm{start}}$  indicates the start time of that operation. As for the computation overhead, it can be evaluated by the peak GPU memory allocation. In previous works, Tack et al. [106] utilize the peak memory allocation and adaptation time to assess the efficiency of memory operations.\n\nObjective evaluation offers numeric strategies to compare different methods of memory, which is important to benchmark this field and promote future developments.\n\n# 6.2 Indirect Evaluation\n\nBesides the above method that directly evaluates the memory module, evaluating via task completion is also a popular evaluation strategy. The intuition behind this type of approaches is that if the agent can successfully complete a task that highly depends on memory, it suggests that the designed memory module is effective. In the following parts, we present several representative tasks that are leveraged to evaluate the memory module in indirect ways.\n\n# 6.2.1 Conversation\n\nEngaging in conversations with humans is one of the most important applications of agents, where memory plays a crucial role in this process. By storing context information in memory, the agents allow users to experience personalized conversations, thus improving users' satisfaction. Therefore, when other parts of the agents are determined, the performance of the conversation tasks can reflect the effectiveness of different memory modules.\n\nIn the context of conversation, consistency and engagement are two commonly used methods to evaluate the effectiveness of the agents' memory. Consistency refers to how the response from agents is consistent with the context because dramatic changes should be avoided during the conversation. For example, Lu et al. [94] evaluate the consistency of agents on interactive dialogues, using GPT-4 to score on the responses from agents. Engagement refers to how the user is engaged to continue the conversation. It reflects the quality and attraction of agents' responses, as well as the ability of agents to craft the personas for current conversations. For example, Lee et al. [101] assess the engagingness of responses by SCE-p score, and Packer et al. [100] utilize CSIM score to evaluate the memory effect on increasing engagement of users.\n\n# 6.2.2 Multi-source Question-answering\n\nMulti-source questing-answering can comprehensively evaluate the memorized information from multiple sources, including inside-trial information, cross-trial information, and external knowledge. It focuses on the integration of memory utilization from various contents and sources.\n\nIn previous works, Yao et al. [104] evaluate the memory that integrates information from the task trial and the external knowledge from Wikipedia. Then, Shinn et al. [5] and Yao et al. [103] further include the cross-trial information of the same task, where the memory is permitted to obtain more experiences from previous failed trials. Moreover, Packer et al. [100] allow agents to utilize the memory from multi-document information for question-answering.\n\nBy evaluating multi-source question-answering tasks, the memory of agents can be examined on the capability of content integration from various sources. It also reveals the issue of the memory contradiction due to multiple information sources, and the problem of updated knowledge, which can potentially affect the performance of the memory module.\n\n# 6.2.3 Long-context Applications\n\nBeyond the above general applications, in many scenarios, LLM-based agents have to make decisions based on extremely long prompts. In these scenarios, the long prompts are usually regarded as the memory contents, which play an important role in driving agent behaviors.\n\nIn previous works, Huang et al. [19] organize a comprehensive survey for long-context LLMs, which provides a summary of evaluation metrics on long-context scenarios. Moreover, Shaham et al. [138] propose a zero-shot benchmark for evaluating agents' understanding of long-context natural languages. As for specific long-context tasks, long-context passage retrieval is one of the important tasks for evaluating the long-context ability of agents. It requires agents to find the correct paragraph in a long context that corresponds to the given questions or descriptions [139]. Long-context summarization is another representative task. It requests agents to formulate a global understanding of the whole context, and summarizes it according to the descriptions, where some metrics on matching scores like ROUGE can be utilized to compare the results with ground truths.\n\nThe evaluation of long-context applications provides broader approaches to assess the function of memory in agents, focusing on practical downstream scenarios. The comprehensive benchmarks [138, 140] also provide an objective assessment for the ability of long-context understanding.\n\n# 6.2.4 Other Tasks\n\nIn addition to the above three types of major tasks for indirect evaluation, there are also some other metrics in general tasks that can reveal the effectiveness of the memory module.\n\nSuccess rate refers to the proportion of tasks that agents can successfully solve. For Yao et al. [104], Shinn et al. [5] and Zhao et al. [82], they assess how many spacial tasks can be correctly completed through reasoning and memory in AlfWorld [141]. In Zhu et al. [93], they evaluate the success rate of producing different items in Minecraft to show the effect of memory. Moreover, Shinn et al. [5] measure the success rate of passed problems by generated codes, and Zheng et al. [91] calculate the success rate of computer control and accuracy of element selection to show the function of trajectory-as-exemplar memory. Exploration degree typically appears in exploratory games, which reflects the extent that agents can explore the environment. For example, Wang et al. [99] compare the numbers of distinct items explored in Minecraft to reflect the skill learning in memory.\n\nIn fact, nearly all the memory-equipped agents can evaluate the effect of memory by ablation studies, comparing the performance between with/without memory modules. The evaluation on specific scenarios can better reflect the significance of memory for the downstream applications practically.\n\n# 6.3 Discussions\n\nCompared with direct evaluation, indirect evaluation via specific tasks can be easier to conduct, since there are already many public benchmarks. However, the performance on tasks can be attributed to various factors, and memory is only one of them, which may make the evaluation results biased. By direct evaluation, the effectiveness of the memory module can be independently evaluated, which improves the reliability of the evaluation results. However, to our knowledge, there are no open-sourced benchmarks tailored for the memory modules in LLM-based agents.\n\n# 7 Memory-enhanced Agent Applications\n\nRecently, LLM-based agents have been investigated across a wide variety of scenarios, facilitating societal advancement. In general, most LLM-based agents are equipped with memory modules. However, the specific effects undertaken by these memory components, the particular information they store, and the implementation methods they use, vary across different applications. In order to provide insights for the design of memory functionalities in LLM-based agents, in this section, we review and summarize how memory mechanisms are manifested in LLM-based agents across various application scenarios. In specific, we categorize them into several classes: role-playing and social simulation, personal assistant, open-world games, code generation, recommendation, expert systems in specific domains, and other applications. The summarization is shown in Table 4.\n\n# 7.1 Role-playing and Social Simulation\n\nRole-playing represents a classic application of LLM-based agents, where memory plays a crucial role inside the agents. It endows roles with distinct characteristics, differentiating them from one another. Many previous studies have explored methods for constructing role memories [105, 143, 145-147]. Shao et al. [105] construct the memory of roles by experience uploading, which utilizes SFT to inject memory into model parameters. Li et al. [143] enhance large language models for role-playing via an improved prompt and the character memory extracted from scripts, where user queries and\n\nTable 4: Summarization of memory-enhanced agents applications.  \n\n<table><tr><td>Applications</td><td>Models</td><td>Applications</td><td>Models</td></tr><tr><td>Role-playing</td><td>Character-LLM [105]ChatHaruhi [143]RoleLLM [145]NarrativePlay [146]CharacterGLM [147]</td><td>Code Generation</td><td>RTLFixer [142]GameGPT [144]ChatDev [1]MetaGPT [109]CodeAgent [114]</td></tr><tr><td rowspan=\"2\">Social Simulation</td><td rowspan=\"2\">Generative Agents [83]Lyfe Agents [148]S3[2]MetaAgents [109]WarAgent [150]</td><td>Recommendation</td><td>RecAgent [95]InteRecAgent [108]RecMind [102]AgentCF [149]</td></tr><tr><td>Medicine</td><td>Huatuo [107]</td></tr><tr><td>Personal Assistant</td><td>MemoryBank [6]RET-LLM [7]MemoChat [94]MemGPT [100]MPC [101]AutoGen [153]ChatDB [96]TiM [97]SCM [98]</td><td>Finance</td><td>DoctorGLM [129]Radiology-GPT [132]Wang et al. [151]EHRAgent [152]ChatDoctor [115]InvestLM [113]TradingGPT [154]QuantAgent [155]FinMem [156]Koa et al. [157]</td></tr><tr><td>Game</td><td>Voyager [99]GITM [93]JARVIS [159]LARP [161]</td><td>Science</td><td>Chemist-X [158]ChemDFM [160]MatChat [162]</td></tr></table>\n\nchatbot's responses are concatenated to form a sequence as memory. Wang et al. [145] infuse role-specific knowledge and episode memories into LLM-based agents, where context QA pairs are concatenated to form episode memory. Zhao et al. [146] aim to generate human-like responses, guided by personality traits extracted from narratives, which can be stored and retrieved by relevance and importance. Zhou et al. [147] generate character-based dialogues for different roles and empower LLM-based agents with corresponding styles by SFT.\n\nSocial simulation is basically an extension of role-playing, which focuses more on multi-agent modeling. The memory module is an important component for such applications, which helps to accurately simulate human dynamic behaviors. In previous studies, Kaiya et al. [148] propose a Summarize-and-Forget memory mechanism for better self-monitoring in social scenarios. Gao et al. [2] focus on social network simulation systems. Each agent in the system has a memory pool, which consists of diverse user messages from online platforms to identify the user. Li et al. [163] maintain conversation contexts, encompassing the economic environment and agent decisions from previous months, in order to simulate the impact of broad macroeconomic trends on agents' decision-making and to make the agents grasp market dynamics. Li et al. [109] simulate the job-seeking scenario in human society, where the memory of agents includes profiles and goals initially and is further enriched with other information, like dialogues and personal reflections. Hua et al. [150] simulate the decisions and consequences of the participating countries in the wars, where the conversations of agents are continuously maintained into memory.\n\nThere are several insights in designing an agent's memory for role-play and social simulation. First, the memory should be consistent with the roles' characteristics, which can be used to identify each role and distinguish it from the others. This is crucial for improving the realism of role-play and the diversity of social simulation. Second, the memory should appropriately influence the subsequent\n\nactions of the agent to ensure the consistency and rationality of its behaviors. Additionally, for humanoid agents, their memory mechanisms should align with the features of human memory, such as forgetting and long/short-term memory, which should refer to the theories of cognitive psychology.\n\n# 7.2 Personal Assistant\n\nLLM-based agents are well-suited for creating personal assistants, such as agents capable of engaging in long-term conversations with users [94, 101, 153], as well as those tasked with automatically seeking information [164]. These agents often need to memorize previous dialogues to maintain the consistency, and remember critical styles and events to generate more personalized and relevant responses. Lu et al. [94] maintain the context consistency for dialogues by saving contents and information of conversations, which helps to find proper relevant information by retrieval. Lee et al. [101] summarize conversations to extract important information, store it, and retrieve it for future inference. Pan et al. [164] focus on information-seeking tasks, which design memory modules to store user's context information, and empower external knowledge with tool usage. Wu et al. [153] retain important context as memory to maintain conversation consistency.\n\nIn summary, most memory implementations for personal assistants adopt retrieval methods in textual form, because they are better at finding relevant information from pieces of conversations. For the memory storage, the agent should remember the factual information during user-agent interactions, as well as the personal style of users, in order to generate responses that are tailored to the user's situation. Additionally, when recalling memories, the agent should identify and retrieve the memory that is relevant to the current query and context. This principle can enable the agent to correctly understand the user's requirement, and maintain the consistency in conversations.\n\n# 7.3 Open-world Game\n\nFor games and open-world exploration, LLM-based agents always maintain post observations as task contexts, and store experiences in previous successful trials. By leveraging past experiences, agents can avoid making the same mistakes repeatedly and achieve a high-level understanding of environments, thus exploring more effectively. Some of them can acquire external databases or APIs to obtain general knowledge [99, 93, 159, 161]. Wang et al. [99] save obtained skills into memory for further usage in Minecraft. Zhu et al. [93] store and retrieve successful trajectories as examples for similar tasks, and utilize external Minecraft Wiki by API calls. Wang et al. [159] construct multimodal memory as a knowledge library and provide examples for prompt by retrieving interactive experiences. Yan et al. [161] maintain working memory for decision-making, save and retrieve relevant past experiences, and implement external datasets for general knowledge.\n\nIn summary, no matter inside-trial or cross-trial information, the key aspect of memory is to reflect on past interactions and draw experiences that can be applied to the subsequent exploration. In addition to accumulating experience through self-involving trials, absorbing external knowledge as part of the agent's memory is also an important way to enhance the exploratory capabilities of the agent.\n\n# 7.4 Code Generation\n\nIn the scenario of code generation, LLM-based agents can search relevant information from the memory, thereby obtaining more knowledge for development. They can save previous experiences for future problems, and also maintain context in conversational development interfaces [142, 144, 1, 109]. Tsai et al. [142] construct an external non-parametric memory database, which stores the compiler errors and human expert instructions for automatic syntax error fixing. In [144], personal information will be stored in the memory, and helps in retaining context and knowledge for decision-making. Qian et al. [1] adopt multi-agents to develop software, where each role maintains a memory to store the past conversations with other roles. Li et al. [109] also focus on software development, and the agent can retrieve its historical records preserved in memory when errors occur. Zhang et al. [114] can search relevant information when they face problems on code generation.\n\nBy leveraging external resources, the agents can learn from code-related knowledge and store it into their memory, thereby enhancing the capabilities of code generation. In addition, the memory can improve the continuity and consistency in code generation. By integrating contextual memory, the agent can better understand the requirements for software development, thereby enhancing the coherence of the generated code. Furthermore, the memory is also crucial for the iterative optimization of code, as it can identify the developer's targets based on the histories.\n\n# 7.5 Recommendation\n\nIn the field of recommendation, some previous works focus on simulating users in recommender systems [95, 108], where the memory can represent the user profiles and histories in the real world. Others try to improve the performance of recommendation, or provide other formats of recommendation interfaces [149, 102]. Wang et al. [95] simulate user behaviors in recommendation scenarios to generate data for recommender systems, and the agents store past observations and insights into a hierarchical memory. In Huang et al. [108], the memory in LLM-based agents can archive the user's conversational history over extended periods, as well as capture the most recent dialogues pertinent to the current prompt, to simulate interactive recommender systems. It also uses an actor-critic reflection to improve the robustness of agents. Item agents and user agents are equipped with different memories in [149], where item agents are endowed with dynamic memory modules designed to capture and preserve information pertinent to their intrinsic attributes and the inclinations of their adopters. For user agents, the adaptive memory updating mechanism plays a pivotal role in aligning the agents' operations with user behaviors and preferences. Wang et al. [102] memorize individualized user information like reviews or ratings for items, and acquire domain-specific knowledge and real-time information by web searching tools.\n\nFor both simulating users in recommender systems and capturing their preferences, retaining personalized information through memory is essential. A critical challenge lies in how to align the personalized information and feedback with LLMs, and store them into the memory of agents. It is also an important task for bridging the gap between conventional recommendation models and LLMs.\n\n# 7.6 Expert System in Specific Domains\n\nMedicine Domain. In the field of medicine, most of the previous works empower LLM-based agents with external knowledge in their memory [107, 129, 132, 151, 115]. Wang et al. [107] fine-tune LLaMA [127] with medical knowledge graph CMeKG [165] in QA form, in order to enhance their medical domain knowledge. Xiong et al. [129] adopt LoRA [131] to efficiently fine-tune on foundation models for healthcare. Wang et al. [151] empower LLM-based agents to acquire text-based external knowledge as reasoning reference. Besides, Shi et al. [152] build memory upon the most relevant successful cases from past experiences, and use similarity metric for the retrieval of relevant questions in the medicine domain.\n\nFinance Domain. Some previous works also apply LLM-based agents in the finance domain, whose memory can store financial knowledge [113], market information [154, 156], and successful experiences [157, 155]. Yang et al. [113] construct financial investment dataset to fine-tune LLaMA [127] to empower knowledge on investment. Li et al. [154] design a layered-memory structure to store different types of marketing information. Wang et al. [155] record the ongoing interaction like exchanges and information to ensure consistent response, and record prior outputs as experiences for retrieving relevant examples to provide a diverse learning context for agents. Koa et al. [157] store past price movement and explanations, and generate reflections on previous trials. Yu et al. [156] adopt a layered memory mechanism to provide abundant information for reasoning.\n\nScience. In the domain of science, some existing works design LLM-based agents with a large amount of knowledge in memory to solve problems [158, 160, 162]. Chen et al. [158] include molecule database and online literature as external knowledge for memory in LLM-based agents, and retrieve them when they need related information. Zhao et al. [160] and Chen et al. [162] empower domain knowledge by fine-tuning in Chemistry and structured materials respectively.\n\nTo build an expert system based on agents in a specific vertical domain, it is necessary to retain the domain-specific knowledge in their memory. However, there are several challenges. First, domain knowledge is specialized and requires higher accuracy, leading to difficulties in constructing memory storage. Second, domain knowledge is often time-sensitive, which can become outdated in the future. Therefore, the memory needs to be partially updated when some of the knowledge has been out-of-date. Furthermore, the substantial volume of domain knowledge makes it difficult to recall from memory based on the current query.\n\n# 7.7 Other Applications\n\nThere are some other applications of memory in LLM-based agents. Wang et al. [166] focus on the task of cloud root cause analysis, using memory to store framework rules, task requirements, tools\n\ndocumentation, few-shot examples, and agent observations. Qiang et al. [167] solve the problem of ontology matching. The agents save conversational dialogues and construct a rational database for retrieving external knowledge. Wen et al. [168] investigate autonomous driving, whose memory module is constructed by a vector database and contains the experiences from past driving scenarios. Wang et al. [169] propose to improve user acceptance testing, which employs a self-reflection mechanism. After each trial, the operation agent summarizes the conversation and updates the memory pool, until the goal of the current step is accomplished.\n\nFor different applications, the focus of memory varies, as it inherently serves the downstream tasks. Therefore, the design should also consider the requirements of tasks.\n\n# 8 Limitations & Future Directions\n\n# 8.1 More Advances in Parametric Memory\n\nAt present, the memory of LLM-based agents is predominantly in textual form, especially for contextual knowledge such as observation records, trial experiences, and textual knowledge databases. Although textual memory possesses the advantages of being interpretable and easy to expand and edit, it also implies a sacrifice in efficiency compared to parametric memory. Essentially, parametric memory boasts a higher information density, expressing semantics through continuous real-number vectors in a latent space, whereas textual memory employs a combination of tokens in a discrete space for semantic expression. Thus, parametric memory offers a richer expressive space, and its soft encoding is more robust compared to the hard-coded form of token sequences. Additionally, parametric memory is more storage-efficient, where it does not require the explicit storage of extensive texts, similar to a knowledge compression process. As for the memory management, such as merging and reflection, parametric memory does not necessarily design manual rules like textual memory does, but can employ optimization methods to learn these processes implicitly. Moreover, pluggable parametric memory is similar to a digital life card, capable of endowing agents with the requisite characteristics. For example, Huatuo [107] aims to enhance agents with expertise in the biomedical field by refining the Llama [127] model on Chinese medical knowledge bases. MAC [106] is designed to create a parametric memory adaptation framework suitable for online settings, employing meta-learning techniques to replace the traditional optimization phase.\n\nAlthough parametric memory holds great prospects, it currently faces numerous challenges. Foremost among these is the issue of efficiency: how to effectively transform textual information into parameters or modifications of parameters is a critical question. Presently, researchers can transfer vast amounts of domain knowledge into the parameters of LLMs by SFT. However, it is time-consuming and requires extensive text corpus, making it unsuitable for situational knowledge. One viable approach is to employ meta-learning to let models learn to memorize. For example, MEND [134] leverages the method of meta-learning to train a compact model that has the ability to produce adjustments for the parameters of a pre-trained language model. Moreover, the lack of interpretability associated with parametric memory can be a hindrance, especially in domains requiring high levels of trust, such as medicine. Therefore, enhancing the credibility and interpretability of parametric memory is an urgent issue that needs to be addressed.\n\n# 8.2 Memory in LLM-based Multi-agent Applications\n\nThe exploration of memory mechanisms within LLMs has begeoned into the dynamic domain of multi-agent systems (MAS), marking significant advancements in the realms of synchronization, communication, and the management of information asymmetry. One pivotal aspect that emerges in the cooperative scenarios is memory synchronization among agents. This process is fundamental for establishing a unified knowledge base, ensuring consistency in decision-making across different agents. For example, Chen et al. [170] emphasize the significance of integrating synchronized memory modules for multi-robot collaboration. Another important aspect is the communication among agents, which heavily relies on memory for maintaining context and interpreting messages. For example, Mandi et al. [171] illustrate memory-driven communication frameworks that foster a common understanding among agents. In addition to cooperative scenarios, some studies also focus on competitive scenarios, and the information asymmetry becomes a crucial issue [172].\n\nLooking ahead, the advancement of memory in LLM-based MAS is poised at the confluence of technological innovation and strategic application. It beckons the exploration of novel memory\n\nmodules that can further enhance agent synchronization, enable more effective communication, and provide strategic advantages in information-rich environments. The development of such memory models would not only necessitate addressing the current challenges of memory integration and management, but also explore the untapped potentials of memory in facilitating more robust, intelligent, and adaptable MAS. As evidenced by pioneering research, the evolving landscape of LLM-based MAS sets a promising stage for future innovations in memory utilization and management. This exploration is expected to unravel new dimensions of memory integration, pushing the boundaries of what is currently achievable and setting new benchmarks in the realm of MAS.\n\n# 8.3 Memory-based Lifelong Learning\n\nLifelong learning is an advanced topic in artificial intelligence, extending the learning capabilities of agents across their life-long span [173]. Agents can continuously interact with their environment, persistently observe environments, and acquire external knowledge, enabling a mode of enhancement like humans. The memory of an agent is key to achieving lifelong learning, as it needs to learn to store and apply the past observations. Lifelong learning in LLM-based agents holds significant practical value, such as in long-term social simulations and personal assistance. However, it also faces several challenges. Firstly, lifelong learning is temporal, necessitating that an agent's memory captures temporality. This temporality could cause interactions between memories, such as memory overlap. Furthermore, due to the extended period of lifelong learning, it needs to store a vast amount of memories and retrieve them when needed, possibly incorporating a certain mechanism for forgetting.\n\n# 8.4 Memory in Humanoid Agent\n\nA humanoid agent refers to an agent designed to exhibit behaviors consistent with humans, thereby facilitating applications in social simulation, studies of human behavior, and role-playing. Unlike task-oriented agents where greater capability is typically preferred, the proficiency of a humanoid agent should closely mimic that of humans. Consequently, the memory of humanoid agents should align with human cognitive processes, adhering to psychological principles such as memory distortion and forgetfulness. Additionally, humanoid agents should possess knowledge boundaries, meaning that their knowledge should correspond to that of the entity they replicate. For instance, in role-playing scenarios, an agent embodying a child should not possess an understanding of advanced mathematical concepts or other complex knowledge beyond what is typical for that age [174].\n\n# 9 Conclusion\n\nIn this survey, we provide a systematic review on the memory mechanism of LLM-based agents, where we focus on three key problems including \"What is\", \"Why do we need\" and \"How to design and evaluate\" the memory module in LLM-based agents. To show the importance of the agent's memory, we also present many typical applications, where the memory module plays an important role. We believe this survey can offer valuable references for newcomers to this domain, and also hope it can inspire more advanced memory mechanisms to enhance LLM-based agents.\n\n# Acknowledgement\n\nWe thank Lei Wang for his proofreading and valuable suggestions to this survey.\n\n# References\n\n[1] Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. Communicative agents for software development. arXiv preprint arXiv:2307.07924, 2023.  \n[2] Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong Wang, Depeng Jin, and Yong Li. S<sup>3</sup>: Social-network simulation system with large language model-empowered agents. arXiv preprint arXiv:2307.14984, 2023.  \n[3] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents. arXiv preprint arXiv:2308.11432, 2023.\n\n[4] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.  \n[5] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.  \n[6] Wanjun Zhong, Lianghong Guo, Qiqi Gao, and Yanlin Wang. Memorybank: Enhancing large language models with long-term memory. arXiv preprint arXiv:2305.10250, 2023.  \n[7] Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Schütze. Ret-llm: Towards a general read-write memory for large language models. arXiv preprint arXiv:2305.14322, 2023.  \n[8] Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et al. Instruction tuning for large language models: A survey. arXiv preprint arXiv:2308.10792, 2023.  \n[9] Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. Large language model alignment: A survey. arXiv preprint arXiv:2309.15025, 2023.  \n[10] Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, and Qun Liu. Aligning large language models with human: A survey. arXiv preprint arXiv:2307.12966, 2023.  \n[11] Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo Hao Cheng, Yegor Klochkov, Muhammad Faaiz Taufiq, and Hang Li. Trustworthy llms: a survey and guideline for evaluating large language models' alignment. arXiv preprint arXiv:2308.05374, 2023.  \n[12] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023.  \n[13] Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, et al. Knowledge editing for large language models: A survey. arXiv preprint arXiv:2310.16218, 2023.  \n[14] Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, and Ningyu Zhang. Editing large language models: Problems, methods, and opportunities. arXiv preprint arXiv:2305.13172, 2023.  \n[15] Peng Wang, Ningyu Zhang, Xin Xie, Yunzhi Yao, Bozhong Tian, Mengru Wang, Zekun Xi, Siyuan Cheng, Kangwei Liu, Guozhou Zheng, et al. Easyedit: An easy-to-use knowledge editing framework for large language models. arXiv preprint arXiv:2308.07269, 2023.  \n[16] Zhangyin Feng, Weitao Ma, Weijiang Yu, Lei Huang, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. Trends in integration of knowledge and large language models: A survey and taxonomy of methods, benchmarks, and applications. arXiv preprint arXiv:2311.05876, 2023.  \n[17] Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, et al. A comprehensive study of knowledge editing for large language models. arXiv preprint arXiv:2401.01286, 2024.  \n[18] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al. Tool learning with foundation models. arXiv preprint arXiv:2304.08354, 2023.  \n[19] Yunpeng Huang, Jingwei Xu, Zixu Jiang, Junyu Lai, Zenan Li, Yuan Yao, Taolue Chen, Lijuan Yang, Zhou Xin, and Xiaoxing Ma. Advancing transformer architecture in long-context large language models: A comprehensive survey. arXiv preprint arXiv:2311.12351, 2023.\n\n[20] Xindi Wang, Mahsa Salmani, Parsa Omidi, Xiangyu Ren, Mehdi Rezagholizadeh, and Ar-maghan Eshaghi. Beyond the limits: A survey of techniques to extend the context length in large language models. arXiv preprint arXiv:2402.02244, 2024.  \n[21] Saurav Pawar, SM Tonmoy, SM Zaman, Vinija Jain, Aman Chadha, and Amitava Das. The what, why, and how of context length extension techniques in large language models-a detailed survey. arXiv preprint arXiv:2401.07872, 2024.  \n[22] Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and S Yu Philip. Multimodal large language models: A survey. In 2023 IEEE International Conference on Big Data (BigData), pages 2247-2256. IEEE, 2023.  \n[23] Shezheng Song, Xiaopeng Li, and Shasha Li. How to bridge the gap between modalities: A comprehensive survey on multimodal large language model. arXiv preprint arXiv:2311.07594, 2023.  \n[24] Davide Caffagni, Federico Cocchi, Luca Barsellotti, Nicholas Moratelli, Sara Sarto, Lorenzo Baraldi, Marcella Cornia, and Rita Cucchiara. The (r) evolution of multimodal large language models: A survey. arXiv preprint arXiv:2402.12451, 2024.  \n[25] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. A survey on multimodal large language models. arXiv preprint arXiv:2306.13549, 2023.  \n[26] Guangji Bai, Zheng Chai, Chen Ling, Shiyu Wang, Jiaying Lu, Nan Zhang, Tingwei Shi, Ziyang Yu, Mengdan Zhu, Yifei Zhang, et al. Beyond efficiency: A systematic survey of resource-efficient large language models. arXiv preprint arXiv:2401.00625, 2024.  \n[27] Zhongwei Wan, Xin Wang, Che Liu, Samiul Alam, Yu Zheng, Zhongnan Qu, Shen Yan, Yi Zhu, Quanlu Zhang, Mosharaf Chowdhury, et al. Efficient large language models: A survey. arXiv preprint arXiv:2312.03863, 1, 2023.  \n[28] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin, Tianqi Chen, and Zhihao Jia. Towards efficient generative large language model serving: A survey from algorithms to systems. arXiv preprint arXiv:2312.15234, 2023.  \n[29] Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. Parameter-efficient fine-tuning methods for pretrained language models: A critical review and assessment. arXiv preprint arXiv:2312.12148, 2023.  \n[30] Xunyu Zhu, Jian Li, Yong Liu, Can Ma, and Weiping Wang. A survey on model compression for large language models. arXiv preprint arXiv:2308.07633, 2023.  \n[31] Canwen Xu and Julian McAuley. A survey on model compression and acceleration for pretrained language models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 10566-10575, 2023.  \n[32] Wenxiao Wang, Wei Chen, Yicong Luo, Yongliu Long, Zhengkai Lin, Liye Zhang, Binbin Lin, Deng Cai, and Xiaofei He. Model compression and efficient inference for large language models: A survey. arXiv preprint arXiv:2402.09748, 2024.  \n[33] Seungcheol Park, Jaehyeon Choi, Sojin Lee, and U Kang. A comprehensive survey of compression algorithms for language models. arXiv preprint arXiv:2401.15347, 2024.  \n[34] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey on evaluation of large language models. ACM Transactions on Intelligent Systems and Technology, 2023.  \n[35] Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong, et al. Evaluating large language models: A comprehensive survey. arXiv preprint arXiv:2310.19736, 2023.  \n[36] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. Harnessing the power of llms in practice: A survey on chatgpt and beyond. arXiv preprint arXiv:2304.13712, 2023.\n\n[37] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. Large language models for information retrieval: A survey. arXiv preprint arXiv:2308.07107, 2023.  \n[38] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, and Enhong Chen. Large language models for generative information extraction: A survey. arXiv preprint arXiv:2312.17617, 2023.  \n[39] Angela Fan, Belize Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, and Jie M Zhang. Large language models for software engineering: Survey and open problems. arXiv preprint arXiv:2310.03533, 2023.  \n[40] Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, and Qing Wang. Software testing with large language models: Survey, landscape, and vision. IEEE Transactions on Software Engineering, 2024.  \n[41] Zibin Zheng, Kaiwen Ning, Yanlin Wang, Jingwen Zhang, Dewu Zheng, Mingxi Ye, and Jiachi Chen. A survey of large language models for code: Evolution, benchmarking, and future trends. arXiv preprint arXiv:2311.10372, 2023.  \n[42] Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, and Philip S Yu. Large language models for robotics: A survey. arXiv preprint arXiv:2311.07226, 2023.  \n[43] Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zichong Yang, Kuei-Da Liao, et al. A survey on multimodal large language models for autonomous driving. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 958-979, 2024.  \n[44] Zhenjie Yang, Xiaosong Jia, Hongyang Li, and Junchi Yan. A survey of large language models for autonomous driving. arXiv preprint arXiv:2311.01043, 2023.  \n[45] Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, and Erik Cambria. A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics. arXiv preprint arXiv:2310.05694, 2023.  \n[46] Hongjian Zhou, Boyang Gu, Xinyu Zou, Yiru Li, Sam S Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Xian Wu, et al. A survey of large language models in medicine: Progress, application, and challenge. arXiv preprint arXiv:2311.05112, 2023.  \n[47] Benyou Wang, Qianqian Xie, Jiahuan Pei, Zhihong Chen, Prayag Tiwari, Zhao Li, and Jie Fu. Pre-trained language models in biomedical domain: A systematic survey. ACM Computing Surveys, 56(3):1-52, 2023.  \n[48] Yinheng Li, Shaofei Wang, Han Ding, and Hang Chen. Large language models in finance: A survey. In Proceedings of the Fourth ACM International Conference on AI in Finance, pages 374-382, 2023.  \n[49] Tianyu He, Guanghui Fu, Yijing Yu, Fan Wang, Jianqiang Li, Qing Zhao, Changwei Song, Hongzhi Qi, Dan Luo, Huijing Zou, et al. Towards a psychological generalist ai: A survey of current applications of large language models and future prospects. arXiv preprint arXiv:2312.04578, 2023.  \n[50] Lei Li, Yongfeng Zhang, Dugang Liu, and Li Chen. Large language models for generative recommendation: A survey and visionary discussions. arXiv preprint arXiv:2309.01157, 2023.  \n[51] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. How can recommender systems benefit from large language models: A survey. arXiv preprint arXiv:2306.05817, 2023.  \n[52] Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, and Tat-Seng Chua. Generative recommendation: Towards next-generation recommender paradigm. arXiv preprint arXiv:2304.03516, 2023.\n\n[53] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. Siren's song in the ai ocean: a survey on hallucination in large language models. arXiv preprint arXiv:2309.01219, 2023.  \n[54] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qian-glong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. arXiv preprint arXiv:2311.05232, 2023.  \n[55] Vipula Rawte, Amit Sheth, and Amitava Das. A survey of hallucination in large foundation models. arXiv preprint arXiv:2309.05922, 2023.  \n[56] Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, and Weiqiang Jia. Cognitive mirage: A review of hallucinations in large language models. arXiv preprint arXiv:2309.06794, 2023.  \n[57] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1-38, 2023.  \n[58] SM Tonmoy, SM Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, and Amitava Das. A comprehensive survey of hallucination mitigation techniques in large language models. arXiv preprint arXiv:2401.01313, 2024.  \n[59] Xuhui Jiang, Yuxing Tian, Fengrui Hua, Chengjin Xu, Yuanzhuo Wang, and Jian Guo. A survey on large language model hallucination via a creativity perspective. arXiv preprint arXiv:2402.06647, 2024.  \n[60] Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K Ahmed. Bias and fairness in large language models: A survey. arXiv preprint arXiv:2309.00770, 2023.  \n[61] Hadas Kotek, Rikker Dockum, and David Sun. Gender bias and stereotypes in large language models. In Proceedings of The ACM Collective Intelligence Conference, pages 12-24, 2023.  \n[62] Yingji Li, Mengnan Du, Rui Song, Xin Wang, and Ying Wang. A survey on fairness in large language models. arXiv preprint arXiv:2308.10149, 2023.  \n[63] Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and Mengnan Du. Explainability for large language models: A survey. ACM Transactions on Intelligent Systems and Technology, 2023.  \n[64] Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Eric Sun, and Yue Zhang. A survey on large language model (llm) security and privacy: The good, the bad, and the ugly. arXiv preprint arXiv:2312.02003, 1, 2023.  \n[65] Erfan Shayegani, Md Abdullah Al Mamun, Yu Fu, Pedram Zaree, Yue Dong, and Nael Abu-Ghazaleh. Survey of vulnerabilities in large language models revealed by adversarial attacks. arXiv preprint arXiv:2310.10844, 2023.  \n[66] Seth Neel and Peter Chang. Privacy issues in large language models: A survey. arXiv preprint arXiv:2312.06717, 2023.  \n[67] Victoria Smith, Ali Shahin Shamsabadi, Carolyn Ashurst, and Adrian Weller. Identifying and mitigating privacy risks stemming from language models: A survey. arXiv preprint arXiv:2310.01424, 2023.  \n[68] Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, and Yu Qiao. Attacks, defenses and evaluations for llm conversation safety: A survey. arXiv preprint arXiv:2402.09283, 2024.  \n[69] Badhan Chandra Das, M Hadi Amini, and Yanzhao Wu. Security and privacy challenges of large language models: A survey. arXiv preprint arXiv:2402.00888, 2024.  \n[70] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.\n\n[71] Muhammad Usman Hadi, Rizwan Qureshi, Abbas Shah, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili, et al. A survey on large language models: Applications, challenges, limitations, and practical usage. Authorea Preprints, 2023.  \n[72] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained language models: A survey. ACM Computing Surveys, 56(2): 1-40, 2023.  \n[73] Grégoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. arXiv preprint arXiv:2302.07842, 2023.  \n[74] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, and Enhong Chen. Understanding the planning of llm agents: A survey. arXiv preprint arXiv:2402.02716, 2024.  \n[75] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V Chawla, Olaf Wiest, and Xiangliang Zhang. Large language model based multi-agents: A survey of progress and challenges. arXiv preprint arXiv:2402.01680, 2024.  \n[76] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, et al. Personal llm agents: Insights and survey about the capability, efficiency and security. arXiv preprint arXiv:2401.05459, 2024.  \n[77] Pengyu Zhao, Zijian Jin, and Ning Cheng. An in-depth survey of large language model-based artificial intelligence agents. arXiv preprint arXiv:2309.14365, 2023.  \n[78] Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, et al. Exploring large language model based intelligent agents: Definitions, methods, and prospects. arXiv preprint arXiv:2401.03428, 2024.  \n[79] Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong, Jae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Yejin Choi, et al. Agent ai: Surveying the horizons of multimodal interaction. arXiv preprint arXiv:2401.03568, 2024.  \n[80] Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan, and Yongfeng Zhang. LIm as os (llmao), agents as apps: Envisioning aios, agents and the aios-agent ecosystem. arXiv preprint arXiv:2312.03815, 2023.  \n[81] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, et al. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models. arXiv preprint arXiv:2203.06904, 2022.  \n[82] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang. Expel: Llm agents are experiential learners. arXiv preprint arXiv:2308.10144, 2023.  \n[83] Joon Sung Park, Joseph O'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein. Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, pages 1-22, 2023.  \n[84] Robert L Solso and Jerome Kagan. Cognitive psychology. Houghton Mifflin Harcourt P, 1979.  \n[85] Fergus IM Craik and Robert S Lockhart. Levels of processing: A framework for memory research. Journal of verbal learning and verbal behavior, 11(6):671-684, 1972.  \n[86] Selma Leydesdorff. Memory cultures: Memory, subjectivity and recognition. Routledge, 2017.  \n[87] Philip Nicholas Johnson-Laird. Mental models: Towards a cognitive science of language, inference, and consciousness. Number 6. Harvard University Press, 1983.\n\n[88] John E Laird. The Soar cognitive architecture. MIT press, 2019.  \n[89] Ron Sun. Duality of the mind: A bottom-up approach toward cognition. Psychology Press, 2001.  \n[90] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.  \n[91] Longtao Zheng, Rundong Wang, Xinrun Wang, and Bo An. Synapse: Trajectory-as-exemplar prompting with memory for computer control. In NeurIPS 2023 Foundation Models for Decision Making Workshop, 2023.  \n[92] Ali Montazeralghaem, Hamed Zamani, and James Allan. A reinforcement learning framework for relevance feedback. In Proceedings of the 43rd international acm SIGIR conference on research and development in information retrieval, pages 59–68, 2020.  \n[93] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory. arXiv preprint arXiv:2305.17144, 2023.  \n[94] Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, and Yunsheng Wu. Memochat: Tuning llms to use memos for consistent long-range open-domain conversation. arXiv preprint arXiv:2308.08239, 2023.  \n[95] Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Jun Xu, Zhicheng Dou, Jun Wang, and Ji-Rong Wen. When large language model based agent meets user behavior analysis: A novel user simulation paradigm, 2023.  \n[96] Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. Chatdb: Augmenting llms with databases as their symbolic memory. arXiv preprint arXiv:2306.03901, 2023.  \n[97] Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, and Guannan Zhang. Think-in-memory: Recalling and post-thinking enable llms with long-term memory. arXiv preprint arXiv:2311.08719, 2023.  \n[98] Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu Lu, Zejun Ma, and Zhoujun Li. Unleashing infinite-length input capacity for large-scale language models with self-controlled memory system. arXiv preprint arXiv:2304.13343, 2023.  \n[99] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023.  \n[100] Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah Wooders, and Joseph E Gonzalez. Memgpt: Towards llms as operating systems. arXiv preprint arXiv:2310.08560, 2023.  \n[101] Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, and Kangwook Lee. Prompted llms as chatbot modules for long open-domain conversation. arXiv preprint arXiv:2305.04533, 2023.  \n[102] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. Recmind: Large language model powered agent for recommendation. arXiv preprint arXiv:2308.14296, 2023.  \n[103] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et al. Retroformer: Retrospective large language agents with policy gradient optimization. arXiv preprint arXiv:2308.02151, 2023.  \n[104] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.\n\n[105] Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. Character-llm: A trainable agent for role-playing. arXiv preprint arXiv:2310.10158, 2023.  \n[106] Jihoon Tack, Jaehyung Kim, Eric Mitchell, Jinwoo Shin, Yee Whye Teh, and Jonathan Richard Schwarz. Online adaptation of language models with a memory of amortized contexts. arXiv preprint arXiv:2403.04317, 2024.  \n[107] Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting Liu. Hu- atuo: Tuning llama model with chinese medical knowledge. arXiv preprint arXiv:2304.06975, 2023.  \n[108] Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. Recommender ai agent: Integrating large language models for interactive recommendations. arXiv preprint arXiv:2308.16505, 2023.  \n[109] Yuan Li, Yixuan Zhang, and Lichao Sun. Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents. arXiv preprint arXiv:2310.06500, 2023.  \n[110] Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao. Tptu: Task planning and tool usage of large language model-based ai agents. arXiv preprint arXiv:2308.03427, 2023.  \n[111] Yilun Kong, Jingqing Ruan, Yihong Chen, Bin Zhang, Tianpeng Bao, Shiwei Shi, Guoqing Du, Xiaoru Hu, Hangyu Mao, Ziyue Li, et al. Tptu-v2: Boosting task planning and tool usage of large language model-based agents in real-world systems. arXiv preprint arXiv:2311.11315, 2023.  \n[112] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. Metagpt: Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352, 2023.  \n[113] Yi Yang, Yixuan Tang, and Kar Yan Tam. Investlm: A large language model for investment using financial domain instruction tuning. arXiv preprint arXiv:2309.13064, 2023.  \n[114] Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, and Zhi Jin. Codeagent: Enhancing code generation with tool-integrated agent systems for real-world repo-level coding challenges. arXiv preprint arXiv:2401.07339, 2024.  \n[115] Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge. arXiv preprint arXiv:2303.14070, 2023.  \n[116] Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica, Xuezhe Ma, and Hao Zhang. How long can context length of open-source llms truly promise? In NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following, 2023.  \n[117] Ziheng Huang, Sebastian Gutierrez, Hemanth Kamana, and Stephen MacNeil. Memory sandbox: Transparent and interactive memory management for conversational agents. In Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, pages 1-3, 2023.  \n[118] Arka Pal, Deep Karkhanis, Manley Roberts, Samuel Dooley, Arvind Sundararajan, and Siddartha Naidu. Giraffe: Adventures in expanding context lengths in llms. arXiv preprint arXiv:2308.10882, 2023.  \n[119] Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, and Piotr Miłos. Focused transformer: Contrastive training for context scaling, 2023.  \n[120] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts. arXiv preprint arXiv:2307.03172, 2023.  \n[121] Peter J Denning. The locality principle. Communications of the ACM, 48(7):19-24, 2005.\n\n[122] Hermann Ebbinghaus. Memory: A contribution to experimental psychology, trans. HA Ruger & CE Bussenius. Teachers College.[rWvH], 1885.  \n[123] Jaap MJ Murre and Joeri Dros. Replication and analysis of ebbinghaus' forgetting curve. *PloS one*, 10(7):e0120644, 2015.  \n[124] Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus. IEEE Transactions on Big Data, 7(3):535-547, 2019.  \n[125] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.  \n[126] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis. arXiv preprint arXiv:2307.16789, 2023.  \n[127] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.  \n[128] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang, Minlie Huang, Nan Duan, Weizhu Chen, et al. Tora: A tool-integrated reasoning agent for mathematical problem solving. arXiv preprint arXiv:2309.17452, 2023.  \n[129] Honglin Xiong, Sheng Wang, Yitao Zhu, Zihao Zhao, Yuxiao Liu, Qian Wang, and Dinggang Shen. Doctoral: Fine-tuning your chinese doctor is not a herculean task. arXiv preprint arXiv:2304.01097, 2023.  \n[130] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414, 2022.  \n[131] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuzhhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021.  \n[132] Zhengliang Liu, Aoxiao Zhong, Yiwei Li, Longtao Yang, Chao Ju, Zihao Wu, Chong Ma, Peng Shu, Cheng Chen, Sekeun Kim, et al. Radiology-gpt: A large language model for radiology. arXiv preprint arXiv:2306.08666, 2023.  \n[133] Nicola De Cao, Wilker Aziz, and Ivan Titov. Editing factual knowledge in language models. arXiv preprint arXiv:2104.08164, 2021.  \n[134] Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. Fast model editing at scale. arXiv preprint arXiv:2110.11309, 2021.  \n[135] Shengyu Mao, Ningyu Zhang, Xiaohan Wang, Mengru Wang, Yunzhi Yao, Yong Jiang, Pengjun Xie, Fei Huang, and Huajun Chen. Editing personality for large language models. 2023.  \n[136] Jun-Yu Ma, Jia-Chen Gu, Ningyu Zhang, and Zhen-Hua Ling. Neighboring perturbations of knowledge editing on large language models. arXiv preprint arXiv:2401.17623, 2024.  \n[137] Mengru Wang, Ningyu Zhang, Ziwen Xu, Zekun Xi, Shumin Deng, Yunzhi Yao, Qishen Zhang, Linyi Yang, Jindong Wang, and Huajun Chen. Detoxifying large language models via knowledge editing. arXiv preprint arXiv:2403.14472, 2024.  \n[138] Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, and Omer Levy. Zeroscrolls: A zero-shot benchmark for long text understanding. arXiv preprint arXiv:2305.14196, 2023.  \n[139] Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, et al. Longbench: A bilingual, multitask benchmark for long context understanding. arXiv preprint arXiv:2308.14508, 2023.\n\n[140] Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica, Xuezhe Ma, and Hao Zhang. How long can context length of open-source llms truly promise? In NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following, 2023.  \n[141] Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. Alfworld: Aligning text and embodied environments for interactive learning. arXiv preprint arXiv:2010.03768, 2020.  \n[142] YunDa Tsai, Mingjie Liu, and Haoxing Ren. Rtlfixer: Automatically fixing rtI syntax errors with large language models. arXiv preprint arXiv:2311.16543, 2023.  \n[143] Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi Mi, Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, et al. Chatharuhi: Reviving anime character in reality via large language model. arXiv preprint arXiv:2308.09597, 2023.  \n[144] Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, and Haoyang Zhang. Gamegpt: Multiagent collaborative framework for game development. arXiv preprint arXiv:2310.08067, 2023.  \n[145] Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, et al. Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models. arXiv preprint arXiv:2310.00746, 2023.  \n[146] Runcong Zhao, Wenjia Zhang, Jiazheng Li, Lixing Zhu, Yanran Li, Yulan He, and Lin Gui. Narrativeplay: Interactive narrative understanding. arXiv preprint arXiv:2310.01459, 2023.  \n[147] Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, et al. Characterglm: Customizing chinese conversational ai characters with large language models. arXiv preprint arXiv:2311.16832, 2023.  \n[148] Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes, Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, and Andrew Ahn. Lyfe agents: Generative agents for low-cost real-time social interactions. arXiv preprint arXiv:2310.02172, 2023.  \n[149] Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. Agentcf: Collaborative learning with autonomous language agents for recommender systems. arXiv preprint arXiv:2310.09233, 2023.  \n[150] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. War and peace (waragent): Large language model-based multi-agent simulation of world wars. arXiv preprint arXiv:2311.17227, 2023.  \n[151] Haochun Wang, Sendong Zhao, Zewen Qiang, Zijian Li, Nuwa Xi, Yanrui Du, MuZhen Cai, Haoqiang Guo, Yuhan Chen, Haoming Xu, et al. Knowledge-tuning large language models with structured medical knowledge bases for reliable response generation in chinese. arXiv preprint arXiv:2309.04175, 2023.  \n[152] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce Ho, Carl Yang, and May D Wang. Ehragent: Code empowers large language models for complex tabular reasoning on electronic health records. arXiv preprint arXiv:2401.07128, 2024.  \n[153] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155, 2023.  \n[154] Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and Khaldoun Khashanah. Tradinggpt: Multiagent system with layered memory and distinct characters for enhanced financial trading performance. arXiv preprint arXiv:2309.03736, 2023.  \n[155] Saizhuo Wang, Hang Yuan, Lionel M Ni, and Jian Guo. Quantagent: Seeking holy grail in trading by self-improving large language model. arXiv preprint arXiv:2402.03755, 2024.\n\n[156] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong Liu, Jordan W Suchow, and Khaldoun Khashanah. Finmem: A performance-enhanced llm trading agent with layered memory and character design. arXiv e-prints, pages arXiv-2311, 2023.  \n[157] Kelvin JL Koa, Yunshan Ma, Ritchie Ng, and Tat-Seng Chua. Learning to generate explainable stock predictions using self-reflective large language models. arXiv preprint arXiv:2402.03659, 2024.  \n[158] Kexin Chen, Junyou Li, Kunyi Wang, Yuyang Du, Jiahui Yu, Jiamin Lu, Lanqing Li, Jiezhong Qiu, Jianzhang Pan, Yi Huang, Qun Fang, Pheng Ann Heng, and Guangyong Chen. Chemist-x: Large language model-empowered agent for reaction condition recommendation in chemical synthesis, 2024.  \n[159] Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, et al. Jarvis-1: Open-world multi-task agents with memory-augmented multimodal language models. arXiv preprint arXiv:2311.05997, 2023.  \n[160] Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Hongshen Xu, Zichen Zhu, Su Zhu, Shuai Fan, Guodong Shen, et al. Chemdfm: Dialogue foundation model for chemistry. arXiv preprint arXiv:2401.14818, 2024.  \n[161] Ming Yan, Ruihao Li, Hao Zhang, Hao Wang, Zhilan Yang, and Ji Yan. Larp: Language-agent role play for open-world games. arXiv preprint arXiv:2312.17653, 2023.  \n[162] Zi-Yi Chen, Fan-Kai Xie, Meng Wan, Yang Yuan, Miao Liu, Zong-Guo Wang, Sheng Meng, and Yan-Gang Wang. Matchat: A large language model and application service platform for materials science. Chinese Physics B, 32(11):118104, 2023.  \n[163] Nian Li, Chen Gao, Yong Li, and Qingmin Liao. Large language model-empowered agents for simulating macroeconomic activities. arXiv preprint arXiv:2310.10436, 2023.  \n[164] Haojie Pan, Zepeng Zhai, Hao Yuan, Yaojia Lv, Ruiji Fu, Ming Liu, Zhongyuan Wang, and Bing Qin. Kwaiagents: Generalized information-seeking agent system with large language models. arXiv preprint arXiv:2312.04889, 2023.  \n[165] Odma Byambasuren, Yunfei Yang, Zhifang Sui, Damai Dai, Baobao Chang, Sujian Li, and Hongying Zan. Preliminary study on the construction of chinese medical knowledge graph. Journal of Chinese Information Processing, 33(10):1-9, 2019.  \n[166] Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Lunting Fan, Lingfei Wu, and Qingsong Wen. Rcagent: Cloud root cause analysis by autonomous agents with tool-augmented large language models. arXiv preprint arXiv:2310.16340, 2023.  \n[167] Zhangcheng Qiang, Weiqing Wang, and Kerry Taylor. Agent-om: Leveraging large language models for ontology matching. arXiv preprint arXiv:2312.00326, 2023.  \n[168] Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao Ma, Pinlong Cai, Min Dou, Botian Shi, Liang He, and Yu Qiao. Dilu: A knowledge-driven approach to autonomous driving with large language models. arXiv preprint arXiv:2309.16292, 2023.  \n[169] Zhitao Wang, Wei Wang, Zirao Li, Long Wang, Can Yi, Xinjie Xu, Luyang Cao, Hanjing Su, Shouzhi Chen, and Jun Zhou. Xuat-copilot: Multi-agent collaborative system for automated user acceptance testing with large language model. arXiv preprint arXiv:2401.02705, 2024.  \n[170] Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and Chuchu Fan. Scalable multirobot collaboration with large language models: Centralized or decentralized systems? arXiv preprint arXiv:2309.15943, 2023.  \n[171] Zhao Mandi, Shreeya Jain, and Shuran Song. Roco: Dialectic multi-robot collaboration with large language models. arXiv preprint arXiv:2307.04738, 2023.  \n[172] Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu. From text to tactic: Evaluating llms playing the game of avalon. arXiv preprint arXiv:2310.05036, 2023.\n\n[173] Bing Liu. Lifelong machine learning: a paradigm for continuous learning. Frontiers of Computer Science, 11:359-361, 2017.  \n[174] Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. Using large language models to simulate multiple humans and replicate human subject studies. In International Conference on Machine Learning, pages 337-371. PMLR, 2023.",
    "arxiv_id": "2404.13501",
    "error_message": "'\\n  \"paper_type\"'",
    "embedding": [
      -0.75,
      -0.79296875,
      -1.1171875,
      -2.3125,
      -4.78125,
      1,
      -1.4375,
      -1.390625,
      3.46875,
      1.84375,
      1.171875,
      2.515625,
      3.328125,
      2.140625,
      -0.9609375,
      2.109375,
      0.1103515625,
      0.97265625,
      2.578125,
      -5.8125,
      1.3515625,
      2.328125,
      -0.46484375,
      -6.53125,
      3.703125,
      -5,
      1.65625,
      3.5,
      1.9453125,
      -4.125,
      8.125,
      -6.34375,
      -0.8046875,
      -1.171875,
      2.546875,
      2.40625,
      -3.359375,
      -4.21875,
      6.96875,
      3.4375,
      -7.09375,
      -0.94921875,
      0.431640625,
      1.828125,
      -0.83203125,
      3.4375,
      -0.625,
      -1.4453125,
      -4.21875,
      -0.232421875,
      -5,
      -2.640625,
      6.71875,
      -2.25,
      5.03125,
      -5.78125,
      -5.5,
      5.25,
      -2.796875,
      -1.625,
      1.21875,
      0.8984375,
      2.265625,
      -2.5625,
      2.859375,
      1.1328125,
      2.75,
      3.484375,
      -1.6953125,
      3.09375,
      -1.65625,
      -3.40625,
      6.125,
      -4.5625,
      9.9375,
      5.875,
      0.9375,
      1.0390625,
      -1.25,
      5.90625,
      -3.75,
      3.046875,
      3.890625,
      2.390625,
      6.03125,
      2.765625,
      -3.296875,
      -0.859375,
      -2.703125,
      1.53125,
      -1.0234375,
      2.390625,
      -0.34765625,
      -0.0269775390625,
      -1.6875,
      5.09375,
      -1.46875,
      -4.09375,
      -6.3125,
      0.049560546875,
      -2.796875,
      -2.59375,
      1.6953125,
      -5.65625,
      -4.21875,
      -2.265625,
      -5.21875,
      -5.8125,
      -1.171875,
      -2.65625,
      0.625,
      2.25,
      3.328125,
      -2.6875,
      2.375,
      0.59375,
      2.609375,
      -3.546875,
      -7.40625,
      1.4296875,
      3.3125,
      -0.1650390625,
      -0.64453125,
      0.0299072265625,
      4.96875,
      2.125,
      -5.59375,
      2.75,
      7.8125,
      -3.390625,
      5.5,
      1.046875,
      2.390625,
      -1.1640625,
      -7.5,
      -3.6875,
      -3.78125,
      6.15625,
      5.625,
      7.25,
      -5.21875,
      0.33203125,
      -1.109375,
      -5.75,
      4.75,
      0.76171875,
      -4.90625,
      1.4609375,
      7.5,
      -2.875,
      -1.4296875,
      2.109375,
      4,
      7.21875,
      -2.90625,
      -5.5,
      1.8046875,
      -2.4375,
      1.1328125,
      -1.6875,
      1.421875,
      2.921875,
      0.5703125,
      0.96484375,
      -1.2421875,
      -1.9140625,
      -5.15625,
      1.8046875,
      0.578125,
      0.09326171875,
      4.21875,
      15.5625,
      0.96875,
      -1.3828125,
      -1.53125,
      2.203125,
      -4.375,
      6.9375,
      3.8125,
      -1.4765625,
      1.296875,
      0.5078125,
      -2.3125,
      1.5390625,
      -2.375,
      0.333984375,
      1.71875,
      -2.875,
      1.890625,
      -4,
      2.796875,
      3.359375,
      1.546875,
      -1.9453125,
      -4.4375,
      0.671875,
      1.921875,
      -1.6875,
      0.4921875,
      1.015625,
      0.78515625,
      -8.375,
      0.3984375,
      -2.53125,
      -1.8125,
      -3.734375,
      1.8984375,
      -1.78125,
      -0.2333984375,
      -0.16015625,
      1.1484375,
      2.78125,
      3.984375,
      -1.2265625,
      7.03125,
      3.484375,
      2.15625,
      -4.15625,
      5.15625,
      2.390625,
      2.40625,
      4.0625,
      6.25,
      0.73046875,
      0.1298828125,
      2.546875,
      1.09375,
      2.75,
      2.578125,
      7.8125,
      3.140625,
      3.703125,
      5.21875,
      -4.3125,
      -3.859375,
      -2.578125,
      -3.9375,
      0.984375,
      -3,
      2.34375,
      -2.96875,
      -3.234375,
      1.5234375,
      3.234375,
      4.40625,
      -2.078125,
      -1.078125,
      -1.359375,
      -2.234375,
      -7.34375,
      2.15625,
      4.1875,
      -8.25,
      -0.54296875,
      3.296875,
      7,
      2.265625,
      -1.359375,
      -0.76171875,
      -4.59375,
      3.671875,
      -4.21875,
      -5.625,
      1.3671875,
      2.78125,
      -2.359375,
      4.375,
      -1.34375,
      4.75,
      4.09375,
      0.58203125,
      0.447265625,
      0.8828125,
      1.2109375,
      -2.5625,
      5.875,
      2.53125,
      -4.3125,
      1.9921875,
      -1.125,
      -6.46875,
      -7.96875,
      3.734375,
      -3.453125,
      4.28125,
      -1.1796875,
      1.7109375,
      6.40625,
      -5,
      13.75,
      5.6875,
      2.609375,
      -0.474609375,
      -0.87890625,
      -3.25,
      3.578125,
      -5.15625,
      1.421875,
      -4.78125,
      -0.7421875,
      3.1875,
      -0.357421875,
      -0.50390625,
      -2.0625,
      -1.6796875,
      3.296875,
      -0.439453125,
      -5,
      -4.34375,
      -0.06640625,
      -3.734375,
      1.7578125,
      7.96875,
      -2.515625,
      3.390625,
      -1.578125,
      -2.40625,
      5.03125,
      3.65625,
      -3.375,
      -5.40625,
      -4.21875,
      -1.7109375,
      -4.3125,
      -2.4375,
      -1.484375,
      2.3125,
      0.95703125,
      3.734375,
      -1.0078125,
      2.625,
      1.671875,
      -6.40625,
      -9.3125,
      8.3125,
      0.48828125,
      2.5625,
      2.421875,
      1.7265625,
      2.0625,
      -1.96875,
      -3.9375,
      2.15625,
      -3.28125,
      -1.328125,
      0.40625,
      2.453125,
      -1.3984375,
      3.453125,
      -7.21875,
      2.03125,
      1.09375,
      0.99609375,
      2.625,
      8.5,
      0.09033203125,
      3.265625,
      -3.203125,
      0.9296875,
      0.6171875,
      -0.318359375,
      -3.59375,
      7.90625,
      -2.1875,
      -3.734375,
      -2.84375,
      -0.1689453125,
      2.765625,
      0.193359375,
      -3.390625,
      1.0703125,
      -4.84375,
      4.15625,
      -1.1796875,
      1.1875,
      1.3984375,
      2.046875,
      -3.3125,
      -4.5,
      2.109375,
      -3.671875,
      -2.6875,
      1.2265625,
      0.9296875,
      4.5625,
      2.140625,
      -1.234375,
      4.59375,
      2.140625,
      -0.6796875,
      -2.4375,
      0.19921875,
      -2.875,
      0.1728515625,
      5.0625,
      0.484375,
      -1.921875,
      1.9921875,
      -2.53125,
      -1.40625,
      2.84375,
      1.4296875,
      0.453125,
      -3.265625,
      -4.59375,
      0.578125,
      0.333984375,
      -6.78125,
      -1.34375,
      0.7421875,
      -2.265625,
      1.703125,
      -0.23046875,
      -0.158203125,
      0.49609375,
      3.921875,
      0.353515625,
      2.859375,
      -5.5625,
      -2.15625,
      -1.4140625,
      0.91796875,
      2.46875,
      -2.859375,
      1.25,
      -1.859375,
      1.25,
      6.375,
      -0.8359375,
      3.328125,
      1.6328125,
      0.69921875,
      -4.09375,
      2.328125,
      -2.109375,
      -2.5,
      1.2890625,
      -3.5625,
      -6.1875,
      1.2109375,
      1.5546875,
      -2.4375,
      4.5,
      4.90625,
      -5.96875,
      -3.8125,
      4.09375,
      3.234375,
      -3.71875,
      -1.34375,
      -1.75,
      0.6328125,
      -3.078125,
      0.154296875,
      1.9765625,
      0.01708984375,
      -3.671875,
      2.09375,
      4.09375,
      0.3671875,
      0.66015625,
      -1.3515625,
      -3.109375,
      -0.177734375,
      1.9296875,
      -2.578125,
      0.302734375,
      5,
      4.78125,
      -7.375,
      -8.6875,
      5.125,
      -1.484375,
      -3.203125,
      -2.78125,
      2.34375,
      1.125,
      4.0625,
      -6.15625,
      -5.34375,
      -0.310546875,
      0.66015625,
      2.21875,
      2.234375,
      -0.88671875,
      -0.416015625,
      -3.375,
      6.71875,
      1.7734375,
      5.53125,
      0.66015625,
      -1.0078125,
      3.015625,
      -4.65625,
      1.75,
      0.1220703125,
      8.75,
      -1.0625,
      0.248046875,
      1.890625,
      -10,
      0.26171875,
      -2.828125,
      -0.95703125,
      -1.0234375,
      -0.2490234375,
      5.03125,
      -1.7890625,
      0.1611328125,
      0.01507568359375,
      3.109375,
      -1.296875,
      -2.859375,
      2.65625,
      -5.46875,
      -3.53125,
      2.78125,
      3.25,
      2.15625,
      -2.65625,
      -2.96875,
      -1.265625,
      3.15625,
      -2.15625,
      0.484375,
      -0.60546875,
      0.298828125,
      -2.265625,
      1.515625,
      4.75,
      0.765625,
      1.515625,
      -0.16015625,
      -3.75,
      -1.78125,
      0.158203125,
      1.2421875,
      -0.265625,
      1.609375,
      1.2109375,
      0.494140625,
      1,
      -2.046875,
      -0.201171875,
      0.2490234375,
      -0.31640625,
      -3.875,
      1.6953125,
      -0.9296875,
      4.96875,
      1.6171875,
      1.1953125,
      -2.234375,
      -0.98046875,
      2.625,
      -4.5,
      -4.46875,
      -2.984375,
      2.59375,
      -1.0546875,
      -1.875,
      -1.3671875,
      -0.27734375,
      -0.259765625,
      1.3125,
      -1.265625,
      2.6875,
      5.8125,
      1.9140625,
      2.421875,
      2.375,
      4.46875,
      -4.09375,
      -0.353515625,
      1.2265625,
      1.7734375,
      -2.921875,
      -7.8125,
      -3.046875,
      2.015625,
      7.4375,
      -2.109375,
      2.078125,
      -4.90625,
      5.71875,
      -0.056640625,
      0.59765625,
      -14.5625,
      1.9375,
      -0.79296875,
      -4.84375,
      -1.2578125,
      -4.0625,
      2.28125,
      -2.484375,
      3.203125,
      0.53515625,
      -1.4296875,
      0.443359375,
      4.96875,
      1.390625,
      0.82421875,
      1.28125,
      1.703125,
      -2.296875,
      2.125,
      -6.0625,
      -0.83984375,
      0.201171875,
      -2.390625,
      1.2421875,
      2.9375,
      4.71875,
      -2.53125,
      0.365234375,
      3.921875,
      -4.21875,
      -0.455078125,
      3.546875,
      2.703125,
      -2.15625,
      -3.609375,
      -2.375,
      7.4375,
      -5,
      3.734375,
      0.39453125,
      -1.03125,
      2.5,
      6.5,
      -4.03125,
      -1.859375,
      -3.015625,
      1.5546875,
      4.65625,
      5.53125,
      -5.84375,
      0.859375,
      0.703125,
      0.8359375,
      3.703125,
      -0.185546875,
      -0.92578125,
      -2.796875,
      4.40625,
      2,
      -1.8515625,
      5.625,
      2.15625,
      -5.09375,
      -1.21875,
      1.640625,
      -1.640625,
      1.9921875,
      1.375,
      -1.9453125,
      1.0625,
      1.609375,
      3.21875,
      -3.890625,
      -4.9375,
      -1.4140625,
      2.359375,
      -6.96875,
      2.9375,
      -1.9921875,
      -1.15625,
      -2.09375,
      -1.3671875,
      2.15625,
      3.984375,
      2.65625,
      -0.97265625,
      5.375,
      5.28125,
      -2.40625,
      1.28125,
      -5.46875,
      -4.03125,
      0.17578125,
      -3.890625,
      -0.84765625,
      2.171875,
      1.421875,
      -0.255859375,
      -3.578125,
      -2.0625,
      -5.0625,
      -4.46875,
      -2.515625,
      4.09375,
      -1.390625,
      0.498046875,
      -2.546875,
      3.5,
      -1.6015625,
      -4.5625,
      1.09375,
      -0.310546875,
      -2.71875,
      -0.33203125,
      1.125,
      -4.96875,
      -0.95703125,
      6.4375,
      2.78125,
      -2.15625,
      7.46875,
      2.8125,
      -3.71875,
      -2.0625,
      3.609375,
      -1.6171875,
      2.171875,
      0.2412109375,
      -2.5625,
      -2.015625,
      -0.953125,
      0.6015625,
      -1.25,
      2.6875,
      -2.453125,
      0.76171875,
      -0.11572265625,
      -5.375,
      -2.234375,
      -0.85546875,
      -1.5859375,
      0.443359375,
      3.59375,
      -0.2412109375,
      -4.46875,
      5.125,
      1.65625,
      3.90625,
      2.421875,
      2.53125,
      3.140625,
      -0.224609375,
      2.1875,
      -4.125,
      -3.96875,
      0.28125,
      1.4765625,
      -1.25,
      2.328125,
      1.3671875,
      -1.03125,
      0.6875,
      1.8125,
      -5.40625,
      -4.9375,
      2.734375,
      -3.125,
      -1.875,
      -1.484375,
      1.9375,
      0.8359375,
      2.125,
      0.3828125,
      -2.171875,
      -0.337890625,
      3.5625,
      2.8125,
      -0.703125,
      -2.671875,
      2.03125,
      2.203125,
      3.03125,
      -4.9375,
      -4.625,
      -1.5390625,
      0.158203125,
      -0.51171875,
      -0.76171875,
      8.4375,
      -3.859375,
      1.7578125,
      -0.95703125,
      0.68359375,
      2.90625,
      -0.3828125,
      0.703125,
      -1.5390625,
      -1.15625,
      1.5,
      -0.89453125,
      -0.73828125,
      -2.65625,
      -1.671875,
      -0.2158203125,
      0.283203125,
      -1.5,
      2,
      -0.1494140625,
      0.1884765625,
      -2.765625,
      3.640625,
      -1.1953125,
      6.8125,
      7.90625,
      -1.5625,
      0.66015625,
      0.8828125,
      3.546875,
      -1.1484375,
      3.375,
      0.412109375,
      8.25,
      -3.875,
      -4.09375,
      5,
      -2.140625,
      1.2421875,
      1.609375,
      -7.875,
      -4,
      -0.8671875,
      -0.3984375,
      -0.53125,
      0.87890625,
      -6.03125,
      -0.6953125,
      5.75,
      2.234375,
      3.859375,
      4.375,
      7.1875,
      1.1640625,
      -1.2265625,
      -5.5625,
      -1.6328125,
      -1.65625,
      0.05517578125,
      3.046875,
      -3.40625,
      2.515625,
      3.953125,
      5.0625,
      -0.953125,
      -1.8203125,
      -3.9375,
      6.46875,
      1.1640625,
      -0.61328125,
      2.328125,
      -1.859375,
      1.7734375,
      0.8828125,
      3.078125,
      -3.671875,
      -0.2578125,
      4.15625,
      4.9375,
      -2.25,
      2.078125,
      0.40625,
      1.3515625,
      -3.8125,
      -2.625,
      -1.703125,
      0.208984375,
      -4.34375,
      0.287109375,
      -1.4453125,
      2.921875,
      -5.53125,
      0.578125,
      -2.03125,
      -3.21875,
      1.921875,
      -0.439453125,
      -0.03564453125,
      3.828125,
      2.96875,
      4.71875,
      -0.12255859375,
      -2.265625,
      -3.953125,
      -7.03125,
      -2.75,
      -1.421875,
      1.2734375,
      3.890625,
      0.0224609375,
      -2.453125,
      3.640625,
      -4.40625,
      1.4921875,
      -5.28125,
      4.59375,
      3.65625,
      -3.625,
      0.435546875,
      -1.75,
      -5.84375,
      -3.765625,
      -1.5,
      -3.328125,
      -2.265625,
      -3.59375,
      1.59375,
      1.1328125,
      -3.03125,
      -2.265625,
      -2.78125,
      -0.76171875,
      -0.47265625,
      1.5234375,
      1.8359375,
      -2.078125,
      2.828125,
      3.234375,
      -1.7890625,
      1.671875,
      2.875,
      1.328125,
      5.625,
      -1.421875,
      1.46875,
      -2.921875,
      5.90625,
      -3.015625,
      8.75,
      4.09375,
      -0.5625,
      -5.125,
      2.375,
      -2.21875,
      0.337890625,
      -5.9375,
      0.91796875,
      -1.171875,
      -2.359375,
      2.390625,
      -1.21875,
      -1.5859375,
      -6.4375,
      -1.4453125,
      -1.0234375,
      -3.609375,
      2.296875,
      5.9375,
      -1.4453125,
      7.375,
      1.1171875,
      0.72265625,
      -0.69140625,
      0.490234375,
      0.82421875,
      -2.59375,
      2.875,
      -4.3125,
      2.515625,
      -1.1484375,
      -2.71875,
      -0.294921875,
      -4.21875,
      -0.7734375,
      2.328125,
      -0.15625,
      3.671875,
      2.453125,
      4.1875,
      -1.0703125,
      4.625,
      -1.328125,
      -0.66015625,
      0.68359375,
      -2.15625,
      2.234375,
      1.453125,
      0.3984375,
      0.48828125,
      1.34375,
      -2.890625,
      0.93359375,
      0.4140625,
      -9.75,
      -2.359375,
      -3.84375,
      -3.015625,
      5.4375,
      -0.035400390625,
      1.421875,
      0.9453125,
      1.7890625,
      2.703125,
      5.71875,
      0.984375,
      0.400390625,
      -0.91015625,
      -0.228515625,
      3.5,
      -0.2451171875,
      -2.265625,
      2.421875,
      -0.4375,
      4.5625,
      -0.73828125,
      -1.28125,
      -3.890625,
      -2.5625,
      4.875,
      -2.046875,
      -0.2431640625,
      8.25,
      0.9921875,
      -2.015625,
      1.1328125,
      -2.078125,
      1,
      -3.34375,
      -0.71484375,
      8.5625,
      6.3125,
      -2.78125,
      -1.09375,
      -5.1875,
      -2.15625,
      -0.46875,
      2.65625,
      -0.3984375,
      1.9921875,
      1.796875,
      1.8359375,
      0.99609375,
      0.126953125,
      0.55859375,
      -5.3125,
      -0.921875,
      2.140625,
      1.9765625,
      2.34375,
      -1.59375,
      1.796875,
      -5.15625,
      2.109375,
      1.6875,
      -4.0625,
      0.76171875,
      1.359375,
      -1.4453125,
      6.71875,
      3.984375,
      2.46875,
      1.0859375,
      -2.8125,
      -3.46875,
      -1.4453125,
      0.671875,
      3.46875,
      -3.890625,
      -1.2734375,
      3.890625,
      2.171875,
      0.77734375,
      3.625,
      -0.119140625,
      -0.435546875,
      2.15625,
      -2.03125,
      -6.75,
      -3.125,
      -0.5703125,
      -1.75,
      -0.51171875,
      -2.234375,
      1.390625,
      1.8203125,
      -4.9375,
      3.484375,
      -3.09375,
      5.53125,
      0.2353515625,
      -3.875,
      1.796875,
      -2.21875,
      2.6875,
      -2.8125,
      2.328125,
      -0.71875,
      -1.34375,
      2.25,
      -3.78125,
      -0.1044921875,
      -2.8125,
      -0.8203125,
      2.46875,
      -1.109375,
      -0.4765625,
      -3.9375,
      3.046875,
      -6.625,
      -3.8125,
      -1.34375,
      2.03125,
      1.5859375,
      -0.50390625,
      0.94921875,
      -0.30859375,
      4.15625,
      -3.1875,
      1.75,
      -3.5,
      -1.921875,
      2.15625,
      -2.140625,
      3.8125,
      3.234375,
      -1.875,
      1.71875,
      -4.25,
      -4.84375,
      -2.15625,
      -0.2333984375,
      2.625,
      -4,
      0.29296875,
      0.97265625,
      0.408203125,
      -2.03125,
      1.65625,
      1.375,
      4.875,
      2.75,
      -0.90625,
      2.9375,
      -0.69921875,
      0.72265625,
      -4.9375,
      -2.71875,
      -4.25,
      4.75,
      3.15625,
      -2.640625,
      4.09375,
      -0.208984375,
      -0.326171875,
      2.453125,
      -1.6015625,
      -2.640625,
      -0.404296875,
      4.71875,
      -2.859375,
      -0.2578125,
      3.65625,
      -1.3828125,
      2.21875,
      -0.796875,
      -1.8359375,
      -4.46875,
      0.859375,
      -3.25,
      0.59375,
      -0.10693359375,
      -1.0703125,
      -3.015625,
      1.203125,
      -3.421875,
      -2.109375,
      5.96875,
      3.796875,
      2.0625,
      1.578125,
      0.267578125,
      -2.234375,
      0.68359375,
      -2.015625,
      4.21875,
      1.3203125,
      -2.1875,
      4.25,
      -1.7890625,
      3.046875,
      -3.234375,
      -1.7734375,
      -7.03125,
      0.33203125,
      7.25,
      3,
      -0.98046875,
      -0.765625,
      1.1484375,
      2.015625,
      -1.8671875,
      3.609375,
      -1.515625,
      -0.73828125,
      -0.279296875,
      3.96875,
      3.140625,
      -6.78125,
      0.55078125,
      1.25,
      -1.6171875,
      4.3125,
      5.03125,
      4.65625,
      0.400390625,
      3.015625,
      2.15625,
      -3.375,
      -7.03125,
      2.921875,
      -0.7890625,
      1.4140625,
      -1.3046875,
      -0.474609375,
      -0.5078125,
      -1.8125,
      0.255859375,
      4.46875,
      -0.30859375,
      4.0625,
      -0.48828125,
      2.09375,
      2.765625,
      -1.1015625,
      -2.984375,
      4.96875,
      -0.279296875,
      -4.71875,
      0.283203125,
      -6.09375,
      1.5625,
      -1.9296875,
      -7.40625,
      -1.4765625,
      3.453125,
      -1.484375,
      6.9375,
      0.8828125,
      -0.90625,
      -1.4921875,
      0.1240234375,
      2.0625,
      -2.203125,
      0.408203125,
      0.58203125,
      0.0059814453125,
      -0.6875,
      2.296875,
      -2.484375,
      -2.84375,
      -1.1171875,
      3.0625,
      -0.984375,
      6.5625,
      0.71875,
      1.3515625,
      -5.03125,
      0.69921875,
      -3.109375,
      -0.91015625,
      -2.984375,
      -0.498046875,
      -0.26953125,
      3.4375,
      0.92578125,
      1.203125,
      -6.15625,
      1.578125,
      -4.21875,
      5.28125,
      -0.28515625,
      1.671875,
      -2.546875,
      2.078125,
      -3.625,
      -2.515625,
      2.890625,
      0.1611328125,
      -3.375,
      2.140625,
      -2.359375,
      0.9609375,
      2.5625,
      -0.1748046875,
      -2.671875,
      4.53125,
      -0.81640625,
      0.3828125,
      -4.96875,
      1.953125,
      0.46875,
      -2.90625,
      3.5625,
      -3.25,
      -1.046875,
      -3.65625,
      -3.25,
      -2.15625,
      -1.1171875,
      0.79296875,
      2.234375,
      2.640625,
      -0.11572265625,
      -0.115234375,
      -3.921875,
      6.40625,
      3.328125,
      -0.53125,
      3.546875,
      -0.0380859375,
      0.84375,
      -3.90625,
      4.4375,
      1.7734375,
      0.08349609375,
      3.40625,
      3.671875,
      -2.53125,
      -1.515625,
      3.21875,
      3.03125,
      -0.78125,
      -0.78515625,
      0.2578125,
      7.28125,
      -4.46875,
      2.3125,
      -3.859375,
      -0.91796875,
      2.15625,
      -2.6875,
      3.375,
      -1.265625,
      0.2734375,
      -4.65625,
      -1.234375,
      3.78125,
      1.7890625,
      3.890625,
      -2.640625,
      1.03125,
      3.28125,
      0.89453125,
      3.328125,
      -2.296875,
      -5.46875,
      -0.9609375,
      2.8125,
      -6.9375,
      -3.59375,
      -6.75,
      -0.326171875,
      -2.921875,
      -0.765625,
      -1.40625,
      2.171875,
      -1.6328125,
      -0.41015625,
      -3.375,
      -2.34375,
      -2.96875,
      -3.984375,
      3.03125,
      -2.078125,
      -6.1875,
      0.4765625,
      1.109375,
      6.625,
      4.21875,
      6.90625,
      3.578125,
      -1.90625,
      -0.1328125,
      -0.462890625,
      -0.423828125,
      -1.59375,
      2.640625,
      -0.310546875,
      -0.83203125,
      -0.75,
      -0.33984375,
      2.828125,
      -6.1875,
      -3.671875,
      -1.03125,
      -4.09375,
      0.94140625,
      1.2421875,
      -2.265625,
      0.34375,
      5.5625,
      -0.734375,
      2.84375,
      0.38671875,
      -2.890625,
      -3.109375,
      3.5,
      0.1962890625,
      2.671875,
      4,
      0.09130859375,
      -6.03125,
      1.75,
      2.859375,
      -0.267578125,
      3.265625,
      4.53125,
      -0.7578125,
      -5.34375,
      3.0625,
      3.171875,
      5.1875,
      -2.203125,
      0.035400390625,
      3.78125,
      -0.86328125,
      4.34375,
      2.609375,
      -1.3828125,
      -1.03125,
      2.875,
      3.140625,
      -3.25,
      -1.53125,
      3.25,
      -2.375,
      -1.90625,
      2.84375,
      0.5546875,
      4.09375,
      -0.86328125,
      0.73046875,
      1.53125,
      3.359375,
      -3.8125,
      0.69140625,
      -5.21875,
      3.0625,
      -5.0625,
      2.0625,
      -10.1875,
      0.2333984375,
      1.5625,
      4.59375,
      -1.5859375,
      -2.78125,
      2.96875,
      5.03125,
      -2.75,
      -2.46875,
      4.78125,
      0.68359375,
      0.6953125,
      -3.1875,
      -2.8125,
      -0.7578125,
      -0.984375,
      0.72265625,
      -3.1875,
      3.203125,
      -1.5625,
      -4.3125,
      -5.40625,
      2.09375,
      -0.466796875,
      -4.09375,
      -4.28125,
      -4.375,
      -0.2333984375,
      -3.640625,
      6.46875,
      3.578125,
      -0.69140625,
      0.84765625,
      1,
      1.25,
      1.6796875,
      -0.048583984375,
      -0.20703125,
      2.171875,
      -3.09375,
      0.8984375,
      2.28125,
      -2.328125,
      3.171875,
      -1.4140625,
      1.9296875,
      2.953125,
      -4.25,
      0.3515625,
      -4.40625,
      1.6796875,
      1.4453125,
      3.34375,
      1.1796875,
      -3.6875,
      -0.97265625,
      2.109375,
      -2.703125,
      -1.9453125,
      0.14453125,
      -1,
      0.0830078125,
      1.4453125,
      -0.73828125,
      6,
      1.828125,
      3.546875,
      -0.04296875,
      0.03125,
      -2.625,
      0.7265625,
      -4.03125,
      1.8515625,
      -1,
      5.3125,
      -2.15625,
      -0.33984375,
      0.77734375,
      2.140625,
      -0.3828125,
      -0.85546875,
      0.373046875,
      0.431640625,
      0.8515625,
      3.40625,
      0.3125,
      -4.3125,
      3.640625,
      4.625,
      -1.5546875,
      -0.35546875,
      -1.6953125,
      -3.0625,
      1.3984375,
      -2.125,
      -2.203125,
      -0.48828125,
      2.046875,
      -2.25,
      -10.0625,
      0.2451171875,
      -1.96875,
      0.8828125,
      -2.328125,
      0.94921875,
      2.578125,
      3.03125,
      2.375,
      2.28125,
      -0.2138671875,
      -2.71875,
      4.90625,
      15.875,
      2.0625,
      -5.4375,
      -2.34375,
      -1.046875,
      2.234375,
      6.65625,
      2.8125,
      0.51953125,
      1.171875,
      0.48828125,
      2.015625,
      2.71875,
      4.03125,
      -0.52734375,
      -1.15625,
      3.75,
      -1.9921875,
      -2.53125,
      -6.3125,
      -0.04638671875,
      2.09375,
      -2.8125,
      3.6875,
      0.55078125,
      1.3828125,
      0.45703125,
      -1.5390625,
      -0.984375,
      -1.25,
      -3.734375,
      -2.53125,
      -1.171875,
      -2.703125,
      -1.9296875,
      -4.4375,
      1.46875,
      -0.4609375,
      2.765625,
      -2.15625,
      -4.6875,
      -4.1875,
      2.734375,
      -2.40625,
      -2.125,
      0.6953125,
      -1.875,
      -2.109375,
      1.625,
      1.3046875,
      -3.015625,
      0.022216796875,
      -5.21875,
      1.2890625,
      -0.97265625,
      -2.25,
      -2.5625,
      -5.59375,
      -5.34375,
      -4.65625,
      -1.8125,
      -3.84375,
      0.8046875,
      -0.48046875,
      0.12353515625,
      -3.25,
      -1.296875,
      0.5234375,
      0.8515625,
      -0.5625,
      -3.84375,
      -2.46875,
      6.1875,
      3.96875,
      -1.109375,
      -2.390625,
      2.609375,
      2.640625,
      -0.7109375,
      1.40625,
      0.2099609375,
      0.8203125,
      -2.65625,
      -0.06884765625,
      -1.9921875,
      1.8515625,
      -1.734375,
      1.796875,
      0.234375,
      0.91015625,
      6.375,
      -2.625,
      2.578125,
      0.51953125,
      -6.09375,
      -0.90234375,
      -0.11181640625,
      4.1875,
      1.9609375,
      -0.66015625,
      1.3984375,
      4.3125,
      -1.484375,
      -1.484375,
      1.546875,
      0.9921875,
      2.921875,
      -1.7265625,
      0.48046875,
      1.203125,
      -1.4609375,
      2.234375,
      -0.2890625,
      -1.125,
      -1.9921875,
      3.140625,
      -4.25,
      -2.203125,
      -1.2109375,
      -0.265625,
      4.5625,
      2.515625,
      -4.46875,
      0.61328125,
      -7.09375,
      -3.40625,
      -3.640625,
      -5.03125,
      3.015625,
      -2.96875,
      0.83984375,
      -0.12158203125,
      -3.46875,
      -3.28125,
      -0.1748046875,
      -3.859375,
      4.1875,
      1.296875,
      1.3359375,
      0.279296875,
      -3.09375,
      2.515625,
      3.171875,
      -3.59375,
      -4.53125,
      1.3984375,
      -3.5,
      1.265625,
      4.09375,
      0.77734375,
      -3.6875,
      2.59375,
      0.77734375,
      -4,
      0.34765625,
      1.2890625,
      -3.625,
      -1.9296875,
      -4.46875,
      0.07373046875,
      0.1142578125,
      -1.84375,
      -1.546875,
      -3.796875,
      -2.015625,
      -1.03125,
      1.0625,
      -0.337890625,
      -4.90625,
      3.015625,
      5.21875,
      -5.46875,
      -1.8984375,
      -3.203125,
      4.75,
      -3.765625,
      1.2265625,
      4.53125,
      1.09375,
      -2.46875,
      3.671875,
      1.328125,
      -0.82421875,
      -4.84375,
      2.234375,
      2.40625,
      -3.3125,
      0.3203125,
      3.546875,
      -3.0625,
      -0.8046875,
      -4.1875,
      -3.6875,
      6.65625,
      4.65625,
      -6.25,
      -2.390625,
      -1.4375,
      1.7109375,
      -4.03125,
      -2.875,
      2.71875,
      0.2578125,
      4.21875,
      3.671875,
      -0.11962890625,
      -4.21875,
      -1.3984375,
      -2.21875,
      -0.91015625,
      -4.8125,
      3.734375,
      0.890625,
      0.95703125,
      -6.96875,
      5.8125,
      1.8203125,
      0.53515625,
      -4.8125,
      0.169921875,
      1.4609375,
      1,
      -6.0625,
      -0.380859375,
      -3.875,
      2.3125,
      -7.53125,
      2.390625,
      -2.1875,
      2.375,
      -4.53125,
      4.8125,
      1.4453125,
      1.609375,
      -4.3125,
      -5.09375,
      -4.78125,
      2.84375,
      -1.125,
      2.375,
      4.21875,
      -1.65625,
      1.21875,
      0.52734375,
      0.1298828125,
      0.1455078125,
      1.9609375,
      1.40625,
      0.314453125,
      0.04736328125,
      0.76171875,
      -0.6640625,
      2.40625,
      -1.203125,
      -3.328125,
      -0.7265625,
      -1.375,
      -0.52734375,
      -4.15625,
      3.265625,
      0.5390625,
      -4.25,
      2.625,
      -1.9921875,
      -2.0625,
      2.5,
      2.46875,
      -5.15625,
      6.28125,
      3.3125,
      -4.15625,
      6.6875,
      -0.6015625,
      -5.15625,
      0.60546875,
      -3.171875,
      0.671875,
      -7.9375,
      1.1484375,
      1.6640625,
      -0.310546875,
      -0.52734375,
      4.625,
      -0.5390625,
      -1.5,
      -4.125,
      5.125,
      2.03125,
      0.58203125,
      0.83203125,
      4.625,
      0.79296875,
      -4.5,
      0.765625,
      -4.75,
      -0.62890625,
      -2.015625,
      0.25,
      4.46875,
      -4.21875,
      1.6171875,
      3.15625,
      2.84375,
      -8.625,
      -2.90625,
      0.1376953125,
      -3.890625,
      5.75,
      0.36328125,
      1.7109375,
      -3.03125,
      -1.28125,
      0.69921875,
      2.09375,
      -1.0234375,
      -0.984375,
      -4.6875,
      2.90625,
      -2.09375,
      -6.96875,
      2.765625,
      -1.171875,
      -0.62890625,
      -3.5625,
      -2.59375,
      -1.015625,
      -0.15234375,
      1.40625,
      -5.1875,
      2.375,
      -0.412109375,
      -0.326171875,
      3.0625,
      3.734375,
      4,
      4.8125,
      1.0703125,
      -4.8125,
      2.59375,
      0.609375,
      1.4609375,
      4.03125,
      -2.328125,
      3.71875,
      -1.03125,
      2.015625,
      -6.5625,
      6,
      -0.6953125,
      -10.5625,
      6.40625,
      -0.671875,
      -2.09375,
      -1.734375,
      -8.875,
      -4,
      6.375,
      1.125,
      -1.1171875,
      3.203125,
      -0.058349609375,
      0.890625,
      2.71875,
      0.2294921875,
      -4.0625,
      1.9375,
      1.421875,
      -4.6875,
      2.828125,
      3.890625,
      -1.1484375,
      -1.5859375,
      -2.875,
      2.4375,
      -1.5078125,
      -1.8125,
      3.65625,
      2.421875,
      -2.703125,
      -1.6328125,
      -4.9375,
      0.5234375,
      0.42578125,
      -3.6875,
      1.9140625,
      -0.150390625,
      0.703125,
      -4.15625,
      2.03125,
      0.70703125,
      -3.359375,
      -3.21875,
      -2.765625,
      -1.6640625,
      2.21875,
      1.4921875,
      3.171875,
      -1.65625,
      1.96875,
      0.6171875,
      2.828125,
      -3.125,
      -3.53125,
      0.384765625,
      -5.03125,
      -1.4609375,
      -5.5,
      2.515625,
      -6.21875,
      -0.1689453125,
      1.265625,
      0.6796875,
      -1.515625,
      0.26953125,
      -4.34375,
      3.0625,
      -1.1953125,
      -0.94140625,
      -2.265625,
      -0.984375,
      0.28125,
      2.3125,
      -4.71875,
      -0.671875,
      -0.88671875,
      -0.1142578125,
      -4.65625,
      -4.3125,
      1.1796875,
      -0.048828125,
      0.52734375,
      2.171875,
      -0.65625,
      -0.2197265625,
      0.14453125,
      -7.34375,
      -3,
      2.53125,
      2.625,
      1.0078125,
      1.1171875,
      0.91796875,
      -3.984375,
      3.671875,
      7.5,
      1.0234375,
      -1.7265625,
      -0.796875,
      0.1962890625,
      -0.390625,
      -2.0625,
      -0.7734375,
      -1.40625,
      -2.765625,
      6.09375,
      -1.9375,
      2.34375,
      0.7578125,
      0.150390625,
      2.078125,
      -2.25,
      3.203125,
      0.79296875,
      0.78125,
      3.109375,
      -3.015625,
      -1.15625,
      -3.4375,
      0.59375,
      1.140625,
      1.6875,
      -0.12890625,
      0.08349609375,
      3.34375,
      -3,
      0.201171875,
      1.015625,
      -1.4609375,
      5.125,
      -4.59375,
      -2.765625,
      -3.203125,
      -1.453125,
      1.9453125,
      -1.046875,
      0.11767578125,
      -4.46875,
      0.052734375,
      -2.3125,
      -0.62890625,
      0.7578125,
      2.65625,
      -2.484375,
      -5.625,
      -3.765625,
      3.96875,
      -0.59375,
      3.34375,
      3.890625,
      3.421875,
      1.90625,
      1.0234375,
      2.40625,
      5.03125,
      4.71875,
      -2.734375,
      -1.1796875,
      2.03125,
      -1.2421875,
      -0.494140625,
      -3.59375,
      -0.4296875,
      0.2158203125,
      5.28125,
      3.1875,
      -0.6875,
      1.6328125,
      -0.5703125,
      -2.46875,
      -1.875,
      3.46875,
      0.7421875,
      -1.2265625,
      0.1787109375,
      1.40625,
      1.5859375,
      2.1875,
      4.21875,
      -0.33984375,
      -0.0279541015625,
      -1.1875,
      -0.4375,
      0.82421875,
      -1.65625,
      1.2421875,
      -0.435546875,
      -0.369140625,
      -0.00133514404296875,
      -1.8046875,
      3.203125,
      0.26171875,
      0.443359375,
      4,
      1.0546875,
      -1.859375,
      1.015625,
      0.15625,
      -2.921875,
      -1.6796875,
      1.6875,
      2.359375,
      -1.9296875,
      -1.734375,
      0.61328125,
      3.359375,
      -0.53515625,
      3.046875,
      2.453125,
      -1.6484375,
      -2.125,
      -1.15625,
      3.046875,
      -1.453125,
      1.78125,
      -1.1484375,
      1.15625,
      1.8359375,
      -1.3203125,
      -4.28125,
      3.59375,
      -2.34375,
      0.0859375,
      -0.03466796875,
      0.6640625,
      3.75,
      3.65625,
      -0.125,
      -0.126953125,
      -0.99609375,
      -3.25,
      -0.28125,
      -2.734375,
      -2.125,
      -4,
      -1.15625,
      3.3125,
      -0.15625,
      -0.578125,
      -2.671875,
      0.62109375,
      0.5078125,
      0.478515625,
      -0.0888671875,
      -0.451171875,
      0.365234375,
      0.35546875,
      -2.046875,
      1.734375,
      -1.1875,
      1.375,
      1.0078125,
      -0.85546875,
      -1.828125,
      0.1337890625,
      -1.0703125,
      1.671875,
      -0.51953125,
      0.33984375,
      -1.5,
      0.5859375,
      0.87890625,
      -0.298828125,
      -0.458984375,
      0.9140625,
      1.0546875,
      0.390625,
      1.328125,
      2.671875,
      1.125,
      -0.34765625,
      3.6875,
      -2.765625,
      1.375,
      0.97265625,
      0.80859375,
      -0.333984375,
      -1.1015625,
      -2.3125,
      0.416015625,
      -3.3125,
      -0.03759765625,
      1.703125,
      2.296875,
      -0.86328125,
      -0.6171875,
      -0.5625,
      -3.46875,
      -0.4375,
      1.8515625,
      1.359375,
      1.015625,
      0.263671875,
      -2.828125,
      -0.4921875,
      -0.44140625,
      -0.1923828125,
      -0.1845703125,
      0.91015625,
      -3.75,
      -1.1171875,
      1.9453125,
      -3.125,
      -1.140625,
      -1.34375,
      -0.75,
      2.046875,
      1.9453125,
      1.015625,
      -0.5625,
      -0.7890625,
      -1.2890625,
      -0.107421875,
      -1.2890625,
      0.283203125,
      -0.8359375,
      -0.435546875,
      -0.60546875,
      -0.97265625,
      1.296875,
      -4.15625,
      -2.328125,
      -2.046875,
      2.484375,
      -1.2421875,
      2.265625,
      0.8828125,
      3.171875,
      0.150390625,
      1.7421875,
      0.3125,
      0.48046875,
      1.65625,
      1.2109375,
      -2.265625,
      0.55859375,
      3.234375,
      -0.11376953125,
      -2.0625,
      -1.0234375,
      -1.046875,
      -0.515625,
      1.5390625,
      -3.515625,
      1.34375,
      -0.4453125,
      -2.609375,
      2.046875,
      0.7109375,
      1.4375,
      2.15625,
      -0.462890625,
      3.984375,
      2.59375,
      0.57421875,
      4.40625,
      0.27734375,
      -0.84375,
      1.953125,
      -2.84375,
      0.1396484375,
      1.078125,
      3.4375,
      -0.96875,
      1.609375,
      -0.384765625,
      0.09619140625,
      -1.7109375,
      -0.58203125,
      -0.61328125,
      -1.4921875,
      2.359375,
      0.6796875,
      -2.109375,
      3.484375,
      1.0859375,
      -1.9765625,
      -0.259765625,
      -5.09375,
      -1.671875,
      -2.703125,
      1.0625,
      0.99609375,
      -2.84375,
      0.57421875,
      -0.4453125,
      1.2421875,
      0.359375,
      -0.9921875,
      2.828125,
      2.703125,
      1.4375,
      -1.65625,
      0.103515625,
      -0.6171875,
      2.34375,
      -1.375,
      -2.75,
      2.265625,
      0.3828125,
      -2.171875,
      -3.71875,
      -1.390625,
      -2.640625,
      -2.828125,
      2.21875,
      1.7578125,
      0.28125,
      2.078125,
      -0.546875,
      -5.15625,
      -1.4296875,
      -0.111328125,
      3.109375,
      -0.8046875,
      -1.859375,
      0.87890625,
      -0.640625,
      1.828125,
      0.58203125,
      -0.44921875,
      -0.99609375,
      -0.7109375,
      2.234375,
      1.4609375,
      3.265625,
      1.140625,
      -2.640625,
      -3.140625,
      0.703125,
      -2.109375,
      0.28515625,
      -0.328125,
      0.24609375,
      -0.8359375,
      0.1240234375,
      1.5859375,
      5.0625,
      -0.2255859375,
      -0.375,
      1.8828125,
      2.15625,
      2.359375,
      -0.890625,
      -3.0625,
      -2.90625,
      1.1484375,
      2.6875,
      3.0625,
      0.1455078125,
      -1.0234375,
      4.09375,
      -0.39453125,
      1.6796875,
      -0.24609375,
      0.78515625,
      -1.046875,
      1.546875,
      3.4375,
      -5.09375,
      -1.0234375,
      0.353515625,
      -1.4296875,
      2.703125,
      -0.55859375,
      2.03125,
      2.578125,
      1.3203125,
      0.796875,
      2.328125,
      0.09814453125,
      2.4375,
      1.96875,
      2.25,
      3.953125,
      0.2451171875,
      -3.0625,
      0.06787109375,
      -0.84765625,
      3.640625,
      -1.40625,
      -2.578125,
      3.9375,
      -2.984375,
      1.1015625,
      -2.546875,
      0.90234375,
      2.046875,
      -1.7265625,
      -1.53125,
      2.234375,
      -1.609375,
      2.515625,
      1.359375,
      2.984375,
      -3.921875,
      2.328125,
      1.046875,
      -2.328125,
      -2.0625,
      -2.34375,
      -1.8984375,
      -0.49609375,
      0.4296875,
      -0.388671875,
      -3.140625,
      3.5625,
      -3.96875,
      1.390625,
      6.84375,
      4.46875,
      1.3671875,
      3.015625,
      0.0260009765625,
      2.78125,
      0.73046875,
      -4.34375,
      3.8125,
      2.875,
      -3.09375,
      0.80859375,
      -0.029296875,
      -4.65625,
      -0.8125,
      -0.78515625,
      -0.65625,
      -0.5625,
      1.015625,
      -1.5546875,
      0.494140625,
      2.859375,
      -0.32421875,
      -0.578125,
      0.310546875,
      0.375,
      -2.09375,
      3.921875,
      0.70703125,
      -1.71875,
      1.1171875,
      0.2119140625,
      -0.431640625,
      -1.84375,
      -2.46875,
      -2.671875,
      -0.96875,
      -0.27734375,
      1.7421875,
      -2.171875,
      0.7109375,
      1.453125,
      1.3828125,
      -3.046875,
      -0.8984375,
      -0.390625,
      -1.734375,
      1.5546875,
      3.390625,
      1.28125,
      -0.1396484375,
      -0.9609375,
      2.40625,
      -1.8203125,
      1.2890625,
      -3.453125,
      1.6171875,
      -3.6875,
      3.125,
      -0.5,
      0.87890625,
      1.5,
      1.3828125,
      0.44921875,
      -3.6875,
      1.625,
      -3.625,
      0.1533203125,
      2.859375,
      1.734375,
      1.046875,
      -5.3125,
      1.265625,
      -1.7578125,
      3.265625,
      0.19921875,
      -0.201171875,
      4,
      -0.65625,
      -2.609375,
      5.28125,
      0.0361328125,
      -0.734375,
      3.640625,
      0.92578125,
      -0.84375,
      0.515625,
      -0.0262451171875,
      -0.64453125,
      1.1953125,
      1.40625,
      -2.4375,
      -1.9609375,
      -1.171875,
      -3.25,
      -0.4921875,
      4.09375,
      1.4765625,
      5.09375,
      1.0234375,
      -2.34375,
      2.171875,
      -0.1787109375,
      2.78125,
      2,
      -0.0189208984375,
      1.3515625,
      -1.890625,
      -2.28125,
      -0.8671875,
      0.447265625,
      0.984375,
      1.546875,
      -0.78125,
      0.49609375,
      0.52734375,
      0.54296875,
      3.53125,
      -2.625,
      0.1640625,
      -0.0108642578125,
      -0.08203125,
      -3.21875,
      1.5390625,
      -2.09375,
      4.125,
      -0.62109375,
      -2.15625,
      0.32421875,
      -0.859375,
      -2.515625,
      -0.490234375,
      -0.5078125,
      2.3125,
      -0.33984375,
      0.08935546875,
      -0.7734375,
      1.9921875,
      -0.1708984375,
      -1.2421875,
      2.046875,
      1.328125,
      1.1171875,
      -1.0625,
      -0.7421875,
      -0.96484375,
      0.033203125,
      -0.078125,
      -1.4609375,
      0.85546875,
      -0.81640625,
      -2.1875,
      3.953125,
      1.1328125
    ],
    "tags": [
      "LLM智能体",
      "记忆机制",
      "文献综述"
    ],
    "suggested_tags": [
      "LLM智能体",
      "记忆机制",
      "文献综述",
      "AGI",
      "智能体架构"
    ],
    "tag_suggestions": [
      {
        "name": "LLM智能体",
        "confidence": 0.95,
        "reason": "论文核心研究领域为基于大语言模型的智能体系统，重点探讨其记忆机制"
      },
      {
        "name": "记忆机制",
        "confidence": 0.9,
        "reason": "论文系统综述LLM智能体的记忆模块设计、实现和评估方法"
      },
      {
        "name": "文献综述",
        "confidence": 0.85,
        "reason": "这是一篇系统性综述论文，总结和比较了该领域的前沿研究成果"
      },
      {
        "name": "AGI",
        "confidence": 0.8,
        "reason": "论文讨论记忆机制在实现通用人工智能目标中的重要作用"
      },
      {
        "name": "智能体架构",
        "confidence": 0.75,
        "reason": "涉及LLM智能体的整体架构设计，特别是记忆模块与其他组件的交互"
      }
    ],
    "tags_confirmed": true,
    "category": "LLM Agents",
    "s2_graph": {
      "citations": [
        {
          "external_id": "CorpusId:283790278",
          "title": "Agentic digital twin-embedded maintenance methodology for energy equipment: A self-evolving operational paradigm",
          "authors": [
            "Wang Cong",
            "Wu Tao",
            "Jinsong Bao"
          ],
          "year": 2026,
          "venue": "Journal of manufacturing systems",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283983558",
          "title": "LLM-enhanced embodied multi-agent manufacturing system: A novel self-organizing production paradigm for embodied perception, embodied analysis and embodied decision",
          "authors": [
            "Changchun Liu",
            "Dunbing Tang",
            "Haihua Zhu",
            "Liping Wang",
            "Qixiang Cai",
            "Qingwei Nie"
          ],
          "year": 2026,
          "venue": "Journal of manufacturing systems",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281551333",
          "title": "Applications of multimodal large language models in construction industry",
          "authors": [
            "Abdolmajid Erfani",
            "Ali Mansouri"
          ],
          "year": 2026,
          "venue": "Advanced Engineering Informatics",
          "citation_count": 4
        },
        {
          "external_id": "CorpusId:283895975",
          "title": "Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI",
          "authors": [
            "Samarth Sarin",
            "Lovepreet Singh",
            "Bhaskarjit Sarmah",
            "Dhagash Mehta"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283897359",
          "title": "Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems",
          "authors": [
            "Sreemaee Akshathala",
            "Bassam Adnan",
            "Mahisha Ramesh",
            "Karthik Vaidhyanathan",
            "Basil Muhammed",
            "Kannan Parthasarathy"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283897719",
          "title": "Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects",
          "authors": [
            "Chris Latimer",
            "Nicol'o Boschi",
            "Andrew Neeser",
            "Chris Bartholomew",
            "Gaurav Srivastava",
            "Xuan Wang",
            "Naren Ramakrishnan"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283737683",
          "title": "Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution",
          "authors": [
            "Zouying Cao",
            "Jiaji Deng",
            "Li Yu",
            "Weikang Zhou",
            "Zhaoyang Liu",
            "Bolin Ding",
            "Hai Zhao"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283693901",
          "title": "PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas and Agentic Memory",
          "authors": [
            "Bowen Jiang",
            "Yuan Yuan",
            "Maohao Shen",
            "Zhuoqun Hao",
            "Zhangchen Xu",
            "Zichen Chen",
            "Ziyi Liu",
            "Anvesh Rao Vijjini",
            "Jiashu He",
            "Hanchao Yu",
            "Radha Poovendran",
            "Greg Wornell",
            "Lyle Ungar",
            "Dan Roth",
            "Sihao Chen",
            "C. J. Taylor"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283468692",
          "title": "Conversational Agents: From RAG to LTM",
          "authors": [
            "Dell Zhang",
            "Yue Feng",
            "Haiming Liu",
            "Changzhi Sun",
            "Jixiang Luo",
            "Xiangyu Chen",
            "Xuelong Li"
          ],
          "year": 2025,
          "venue": "Proceedings of the 2025 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283466545",
          "title": "MemVerse: Multimodal Memory for Lifelong Learning Agents",
          "authors": [
            "Junming Liu",
            "Yifei Sun",
            "Weihua Cheng",
            "Haodong Lei",
            "Yirong Chen",
            "Licheng Wen",
            "Xuemeng Yang",
            "Daocheng Fu",
            "Pinlong Cai",
            "Nianchen Deng",
            "Yi Yu",
            "Shuyue Hu",
            "Botian Shi",
            "Ding Wang"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283438865",
          "title": "ThetaEvolve: Test-time Learning on Open Problems",
          "authors": [
            "Yiping Wang",
            "Shao-Rong Su",
            "Zhiyuan Zeng",
            "Eva Xu",
            "Liliang Ren",
            "Xinyu Yang",
            "Zeyi Huang",
            "Xuehai He",
            "Luyao Ma",
            "Baolin Peng",
            "Hao Cheng",
            "Pengcheng He",
            "Weizhu Chen",
            "Shuohang Wang",
            "S. Du",
            "Yelong Shen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283261649",
          "title": "EWE: An Agentic Framework for Extreme Weather Analysis",
          "authors": [
            "Zhe Jiang",
            "Jiong Wang",
            "Xiaoyu Yue",
            "Zijie Guo",
            "Wenlong Zhang",
            "Fenghua Ling",
            "Wanli Ouyang",
            "Lei Bai"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283261501",
          "title": "Agentic Learner with Grow-and-Refine Multimodal Semantic Memory",
          "authors": [
            "Weihao Bo",
            "Shan Zhang",
            "Yanpeng Sun",
            "Jingjing Wu",
            "Qunyi Xie",
            "Xiao Tan",
            "Kunbin Chen",
            "Wei He",
            "Xiaofan Li",
            "Na Zhao",
            "Jingdong Wang",
            "Zechao Li"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283243784",
          "title": "General Agentic Memory Via Deep Research",
          "authors": [
            "B. Y. Yan",
            "Chaofan Li",
            "Hongjin Qian",
            "Shuqi Lu",
            "Zheng Liu"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:283244111",
          "title": "Cross-Disciplinary Knowledge Retrieval and Synthesis: A Compound AI Architecture for Scientific Discovery",
          "authors": [
            "Svitlana Volkova",
            "Peter Bautista",
            "Avinash Hiriyanna",
            "Gabriel Ganberg",
            "Isabel Erickson",
            "Zachary Klinefelter",
            "Nick Abele",
            "Hsien-Te Kao",
            "Grant Engberson"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283243578",
          "title": "AnimAgents: Coordinating Multi-Stage Animation Pre-Production with Human-Multi-Agent Collaboration",
          "authors": [
            "WEN-FAN Wang",
            "LU CHIEN-TING",
            "Jinping Ng",
            "Yi-Ting Chiu",
            "BING-YU Chen",
            "Wang Lu",
            "Ng Chiu",
            "Lee Wang",
            "Chen Chen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283226308",
          "title": "Agentifying Agentic AI",
          "authors": [
            "Virginia Dignum",
            "F. Dignum"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283243834",
          "title": "Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL Assertion Failures",
          "authors": [
            "Yunsheng Bai",
            "Haoxing Ren"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283109792",
          "title": "AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization",
          "authors": [
            "Genghan Zhang",
            "Shaowei Zhu",
            "Anjiang Wei",
            "Zhenyu Song",
            "Allen Nie",
            "Zhen Jia",
            "Nandita Vijaykumar",
            "Yida Wang",
            "K. Olukotun"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283073241",
          "title": "O-Mem: Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents",
          "authors": [
            "Piaohong Wang",
            "Motong Tian",
            "Jiaxian Li",
            "Yuan Liang",
            "Yuqing Wang",
            "Qianben Chen",
            "Tiannan Wang",
            "Zhicong Lu",
            "Jiawei Ma",
            "Y. Jiang",
            "Wangchunshu Zhou"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283089941",
          "title": "MEDIA COMMUNICATION OF WESTERN BALKAN NEWSPAPERS IN THE FUNCTION OF PUBLIC EDUCATION",
          "authors": [
            "Rexhep Suma",
            "Ferid Selimi"
          ],
          "year": 2025,
          "venue": "Veredas do Direito",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282921566",
          "title": "Smarter Together: Creating Agentic Communities of Practice through Shared Experiential Learning",
          "authors": [
            "V. Tablan",
            "Scott Taylor",
            "Gabriel Hurtado",
            "Kristoffer Bernhem",
            "Anders Uhrenholt",
            "Gabriele Farei",
            "Karo Moilanen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282930770",
          "title": "MemIndex: Agentic Event-based Distributed Memory Management for Multi-agent Systems",
          "authors": [
            "Alaa Saleh",
            "Sasu Tarkoma",
            "Anders Lindgren",
            "Praveen Kumar Donta",
            "S. Dustdar",
            "Susanna Pirttikangas",
            "Lauri Lovén"
          ],
          "year": 2025,
          "venue": "ACM Transactions on Autonomous and Adaptive Systems",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282912002",
          "title": "The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation",
          "authors": [
            "Zhengyuan Liu",
            "Stella Xin Yin",
            "Bryan Chen Zhengyu Tan",
            "Roy Ka-Wei Lee",
            "Guimei Liu",
            "D. Goh",
            "Wenya Wang",
            "Nancy F. Chen"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282749414",
          "title": "LLMs as Judges: Toward The Automatic Review of GSN-compliant Assurance Cases",
          "authors": [
            "Gerhard Yu",
            "Mithila Sivakumar",
            "A. B. Belle",
            "Soude Ghari",
            "Song Wang",
            "T. Lethbridge"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282739912",
          "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning",
          "authors": [
            "Zhengjun Huang",
            "Zhoujin Tian",
            "Qintian Guo",
            "Fangyuan Zhang",
            "Yingli Zhou",
            "Di Jiang",
            "Xiaofang Zhou"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282739615",
          "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving",
          "authors": [
            "Chengying Huan",
            "Ziheng Meng",
            "Yongchao Liu",
            "Zhengyi Yang",
            "Yun Zhu",
            "Yue Yun",
            "Shipeng Li",
            "Rong Gu",
            "Xiabao Wu",
            "Haitao Zhang",
            "Chuntao Hong",
            "Shaonan Ma",
            "Guihai Chen",
            "Chen Tian"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:283266405",
          "title": "Poster: MemAura: Persistent Personalized Context Memory for LLM Services in Smart Environments",
          "authors": [
            "Siyuan Liu",
            "Huangxun Chen"
          ],
          "year": 2025,
          "venue": "Proceedings of the 31st Annual International Conference on Mobile Computing and Networking",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282740197",
          "title": "Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence",
          "authors": [
            "Hong Su"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282936203",
          "title": "The rise and potential opportunities of large language model agents in bioinformatics and biomedicine",
          "authors": [
            "Tiantian Yang",
            "Yihang Xiao",
            "Zhijie Bao",
            "Jianye Hao",
            "Jiajie Peng"
          ],
          "year": 2025,
          "venue": "Briefings Bioinform.",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282995979",
          "title": "Security of LLM-based Agents Regarding Attacks, Defenses, and Applications: A Comprehensive Survey",
          "authors": [
            "Yaxin Tang",
            "Yijia Liu",
            "Jiahe Lan",
            "Zheng Yan",
            "Erol Gelenbe"
          ],
          "year": 2025,
          "venue": "Information Fusion",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282719877",
          "title": "Dynamic Affective Memory Management for Personalized LLM Agents",
          "authors": [
            "Junfeng Lu",
            "Yueyan Li"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282573827",
          "title": "The Narrative Continuity Test: A Conceptual Framework for Evaluating Identity Persistence in AI Systems",
          "authors": [
            "Stefano Natangelo"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282389952",
          "title": "CompressionAttack: Exploiting Prompt Compression as a New Attack Surface in LLM-Powered Agents",
          "authors": [
            "Zesen Liu",
            "Zhixiang Zhang",
            "Yuchong Xie",
            "Dongdong She"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282400883",
          "title": "Evaluating Long-Term Memory for Long-Context Question Answering",
          "authors": [
            "Alessandra Terranova",
            "Bjorn Ross",
            "Alexandra Birch"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282384295",
          "title": "Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware Meta-Verification and Trustworthy Reasoning with Structured Facts",
          "authors": [
            "Hongwei Zhang",
            "Ji Lu",
            "Shiqing Jiang",
            "Chenxiang Zhu",
            "Li Xie",
            "Chen Zhong",
            "Haoran Chen",
            "Yurui Zhu",
            "Yongsheng Du",
            "Yanqin Gao",
            "Lingjun Huang",
            "Baoli Wang",
            "Fang Tan",
            "Peng Zou"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282352943",
          "title": "Probing the Gaps in ChatGPT's Live Video Chat for Real-World Assistance for People who are Blind or Visually Impaired",
          "authors": [
            "Ruei-Che Chang",
            "Rosiana Natalie",
            "Wenqian Xu",
            "Jovan Zheng Feng Yap",
            "Anhong Guo"
          ],
          "year": 2025,
          "venue": "Proceedings of the 27th International ACM SIGACCESS Conference on Computers and Accessibility",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282245881",
          "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation",
          "authors": [
            "Jizhan Fang",
            "Xinle Deng",
            "Haoming Xu",
            "Ziyan Jiang",
            "Yuqi Tang",
            "Ziwen Xu",
            "Shumin Deng",
            "Yunzhi Yao",
            "Mengru Wang",
            "Shuofei Qiao",
            "Huajun Chen",
            "Ningyu Zhang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 3
        },
        {
          "external_id": "CorpusId:282210434",
          "title": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems",
          "authors": [
            "Qingyao Ai",
            "Yichen Tang",
            "Changyue Wang",
            "Jianming Long",
            "Weihang Su",
            "Yiqun Liu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282209161",
          "title": "Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents",
          "authors": [
            "Yihong Tang",
            "Kehai Chen",
            "Liang Yue",
            "Jinxin Fan",
            "Caishen Zhou",
            "Xiaoguang Li",
            "Yuyang Zhang",
            "Mingming Zhao",
            "Shixiong Kai",
            "Kaiyang Guo",
            "Xingshan Zeng",
            "Wenjing Cun",
            "Lifeng Shang",
            "Min Zhang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282138871",
          "title": "The Gatekeeper Knows Enough",
          "authors": [
            "Fikresilase Wondmeneh Abebayew"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282102171",
          "title": "Higher Satisfaction, Lower Cost: A Technical Report on How LLMs Revolutionize Meituan's Intelligent Interaction Systems",
          "authors": [
            "Xuxin Cheng",
            "Ke Zeng",
            "Zhiquan Cao",
            "Linyi Dai",
            "Wenxuan Gao",
            "Fei Han",
            "Ai Jian",
            "Feng Hong",
            "Wenxing Hu",
            "Zihe Huang",
            "Dejian Kong",
            "Jia Leng",
            "Zhuoyuan Liao",
            "Pei Liu",
            "Jiaye Lin",
            "Xing Ma",
            "Jingqing Ruan",
            "Jiaxing Song",
            "Xiaoyu Tan",
            "Ruixuan Xiao",
            "Wenhui Yu",
            "Wenyu Zhan",
            "Haoxing Zhang",
            "Chaohua Zhou",
            "Hao Zhou",
            "Shaodong Zheng",
            "Ruinian Chen",
            "Siyuan Chen",
            "Zi-Yu Chen",
            "Yiwen Dong",
            "Yao Fan",
            "Yangyi Fang",
            "Y. Gan",
            "Shiguang Guo",
            "Qianyun He",
            "Chaowen Hu",
            "Binghui Li",
            "Dailin Li",
            "Xiangyu Li",
            "Yan Li",
            "Chengjia Liu",
            "Xiang-Ru Liu",
            "Jiahui Lv",
            "Q. Ma",
            "Jiang Pan",
            "Cong Qin",
            "Chen-Yi Sun",
            "Wen Sun",
            "Zhonghui Wang",
            "Abudukelimu Wuerkaixi",
            "Xin Yang",
            "Fang Yuan",
            "Yawen Zhu",
            "Tianyi Zhai",
            "Jie Zhang",
            "Run-dong Zhang",
            "Yao Xu",
            "Yiran Zhao",
            "Yifan Wang",
            "Xunliang Cai",
            "Yangen Hu",
            "Cao Liu",
            "Lu Pan",
            "Xiaoli Wang",
            "Bowen Xiao",
            "Wen‐De Yao",
            "Qian-Yang Zhou",
            "Benchang Zhu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282139330",
          "title": "GenCellAgent: Generalizable, Training-Free Cellular Image Segmentation via Large Language Model Agents",
          "authors": [
            "Xi Yu",
            "Yang Yang",
            "Qun Liu",
            "Yonghua Du",
            "Sean McSweeney",
            "Yuewei Lin"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282057825",
          "title": "PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature",
          "authors": [
            "Daoyu Wang",
            "Mingyue Cheng",
            "Qi Liu",
            "Shuo Yu",
            "Zirui Liu",
            "Ze Guo"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:282056919",
          "title": "Attacks by Content: Automated Fact-checking is an AI Security Issue",
          "authors": [
            "Michael Schlichtkrull"
          ],
          "year": 2025,
          "venue": "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282064568",
          "title": "VizCopilot: Fostering Appropriate Reliance on Enterprise Chatbots with Context Visualization",
          "authors": [
            "Sam Yu-Te Lee",
            "Jingya Chen",
            "Albert Calzaretto",
            "Richard Lee",
            "Alice Ferng",
            "Mihaela Vorvoreanu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282057267",
          "title": "Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction",
          "authors": [
            "Sihang Zeng",
            "Yujuan Velvin Fu",
            "Sitong Zhou",
            "Zixuan Yu",
            "Lucas Jing Liu",
            "Jun Wen",
            "Matthew Thompson",
            "Ruth Etzioni",
            "Meliha Yetisgen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282057006",
          "title": "D3MAS: Decompose, Deduce, and Distribute for Enhanced Knowledge Sharing in Multi-Agent Systems",
          "authors": [
            "Heng Zhang",
            "Yuling Shi",
            "Xiaodong Gu",
            "Haochen You",
            "Zijian Zhang",
            "Lubin Gan",
            "Yilei Yuan",
            "Jin Huang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282056085",
          "title": "Student Development Agent: Risk-free Simulation for Evaluating AIED Innovations",
          "authors": [
            "Jianxiao Jiang",
            "Yu Zhang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282058598",
          "title": "Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs",
          "authors": [
            "Xu Pan",
            "Ely Hahami",
            "Jingxuan Fan",
            "Ziqian Xie",
            "H. Sompolinsky"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282057135",
          "title": "The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs",
          "authors": [
            "Xi Fang",
            "Weijie Xu",
            "Yuchong Zhang",
            "Stephanie Eckman",
            "Scott Nickleach",
            "Chandan K. Reddy"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282058600",
          "title": "Preference-Aware Memory Update for Long-Term LLM Agents",
          "authors": [
            "Haoran Sun",
            "Zekun Zhang",
            "Shaoning Zeng"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281951166",
          "title": "MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation",
          "authors": [
            "Shuo Yu",
            "Mingyue Cheng",
            "Daoyu Wang",
            "Qi Liu",
            "Zirui Liu",
            "Ze Guo",
            "Xiaoyu Tao"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:281886660",
          "title": "CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension",
          "authors": [
            "Rui Li",
            "Zeyu Zhang",
            "Xiaohe Bo",
            "Zihang Tian",
            "Xu Chen",
            "Quanyu Dai",
            "Zhenhua Dong",
            "Ruiming Tang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:281886275",
          "title": "The New Quant: A Survey of Large Language Models in Financial Prediction and Trading",
          "authors": [
            "Weilong Fu"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281886866",
          "title": "A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks",
          "authors": [
            "Shuzheng Si",
            "Haozhe Zhao",
            "Kangyang Luo",
            "Gang Chen",
            "Fanchao Qi",
            "Minjia Zhang",
            "Baobao Chang",
            "Maosong Sun"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:281842361",
          "title": "PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian",
          "authors": [
            "Mohammad Amin Abbasi",
            "Hassan Naderi"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281706398",
          "title": "JoyAgent-JDGenie: Technical Report on the GAIA",
          "authors": [
            "Jiarun Liu",
            "Shiyue Xu",
            "Shangkun Liu",
            "Yang Li",
            "Wen Liu",
            "Min Liu",
            "Xiaoqing Zhou",
            "Hanmin Wang",
            "Shilin Jia",
            "zhen Wang",
            "Shaohua Tian",
            "Hanhao Li",
            "Junbo Zhang",
            "Yongli Yu",
            "Peng Cao",
            "Haofen Wang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281724947",
          "title": "MEMTRACK: Evaluating Long-Term Memory and State Tracking in Multi-Platform Dynamic Agent Environments",
          "authors": [
            "Darshan Deshpande",
            "Varun Gangal",
            "Hersh Mehta",
            "Anand Kannappan",
            "Rebecca Qian",
            "Peng Wang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281682562",
          "title": "TVS Sidekick: Challenges and Practical Insights from Deploying Large Language Models in the Enterprise",
          "authors": [
            "Paula Reyero Lobo",
            "Kevin Johnson",
            "Bill Buchanan",
            "M. Shardlow",
            "Ashley Williams",
            "Samuel Attwood"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281829886",
          "title": "From Trace to Line: LLM Agent for Real-World OSS Vulnerability Localization",
          "authors": [
            "Haoran Xi",
            "Minghao Shao",
            "Brendan Dolan-Gavitt",
            "Muhammad Shafique",
            "Ramesh Karri"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:282285318",
          "title": "Enhancing LLM Agent Effectiveness via Reflective Multi-Agent System",
          "authors": [
            "Aissa Hadj Mohamed",
            "Frances A. Santos",
            "J. C. D. Reis"
          ],
          "year": 2025,
          "venue": "Anais do XIX Workshop-Escola de Sistemas de Agentes, seus Ambientes e Aplicações (WESAAC 2025)",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281674540",
          "title": "ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory",
          "authors": [
            "Siru Ouyang",
            "Jun Yan",
            "I-Hung Hsu",
            "Yanfei Chen",
            "Ke Jiang",
            "Zifeng Wang",
            "Rujun Han",
            "Long T. Le",
            "Samira Daruki",
            "Xiangru Tang",
            "Vishy Tirumalashetty",
            "George Lee",
            "Mahsan Rofouei",
            "Hangfei Lin",
            "Jiawei Han",
            "Chen-Yu Lee",
            "Tomas Pfister"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 7
        },
        {
          "external_id": "CorpusId:281676243",
          "title": "MemGen: Weaving Generative Latent Memory for Self-Evolving Agents",
          "authors": [
            "Gui-Min Zhang",
            "Muxin Fu",
            "Shuicheng Yan"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:281814029",
          "title": "A review on an AI-driven face robot for human-robot expression interaction",
          "authors": [
            "Qincheng Sheng",
            "Wei Tang",
            "Hao Qin",
            "Yujie Kong",
            "Haokai Dai",
            "Yiding Zhong",
            "Yonghao Wang",
            "Jun Zou",
            "Huayong Yang"
          ],
          "year": 2025,
          "venue": "Science China Technological Sciences",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281525995",
          "title": "SGMem: Sentence Graph Memory for Long-Term Conversational Agents",
          "authors": [
            "Yaxiong Wu",
            "Yongyue Zhang",
            "Sheng Liang",
            "Yong Liu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:281505303",
          "title": "Embodied AI: From LLMs to World Models",
          "authors": [
            "Tongtong Feng",
            "Xin Wang",
            "Yu-Gang Jiang",
            "Wenwu Zhu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 7
        },
        {
          "external_id": "CorpusId:281496282",
          "title": "MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service",
          "authors": [
            "Yizhe Huang",
            "Yang Liu",
            "Ruiyu Zhao",
            "Xiaolong Zhong",
            "Xingming Yue",
            "Ling Jiang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:281495897",
          "title": "LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions",
          "authors": [
            "Xixun Lin",
            "Yucheng Ning",
            "Jingwen Zhang",
            "Yan Dong",
            "Yilong Liu",
            "Yongxuan Wu",
            "Xiaohua Qi",
            "Nan Sun",
            "Yanmin Shang",
            "Pengfei Cao",
            "Lixin Zou",
            "Xu Chen",
            "Chuan Zhou",
            "Jia Wu",
            "Shirui Pan",
            "Bin Wang",
            "Yanan Cao",
            "Kai Chen",
            "Songlin Hu",
            "Li Guo"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 4
        },
        {
          "external_id": "CorpusId:282066985",
          "title": "Poster: Vortex: Efficient Decentralized Vector Overlay for Similarity Search and Delivery",
          "authors": [
            "Shengze Wang",
            "Yi Liu",
            "Chen Qian"
          ],
          "year": 2025,
          "venue": "IEEE International Conference on Network Protocols",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281420632",
          "title": "Temporal-Aware User Behaviour Simulation with Large Language Models for Recommender Systems",
          "authors": [
            "Xinye Wanyan",
            "Danula Hettiachchi",
            "Chenglong Ma",
            "Ziqi Xu",
            "Jeffrey Chan"
          ],
          "year": 2025,
          "venue": "International Conference on Information and Knowledge Management",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281315176",
          "title": "AgenticIE: An Adaptive Agent for Information Extraction from Complex Regulatory Documents",
          "authors": [
            "Gaye Colakoglu",
            "Gürkan Solmaz",
            "Jonathan Furst"
          ],
          "year": 2025,
          "venue": "",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281243759",
          "title": "SWE-Mirror: Scaling Issue-Resolving Datasets by Mirroring Issues Across Repositories",
          "authors": [
            "Junhao Wang",
            "Daoguang Zan",
            "Shulin Xin",
            "Siyao Liu",
            "Yurong Wu",
            "Kai Shen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 4
        },
        {
          "external_id": "CorpusId:281103608",
          "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent",
          "authors": [
            "Chunlong Wu",
            "Ye Luo",
            "Zhibo Qu",
            "Min Wang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:281079714",
          "title": "Social World Models",
          "authors": [
            "Xuhui Zhou",
            "Jiarui Liu",
            "Akhila Yerukola",
            "Hyunwoo Kim",
            "M. Sap"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280985390",
          "title": "AI Compute Architecture and Evolution Trends",
          "authors": [
            "Bor-Sung Liang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280918480",
          "title": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning",
          "authors": [
            "Sikuan Yan",
            "Xiufeng Yang",
            "Zuchao Huang",
            "Ercong Nie",
            "Zifeng Ding",
            "Zonggen Li",
            "Xiaowen Ma",
            "Hinrich Schutze",
            "Volker Tresp",
            "Yunpu Ma"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 23
        },
        {
          "external_id": "CorpusId:280711623",
          "title": "Chinese Court Simulation with LLM-Based Agent System",
          "authors": [
            "Kaiyuan Zhang",
            "Jiaqi Li",
            "Yueyue Wu",
            "Haitao Li",
            "Cheng Luo",
            "Shaokun Zou",
            "Yujia Zhou",
            "Weihang Su",
            "Qingyao Ai",
            "Yiqun Liu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:280699793",
          "title": "Multiple Memory Systems for Enhancing the Long-term Memory of Agent",
          "authors": [
            "Gaoke Zhang",
            "Bo Wang",
            "Yunlong Ma",
            "Dong-Lin Zhao",
            "Zifei Yu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280686168",
          "title": "Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information",
          "authors": [
            "Zeyu Zhang",
            "Yang Zhang",
            "Haoran Tan",
            "Rui Li",
            "Xu Chen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:280676831",
          "title": "A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond",
          "authors": [
            "Xiaodong Qu",
            "Andrews Damoah",
            "Joshua Sherwood",
            "Peiyan Liu",
            "Christian Shun Jin",
            "Lulu Chen",
            "Minjie Shen",
            "Nawwaf Aleisa",
            "Zeyuan Hou",
            "Chenyu Zhang",
            "Lifu Gao",
            "Yanshu Li",
            "Qikai Yang",
            "Qun Wang",
            "Cristabelle Madona De Souza"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:280711822",
          "title": "Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework",
          "authors": [
            "Zeyu Zhang",
            "Quanyu Dai",
            "Rui Li",
            "Xiaohe Bo",
            "Xu Chen",
            "Zhenhua Dong"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 3
        },
        {
          "external_id": "CorpusId:280676428",
          "title": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Enhanced Model Architectures",
          "authors": [
            "Parsa Omidi",
            "Xingshuai Huang",
            "Axel Laborieux",
            "Bahareh Nikpour",
            "Tianyu Shi",
            "Armaghan Eshaghi"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 2
        },
        {
          "external_id": "CorpusId:280635601",
          "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory",
          "authors": [
            "Sizhe Yuen",
            "Francisco Gomez Medina",
            "Ting Su",
            "Yali Du",
            "A. Sobey"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280565914",
          "title": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows",
          "authors": [
            "Jingwen Zhou",
            "Jieshan Chen",
            "Qinghua Lu",
            "Dehai Zhao",
            "Liming Zhu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:280567255",
          "title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks",
          "authors": [
            "Rui Miao",
            "Yixin Liu",
            "Yili Wang",
            "Xu Shen",
            "Yue Tan",
            "Yiwei Dai",
            "Shirui Pan",
            "Xin Wang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 6
        },
        {
          "external_id": "CorpusId:280566222",
          "title": "Measuring Stereotype and Deviation Biases in Large Language Models",
          "authors": [
            "Daniel Wang",
            "Eli Brignac",
            "Minjia Mao",
            "Xiao Fang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280561810",
          "title": "Memp: Exploring Agent Procedural Memory",
          "authors": [
            "Runnan Fang",
            "Yuan Liang",
            "Xiaobin Wang",
            "Jialong Wu",
            "Shuofei Qiao",
            "Pengjun Xie",
            "Fei Huang",
            "Huajun Chen",
            "Ningyu Zhang"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:280536147",
          "title": "OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use",
          "authors": [
            "Xueyu Hu",
            "Tao Xiong",
            "Biao Yi",
            "Zishu Wei",
            "Ruixuan Xiao",
            "Yurun Chen",
            "Jiasheng Ye",
            "Meiling Tao",
            "Xiangxin Zhou",
            "Ziyu Zhao",
            "Yuhuai Li",
            "Shengze Xu",
            "Shenzhi Wang",
            "Xinchen Xu",
            "Shuofei Qiao",
            "Zhaokai Wang",
            "Kun Kuang",
            "Tieyong Zeng",
            "Liang Wang",
            "Jiwei Li",
            "Y. Jiang",
            "Wangchunshu Zhou",
            "Guoyin Wang",
            "Keting Yin",
            "Zhou Zhao",
            "Hongxia Yang",
            "Fan Wu",
            "Shengyu Zhang",
            "Fei Wu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 29
        },
        {
          "external_id": "CorpusId:280536657",
          "title": "RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case",
          "authors": [
            "Baihui Xiao",
            "Chengjian Feng",
            "Zhijian Huang",
            "Feng Yan",
            "Yujie Zhong",
            "Lin Ma"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 3
        },
        {
          "external_id": "CorpusId:280526452",
          "title": "Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science",
          "authors": [
            "Jiayan Nan",
            "Wenquan Ma",
            "Wenlong Wu",
            "Yize Chen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:280526789",
          "title": "Probing the Gaps in ChatGPT Live Video Chat for Real-World Assistance for People who are Blind or Visually Impaired",
          "authors": [
            "Ruei-Che Chang",
            "Rosiana Natalie",
            "Wenqian Xu",
            "Jovan Zheng Feng Yap",
            "Anhong Guo"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280526980",
          "title": "Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow",
          "authors": [
            "Chia-Tung Ho",
            "Jing Gong",
            "Xufeng Yao",
            "Yunsheng Bai",
            "Abhishek B. Akkur",
            "Haoxing Ren"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:280422396",
          "title": "AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection",
          "authors": [
            "Peiran Wang",
            "Yang Liu",
            "Yunfei Lu",
            "Yifeng Cai",
            "Hongbo Chen",
            "Qingyou Yang",
            "Jie Zhang",
            "Jue Hong",
            "Ye Wu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 4
        },
        {
          "external_id": "CorpusId:280417422",
          "title": "Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents",
          "authors": [
            "Janika Deborah Gajo",
            "Gerarld Paul Merales",
            "Jerome Escarcha",
            "Brenden Ashley Molina",
            "Gian Nartea",
            "Emmanuel G. Maminta",
            "Juan Carlos Roldan",
            "Rowel O. Atienza"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:280401099",
          "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying",
          "authors": [
            "Qian Zhao",
            "Zhuo Sun",
            "Bin Guo",
            "Zhiwen Yu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 1
        },
        {
          "external_id": "CorpusId:280391740",
          "title": "Towards Interpretable Renal Health Decline Forecasting via Multi-LMM Collaborative Reasoning Framework",
          "authors": [
            "Peng-Yi Wu",
            "Pei-Cing Huang",
            "Ting-Yu Chen",
            "Chan-Tung Ku",
            "Ming-Yen Lin",
            "Yihuang Kang"
          ],
          "year": 2025,
          "venue": "IEEE International Conference on Information Reuse and Integration",
          "citation_count": 0
        },
        {
          "external_id": "CorpusId:280337602",
          "title": "Evaluation and Benchmarking of LLM Agents: A Survey",
          "authors": [
            "Mahmoud Mohammadi",
            "Yipeng Li",
            "Jane Lo",
            "Wendy Yip"
          ],
          "year": 2025,
          "venue": "Knowledge Discovery and Data Mining",
          "citation_count": 27
        },
        {
          "external_id": "CorpusId:280526822",
          "title": "Efficient Agents: Building Effective Agents While Reducing Cost",
          "authors": [
            "Ningning Wang",
            "Xavier Hu",
            "Pai Liu",
            "He Zhu",
            "Yue Hou",
            "Heyuan Huang",
            "Shengyu Zhang",
            "Jian Yang",
            "Jiaheng Liu",
            "Ge Zhang",
            "Changwang Zhang",
            "Jun Wang",
            "Y. Jiang",
            "Wangchunshu Zhou"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 8
        },
        {
          "external_id": "CorpusId:280401166",
          "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents",
          "authors": [
            "Haoran Sun",
            "Shaoning Zeng"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 5
        }
      ],
      "citations_fetched_at": "2025-12-21T20:23:47.725261",
      "references": [
        {
          "external_id": "CorpusId:276317785",
          "title": "AgentSociety: Large-Scale Simulation of LLM-Driven Generative Agents Advances Understanding of Human Behaviors and Society",
          "authors": [
            "J. Piao",
            "Yuwei Yan",
            "Jun Zhang",
            "Nian Li",
            "Junbo Yan",
            "Xiaochong Lan",
            "Zhihong Lu",
            "Zhiheng Zheng",
            "Jing Yi Wang",
            "Di Zhou",
            "Chen Gao",
            "Fengli Xu",
            "Fang Zhang",
            "Ke Rong",
            "Jun Su",
            "Yong Li"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 82
        },
        {
          "external_id": "CorpusId:276094310",
          "title": "RTBAgent: A LLM-based Agent System for Real-Time Bidding",
          "authors": [
            "Leng Cai",
            "Junxuan He",
            "Yikai Li",
            "Junjie Liang",
            "Yuanping Lin",
            "Ziming Quan",
            "Yawen Zeng",
            "Jin Xu"
          ],
          "year": 2025,
          "venue": "The Web Conference",
          "citation_count": 15
        },
        {
          "external_id": "CorpusId:275515451",
          "title": "CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation",
          "authors": [
            "Ruwei Pan",
            "Hongyu Zhang",
            "Chao Liu"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 23
        },
        {
          "external_id": "CorpusId:275471055",
          "title": "ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning",
          "authors": [
            "Xiangru Tang",
            "Tianyu Hu",
            "Muyang Ye",
            "Yanjun Shao",
            "Xunjian Yin",
            "Siru Ouyang",
            "Wangchunshu Zhou",
            "Pan Lu",
            "Zhuosheng Zhang",
            "Yilun Zhao",
            "Arman Cohan",
            "Mark Gerstein"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 24
        },
        {
          "external_id": "CorpusId:275471465",
          "title": "Multi-Agent Collaboration Mechanisms: A Survey of LLMs",
          "authors": [
            "Khanh-Tung Tran",
            "Dung Dao",
            "Minh-Duong Nguyen",
            "Quoc-Viet Pham",
            "Barry O’Sullivan",
            "Hoang D. Nguyen"
          ],
          "year": 2025,
          "venue": "arXiv.org",
          "citation_count": 218
        },
        {
          "external_id": "CorpusId:274306375",
          "title": "Large Language Model-Brained GUI Agents: A Survey",
          "authors": [
            "Chaoyun Zhang",
            "Shilin He",
            "Jiaxu Qian",
            "Bowen Li",
            "Liqun Li",
            "Si Qin",
            "Yu Kang",
            "Ming-Jie Ma",
            "Qingwei Lin",
            "S. Rajmohan",
            "Dongmei Zhang",
            "Qi Zhang"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 110
        },
        {
          "external_id": "CorpusId:273482193",
          "title": "From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs",
          "authors": [
            "Alireza Rezazadeh",
            "Zichao Li",
            "Wei Wei",
            "Yujia Bao"
          ],
          "year": 2024,
          "venue": "International Conference on Learning Representations",
          "citation_count": 17
        },
        {
          "external_id": "CorpusId:273345961",
          "title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory",
          "authors": [
            "Di Wu",
            "Hongwei Wang",
            "Wenhao Yu",
            "Yuwei Zhang",
            "Kai-Wei Chang",
            "Dong Yu"
          ],
          "year": 2024,
          "venue": "International Conference on Learning Representations",
          "citation_count": 80
        },
        {
          "external_id": "CorpusId:273218743",
          "title": "A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges",
          "authors": [
            "Xinyi Li",
            "Sai Wang",
            "Siqi Zeng",
            "Yu Wu",
            "Yi Yang"
          ],
          "year": 2024,
          "venue": "Vicinagearth",
          "citation_count": 236
        },
        {
          "external_id": "CorpusId:273185562",
          "title": "GenSim: A General Social Simulation Platform with Large Language Model based Agents",
          "authors": [
            "Jiakai Tang",
            "Heyang Gao",
            "Xuchen Pan",
            "Lei Wang",
            "Haoran Tan",
            "Dawei Gao",
            "Yushuo Chen",
            "Xu Chen",
            "Yankai Lin",
            "Yaliang Li",
            "Bolin Ding",
            "Jingren Zhou",
            "Jun Wang",
            "Jiayao Wen"
          ],
          "year": 2024,
          "venue": "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (System Demonstrations)",
          "citation_count": 30
        },
        {
          "external_id": "CorpusId:272987213",
          "title": "MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants",
          "authors": [
            "Zeyu Zhang",
            "Quanyu Dai",
            "Luyu Chen",
            "Zeren Jiang",
            "Rui Li",
            "Jieming Zhu",
            "Xu Chen",
            "Yi Xie",
            "Zhenhua Dong",
            "Ji-Rong Wen"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 11
        },
        {
          "external_id": "CorpusId:272911445",
          "title": "AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environments",
          "authors": [
            "Nan Sun",
            "Bo Mao",
            "Yongchang Li",
            "Lumeng Ma",
            "Di Guo",
            "Huaping Liu"
          ],
          "year": 2024,
          "venue": "IEEE/RJS International Conference on Intelligent RObots and Systems",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:272704025",
          "title": "MEOW: MEMOry Supervised LLM Unlearning Via Inverted Facts",
          "authors": [
            "Tianle Gu",
            "Kexin Huang",
            "Ruilin Luo",
            "Yuanqi Yao",
            "Yujiu Yang",
            "Yan Teng",
            "Yingchun Wang"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 15
        },
        {
          "external_id": "CorpusId:272423732",
          "title": "Large Language Model-Based Agents for Software Engineering: A Survey",
          "authors": [
            "Junwei Liu",
            "Kaixin Wang",
            "Yixuan Chen",
            "Xin Peng",
            "Zhenpeng Chen",
            "Lingming Zhang",
            "Yiling Lou"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 120
        },
        {
          "external_id": "CorpusId:271923927",
          "title": "MEDCO: Medical Education Copilots Based on A Multi-Agent Framework",
          "authors": [
            "Hao Wei",
            "Jianing Qiu",
            "Haibao Yu",
            "Wu Yuan"
          ],
          "year": 2024,
          "venue": "ECCV Workshops",
          "citation_count": 37
        },
        {
          "external_id": "CorpusId:271903170",
          "title": "Graph Retrieval-Augmented Generation: A Survey",
          "authors": [
            "Boci Peng",
            "Yun Zhu",
            "Yongchao Liu",
            "Xiaohe Bo",
            "Haizhou Shi",
            "Chuntao Hong",
            "Yan Zhang",
            "Siliang Tang"
          ],
          "year": 2024,
          "venue": "ACM Transactions on Information Systems",
          "citation_count": 244
        },
        {
          "external_id": "CorpusId:271534130",
          "title": "The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies",
          "authors": [
            "Feng He",
            "Tianqing Zhu",
            "Dayong Ye",
            "Bo Liu",
            "Wanlei Zhou",
            "Philip S. Yu"
          ],
          "year": 2024,
          "venue": "ACM Computing Surveys",
          "citation_count": 72
        },
        {
          "external_id": "CorpusId:271039035",
          "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents",
          "authors": [
            "Petr Anokhin",
            "Nikita Semenov",
            "Artyom Y. Sorokin",
            "Dmitry Evseev",
            "M. Burtsev",
            "Evgeny Burnaev"
          ],
          "year": 2024,
          "venue": "International Joint Conference on Artificial Intelligence",
          "citation_count": 30
        },
        {
          "external_id": "CorpusId:271039713",
          "title": "LLM Roleplay: Simulating Human-Chatbot Interaction",
          "authors": [
            "Hovhannes Tamoyan",
            "Hendrik Schuff",
            "Iryna Gurevych"
          ],
          "year": 2024,
          "venue": "Proceedings of the Third Workshop on Social Influence in Conversations (SICon 2025)",
          "citation_count": 17
        },
        {
          "external_id": "CorpusId:270870116",
          "title": "Memory3: Language Modeling with Explicit Memory",
          "authors": [
            "Hongkang Yang",
            "Zehao Lin",
            "Wenjin Wang",
            "Hao Wu",
            "Zhiyu Li",
            "Bo Tang",
            "Wenqiang Wei",
            "Jinbo Wang",
            "Zeyun Tang",
            "Shichao Song",
            "Chenyang Xi",
            "Yu Yu",
            "Kai Chen",
            "Feiyu Xiong",
            "Linpeng Tang",
            "E. Weinan"
          ],
          "year": 2024,
          "venue": "Journal of Machine Learning",
          "citation_count": 32
        },
        {
          "external_id": "CorpusId:270620354",
          "title": "GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models",
          "authors": [
            "Shilong Li",
            "Yancheng He",
            "Hangyu Guo",
            "Xingyuan Bu",
            "Ge Bai",
            "Jie Liu",
            "Jiaheng Liu",
            "Xingwei Qu",
            "Yangguang Li",
            "Wanli Ouyang",
            "Wenbo Su",
            "Bo Zheng"
          ],
          "year": 2024,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 30
        },
        {
          "external_id": "CorpusId:270560778",
          "title": "Towards Lifelong Dialogue Agents via Timeline-based Memory Management",
          "authors": [
            "Seo Hyun Kim",
            "Kai Tzu-iunn Ong",
            "Taeyoon Kwon",
            "Namyoung Kim",
            "Keummin Ka",
            "Seonghyeon Bae",
            "Yohan Jo",
            "Seung-won Hwang",
            "Dongha Lee",
            "Jinyoung Yeo"
          ],
          "year": 2024,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 9
        },
        {
          "external_id": "CorpusId:270371213",
          "title": "HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs",
          "authors": [
            "Pranoy Panda",
            "Ankush Agarwal",
            "Chaitanya Devaguptapu",
            "Manohar Kaul",
            "Prathosh Ap"
          ],
          "year": 2024,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 30
        },
        {
          "external_id": "CorpusId:270371602",
          "title": "FinVerse: An Autonomous Agent System for Versatile Financial Analysis",
          "authors": [
            "Siyu An",
            "Qin Li",
            "Junru Lu",
            "Di Yin",
            "Xing Sun"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 8
        },
        {
          "external_id": "CorpusId:269921148",
          "title": "MapCoder: Multi-Agent Code Generation for Competitive Problem Solving",
          "authors": [
            "Md. Ashraful Islam",
            "Mohammed Eunus Ali",
            "Md. Rizwan Parvez"
          ],
          "year": 2024,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 142
        },
        {
          "external_id": "CorpusId:269605152",
          "title": "Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents",
          "authors": [
            "Junkai Li",
            "Siyu Wang",
            "Meng Zhang",
            "Weitao Li",
            "Yunghwei Lai",
            "Xinhui Kang",
            "Weizhi Ma",
            "Yang Liu"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 205
        },
        {
          "external_id": "CorpusId:269457256",
          "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
          "authors": [
            "Yucheng Hu",
            "Yuxing Lu"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 31
        },
        {
          "external_id": "CorpusId:269293342",
          "title": "Information Re-Organization Improves Reasoning in Large Language Models",
          "authors": [
            "Xiaoxia Cheng",
            "Zeqi Tan",
            "Weiming Lu"
          ],
          "year": 2024,
          "venue": "Neural Information Processing Systems",
          "citation_count": 5
        },
        {
          "external_id": "CorpusId:268856673",
          "title": "A Survey on Large Language Model-Based Game Agents",
          "authors": [
            "Sihao Hu",
            "Tiansheng Huang",
            "Fatih Ilhan",
            "S. Tekin",
            "Gaowen Liu",
            "R. Kompella",
            "Ling Liu"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 105
        },
        {
          "external_id": "CorpusId:268692056",
          "title": "RepairAgent: An Autonomous, LLM-Based Agent for Program Repair",
          "authors": [
            "Islem Bouzenia",
            "Prem Devanbu",
            "Michael Pradel"
          ],
          "year": 2024,
          "venue": "International Conference on Software Engineering",
          "citation_count": 190
        },
        {
          "external_id": "CorpusId:268553537",
          "title": "Detoxifying Large Language Models via Knowledge Editing",
          "authors": [
            "Mengru Wang",
            "Ningyu Zhang",
            "Ziwen Xu",
            "Zekun Xi",
            "Shumin Deng",
            "Yunzhi Yao",
            "Qishen Zhang",
            "Linyi Yang",
            "Jindong Wang",
            "Huajun Chen"
          ],
          "year": 2024,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 86
        },
        {
          "external_id": "CorpusId:268264809",
          "title": "Online Adaptation of Language Models with a Memory of Amortized Contexts",
          "authors": [
            "Jihoon Tack",
            "Jaehyung Kim",
            "Eric Mitchell",
            "Jinwoo Shin",
            "Yee Whye Teh",
            "Jonathan Richard Schwarz"
          ],
          "year": 2024,
          "venue": "Neural Information Processing Systems",
          "citation_count": 29
        },
        {
          "external_id": "CorpusId:268041615",
          "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
          "authors": [
            "Adyasha Maharana",
            "Dong-Ho Lee",
            "S. Tulyakov",
            "Mohit Bansal",
            "Francesco Barbieri",
            "Yuwei Fang"
          ],
          "year": 2024,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 171
        },
        {
          "external_id": "CorpusId:267938190",
          "title": "PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Synthesis in Question Answering",
          "authors": [
            "Yiming Du",
            "Hongru Wang",
            "Zhengyi Zhao",
            "Bin Liang",
            "Baojun Wang",
            "Wanjun Zhong",
            "Zezhong Wang",
            "Kam-Fai Wong"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 14
        },
        {
          "external_id": "CorpusId:267897830",
          "title": "Large multimodal agents: a survey",
          "authors": [
            "Junlin Xie",
            "Zhihong Chen",
            "Ruifei Zhang",
            "Xiang Wan",
            "Guanbin Li"
          ],
          "year": 2024,
          "venue": "Visual Intelligence",
          "citation_count": 78
        },
        {
          "external_id": "CorpusId:267682382",
          "title": "Model Compression and Efficient Inference for Large Language Models: A Survey",
          "authors": [
            "Wenxiao Wang",
            "Wei Chen",
            "Yicong Luo",
            "Yongliu Long",
            "Zhengkai Lin",
            "Liye Zhang",
            "Binbin Lin",
            "Deng Cai",
            "Xiaofei He"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 85
        },
        {
          "external_id": "CorpusId:267658120",
          "title": "Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",
          "authors": [
            "Zhichen Dong",
            "Zhanhui Zhou",
            "Chao Yang",
            "Jing Shao",
            "Yu Qiao"
          ],
          "year": 2024,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 117
        },
        {
          "external_id": "CorpusId:267617032",
          "title": "Large Language Models: A Survey",
          "authors": [
            "Shervin Minaee",
            "Tomáš Mikolov",
            "Narjes Nikzad",
            "M. Chenaghlu",
            "R. Socher",
            "Xavier Amatriain",
            "Jianfeng Gao"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 734
        },
        {
          "external_id": "CorpusId:267500314",
          "title": "Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models",
          "authors": [
            "Kelvin J.L. Koa",
            "Yunshan Ma",
            "Ritchie Ng",
            "Tat-Seng Chua"
          ],
          "year": 2024,
          "venue": "The Web Conference",
          "citation_count": 48
        },
        {
          "external_id": "CorpusId:267499667",
          "title": "QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model",
          "authors": [
            "Sai Wang",
            "Hang Yuan",
            "Lionel M. Ni",
            "Jian Guo"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 24
        },
        {
          "external_id": "CorpusId:267411892",
          "title": "Understanding the planning of LLM agents: A survey",
          "authors": [
            "Xu Huang",
            "Weiwen Liu",
            "Xiaolong Chen",
            "Xingmei Wang",
            "Hao Wang",
            "Defu Lian",
            "Yasheng Wang",
            "Ruiming Tang",
            "Enhong Chen"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 333
        },
        {
          "external_id": "CorpusId:267412232",
          "title": "Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models",
          "authors": [
            "Xindi Wang",
            "Mahsa Salmani",
            "Parsa Omidi",
            "Xiangyu Ren",
            "Mehdi Rezagholizadeh",
            "A. Eshaghi"
          ],
          "year": 2024,
          "venue": "International Joint Conference on Artificial Intelligence",
          "citation_count": 76
        },
        {
          "external_id": "CorpusId:267627389",
          "title": "A Survey on Large Language Model Hallucination via a Creativity Perspective",
          "authors": [
            "Xuhui Jiang",
            "Yuxing Tian",
            "Fengrui Hua",
            "Chengjin Xu",
            "Yuanzhuo Wang",
            "Jian Guo"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 51
        },
        {
          "external_id": "CorpusId:267334803",
          "title": "Neighboring Perturbations of Knowledge Editing on Large Language Models",
          "authors": [
            "Jun-Yu Ma",
            "Jia-Chen Gu",
            "Ningyu Zhang",
            "Zhen-Hua Ling"
          ],
          "year": 2024,
          "venue": "International Conference on Machine Learning",
          "citation_count": 6
        },
        {
          "external_id": "CorpusId:267406814",
          "title": "Security and Privacy Challenges of Large Language Models: A Survey",
          "authors": [
            "B. Das",
            "M. H. Amini",
            "Yanzhao Wu"
          ],
          "year": 2024,
          "venue": "ACM Computing Surveys",
          "citation_count": 291
        },
        {
          "external_id": "CorpusId:267312283",
          "title": "A Comprehensive Survey of Compression Algorithms for Language Models",
          "authors": [
            "Seungcheol Park",
            "Jaehyeon Choi",
            "Sojin Lee",
            "U. Kang"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 20
        },
        {
          "external_id": "CorpusId:267412980",
          "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges",
          "authors": [
            "Taicheng Guo",
            "Xiuying Chen",
            "Yaqi Wang",
            "Ruidi Chang",
            "Shichao Pei",
            "N. Chawla",
            "Olaf Wiest",
            "Xiangliang Zhang"
          ],
          "year": 2024,
          "venue": "International Joint Conference on Artificial Intelligence",
          "citation_count": 594
        },
        {
          "external_id": "CorpusId:266999544",
          "title": "The What, Why, and How of Context Length Extension Techniques in Large Language Models - A Detailed Survey",
          "authors": [
            "Saurav Pawar",
            "S. Tonmoy",
            "S. M. M. Zaman",
            "Vinija Jain",
            "Aman Chadha",
            "Amitava Das"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 39
        },
        {
          "external_id": "CorpusId:266999556",
          "title": "CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges",
          "authors": [
            "Kechi Zhang",
            "Jia Li",
            "Ge Li",
            "Xianjie Shi",
            "Zhi Jin"
          ],
          "year": 2024,
          "venue": "Annual Meeting of the Association for Computational Linguistics",
          "citation_count": 183
        },
        {
          "external_id": "CorpusId:266933252",
          "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security",
          "authors": [
            "Yuanchun Li",
            "Hao Wen",
            "Weijun Wang",
            "Xiangyu Li",
            "Yizhen Yuan",
            "Guohong Liu",
            "Jiacheng Liu",
            "Wenxing Xu",
            "Xiang Wang",
            "Yi Sun",
            "Rui Kong",
            "Yile Wang",
            "Hanfei Geng",
            "Jian Luan",
            "Xuefeng Jin",
            "Zi-Liang Ye",
            "Guanjing Xiong",
            "Fan Zhang",
            "Xiang Li",
            "Mengwei Xu",
            "Zhijun Li",
            "Peng Li",
            "Yang Liu",
            "Yaqiong Zhang",
            "Yunxin Liu"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 261
        },
        {
          "external_id": "CorpusId:266844635",
          "title": "Agent AI: Surveying the Horizons of Multimodal Interaction",
          "authors": [
            "Zane Durante",
            "Qiuyuan Huang",
            "Naoki Wake",
            "Ran Gong",
            "J. Park",
            "Bidipta Sarkar",
            "Rohan Taori",
            "Yusuke Noda",
            "D. Terzopoulos",
            "Yejin Choi",
            "Katsushi Ikeuchi",
            "Hoi Vo",
            "Fei-Fei Li",
            "Jianfeng Gao"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:266844118",
          "title": "Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects",
          "authors": [
            "Yuheng Cheng",
            "Ceyao Zhang",
            "Zhengwen Zhang",
            "Xiangrui Meng",
            "Sirui Hong",
            "Wenhao Li",
            "Zihao Wang",
            "Zekai Wang",
            "Feng Yin",
            "Junhua Zhao",
            "Xiuqiang He"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 147
        },
        {
          "external_id": "CorpusId:266818292",
          "title": "XUAT-Copilot: Multi-Agent Collaborative System for Automated User Acceptance Testing with Large Language Model",
          "authors": [
            "Zhitao Wang",
            "Wei Wang",
            "Zirao Li",
            "Long Wang",
            "Can Yi",
            "Xinjie Xu",
            "Luyang Cao",
            "Hanjing Su",
            "Shouzhi Chen",
            "Jun Zhou"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:266725300",
          "title": "A Comprehensive Study of Knowledge Editing for Large Language Models",
          "authors": [
            "Ningyu Zhang",
            "Yunzhi Yao",
            "Bo Tian",
            "Peng Wang",
            "Shumin Deng",
            "Mengru Wang",
            "Zekun Xi",
            "Shengyu Mao",
            "Jintian Zhang",
            "Yuansheng Ni",
            "Siyuan Cheng",
            "Ziwen Xu",
            "Xin Xu",
            "Jia-Chen Gu",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Lei Liang",
            "Zhiqiang Zhang",
            "Xiaowei Zhu",
            "Jun Zhou",
            "Huajun Chen"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 123
        },
        {
          "external_id": "CorpusId:266725532",
          "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
          "authors": [
            "S. Tonmoy",
            "S. M. M. Zaman",
            "Vinija Jain",
            "Anku Rani",
            "Vipula Rawte",
            "Aman Chadha",
            "Amitava Das"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 331
        },
        {
          "external_id": "CorpusId:266693677",
          "title": "Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models",
          "authors": [
            "Guangji Bai",
            "Zheng Chai",
            "Chen Ling",
            "Shiyu Wang",
            "Jiaying Lu",
            "Nan Zhang",
            "Tingwei Shi",
            "Ziyang Yu",
            "Mengdan Zhu",
            "Yifei Zhang",
            "Carl Yang",
            "Yue Cheng",
            "Liang Zhao"
          ],
          "year": 2024,
          "venue": "arXiv.org",
          "citation_count": 75
        },
        {
          "external_id": "CorpusId:266690657",
          "title": "Large language models for generative information extraction: a survey",
          "authors": [
            "Derong Xu",
            "Wei Chen",
            "Wenjun Peng",
            "Chao Zhang",
            "Tong Xu",
            "Xiangyu Zhao",
            "Xian Wu",
            "Yefeng Zheng",
            "Enhong Chen"
          ],
          "year": 2023,
          "venue": "Frontiers of Computer Science",
          "citation_count": 286
        },
        {
          "external_id": "CorpusId:266690872",
          "title": "LARP: Language-Agent Role Play for Open-World Games",
          "authors": [
            "Ming Yan",
            "Ruihao Li",
            "Hao Zhang",
            "Hao Wang",
            "Zhilan Yang",
            "Ji Yan"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 22
        },
        {
          "external_id": "CorpusId:266551872",
          "title": "Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems",
          "authors": [
            "Xupeng Miao",
            "Gabriele Oliaro",
            "Zhihao Zhang",
            "Xinhao Cheng",
            "Hongyi Jin",
            "Tianqi Chen",
            "Zhihao Jia"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 118
        },
        {
          "external_id": "CorpusId:266362573",
          "title": "Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment",
          "authors": [
            "Lingling Xu",
            "Haoran Xie",
            "S. J. Qin",
            "Xiaohui Tao",
            "F. Wang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 257
        },
        {
          "external_id": "CorpusId:266359151",
          "title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
          "authors": [
            "Yunfan Gao",
            "Yun Xiong",
            "Xinyu Gao",
            "Kangxiang Jia",
            "Jinliu Pan",
            "Yuxi Bi",
            "Yi Dai",
            "Jiawei Sun",
            "Qianyu Guo",
            "Meng Wang",
            "Haofen Wang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 2627
        },
        {
          "external_id": "CorpusId:266174760",
          "title": "Privacy Issues in Large Language Models: A Survey",
          "authors": [
            "Seth Neel",
            "Peter Chang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 80
        },
        {
          "external_id": "CorpusId:266149461",
          "title": "KwaiAgents: Generalized Information-seeking Agent System with Large Language Models",
          "authors": [
            "Haojie Pan",
            "Zepeng Zhai",
            "Hao Yuan",
            "Yaojia Lv",
            "Ruiji Fu",
            "Ming Liu",
            "Zhongyuan Wang",
            "Bing Qin"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:266694338",
          "title": "LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem",
          "authors": [
            "Yingqiang Ge",
            "Yujie Ren",
            "Wenyue Hua",
            "Shuyuan Xu",
            "Juntao Tan",
            "Yongfeng Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 38
        },
        {
          "external_id": "CorpusId:266044196",
          "title": "Efficient Large Language Models: A Survey",
          "authors": [
            "Zhongwei Wan",
            "Xin Wang",
            "Che Liu",
            "Samiul Alam",
            "Yu Zheng",
            "Jiachen Liu",
            "Zhongnan Qu",
            "Shen Yan",
            "Yi Zhu",
            "Quanlu Zhang",
            "Mosharaf Chowdhury",
            "Mi Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 188
        },
        {
          "external_id": "CorpusId:265609409",
          "title": "A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly",
          "authors": [
            "Yifan Yao",
            "Jinhao Duan",
            "Kaidi Xu",
            "Yuanfang Cai",
            "Eric Sun",
            "Yue Zhang"
          ],
          "year": 2023,
          "venue": "High-Confidence Computing",
          "citation_count": 878
        },
        {
          "external_id": "CorpusId:265690585",
          "title": "MobileGPT: Augmenting LLM with Human-like App Memory for Mobile Task Automation",
          "authors": [
            "Sunjae Lee",
            "Junyoung Choi",
            "Jungjae Lee",
            "Munim Hasan Wasi",
            "Hojun Choi",
            "Steven Y. Ko",
            "Sangeun Oh",
            "Insik Shin"
          ],
          "year": 2023,
          "venue": "ACM/IEEE International Conference on Mobile Computing and Networking",
          "citation_count": 45
        },
        {
          "external_id": "CorpusId:266149522",
          "title": "Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects",
          "authors": [
            "Tianyu He",
            "Guanghui Fu",
            "Y. Yu",
            "Fan Wang",
            "Jianqiang Li",
            "Qing Zhao",
            "Changwei Song",
            "Hongzhi Qi",
            "Dan Luo",
            "Huijing Zou",
            "Bing Xiang Yang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 13
        },
        {
          "external_id": "CorpusId:265466273",
          "title": "RTLFixer: Automatically Fixing RTL Syntax Errors with Large Language Model",
          "authors": [
            "Yun-Da Tsai",
            "Mingjie Liu",
            "Haoxing Ren"
          ],
          "year": 2023,
          "venue": "Design Automation Conference",
          "citation_count": 129
        },
        {
          "external_id": "CorpusId:265466372",
          "title": "CharacterGLM: Customizing Chinese Conversational AI Characters with Large Language Models",
          "authors": [
            "Jinfeng Zhou",
            "Zhuang Chen",
            "Dazhen Wan",
            "Bosi Wen",
            "Yi Song",
            "Jifan Yu",
            "Yongkang Huang",
            "Libiao Peng",
            "Jiaming Yang",
            "Xiyao Xiao",
            "Sahand Sabour",
            "Xiaohan Zhang",
            "Wenjing Hou",
            "Yijia Zhang",
            "Yuxiao Dong",
            "Jie Tang",
            "Minlie Huang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 34
        },
        {
          "external_id": "CorpusId:265498466",
          "title": "War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars",
          "authors": [
            "Wenyue Hua",
            "Lizhou Fan",
            "Lingyao Li",
            "Kai Mei",
            "Jianchao Ji",
            "Yingqiang Ge",
            "Libby Hemphill",
            "Yongfeng Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 127
        },
        {
          "external_id": "CorpusId:265445755",
          "title": "FinMem: A Performance-Enhanced LLM Trading Agent With Layered Memory and Character Design",
          "authors": [
            "Yangyang Yu",
            "Haohang Li",
            "Zhi Chen",
            "Yuechen Jiang",
            "Yang Li",
            "Jordan W. Suchow",
            "Denghui Zhang",
            "K. Khashanah"
          ],
          "year": 2023,
          "venue": "IEEE Transactions on Big Data",
          "citation_count": 127
        },
        {
          "external_id": "CorpusId:265351653",
          "title": "Multimodal Large Language Models: A Survey",
          "authors": [
            "Jiayang Wu",
            "Wensheng Gan",
            "Zefeng Chen",
            "Shicheng Wan",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "BigData Congress [Services Society]",
          "citation_count": 288
        },
        {
          "external_id": "CorpusId:265308931",
          "title": "A Survey on Multimodal Large Language Models for Autonomous Driving",
          "authors": [
            "Can Cui",
            "Yunsheng Ma",
            "Xu Cao",
            "Wenqian Ye",
            "Yang Zhou",
            "Kaizhao Liang",
            "Jintai Chen",
            "Juanwu Lu",
            "Zichong Yang",
            "Kuei-Da Liao",
            "Tianren Gao",
            "Erlong Li",
            "Kun Tang",
            "Zhipeng Cao",
            "Tongxi Zhou",
            "Ao Liu",
            "Xinrui Yan",
            "Shuqi Mei",
            "Jianguo Cao",
            "Ziran Wang",
            "Chao Zheng"
          ],
          "year": 2023,
          "venue": "2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW)",
          "citation_count": 420
        },
        {
          "external_id": "CorpusId:265308945",
          "title": "Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey",
          "authors": [
            "Yunpeng Huang",
            "Jingwei Xu",
            "Zixu Jiang",
            "Junyu Lai",
            "Zenan Li",
            "Yuan Yao",
            "Taolue Chen",
            "Lijuan Yang",
            "Zhou Xin",
            "Xiaoxing Ma"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 97
        },
        {
          "external_id": "CorpusId:265294410",
          "title": "TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems",
          "authors": [
            "Yilun Kong",
            "Jingqing Ruan",
            "Yihong Chen",
            "Bin Zhang",
            "Tianpeng Bao",
            "Shiwei Shi",
            "Guoqing Du",
            "Xiaoru Hu",
            "Hangyu Mao",
            "Ziyue Li",
            "Xingyu Zeng",
            "Rui Zhao"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 50
        },
        {
          "external_id": "CorpusId:265281389",
          "title": "A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends",
          "authors": [
            "Zibin Zheng",
            "Kaiwen Ning",
            "Yanlin Wang",
            "Jingwen Zhang",
            "Dewu Zheng",
            "Mingxi Ye",
            "Jiachi Chen"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 81
        },
        {
          "external_id": "CorpusId:265295651",
          "title": "Chemist-X: Large Language Model-empowered Agent for Reaction Condition Recommendation in Chemical Synthesis",
          "authors": [
            "Kexin Chen",
            "Junyou Li",
            "Kunyi Wang",
            "Yuyang Du",
            "Jiahui Yu",
            "Jiamin Lu",
            "Lanqing Li",
            "Jiezhong Qiu",
            "Jianzhang Pan",
            "Yi Huang",
            "Qun Fang",
            "P. Heng",
            "Guangyong Chen"
          ],
          "year": 2023,
          "venue": "",
          "citation_count": 22
        },
        {
          "external_id": "CorpusId:265212826",
          "title": "Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory",
          "authors": [
            "Lei Liu",
            "Xiaoyan Yang",
            "Yue Shen",
            "Binbin Hu",
            "Zhiqiang Zhang",
            "Jinjie Gu",
            "Guannan Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 40
        },
        {
          "external_id": "CorpusId:265213049",
          "title": "Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning",
          "authors": [
            "Xin Su",
            "Tiep Le",
            "Steven Bethard",
            "Phillip Howard"
          ],
          "year": 2023,
          "venue": "North American Chapter of the Association for Computational Linguistics",
          "citation_count": 12
        },
        {
          "external_id": "CorpusId:265149884",
          "title": "Large Language Models for Robotics: A Survey",
          "authors": [
            "Fanlong Zeng",
            "Wensheng Gan",
            "Yongheng Wang",
            "Ning Liu",
            "Philip S. Yu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 189
        },
        {
          "external_id": "CorpusId:265129059",
          "title": "JARVIS-1: Open-World Multi-Task Agents With Memory-Augmented Multimodal Language Models",
          "authors": [
            "Zihao Wang",
            "Shaofei Cai",
            "Anji Liu",
            "Yonggang Jin",
            "Jinbing Hou",
            "Bowei Zhang",
            "Haowei Lin",
            "Zhaofeng He",
            "Zilong Zheng",
            "Yaodong Yang",
            "Xiaojian Ma",
            "Yitao Liang"
          ],
          "year": 2023,
          "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
          "citation_count": 148
        },
        {
          "external_id": "CorpusId:265128686",
          "title": "Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications",
          "authors": [
            "Zhangyin Feng",
            "Weitao Ma",
            "Weijiang Yu",
            "Lei Huang",
            "Haotian Wang",
            "Qianglong Chen",
            "Weihua Peng",
            "Xiaocheng Feng",
            "Bing Qin",
            "Ting Liu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 46
        },
        {
          "external_id": "CorpusId:265067168",
          "title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions",
          "authors": [
            "Lei Huang",
            "Weijiang Yu",
            "Weitao Ma",
            "Weihong Zhong",
            "Zhangyin Feng",
            "Haotian Wang",
            "Qianglong Chen",
            "Weihua Peng",
            "Xiaocheng Feng",
            "Bing Qin",
            "Ting Liu"
          ],
          "year": 2023,
          "venue": "ACM Trans. Inf. Syst.",
          "citation_count": 1802
        },
        {
          "external_id": "CorpusId:265067484",
          "title": "A Survey of Large Language Models in Medicine: Progress, Application, and Challenge",
          "authors": [
            "Hongjian Zhou",
            "Boyang Gu",
            "Xinyu Zou",
            "Jinfa Huang",
            "Yiru Li",
            "Sam S. Chen",
            "Peilin Zhou",
            "Junling Liu",
            "Y. Hua",
            "Chengfeng Mao",
            "Xian Wu",
            "Zheng Li",
            "Fenglin Liu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 177
        },
        {
          "external_id": "CorpusId:265043051",
          "title": "Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning",
          "authors": [
            "Ruosen Li",
            "Xinya Du"
          ],
          "year": 2023,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 29
        },
        {
          "external_id": "CorpusId:264935408",
          "title": "LLM4Drive: A Survey of Large Language Models for Autonomous Driving",
          "authors": [
            "Zhenjie Yang",
            "Xiaosong Jia",
            "Hongyang Li",
            "Junchi Yan"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 163
        },
        {
          "external_id": "CorpusId:264825354",
          "title": "Evaluating Large Language Models: A Comprehensive Survey",
          "authors": [
            "Zishan Guo",
            "Renren Jin",
            "Chuang Liu",
            "Yufei Huang",
            "Dan Shi",
            "Supryadi",
            "Linhao Yu",
            "Yan Liu",
            "Jiaxuan Li",
            "Bojian Xiong",
            "Deyi Xiong"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 264
        },
        {
          "external_id": "CorpusId:264590387",
          "title": "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game",
          "authors": [
            "Zelai Xu",
            "Chao Yu",
            "Fei Fang",
            "Yu Wang",
            "Yi Wu"
          ],
          "year": 2023,
          "venue": "International Conference on Machine Learning",
          "citation_count": 126
        },
        {
          "external_id": "CorpusId:264487299",
          "title": "RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models",
          "authors": [
            "Zefan Wang",
            "Zichuan Liu",
            "Yingying Zhang",
            "Aoxiao Zhong",
            "Lunting Fan",
            "Lingfei Wu",
            "Qingsong Wen"
          ],
          "year": 2023,
          "venue": "International Conference on Information and Knowledge Management",
          "citation_count": 59
        },
        {
          "external_id": "CorpusId:264487359",
          "title": "Knowledge Editing for Large Language Models: A Survey",
          "authors": [
            "Song Wang",
            "Yaochen Zhu",
            "Haochen Liu",
            "Zaiyi Zheng",
            "Chen Chen",
            "Jundong Li"
          ],
          "year": 2023,
          "venue": "ACM Computing Surveys",
          "citation_count": 197
        },
        {
          "external_id": "CorpusId:264172191",
          "title": "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks",
          "authors": [
            "Erfan Shayegani",
            "Md. Abdullah Al Mamun",
            "Yu Fu",
            "Pedram Zaree",
            "Yue Dong",
            "Nael B. Abu-Ghazaleh"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 218
        },
        {
          "external_id": "CorpusId:264145862",
          "title": "Character-LLM: A Trainable Agent for Role-Playing",
          "authors": [
            "Yunfan Shao",
            "Linyang Li",
            "Junqi Dai",
            "Xipeng Qiu"
          ],
          "year": 2023,
          "venue": "Conference on Empirical Methods in Natural Language Processing",
          "citation_count": 338
        },
        {
          "external_id": "CorpusId:264128019",
          "title": "AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems",
          "authors": [
            "Junjie Zhang",
            "Yupeng Hou",
            "Ruobing Xie",
            "Wenqi Sun",
            "Julian McAuley",
            "Wayne Xin Zhao",
            "Leyu Lin",
            "Ji-rong Wen"
          ],
          "year": 2023,
          "venue": "The Web Conference",
          "citation_count": 120
        },
        {
          "external_id": "CorpusId:263909014",
          "title": "MemGPT: Towards LLMs as Operating Systems",
          "authors": [
            "Charles Packer",
            "Vivian Fang",
            "Shishir G. Patil",
            "Kevin Lin",
            "Sarah Wooders",
            "Joseph Gonzalez"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 267
        },
        {
          "external_id": "CorpusId:263909137",
          "title": "GameGPT: Multi-agent Collaborative Framework for Game Development",
          "authors": [
            "Dake Chen",
            "Hanbin Wang",
            "Yunhao Huo",
            "Yuzhao Li",
            "Haoyang Zhang"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 31
        },
        {
          "external_id": "CorpusId:263835191",
          "title": "MatChat: A large language model and application service platform for materials science",
          "authors": [
            "Ziyi Chen",
            "Fankai Xie",
            "Meng Wan",
            "Yang Yuan",
            "Miao Liu",
            "Zongguo Wang",
            "Sheng Meng",
            "Yangang Wang"
          ],
          "year": 2023,
          "venue": "Chinese Physics B",
          "citation_count": 24
        },
        {
          "external_id": "CorpusId:263829396",
          "title": "A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics",
          "authors": [
            "Kai He",
            "Rui Mao",
            "Qika Lin",
            "Yucheng Ruan",
            "Xiang Lan",
            "Mengling Feng",
            "Erik Cambria"
          ],
          "year": 2023,
          "venue": "Information Fusion",
          "citation_count": 255
        },
        {
          "external_id": "CorpusId:263828774",
          "title": "From Text to Tactic: Evaluating LLMs Playing the Game of Avalon",
          "authors": [
            "Jonathan Light",
            "Min Cai",
            "Sheng Shen",
            "Ziniu Hu"
          ],
          "year": 2023,
          "venue": "arXiv.org",
          "citation_count": 22
        },
        {
          "external_id": "CorpusId:263608742",
          "title": "Editing Personality For Large Language Models",
          "authors": [
            "Shengyu Mao",
            "Ningyu Zhang",
            "Xiaohan Wang",
            "Mengru Wang",
            "Yunzhi Yao",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Huajun Chen"
          ],
          "year": 2023,
          "venue": "Natural Language Processing and Chinese Computing",
          "citation_count": 16
        }
      ],
      "references_fetched_at": "2025-12-21T20:17:33.098634"
    },
    "summary": "## 1. 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | LLM-based agents 的记忆机制研究零散，缺乏系统性的分类、比较和设计模式总结，难以指导未来研究 [cite] |\n| **核心方案** | 提出首个关于 LLM-based agents 记忆机制的系统性综述，涵盖定义、必要性、设计、评估和应用 [cite] |\n| **关键概念** | 记忆被定义为代理在环境交互中积累和使用的信息，分为狭义（历史交互记录）和广义（包括外部知识等） [cite] |\n| **核心数据** | 创建并维护开源仓库 https://github.com/nuster1128/LLM_Agent_Memory_Survey 以跟踪领域最新进展 [cite] |\n| **主要结论** | 记忆模块是 LLM-based agents 实现自我演进和解决复杂现实问题的关键，未来需关注参数化记忆、多智能体记忆等方向 [cite] |\n\n## 2. 💡 费曼深度解读 (The Feynman Explanation)\n\n想象一下，你要教一个完全不懂AI的建筑师理解这篇论文的核心——**“LLM-based Agent 的记忆”**。\n\n**原来的LLM（比如ChatGPT）就像一个记忆力极差的临时工。** 你让他帮你规划一次旅行，他每次只能根据你当前的一句话来回答。如果你说“我想去北京”，他可能会推荐故宫；但如果你十分钟后再说“但我只有半天时间”，他已经完全忘了你之前说要去北京这件事了。他就像一个没有笔记本的助手，每次对话都是全新的开始。\n\n**而这篇论文讨论的“LLM-based Agent”，则像是一个配备了超级工作日志的专业项目经理。** 这个“记忆”就是他的工作日志。这篇综述的核心工作，就是系统地梳理了市面上各种“工作日志”的写法、用法和效果。\n\n*   **记忆的来源（Memory Sources）**：就像项目经理的日志里可以记什么？可以记本次项目会议的内容（Inside-trial），也可以翻看之前类似项目的记录吸取经验（Cross-trial），甚至可以去查阅行业标准手册（External Knowledge）。\n*   **记忆的形式（Memory Forms）**：日志可以怎么写？可以像传统一样用文字一条条记下来（Textual Form），方便查阅和解释；也可以像高手一样，把经验教训内化成自己的工作直觉和条件反射（Parametric Form），遇到类似情况直接反应。\n*   **记忆的操作（Memory Operations）**：怎么用这个日志？包括什么时候记一笔（Writing），如何整理和删除过时信息（Management），以及如何在需要时快速找到关键信息（Reading）。\n\n**所以，这篇论文的“创新点”不在于发明了一种新的记忆方法，而在于它像一个专业的“项目管理方法论专家”，把市面上所有零散的“工作日志系统”进行了归纳、比较和评级，总结出了一套通用的设计模式。** 它告诉你，为什么项目经理必须记日志（必要性），日志可以记什么、怎么记、怎么用（设计逻辑），以及如何判断一个日志系统是不是真的好用（评估方法）。\n\n**底层的因果链条是：** 拥有了系统化、结构化的记忆，智能体才能像人一样，从过去的成功和失败中学习，调整策略，从而实现“自我演进”，去处理需要多步交互、信息随时间累积的复杂现实任务。没有记忆，LLM就只是一个聪明的“对话机器”；有了记忆，它才真正开始向“智能代理”迈进。\n\n## 3. ⚔️ 对抗性评审 (The Adversarial Review)\n\n作为苛刻的审稿人#2，我必须指出这篇系统性综述存在的几个潜在弱点：\n\n1.  **分类框架的主观性与时效性风险：** 论文提出的分类框架（如记忆来源、形式、操作）虽然清晰，但其合理性和完备性高度依赖于作者对现有文献的主观归纳。这是一个快速发展的领域，新的记忆机制可能无法被现有框架很好地容纳。例如，将记忆简单二分為“文本”和“参数”形式可能过于粗糙，忽略了中间状态或混合形式。这套分类法可能很快会过时或被证明不够普适 [cite]。\n2.  **缺乏对记忆机制“有效性”的批判性分析：** 综述大量列举了各种记忆设计，但缺乏对这些机制在实际应用中究竟“多大程度上”提升了智能体性能的深度分析。很多被引用的研究可能只是在特定、简化的实验环境中展示了优势，其结论在更复杂、开放的现实场景中是否依然成立存疑。论文未能充分讨论这些记忆方法各自的局限性、计算开销以及可扩展性瓶颈 [cite]。\n3.  **未来方向的展望偏向宏大叙事，缺乏具体路径：** 第8节提出的未来方向（如参数化记忆、终身学习）虽然重要，但流于表面，更像是领域共识的罗列，而非基于本次综述的深刻洞察。未能提出更具挑战性、更具体的“下一步”研究问题，例如，如何定量衡量不同记忆机制对“自我演进”能力的贡献，或者如何设计实验来验证记忆在长期任务中的因果作用 [cite]。\n\n## 4. 📝 一句话总结 (The Takeaway)\n\n如果我只记这篇论文的一个贡献，那应该是：**它首次为LLM智能体领域杂乱无章的记忆机制研究建立了一个系统性的分类、分析和评估框架，为后续研究提供了重要的“地图”和“设计模式”参考。**",
    "structure": {
      "sections": [
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 5
        },
        {
          "title": "Contents",
          "level": 1,
          "start_line": 26
        },
        {
          "title": "1 Introduction 4",
          "level": 1,
          "start_line": 28
        },
        {
          "title": "2 Related Surveys 5",
          "level": 1,
          "start_line": 30
        },
        {
          "title": "3 What is the Memory of LLM-based Agent 7",
          "level": 1,
          "start_line": 35
        },
        {
          "title": "4 Why We Need the Memory in LLM-based Agent 10",
          "level": 1,
          "start_line": 42
        },
        {
          "title": "5 How to Implement the Memory of LLM-based Agent 11",
          "level": 1,
          "start_line": 48
        },
        {
          "title": "6 How to Evaluate the Memory in LLM-based Agent 20",
          "level": 1,
          "start_line": 68
        },
        {
          "title": "7 Memory-enhanced Agent Applications 23",
          "level": 1,
          "start_line": 85
        },
        {
          "title": "8 Limitations & Future Directions 27",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "9 Conclusion 28",
          "level": 1,
          "start_line": 102
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 104
        },
        {
          "title": "2 Related Surveys",
          "level": 1,
          "start_line": 120
        },
        {
          "title": "2.1 Surveys on Large Language Models",
          "level": 1,
          "start_line": 124
        },
        {
          "title": "2.2 Surveys on Large Language Model-based Agents",
          "level": 1,
          "start_line": 139
        },
        {
          "title": "3 What is the Memory of LLM-based Agent",
          "level": 1,
          "start_line": 145
        },
        {
          "title": "3.1 Basic Knowledge",
          "level": 1,
          "start_line": 149
        },
        {
          "title": "3.2 Narrow Definition of the Agent Memory",
          "level": 1,
          "start_line": 181
        },
        {
          "title": "3.3 Broad Definition of the Agent Memory",
          "level": 1,
          "start_line": 185
        },
        {
          "title": "3.4 Memory-assisted Agent-Environment Interaction",
          "level": 1,
          "start_line": 189
        },
        {
          "title": "4 Why We Need the Memory in LLM-based Agent",
          "level": 1,
          "start_line": 227
        },
        {
          "title": "4.1 Perspective of Cognitive Psychology",
          "level": 1,
          "start_line": 231
        },
        {
          "title": "4.2 Perspective of Self-Evolution",
          "level": 1,
          "start_line": 242
        },
        {
          "title": "4.3 Perspective of Agent Applications",
          "level": 1,
          "start_line": 246
        },
        {
          "title": "5 How to Implement the Memory of LLM-based Agent",
          "level": 1,
          "start_line": 252
        },
        {
          "title": "5.1 Memory Sources",
          "level": 1,
          "start_line": 256
        },
        {
          "title": "5.1.1 Inside-trial Information",
          "level": 1,
          "start_line": 266
        },
        {
          "title": "5.1.2 Cross-trial Information",
          "level": 1,
          "start_line": 274
        },
        {
          "title": "5.1.3 External Knowledge",
          "level": 1,
          "start_line": 282
        },
        {
          "title": "5.2 Memory Forms",
          "level": 1,
          "start_line": 290
        },
        {
          "title": "5.2.1 Memory in Textual Form",
          "level": 1,
          "start_line": 300
        },
        {
          "title": "5.2.2 Memory in Parametric Form",
          "level": 1,
          "start_line": 330
        },
        {
          "title": "5.2.3 Advantages and Disadvantages of Textual and Parametric Memory",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "5.3 Memory Operations",
          "level": 1,
          "start_line": 358
        },
        {
          "title": "5.3.1 Memory Writing",
          "level": 1,
          "start_line": 362
        },
        {
          "title": "5.3.2 Memory Management",
          "level": 1,
          "start_line": 370
        },
        {
          "title": "5.3.3 Memory Reading",
          "level": 1,
          "start_line": 382
        },
        {
          "title": "6 How to Evaluate the Memory in LLM-based Agent",
          "level": 1,
          "start_line": 395
        },
        {
          "title": "6.1 Direct Evaluation",
          "level": 1,
          "start_line": 399
        },
        {
          "title": "6.1.1 Subjective Evaluation",
          "level": 1,
          "start_line": 403
        },
        {
          "title": "6.1.2 Objective Evaluation",
          "level": 1,
          "start_line": 417
        },
        {
          "title": "6.2 Indirect Evaluation",
          "level": 1,
          "start_line": 457
        },
        {
          "title": "6.2.1 Conversation",
          "level": 1,
          "start_line": 461
        },
        {
          "title": "6.2.2 Multi-source Question-answering",
          "level": 1,
          "start_line": 467
        },
        {
          "title": "6.2.3 Long-context Applications",
          "level": 1,
          "start_line": 475
        },
        {
          "title": "6.2.4 Other Tasks",
          "level": 1,
          "start_line": 483
        },
        {
          "title": "6.3 Discussions",
          "level": 1,
          "start_line": 491
        },
        {
          "title": "7 Memory-enhanced Agent Applications",
          "level": 1,
          "start_line": 495
        },
        {
          "title": "7.1 Role-playing and Social Simulation",
          "level": 1,
          "start_line": 499
        },
        {
          "title": "7.2 Personal Assistant",
          "level": 1,
          "start_line": 515
        },
        {
          "title": "7.3 Open-world Game",
          "level": 1,
          "start_line": 521
        },
        {
          "title": "7.4 Code Generation",
          "level": 1,
          "start_line": 527
        },
        {
          "title": "7.5 Recommendation",
          "level": 1,
          "start_line": 533
        },
        {
          "title": "7.6 Expert System in Specific Domains",
          "level": 1,
          "start_line": 539
        },
        {
          "title": "7.7 Other Applications",
          "level": 1,
          "start_line": 549
        },
        {
          "title": "8 Limitations & Future Directions",
          "level": 1,
          "start_line": 557
        },
        {
          "title": "8.1 More Advances in Parametric Memory",
          "level": 1,
          "start_line": 559
        },
        {
          "title": "8.2 Memory in LLM-based Multi-agent Applications",
          "level": 1,
          "start_line": 565
        },
        {
          "title": "8.3 Memory-based Lifelong Learning",
          "level": 1,
          "start_line": 573
        },
        {
          "title": "8.4 Memory in Humanoid Agent",
          "level": 1,
          "start_line": 577
        },
        {
          "title": "9 Conclusion",
          "level": 1,
          "start_line": 581
        },
        {
          "title": "Acknowledgement",
          "level": 1,
          "start_line": 585
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 589
        }
      ]
    },
    "translation_status": "completed",
    "translation_progress": 100,
    "translation_chunks_total": 53,
    "translation_chunks_done": 53,
    "translated_content": "张泽宇 $^{1}$， 薄晓贺 $^{1}$， 马晨 $^{1}$， 李睿 $^{1}$， 陈旭 $^{1}$， 戴权禹 $^{2}$， 朱洁明 $^{2}$， 董振华 $^{2}$， 文继荣 $^{1}$ $^{1}$ 中国人民大学高瓴人工智能学院， 北京， 中国  \n $^{2}$ 华为诺亚方舟实验室， 中国  \nzeyuzhang@ruc.edu.cn, xu.chen@ruc.edu.cn\n\n# 摘要\n\n基于大语言模型（LLM）的智能体（agent）近来吸引了研究界和工业界的广泛关注。与原始的大语言模型相比，基于大语言模型的智能体以其自我进化的能力为特征，这是解决需要长期且复杂的智能体-环境交互的现实世界问题的基础。支持智能体-环境交互的关键组件是智能体的记忆（memory）。尽管先前的研究提出了许多有前景的记忆机制，但它们分散在不同的论文中，并且缺乏一个系统性的综述来从整体视角总结和比较这些工作，未能抽象出通用且有效的设计模式以启发未来的研究。为了弥补这一空白，本文对基于大语言模型的智能体的记忆机制进行了全面的综述。具体而言，我们首先讨论了基于大语言模型的智能体中记忆“是什么”以及“为什么需要”记忆。然后，我们系统地回顾了关于如何设计和评估记忆模块的先前研究。此外，我们还介绍了许多记忆模块在其中扮演重要角色的智能体应用。最后，我们分析了现有工作的局限性并指出了重要的未来研究方向。为了跟进该领域的最新进展，我们在 https://github.com/nuster1128/LLM_Agent_Memory_Survey 创建了一个资源库。\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/b45daab8d13fd79cc986247b3fc06262ffed28e4d02cbe98a1354bd006302025.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/d5e161d1193da83dfe1be348819aad6a4bdb03869f955ecd298067e1feab6c6b.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/187b77164c1a70c4ae670d8bd352361fe523314e901524b2c8efa1c45be98207.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/dc6ca064d796b8cf965620450953aef7b73d520974647c31519f759391770029.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/988fdd8ca1ad763efa9c2c7121e96d48e372dc792e1447264cdc28dca124f586.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/e058c0bfbdaa099d98aef0f5052982a79eb1e9e4a6056caad3abb3bc1c355a23.jpg)\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/c9b5b5879701a03db38905d4800c4893b3f66d5d061507a4b5a8347804f83a4b.jpg)  \n图 1：记忆模块在基于大语言模型的智能体中的重要性。\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/2dfd1f6e260467d4154b9c01d85fbe0ea21bb866a7617bdf9ad57e17b529a777.jpg)\n\n# 目录\n\n# 1 引言 4\n\n# 2 相关综述 5\n\n2.1 关于大语言模型的综述 5  \n2.2 关于基于大语言模型的智能体的综述 7\n\n# 3 基于大语言模型的智能体的记忆是什么 7\n\n## 翻译要求\n1.  **保持格式**：保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**：专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**：使用学术论文的正式语体\n4.  **公式保留**：LaTeX 公式保持原样，不翻译\n5.  **引用保留**：参考文献引用格式保持原样\n\n## 原文内容\n3.1 基础知识 7  \n3.2 智能体记忆的狭义定义 9  \n3.3 智能体记忆的广义定义 9  \n3.4 记忆辅助的智能体-环境交互 9\n\n# 4 为何基于大语言模型的智能体需要记忆 10\n\n4.1 认知心理学视角 10  \n4.2 自我进化视角 11  \n4.3 智能体应用视角 11\n\n# 5 如何实现基于大语言模型的智能体记忆 11\n\n5.1 记忆来源 11\n\n5.1.1 单次试验内信息 12  \n5.1.2 跨试验信息 13  \n5.1.3 外部知识 13\n\n5.2 记忆形式 13\n\n5.2.1 文本形式记忆 14  \n5.2.2 参数形式记忆 16  \n5.2.3 文本与参数形式记忆的优缺点 17\n\n5.3 记忆操作 18\n\n5.3.1 记忆写入 18  \n5.3.2 记忆管理 18  \n5.3.3 记忆读取 19\n\n# 6 如何评估基于大语言模型的智能体记忆 20\n\n6.1 直接评估 20\n\n6.1.1 主观评估 20  \n6.1.2 客观评估 21\n\n6.2 间接评估 22\n\n6.2.1 对话 22  \n6.2.2 多源问答 22  \n6.2.3 长上下文应用 22\n\n6.2.4 其他任务 23\n\n6.3 讨论 23\n\n# 7 记忆增强的智能体应用 23\n\n7.1 角色扮演与社会模拟 23  \n7.2 个人助理 25  \n7.3 开放世界游戏 25  \n7.4 代码生成 25  \n7.5 推荐系统 26  \n7.6 特定领域专家系统 26  \n7.7 其他应用 26\n\n# 8 局限性与未来方向 27\n\n8.1 参数形式记忆的更多进展 27  \n8.2 基于大语言模型的多智能体应用中的记忆 27  \n8.3 基于记忆的终身学习 28  \n8.4 拟人化智能体中的记忆 28\n\n# 9 结论 28\n\n# 1 引言\n\n\"若无记忆，则无文化。若无记忆，则无文明，无社会，无未来。\"\n\n——埃利·维瑟尔，1928-2016\n\n近年来，大语言模型（LLMs）在众多领域取得了显著成功，范围涵盖人工智能、软件工程乃至教育和社会科学 [1-3]。原始的大语言模型通常在不与环境交互的情况下完成不同任务。然而，为了实现通用人工智能（AGI）的最终目标，智能机器应能够通过自主探索现实世界并从中学习来改进自身。例如，如果一个旅行规划智能体打算预订一张票，它应该向票务网站发送订单请求，并在采取下一步行动前观察响应。个人助理智能体应根据用户的反馈调整其行为，提供个性化响应以提高用户满意度。为了进一步推动大语言模型向通用人工智能的边界迈进，近年来涌现了大量关于基于大语言模型的智能体的研究 [3, 4]，其关键在于为LLMs配备额外的模块，以增强其在现实世界环境中的自我进化能力。\n\n## 翻译结果\n\n在所有添加的模块中，**记忆**是一个关键组件，它将智能体与原始大语言模型区分开来，使智能体真正成为一个智能体（见图1）。它在决定智能体如何积累知识、处理历史经验、检索信息性知识以支持其行动等方面发挥着极其重要的作用。围绕记忆模块，研究者们投入了大量精力来设计其信息来源、存储形式和操作机制。例如，Shinn 等人 [5] 结合了任务内和跨任务的信息来构建记忆模块，以增强智能体的推理能力。Zhong 等人 [6] 以自然语言的形式存储记忆信息，这种方式具有可解释性且对用户友好。Modarressi 等人 [7] 设计了记忆读取和写入操作，以与环境交互来解决问题。\n\n尽管先前的研究已经设计了许多有前景的记忆模块，但仍然缺乏一个系统性的研究来从整体视角审视记忆模块。为了弥补这一空白，本文全面回顾了先前的研究，提出了清晰的设计和评估记忆模块的分类法及关键原则。具体而言，我们讨论了三个关键问题：（1）基于大语言模型的智能体的记忆是什么？（2）为什么我们需要基于大语言模型的智能体具备记忆？（3）如何在基于大语言模型的智能体中实现和评估记忆？首先，我们详细阐述了基于大语言模型的智能体中记忆的概念，提供了狭义和广义的定义。然后，我们分析了记忆在基于大语言模型的智能体中的必要性，从认知心理学、自我进化和智能体应用三个角度展示了其重要性。基于“是什么”和“为什么”的问题，我们提出了设计和评估记忆模块的常用策略。对于记忆设计，我们从三个维度讨论先前的工作，即记忆来源、记忆形式和记忆操作。对于记忆评估，我们介绍了两种广泛使用的方法，包括直接评估和通过特定智能体任务进行的间接评估。接下来，我们讨论了智能体应用，包括角色扮演、社会模拟、个人助理、开放世界游戏、代码生成、推荐系统和专家系统，以展示记忆模块在实际场景中的重要性。最后，我们分析了现有工作的局限性，并强调了重要的未来研究方向。\n\n## 翻译结果\n\n本文的主要贡献可概括如下：(1) 我们正式定义了记忆模块，并全面分析了其在基于大语言模型（LLM）的智能体中的必要性。(2) 我们系统性地总结了关于设计和评估基于LLM的智能体中记忆模块的现有研究，提供了清晰的分类和直观的见解。(3) 我们展示了典型的智能体应用，以说明记忆模块在不同场景中的重要性。(4) 我们分析了现有记忆模块的关键局限性，并指出了潜在的解决方案以启发未来的研究。据我们所知，这是首个关于基于LLM的智能体记忆机制的综述。\n\n本综述的其余部分组织如下。首先，我们在第2节为LLM和基于LLM的智能体领域提供了一个系统性的元综述，对不同综述进行了分类并总结了它们的关键贡献。接着，我们在第3至第6节讨论了基于LLM的智能体中记忆模块的“是什么”、“为什么需要”以及“如何实现和评估”等问题。然后，我们在第7节展示了记忆增强型智能体的应用。最后，现有工作的局限性和未来方向将在第8节和第9节进行讨论。\n\n# 2 相关综述\n\n过去两年，大语言模型（LLMs）吸引了学术界和工业界的广泛关注。为了系统性地总结该领域的研究，研究者们撰写了大量综述论文。在本节中，我们简要回顾这些综述（概述见图2），重点介绍它们的主要关注点和贡献，以便更好地定位我们的研究。\n\n# 2.1 关于大语言模型的综述\n\n在LLM领域，Zhao等人[70]提出了首个全面的综述，总结了LLMs的背景、发展路径、模型架构、训练方法和评估策略。Hadi等人[71]和Min等人[72]也从整体视角进行了LLM综述，但提供了不同的分类和对LLMs的理解。在这些综述之后，人们深入研究了LLMs的具体方面，并回顾了相应的里程碑研究和关键技术。这些方面可分为四类，包括LLMs的基本问题、评估、应用和挑战。\n\n## 翻译结果\n\n**基础性问题**。 此类别中的综述旨在总结可用于解决大语言模型（LLMs）基础性问题的技术。具体而言，Zhang 等人 [8] 对监督微调方法进行了全面综述，这是更好地训练 LLMs 的一项关键技术。Shen 等人 [9]、Wang 等人 [10] 和 Liu 等人 [11] 对 LLMs 的对齐问题进行了综述，这是 LLMs 产生符合人类价值观输出的关键要求。Gao 等人 [12] 对 LLMs 的检索增强生成（RAG）能力进行了综述，这对于为 LLMs 提供事实性和最新知识、消除幻觉至关重要。Qin 等人 [18] 总结了使 LLMs 能够利用外部工具的最新方法，这对于 LLMs 在需要专业知识的领域扩展其能力至关重要。Wang 等人 [13]、Yao 等人 [14]、Wang 等人 [15]、Feng 等人 [16] 和 Zhang 等人 [17] 对 LLM 知识编辑方向进行了综述，这对于定制 LLMs 以满足特定需求非常重要。Huang 等人 [19]、Wang 等人 [20] 和 Pawar 等人 [21] 关注 LLMs 的长上下文能力，这对于 LLMs 每次处理更多信息并增强其应用场景至关重要。Wu 等人 [22]、Song 等人 [23]、Caffagni 等人 [24] 和 Yin 等人 [25] 总结了多模态 LLMs，这将 LLMs 的能力从文本扩展到视觉和其他模态。上述综述主要关注 LLMs 的有效性。LLMs 的另一个重要方面是其训练和推理效率。为了总结这方面的研究，Zhu 等人 [30]、Xu 和 McAuley [31]、Wang 等人 [32] 和 Park 等人 [33] 系统性地回顾了模型压缩技术。Ding 等人 [81] 和 Xu 等人 [29] 分析并总结了参数高效微调方面的研究。Bai 等人 [26]、Wan 等人 [27]、Miao 等人 [28] 和 Ding 等人 [81] 则更广泛地关注资源利用效率。\n\n**评估**。 此类别中的综述关注如何评估 LLMs 的能力。具体而言，Chang 等人 [34] 从整体视角全面总结了评估方法，涵盖了不同的评估任务、方法和基准，这些是评估 LLM 性能的关键部分。Guo 等人 [35] 更关注评估目标，描述了如何评估 LLMs 的知识、对齐和安全控制能力，这补充了性能之外的评估指标。\n\n## 翻译结果\n\n应用。此类综述旨在总结利用大语言模型改进不同应用的模型。具体而言，Zhu等人[37]聚焦于信息检索领域，总结了基于大语言模型的查询处理相关研究。Xu等人[38]更关注信息抽取领域，并为该领域基于大语言模型的模型提供了全面的分类体系。Li等人[50]、Lin等人[51]和Wang等人[52]讨论了大语言模型在推荐系统领域的应用，他们利用智能体生成数据并提供推荐。Fan等人[39]、Wang等人[40]和Zheng等人[41]则专注于大语言模型如何在软件设计、开发和测试等方面有益于软件工程。Zeng等人[42]总结了机器人学领域基于大语言模型的方法。Cui等人[43]和Yang等人[44]聚焦于自动驾驶应用，并从不同角度总结了该领域基于大语言模型的模型。除了上述人工智能领域，大语言模型也被应用于自然科学和社会科学。He等人[45]、Zhou等人[46]和Wang等人[47]总结了大语言模型在医学领域的应用。Li等人[48]专注于大语言模型在金融领域的应用。He等人[49]回顾了利用大语言模型促进心理学发展的相关模型。\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/883c791e15a5097827c82bc2ca131ce2daf0abcaffe972bbf5a41dc7e6955c19.jpg)\n图2：关于大语言模型及基于大语言模型的智能体的相关综述组织结构。\n\n挑战。此类综述关注大语言模型的可信度问题，例如幻觉、偏见、不公平性、可解释性、安全性和隐私性。大语言模型中的幻觉问题指的是模型可能生成错误观念或虚构内容，影响其在下游应用中的可靠性。Zhang等人[53]、Huang等人[54]、Rawte等人[55]、Ye等人[56]、Ji等人[57]、Tonmoy等人[58]和Jiang等人[59]总结了缓解大语言模型幻觉问题的主流模型。偏见与不公平性问题指的是大语言模型可能不平等地对待不同人群或目标，这可能导致社会刻板印象和歧视的传播。Gallegos等人[60]、Kotek等人[61]和Li等人[62]全面讨论了这些挑战，并总结了现有的缓解方法。可解释性问题意味着大语言模型的内部工作机制仍不清晰。Zhao等人[63]系统地讨论了此问题，并总结了先前在提高大语言模型可解释性方面的努力。安全性和隐私性也是具有挑战性的问题，Yao等人[64]、Shayegani等人[65]、Neel和Chang[66]、Smith等人[67]、Dong等人[68]以及Das等人[69]已对此进行了全面综述。\n\n# 2.2 基于大语言模型的智能体综述\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n基于大型语言模型（LLM）的能力，人们已经开展了大量关于构建基于LLM的智能体（agent）的研究。这类智能体能够自主感知环境、采取行动、积累知识并实现自我演进。在该领域，Wang等人[3]发表了首篇系统性综述论文，从智能体构建、智能体应用和智能体评估三个角度对基于LLM的智能体研究进行了总结。Xi等人[4]、Zhao等人[77]、Cheng等人[78]和Ge等人[80]也从整体视角总结了基于LLM的智能体研究，但他们的侧重点和分类体系各不相同，为该领域提供了更多样化的理解。除了这些整体性综述外，也出现了一些聚焦于基于LLM的智能体特定方面的综述论文。针对基础性问题，Durante等人[79]总结了多模态智能体的研究。Huang等人[74]重点关注基于LLM的智能体的规划能力。Guo等人[75]则更关注多智能体交互的场景。在应用方面，Li等人[76]对作为个人助理应用的基于LLM的智能体进行了总结。\n\n**本工作的定位**。本综述总结了对基于LLM的智能体的一个基础性问题的研究，即智能体的记忆机制。据我们所知，这是该方向上的首篇综述。我们希望它不仅能够启发未来更先进的记忆架构设计，也能为新手提供全面的入门资料。\n\n# 3 什么是基于LLM的智能体的记忆\n\n与环境交互并从中学习是基于LLM的智能体的基本要求。在智能体与环境的交互过程中，存在三个关键阶段，即：（1）智能体从环境中感知信息，并将其存储到记忆中；（2）智能体处理存储的信息，使其更具可用性；（3）智能体基于处理后的记忆信息采取下一步行动。在所有阶段中，记忆都扮演着极其重要的角色。接下来，我们首先从狭义和广义两个视角定义智能体的记忆，然后基于记忆模块详细阐述上述三个阶段的执行过程。\n\n# 3.1 基础知识\n\n为清晰阐述，我们首先介绍以下几项重要的背景知识：\n\n**定义 1（任务）**。任务是智能体需要达成的最终目标，例如，为Alice预订一张机票、为Bob推荐一家餐厅等。形式上，我们使用 $\\mathcal{T}$ 来表示一个任务，并在下文中使用下标来区分不同的任务。\n\n**定义 2（环境）**。狭义上，环境是智能体为完成任务需要与之交互的对象。对于定义 1 中的示例，环境分别是 Alice 和 Bob，他们对智能体的行动提供反馈。更广义地说，环境可以是影响智能体决策的任何情境因素，例如预订机票时的天气、推荐餐厅时的时间和地点等。\n\n**定义 3（轮次与步骤）**。为完成任务，智能体需要与环境进行交互。通常，智能体首先采取一个行动，然后环境对该行动作出响应。最后，智能体基于该响应采取下一个行动。此过程迭代进行，直至任务完成。完整的智能体-环境交互过程称为一个**轮次**，每次交互回合称为一个\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/5ba697e4fc20842efed37cd6ba4d6839b9c10ae4c5b0b7e48666107026f8b411.jpg)  \n任务 A：为 Alice 制定北京旅行计划  \n**图 3**：(a) 智能体-环境交互过程中潜在轮次的示例。(b) 记忆读取、写入和管理过程的图示，其中虚线表示跨轮次信息可以被整合到记忆模块中。\n\n**步骤**。在每个轮次中，智能体可以采取多个步骤以形成任务的潜在解决方案。对于每个任务，智能体可以探索多个轮次以完成任务 [5]。形式上，在步骤 $t$，我们分别用 $a_{t}$ 和 $o_{t}$ 表示智能体行动和观察到的环境响应。那么，一个长度为 $T$ 的轮次可以表示为 $\\xi_{T} = \\{a_{1}, o_{1}, a_{2}, o_{2}, \\dots, o_{T}, a_{T}\\}$。\n\n在上述定义中，任务和环境是最粗粒度的概念，而步骤是最细粒度的概念。它们共同描述了完整的智能体-环境交互过程。\n\n**一个示例**。基于以上定义，我们展示一个示例，并在全文中使用它来提供更直观的理解。在此示例中，智能体有两个任务：(A) 为 Alice 制定一个从 2024年5月1日 到 2024年5月3日 在北京的旅行计划，其中智能体需要 (i) 购买往返机票，(ii) 根据 Alice 的偏好确定若干景点，以及 (iii) 安排这些景点的游览顺序。(B) 在 2024年5月10日 为 Alice 推荐一部电影，其中智能体需要 (i) 确定 Alice 有空看电影的时间，以及 (ii) 根据 Alice 的观影偏好选择一部电影。对于每个任务，我们在下面展示一个潜在的轮次（亦见图 3(a)）。对于任务 (A)，该轮次如下：\n\n## 翻译要求\n1. **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2. **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3. **学术风格**: 使用学术论文的正式语体\n4. **公式保留**: LaTeX 公式保持原样，不翻译\n5. **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n[步骤 1] 智能体：我需要通过在线票务平台预订2024年5月1日从上海飞往北京，以及2024年5月3日从北京返回上海的机票。环境（在线票务平台）：订单已确认。去程航班于上午9:00起飞，您的票号为 EK240501SX9021。返程航班于下午4:30起飞，您的票号为 LG240503FN6317。请准时抵达机场搭乘航班。\n[步骤 2] 智能体：我已从杂志《北京名胜》中获取了外部知识。其中显示，长城、故宫和颐和园是著名景点。根据 Alice 的偏好，我认为她更偏爱古建筑，因此我将故宫和颐和园确定为目的地。环境（Alice）：做得好！\n[步骤 3] 智能体：现在，我需要为 Alice 安排游览顺序。根据以上信息，我建议她在抵达北京后游览颐和园，因为那里适合花费整个下午并观赏日落。然后，她可以在第二天游览故宫，这将给她充足的时间。最后，她可以在第三天返回上海并休息。环境（Alice）：我喜欢这个计划。谢谢！\n\n对于任务 (B)，其试验过程如下：\n\n[步骤 1] 智能体：根据我之前为 Alice 推荐电影的经验，她倾向于在晚上9:00开始看电影，因为那时她已经结束工作。我应该询问 Alice 那个时间是否方便。环境（Alice）：当然，这是个好时间！\n\n[步骤 2] 智能体：现在，我需要找出 Alice 在 Netflix 上标记为\"想观看\"的一些电影。环境（Netflix）：Alice 的想观看列表：《星际穿越》、《恐怖星球》、《鬼吹灯》。\n\n[步骤 3] 智能体：由于 Alice 从不在晚上观看恐怖电影，《星际穿越》对她来说会更合适。现在，我需要与 Alice 确认这部电影。环境（Alice）：太好了！我喜欢！\n\n# 3.2 智能体记忆的狭义定义\n\n从狭义上讲，智能体的记忆仅与同一试验内的历史信息相关。形式上，对于给定任务，步骤 $t$ 之前的试验历史信息为 $\\xi_{t} = \\{a_{1}, o_{1}, a_{2}, o_{2}, \\dots, a_{t-1}, o_{t-1}\\}$，然后记忆基于 $\\xi_{t}$ 推导得出。在上述示例中，对于任务 (A)，智能体在[步骤 3]需要为 Alice 安排游览顺序；此时，其记忆包含了[步骤 1]和[步骤 2]中关于选定景点和抵达时间的信息。对于任务 (B)，智能体必须在[步骤 3]为 Alice 选择一部电影；此时，其记忆包含了已安排的观影时间。\n\n# 3.3 智能体记忆的广义定义\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n广义而言，智能体的记忆可以来源于更广泛的渠道，例如，来自不同试验（trial）的信息以及超越智能体-环境交互的外部知识。形式化地，给定一系列顺序任务 $\\{\\mathcal{T}_1,\\mathcal{T}_2,\\dots,\\mathcal{T}_K\\}$，对于任务 $\\mathcal{T}_k$，在步骤 $t$ 的记忆信息来源于三个渠道：(1) 同一试验内的历史信息，即 $\\xi_t^k = \\{a_1^k,o_1^k,\\ldots ,a_{t - 1}^k,o_{t - 1}^k\\}$，其中我们添加了上标 $k$ 来标记任务索引。(2) 跨不同试验的历史信息，即 $\\Xi^k = \\{\\xi^1,\\xi^2,\\dots,\\xi^{k - 1},\\xi^{k'}\\}$，其中 $\\xi^j$ ( $j\\in \\{1,\\dots,k - 1\\}$ ) 代表任务 $j^1$ 的试验，而 $\\xi^{k'}$ 表示任务 $\\mathcal{T}_k$ 先前探索过的试验。(3) 外部知识，由 $D_t^k$ 表示。智能体的记忆是基于 $(\\xi_t^k,\\Xi^k,D_t^k)$ 衍生而来的。在上述的玩具示例中，对于任务 (A)，如果存在若干次失败的试验，即来自 Alice 的反馈是负面的，那么这些试验可以被纳入智能体的记忆中，以避免未来犯类似的错误（对应于 $\\xi^{k'}$）。此外，对于任务 (B)，智能体可能会推荐与 Alice 在任务 (A) 中参观过的景点相关的电影，以捕捉她近期的偏好（对应于 $\\{\\xi^1,\\xi^2,\\dots,\\xi^{k - 1}\\}$）。在智能体的决策过程中，它还参考了杂志《北京景点》来制定旅行计划，这即是当前任务 $\\mathcal{T}_k$ 的外部知识（对应于 $D_t^k$）。\n\n# 3.4 记忆辅助的智能体-环境交互\n\n如第 3 节开头所述，智能体-环境交互过程包含三个关键阶段。智能体记忆模块通过三个操作来实现这些阶段，包括记忆写入、记忆管理和记忆读取。\n\n**记忆写入**。此操作旨在将原始观察（observation）投射为实际存储的记忆内容，这些内容更具信息量 [7] 且更简洁 [6]。它对应于智能体-环境交互过程的第一个阶段。给定一个任务 $\\mathcal{T}_k$，如果智能体在步骤 $t$ 采取行动 $a_{t}^{k}$，并且环境提供观察 $o_t^k$，那么记忆写入操作可以形式化地表示为：\n\n$$\nm _ {t} ^ {k} = W (\\{a _ {t} ^ {k}, o _ {t} ^ {k} \\}),\n$$\n\n其中 $W$ 是一个投射函数。$m_t^k$ 是最终存储的记忆内容，可以是自然语言或参数化表示。在上述玩具示例中，对于任务 (A)，智能体应在 [步骤 2] 后记住航班安排和景点的决定。对于任务 (B)，智能体应在 [步骤 1] 后记住 Alice 希望在晚上 9 点看电影这一事实。\n\n## 翻译结果\n\n## 翻译结果\n\n**记忆管理**。此操作旨在处理已存储的记忆信息，使其更加有效，例如：总结高级概念以使智能体更具泛化能力 [6]、合并相似信息以减少冗余 [7]、以及遗忘不重要或不相关的信息以消除其负面影响。此操作对应于智能体-环境交互过程的第二阶段。令 $M_{t-1}^{k}$ 表示步骤 $t$ 之前任务 $k$ 的记忆内容，并假设 $m_{t}^{k}$ 是基于上述记忆写入操作在步骤 $t$ 存储的信息，那么，记忆管理操作可以表示为：\n\n$$\nM _ {t} ^ {k} = P (M _ {t - 1} ^ {k}, m _ {t} ^ {k}),\n$$\n\n其中 $P$ 是一个迭代处理已存储记忆信息的函数。对于狭义记忆定义，迭代仅发生在同一试验内，且试验结束时记忆被清空。对于广义记忆定义，迭代发生在不同试验甚至不同任务之间，也包括外部知识的整合。对于上述示例中的任务 (B)，智能体可以推断出 Alice 喜欢在晚上观看科幻电影，这可以作为一条默认规则，用于未来为 Alice 提供推荐。\n\n**记忆读取**。此操作旨在从记忆中获取重要信息，以支持智能体的下一个动作。它对应于智能体-环境交互过程的第三阶段。假设 $M_t^k$ 是步骤 $t$ 时任务 $k$ 的记忆内容，$c_t^k$ 是下一个动作的上下文，那么记忆读取操作可以表示为：\n\n$$\n\\hat {M} _ {t} ^ {k} = R (M _ {t} ^ {k}, c _ {t + 1} ^ {k}),\n$$\n\n其中 $R$ 通常通过计算 $M_t^k$ 和 $c_{t+1}^k$ 之间的相似度来实现 [82]。$\\hat{M}_t^k$ 用作最终提示的一部分，以驱动智能体的下一个动作。对于上述示例中的任务 (B)，当智能体在[步骤 3]中决定最终推荐的电影时，它应关注[步骤 2]中的\"想观看\"列表，并从中选择一部。\n\n基于上述操作，我们可以推导出从 $\\{a_t^k,o_t^k\\}$ 到 $a_{t + 1}^{k}$ 的演化过程的统一函数，即：\n\n$$\na _ {t + 1} ^ {k} = \\operatorname {L L M} \\{R (P (M _ {t - 1} ^ {k}, W (\\{a _ {t} ^ {k}, o _ {t} ^ {k} \\})), c _ {t + 1} ^ {k}) \\},\n$$\n\n其中 LLM 指大型语言模型。通过迭代展开此函数，可以轻松获得完整的智能体-环境交互过程（直观示意图见图 3(b)）。**注记**：此函数为智能体记忆过程提供了通用形式化表述。先前研究可能采用不同的具体实现方式。例如在文献 [5] 中，$R$ 与 $P$ 被设定为相同函数，且 $P$ 仅在试验结束时生效；在 Park 等人 [83] 的研究中，$R$ 基于相似性、时间间隔和重要性三个标准实现，$P$ 则通过反思过程实现以获得更抽象的思考。本节我们聚焦于智能体记忆操作的整体框架，$W$、$P$ 和 $R$ 更具体的实现细节将在第 5 节展开。\n\n# 4 基于 LLM 的智能体为何需要记忆机制\n\n前文已阐述基于 LLM 的智能体记忆机制的内涵。在系统介绍其实现方法之前，本节将从认知心理学、自我演进和智能体应用三个维度，简要论述为何记忆机制对构建基于 LLM 的智能体不可或缺。\n\n# 4.1 认知心理学视角\n\n认知心理学是研究人类心智过程的科学，涵盖注意、语言使用、记忆、知觉、问题解决、创造力与推理等维度<sup>2</sup>。在这些心智过程中，记忆被广泛认为是至关重要的组成部分 [84]。它是人类通过积累重要信息与抽象高层概念来学习知识的基础 [85]，通过铭记文化价值与个体经验来形成社会规范的基础 [86]，通过设想潜在正负后果来采取合理行为的基础 [87] 等。\n\n基于 LLM 的智能体主要目标在于替代人类完成各类任务。为使智能体能够类人化运作，遵循人类工作机制设计智能体是自然而必要的选择 [88]。鉴于记忆对人类的重要性，为智能体设计记忆模块同样具有重要意义。此外，认知心理学历经长期研究，已积累诸多有效的人类记忆理论与架构，这些成果能够为智能体提供更高级的能力支持 [89]。\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/6c73759e440abf0e1d672cbdfc6fdd19f9bfe9401c40b829f60bff6d9b691814.jpg)  \n图 4：基于 LLM 的智能体中记忆的来源、形式与操作概览\n\n![](/uploads/images/1c49a709-c83a-4a17-bdef-5c546b0e6aa5/cb56e8954692e99fe487df02322be080432ee13fe887e54815071c983b4b29ce.jpg)\n\n# 4.2 自我演进视角\n\n为实现不同的实际任务，智能体必须在动态环境中实现自我演化[90]。在智能体与环境的交互过程中，记忆在以下方面发挥着关键作用：(1) **经验积累**。记忆的一项重要功能是记住过去的错误规划、不当行为或失败经验，从而使智能体在未来处理类似任务时更加高效[91]。这对于提升智能体在自我演化过程中的学习效率至关重要。(2) **环境探索**。为了在环境中自主演化，智能体必须探索不同的行动并从反馈中学习[92]。通过记住历史信息，记忆有助于更好地决定何时以及如何进行探索，例如更关注先前失败的尝试或探索频率较低的行动[93]。(3) **知识抽象**。记忆的另一项重要功能是从原始观察中总结和抽象出高层次信息，这是智能体对未见环境更具适应性和泛化能力的基础[82]。总而言之，自我演化是基于大语言模型的智能体的基本特征，而记忆对于自我演化至关重要。\n\n# 4.3 智能体应用的视角\n\n在许多应用中，记忆是智能体不可或缺的组成部分。例如，在对话智能体中，记忆存储了历史对话的信息，这对于智能体生成下一个回复是必需的。没有记忆，智能体就无法了解上下文，也无法继续对话[94]。在模拟智能体中，记忆对于确保智能体始终遵循角色设定至关重要。没有记忆，智能体在模拟过程中很容易偏离角色[95]。上述两个例子都表明，记忆并非可选组件，而是智能体完成给定任务所必需的。\n\n在上述三个视角中，第一个视角揭示了记忆构建了智能体的认知基础。第二和第三个视角则表明，记忆对于智能体的演化原理和应用是必要的，这为设计具有记忆机制的智能体提供了启示。\n\n# 5 如何实现基于大语言模型的智能体的记忆\n\n在本节中，我们从三个角度讨论记忆模块的实现：记忆来源、记忆形式和记忆操作。记忆来源指的是记忆内容从何而来。记忆形式关注如何表示记忆内容。记忆操作旨在处理记忆内容。这三个视角全面回顾了记忆实现方法，对未来研究有所帮助。为更好地展示，我们在图4中给出了实现方法的概览。\n\n# 5.1 记忆来源\n\n在先前的研究中，记忆内容可能来自不同的来源。根据我们在第3节中的表述，这些来源可分为三类，即**试次内信息**、**跨试次信息**以及**外部知识**。前两者是在智能体与环境交互过程中动态生成的（例如，任务内部信息），而后者则是循环之外的静态信息（例如，任务外部信息）。我们在表1中对先前关于记忆来源的研究进行了总结。\n\n表 1：记忆来源总结。我们使用 $\\checkmark$ 和 $\\times$ 来标记相应来源是否被模型采用。\n\n<table><tr><td>模型</td><td>试次内信息</td><td>跨试次信息</td><td>外部知识</td></tr><tr><td>MemoryBank [6]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>RET-LLM [7]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>ChatDB [96]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>TiM [97]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>SCM [98]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Voyager [99]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MemGPT [100]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MemoChat [94]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MPC [101]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Generative Agents [83]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>RecMind [102]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>Retroformer [103]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>ExpeL [82]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Synapse [91]</td><td>✓</td><td>✓</td><td>×</td></tr><tr><td>GITM [93]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>ReAct [104]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>Reflexion [5]</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RecAgent [95]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Character-LLM [105]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MAC [106]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Huatuo [107]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>ChatDev [1]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>InteRecAgent [108]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaAgents [109]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>TPTU [110, 111]</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaGPT [112]</td><td>✓</td><td>✓</td><td>×</td></tr><tr><td>S3[2]</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>InvestLM [113]</td><td>✓</td><td>×</td><td>✓</td></tr></table>\n\n# 5.1.1 试次内信息\n\n在智能体与环境的交互过程中，一个试次内的历史步骤通常是支持智能体未来行动最相关且信息量最大的信号。几乎所有先前的研究都将此信息作为记忆来源的一部分。\n\n## 代表性研究\n生成式智能体 [83] 旨在通过使用基于大语言模型的智能体来模拟人类的日常行为。智能体的记忆来源于为实现目标而产生的历史行为，例如，在研究特定主题时收集相关论文。MemoChat [94] 旨在与人类进行对话，其中智能体的记忆基于对话会话的对话历史生成。TiM [97] 旨在通过智能体在完成任务后自我生成多个\"思考\"来增强其推理能力，这些\"思考\"被用作记忆，以提供更具泛化性的信息。Voyager [99] 专注于基于《我的世界》构建游戏智能体，其记忆包含为完成任务而生成的初步和基础动作的可执行代码。需要注意的是，**试次内信息**不仅包括智能体与环境的交互，还包含交互上下文，例如时间和位置信息。\n\n## 讨论\n**试次内信息**是最明显、最直观的应被用于构建智能体记忆的来源，因为它与智能体当前必须完成的任务高度相关。然而，仅依赖试次内信息可能会阻碍智能体从各种任务中积累有价值的知识并学习更具泛化性的信息。因此，许多研究也探索了如何有效利用跨不同任务的信息来构建记忆模块，这将在后续章节中详细阐述。\n\n# 5.1.2 跨试次信息\n\n对于基于大语言模型的智能体而言，在环境中多次试次所积累的信息也是记忆的重要组成部分，通常包括成功和失败的行动及其洞察，例如失败原因、成功的常见行动模式等。\n\n## 代表性研究\n其中最突出的研究之一是 Reflexion [5]，它为大语言模型智能体提出了**言语强化学习**。它以言语形式从过去的试次中提取经验，并将其应用于后续试次中，以提高同一任务的性能。此外，Retroformer [103] 对反思模型进行了微调，使智能体能够更有效地从过去的试次中提取跨试次信息。在 Synapse [91] 中，智能体专注于解决计算机控制任务。它们的记忆可以通过成功的范例记录跨试次信息，这些范例将在类似的试次中作为参考。在 ExpeL [82] 中，智能体需要在环境中解决一系列复杂的交互任务。它们存储并组织已完成的轨迹，并为新任务召回相似的轨迹。在召回的轨迹中，成功的案例将与失败的案例进行比较，以识别成功的模式。\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n讨论。根据跨试验信息的累积记忆，智能体能够积累经验，这对它们的演化至关重要。基于过去的经验，智能体可以根据整个过程的整体反馈来调整其行为。与作为短期记忆的试验内观察相比，试验经验可被视为长期记忆。它利用来自不同试验的反馈来支持更广泛的智能体试验，为智能体提供更持久的经验支持。然而，其局限性在于，无论是试验内信息还是跨试验信息，都要求智能体亲自参与智能体-环境交互，其中不包含外部经验和知识。\n\n# 5.1.3 外部知识\n\n基于大语言模型的智能体的一个重要特征是，它们可以直接通过自然语言进行沟通和控制。因此，基于大语言模型的智能体可以轻松地整合文本形式的外部知识（例如，维基百科<sup>3</sup>）以辅助其决策。\n\n**代表性研究**。在 ReAct [104] 中，智能体需要通过多步推理来回答关于常识的问题。如果在此过程中缺乏信息，它们可以利用维基百科 API 获取外部知识。GITM [93] 旨在设计用于《我的世界》的智能体，使其能够在复杂且奖励稀疏的环境中探索。智能体从在线的 Minecraft Wiki 和合成配方中汲取知识，为其导航提供无限的知识来源。CodeAgent [114] 专注于仓库级别的代码生成任务，这通常需要复杂的依赖关系和大量的文档。它设计了一种网络搜索策略来获取相关的外部知识。ChatDoctor [115] 将基于大语言模型的智能体应用于医疗领域。它微调了一个知识获取流程，以便从维基百科和医疗数据库中检索外部知识。\n\n**讨论**。外部知识可以从私有和公共来源获取。它为基于大语言模型的智能体提供了远超其内部环境的大量知识，这些知识可能难以甚至无法通过智能体-环境交互获得。此外，大多数外部知识可以根据任务需求，通过动态实时访问各种工具的 API 来获取，从而缓解知识过时的问题。将外部知识整合到基于大语言模型的智能体的记忆中，极大地扩展了其知识边界，为其决策提供了无限的、最新的、有充分依据的知识。\n\n# 5.2 记忆形式\n\n通常，有两种形式来表示记忆内容：文本形式和参数形式。在文本形式中，信息通过自然语言被显式地保留和回忆。在参数形式中，\n\n表 2：记忆形式的总结。我们使用 $\\checkmark$ 和 $\\times$ 来标注模型中是否采用了相应的记忆形式。\n\n<table><tr><td rowspan=\"2\">模型</td><td colspan=\"4\">文本形式</td><td colspan=\"2\">参数化形式</td></tr><tr><td>完整</td><td>近期</td><td>检索</td><td>外部</td><td>微调</td><td>编辑</td></tr><tr><td>MemoryBank [6]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>RET-LLM [7]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>ChatDB [96]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>TiM [97]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>SCM [98]</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Voyager [99]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>MemGPT [100]</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>MemoChat [94]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>MPC [101]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Generative Agents [83]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>RecMind [102]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Retroformer [103]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>✓</td><td>×</td></tr><tr><td>ExpeL [82]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Synapse [91]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>GITM [93]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>ReAct [104]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Reflexion [5]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>RecAgent [95]</td><td>×</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>Character-LLM [105]</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td></tr><tr><td>MAC [106]</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Huatuo [107]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td><td>×</td></tr><tr><td>ChatDev [1]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td></tr><tr><td>InteRecAgent [108]</td><td>×</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MetaAgents [109]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>TPTU [110, 111]</td><td>✓</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>MetaGPT [112]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>×</td><td>×</td></tr><tr><td>S3[2]</td><td>×</td><td>×</td><td>✓</td><td>×</td><td>×</td><td>×</td></tr><tr><td>InvestLM [113]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td><td>×</td></tr></table>\n\n## 翻译要求\n1.  **保持格式**：保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**：专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**：使用学术论文的正式语体\n4.  **公式保留**：LaTeX 公式保持原样，不翻译\n5.  **引用保留**：参考文献引用格式保持原样\n\n## 原文内容\n在这种形式中，记忆信息被编码到参数中，并隐式地影响智能体的行为。我们在表 2 中总结了先前关于记忆形式及其实现的研究工作。\n\n# 5.2.1 文本形式的记忆\n\n文本形式是目前表示记忆内容的主流方法，其特点是可解释性更好、实现更容易、读写效率更高。具体而言，文本形式既可以是非结构化的表示（如原始自然语言），也可以是结构化的信息（如元组、数据库等）。总体而言，先前的研究使用文本形式的记忆来存储四类信息，包括：(1) 完整的智能体-环境交互；(2) 近期的智能体-环境交互；(3) 检索到的智能体-环境交互；(4) 外部知识。在前三种方法中，记忆利用自然语言来描述智能体-环境交互循环内的信息。在前三种类型中，它们记录的是智能体-环境交互循环内部的信息，而最后一种类型则利用自然语言存储该循环之外的信息。\n\n**完整交互**。该方法基于长上下文策略存储智能体-环境交互历史的所有信息 [116]。以第 3.1 节中的示例为例，智能体在任务 (A) 中执行步骤 2 后的记忆可以通过连接步骤 2 之前的所有信息来实现，最终的文本形式记忆为：\"你的记忆是 [步骤 1] (智能体) ... (在线售票处) ... [步骤 2] ... 请根据你的记忆进行推理\"。\n\n在先前的工作中，不同的模型使用不同的策略存储记忆信息。例如，在 LongChat [116] 中，智能体专注于理解长上下文场景中的自然语言。它对基础模型进行微调，以更好地适应记忆完整交互。Memory Sandbox [117] 旨在减轻对话中无关记忆的影响。它设计了一种透明且交互式的方法来管理智能体的记忆，该方法在将记忆连接为提示之前会移除无关的记忆。此外，一些研究致力于增强大语言模型处理更长上下文的能力 [118, 119]。\n\n## 翻译结果\n\n虽然存储所有智能体-环境交互能够保持信息的全面性，但在计算成本、推理时间和推理鲁棒性方面存在明显的局限性。首先，实践中快速增长的长上下文记忆会导致大语言模型推理时产生高昂的计算成本，这是由于注意力计算的时间复杂度随序列长度呈二次方增长。因此，这需要更多的计算资源并显著增加推理延迟，阻碍了其实际部署。此外，随着其快速增长，记忆长度很容易超过大语言模型预训练时的序列长度上限，这使得对记忆进行截断成为必要。因此，由于智能体记忆的不完整性，可能导致信息丢失。最后但同样重要的是，这可能导致大语言模型推理出现偏差和缺乏鲁棒性。具体而言，先前的一项研究[120]表明，长上下文中文本片段的位置会极大地影响其被利用的程度，因此长上下文提示中的记忆不能被平等且稳定地对待。所有这些缺点表明，有必要为基于大语言模型的智能体设计额外的记忆模块，而不是简单地将所有信息拼接成一个提示。\n\n**近期交互**。该方法使用自然语言存储和维护最近获取的记忆，从而根据局部性原理[121]提高记忆信息利用的效率。在3.1节示例的任务（B）中，我们可以只记住Alice最近三年的偏好，并截断较远的部分，其中最近三年可以被视为记忆窗口大小。\n\n在以往的研究中，存在多种存储近期文本记忆的策略。例如，SCM[98]提出了一种基于缓存机制的闪存，它保留了最近 $t - 1$ 个时间步的观察结果，旨在增强信息的时效性。MemGPT[100]将智能体视为一个操作系统，可以通过自然界面与用户动态交互。它设计了工作上下文来保存近期历史，作为虚拟上下文管理的一部分。在RecAgent[95]中，智能体被设计用于模拟用户在电影推荐中的行为。它将一些时间信息存储在短期记忆中作为中间缓存，这可以模拟人脑的记忆机制[122, 123]。这些代表性方法能够基于近期交互动态更新记忆，并更关注对当前阶段重要的近期上下文。\n\n## 翻译结果\n\n**基于时效性的缓存**是一种提升记忆效率的有效方法，它使智能体能够更专注于近期信息。然而，在长期任务中，这种方法无法访问遥远记忆中的关键信息。这可能导致不在当前缓存窗口内、但潜在至关重要的信息丢失。换言之，强调时效性本质上可能忽略早期但关键的信息，从而在对过往事件需要全面理解的场景中构成挑战。\n\n**检索式交互**。与上述基于时间截断记忆的方法不同，该方法通常根据记忆内容的相关性、重要性和主题进行选择。它确保了遥远但关键的记忆能被纳入决策过程，从而解决了仅记忆近期信息的局限性。在第3.1节示例的任务（A）中，Alice的偏好在此任务之前已存储于记忆中。在[步骤2]，智能体将根据查询关键词\"travel\"从记忆中检索与Alice偏好最相关的方面，从而获得Alice对古建筑类景点的偏好。一般而言，检索方法会在记忆写入时为记忆条目生成嵌入向量作为索引，并记录辅助信息以协助检索。在记忆读取时，会为每个记忆条目计算匹配分数，得分最高的前 $K$ 个条目将被用于智能体的决策过程。\n\n在现有研究中，大多数智能体利用检索方法来处理记忆信息。例如，Park等人[83]首先通过余弦相似度计算当前上下文与记忆条目之间的相关性，并根据辅助信息获取重要性和时效性。MemoryBank[6]采用双塔密集检索模型从过往对话中查找相关信息。每个记忆条目被编码成一个嵌入向量，随后通过FAISS[124]建立索引以提高检索效率。在读取记忆时，当前上下文会被编码为表示向量，以获取最相关的记忆。此外，RET-LLM[7]旨在设计一个通用的读写记忆模块。它利用局部敏感哈希从数据库中检索具有相关条目的元组，以提供更多信息。另外，ChatDB[96]设计为利用符号记忆，并提出生成SQL语句从数据库中检索以获取存储的信息。\n\n## 翻译结果\n\n检索方法在很大程度上依赖于获取预期信息的准确性和效率。不准确的检索策略可能会获取与任务无关的信息，这些信息对智能体推理并无助益。而一个沉重的检索系统则会导致巨大的计算成本和较长的时间延迟，尤其是在处理海量信息时。此外，检索方法通常将同质信息存储在环境内部，其中所有信息都采用一致的形式。对于环境外部的异构信息，则难以直接应用相同的方法进行记忆存储。\n\n**外部知识**。为了获取更多信息，一些智能体通过调用工具来获取外部知识，旨在将额外的相关知识转化为自身的记忆以辅助决策。例如，通过应用程序编程接口访问外部知识是一种常见做法 [104, 5]。如今，大量的公共信息（如维基百科和 OpenWeatherMap<sup>4</sup>）可在线上获取（免费或付费），并且可以通过 API 调用方便地访问。例如，在 3.1 节示例的任务 (A) 的 [步骤 2] 中，就是通过工具方法从数字杂志获取了外部知识。\n\n在现有模型中，Toolformer [125] 提出教导大语言模型使用工具，从而能够获取外部知识以更好地解决问题。此外，ToolLLM [126] 赋予了 Llama [127] 模型使用 RapidAPI<sup>5</sup> 中更多 API 以及启用多工具协同的能力，这为扩展智能体的能力提供了一个通用接口。在 TPTU [110] 中，智能体被整合到任务规划和工具使用中，以解决复杂问题。其后续工作 [111] 进一步广泛提升了其在检索等方面的能力。在 ToRA [128] 中，智能体被要求解决数学问题。它们利用模仿学习来提高其使用基于程序的工具的能力。\n\n上述方法通过允许智能体从不同来源访问外部的最新现实世界信息，显著提升了智能体的能力。然而，由于潜在的不准确性和偏见，这些信息的可靠性可能存疑 [18]。此外，将工具集成到智能体中需要全面的理解力，以解释不同情境下检索到的信息，这可能导致更高的计算成本，并使外部数据与内部决策过程的对齐变得复杂。另外，使用外部 API 会引发关于隐私、数据安全以及使用政策合规性的担忧，需要进行严格的管理和监督 [18]。\n\n# 5.2.2 参数化形式的记忆\n\n另一种类型的方法是以参数化形式表示记忆。它们不会占用提示中额外的上下文长度，因此不受大型语言模型上下文长度限制的约束。然而，参数化记忆形式的研究仍不充分，我们将先前的工作分为两类：微调方法和记忆编辑方法。\n\n**微调方法**。将外部知识整合到智能体的记忆中有助于在其通用知识基础上丰富领域特定知识。为了将领域知识注入大型语言模型，监督式微调是一种常见方法，它使智能体具备领域专家的记忆。这显著提升了智能体完成领域特定任务的能力。在3.1节示例的任务（A）中，来自杂志的景点外部知识可在此任务执行前通过微调注入大型语言模型的参数中。\n\n在先前的研究中，Character-LLM [105] 专注于角色扮演场景。它利用监督式微调策略结合角色相关数据（如经历），赋予智能体特定角色的特质与特征。Huatuo [107] 旨在赋予智能体生物医学领域的专业能力，尝试基于中文医学知识库对 Llama [127] 进行微调。此外，为创建人工智能医生，DoctorGLM [129] 使用 LoRA [131] 对 ChatGLM [130] 进行微调，而 Radiology-GPT [132] 通过在标注的放射学数据集上进行监督式微调来提升放射学分析领域的知识。此外，InvestLM [113] 收集投资数据并进行微调，以增强金融投资领域的特定能力。\n\n微调方法能有效弥合通用智能体与专用智能体之间的差距。它提升了智能体在需要高精度和可靠领域特定信息的任务上的能力。然而，针对特定领域微调大型语言模型可能导致过拟合，同时也引发了对灾难性遗忘的担忧——即大型语言模型可能因参数更新而遗忘原有知识。微调的另一局限性在于计算成本和时间消耗，以及对大量数据的需求。因此，大多数微调方法应用于离线场景，难以处理在线场景（例如基于智能体观察和试验经验进行微调）。由于智能体与环境交互频繁，通过反向传播对在线动态交互的每一步进行微调的成本是难以承受的。\n\n## 原文内容\n记忆编辑方法。除了微调方法之外，另一种将记忆注入模型参数的方法是知识编辑 [133, 134]。与从特定数据集中提取模式的微调方法不同，知识编辑方法专门针对并仅调整需要更改的事实。它确保不相关的知识不受影响。知识编辑方法更适合小规模的记忆调整。通常，它们的计算成本较低，使其更适用于在线场景。在我们的任务（B）示例中，根据智能体的记忆，Alice总是在 $9:00\\mathrm{PM}$ 看电影，但她最近可能换了工作，在 $9:00\\mathrm{PM}$ 不再有空闲。如果是这样，相关的记忆（例如 $9:00\\mathrm{PM}$ 的惯例）应该被编辑，这可以通过知识编辑方法来实现。\n\n在先前的研究中，MAC [106] 旨在为在线场景设计一个有效且高效的记忆适应框架。它利用元学习来替代优化步骤。PersonalityEdit [135] 专注于编辑LLM和智能体的个性，基于大五人格等理论改变其特质。MEND [134] 利用元学习的思想训练一个轻量级模型，该模型能够为预训练语言模型的模型参数生成修改。APP [136] 研究添加新事实是否会导致对现有事实的灾难性遗忘。它关注邻居扰动对记忆添加的影响。此外，KnowledgeEditor [133] 基于学习-更新问题表述，训练一个超网络来预测注入记忆时模型参数的修改。Wang等人 [137] 提出了一个新的优化目标来改变LLM的中毒知识，同时保持其通用性能。对于基于LLM的智能体，智能体可以通过知识编辑来改变不良记忆，这可以被视为一种遗忘机制。\n\n知识编辑方法为更新存储在LLM参数内的信息提供了一种创新方式。通过专门针对和调整事实，这些方法可以确保非目标知识在更新过程中不受影响，从而缓解灾难性遗忘问题。此外，这种针对性调整机制允许进行更高效、资源密集度更低的更新，使得知识编辑成为高精度和实时修改的一个有吸引力的选择。然而，尽管有这些有前景的发展，元训练的计算成本以及无关记忆的保留仍然是重大的挑战。\n\n# 5.2.3 文本记忆与参数记忆的优缺点\n\n## 翻译要求\n1. **保持格式**：保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2. **术语准确**：专业术语翻译准确，必要时保留英文原词\n3. **学术风格**：使用学术论文的正式语体\n4. **公式保留**：LaTeX 公式保持原样，不翻译\n5. **引用保留**：参考文献引用格式保持原样\n\n## 原文内容\n文本记忆与参数记忆各有其优缺点，使其分别适用于不同的记忆内容与应用场景。本节，我们从多个方面讨论这两种记忆形式的优势与不足。\n\n**有效性**。文本记忆存储了智能体与环境交互的原始信息，更为全面和详细。然而，它受到大语言模型提示词令牌数量的限制，这使得智能体难以存储大量信息。相比之下，参数记忆不受提示词长度的限制，但在将文本转化为参数时可能会遭受信息损失，且复杂的记忆训练会带来额外的挑战。\n\n**效率**。对于文本记忆，每次大语言模型推理都需要将记忆整合到上下文提示词中，这导致了更高的成本和更长的处理时间。相比之下，对于参数记忆，信息可以被整合到大语言模型的参数中，从而消除了这些上下文的额外开销。然而，参数记忆在写入过程中会产生额外成本，而文本记忆则更容易写入，尤其是对于少量数据。简而言之，文本记忆在写入方面更高效，而参数记忆在读取方面更高效。\n\n**可解释性**。文本记忆通常比参数记忆更具可解释性，因为自然语言是人类理解信息最自然、最直接的方式，而参数记忆通常以潜在空间表示。然而，这种可解释性是以信息密度为代价获得的。这是因为文本记忆中的词序列是在离散空间中表示的，其密度不如参数记忆中的连续空间。\n\n总之，这两种记忆类型之间的权衡使其适用于不同的应用。例如，对于需要回忆近期交互的任务，如对话和特定上下文任务，文本记忆似乎更有效。对于需要大量记忆或成熟知识的任务，参数记忆可能是更好的选择。\n\n# 5.3 记忆操作\n\n我们将记忆的整个过程分为三个操作：记忆写入、记忆管理和记忆读取。这三者通常协同工作以实现记忆功能，为大语言模型推理提供信息。我们在表3中总结了先前关于记忆操作的研究工作。\n\n# 5.3.1 记忆写入\n\n在信息被智能体感知后，其中一部分将通过记忆写入操作被智能体存储以供后续使用，而识别哪些信息是必须存储的至关重要。许多研究选择存储原始信息，而其他研究也将原始信息的摘要存入记忆模块。\n\n## 代表性研究\n在 TiM [97] 中，原始信息将被提取为两个实体之间的关系，并存储在一个结构化数据库中。当写入数据库时，相似的内容将被存储在同一个组中。在 SCM [98] 中，它设计了一个内存控制器来决定何时执行操作。该控制器作为整个内存模块的指导。在 MemGPT [100] 中，内存写入是完全自主的。智能体可以根据上下文自主更新内存。在 MemoChat [94] 中，智能体通过抽象主要讨论的主题来总结每个对话片段，并将其存储为索引内存片段的键。\n\n## 讨论\n先前的研究表明，设计内存写入操作期间的信息提取策略至关重要 [94]。这是因为原始信息通常冗长且包含噪声。此外，不同的环境可能提供各种形式的反馈，如何提取信息并将其表示为内存对于内存写入也具有重要意义。\n\n# 5.3.2 内存管理\n\n对人类而言，记忆信息在大脑中不断被处理和抽象。智能体中的内存也可以通过反思来管理，以生成更高层次的记忆、合并冗余的记忆条目，以及遗忘不重要的早期记忆。\n\n## 代表性研究\n在 MemoryBank [6] 中，智能体处理和提炼对话，生成关于日常事件的高层次摘要，类似于人类回忆其经历的关键方面。通过长期互动，它们持续评估和完善其知识，生成关于个性特征的日常洞见。在 Voyager [99] 中，智能体能够根据环境的反馈来完善其记忆。在 Generative Agents [83] 中，智能体可以通过反思获得更高层次的信息，其中抽象思想由智能体生成。当累积了足够多需要处理的事件时，反思过程将被激活。对于 GITM [93]，为了为各种情况建立共同的参考计划，多个计划中的关键动作会在内存模块中被进一步总结。\n\n## 讨论\n大多数内存管理操作都受到人脑工作机制的启发。凭借大语言模型模拟人类思维的强大能力，这些操作可以帮助智能体更好地生成高层次信息并与环境交互。\n\n表 3：内存操作总结。如果一个模型在内存操作上没有特殊设计，我们用 $\\circ$ 标记，否则用 $\\checkmark$ 表示。$\\times$ 表示论文中未讨论内存操作。\n\n<table><tr><td rowspan=\"2\">模型</td><td rowspan=\"2\">写入</td><td colspan=\"3\">管理</td><td rowspan=\"2\">读取</td></tr><tr><td>合并</td><td>反思</td><td>遗忘</td></tr><tr><td>MemoryBank [6]</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RET-LLM [7]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>ChatDB [96]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>TiM [97]</td><td>✓</td><td>✓</td><td>×</td><td>✓</td><td>✓</td></tr><tr><td>SCM [98]</td><td>✓</td><td>✓</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Voyager [99]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MemGPT [100]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MemoChat [94]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>MPC [101]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Generative Agents [83]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>RecMind [102]</td><td>○</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>Retroformer [103]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>○</td></tr><tr><td>ExpeL [82]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>○</td></tr><tr><td>Synapse [91]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>✓</td></tr><tr><td>GITM [93]</td><td>○</td><td>✓</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>ReAct [104]</td><td>○</td><td>×</td><td>×</td><td>×</td><td>○</td></tr><tr><td>Reflexion [5]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>○</td></tr><tr><td>RecAgent [95]</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Character-LLM [105]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>○</td></tr><tr><td>MAC [106]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>Huatuo [107]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>○</td></tr><tr><td>ChatDev [1]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>InteRecAgent [108]</td><td>✓</td><td>✓</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaAgents [109]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>TPTU [110, 111]</td><td>○</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>MetaGPT [112]</td><td>✓</td><td>×</td><td>✓</td><td>×</td><td>✓</td></tr><tr><td>S3 [2]</td><td>✓</td><td>×</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>InvestLM [113]</td><td>✓</td><td>×</td><td>×</td><td>×</td><td>○</td></tr></table>\n\n# 5.3.3 记忆读取\n\n当智能体需要信息进行推理和决策时，记忆读取操作将从记忆中提取相关信息以供使用。因此，如何访问与当前状态相关的信息至关重要。由于记忆实体的数量庞大，且并非所有实体都与当前状态相关，需要精心设计，以基于相关性及其他面向任务的因素提取有用信息。\n\n代表性研究。在 ChatDB [96] 中，记忆读取操作通过 SQL 语句执行。这些语句将由智能体预先生成为一系列记忆链。在 MPC [101] 中，智能体可以从记忆池中检索相关记忆。该方法还提出提供思维链示例以忽略某些记忆。ExpeL [82] 利用 Faiss [124] 向量存储作为记忆池，并获取与当前任务相似度得分最高的前 $K$ 个成功轨迹。\n\n讨论。在某种程度上，记忆的读取和写入操作是协作的，记忆写入的形式极大地影响了记忆读取的方法。对于文本形式的记忆，大多数先前工作使用文本相似度和其他辅助信息进行读取。对于参数化记忆的形式，现有模型可能仅利用更新后的参数进行推理，这可以视为一种隐式的读取过程。\n\n# 6 如何评估基于大语言模型的智能体中的记忆\n\n如何有效评估记忆模块仍然是一个开放性问题，先前的研究根据不同应用提出了多种评估策略。为了清晰地展示不同评估方法的共同思路，本节我们总结了一个通用框架，该框架包含两大类评估策略（概述见图5），即：（1）直接评估，独立衡量记忆模块的能力。（2）间接评估，通过端到端的智能体任务来评估记忆模块。如果任务能够被有效完成，则证明记忆模块是有用的。\n\n# 6.1 直接评估\n\n这类方法将智能体的记忆视为一个独立组件，并独立评估其有效性。先前的研究可分为两类：主观评估和客观评估。主观评估旨在基于人类判断来衡量记忆的有效性，这在缺乏客观事实依据的场景中可广泛应用。客观评估则基于数值指标评估记忆的有效性，这使得比较不同的记忆模块变得容易。\n\n# 6.1.1 主观评估\n\n在主观评估中，存在两个关键问题，即：（1）应该评估哪些方面，以及（2）如何执行评估过程。首先，以下两个方面是评估记忆模块最常用的视角。\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n**连贯性**。此方面指被回忆的记忆是否自然且适合当前语境。例如，若智能体正在为 Alice 的旅行制定计划，相关记忆应与其旅行偏好相关，而非工作偏好。在先前研究中，Modarressi 等人 [7] 探讨了记忆模块能否在不断变化的知识中提供恰当的参照。Liang 等人 [98] 通过示例展示了当前查询与历史记忆之间的关系。Zhong 等人 [6] 和 Liu 等人 [97] 通过评分标签来评估整合了上下文与检索记忆的响应的连贯性。Lee 等人 [101] 则关注被回忆的记忆与上下文之间的矛盾。\n\n**合理性**。此方面旨在评估被回忆的记忆是否合理。例如，若智能体被要求回答\"颐和园在哪里\"，被回忆的记忆应是\"颐和园在北京\"，而非\"颐和园在月球上\"。在先前研究中，Lee 等人 [101] 要求众包工作者直接对检索记忆的合理性进行评分。Zhong 等人 [6] 和 Liu 等人 [97] 则招募人工评估员来检查记忆是否包含针对当前问题的合理答案。\n\n关于如何执行评估过程，存在两个重要问题。第一个是如何选择人工评估员。通常，评估员应熟悉评估任务，以确保标注结果具有说服力和可靠性。此外，评估员的背景应多样化，以消除特定人群的主观偏见。第二个问题是如何对记忆模块的输出进行标注。通常，可以直接对结果进行评分 [6]，或对两个候选结果进行比较 [95]。前者可以获得绝对且量化的评估结果，而后者在独立评分每个候选结果时可以减少标注噪声。此外，评分粒度也需要精心设计。过于粗略的评分可能无法有效区分不同记忆模块的能力，而过于精细的评分则可能增加评估员做出判断的工作量。\n\n总体而言，主观评估可应用于广泛场景，只需定义评估维度并让招募的评估员做出判断。这种方法通常更具可解释性，因为评估员可以提供其判断的理由。然而，由于需要雇佣人工评估员，主观评估成本较高。此外，不同的评估员群体可能存在各种偏见，使得结果难以复现和比较。\n\n# 6.1.2 客观评估\n\n在客观评估中，先前研究通常定义数值化指标来评估记忆模块的有效性和效率。\n\n## 翻译结果\n\n**结果正确性**。该指标衡量智能体能否基于记忆模块成功回答预定义的问题。例如，问题可以是\"Alice今天去了哪里？\"，并给出两个选项\"A: 颐和园\"和\"B: 长城\"。然后，智能体应根据问题及其记忆选择正确答案。智能体生成的答案将与标准答案进行比较。形式上，准确率可计算为\n\n$$\n\\text {C o r r e c t n e s s} = \\frac {1}{N} \\sum_ {i = 1} ^ {N} \\mathbb {I} \\left[ a _ {i} = \\hat {a} _ {i} \\right],\n$$\n\n其中 $N$ 是问题数量，$a_{i}$ 表示第 $i$ 个问题的标准答案，$\\hat{a}_{i}$ 表示智能体给出的答案，而 $\\mathbb{I}[a_i = \\hat{a}_i]$ 是匹配函数，通常表示为\n\n$$\n\\mathbb {I} \\left[ a _ {i} = \\hat {a} _ {i} \\right] = \\left\\{ \\begin{array}{l l} 1 & \\text {i f} a _ {i} = \\hat {a} _ {i}, \\\\ 0 & \\text {i f} a _ {i} \\neq \\hat {a} _ {i}. \\end{array} \\right.\n$$\n\n在先前的研究中，Hu等人[96]从带有标注标准答案的历史记录中构建问题，并计算被回忆的记忆能否匹配正确答案的准确率。类似地，Packer等人[100]生成只能从过往会话中推导出的问题与答案，并将智能体的响应与标准答案进行比较以计算准确率。\n\n**引用准确性**。该指标评估智能体能否发现相关的记忆内容来回答问题。与上述关注最终结果的指标不同，引用准确性更关注支持智能体最终决策的中间信息。具体而言，它将检索到的记忆与预先准备的标准答案进行比较。对于上述\"Alice今天去了哪里？\"的问题，如果记忆内容包括(A)\"Alice今天在王府井和朋友吃了午餐。\"和(B)\"Alice午餐吃了烤鸭\"，那么一个更好的记忆模块应选择(A)作为回答问题的引用。通常，研究者利用F1分数来评估引用准确性，其计算公式为\n\n$$\n\\mathrm {F} 1 = 2 \\cdot \\frac {\\text {P r e c i s i o n} \\cdot \\text {R e c a l l}}{\\text {P r e c i s i o n} + \\text {R e c a l l}},\n$$\n\n其中精确率和召回率的计算公式为 精确率 = $\\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}$，召回率 = $\\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$。TP代表真正例记忆内容的数量，FP代表假正例记忆内容的数量，FN代表假负例记忆内容的数量。在先前的研究中，Lu等人[94]利用F1分数来评估记忆的检索过程，而Zhong等人[6]则侧重于评估相关的记忆能否被成功检索。\n\n## 翻译结果\n\n结果正确性与引用准确性均被用于评估记忆模块的有效性。除有效性外，效率也是一个重要方面，尤其是在实际应用中。因此，我们对效率的评估描述如下。\n\n**时间与硬件成本**。总时间成本包括用于记忆适配和推理的时间。适配时间指记忆写入和记忆管理所花费的时间，而推理时间则表示记忆读取的时间延迟。具体而言，记忆操作结束时间与开始时间之差可视为时间消耗。形式上，每类操作的平均时间消耗可表示为\n\n$$\n\\Delta \\mathrm {t i m e} = \\frac {1}{M} \\sum_ {i = 1} ^ {M} t _ {i} ^ {\\mathrm {e n d}} - t _ {i} ^ {\\mathrm {s t a r t}},\n$$\n\n其中 $M$ 表示此类操作的数量，$t_i^{\\mathrm{end}}$ 表示第 $i$ 次操作的结束时间，$t_i^{\\mathrm{start}}$ 表示该操作的开始时间。至于计算开销，可通过 GPU 峰值内存分配量进行评估。在先前的工作中，Tack 等人 [106] 利用峰值内存分配量和适配时间来评估记忆操作的效率。\n\n客观评估提供了数值化的策略来比较不同的记忆方法，这对于该领域的基准测试和推动未来发展至关重要。\n\n# 6.2 间接评估\n\n除了上述直接评估记忆模块的方法外，通过任务完成情况进行评估也是一种流行的评估策略。这类方法背后的直觉是，如果智能体能够成功完成一项高度依赖记忆的任务，则表明所设计的记忆模块是有效的。在以下部分，我们将介绍几种用于间接评估记忆模块的代表性任务。\n\n# 6.2.1 对话\n\n与人类进行对话是智能体最重要的应用之一，在此过程中记忆起着至关重要的作用。通过将上下文信息存储在记忆中，智能体使用户能够体验个性化的对话，从而提高用户的满意度。因此，当智能体的其他部分确定时，对话任务的性能可以反映不同记忆模块的有效性。\n\n## 翻译结果\n\n在对话语境中，一致性和参与度是评估智能体记忆有效性的两种常用方法。一致性指智能体的回应与上下文保持连贯的程度，因为在对话过程中应避免出现剧烈的变化。例如，Lu 等人 [94] 在交互式对话中评估智能体的一致性，使用 GPT-4 对智能体的回应进行评分。参与度则指用户被吸引以继续对话的程度。它反映了智能体回应的质量与吸引力，以及智能体为当前对话塑造角色的能力。例如，Lee 等人 [101] 通过 SCE-p 分数评估回应的吸引度，而 Packer 等人 [100] 则利用 CSIM 分数来评估记忆对提升用户参与度的效果。\n\n# 6.2.2 多源问答\n\n多源问答能够全面评估来自多个来源的记忆信息，包括任务内部信息、跨任务信息以及外部知识。其重点在于整合来自不同内容和来源的记忆利用。\n\n在先前的研究中，Yao 等人 [104] 评估了整合任务试验信息与来自维基百科的外部知识的记忆。随后，Shinn 等人 [5] 和 Yao 等人 [103] 进一步纳入了同一任务的跨试验信息，允许记忆从先前失败的试验中获取更多经验。此外，Packer 等人 [100] 允许智能体利用来自多文档信息的记忆进行问答。\n\n通过评估多源问答任务，可以检验智能体记忆在整合来自不同来源的内容方面的能力。它也揭示了由于多信息源导致的记忆矛盾问题，以及可能影响记忆模块性能的知识更新问题。\n\n# 6.2.3 长上下文应用\n\n除了上述通用应用外，在许多场景中，基于大语言模型的智能体必须依据极长的提示进行决策。在这些场景中，长提示通常被视为记忆内容，在驱动智能体行为方面发挥着重要作用。\n\n## 翻译结果\n\n在先前的研究中，Huang 等人 [19] 组织了一项关于长上下文大语言模型的全面综述，该综述总结了长上下文场景下的评估指标。此外，Shaham 等人 [138] 提出了一个零样本基准，用于评估智能体对长上下文自然语言的理解能力。至于具体的长上下文任务，长上下文段落检索是评估智能体长上下文能力的重要任务之一。它要求智能体在长上下文中找到与给定问题或描述相对应的正确段落 [139]。长上下文摘要则是另一个代表性任务。它要求智能体对整个上下文形成全局理解，并根据描述进行总结，在此过程中可以使用诸如 ROUGE 等匹配分数指标将结果与真实情况进行比较。\n\n对长上下文应用的评估为评估智能体中记忆功能提供了更广泛的途径，侧重于实际的下游场景。综合基准测试 [138, 140] 也为长上下文理解能力提供了客观的评估。\n\n# 6.2.4 其他任务\n\n除了上述三类主要的间接评估任务外，在通用任务中还存在一些其他指标，可以揭示记忆模块的有效性。\n\n**成功率** 指的是智能体能够成功解决的任务比例。对于 Yao 等人 [104]、Shinn 等人 [5] 和 Zhao 等人 [82] 的研究，他们评估了在 AlfWorld [141] 中通过推理和记忆能够正确完成多少空间任务。在 Zhu 等人 [93] 的研究中，他们评估了在 Minecraft 中生产不同物品的成功率，以展示记忆的效果。此外，Shinn 等人 [5] 通过生成的代码衡量了通过问题的成功率，而 Zheng 等人 [91] 则计算了计算机控制的成功率和元素选择的准确率，以展示轨迹即示例记忆的功能。**探索度** 通常出现在探索性游戏中，反映了智能体能够探索环境的程度。例如，Wang 等人 [99] 比较了在 Minecraft 中探索到的不同物品的数量，以反映记忆中的技能学习。\n\n事实上，几乎所有配备了记忆模块的智能体都可以通过消融研究来评估记忆的效果，比较有/无记忆模块时的性能表现。对特定场景的评估可以更实际地反映记忆对于下游应用的重要性。\n\n# 6.3 讨论\n\n与直接评估相比，通过特定任务进行间接评估可能更容易实施，因为目前已存在许多公开基准。然而，任务表现可归因于多种因素，记忆仅是其中之一，这可能导致评估结果存在偏差。通过直接评估，可以独立评估记忆模块的有效性，从而提高评估结果的可靠性。然而，据我们所知，目前尚无专门为基于大语言模型（LLM）的智能体中的记忆模块设计的开源基准。\n\n# 7 记忆增强的智能体应用\n\n近年来，基于大语言模型（LLM）的智能体已在多种场景中得到研究，推动了社会进步。一般而言，大多数基于LLM的智能体都配备了记忆模块。然而，这些记忆组件所承担的具体作用、存储的特定信息以及使用的实现方法，在不同的应用中各不相同。为了为基于LLM的智能体中记忆功能的设计提供见解，在本节中，我们回顾并总结了记忆机制在各种应用场景的基于LLM的智能体中是如何体现的。具体而言，我们将其分为以下几类：角色扮演与社会模拟、个人助理、开放世界游戏、代码生成、推荐、特定领域的专家系统以及其他应用。总结如表4所示。\n\n# 7.1 角色扮演与社会模拟\n\n角色扮演是基于LLM智能体的经典应用，其中记忆在智能体内部扮演着至关重要的角色。它赋予角色独特的特征，使其彼此区分。先前许多研究已探索了构建角色记忆的方法 [105, 143, 145-147]。Shao等人[105]通过经验上传构建角色记忆，该方法利用监督微调（SFT）将记忆注入模型参数。Li等人[143]通过改进的提示词和从剧本中提取的角色记忆来增强大语言模型在角色扮演中的表现，其中用户查询和\n\n表4：记忆增强智能体应用总结。\n\n<table><tr><td>应用领域</td><td>模型</td><td>应用领域</td><td>模型</td></tr><tr><td>角色扮演</td><td>Character-LLM [105]<br>ChatHaruhi [143]<br>RoleLLM [145]<br>NarrativePlay [146]<br>CharacterGLM [147]</td><td>代码生成</td><td>RTLFixer [142]<br>GameGPT [144]<br>ChatDev [1]<br>MetaGPT [109]<br>CodeAgent [114]</td></tr><tr><td rowspan=\"2\">社会模拟</td><td rowspan=\"2\">Generative Agents [83]<br>Lyfe Agents [148]<br>S3[2]<br>MetaAgents [109]<br>WarAgent [150]</td><td>推荐系统</td><td>RecAgent [95]<br>InteRecAgent [108]<br>RecMind [102]<br>AgentCF [149]</td></tr><tr><td>医疗</td><td>Huatuo [107]</td></tr><tr><td>个人助理</td><td>MemoryBank [6]<br>RET-LLM [7]<br>MemoChat [94]<br>MemGPT [100]<br>MPC [101]<br>AutoGen [153]<br>ChatDB [96]<br>TiM [97]<br>SCM [98]</td><td>金融</td><td>DoctorGLM [129]<br>Radiology-GPT [132]<br>Wang et al. [151]<br>EHRAgent [152]<br>ChatDoctor [115]<br>InvestLM [113]<br>TradingGPT [154]<br>QuantAgent [155]<br>FinMem [156]<br>Koa et al. [157]</td></tr><tr><td>游戏</td><td>Voyager [99]<br>GITM [93]<br>JARVIS [159]<br>LARP [161]</td><td>科学</td><td>Chemist-X [158]<br>ChemDFM [160]<br>MatChat [162]</td></tr></table>\n\n聊天机器人的回复被连接起来形成一个序列作为记忆。Wang等人[145]将角色特定知识和情景记忆注入基于大语言模型的智能体中，其中上下文问答对被连接起来形成情景记忆。Zhao等人[146]旨在生成类人回复，其指导来自从叙事中提取的人格特质，这些特质可以根据相关性和重要性进行存储和检索。Zhou等人[147]为不同角色生成基于角色的对话，并通过监督微调赋予基于大语言模型的智能体相应的风格。\n\n社会模拟本质上是角色扮演的延伸，更侧重于多智能体建模。记忆模块是此类应用的重要组成部分，有助于准确模拟人类的动态行为。在先前的研究中，Kaiya等人[148]提出了一种“总结与遗忘”记忆机制，以在社会场景中实现更好的自我监控。Gao等人[2]专注于社交网络模拟系统。系统中的每个智能体都有一个记忆池，其中包含来自在线平台的各种用户消息，用于识别用户。Li等人[163]维护对话上下文，包括经济环境和前几个月的智能体决策，以模拟广泛的宏观经济趋势对智能体决策的影响，并使智能体掌握市场动态。Li等人[109]模拟了人类社会中的求职场景，其中智能体的记忆最初包含个人资料和目标，并进一步通过对话和个人反思等其他信息进行丰富。Hua等人[150]模拟了参与战争国家的决策和后果，其中智能体的对话被持续维护到记忆中。\n\n在设计用于角色扮演和社交模拟的智能体记忆系统时，存在若干关键见解。首先，记忆应与角色特征保持一致，这些特征可用于识别每个角色并将其与其他角色区分开来。这对于提升角色扮演的真实性和社交模拟的多样性至关重要。其次，记忆应适当地影响智能体的后续行为，以确保其行为的一致性与合理性。此外，对于拟人化智能体，其记忆机制应符合人类记忆的特征，例如遗忘和长/短期记忆，这应参考认知心理学的相关理论。\n\n# 7.2 个人助理\n\n基于大语言模型的智能体非常适合创建个人助理，例如能够与用户进行长期对话的智能体 [94, 101, 153]，以及负责自动搜索信息的智能体 [164]。这些智能体通常需要记忆先前的对话以保持一致性，并记住关键风格和事件，以生成更具个性化和相关性的回应。Lu 等人 [94] 通过保存对话的内容和信息来维持对话的上下文一致性，这有助于通过检索找到合适的相关信息。Lee 等人 [101] 总结对话以提取重要信息，将其存储起来，并在未来推理时进行检索。Pan 等人 [164] 专注于信息搜索任务，他们设计了记忆模块来存储用户的上下文信息，并通过工具使用来增强外部知识。Wu 等人 [153] 保留重要的上下文作为记忆，以维持对话的一致性。\n\n总而言之，大多数个人助理的记忆实现采用文本形式的检索方法，因为它们更擅长从对话片段中找到相关信息。在记忆存储方面，智能体应记住用户与智能体交互过程中的事实信息，以及用户的个人风格，以便生成适应用户情境的回应。此外，在回忆记忆时，智能体应识别并检索与当前查询和上下文相关的记忆。这一原则能使智能体正确理解用户需求，并保持对话的一致性。\n\n# 7.3 开放世界游戏\n\n## 翻译结果\n\n对于游戏和开放世界探索，基于大语言模型（LLM）的智能体始终将后续观察作为任务上下文进行维护，并将先前成功试验中的经验存储起来。通过利用过去的经验，智能体可以避免重复犯同样的错误，并对环境达成高层次的理解，从而更有效地进行探索。其中一些智能体能够获取外部数据库或API以获取通用知识[99, 93, 159, 161]。Wang等人[99]将获得的技能存入记忆，以备在《我的世界》中进一步使用。Zhu等人[93]存储并检索成功的轨迹作为类似任务的示例，并通过API调用利用外部《我的世界》维基。Wang等人[159]构建了多模态记忆作为知识库，并通过检索交互经验为提示提供示例。Yan等人[161]维护用于决策的工作记忆，保存并检索相关的过去经验，并利用外部数据集获取通用知识。\n\n总而言之，无论是单次试验内还是跨试验的信息，记忆的关键方面在于反思过去的交互，并总结出可应用于后续探索的经验。除了通过自身参与的试验积累经验外，吸收外部知识作为智能体记忆的一部分，也是增强智能体探索能力的重要途径。\n\n# 7.4 代码生成\n\n在代码生成的场景中，基于大语言模型（LLM）的智能体可以从记忆中搜索相关信息，从而获得更多用于开发的知识。它们可以保存先前的经验以应对未来的问题，也可以在对话式开发界面中维护上下文[142, 144, 1, 109]。Tsai等人[142]构建了一个外部非参数记忆数据库，用于存储编译器错误和人类专家指令，以自动修复语法错误。在[144]中，个人信息将被存储在记忆中，有助于保留决策的上下文和知识。Qian等人[1]采用多智能体进行软件开发，其中每个角色都维护一个记忆来存储与其他角色的过去对话。Li等人[109]同样专注于软件开发，当错误发生时，智能体可以检索其保存在记忆中的历史记录。Zhang等人[114]在代码生成遇到问题时可以搜索相关信息。\n\n通过利用外部资源，智能体可以学习与代码相关的知识并将其存储到记忆中，从而增强代码生成的能力。此外，记忆可以提高代码生成的连续性和一致性。通过整合上下文记忆，智能体可以更好地理解软件开发的需求，从而增强生成代码的连贯性。再者，记忆对于代码的迭代优化也至关重要，因为它可以根据历史记录识别开发者的目标。\n\n# 7.5 推荐\n\n在推荐系统领域，先前的研究工作主要聚焦于两个方向：一是模拟推荐系统中的用户行为[95, 108]，其中记忆模块可用于表征现实世界中的用户画像与历史交互；二是致力于提升推荐性能，或提供新型推荐交互界面[149, 102]。Wang 等人[95]通过在推荐场景中模拟用户行为来生成推荐系统所需数据，其智能体将历史观测与洞察存储于分层记忆结构中。Huang 等人[108]的研究中，基于大语言模型的智能体通过记忆模块长期存档用户对话历史，并捕捉与当前提示最相关的近期对话，以此构建交互式推荐系统。该研究还采用演员-评论家反思机制以增强智能体的鲁棒性。在[149]中，物品智能体与用户智能体被赋予不同类型的记忆模块：物品智能体配备动态记忆模块，用于捕捉并保存与其内在属性及采纳者偏好相关的信息；用户智能体则通过自适应记忆更新机制，使其行为与用户行为及偏好保持动态对齐。Wang 等人[102]通过记忆模块存储用户个性化信息（如物品评价与评分），并借助网络搜索工具获取领域专业知识与实时信息。\n\n无论是模拟推荐系统中的用户行为，还是捕捉用户偏好，通过记忆模块保留个性化信息都至关重要。核心挑战在于如何将个性化信息及反馈与大语言模型对齐，并将其有效存储于智能体记忆之中。这也是弥合传统推荐模型与大语言模型间鸿沟的关键任务。\n\n# 7.6 特定领域的专家系统\n\n**医学领域**。在医学领域中，多数现有研究通过为基于大语言模型的智能体配备包含外部知识的记忆模块来增强其能力[107, 129, 132, 151, 115]。Wang 等人[107]以问答形式将医学知识图谱 CMeKG[165]融入 LLaMA[127]的微调过程，以强化模型的医学领域知识。Xiong 等人[129]采用 LoRA[131]对基础模型进行高效微调，以适配医疗健康场景。Wang 等人[151]使基于大语言模型的智能体能够获取基于文本的外部知识作为推理参考。此外，Shi 等人[152]基于历史经验中最相关的成功案例构建记忆库，并采用相似度度量方法实现医学领域相关问题的检索。\n\n## 翻译结果\n\n**金融领域**。先前的一些研究也将基于大语言模型的智能体应用于金融领域，其记忆能够存储金融知识[113]、市场信息[154, 156]以及成功经验[157, 155]。Yang等人[113]构建了金融投资数据集来微调LLaMA[127]，以赋予其投资相关知识。Li等人[154]设计了一种分层记忆结构来存储不同类型的市场信息。Wang等人[155]记录持续的交互（如交流和信息）以确保响应的一致性，并将先前的输出记录为经验，用于检索相关示例，从而为智能体提供多样化的学习情境。Koa等人[157]存储过去的价格变动及其解释，并对先前的尝试进行反思生成。Yu等人[156]采用分层记忆机制，为推理提供丰富的信息。\n\n**科学领域**。在科学领域，一些现有研究设计了基于大语言模型的智能体，其记忆中含有大量知识，用于解决问题[158, 160, 162]。Chen等人[158]将分子数据库和在线文献作为外部知识纳入基于大语言模型的智能体的记忆中，并在需要相关信息时进行检索。Zhao等人[160]和Chen等人[162]分别通过在化学和结构材料领域进行微调，来赋予智能体领域知识。\n\n要在特定的垂直领域基于智能体构建专家系统，必须在其记忆中保留领域特定的知识。然而，这面临几个挑战。首先，领域知识具有专业性且要求更高的准确性，这导致构建记忆存储存在困难。其次，领域知识通常具有时效性，未来可能变得过时。因此，当部分知识过时后，记忆需要进行部分更新。此外，领域知识的体量庞大，使得基于当前查询从记忆中回忆相关知识变得困难。\n\n# 7.7 其他应用\n\n记忆在基于大语言模型的智能体中还有其他一些应用。Wang等人[166]专注于云根因分析任务，使用记忆来存储框架规则、任务要求、工具文档、少样本示例以及智能体观察结果。Qiang等人[167]解决了本体匹配问题。智能体保存对话记录，并构建一个用于检索外部知识的理性数据库。Wen等人[168]研究自动驾驶，其记忆模块由向量数据库构建，并包含来自过去驾驶场景的经验。Wang等人[169]提出改进用户验收测试，采用了自我反思机制。在每次尝试后，操作智能体总结对话并更新记忆池，直到完成当前步骤的目标。\n\n对于不同的应用，记忆的关注点各不相同，因为它本质上是为下游任务服务的。因此，其设计也应考虑任务的需求。\n\n# 8 局限性与未来方向\n\n# 8.1 参数化记忆的更多进展\n\n目前，基于大语言模型（LLM）的智能体的记忆主要以文本形式存在，特别是对于观察记录、试验经验和文本知识库等上下文知识。尽管文本记忆具有可解释性强、易于扩展和编辑的优点，但与参数化记忆相比，这也意味着效率上的牺牲。本质上，参数化记忆拥有更高的信息密度，它通过在潜在空间中的连续实数向量来表达语义，而文本记忆则使用离散空间中标记（token）的组合进行语义表达。因此，参数化记忆提供了更丰富的表达空间，其软编码形式相较于标记序列的硬编码形式也更为鲁棒。此外，参数化记忆在存储上更为高效，它无需显式存储大量文本，类似于一个知识压缩过程。至于记忆管理，如合并与反思，参数化记忆不一定像文本记忆那样需要设计手动规则，而是可以采用优化方法隐式地学习这些过程。而且，可插拔的参数化记忆类似于一张数字生命卡，能够赋予智能体所需的特性。例如，华佗 [107] 旨在通过在中国医学知识库上精调 Llama [127] 模型，来增强智能体在生物医学领域的专业知识。MAC [106] 旨在创建一个适用于在线环境的参数化记忆适配框架，它采用元学习技术来替代传统的优化阶段。\n\n尽管参数化记忆前景广阔，但目前仍面临诸多挑战。其中首要的是效率问题：如何有效地将文本信息转化为参数或参数的修改是一个关键问题。目前，研究者可以通过监督微调（SFT）将大量领域知识转移到LLM的参数中。然而，这个过程耗时且需要大量的文本语料，因此不适合情境性知识。一种可行的方法是采用元学习让模型学会记忆。例如，MEND [134] 利用元学习方法训练一个紧凑模型，该模型能够为预训练语言模型的参数生成调整量。此外，参数化记忆缺乏可解释性可能构成障碍，尤其是在需要高度信任的领域，如医学。因此，增强参数化记忆的可信度和可解释性是一个亟待解决的问题。\n\n# 8.2 基于LLM的多智能体应用中的记忆\n\n对大型语言模型（LLM）中记忆机制的探索已扩展至多智能体系统（MAS）这一动态领域，标志着在同步、通信及信息不对称管理方面取得了显著进展。在协作场景中，一个关键方面是智能体间的记忆同步。这一过程对于建立统一的知识库、确保不同智能体间决策的一致性至关重要。例如，Chen 等人 [170] 强调了集成同步记忆模块对于多机器人协作的重要性。另一个重要方面是智能体间的通信，这在很大程度上依赖于记忆来维持上下文并解释信息。例如，Mandi 等人 [171] 阐述了促进智能体间达成共识的记忆驱动通信框架。除了协作场景，一些研究也关注竞争场景，其中信息不对称成为一个关键问题 [172]。\n\n展望未来，基于 LLM 的 MAS 中记忆的发展正处于技术创新与战略应用的交汇点。它呼唤着对新型记忆模块的探索，这些模块能够进一步增强智能体同步、实现更有效的通信，并在信息丰富的环境中提供战略优势。此类记忆模型的开发不仅需要应对当前记忆集成与管理方面的挑战，还需探索记忆在促进更鲁棒、更智能、更具适应性的 MAS 方面尚未开发的潜力。正如开创性研究所表明的，基于 LLM 的 MAS 不断发展的格局为未来记忆利用与管理方面的创新搭建了一个充满前景的舞台。预计这一探索将揭示记忆集成的新维度，突破当前可实现的范围，并在 MAS 领域树立新的标杆。\n\n# 8.3 基于记忆的终身学习\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n终身学习是人工智能领域的一个前沿课题，旨在扩展智能体在其整个生命周期内的学习能力[173]。智能体能够持续与环境交互，持久地观察环境，并获取外部知识，从而实现类似人类的渐进式提升模式。智能体的记忆是实现终身学习的关键，因为它需要学会存储和应用过去的观察结果。基于大语言模型的智能体的终身学习具有重要的实用价值，例如在长期社会模拟和个人助理等领域。然而，它也面临若干挑战。首先，终身学习具有时序性，要求智能体的记忆能够捕捉时间维度。这种时序性可能导致记忆之间的相互作用，例如记忆重叠。此外，由于终身学习周期漫长，它需要存储海量记忆并在需要时进行检索，可能还需要引入某种遗忘机制。\n\n# 8.4 拟人化智能体中的记忆\n\n拟人化智能体是指被设计为表现出与人类一致行为的智能体，从而促进其在社会模拟、人类行为研究和角色扮演等领域的应用。与通常追求更强能力的目标导向型智能体不同，拟人化智能体的能力水平应紧密模仿人类。因此，拟人化智能体的记忆应与人类的认知过程保持一致，遵循诸如记忆失真和遗忘等心理学原理。此外，拟人化智能体应具备知识边界，即其知识应与其所模拟实体的知识相对应。例如，在角色扮演场景中，一个扮演儿童的智能体不应理解超出该年龄段典型认知水平的高等数学概念或其他复杂知识[174]。\n\n# 9 结论\n\n在本综述中，我们对基于大语言模型的智能体的记忆机制进行了系统性回顾，重点关注了“是什么”、“为何需要”以及“如何设计与评估”基于大语言模型的智能体中的记忆模块这三个关键问题。为了展示智能体记忆的重要性，我们还介绍了许多典型应用，其中记忆模块发挥着重要作用。我们相信本综述能为该领域的新研究者提供有价值的参考，同时也希望能启发更多先进的记忆机制，以增强基于大语言模型的智能体。\n\n# 致谢\n\n我们感谢王磊对本综述的校对和宝贵建议。\n\n# 参考文献\n\n[1] 陈骞，丛鑫，杨成，陈伟泽，苏雨生，许巨圆，刘知远，孙茂松。面向软件开发任务的智能体协作系统。arXiv 预印本 arXiv:2307.07924，2023年。  \n[2] 高晨，兰晓冲，卢志宏，毛金柱，朴京华，王焕东，金德鹏，李勇。S<sup>3</sup>：基于大语言模型智能体的社交网络模拟系统。arXiv 预印本 arXiv:2307.14984，2023年。  \n[3] 王磊，马晨，冯雪阳，张泽宇，杨浩，张景森，陈致远，唐佳锴，陈旭，林衍凯等。基于大语言模型的自主智能体研究综述。arXiv 预印本 arXiv:2308.11432，2023年。\n\n[4] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, 等. 基于大语言模型的智能体的崛起与潜力：综述. arXiv 预印本 arXiv:2309.07864, 2023.  \n[5] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. Reflexion：具备语言强化学习能力的语言智能体. In 第三十七届神经信息处理系统大会, 2023.  \n[6] Wanjun Zhong, Lianghong Guo, Qiqi Gao, and Yanlin Wang. Memorybank：为大型语言模型增强长期记忆能力. arXiv 预印本 arXiv:2305.10250, 2023.  \n[7] Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Schütze. Ret-llm：迈向通用的大型语言模型读写记忆. arXiv 预印本 arXiv:2305.14322, 2023.  \n[8] Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, 等. 大型语言模型的指令微调：综述. arXiv 预印本 arXiv:2308.10792, 2023.  \n[9] Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. 大型语言模型对齐：综述. arXiv 预印本 arXiv:2309.15025, 2023.  \n[10] Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, and Qun Liu. 大型语言模型与人类对齐：综述. arXiv 预印本 arXiv:2307.12966, 2023.  \n[11] Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo Hao Cheng, Yegor Klochkov, Muhammad Faaiz Taufiq, and Hang Li. 可信赖的大型语言模型：评估大语言模型对齐性的综述与指南. arXiv 预印本 arXiv:2308.05374, 2023.  \n[12] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang. 大型语言模型的检索增强生成：综述. arXiv 预印本 arXiv:2312.10997, 2023.  \n[13] Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, 等. 大型语言模型的知识编辑：综述. arXiv 预印本 arXiv:2310.16218, 2023.  \n[14] Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, and Ningyu Zhang. 编辑大型语言模型：问题、方法与机遇. arXiv 预印本 arXiv:2305.13172, 2023.  \n[15] Peng Wang, Ningyu Zhang, Xin Xie, Yunzhi Yao, Bozhong Tian, Mengru Wang, Zekun Xi, Siyuan Cheng, Kangwei Liu, Guozhou Zheng, 等. Easyedit：一个易于使用的大型语言模型知识编辑框架. arXiv 预印本 arXiv:2308.07269, 2023.  \n[16] Zhangyin Feng, Weitao Ma, Weijiang Yu, Lei Huang, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, 等. 知识与大型语言模型融合的趋势：方法、基准与应用的综述与分类. arXiv 预印本 arXiv:2311.05876, 2023.  \n[17] Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, 等. 大型语言模型知识编辑的综合研究. arXiv 预印本 arXiv:2401.01286, 2024.  \n[18] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, 等. 基于基础模型的工具学习. arXiv 预印本 arXiv:2304.08354, 2023.  \n[19] Yunpeng Huang, Jingwei Xu, Zixu Jiang, Junyu Lai, Zenan Li, Yuan Yao, Taolue Chen, Lijuan Yang, Zhou Xin, and Xiaoxing Ma. 长上下文大型语言模型中Transformer架构的进展：一项全面综述. arXiv 预印本 arXiv:2311.12351, 2023.\n\n[20] Xindi Wang, Mahsa Salmani, Parsa Omidi, Xiangyu Ren, Mehdi Rezagholizadeh, and Ar-maghan Eshaghi. 超越极限：大语言模型上下文长度扩展技术综述. arXiv preprint arXiv:2402.02244, 2024.\n[21] Saurav Pawar, SM Tonmoy, SM Zaman, Vinija Jain, Aman Chadha, and Amitava Das. 大语言模型上下文长度扩展技术：内容、原因与方法——详细综述. arXiv preprint arXiv:2401.07872, 2024.\n[22] Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and S Yu Philip. 多模态大语言模型综述. In 2023 IEEE International Conference on Big Data (BigData), pages 2247-2256. IEEE, 2023.\n[23] Shezheng Song, Xiaopeng Li, and Shasha Li. 如何弥合模态间的鸿沟：多模态大语言模型全面综述. arXiv preprint arXiv:2311.07594, 2023.\n[24] Davide Caffagni, Federico Cocchi, Luca Barsellotti, Nicholas Moratelli, Sara Sarto, Lorenzo Baraldi, Marcella Cornia, and Rita Cucchiara. 多模态大语言模型的（演）进化：一项综述. arXiv preprint arXiv:2402.12451, 2024.\n[25] Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. 多模态大语言模型综述. arXiv preprint arXiv:2306.13549, 2023.\n[26] Guangji Bai, Zheng Chai, Chen Ling, Shiyu Wang, Jiaying Lu, Nan Zhang, Tingwei Shi, Ziyang Yu, Mengdan Zhu, Yifei Zhang, et al. 超越效率：资源高效大语言模型系统综述. arXiv preprint arXiv:2401.00625, 2024.\n[27] Zhongwei Wan, Xin Wang, Che Liu, Samiul Alam, Yu Zheng, Zhongnan Qu, Shen Yan, Yi Zhu, Quanlu Zhang, Mosharaf Chowdhury, et al. 高效大语言模型：一项综述. arXiv preprint arXiv:2312.03863, 1, 2023.\n[28] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin, Tianqi Chen, and Zhihao Jia. 迈向高效生成式大语言模型服务：从算法到系统的综述. arXiv preprint arXiv:2312.15234, 2023.\n[29] Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. 预训练语言模型的参数高效微调方法：批判性回顾与评估. arXiv preprint arXiv:2312.12148, 2023.\n[30] Xunyu Zhu, Jian Li, Yong Liu, Can Ma, and Weiping Wang. 大语言模型压缩综述. arXiv preprint arXiv:2308.07633, 2023.\n[31] Canwen Xu and Julian McAuley. 预训练语言模型的压缩与加速综述. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 10566-10575, 2023.\n[32] Wenxiao Wang, Wei Chen, Yicong Luo, Yongliu Long, Zhengkai Lin, Liye Zhang, Binbin Lin, Deng Cai, and Xiaofei He. 大语言模型的压缩与高效推理：一项综述. arXiv preprint arXiv:2402.09748, 2024.\n[33] Seungcheol Park, Jaehyeon Choi, Sojin Lee, and U Kang. 语言模型压缩算法全面综述. arXiv preprint arXiv:2401.15347, 2024.\n[34] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 大语言模型评估综述. ACM Transactions on Intelligent Systems and Technology, 2023.\n[35] Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, Deyi Xiong, et al. 评估大语言模型：一项全面综述. arXiv preprint arXiv:2310.19736, 2023.\n[36] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 在实践中利用大语言模型的力量：ChatGPT 及其他模型综述. arXiv preprint arXiv:2304.13712, 2023.\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n[37] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. Large language models for information retrieval: A survey. arXiv preprint arXiv:2308.07107, 2023.\n[38] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, and Enhong Chen. Large language models for generative information extraction: A survey. arXiv preprint arXiv:2312.17617, 2023.\n[39] Angela Fan, Belize Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, and Jie M Zhang. Large language models for software engineering: Survey and open problems. arXiv preprint arXiv:2310.03533, 2023.\n[40] Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, and Qing Wang. Software testing with large language models: Survey, landscape, and vision. IEEE Transactions on Software Engineering, 2024.\n[41] Zibin Zheng, Kaiwen Ning, Yanlin Wang, Jingwen Zhang, Dewu Zheng, Mingxi Ye, and Jiachi Chen. A survey of large language models for code: Evolution, benchmarking, and future trends. arXiv preprint arXiv:2311.10372, 2023.\n[42] Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, and Philip S Yu. Large language models for robotics: A survey. arXiv preprint arXiv:2311.07226, 2023.\n[43] Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zichong Yang, Kuei-Da Liao, et al. A survey on multimodal large language models for autonomous driving. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 958-979, 2024.\n[44] Zhenjie Yang, Xiaosong Jia, Hongyang Li, and Junchi Yan. A survey of large language models for autonomous driving. arXiv preprint arXiv:2311.01043, 2023.\n[45] Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, and Erik Cambria. A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics. arXiv preprint arXiv:2310.05694, 2023.\n[46] Hongjian Zhou, Boyang Gu, Xinyu Zou, Yiru Li, Sam S Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Xian Wu, et al. A survey of large language models in medicine: Progress, application, and challenge. arXiv preprint arXiv:2311.05112, 2023.\n[47] Benyou Wang, Qianqian Xie, Jiahuan Pei, Zhihong Chen, Prayag Tiwari, Zhao Li, and Jie Fu. Pre-trained language models in biomedical domain: A systematic survey. ACM Computing Surveys, 56(3):1-52, 2023.\n[48] Yinheng Li, Shaofei Wang, Han Ding, and Hang Chen. Large language models in finance: A survey. In Proceedings of the Fourth ACM International Conference on AI in Finance, pages 374-382, 2023.\n[49] Tianyu He, Guanghui Fu, Yijing Yu, Fan Wang, Jianqiang Li, Qing Zhao, Changwei Song, Hongzhi Qi, Dan Luo, Huijing Zou, et al. Towards a psychological generalist ai: A survey of current applications of large language models and future prospects. arXiv preprint arXiv:2312.04578, 2023.\n[50] Lei Li, Yongfeng Zhang, Dugang Liu, and Li Chen. Large language models for generative recommendation: A survey and visionary discussions. arXiv preprint arXiv:2309.01157, 2023.\n[51] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. How can recommender systems benefit from large language models: A survey. arXiv preprint arXiv:2306.05817, 2023.\n[52] Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, and Tat-Seng Chua. Generative recommendation: Towards next-generation recommender paradigm. arXiv preprint arXiv:2304.03516, 2023.\n\n## 翻译结果\n[37] Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. 用于信息检索的大语言模型：综述. arXiv preprint arXiv:2308.07107, 2023.\n[38] Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu, Xiangyu Zhao, Xian Wu, Yefeng Zheng, and Enhong Chen. 用于生成式信息抽取的大语言模型：综述. arXiv preprint arXiv:2312.17617, 2023.\n[39] Angela Fan, Belize Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, and Jie M Zhang. 用于软件工程的大语言模型：综述与开放性问题. arXiv preprint arXiv:2310.03533, 2023.\n[40] Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, and Qing Wang. 使用大语言模型进行软件测试：综述、现状与展望. IEEE Transactions on Software Engineering, 2024.\n[41] Zibin Zheng, Kaiwen Ning, Yanlin Wang, Jingwen Zhang, Dewu Zheng, Mingxi Ye, and Jiachi Chen. 面向代码的大语言模型综述：演进、基准测试与未来趋势. arXiv preprint arXiv:2311.10372, 2023.\n[42] Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, and Philip S Yu. 用于机器人学的大语言模型：综述. arXiv preprint arXiv:2311.07226, 2023.\n[43] Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zichong Yang, Kuei-Da Liao, et al. 面向自动驾驶的多模态大语言模型综述. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 958-979, 2024.\n[44] Zhenjie Yang, Xiaosong Jia, Hongyang Li, and Junchi Yan. 面向自动驾驶的大语言模型综述. arXiv preprint arXiv:2311.01043, 2023.\n[45] Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, and Erik Cambria. 用于医疗健康领域的大语言模型综述：从数据、技术、应用，到责任与伦理. arXiv preprint arXiv:2310.05694, 2023.\n[46] Hongjian Zhou, Boyang Gu, Xinyu Zou, Yiru Li, Sam S Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Xian Wu, et al. 医学领域大语言模型综述：进展、应用与挑战. arXiv preprint arXiv:2311.05112, 2023.\n[47] Benyou Wang, Qianqian Xie, Jiahuan Pei, Zhihong Chen, Prayag Tiwari, Zhao Li, and Jie Fu. 生物医学领域的预训练语言模型：系统性综述. ACM Computing Surveys, 56(3):1-52, 2023.\n[48] Yinheng Li, Shaofei Wang, Han Ding, and Hang Chen. 金融领域的大语言模型：综述. In Proceedings of the Fourth ACM International Conference on AI in Finance, pages 374-382, 2023.\n[49] Tianyu He, Guanghui Fu, Yijing Yu, Fan Wang, Jianqiang Li, Qing Zhao, Changwei Song, Hongzhi Qi, Dan Luo, Huijing Zou, et al. 迈向心理通用人工智能：大语言模型当前应用与未来展望综述. arXiv preprint arXiv:2312.04578, 2023.\n[50] Lei Li, Yongfeng Zhang, Dugang Liu, and Li Chen. 用于生成式推荐的大语言模型：综述与前瞻性讨论. arXiv preprint arXiv:2309.01157, 2023.\n[51] Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al. 推荐系统如何受益于大语言模型：综述. arXiv preprint arXiv:2306.05817, 2023.\n[52] Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, and Tat-Seng Chua. 生成式推荐：迈向下一代推荐范式. arXiv preprint arXiv:2304.03516, 2023.\n\n## 翻译结果\n\n[53] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, 等. 人工智能海洋中的塞壬之歌：大型语言模型幻觉问题综述. arXiv 预印本 arXiv:2309.01219, 2023.\n[54] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, 等. 大型语言模型幻觉问题综述：原理、分类、挑战与开放性问题. arXiv 预印本 arXiv:2311.05232, 2023.\n[55] Vipula Rawte, Amit Sheth, and Amitava Das. 大型基础模型幻觉问题综述. arXiv 预印本 arXiv:2309.05922, 2023.\n[56] Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, and Weiqiang Jia. 认知幻象：大型语言模型幻觉问题回顾. arXiv 预印本 arXiv:2309.06794, 2023.\n[57] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 自然语言生成中的幻觉问题综述. ACM Computing Surveys, 55(12):1-38, 2023.\n[58] SM Tonmoy, SM Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, and Amitava Das. 大型语言模型幻觉缓解技术全面综述. arXiv 预印本 arXiv:2401.01313, 2024.\n[59] Xuhui Jiang, Yuxing Tian, Fengrui Hua, Chengjin Xu, Yuanzhuo Wang, and Jian Guo. 从创造力视角看大型语言模型幻觉问题综述. arXiv 预印本 arXiv:2402.06647, 2024.\n[60] Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen K Ahmed. 大型语言模型中的偏见与公平性：一项综述. arXiv 预印本 arXiv:2309.00770, 2023.\n[61] Hadas Kotek, Rikker Dockum, and David Sun. 大型语言模型中的性别偏见与刻板印象. 见：Proceedings of The ACM Collective Intelligence Conference, 页 12-24, 2023.\n[62] Yingji Li, Mengnan Du, Rui Song, Xin Wang, and Ying Wang. 大型语言模型公平性研究综述. arXiv 预印本 arXiv:2308.10149, 2023.\n[63] Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and Mengnan Du. 大型语言模型可解释性研究综述. ACM Transactions on Intelligent Systems and Technology, 2023.\n[64] Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Eric Sun, and Yue Zhang. 大型语言模型安全与隐私综述：优势、劣势与隐患. arXiv 预印本 arXiv:2312.02003, 1, 2023.\n[65] Erfan Shayegani, Md Abdullah Al Mamun, Yu Fu, Pedram Zaree, Yue Dong, and Nael Abu-Ghazaleh. 对抗性攻击揭示的大型语言模型漏洞综述. arXiv 预印本 arXiv:2310.10844, 2023.\n[66] Seth Neel and Peter Chang. 大型语言模型中的隐私问题：一项综述. arXiv 预印本 arXiv:2312.06717, 2023.\n[67] Victoria Smith, Ali Shahin Shamsabadi, Carolyn Ashurst, and Adrian Weller. 识别与缓解语言模型隐私风险：一项综述. arXiv 预印本 arXiv:2310.01424, 2023.\n[68] Zhichen Dong, Zhanhui Zhou, Chao Yang, Jing Shao, and Yu Qiao. 大型语言模型对话安全性的攻击、防御与评估：一项综述. arXiv 预印本 arXiv:2402.09283, 2024.\n[69] Badhan Chandra Das, M Hadi Amini, and Yanzhao Wu. 大型语言模型的安全与隐私挑战：一项综述. arXiv 预印本 arXiv:2402.00888, 2024.\n[70] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, 等. 大型语言模型综述. arXiv 预印本 arXiv:2303.18223, 2023.\n\n## 翻译结果\n\n[71] Muhammad Usman Hadi, Rizwan Qureshi, Abbas Shah, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili, 等. 关于大语言模型的综述：应用、挑战、局限性与实际使用. Authorea 预印本, 2023.\n[72] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, 与 Dan Roth. 基于大规模预训练语言模型的自然语言处理最新进展：一项综述. ACM 计算概览, 56(2): 1-40, 2023.\n[73] Grégoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, 等. 增强语言模型：一项综述. arXiv 预印本 arXiv:2302.07842, 2023.\n[74] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, 与 Enhong Chen. 理解大语言模型智能体的规划：一项综述. arXiv 预印本 arXiv:2402.02716, 2024.\n[75] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V Chawla, Olaf Wiest, 与 Xiangliang Zhang. 基于大语言模型的多智能体：进展与挑战综述. arXiv 预印本 arXiv:2402.01680, 2024.\n[76] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, 等. 个性化大语言模型智能体：关于能力、效率与安全性的见解与综述. arXiv 预印本 arXiv:2401.05459, 2024.\n[77] Pengyu Zhao, Zijian Jin, 与 Ning Cheng. 基于大语言模型的人工智能智能体深度综述. arXiv 预印本 arXiv:2309.14365, 2023.\n[78] Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, 等. 探索基于大语言模型的智能体：定义、方法与展望. arXiv 预印本 arXiv:2401.03428, 2024.\n[79] Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong, Jae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Yejin Choi, 等. 智能体人工智能：多模态交互的视野展望. arXiv 预印本 arXiv:2401.03568, 2024.\n[80] Yingqiang Ge, Yujie Ren, Wenyue Hua, Shuyuan Xu, Juntao Tan, 与 Yongfeng Zhang. LIm as OS (LLMAO), Agents as Apps: 展望 AIOS、智能体与 AIOS-智能体生态系统. arXiv 预印本 arXiv:2312.03815, 2023.\n[81] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, 等. Delta 调优：预训练语言模型参数高效方法的综合研究. arXiv 预印本 arXiv:2203.06904, 2022.\n[82] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, 与 Gao Huang. Expel: 大语言模型智能体是经验学习者. arXiv 预印本 arXiv:2308.10144, 2023.\n[83] Joon Sung Park, Joseph O'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, 与 Michael S Bernstein. 生成式智能体：人类行为的交互式拟像. 见：第 36 届 ACM 用户界面软件与技术研讨会论文集，第 1-22 页，2023.\n[84] Robert L Solso 与 Jerome Kagan. 认知心理学. Houghton Mifflin Harcourt P, 1979.\n[85] Fergus IM Craik 与 Robert S Lockhart. 加工水平：记忆研究的框架. 言语学习与言语行为杂志, 11(6):671-684, 1972.\n[86] Selma Leydesdorff. 记忆文化：记忆、主体性与认同. Routledge, 2017.\n[87] Philip Nicholas Johnson-Laird. 心理模型：走向语言、推理与意识的认知科学. 第 6 号. 哈佛大学出版社, 1983.\n\n## 翻译要求\n1.  **保持格式**: 保留所有 Markdown 格式（标题、列表、代码块、表格等）\n2.  **术语准确**: 专业术语翻译准确，必要时保留英文原词\n3.  **学术风格**: 使用学术论文的正式语体\n4.  **公式保留**: LaTeX 公式保持原样，不翻译\n5.  **引用保留**: 参考文献引用格式保持原样\n\n## 原文内容\n[88] John E Laird. The Soar cognitive architecture. MIT press, 2019.\n[89] Ron Sun. Duality of the mind: A bottom-up approach toward cognition. Psychology Press, 2001.\n[90] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.\n[91] Longtao Zheng, Rundong Wang, Xinrun Wang, and Bo An. Synapse: Trajectory-as-exemplar prompting with memory for computer control. In NeurIPS 2023 Foundation Models for Decision Making Workshop, 2023.\n[92] Ali Montazeralghaem, Hamed Zamani, and James Allan. A reinforcement learning framework for relevance feedback. In Proceedings of the 43rd international acm SIGIR conference on research and development in information retrieval, pages 59–68, 2020.\n[93] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, et al. Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory. arXiv preprint arXiv:2305.17144, 2023.\n[94] Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, and Yunsheng Wu. Memochat: Tuning llms to use memos for consistent long-range open-domain conversation. arXiv preprint arXiv:2308.08239, 2023.\n[95] Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Jun Xu, Zhicheng Dou, Jun Wang, and Ji-Rong Wen. When large language model based agent meets user behavior analysis: A novel user simulation paradigm, 2023.\n[96] Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. Chatdb: Augmenting llms with databases as their symbolic memory. arXiv preprint arXiv:2306.03901, 2023.\n[97] Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, and Guannan Zhang. Think-in-memory: Recalling and post-thinking enable llms with long-term memory. arXiv preprint arXiv:2311.08719, 2023.\n[98] Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu Lu, Zejun Ma, and Zhoujun Li. Unleashing infinite-length input capacity for large-scale language models with self-controlled memory system. arXiv preprint arXiv:2304.13343, 2023.\n[99] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023.\n[100] Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah Wooders, and Joseph E Gonzalez. Memgpt: Towards llms as operating systems. arXiv preprint arXiv:2310.08560, 2023.\n[101] Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, and Kangwook Lee. Prompted llms as chatbot modules for long open-domain conversation. arXiv preprint arXiv:2305.04533, 2023.\n[102] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. Recmind: Large language model powered agent for recommendation. arXiv preprint arXiv:2308.14296, 2023.\n[103] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et al. Retroformer: Retrospective large language agents with policy gradient optimization. arXiv preprint arXiv:2308.02151, 2023.\n[104] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.\n\n## 翻译结果\n[88] John E Laird. Soar认知架构. MIT press, 2019.\n[89] Ron Sun. 心智的二重性：一种自底向上的认知研究途径. Psychology Press, 2001.\n[90] Richard S Sutton 与 Andrew G Barto. 强化学习导论. MIT press, 2018.\n[91] Longtao Zheng, Rundong Wang, Xinrun Wang, 与 Bo An. Synapse：基于轨迹范例提示与记忆的计算机控制方法. 发表于 NeurIPS 2023 决策制定基础模型研讨会, 2023.\n[92] Ali Montazeralghaem, Hamed Zamani, 与 James Allan. 一种用于相关性反馈的强化学习框架. 发表于 第43届国际ACM SIGIR信息检索研究与发展会议论文集, 第59–68页, 2020.\n[93] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, 等. Ghost in the minecraft：通过具备文本知识与记忆的大语言模型实现开放世界环境中的通用智能体. arXiv 预印本 arXiv:2305.17144, 2023.\n[94] Junru Lu, Siyu An, Mingbao Lin, Gabriele Pergola, Yulan He, Di Yin, Xing Sun, 与 Yunsheng Wu. Memochat：微调大语言模型以使用备忘录进行一致的长程开放域对话. arXiv 预印本 arXiv:2308.08239, 2023.\n[95] Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen, Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, Jun Xu, Zhicheng Dou, Jun Wang, 与 Ji-Rong Wen. 当基于大语言模型的智能体遇见用户行为分析：一种新颖的用户模拟范式, 2023.\n[96] Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, 与 Hang Zhao. Chatdb：使用数据库作为符号记忆来增强大语言模型. arXiv 预印本 arXiv:2306.03901, 2023.\n[97] Lei Liu, Xiaoyan Yang, Yue Shen, Binbin Hu, Zhiqiang Zhang, Jinjie Gu, 与 Guannan Zhang. Think-in-memory：回忆与事后思考赋能大语言模型的长时记忆. arXiv 预印本 arXiv:2311.08719, 2023.\n[98] Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu Lu, Zejun Ma, 与 Zhoujun Li. 通过自控记忆系统释放大规模语言模型的无限长度输入能力. arXiv 预印本 arXiv:2304.13343, 2023.\n[99] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, 与 Anima Anandkumar. Voyager：一个基于大语言模型的开放式具身智能体. arXiv 预印本 arXiv:2305.16291, 2023.\n[100] Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah Wooders, 与 Joseph E Gonzalez. Memgpt：迈向将大语言模型作为操作系统. arXiv 预印本 arXiv:2310.08560, 2023.\n[101] Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, 与 Kangwook Lee. 提示化大语言模型作为长程开放域对话的聊天机器人模块. arXiv 预印本 arXiv:2305.04533, 2023.\n[102] Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, 与 Yingzhen Yang. Recmind：大语言模型驱动的推荐智能体. arXiv 预印本 arXiv:2308.14296, 2023.\n[103] Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, 等. Retroformer：基于策略梯度优化的回顾式大语言智能体. arXiv 预印本 arXiv:2308.02151, 2023.\n[104] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, 与 Yuan Cao. React：在语言模型中协同推理与行动. arXiv 预印本 arXiv:2210.03629, 2022.\n\n[105] Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu. Character-LLM: 一个用于角色扮演的可训练智能体。arXiv 预印本 arXiv:2310.10158, 2023.\n[106] Jihoon Tack, Jaehyung Kim, Eric Mitchell, Jinwoo Shin, Yee Whye Teh, and Jonathan Richard Schwarz. 利用摊销上下文记忆进行语言模型的在线适应。arXiv 预印本 arXiv:2403.04317, 2024.\n[107] Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting Liu. 华佗：利用中文医学知识微调 LLaMA 模型。arXiv 预印本 arXiv:2304.06975, 2023.\n[108] Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, and Xing Xie. 推荐 AI 智能体：集成大语言模型实现交互式推荐。arXiv 预印本 arXiv:2308.16505, 2023.\n[109] Yuan Li, Yixuan Zhang, and Lichao Sun. MetaAgents：通过协作生成式智能体模拟人类行为交互以实现基于大语言模型的任务导向协同。arXiv 预印本 arXiv:2310.06500, 2023.\n[110] Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao. TPTU：基于大语言模型的 AI 智能体的任务规划与工具使用。arXiv 预印本 arXiv:2308.03427, 2023.\n[111] Yilun Kong, Jingqing Ruan, Yihong Chen, Bin Zhang, Tianpeng Bao, Shiwei Shi, Guoqing Du, Xiaoru Hu, Hangyu Mao, Ziyue Li, et al. TPTU-V2：在现实世界系统中增强基于大语言模型的智能体的任务规划与工具使用能力。arXiv 预印本 arXiv:2311.11315, 2023.\n[112] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, et al. MetaGPT：面向多智能体协作框架的元编程。arXiv 预印本 arXiv:2308.00352, 2023.\n[113] Yi Yang, Yixuan Tang, and Kar Yan Tam. InvestLM：一个通过金融领域指令微调用于投资的大语言模型。arXiv 预印本 arXiv:2309.13064, 2023.\n[114] Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, and Zhi Jin. CodeAgent：通过集成工具的智能体系统增强代码生成以应对现实世界的仓库级编码挑战。arXiv 预印本 arXiv:2401.07339, 2024.\n[115] Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. ChatDoctor：一个在 LLaMA 模型上使用医学领域知识微调的医疗对话模型。arXiv 预印本 arXiv:2303.14070, 2023.\n[116] Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica, Xuezhe Ma, and Hao Zhang. 开源大语言模型的上下文长度究竟能承诺多长？收录于 NeurIPS 2023 指令微调与指令遵循研讨会，2023.\n[117] Ziheng Huang, Sebastian Gutierrez, Hemanth Kamana, and Stephen MacNeil. Memory Sandbox：对话智能体的透明交互式内存管理。收录于第 36 届 ACM 用户界面软件与技术年度研讨会附属会议论文集，第 1-3 页，2023.\n[118] Arka Pal, Deep Karkhanis, Manley Roberts, Samuel Dooley, Arvind Sundararajan, and Siddartha Naidu. Giraffe：扩展大语言模型上下文长度的探索。arXiv 预印本 arXiv:2308.10882, 2023.\n[119] Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, and Piotr Miłos. Focused Transformer：面向上下文扩展的对比训练，2023.\n[120] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 迷失在中部：语言模型如何使用长上下文。arXiv 预印本 arXiv:2307.03172, 2023.\n[121] Peter J Denning. 局部性原理。ACM 通讯，48(7):19-24, 2005.\n\n## 参考文献\n\n[122] Hermann Ebbinghaus. *记忆：对实验心理学的贡献*，HA Ruger & CE Bussenius 译. 师范学院出版社，1885年。\n[123] Jaap MJ Murre 和 Joeri Dros. 艾宾浩斯遗忘曲线的复现与分析. *《公共科学图书馆：综合》*, 10(7):e0120644, 2015年。\n[124] Jeff Johnson, Matthijs Douze, 和 Hervé Jégou. 使用GPU进行十亿级相似性搜索. *IEEE大数据汇刊*, 7(3):535-547, 2019年。\n[125] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom. Toolformer：语言模型可以自学使用工具. arXiv预印本 arXiv:2302.04761, 2023年。\n[126] 秦禹嘉, 梁世豪, 叶奕宁, 朱坤伦, 严澜, 卢亚西, 林衍凯, 丛鑫, 唐相儒, 钱比尔, 等. ToolLLM：助力大语言模型掌握16000+真实世界API. arXiv预印本 arXiv:2307.16789, 2023年。\n[127] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, 等. LLaMA：开放且高效的基础语言模型. arXiv预印本 arXiv:2302.13971, 2023年。\n[128] 苟志斌, 邵志宏, 宫业龚, 杨玉基, 黄民烈, 段楠, 陈伟柱, 等. Tora：一个用于数学问题求解的工具集成推理智能体. arXiv预印本 arXiv:2309.17452, 2023年。\n[129] 熊宏林, 王晟, 朱艺涛, 赵子豪, 刘宇骁, 王骞, 沈定刚. DoctorGLM：微调您的中文医生模型并非难事. arXiv预印本 arXiv:2304.01097, 2023年。\n[130] 曾傲寒, 刘潇, 杜政晓, 王子寒, 来瀚宇, 丁铭, 杨卓毅, 徐一帆, 郑文迪, 夏骁, 等. GLM-130B：一个开放的双语预训练模型. arXiv预印本 arXiv:2210.02414, 2022年。\n[131] Edward J Hu, 沈业龙, Phillip Wallis, Zeyuan Allen-Zhu, 李玉志, 王深, 王璐, 和陈伟柱. LoRA：大语言模型的低秩自适应. arXiv预印本 arXiv:2106.09685, 2021年。\n[132] 刘正亮, 钟翱霄, 李一玮, 杨龙涛, 鞠超, 吴子豪, 马冲, 舒鹏, 陈成, Sekeun Kim, 等. Radiology-GPT：一个用于放射学的大语言模型. arXiv预印本 arXiv:2306.08666, 2023年。\n[133] Nicola De Cao, Wilker Aziz, 和 Ivan Titov. 编辑语言模型中的事实性知识. arXiv预印本 arXiv:2104.08164, 2021年。\n[134] Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, 和 Christopher D Manning. 大规模快速模型编辑. arXiv预印本 arXiv:2110.11309, 2021年。\n[135] 毛圣宇, 张宁豫, 汪晓晗, 王梦如, 姚云志, 蒋勇, 谢澎军, 黄斐, 和陈华钧. 编辑大语言模型的人格. 2023年。\n[136] 马俊宇, 顾佳辰, 张宁豫, 和凌震华. 大语言模型知识编辑的邻域扰动. arXiv预印本 arXiv:2401.17623, 2024年。\n[137] 王梦如, 张宁豫, 徐子雯, 席泽坤, 邓淑敏, 姚云志, 张启深, 杨林易, 王晋东, 和陈华钧. 通过知识编辑对大语言模型进行去毒化. arXiv预印本 arXiv:2403.14472, 2024年。\n[138] Uri Shaham, Maor Ivgi, Avia Efrat, Jonathan Berant, 和 Omer Levy. ZeroSCROLLS：一个用于长文本理解的零样本基准. arXiv预印本 arXiv:2305.14196, 2023年。\n[139] 白雨石, 吕欣, 张佳洁, 吕洪昌, 唐建凯, 黄志点, 杜政晓, 刘潇, 曾傲寒, 侯磊, 等. LongBench：一个用于长上下文理解的双语多任务基准. arXiv预印本 arXiv:2308.14508, 2023年。\n\n## 参考文献\n\n[140] Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica, Xuezhe Ma, and Hao Zhang. 开源大语言模型的上下文长度究竟能承诺多长？. 收录于 NeurIPS 2023 指令微调与指令遵循研讨会，2023.\n[141] Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. Alfworld: 对齐文本与具身环境以进行交互式学习. arXiv 预印本 arXiv:2010.03768, 2020.\n[142] YunDa Tsai, Mingjie Liu, and Haoxing Ren. Rtlfixer: 使用大语言模型自动修复 RTL 语法错误. arXiv 预印本 arXiv:2311.16543, 2023.\n[143] Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi Mi, Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, 等. Chatharuhi: 通过大语言模型在现实中复活动漫角色. arXiv 预印本 arXiv:2308.09597, 2023.\n[144] Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, and Haoyang Zhang. Gamegpt: 用于游戏开发的多智能体协作框架. arXiv 预印本 arXiv:2310.08067, 2023.\n[145] Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, 等. Rolellm: 大语言模型角色扮演能力的基准测试、激发与增强. arXiv 预印本 arXiv:2310.00746, 2023.\n[146] Runcong Zhao, Wenjia Zhang, Jiazheng Li, Lixing Zhu, Yanran Li, Yulan He, and Lin Gui. Narrativeplay: 交互式叙事理解. arXiv 预印本 arXiv:2310.01459, 2023.\n[147] Jinfeng Zhou, Zhuang Chen, Dazhen Wan, Bosi Wen, Yi Song, Jifan Yu, Yongkang Huang, Libiao Peng, Jiaming Yang, Xiyao Xiao, 等. Characterglm: 使用大语言模型定制中文对话 AI 角色. arXiv 预印本 arXiv:2311.16832, 2023.\n[148] Zhao Kaiya, Michelangelo Naim, Jovana Kondic, Manuel Cortes, Jiaxin Ge, Shuying Luo, Guangyu Robert Yang, and Andrew Ahn. Lyfe agents: 用于低成本实时社交交互的生成式智能体. arXiv 预印本 arXiv:2310.02172, 2023.\n[149] Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian McAuley, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. Agentcf: 基于自主语言智能体协同学习的推荐系统. arXiv 预印本 arXiv:2310.09233, 2023.\n[150] Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei, Jianchao Ji, Yingqiang Ge, Libby Hemphill, and Yongfeng Zhang. War and peace (waragent): 基于大语言模型的世界大战多智能体模拟. arXiv 预印本 arXiv:2311.17227, 2023.\n[151] Haochun Wang, Sendong Zhao, Zewen Qiang, Zijian Li, Nuwa Xi, Yanrui Du, MuZhen Cai, Haoqiang Guo, Yuhan Chen, Haoming Xu, 等. 基于结构化医学知识库对大语言模型进行知识调优以生成可靠的中文响应. arXiv 预印本 arXiv:2309.04175, 2023.\n[152] Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Jieyu Zhang, Hang Wu, Yuanda Zhu, Joyce Ho, Carl Yang, and May D Wang. Ehragent: 代码赋能大语言模型对电子健康记录进行复杂表格推理. arXiv 预印本 arXiv:2401.07128, 2024.\n[153] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, and Chi Wang. Autogen: 通过多智能体对话框架实现下一代大语言模型应用. arXiv 预印本 arXiv:2308.08155, 2023.\n[154] Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and Khaldoun Khashanah. Tradinggpt: 具有分层记忆和鲜明特征的多智能体系统以提升金融交易性能. arXiv 预印本 arXiv:2309.03736, 2023.\n[155] Saizhuo Wang, Hang Yuan, Lionel M Ni, and Jian Guo. Quantagent: 通过自改进大语言模型在交易中寻求圣杯. arXiv 预印本 arXiv:2402.03755, 2024.\n\n## 翻译结果\n\n[156] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong Liu, Jordan W Suchow, and Khaldoun Khashanah. FinMem：一种具有分层记忆与角色设计的性能增强型大语言模型交易代理。arXiv e-prints, pages arXiv-2311, 2023.\n[157] Kelvin JL Koa, Yunshan Ma, Ritchie Ng, and Tat-Seng Chua. 学习使用自反思大语言模型生成可解释的股票预测。arXiv preprint arXiv:2402.03659, 2024.\n[158] Kexin Chen, Junyou Li, Kunyi Wang, Yuyang Du, Jiahui Yu, Jiamin Lu, Lanqing Li, Jiezhong Qiu, Jianzhang Pan, Yi Huang, Qun Fang, Pheng Ann Heng, and Guangyong Chen. Chemist-X：大语言模型赋能的化学合成反应条件推荐代理，2024.\n[159] Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zilong Zheng, Yaodong Yang, et al. Jarvis-1：具有记忆增强多模态大语言模型的开放世界多任务代理。arXiv preprint arXiv:2311.05997, 2023.\n[160] Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Hongshen Xu, Zichen Zhu, Su Zhu, Shuai Fan, Guodong Shen, et al. ChemDFM：面向化学的对话基础模型。arXiv preprint arXiv:2401.14818, 2024.\n[161] Ming Yan, Ruihao Li, Hao Zhang, Hao Wang, Zhilan Yang, and Ji Yan. LARP：面向开放世界游戏的语言代理角色扮演。arXiv preprint arXiv:2312.17653, 2023.\n[162] Zi-Yi Chen, Fan-Kai Xie, Meng Wan, Yang Yuan, Miao Liu, Zong-Guo Wang, Sheng Meng, and Yan-Gang Wang. MatChat：面向材料科学的大语言模型与应用服务平台。Chinese Physics B, 32(11):118104, 2023.\n[163] Nian Li, Chen Gao, Yong Li, and Qingmin Liao. 大语言模型赋能的宏观经济活动模拟代理。arXiv preprint arXiv:2310.10436, 2023.\n[164] Haojie Pan, Zepeng Zhai, Hao Yuan, Yaojia Lv, Ruiji Fu, Ming Liu, Zhongyuan Wang, and Bing Qin. KwaiAgents：基于大语言模型的通用信息检索代理系统。arXiv preprint arXiv:2312.04889, 2023.\n[165] Odma Byambasuren, Yunfei Yang, Zhifang Sui, Damai Dai, Baobao Chang, Sujian Li, and Hongying Zan. 中文医学知识图谱构建初探。Journal of Chinese Information Processing, 33(10):1-9, 2019.\n[166] Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Lunting Fan, Lingfei Wu, and Qingsong Wen. RCAgent：基于工具增强大语言模型的自主代理进行云根因分析。arXiv preprint arXiv:2310.16340, 2023.\n[167] Zhangcheng Qiang, Weiqing Wang, and Kerry Taylor. Agent-OM：利用大语言模型进行本体匹配。arXiv preprint arXiv:2312.00326, 2023.\n[168] Licheng Wen, Daocheng Fu, Xin Li, Xinyu Cai, Tao Ma, Pinlong Cai, Min Dou, Botian Shi, Liang He, and Yu Qiao. DiLu：一种基于大语言模型的知识驱动自动驾驶方法。arXiv preprint arXiv:2309.16292, 2023.\n[169] Zhitao Wang, Wei Wang, Zirao Li, Long Wang, Can Yi, Xinjie Xu, Luyang Cao, Hanjing Su, Shouzhi Chen, and Jun Zhou. XUAT-Copilot：基于大语言模型的多代理协作自动化用户验收测试系统。arXiv preprint arXiv:2401.02705, 2024.\n[170] Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and Chuchu Fan. 基于大语言模型的可扩展多机器人协作：集中式还是分布式系统？arXiv preprint arXiv:2309.15943, 2023.\n[171] Zhao Mandi, Shreeya Jain, and Shuran Song. ROCO：基于大语言模型的辩证多机器人协作。arXiv preprint arXiv:2307.04738, 2023.\n[172] Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu. 从文本到策略：评估大语言模型玩《阿瓦隆》游戏。arXiv preprint arXiv:2310.05036, 2023.\n\n[173] Bing Liu. 终身机器学习：一种持续学习的范式。Frontiers of Computer Science, 11:359-361, 2017.  \n[174] Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. 使用大语言模型模拟多人类并复现人类主体研究。In International Conference on Machine Learning, pages 337-371. PMLR, 2023.",
    "is_translated": true,
    "analysis": {
      "status": "completed",
      "started_at": "2025-12-21T13:03:51.798412",
      "completed_at": "2025-12-21T13:05:36.366748",
      "summary": "## 1. 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | LLM-based agents 的记忆机制研究零散，缺乏系统性的分类、比较和设计模式总结，难以指导未来研究 [cite] |\n| **核心方案** | 提出首个关于 LLM-based agents 记忆机制的系统性综述，涵盖定义、必要性、设计、评估和应用 [cite] |\n| **关键概念** | 记忆被定义为代理在环境交互中积累和使用的信息，分为狭义（历史交互记录）和广义（包括外部知识等） [cite] |\n| **核心数据** | 创建并维护开源仓库 https://github.com/nuster1128/LLM_Agent_Memory_Survey 以跟踪领域最新进展 [cite] |\n| **主要结论** | 记忆模块是 LLM-based agents 实现自我演进和解决复杂现实问题的关键，未来需关注参数化记忆、多智能体记忆等方向 [cite] |\n\n## 2. 💡 费曼深度解读 (The Feynman Explanation)\n\n想象一下，你要教一个完全不懂AI的建筑师理解这篇论文的核心——**“LLM-based Agent 的记忆”**。\n\n**原来的LLM（比如ChatGPT）就像一个记忆力极差的临时工。** 你让他帮你规划一次旅行，他每次只能根据你当前的一句话来回答。如果你说“我想去北京”，他可能会推荐故宫；但如果你十分钟后再说“但我只有半天时间”，他已经完全忘了你之前说要去北京这件事了。他就像一个没有笔记本的助手，每次对话都是全新的开始。\n\n**而这篇论文讨论的“LLM-based Agent”，则像是一个配备了超级工作日志的专业项目经理。** 这个“记忆”就是他的工作日志。这篇综述的核心工作，就是系统地梳理了市面上各种“工作日志”的写法、用法和效果。\n\n*   **记忆的来源（Memory Sources）**：就像项目经理的日志里可以记什么？可以记本次项目会议的内容（Inside-trial），也可以翻看之前类似项目的记录吸取经验（Cross-trial），甚至可以去查阅行业标准手册（External Knowledge）。\n*   **记忆的形式（Memory Forms）**：日志可以怎么写？可以像传统一样用文字一条条记下来（Textual Form），方便查阅和解释；也可以像高手一样，把经验教训内化成自己的工作直觉和条件反射（Parametric Form），遇到类似情况直接反应。\n*   **记忆的操作（Memory Operations）**：怎么用这个日志？包括什么时候记一笔（Writing），如何整理和删除过时信息（Management），以及如何在需要时快速找到关键信息（Reading）。\n\n**所以，这篇论文的“创新点”不在于发明了一种新的记忆方法，而在于它像一个专业的“项目管理方法论专家”，把市面上所有零散的“工作日志系统”进行了归纳、比较和评级，总结出了一套通用的设计模式。** 它告诉你，为什么项目经理必须记日志（必要性），日志可以记什么、怎么记、怎么用（设计逻辑），以及如何判断一个日志系统是不是真的好用（评估方法）。\n\n**底层的因果链条是：** 拥有了系统化、结构化的记忆，智能体才能像人一样，从过去的成功和失败中学习，调整策略，从而实现“自我演进”，去处理需要多步交互、信息随时间累积的复杂现实任务。没有记忆，LLM就只是一个聪明的“对话机器”；有了记忆，它才真正开始向“智能代理”迈进。\n\n## 3. ⚔️ 对抗性评审 (The Adversarial Review)\n\n作为苛刻的审稿人#2，我必须指出这篇系统性综述存在的几个潜在弱点：\n\n1.  **分类框架的主观性与时效性风险：** 论文提出的分类框架（如记忆来源、形式、操作）虽然清晰，但其合理性和完备性高度依赖于作者对现有文献的主观归纳。这是一个快速发展的领域，新的记忆机制可能无法被现有框架很好地容纳。例如，将记忆简单二分為“文本”和“参数”形式可能过于粗糙，忽略了中间状态或混合形式。这套分类法可能很快会过时或被证明不够普适 [cite]。\n2.  **缺乏对记忆机制“有效性”的批判性分析：** 综述大量列举了各种记忆设计，但缺乏对这些机制在实际应用中究竟“多大程度上”提升了智能体性能的深度分析。很多被引用的研究可能只是在特定、简化的实验环境中展示了优势，其结论在更复杂、开放的现实场景中是否依然成立存疑。论文未能充分讨论这些记忆方法各自的局限性、计算开销以及可扩展性瓶颈 [cite]。\n3.  **未来方向的展望偏向宏大叙事，缺乏具体路径：** 第8节提出的未来方向（如参数化记忆、终身学习）虽然重要，但流于表面，更像是领域共识的罗列，而非基于本次综述的深刻洞察。未能提出更具挑战性、更具体的“下一步”研究问题，例如，如何定量衡量不同记忆机制对“自我演进”能力的贡献，或者如何设计实验来验证记忆在长期任务中的因果作用 [cite]。\n\n## 4. 📝 一句话总结 (The Takeaway)\n\n如果我只记这篇论文的一个贡献，那应该是：**它首次为LLM智能体领域杂乱无章的记忆机制研究建立了一个系统性的分类、分析和评估框架，为后续研究提供了重要的“地图”和“设计模式”参考。**"
    }
  },
  "9e05a74f-6f2b-49f0-8604-bc71b67d094b": {
    "id": "9e05a74f-6f2b-49f0-8604-bc71b67d094b",
    "filename": "ssrn-4768574.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/9e05a74f-6f2b-49f0-8604-bc71b67d094b_ssrn-4768574.pdf",
    "status": "completed",
    "created_at": "2025-12-21 21:28:19.372634",
    "updated_at": "2025-12-21 13:29:35.367511",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "The cost of auditing service performance information",
    "markdown_content": "Working Paper No. 24-02\n\n# The cost of auditing service performance information\n\nXikai Chen\n\nDepartment of Accounting\n\nDeakin University\n\nMelbourne, Australia\n\nxikai.chen@deakin.edu.au\n\nTom Scott*\n\nDepartment of Accounting\n\nAuckland University of Technology\n\nAuckland, New Zealand\n\nthomas.scott@aut.ac.nz\n\n5 March 2024\n\n# The cost of auditing service performance information\n\n# ABSTRACT\n\nThis paper adds to prior literature by examining the impact on audit effort from requiring the assurance of non-financial information. Specifically, we use a sample of large New Zealand not-for-profits (charities) newly required to report and have assured statements of service performance following accounting and auditing standards. We find an increase in audit fees of  $14.5\\%$ , although there is no change in audit or filing lag. There is no difference based on auditing standard used, audit firm or whether an 'other matter' is expressed in the audit report. Overall, our results suggesting mandating the reporting and assurance of non-financial information should be viewed as having greater costs than adopting International Financial Reporting Standards.\n\nKeywords: Service performance; Not-for-profits; charities; audit fee; non-financial assurance\n\nJEL Classifications: G38, M42, M48\n\n*Corresponding author\n\nDeclaration: The authors have no relevant financial or non-financial conflict of interests to disclose.\n\nAcknowledgments: For comments on previous versions, we thank Michael Bradbury and Arung Mayapada.\n\n# I. INTRODUCTION\n\nThere has been a growing interest in non-financial reporting in the public and not-for-profit sectors (Australian Accounting Standards Board [AASB], 2021; External Reporting Board [XRB], 2017; International Public Sector Accounting Standards Board [IPSASB], 2015, 2022). Service performance reporting is argued to be important in these sectors as it provides contextual information in the form of both quantitative performance indicators and qualitative information that allows users to assess whether the entity has been successful in achieving its mission. Furthermore, if service performance information is disclosed then its assurance may also be mandated to enhance its quality and credibility. However, a longstanding concern with uptake of non-financial assurance is its cost (Farooq and de Villiers, 2017). Although Xu and Yang (2023) provide evidence on the assurance of SSP by smaller NZ charities, they do not document the impact on audit effort. Thus, research examining the cost of service performance reporting and assurance contributes to previous research on SSP and balances prior literature on service performance reporting quality, which although notes benefits also suggests that best practise is not always followed (Connolly and Hyndman, 2013; McConville and Cordery, 2018; Johansson et al., 2022).\n\nWe use the New Zealand (NZ) not-for-profit (charity) sector to provide new insight into the cost of service performance reporting and assurance as the largest not-for-profits in NZ (called Tier 1 entities with total expenses over $30 million) are required to prepare statements of service performance (SSPs) from 1 January 2022. Thus, the NZ not-for-profit setting allows the investigation on whether mandating SSP assurance increases audit fees. Tier 1 not-for-profits must follow Public Benefit Entity International Public Sector Accounting Standards (PBE IPSAS), with the NZ specific standard of PBE FRS 48 Service Performance Reporting applying to SSPs. Furthermore, SSPs are audited as part of financial statement audit with the auditor giving their opinion on the SSPs in the same audit report issued for the financial statements. SSPs may currently be audited under International Standard for Assurance Engagement (ISAE) (NZ) 3000 (Revised) Assurance Engagements Other than Audits or Reviews of Historical Financial Information or NZ Auditing Standard (NZ AS) 1 The Audit of Service Performance Information. We focus on a sample based on all Tier 1 not-for profits to enable the examination of the effect of SSP\n\nreporting and assurance in a setting where they must be prepared following accounting standards and assured under auditing standards.\n\nWe find that there is a large and significant increase in audit fees post-SSPs. In economic terms the increase is equal to  $14.5\\%$  or NZD$15,535 of mean audit fees. Thus, the increase can be viewed as economically larger than the cost of International Financial Reporting Standard (IFRS) adoption which was found to increase audit fees by  $11\\%$  in NZ listed companies (Higgins et al., 2016). We find that  $72\\%$  of observations use NZ AS 1 versus ISAE 3000 when assuring the SSP, with the early adoption of NZ AS 1 resulting in no further increase in audit fees. Thus, we conclude that that the early adopters of this service performance auditing standard did not bear any cost of learning the new standard, in contrast to early adopters of IFRS in NZ (Higgins et al., 2016), but that it also led to no efficiency gains. Furthermore, we find no qualified or emphasis of matter audit reports related to the SPP. We did find that  $62\\%$  of SSP observations expressed an \"other matter\" that the prior year comparative figures were not audited, however the clear disclosure of this also did not result in lower audit fees. In addition, although there is an evidence of a Big 4 fee premium, there is no difference in the post-SSP increase for Big 4 clients. Last, we examine the effects on audit and filing lags, and find no differences post-SSP.\n\nOur results first contribute to the academic literature that documents the effect of accounting standards and regulations on audit pricing. This includes the emerging literature on the cost of non-financial assurance (Lu et al., 2023), responding to calls for further research on the effects of regulating non-financial disclosure and the non-financial reporting practices of PBEs (Farooq and de Villiers, 2017; de Villiers et al., 2022). Our results suggest that the shift to SSP assurance results in a larger increase in audit effort than the adoption of IFRS in NZ. Our audit lag results contrast with Mayapada et al. (2023) who finds moving to more detailed and prescriptive statements of recommended practice increases audit lag. We infer the difference may be driven by a longer period between announcement and the adoption period (almost seven years vs less than one year), reducing the unexpected effort component for auditors.\n\nSecond, we add to the literature on service performance assurance, and Xu and Yang (2022) directly by documenting an increase in audit fees and considering the assurance among larger charities who must follow full accounting and auditing standards. As our study focuses on the largest not-for-profits, they may be more able to have the underlying\n\nreporting systems needed to prepare such information suggesting that the costs may be proportionately higher for smaller not-for-profits (Cordery and Deguchi, 2018). We also document no qualified audit opinions relating to SSPs, allaying concerns that there could be a systemic failure in the ability to prepare and audit SSPs. Thus, we contribute to the burgeoning stream of SSP reporting by empirically measuring the cost of SSP reporting and assurance.\n\nLast, we contribute directly to accounting and auditing standard setters. Our results provide direct evidence to the XRB and to not-for-profit regulators when assessing PBE FRS 48. Our results are likely of interest to other standard-setters for whom service performance reporting for this sector is on the work plan, especially the AASB who plan to use PBE FRS 48 as the primary point of reference and have expressed concerns about the auditability and cost of SSPs. Furthermore, evidence may also be of use to IPASB who are planning to revise their guidance note on service performance reporting and indirectly to the International Accounting and Assurance Standards Board when considering the cost of non-financial assurance.\n\nIn the next section, we discuss the institutional setting, literature review and research questions. This is followed by a discussion of our research method. We then report our results, and the final section provides concluding remarks.\n\n# 2. INSTITUTIONAL SETTING, LITERATURE REVIEW AND RESEARCH QUESTIONS\n\n# Institutional Setting\n\nNot-for-profits (charities) in NZ are governed by the Charities Services (previously Charities Commission), part of Department of Internal Affairs (DIA) and governed by the Charities Act 2005. Promoting public trust and confidence in the charitable sector is the main role of Charities Services, including the registration of charities. Importantly, only donors to registered charities benefit from claiming tax credits and rebates for their charitable donations. To be registered, not-for-profits must file with Charities Services, who maintain and process filings via the Charities Register which is publicly available. Reform to not-for-profits reporting in 2015 created a tier system with different reporting and auditing requirements based on not-for-profits size as shown in Table 1. Large charities use PBE IPSAS, whilst smaller not-for-profits use simple formatting reporting, with the smallest reporting on a cash basis. Tseng et al. (2023) find an increase in accuracy and in donations after the reforms, especially for the smaller not-for-profits.\n\nFurthermore, motivated to better meet user needs about why the entity exists, how the entity intends to achieve its broad objectives, and what the entity has done, charities were also required to prepare a statement of service performance (SSP). SSPs include qualitative and quantitative information (i.e. descriptions of performance and performance indicators) about the entity's supply of goods and services and to communicate the effects an entity has on the community. In preparing SSPs, the qualitative characteristics identified in the PBE conceptual framework must be applied and accounting standards followed. SSPs must be prepared following PBE FRS 48, a new NZ specific standard which replaced PBE IPSAS 1. In contrast to PBE IPSAS 1, PBE FRS 48 does not require service objectives to be expressed in terms of inputs, outputs, outcomes, efficiency or effectiveness. Hsiao et al. (2023) document that in the NZ university sector that early adopters of PBE FRS 48 provide users with more performance indicators about contextual information about why the entity exists, what it intends to achieve and how it goes about this and what the entity has done during the reporting period. Service performance reporting requirements are not novel in NZ, as there has been over a decade of service performance reporting in the public sector including government department, local government, amongst other entries (Scott and Pinny, 2016). Not-for-profit service performance reporting began with the smallest not-\n\nfor-profits from 1 April 2015, with mandatory reporting by the larger charities from 1 January 2022.\n\nSSPs must also be audited. For periods beginning from 1 January 2024 a NZ specific auditing standard, NZ AS 1, is mandatory. Although early adoption is permitted, prior to NZ AS 1 ISAE 3000 was used to audit SSPs. In contrast to ISAE 3000, which applied broadly to non-financial audits, NZ AS 1 is focused solely on the audit of service performance information and was written subsequent to PBE FRS 48. The standard was viewed as resolving audit issues specific to SSP including determining materiality, what is a SSP a misstatement and how outcomes and outputs in SSP relate to assertions (XRB, 2018). Thus, as per Table 1, the largest not-for-profits must prepare a statement of service performance following PBE FRS 48 which must also be audited. Figure 1 in Appendix A provides an extract of a not-for-profit audit report in the SSP period. It highlights that the SSP is audited alongside the financial statements as part of the annual report and must not be reported separately.\n\nTable 1: Reporting requirements  \n\n<table><tr><td></td><td>Tier 1</td><td>Tier 2</td><td>Tier 3</td><td>Tier 4</td></tr><tr><td>Threshold</td><td>&gt; $30 million total expenses or public accountability</td><td>&gt; $2 million and &lt; $30 million total expenses</td><td>&gt; $125 thousand and &lt; $2 million total expenses</td><td>&lt; $125 thousand total operating payments</td></tr><tr><td>Accounting Standard</td><td>PBE IPSAS</td><td>Reduced disclosure regime</td><td>Simple format reporting - accrual</td><td>Simple format reporting - cash</td></tr><tr><td>Service Performance Requirements</td><td>From 1 January 2022</td><td>From 1 January 2022</td><td>From 1 April 2015</td><td>From 1 April 2015</td></tr><tr><td>Assurance Requirements</td><td>Audit</td><td>Audit</td><td>&lt; $500 thousand voluntary, &gt; $1 million audit and between audit or review</td><td>Voluntary</td></tr><tr><td>Assurance standards</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td><td>NZ AS 1 from 1 January 2024 (early adoption permitted) or ISAE (NZ) 3000</td></tr></table>\n\n# Literature Review and Hypothesis Development\n\nThere is large body of prior research that examines the supply and demand of audit effort (e.g., Hay et al., 2006; DeFond and Zhang, 2014; Causholli et al. 2010; Eierle et al. 2022). Changes in accounting or auditing regulations would result in a newer higher equilibrium price if auditing became more complex or risky. IFRS are typically argued to be more 'complex' than the previous standards used. For example, IFRS have a greater use of fair value accounting, and revaluations are associated with higher audit fees (Yao et al., 2015). Bradbury and Scott (2020) emphasis the cost of monitoring measurement and judgement issues are more likely to borne by auditors than regulators. Thus there are higher audit fees after IFRS adoption (Kim et al. 2012; De George et al. 2013), including in NZ (Griffin et al., 2009; Higgins et al. 2016). Likewise, there is an increase in audit fees after the passage of the Sarbanes-Oxley Act (Griffin and Lont, 2007; Hoitash et al., 2008; Ghosh and Pawlewicz, 2009; Huang et al., 2009). Evidence also suggests that moving to a less 'strict' auditing standard reduces audit fees (Doogar et al. 2010; Krishnan et al. 2011), as do accounting standard changes that better align auditors and preparers (Grosse et al., 2023). International evidence typically finds no evidence that the requirement to disclose Key Audit Matters increase audit fees (Eierle et al. 2022), including in New Zealand (Al-mulla and Bradbury, 2022). Research from the UK not-for-profit sector, finds moving to more detailed and prescriptive statements of recommended practice increases audit fee, audit lag and reporting lag (Mayapada et al., 2023).\n\nEvidence from non-financial information also suggests that the provision of new information that is assured increases audit fees. In a review of the literature, Farooq and De Villiers (2017) note that cost can be a major barrier for the voluntary adoption of sustainability assurance. There is a positive association between audit fees and CSR concerns and strengths, suggesting that CSR is a source of uncertainty (Garcia et al., 2021). Lu et al. (2023) finds an increase in audit fees for integrated reporters, driven by those who have less useful financial information. They argue that by better understanding the connectivity between firm risks, integrated reporting assurance can have a spillover in improved efficiency. Thus, the assurance of more complex financial or non-financial information increases audit fees, although this may be partly offset by better understanding the entity. This leads to our first hypothesis, stated as:\n\nIn addition, while it would seem likely the requirement to prepare and have audited a SSP would increase audit fees, the increase in audit fees may be heterogeneous across the not-for-profit sector based on engagement characteristics. First, in the year of SSP adoption auditors could choose to use ISAE 3000 or the newly available NZ AS 1, which is more aligned with the applicable accounting standard PBE FRS 48. Recall, that less strict or aligning accounting and auditing standards reduce audit fees (Doogar et al. 2010; Krishnan et al. 2011; Grosse et al., 2023), thus the use of NZ AS 1 could also minimize the costs of SSP assurance. On the other hand, early adopters of IFRS had higher audit fees in NZ (Higgins et al., 2016), early adopters of NZ AS 1 could bear the learning costs for audit firms. Thus, it is unclear whether the early adoption of NZ AS 1 would moderate or heighten the positive association between audit fees and SSP assurance. Second, Xu and Yang (2023) provide descriptive evidence on the assurance of SSPs for selected smaller NZ not-for-profits and suggest there is a high tolerance for lower quality performance information, and that it may be driven by a compliance mindset. A compliance mindset may suggest that any cost increase is modest and costs could be further minimised through disclosure of a non-clean audit opinion, with Xu and Yang (2023) reporting 16 of the 81 audits in their sample had a modified opinion – although only one was in relation in statement of service performance information. Furthermore, as service performance information for the previous period does not need to be audited, the auditor must include an other matter paragraph in the auditor's report that says the corresponding figures are unaudited (CA ANZ, 2022). Therefore, the presence of an other matter could suggest less audit effort, and thus a smaller increase in audit fees, as the corresponding figures from the previous year are unaudited. Last, there is a large literature showing differential audit pricing by the Big 4 (Simunic, 1980), including in the not-for-profit space (Vermeer et al., 2009; Yang and Simnett, 2022). Big 4 audit firms may be better able to resource a change in workload or have a differential cost structure with more fixed costs allowing them to absorb the extra work (Higgins et al., 2016). Thus, the increase in audit fees for SSP assurance may differ based on who the auditor is. We state these jointly as our second hypothesis as follows:\n\nH2: The positively association between audit fees and statement of service performance assurance is impacted by use of auditing standard, audit report and auditor\n\n# 3. RESEARCH METHOD\n\n# Sample\n\nOur sample is based on all Tier 1 not-for-profits (charities) in NZ. As our focus is on the initial adoption of service performance reporting by not-for-profits we exclude 11 entities which although also registered not-for-profits which have different reporting obligations mean that they previously reported SPPs by being quasi public-sector organisations such as museums, or university trusts. 17 (21% of the final sample) not-for-profits are excluded through having insufficient audit data – namely not attaching the audit report to their annual report or not clearly disclosing the audit fee. Thus, our first observation is there is not strong compliance with reporting requirements of filing an audited financial statement, including the audit report. This results in a sample of 62 not-for-profits, which as we are interested in a pre- and post-SSP analysis result in 124 entity-year observations. As SSPs were required for financial years beginning 1 January 2022, not-for-profits with a 31 December 2022, 31 March 2023, 30 June 2023 or financial year-end would be the first year of reporting SSP (i.e. the post period). Accordingly, balance dates of 31 December 2021, 31 March 2022 and 30 June 2022 are the pre-SSP period. $^{2}$ . Therefore, our sample is drawn from 2021 to 2023. We use the Charities Register to access annual report and hand collect relevant audit data, whilst control variables are downloaded via the advanced search function of the register.\n\n# Regression Models\n\nOur analysis uses a regression model to estimate audit effort with determinants drawn from prior literature (Vermeer et al., 2009; Yang and Simnett, 2022). Due to our relatively small sample size, we specific following parsimonious regression model (time and firm subscripts omitted for convenience):\n\n$$\nL n A F = \\beta_ {0} + \\beta_ {1} P O S T + \\beta_ {2} L n T A + \\beta_ {5} A R I N V + \\beta_ {7} T L T A + \\beta_ {8} C A S H T A +\n$$\n\n$$\n\\beta_ {8} D o n a t i o n s + \\beta_ {9} C i t y C o s t + \\beta_ {9} L o s s + \\beta_ {9} C l e a n + \\beta_ {1 0} B i g 4 + S e c t o r + \\varepsilon\n$$\n\n(1)\n\nAll variables are formally defined in Table 2.3 First, we specify  $LnAF$  as the dependent variable which measures the natural logarithm of reported audit fees. Next, we specify the dependent variable as  $POST$ , a binary variable equal to one for the period beginning on or after 1 January 2022 (i.e., after the service performance reporting requirements). If  $POST$  is significantly positive, H1 is supported. To test H2, we then rerun the regression model by including one a time variables that measure differences in the audit engagement. Namely, we examine, a binary variable equal to one if NZ AS 1 is used to audit the SSP ( $AS1$ ), a binary variable equal to one if an other matter is expressed that the prior year corresponding figures in the SSP are unaudited ( $SSPOM$ ) and the interaction if the SSP is audited by a Big 4 auditor and  $POST$ ( $POST\\_Big4$ ). If any of these variables are significantly, support for H2 is found. We do not interact  $AS1$  or  $SSPOM$  as they can only equal one in the post-period by design.\n\nIn a meta-analysis of published studies, Hay et al. (2006) find that client size is the most important determinant of audit effort and this is consistent with not-for-profit studies (Vermeer et al., 2009; Yang and Simnett, 2022). Thus, we expect a positive sign on the natural logarithm of total assets (LnTA). Client risk and complexity are associated with higher audit effort (Simunic 1980; Dickins et al. 2008). We expect a negative association between the proportion of total assets that are accounts receivable or inventory (ARINV), but a positive association for the ratio of total liabilities to total assets (TLTA) and the proportion of total assets that is cash or inventory (CASHTA). Donations is the proportion of revenue from donations may suggest a riskier revenue stream (Yang and Simnett, 2022). Entities under greater financial stress, as measured by whether total expenses are larger than total revenue, may also be more risky (Loss). We also control for whether the audit is conducted in a higher cost centre, using a binary variable equal to one if the audit is based out of Auckland (CityCost) (Chan et al. 1993; Grosse et al., 2023) and if there is any modification to the audit report including other matters (Clean). We also control for the effect of any Big4 effect, with a binary variable equal to one if the audit firm is PwC, Ernst\n\n& Young, KPMG or Deloitte (Simunic 1980; Hay et al. 2006).<sup>4</sup> Last, we include not-for-profit sector fixed effects to control differences across not-for-profit organisations (e.g. Education vs Health).\n\nTable 2: Variable definitions  \n\n<table><tr><td>LnAF</td><td>The natural logarithm of reported audit fees</td></tr><tr><td>POST</td><td>A binary variable that takes the value of 1 if the annual report is for the period beginning on or after 1 January 2022, and 0 otherwise</td></tr><tr><td>ASI</td><td>A binary variable that takes the value of 1 if the SSP is assured using NZ AS 1, and 0 otherwise.</td></tr><tr><td>SSPOM</td><td>A binary variable that takes the value of 1 if there was an other matter noting that the comparative figures for the SSP were unaudited, and 0 otherwise.</td></tr><tr><td>LnTA</td><td>The natural logarithm of total assets.</td></tr><tr><td>ARINV</td><td>The ratio of accounts receivables and inventories to total assets.</td></tr><tr><td>TLTA</td><td>The ratio of total liabilities to total assets.</td></tr><tr><td>CASHTA</td><td>The ratio of cash to total assets</td></tr><tr><td>Donation s</td><td>The ratio of donations to total revenue</td></tr><tr><td>CityCost</td><td>A binary variable that takes the value of 1 if the audit was based in Auckland, and 0 otherwise</td></tr><tr><td>Loss</td><td>A binary variable that takes the value of 1 if total expenses are bigger than total revenue</td></tr><tr><td>Clean</td><td>A binary variable that takes the value of 1 if there is no modification or comments on the audit report (including other or emphasis of matter), and 0 otherwise</td></tr><tr><td>Big4</td><td>A binary variable that takes the value of 1 if the auditor is Deloitte, Ernst and Young, KPMG or PwC, and 0 otherwise.</td></tr><tr><td>ALag</td><td>The number of days between when the audit report is signed and the balance date</td></tr><tr><td>FLag</td><td>The number of days between when the annual report is filed with the Charites Register and the balance date</td></tr></table>\n\n# 4. RESULTS\n\nDescriptive Statistics\n\nTable 3 presents our sample statistics. By design our sample is evenly split pre- and post-SSP. In terms of our other variables of interest,  $72\\%$  of post-SSP observations use NZ AS 1 (36% of whole sample). Thus, a majority of not-for-profits are early adopters of the new auditing standard. It is also common (62% of post-SSP observations, 31% of whole\n\nsample) for the audit report to express an other matter paragraph that the prior year SSP figures are unaudited. It could be assumed that in all cases an other matter would be appropriate if they were unaudited as expressed by the local professional accounting body (CA ANZ, 2022). Thus, it is unknown if the remaining sample did not disclose an other matter or carried our more audit work to have the comparative figures audited – including potentially a readiness audit in the previous period. We focus on other matters as there are no cases of any other modification to the audit report in relation to the SSP, either qualified or emphasis of matter. Therefore, consistent with Xu and Yang (2023) who examine smaller NZ charities not following formal accounting standards, we provide descriptive evidence that the assurance of SSPs has not results in an increase cost to preparers in terms of a qualified audit report. Having an unqualified audit report is important to the not-for-profit sector as it can be a condition of grants and donations.\n\nThe mean audit fee of our sample of NZD$107,130. This is substantially larger than the mean of AUD$18,000 reported by Yang and Simnett (2022). This highlights that our sample not-for-profits are substantially larger, as per our focus on entities using IPSAS, and are less likely to have pro bono audits. Consistent with the larger size, is that mean total assets is NZD$240 million compared to $AUD21 million in Yang and Simnett (2022). As the criteria to be a Tier 1 entity is based on NZD$30 million total expenditure, some not-for-profits may have expenditure of that level but less assets if they mainly serve to redistribute funds in the year received. In terms of other variables, we note that 52% of the sample is audited by a Big 4 audit firm. This is less than the 79% of NZ listed companies (Grosse et al., 2023), and is driven by BDO having a relatively large market share of the NZ not-for-profit market. The market is also less concentrated in terms of location, with a CityCost of 52% vs 70% for NZ listed companies (Grosse et al., 2023). The low proportion of ‘clean’ audit opinions is driven by other matters relating to the SSP as discussed above. There are no qualified opinions issued in regard to the financial statements, although there are four emphasis-of-matters paragraphs relating to changing in accounting policy for measure land and buildings, provision for holiday pay remediation and provision for historical abuse. Also included are other matters unrelated to the SSP including six times the auditor changed.<sup>5</sup> Panel B presents our sample broken down into not-for-profit sectors. We use the highest level of sector as self-reported in the Charites Register. We find the\n\nlargest sector is the provision of accommodation services (39%), followed by education and health.\n\nTable 3: Sample statistics  \nPanel A: Descriptive statistics  \n\n<table><tr><td></td><td>Mean</td><td>Median</td><td>SD</td><td>P25</td><td>P75</td></tr><tr><td>AF</td><td>107,139</td><td>66,444</td><td>114,820</td><td>41,516</td><td>122,903</td></tr><tr><td>LnAF</td><td>11.21</td><td>11.10</td><td>0.81</td><td>10.63</td><td>11.72</td></tr><tr><td>POST</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>AS1</td><td>0.36</td><td>0.00</td><td>0.48</td><td>0.00</td><td>1.00</td></tr><tr><td>SSPOM</td><td>0.31</td><td>0.00</td><td>0.46</td><td>0.00</td><td>1.00</td></tr><tr><td>TA (000s)</td><td>240,396</td><td>78,470</td><td>419,621</td><td>28,660</td><td>221,670</td></tr><tr><td>LnTA</td><td>18.29</td><td>18.14</td><td>1.43</td><td>17.15</td><td>19.19</td></tr><tr><td>ARINV</td><td>0.44</td><td>0.00</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>TLTA</td><td>0.34</td><td>0.29</td><td>0.23</td><td>0.15</td><td>0.49</td></tr><tr><td>CASHTA</td><td>0.19</td><td>0.11</td><td>0.21</td><td>0.04</td><td>0.25</td></tr><tr><td>Donations</td><td>0.15</td><td>0.02</td><td>0.28</td><td>0.00</td><td>0.10</td></tr><tr><td>CityCost</td><td>0.52</td><td>1.00</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>Loss</td><td>0.20</td><td>0.00</td><td>0.40</td><td>0.00</td><td>0.00</td></tr><tr><td>Clean</td><td>0.37</td><td>0.00</td><td>0.48</td><td>0.00</td><td>1.00</td></tr><tr><td>Big4</td><td>0.52</td><td>1.00</td><td>0.50</td><td>0.00</td><td>1.00</td></tr><tr><td>ALag</td><td>135</td><td>126</td><td>47</td><td>100</td><td>160</td></tr><tr><td>FLag</td><td>171</td><td>170</td><td>38</td><td>151</td><td>179</td></tr></table>\n\nPanel B: Sector distribution  \n\n<table><tr><td>Sector</td><td>N</td><td>Percentage</td></tr><tr><td>Accommodation</td><td>48</td><td>39</td></tr><tr><td>Arts</td><td>10</td><td>8</td></tr><tr><td>Community</td><td>14</td><td>11</td></tr><tr><td>Education</td><td>28</td><td>23</td></tr><tr><td>Health</td><td>24</td><td>19</td></tr><tr><td>Total</td><td>124</td><td>100</td></tr></table>\n\nTable 3 presents descriptive statistics for sample variables. Variables are as defined in Table 2.\n\n# Audit Fees and SSPs\n\nTable 4 presents the results of audit fee regressions. Our models have an adjusted  $\\mathbf{R}^2$  of  $69\\%$ , just below the lower end of a range that audit fee research normally achieves (Hay, 2013). We first run the regression focusing on the effect of introduction SSP reporting and assurance (POST) after controlling for other factors. Consistent with our first hypothesis, we find significantly higher audit fees post-SSP. Furthermore, the effect is large with an increase in audit fees of  $14.5\\%$ . This compares with an  $11\\%$  increase in audit fees for the first year of IFRS adoption in NZ (Higgins et al., 2016), suggesting that the transition to requiring SSP reporting, and the increase in assurance is greater than the shift to IFRS. This may be due to a greater degree new work involved with auditing a new statement rather than the wholesale change of accounting standards, such as the preparation of new working papers, templates, materiality estimates etc. Our control variables are broadly consistent with prior literature, with higher audit fees for larger (LnTA), riskier not-for-profits (TLTA and Donations), and those audited by a Big 4 audit firm. However, in contrast to Yang and Simnett (2022) we find a negative association for Loss. As we examine larger more stable not-for-profits, those that a small loss may be viewed as less risky by auditors as the purpose of not-for-profits is to distribute funds for their charitable purpose rather than hoard cash.\n\nNext, in columns (2)-(4), we include our variables to test H2, namely AS1, SSPOM and POST_Big4 one at a time. Across all columns we find consistent evidence that POST remains significantly positive, consistent with our main results. However, there is no difference in the fees for those not-for-profits that adopted AS 1, expressed an other matter or used a Big 4 audit firm. We conclude that the early adopters of NZ AS 1 do not bear the learning costs, or that it is offset by greater alignment of auditing standard with the subject matter. The expression of an other matter may not reduce audit fees as it could be assumed by many users that the comparative figure was unaudited, or other matters are not viewed at mitigating audit risk. For Big 4 firms, while we do find that they have higher audit fees, this relationship has not changed post-SSP. Thus the Big 4 do not have a further premium in regard to non-financial assurance. In untabulated tests, our results are robust to including non-audit fees, excluding sector fixed effects, excluding all control variables, or one at a\n\ntime, and including different controls (e.g. return on assets, current ratio, total expense etc). Overall, we find evidence of a market wide increase audit fees that does not vary with auditing standard, audit report issued, or auditor.\n\nTable 4: Audit fees and SSP  \n\n<table><tr><td></td><td>(1) LnAF</td><td>(2) LnAF</td><td>(3) LnAF</td><td>(4) LnAF</td></tr><tr><td>POST</td><td>0.271**</td><td>0.260**</td><td>0.198*</td><td>0.239**</td></tr><tr><td></td><td>(2.50)</td><td>(2.10)</td><td>(1.65)</td><td>(2.05)</td></tr><tr><td>AS1</td><td></td><td>0.016</td><td></td><td></td></tr><tr><td></td><td></td><td>(0.14)</td><td></td><td></td></tr><tr><td>SSPOM</td><td></td><td></td><td>0.307</td><td></td></tr><tr><td></td><td></td><td></td><td>(1.17)</td><td></td></tr><tr><td>POST_Big4</td><td></td><td></td><td></td><td>0.072</td></tr><tr><td></td><td></td><td></td><td></td><td>(0.41)</td></tr><tr><td>LnTA</td><td>0.433***</td><td>0.432***</td><td>0.444***</td><td>0.434***</td></tr><tr><td></td><td>(7.00)</td><td>(6.88)</td><td>(6.98)</td><td>(7.03)</td></tr><tr><td>ARINV</td><td>-0.048</td><td>-0.048</td><td>-0.073</td><td>-0.047</td></tr><tr><td></td><td>(-0.54)</td><td>(-0.54)</td><td>(-0.82)</td><td>(-0.53)</td></tr><tr><td>TLTA</td><td>0.625**</td><td>0.624**</td><td>0.652**</td><td>0.627**</td></tr><tr><td></td><td>(2.22)</td><td>(2.19)</td><td>(2.22)</td><td>(2.22)</td></tr><tr><td>CASHTA</td><td>0.418</td><td>0.418</td><td>0.438</td><td>0.424</td></tr><tr><td></td><td>(1.57)</td><td>(1.56)</td><td>(1.62)</td><td>(1.58)</td></tr><tr><td>Donations</td><td>-0.404***</td><td>-0.406***</td><td>-0.405***</td><td>-0.404***</td></tr><tr><td></td><td>(-2.78)</td><td>(-2.75)</td><td>(-2.81)</td><td>(-2.77)</td></tr><tr><td>CityCost</td><td>0.120</td><td>0.119</td><td>0.116</td><td>0.119</td></tr><tr><td></td><td>(1.23)</td><td>(1.23)</td><td>(1.19)</td><td>(1.22)</td></tr><tr><td>Loss</td><td>-0.206*</td><td>-0.208*</td><td>-0.207**</td><td>-0.205*</td></tr><tr><td></td><td>(-1.95)</td><td>(-1.90)</td><td>(-2.03)</td><td>(-1.94)</td></tr><tr><td>Clean</td><td>-0.073</td><td>-0.074</td><td>-0.292</td><td>-0.083</td></tr><tr><td></td><td>(-0.65)</td><td>(-0.66)</td><td>(-1.23)</td><td>(-0.70)</td></tr><tr><td>Big4</td><td>0.516***</td><td>0.514***</td><td>0.500***</td><td>0.481***</td></tr><tr><td></td><td>(5.95)</td><td>(5.92)</td><td>(5.69)</td><td>(3.91)</td></tr><tr><td>Observations</td><td>124</td><td>124</td><td>124</td><td>124</td></tr><tr><td>Adjusted R2</td><td>0.692</td><td>0.689</td><td>0.695</td><td>0.689</td></tr><tr><td>Sector FE</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr></table>\n\nTable 4 presents ordinary least square regression results on the natural logarithm of audit fees (LnAF). Other variables are defined in Table 2. Two-tailed test of significance are reported. *** = less than 0.01, ** = less than 0.05, and * = less than 0.1.\n\n# Audit Lag and SSPs\n\nTo provide further evidence on the cost of the SSP reporting and assurance we next examine audit lag. Prior research has shown that audit lag, i.e., the length of time between the end of the financial period and the auditor signing off on the audit report is a proxy for\n\nunexpected audit effort (Knechel and Payne 2001; Knechel et al. 2009; Tanyi et al. 2010). Following Mayapada et al. (2023), we examine both the audit lag and filing lag, which is the length of time between the end of the financial period and when the annual report is recorded was being filed with the Charities Register. NZ charities must file their audited annual report within six months.\n\nTable 5 Panel A, and Panel B provide no support for an increase in audit lag or filing lag post-SSP. This contrasts with Mayapada et al. (2023) who finds an increase in both filing and audit lag when moving towards more detailed and prescriptive statements of recommended practice for UK not-for-profits. One reason for this difference is that the transition to SSP reporting assurance in NZ began with smaller not-for-profits and only applied to the Tier 1 entities in our sample almost seven years later. Thus, as the transition to SSP reporting was known well in advance, we find that it was an increase in expected, but not unexpected audit effort. The results found in Mayapada et al. (2023) may be driven by the change in UK guidance being known less than a year in advance. We conclude that the costs of changing accounting guidance can be minimised by providing a greater period of notice before adoption.\n\nAudit and filing lags also do not vary with assurance standard used, the expression of an other matter or the use of a Big 4 audit firm. This provides further support for our audit fee results that there was no difference in the cost of SSP based on these issues. In terms of control variables, we find that not-for-profits with a greater proportion of donations have a longer lag, while those with a higher percentage of assets in cash have a shorter lag. We infer that donations are relatively more risky to audit, while cash is less so. We also find that the Big 4 have short lags, suggesting that complete their audits in a timelier fashion, consistent with the higher audit fee charged. We find no control variables are significant in the filing lag regression, suggesting that client and auditor characteristics do not drive the filing decision. Despite this, our models appear to be relatively good fits with a higher Adjusted  $\\mathbb{R}^2$  for both audit and filing lags than Mayapada et al. (2023). Our main inferences are also unchanged when we use other measures of logged or change in lag.\n\nTable 5: Lag and SSP  \nPanel A: Audit lag  \n\n<table><tr><td></td><td>(1) ALag</td><td>(2) ALag</td><td>(3) ALag</td><td>(4) ALag</td></tr><tr><td rowspan=\"2\">POST</td><td>-9.356</td><td>-8.745</td><td>3.223</td><td>-2.909</td></tr><tr><td>(-0.71)</td><td>(-0.54)</td><td>(0.29)</td><td>(-0.19)</td></tr><tr><td rowspan=\"2\">AS1</td><td></td><td>-0.901</td><td></td><td></td></tr><tr><td></td><td>(-0.07)</td><td></td><td></td></tr><tr><td>SSPOM</td><td></td><td></td><td>-52.628 (-1.58)</td><td></td></tr><tr><td>POST/big4</td><td></td><td></td><td></td><td>-14.366 (-0.86)</td></tr><tr><td rowspan=\"2\">LnTA</td><td>-6.813</td><td>-6.787</td><td>-8.742</td><td>-6.975</td></tr><tr><td>(-1.19)</td><td>(-1.17)</td><td>(-1.54)</td><td colspan=\"1\">(-1.21)</td></tr><tr><td rowspan=\"2\">ARINV</td><td>13.772</td><td>13.796</td><td>18.039**</td><td>13.698</td></tr><tr><td>(1.62)</td><td>(1.62)</td><td>(2.22)</td><td colspan=\"1\">(1.62)</td></tr><tr><td rowspan=\"2\">TLTA</td><td>11.643</td><td>11.720</td><td>7.001</td><td>11.325</td></tr><tr><td>(0.55)</td><td>(0.55)</td><td>(0.33)</td><td colspan=\"1\">(0.53)</td></tr><tr><td rowspan=\"2\">CASHTA</td><td>-57.978**</td><td>-57.968**</td><td>-61.485**</td><td>-59.179**</td></tr><tr><td>(-2.43)</td><td>(-2.42)</td><td>(-2.60)</td><td colspan=\"1\">(-2.54)</td></tr><tr><td rowspan=\"2\">Donations</td><td>32.522**</td><td>32.639**</td><td>32.662**</td><td>32.567**</td></tr><tr><td>(2.46)</td><td>(2.47)</td><td>(2.51)</td><td colspan=\"1\">(2.52)</td></tr><tr><td rowspan=\"2\">CityCost</td><td>12.248</td><td>12.290</td><td>12.870</td><td>12.416</td></tr><tr><td>(1.35)</td><td>(1.35)</td><td>(1.44)</td><td colspan=\"1\">(1.36)</td></tr><tr><td rowspan=\"2\">Loss</td><td>-6.017</td><td>-5.892</td><td>-5.771</td><td>-6.080</td></tr><tr><td>(-0.65)</td><td>(-0.61)</td><td>(-0.64)</td><td colspan=\"1\">(-0.65)</td></tr><tr><td rowspan=\"2\">Clean</td><td>10.441</td><td>10.499</td><td>47.971</td><td>12.511</td></tr><tr><td>(0.74)</td><td>(0.74)</td><td>(1.45)</td><td colspan=\"1\">(0.86)</td></tr><tr><td rowspan=\"2\">Big4</td><td>-19.827**</td><td>-19.763**</td><td>-17.117*</td><td>-12.804</td></tr><tr><td>(-2.12)</td><td>(-2.09)</td><td>(-1.83)</td><td colspan=\"1\">(-0.89)</td></tr><tr><td>Observations</td><td>124</td><td>124</td><td>124</td><td>124</td></tr><tr><td>Adjusted R²</td><td>0.116</td><td>0.108</td><td>0.156</td><td>0.114</td></tr><tr><td>Sector FE</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr></table>\n\nPanel B: Filing lag  \n\n<table><tr><td></td><td>(1) FLag</td><td>(2) FLag</td><td>(3) FLag</td><td>(4) FLag</td></tr><tr><td>POST</td><td>-9.523(-0.84)</td><td>-16.669(-1.33)</td><td>-1.854(-0.16)</td><td>-4.092(-0.30)</td></tr><tr><td>POST_AS1</td><td></td><td>10.526(0.96)</td><td></td><td></td></tr><tr><td>POST_SSPOM</td><td></td><td></td><td>-32.084(-1.12)</td><td></td></tr><tr><td>POST BIG4</td><td></td><td></td><td></td><td>-12.102(-0.92)</td></tr><tr><td>LnTA</td><td>-1.164(-0.24)</td><td>-1.472(-0.30)</td><td>-2.339(-0.48)</td><td>-1.300(-0.27)</td></tr><tr><td>ARINV</td><td>9.064(1.18)</td><td>8.790(1.13)</td><td>11.665(1.52)</td><td>9.001(1.17)</td></tr><tr><td>TLTA</td><td>-3.264(-0.17)</td><td>-4.160(-0.22)</td><td>-6.095(-0.32)</td><td>-3.532(-0.18)</td></tr><tr><td>CASHTA</td><td>-24.870(-1.15)</td><td>-24.992(-1.16)</td><td>-27.008(-1.24)</td><td>-25.881(-1.20)</td></tr><tr><td>Donations</td><td>6.310(0.65)</td><td>4.938(0.52)</td><td>6.396(0.66)</td><td>6.349(0.66)</td></tr><tr><td>CityCost</td><td>-0.398(-0.05)</td><td>-0.891(-0.11)</td><td>-0.018(-0.00)</td><td>-0.256(-0.03)</td></tr><tr><td>Loss</td><td>0.051(0.01)</td><td>-1.404(-0.15)</td><td>0.200(0.02)</td><td>-0.002(-0.00)</td></tr><tr><td>Clean</td><td>10.743(0.88)</td><td>10.064(0.82)</td><td>33.623(1.23)</td><td>12.486(1.04)</td></tr><tr><td>Big4</td><td>-10.430(-1.21)</td><td>-11.168(-1.26)</td><td>-8.778(-1.04)</td><td>-4.514(-0.39)</td></tr><tr><td>Observations</td><td>124</td><td>124</td><td>124</td><td>124</td></tr><tr><td>Adjusted \\( R^2 \\)</td><td>0.096</td><td>0.103</td><td>0.120</td><td>0.102</td></tr><tr><td>Sector FE</td><td>Yes</td><td>Yes</td><td>Yes</td><td>Yes</td></tr></table>\n\nTable 5 presents ordinary least square regression results on the audit lag (ALag) in Panel A and the filing lag (FLag) in Panel B. Other variables are defined in Table 2. Two-tailed test of significance are reported. *** = less than 0.01, ** = less than 0.05, and * = less than 0.1.\n\n# 5. CONCLUSION\n\nThis study examines whether requiring the reporting and assurance of service performance information is associated with an increase in audit effort. Using a sample of NZ Tier 1 not-for-profit entities, who are required to following IPSAS and be audited, we find a large increase in audit fees post-SSP. There is no difference in the audit or filling lag post-SSP, suggesting that the increase in effort was not unexpected. There also are no differences based on the auditing standard used, whether an other matter expressed or depending on what audit firm is used. This study adds to the both the broader literature on the economic costs of requiring more complex accounting, with a particular contribution to emerging areas in non-financial reporting. Despite the importance of service performance reporting, this study is the first to investigate the economic costs of requiring its reporting and assurance and one of the first to investigate the cost of non-financial reporting. As we find the increase in audit fees is greater than the cost of adopting IFRS in NZ for listed companies, we provide evidence that the magnitude of increased audit effort for requiring SSPs to be audited should be framed as greater than adopting IFRS. We infer results would be similar for requiring the reporting and assurance of other non-financial reporting, including integrated or sustainability reporting. Thus, we provide direct of the cost to regulators and policymakers in assessing the impact of the requiring these changes, supplementing evidence showing an improvement in usefulness (Tseng et al., 2023). Our results also provide insight about how to manage the transition to new, more complex standards. As we find no increase in audit or filing lag in our setting, our results confirm the suggestion from Mayapada et al. (2023) that a that greater notice before adoption may reduce costs for new and complex standards.\n\nFurthermore, this study contributes to the emerging not-for-profit auditing literature by providing additional audit fee and market structure evidence from NZ. In contrast, to other jurisdictions studied, Tier 1 NZ entities must follow full IPSAS and be audited under International Auditing Standards (NZ). We confirm the audit fee models used in other\n\nsettings and provide further evidence of a Big 4 fee premium in this market. The NZ setting in provides evidence of interest to global standard setters due to its early adoption of SSP reporting for not-for-profits, following its longstanding use in the public sector, and calls for further reporting in this area and sustainability reporting. A potential limitation of our study is the small sample size inherent in using New Zealand data which reduces our ability to conduct further statistical robustness tests. Future study is likely needed, to examine the longer-term effects including on the quality of reporting.\n\n# REFERENCES\n\nAASB. 2021. AASB agenda consultation 2022-2026, available at: https://aasb.gov.au/admin/file/content105/c9/ITC46_10-21.pdf  \nAl-mulla, M., and M. Bradbury. 2022. Auditor, client and investor consequences of the enhanced auditor's report. International Journal of Auditing 26 (2):134-150.  \nBradbury, M., and T. Scott. 2020. What accounting standards were the cause of enforcement actions following IFRS adoption? Accounting & Finance 61 (S1): 2247-2268.  \nCA ANZ. 2022. Larger New Zealand charities - are you ready to report service performance information? available at: https://www.charteredaccountantsanz.com/news-and-analysis/news/larger-new-zealand-charities  \nCausholli, M., M. De Martinis, D. Hay, and W. R. Knechel. 2010. Audit markets, fees and production: Towards an integrated view of empirical audit research. Journal of Accounting Literature 29:167-215.  \nChan, P., M. Ezzamel, and D. Gwilliam. 1993. Determinants of audit fees for quoted UK companies. Journal of Business Finance & Accounting 20 (6):765-786.  \nConnolly, C. and N. Hyndman. 2013. Towards charity accountability: narrowing the gap between provision and needs? *Public Management Review* 15(7): 945-968.  \nCordery, C. & Deguchi, M. 2018. Charity registration and reporting: a cross-jurisdictional and theoretical analysis of regulatory impact. *Public Management Review*, 20(9), 1332–1352.  \nDe George, E. T., C. B. Ferguson, and N. A. Spear. 2013. How much does IFRS cost? IFRS adoption and audit fees. The Accounting Review 88 (2):429-462.  \nde Villiers, C., Hsiao, P.-C.K., Zambon, S. and Magnaghi, E. (2022a), “Sustainability, non-financial, integrated, and value reporting (extended external reporting): a conceptual framework and an agenda for future research”, Meditari Accountancy Research, Vol. 30 No. 3, pp. 453-471.  \nDeFond, M., and J. Zhang. 2014. A review of archival auditing research. Journal of Accounting and Economics 58 (2):275-326.  \nDickins, D. E., J. L. Higgs, and T. R. Skantz. 2008. Estimating audit fees post-SOX. Current Issues in Auditing 2 (1):A9-A18.\n\nDoogar, R., P. Sivadasan, and I. Solomon. 2010. The regulation of public company auditing: Evidence from the transition to AS5. Journal of Accounting Research 48 (4):795-814.  \nEierle, B., S. Hartlieb, D. C. Hay, L. Niemi, and H. Ojala. 2022. External factors and the pricing of audit services: A systematic review of the archival literature using a PESTLE analysis. Auditing: A Journal of Practice & Theory 41 (3):95-119.  \nFarooq, M. B., and C. De Villiers, 2017. The market for sustainability assurance services: A comprehensive review of the literature and future avenues for research. Pacific Accounting Review 29(1): 79-106.  \nGarcia, J., C. de Villiers, and L. Li. 2021. Is a client's corporate social responsibility performance a source of audit complexity? International Journal of Auditing 25(1): 75-102.  \nGhosh, A., and R. Pawlewicz, 2009, The impact of regulation on auditor fees: evidence from the Sarbanes-Oxley Act, Auditing: A Journal of Practice and Theory 28: 171-197.  \nGriffin, P. A., and Lont, D. H. 2007. An analysis of audit fees following the passage of Sarbanes-Oxley. *Asia-Pacific Journal of Accounting & Economics* 14: 161-192.  \nGriffin, P. A., D. H. Lont, and Y. Sun. 2009. Governance regulatory changes, International Financial Reporting Standards adoption, and New Zealand audit and non-audit fees: empirical evidence. Accounting & Finance 49 (4):697-724.  \nGrosse, M., T. Scott, and Z. Zang. 2023. Aligning disclosure requirements for managerial assessments of going concern risk: Initial evidence from New Zealand. Accounting & Finance.  \nHay, D. 2013. Further evidence from meta-analysis of audit fee research. International Journal of Auditing 17 (2):162-176.  \nHay, D. C., W. R. Knechel, and N. Wong. 2006. Audit fees: A meta-analysis of the effect of supply and demand attributes. Contemporary Accounting Research 23 (1):141-191.  \nHiggins, S., D. Lont, and T. Scott. 2016. Longer term audit costs of IFRS and the differential impact of implied auditor cost structures. Accounting & Finance 56 (1):165-203.\n\nHsiao, P.-C.K., Low, M. and Scott, T. 2023. Service performance reporting and principles-based authoritative guidance: an analysis of New Zealand higher education institutions. Meditari Accountancy Research.  \nIPSASB. 2015. Recommended practice guideline: reporting service performance information, IPSASB, New York, NY.  \nIPSASB. 2022. Advancing public sector sustainability reporting, IPSASB, New York, NY.  \nJohansson, E., P., Carey, G., Tanewski and I. Yusoff. 2022. The effect of members on charities' annual reporting: evidence from companies limited by guarantee in Australia. Accounting & Finance 62: 1851-1886.  \nKim, J.-B., X. Liu, and L. Zheng. 2012. The impact of mandatory IFRS adoption on audit fees: Theory and evidence. *The Accounting Review* 87 (6):2061-2094.  \nKnechel, W. R., and J. L. Payne. 2001. Additional evidence on audit report lag. Auditing: A Journal of Practice & Theory 20 (1):137-146.  \nKnechel, W. R., P. Rouse, and C. Schelleman. 2009. A modified audit production framework: Evaluating the relative efficiency of audit engagements. The Accounting Review 84 (5):1607-1638.  \nKrishnan, J., J. Krishnan, and H. Song. 2011. The effect of Auditing Standard No. 5 on audit fees. Auditing: A Journal of Practice & Theory 30 (4):1-27.  \nLu, M., R., Wang, A., Wu, and S. Zhou. 2023. Integrated Reporting, Audit Quality and Audit Fees. https://ssrn.com/abstract=4600887  \nMcConville, D. and C. Cordery. 2018. Charity performance reporting, regulatory approaches and standard-setting. Journal of Accounting and Public Policy 37 (4): 300-314.  \nMayapada, A., P. Biswas, and H. Roberts. 2023. Economic consequences of new accounting standards in UK charities. Accounting & Finance.  \nScott, J. and Pinny J. 2016. A new PBE Standard on Service Performance Reporting is on the horizon. Available at https://www.charteredaccountantsanz.com  \nSimunic, D. A. 1980. The pricing of audit services: Theory and evidence. Journal of Accounting Research 18 (1):161-190.  \nTanyi, P., K. Raghunandan, and A. Barua. 2010. Audit report lags after voluntary and involuntary auditor changes. Accounting Horizons 24 (4):671-688.\n\nTseng, Y-J., C. Yang and A. Habib. 2023. The impact of differentiated regulation on the accuracy and usefulness of financial reporting for charities: Evidence from New Zealand. Auckland Region Accounting Conference.  \nVermeer, T., K. Raghunandan, and D. Forgione. 2009 Audit Fees at U.S. Non-Profit Organizations. Auditing: A Journal of Practice & Theory 28 (2): 289-303.  \nXRB. 2017. PBE FRS 48 service performance reporting, XRB, Wellington.  \nXRB. 2019. New Xealand Auditing Standard 1 the Audit of Service Performance Information: Explanation of Decisions made, XRB, Wellington.  \nXu., G., and C. Yang. 2023. Service performance assurance for small charities: Experiences from New Zealand. International Journal of Auditing 27 (4): 190-207.  \nYang, Y., and R. Simnett., 2022. Determinants and Consequences of Audit Pricing for Charities, Including the Provision of Pro Bono Audits. *Auditing: A Journal of Practice* & Theory 42 (1): 183-210.  \nYao, D. F., M. Percy, and F. Hu. 2015. Fair value accounting for non-current assets and audit fees: evidence from Australian companies. Journal of Contemporary Accounting and Economics 11, 31-45.\n\n# Appendix A\n\n![](/uploads/images/9e05a74f-6f2b-49f0-8604-bc71b67d094b/6ab8abcd5b5ce12ab6291184998d2ecf6a63f7211f4d908401ab440e8c6f4d12.jpg)  \nFigure 1: Extract of audit report  \nBuilding a better working world\n\nIndependent auditor's report to the Territorial Commander and Chief Secretary of The Salvation Army New Zealand\n\n# Opinion\n\nWe have audited the general purpose financial report (the \"performance report\") of The Salvation Army New Zealand (\"the Army\") on pages 2 to 25, which comprises the service performance information, the consolidated statement of financial position of the Army as at 30 June 2023, and the consolidated statement of financial performance, consolidated statement of comprehensive income, consolidated statement of changes in equity and consolidated statement of cash flows for the year then ended of the Army, and the notes to the consolidated financial statements including a summary of significant accounting policies.\n\nIn our opinion, the performance report presents fairly, in all material respects;\n\nthe consolidated financial position of the Army as at 30 June 2023 and its consolidated financial performance and cash flows for the year then ended  \n- the service performance for the year then ended 30 June 2023 in accordance with the Army's service performance criteria\n\nin accordance with Public Benefit Entity Standards issued by the New Zealand Accounting Standards Board.\n\nThis report is made solely to the Territorial Commander and Chief Secretary of the Army, as attorneys for the General of the Army. Our audit has been undertaken so that we might state to the Territorial Commander and Chief Secretary of the Army those matters we are required to state to them in an auditor's report and for no other purpose. To the fullest extent permitted by law, we do not accept or assume responsibility to anyone other than the Army and the Territorial Commander and Chief Secretary of the Army as attorneys for the General of the Army, for our audit work, for this report, or for the opinions we have formed.\n\n# Basis for opinion\n\nWe conducted our audit of the consolidated financial statements in accordance with International Standards on Auditing (New Zealand) and the audit of the service performance information in accordance with NZ AS 1 The Audit of Service Performance Information (\"NZ AS 1\"). Our responsibilities under those standards are further described in the Auditor's Responsibilities for the Audit of the performance report section of our report.\n\nWe are independent of the Army in accordance with Professional and Ethical Standard 1 International Code of Ethics for Assurance Practitioners (including International Independence Standards (New Zealand) issued by the New Zealand Auditing and Assurance Standards Board, and we have fulfilled our other ethical responsibilities in accordance with these requirements.\n\nWe believe that the audit evidence we have obtained is sufficient and appropriate to provide a basis for our opinion.",
    "arxiv_id": null,
    "error_message": null,
    "embedding": [
      -4.0625,
      -0.038818359375,
      -3.078125,
      -4.3125,
      -1.2578125,
      2.25,
      -1.703125,
      -0.1259765625,
      3.046875,
      2.734375,
      3.21875,
      1.359375,
      1.9765625,
      1.1171875,
      0.494140625,
      0.83203125,
      0.228515625,
      2.6875,
      -0.7734375,
      -6.1875,
      0.63671875,
      2.703125,
      1.34375,
      -5.03125,
      1.2265625,
      -2.28125,
      0.84765625,
      2.6875,
      2.453125,
      2.828125,
      5.625,
      -3.96875,
      -1.8671875,
      -0.333984375,
      1.3828125,
      -2.140625,
      -0.60546875,
      -4.21875,
      0.76171875,
      5.625,
      -6.40625,
      1.484375,
      -1.5078125,
      0.6015625,
      -4.8125,
      0.34375,
      -0.7890625,
      -0.498046875,
      -5.0625,
      -3.640625,
      -3.046875,
      -0.4765625,
      7.125,
      -1.6796875,
      5.46875,
      -7.3125,
      -2.65625,
      6.59375,
      -8.875,
      -3.53125,
      3.96875,
      -1.75,
      3.953125,
      1.7578125,
      0.48046875,
      4.5625,
      1.3828125,
      -0.4609375,
      -2.15625,
      -2.796875,
      -2.140625,
      3.09375,
      6.9375,
      -3.421875,
      7.125,
      6.25,
      2.859375,
      2.046875,
      -1.3125,
      2.390625,
      -6.1875,
      1.703125,
      6.34375,
      -0.8359375,
      6.65625,
      0.1943359375,
      2.546875,
      -0.5625,
      -1.2734375,
      0.89453125,
      -0.486328125,
      2.859375,
      -4.46875,
      -0.921875,
      1.09375,
      4.625,
      0.03369140625,
      -3.03125,
      -4.625,
      3,
      -1.8046875,
      -1.3359375,
      2.1875,
      -6.875,
      -2.484375,
      -0.8515625,
      -2.359375,
      -6.4375,
      -3.890625,
      -0.9921875,
      1.078125,
      0.146484375,
      1.171875,
      0.91796875,
      3.671875,
      -2.6875,
      2.09375,
      -2.953125,
      -5.4375,
      -0.515625,
      1.3203125,
      -1.8984375,
      -0.16796875,
      -1.5,
      1.25,
      2.0625,
      -2.28125,
      2.625,
      6.125,
      2.859375,
      2.5,
      0.7578125,
      5.15625,
      -1.28125,
      -6.3125,
      -1.03125,
      1.4609375,
      1.203125,
      1.96875,
      5.25,
      -6.78125,
      -0.515625,
      -5.0625,
      -3.75,
      1.3125,
      -0.2431640625,
      -6.3125,
      1.4453125,
      0.53515625,
      -2.03125,
      0.248046875,
      3.0625,
      5.0625,
      -1.2734375,
      -2.140625,
      -4.75,
      1.890625,
      2.453125,
      -0.08349609375,
      -1.828125,
      -0.26171875,
      1.5390625,
      1.9453125,
      -0.33203125,
      0.50390625,
      -0.671875,
      -1.0078125,
      -0.119140625,
      1.484375,
      1.59375,
      2.40625,
      15,
      0.3203125,
      -2.765625,
      0.80859375,
      6,
      -3.96875,
      5.09375,
      4.3125,
      2.4375,
      -0.369140625,
      0.96484375,
      -4.6875,
      3.125,
      1.921875,
      1.484375,
      2.15625,
      -0.111328125,
      0.98046875,
      1.171875,
      -0.48828125,
      0.96484375,
      5.28125,
      -0.515625,
      -6,
      -2.703125,
      2.078125,
      1.2421875,
      -1.0703125,
      -1.7109375,
      -3.453125,
      -9.0625,
      0.6484375,
      -2.4375,
      -1.0703125,
      -2.171875,
      -0.138671875,
      -1.921875,
      0.337890625,
      -1.4140625,
      3.03125,
      0.99609375,
      2.703125,
      -3.328125,
      4.34375,
      1.046875,
      5.0625,
      1.5078125,
      5.5625,
      1.1015625,
      4.28125,
      1.6640625,
      0.09912109375,
      -1.109375,
      -3.1875,
      -0.50390625,
      4.4375,
      6.59375,
      1.25,
      11.375,
      0.5078125,
      0.439453125,
      2.8125,
      0.55078125,
      -2.078125,
      -1.53125,
      -6.875,
      1.671875,
      0.7890625,
      -0.80859375,
      -3.421875,
      -3.546875,
      -1.3359375,
      1.3828125,
      0.48046875,
      -2.125,
      -2.59375,
      -4.625,
      -2.34375,
      -6.84375,
      -0.5859375,
      3.03125,
      -6.28125,
      0.255859375,
      7.375,
      7.125,
      -1.8359375,
      0.314453125,
      -2.15625,
      -1.0078125,
      1.3125,
      -4.75,
      -5.9375,
      2.953125,
      2.390625,
      -1.0546875,
      0.330078125,
      -1.3515625,
      -0.625,
      2.171875,
      4.59375,
      0.53515625,
      -1.6328125,
      -1.9375,
      -2.40625,
      4.03125,
      0.515625,
      -2.625,
      0.11376953125,
      -5.03125,
      -3.703125,
      -8.6875,
      2.28125,
      -5.96875,
      4.59375,
      -2.140625,
      -0.19921875,
      4.15625,
      -0.298828125,
      10.4375,
      3.484375,
      1.421875,
      -0.47265625,
      0.2236328125,
      -1.5546875,
      0.029052734375,
      -4.875,
      -1.3828125,
      -8.8125,
      -2.515625,
      3.96875,
      2.875,
      -1.09375,
      0.06494140625,
      -2.125,
      3.5625,
      -0.9765625,
      -3.828125,
      2.875,
      1.78125,
      -0.68359375,
      -0.9140625,
      4.21875,
      -3.03125,
      2.9375,
      -4.28125,
      -2.5625,
      2.671875,
      2.15625,
      -1.171875,
      -3.296875,
      -2.75,
      -1.5078125,
      -7.375,
      -0.30078125,
      -0.640625,
      3.765625,
      -0.98828125,
      7.21875,
      -0.2294921875,
      2.0625,
      0.734375,
      -5.28125,
      -6.78125,
      8.9375,
      -1.390625,
      3.03125,
      5.03125,
      4.71875,
      3.78125,
      -2.359375,
      -1.453125,
      2.140625,
      -0.392578125,
      -0.08740234375,
      -0.82421875,
      5.25,
      -4.375,
      0.08544921875,
      -3.484375,
      -0.35546875,
      -0.60546875,
      1.546875,
      5.59375,
      7.53125,
      1.671875,
      1.359375,
      2.9375,
      0.95703125,
      -0.359375,
      2.828125,
      -3.140625,
      8.5625,
      5.40625,
      -1.484375,
      -4.125,
      -2.6875,
      4.8125,
      -1.3125,
      4.46875,
      0.59765625,
      -3.8125,
      2.03125,
      -0.6171875,
      -0.322265625,
      1.7890625,
      -0.224609375,
      -5.375,
      -6.8125,
      0.2421875,
      -5.34375,
      1.8125,
      -0.365234375,
      0.48828125,
      0.62890625,
      -0.2138671875,
      -2.3125,
      -0.5078125,
      1.171875,
      -4.28125,
      1.78125,
      -3.78125,
      -1.1171875,
      -3.96875,
      7.625,
      0.205078125,
      2.140625,
      2.421875,
      -2.1875,
      -0.193359375,
      2.609375,
      1.0703125,
      -0.2158203125,
      -3,
      -0.65234375,
      4.75,
      -0.177734375,
      -4.71875,
      3.0625,
      1.9921875,
      -2.359375,
      2.3125,
      0.9609375,
      -0.7421875,
      -2.53125,
      3.890625,
      0.30859375,
      6.75,
      -6.3125,
      -0.73046875,
      -5.9375,
      2.59375,
      4.625,
      -1.1328125,
      -0.9375,
      1.9296875,
      -0.96875,
      2.546875,
      -1.2578125,
      0.96484375,
      5.8125,
      -0.25,
      -3.5,
      2.5,
      -1.328125,
      -3.09375,
      3.59375,
      -2.453125,
      -1.7890625,
      0.453125,
      4.96875,
      -2.890625,
      5.5,
      5.1875,
      -6.25,
      -3.359375,
      -1.0390625,
      6.1875,
      -5.40625,
      -3.15625,
      -1.375,
      0.6953125,
      -5.5625,
      2.96875,
      -1.4765625,
      2.171875,
      -6.3125,
      5.4375,
      6.90625,
      -1.6015625,
      1.359375,
      -2.25,
      0.6640625,
      1.9140625,
      1.4921875,
      -3.34375,
      0.140625,
      0.6484375,
      6.875,
      -2.609375,
      -10.625,
      1.9765625,
      0.150390625,
      4.28125,
      -3.578125,
      4.40625,
      -3.640625,
      1.265625,
      -6,
      -0.65234375,
      1.9375,
      -2.96875,
      3.84375,
      2.796875,
      -4.65625,
      -4.96875,
      -0.80859375,
      6.78125,
      -1.4765625,
      2.5,
      -2.25,
      -0.4296875,
      0.6484375,
      -2.25,
      3.25,
      2.4375,
      5.875,
      -2.375,
      -0.421875,
      1.7734375,
      -7.5625,
      3.203125,
      -5.5625,
      -0.0556640625,
      -1.0234375,
      1.640625,
      2.859375,
      -2.875,
      -0.94140625,
      -2.53125,
      3.453125,
      -5.96875,
      -0.400390625,
      0.6640625,
      -4.40625,
      -3.96875,
      0.9375,
      -0.56640625,
      2.234375,
      -2.125,
      -3.015625,
      2.234375,
      1.7109375,
      2.171875,
      0.66015625,
      -2.5625,
      -2.8125,
      -5.4375,
      -0.318359375,
      4.1875,
      2.5625,
      1.0859375,
      -1.0234375,
      -4.40625,
      -3.1875,
      -5.1875,
      0.9375,
      0.9140625,
      -1.265625,
      2.6875,
      1.1328125,
      2.96875,
      -1.609375,
      1.0234375,
      1.5390625,
      1.5390625,
      -3.265625,
      0.3984375,
      1.3984375,
      -2.203125,
      -3.453125,
      1.71875,
      -4.0625,
      0.953125,
      2.09375,
      -1.578125,
      0.267578125,
      -1.015625,
      2.203125,
      0.55859375,
      -1.34375,
      -3.21875,
      4.09375,
      4.53125,
      1.6953125,
      2.046875,
      2.84375,
      6.03125,
      0.474609375,
      -0.6796875,
      1.046875,
      3.046875,
      1.3046875,
      0.134765625,
      -1.9453125,
      3.75,
      -4.03125,
      -7.15625,
      -3.90625,
      -0.72265625,
      2.125,
      -2.234375,
      2.953125,
      -3.859375,
      7.28125,
      -0.4140625,
      -1.2890625,
      -11.8125,
      0.1259765625,
      0.90625,
      -4.03125,
      -0.08349609375,
      -1.28125,
      4.8125,
      -1.578125,
      4.125,
      1.9140625,
      1.1796875,
      0.5078125,
      5.125,
      -2.390625,
      -0.265625,
      5.125,
      0.3828125,
      1.1171875,
      5.0625,
      -2.703125,
      -5.78125,
      -3.09375,
      -0.64453125,
      0.43359375,
      2.90625,
      4.15625,
      0.2734375,
      0.380859375,
      1.2109375,
      -4.25,
      -1.4296875,
      3.765625,
      2.453125,
      -0.1396484375,
      2.4375,
      -0.9921875,
      3.328125,
      -4.8125,
      3.78125,
      0.2314453125,
      -3.515625,
      1.265625,
      3.890625,
      2.296875,
      -2.109375,
      -1.0390625,
      -1.390625,
      3.90625,
      4,
      -8.5625,
      -2.625,
      0.65234375,
      2.171875,
      6.09375,
      1.4453125,
      0.2734375,
      -4.90625,
      5.0625,
      -2.5,
      -2.1875,
      4.71875,
      -0.92578125,
      -6.1875,
      1.3671875,
      -0.45703125,
      1.6796875,
      0.32421875,
      -0.396484375,
      2.078125,
      0.82421875,
      -0.302734375,
      2.96875,
      -1.546875,
      -2.578125,
      -4.3125,
      -0.09716796875,
      -2.109375,
      6.78125,
      0.82421875,
      -0.419921875,
      -3.359375,
      -1.8203125,
      3.40625,
      4.46875,
      2.109375,
      1.046875,
      0.82421875,
      0.21484375,
      -4.4375,
      4.625,
      4.21875,
      -2.421875,
      0.80078125,
      0.025634765625,
      -4.875,
      0.302734375,
      -2.390625,
      2.265625,
      1.6875,
      -1.15625,
      -4.96875,
      -5.09375,
      -3.375,
      0.7890625,
      4.3125,
      2.109375,
      -2.6875,
      4.46875,
      -0.16796875,
      0.08642578125,
      -1.015625,
      -3.75,
      -1.7265625,
      -2.53125,
      -1.671875,
      -8.125,
      -0.9140625,
      9.0625,
      1.3359375,
      -1.1953125,
      9.125,
      7.46875,
      -2.09375,
      1.265625,
      4.71875,
      -4.09375,
      -1.0234375,
      0.984375,
      -2.5,
      -2.234375,
      -1.8359375,
      2.28125,
      -2.390625,
      1.546875,
      0.0546875,
      -2.09375,
      -1.7734375,
      -4.75,
      -1.4453125,
      0.640625,
      -2.8125,
      1.21875,
      3.390625,
      3.40625,
      -1.0703125,
      6.9375,
      -0.55078125,
      -0.5703125,
      -1.4375,
      0.06396484375,
      2.0625,
      1.4765625,
      0.400390625,
      -2.9375,
      -4.75,
      -1.421875,
      1.25,
      -2.046875,
      3.078125,
      -1.2421875,
      1.6015625,
      2.28125,
      -0.06884765625,
      -6.8125,
      -3.3125,
      0.203125,
      -5.90625,
      -2.703125,
      -0.0166015625,
      3.671875,
      -1.15625,
      5.09375,
      -0.18359375,
      -1.7578125,
      -1.8203125,
      2.484375,
      -0.328125,
      0.9140625,
      -7.125,
      -1.84375,
      -0.2119140625,
      2.625,
      -6.6875,
      -3.84375,
      -2.703125,
      2.578125,
      -0.90234375,
      -4,
      5.53125,
      -3.90625,
      2.140625,
      -3.25,
      -0.57421875,
      2.84375,
      0.93359375,
      5.40625,
      -1.1328125,
      1.171875,
      2.734375,
      -0.90625,
      5.40625,
      -0.84375,
      1.2109375,
      0.40234375,
      1.5,
      1.21875,
      3.109375,
      1.46875,
      0.30078125,
      -0.9375,
      -1.2734375,
      0.52734375,
      2.421875,
      6.71875,
      3.140625,
      -1.3515625,
      3.609375,
      4.71875,
      -1.1328125,
      6.78125,
      1.921875,
      8.4375,
      -4.09375,
      -2.90625,
      6.75,
      0.212890625,
      -2.265625,
      -0.359375,
      -5.3125,
      -3.671875,
      2.796875,
      2.328125,
      -2.03125,
      -2.484375,
      -3.75,
      -1.6328125,
      3.96875,
      2.140625,
      4.8125,
      0.8359375,
      -0.60546875,
      3.140625,
      -1.3984375,
      -2.34375,
      -3.03125,
      -0.69921875,
      -1.4765625,
      1.0625,
      -2.234375,
      -0.73046875,
      -2.265625,
      2.359375,
      -4.5,
      -1.34375,
      -0.76171875,
      4.5,
      1.25,
      2.359375,
      0.054443359375,
      -2.40625,
      2.3125,
      1.359375,
      0.88671875,
      -3.171875,
      -1.453125,
      6.09375,
      7.09375,
      -1.390625,
      -0.96875,
      0.75390625,
      -1.6953125,
      -2.8125,
      -3.296875,
      4.90625,
      0.6953125,
      -5.09375,
      1.625,
      0.412109375,
      -4.96875,
      -4.25,
      4.21875,
      -2.375,
      -1.90625,
      3.8125,
      0.5703125,
      2.9375,
      2.890625,
      2.65625,
      2.703125,
      -1.5546875,
      -1.7578125,
      -3.0625,
      0.03466796875,
      -2.078125,
      3.140625,
      3.25,
      2.515625,
      1.5625,
      -1.453125,
      0.1494140625,
      -0.59375,
      -0.10205078125,
      -4.15625,
      0.466796875,
      -1.2890625,
      -4.8125,
      1.296875,
      -0.8671875,
      -8.3125,
      -4.6875,
      -6,
      -2.453125,
      -2.59375,
      -8.5625,
      -1.8359375,
      1.8359375,
      -5.15625,
      2.84375,
      -3.1875,
      -1.3984375,
      5.25,
      -3.84375,
      1.203125,
      -6.15625,
      3.765625,
      2.703125,
      0.384765625,
      4.1875,
      2.8125,
      1.953125,
      2.921875,
      -1.7734375,
      0.6953125,
      -6.125,
      6.96875,
      0.09033203125,
      7.6875,
      -0.1640625,
      -0.373046875,
      -5.84375,
      3.6875,
      0.43359375,
      1.7890625,
      -5.1875,
      1.5,
      -2.0625,
      -1.0390625,
      -0.0230712890625,
      0.9609375,
      0.271484375,
      -1.09375,
      -4.03125,
      2.84375,
      -0.9140625,
      -2.953125,
      2.015625,
      -1.5859375,
      5.59375,
      2.3125,
      1.03125,
      2.71875,
      2.390625,
      0.232421875,
      1.7421875,
      1.4140625,
      -3.875,
      3.53125,
      1.6640625,
      2.859375,
      -1.65625,
      4.96875,
      -1.2421875,
      0.57421875,
      -1.25,
      2.28125,
      3.015625,
      3.53125,
      -2.484375,
      2.9375,
      -1.96875,
      1,
      -0.193359375,
      1.1875,
      2.96875,
      0.95703125,
      1.8984375,
      -0.0201416015625,
      -3.375,
      -0.07763671875,
      0.53515625,
      1.484375,
      -5.5,
      -2.640625,
      -1.421875,
      -4.375,
      5.4375,
      -2.0625,
      0.6328125,
      1.4765625,
      0.3828125,
      3.59375,
      1.984375,
      -0.484375,
      0.984375,
      -0.21875,
      -1.453125,
      2.890625,
      -3.484375,
      6.75,
      3.4375,
      4.09375,
      5.4375,
      -1.28125,
      -0.5,
      -2.65625,
      1.8984375,
      3.40625,
      -2.625,
      0.064453125,
      5.15625,
      -3.1875,
      -1.484375,
      -2.0625,
      -1.5390625,
      0.32421875,
      -2.5625,
      1.7578125,
      8.8125,
      7.375,
      -3.53125,
      -5.71875,
      -1.40625,
      -3.859375,
      0.314453125,
      3.390625,
      0.1484375,
      1.7734375,
      2.859375,
      -0.2158203125,
      1.109375,
      1.515625,
      1.2734375,
      -6.3125,
      1.03125,
      0.8828125,
      -1.65625,
      -1.046875,
      0.1025390625,
      2.859375,
      0.70703125,
      6,
      1.890625,
      -0.466796875,
      3.65625,
      -1.9296875,
      -2.375,
      1.234375,
      6.59375,
      1.6640625,
      -1.8125,
      -4.8125,
      -1.015625,
      -0.00182342529296875,
      -1.90625,
      1.0078125,
      -3.765625,
      -0.462890625,
      7.3125,
      3.734375,
      0.97265625,
      3.28125,
      0.359375,
      3.625,
      -0.66796875,
      -2.5,
      -6.375,
      -0.8125,
      -3.125,
      1.4140625,
      1.1171875,
      -1.0625,
      -2.609375,
      1.6640625,
      -2.59375,
      2.984375,
      -5.40625,
      2.296875,
      -3.734375,
      -2.703125,
      0.30859375,
      -3.53125,
      4.5625,
      -0.74609375,
      0.353515625,
      2.546875,
      -3.046875,
      -1.9765625,
      -0.51953125,
      1.0625,
      -4.71875,
      -0.51953125,
      7.34375,
      -2.96875,
      -0.234375,
      -1.09375,
      0.30078125,
      -3.46875,
      -0.0458984375,
      -1.421875,
      -1.140625,
      -2.40625,
      0.0830078125,
      -1.328125,
      -3.75,
      4.21875,
      -6.0625,
      1.75,
      -1.1640625,
      1.4140625,
      2.921875,
      1.4140625,
      5.375,
      4.1875,
      -1.8515625,
      -0.75,
      -3.1875,
      -1.609375,
      -3.609375,
      -4.3125,
      1.1015625,
      -0.76953125,
      0.92578125,
      1.0546875,
      -0.46875,
      1.6640625,
      -3.59375,
      -2.8125,
      1.6796875,
      4.40625,
      -2.375,
      -1.0078125,
      1.90625,
      -3.71875,
      -8.125,
      -0.376953125,
      -4.875,
      1.171875,
      3.34375,
      -1.921875,
      3.03125,
      -3.609375,
      3.59375,
      -1.0390625,
      -2.09375,
      -0.38671875,
      -1.828125,
      3.671875,
      0.0284423828125,
      0.66015625,
      1.9765625,
      0.48828125,
      0.032470703125,
      -3.953125,
      -2.53125,
      -3.046875,
      -0.0830078125,
      2.390625,
      2.09375,
      -2.4375,
      -2.75,
      -0.93359375,
      -4.28125,
      -5.625,
      -4.21875,
      1.5625,
      5.75,
      4.4375,
      0.025390625,
      1.75,
      -1.96875,
      3.171875,
      -0.640625,
      5.21875,
      -1.1875,
      -3.734375,
      3.5625,
      -0.9375,
      4.09375,
      -1.4921875,
      -5.40625,
      -6.59375,
      2.640625,
      4.0625,
      6.1875,
      -1.9921875,
      -0.69140625,
      -0.384765625,
      -0.337890625,
      -1.609375,
      5.125,
      -1.9296875,
      -4.65625,
      -3.375,
      1.6328125,
      2.9375,
      -6.4375,
      3.203125,
      1.734375,
      -1.890625,
      -0.1845703125,
      6.90625,
      4.40625,
      -0.46875,
      2.140625,
      -1.25,
      -2.546875,
      2.4375,
      4.46875,
      0.224609375,
      1.6875,
      -1.0078125,
      -5.53125,
      -2.5625,
      -0.32421875,
      1.8125,
      1.9296875,
      -0.67578125,
      3.65625,
      -1.609375,
      1.421875,
      0.80859375,
      0.609375,
      -0.244140625,
      3.109375,
      0.3828125,
      -3.9375,
      2.484375,
      -2.765625,
      -2.03125,
      1.4375,
      -2.765625,
      1.0078125,
      0.94921875,
      -1.4453125,
      2.046875,
      1.09375,
      2.875,
      0.8203125,
      -6,
      0.5703125,
      1.3671875,
      0.9453125,
      4.625,
      -0.64453125,
      -1.2734375,
      1.6796875,
      -0.703125,
      -0.044677734375,
      -4.40625,
      4.40625,
      0.341796875,
      0.83984375,
      0.625,
      3.6875,
      -8.375,
      -1.8515625,
      -0.173828125,
      -0.07958984375,
      -2.453125,
      2.609375,
      -0.875,
      -2.5625,
      2.984375,
      0.84765625,
      -1.359375,
      -1.9453125,
      0.96484375,
      0.1455078125,
      -0.515625,
      1.3671875,
      -1.5234375,
      3.671875,
      -2.09375,
      -0.58203125,
      6.21875,
      -0.0234375,
      -0.033447265625,
      1.984375,
      0.1884765625,
      5.1875,
      3.65625,
      -0.79296875,
      -3.59375,
      -0.796875,
      0.9140625,
      -2.15625,
      -4.0625,
      1.3046875,
      -2.4375,
      -4.71875,
      0.65234375,
      -7.0625,
      -1.2109375,
      -3.65625,
      -6.75,
      -1.921875,
      -2.78125,
      1.09375,
      4.65625,
      3.703125,
      -2.15625,
      0.67578125,
      -2.984375,
      3.3125,
      2.671875,
      -3.296875,
      1.515625,
      -1.9453125,
      0.240234375,
      -4.53125,
      -2.453125,
      1.84375,
      1.7109375,
      3.796875,
      3.734375,
      -2.78125,
      1.953125,
      -1.1015625,
      2.625,
      -3.234375,
      -1.2421875,
      -0.62109375,
      2.765625,
      -4.125,
      -1.7734375,
      -2.828125,
      5.25,
      0.8046875,
      0.88671875,
      1.2421875,
      -1.9296875,
      3.078125,
      0.59765625,
      1.859375,
      2.84375,
      3.484375,
      4.40625,
      -1.96875,
      0.53125,
      -0.2158203125,
      -0.2734375,
      1.046875,
      -2.140625,
      -1.9140625,
      -3.390625,
      1.34375,
      -3.421875,
      -1.9765625,
      -5.9375,
      -0.65625,
      -0.8125,
      2.9375,
      2.6875,
      1.265625,
      -4.0625,
      0.4296875,
      -1.359375,
      -1.3359375,
      -2.203125,
      3.6875,
      -1.4140625,
      1.625,
      -3.984375,
      3.609375,
      4.96875,
      4.71875,
      3.046875,
      0.98046875,
      1.5,
      -2.359375,
      1.40625,
      -3.140625,
      3.140625,
      -0.95703125,
      -1.4765625,
      -0.59765625,
      -1.0390625,
      -1.6953125,
      -1.4453125,
      6.03125,
      -4.34375,
      -5.40625,
      -4.0625,
      -2.484375,
      0.64453125,
      5.28125,
      -4.3125,
      -0.72265625,
      -0.057373046875,
      -2.203125,
      3.3125,
      1.875,
      -1.5,
      -3.859375,
      4.15625,
      -0.8515625,
      4.3125,
      5.5,
      1.0390625,
      0.9453125,
      2.765625,
      0.12890625,
      -1.0625,
      3.75,
      0.625,
      -0.32421875,
      -1.9921875,
      3.234375,
      1.9140625,
      1.40625,
      -1.40625,
      -0.1748046875,
      1.7578125,
      2.875,
      4.5625,
      5.71875,
      -0.36328125,
      0.65625,
      1.8515625,
      -1.1640625,
      -1.9921875,
      -2.78125,
      2.484375,
      0.49609375,
      0.5234375,
      4.375,
      1.234375,
      3.828125,
      -3.640625,
      1.3828125,
      4.59375,
      9.375,
      -4.09375,
      0.042236328125,
      -6.875,
      1.515625,
      -2.125,
      -2.0625,
      -2.390625,
      3.875,
      2.1875,
      5.09375,
      0.1689453125,
      -0.71484375,
      4,
      0.55078125,
      -1.078125,
      -5.03125,
      4.1875,
      0.86328125,
      -0.318359375,
      -3.984375,
      -4.0625,
      0.06005859375,
      3.875,
      0.72265625,
      0.90625,
      0.251953125,
      2.65625,
      2.015625,
      -5.5,
      1.0234375,
      -0.53515625,
      -6.34375,
      -0.57421875,
      -2.4375,
      3.203125,
      -2.78125,
      -0.2080078125,
      4.71875,
      -2.515625,
      3.359375,
      -0.9296875,
      0.27734375,
      1.2421875,
      -1.3515625,
      0.79296875,
      1.0078125,
      -2.90625,
      3.421875,
      -1.0625,
      -5.375,
      0.0791015625,
      -1.4765625,
      0.765625,
      -1.3203125,
      -0.494140625,
      -0.40234375,
      -6.53125,
      0.49609375,
      -1.2890625,
      2.390625,
      0.6796875,
      -1.5546875,
      -2.09375,
      1.84375,
      -1.625,
      -0.95703125,
      1.3203125,
      -1.59375,
      1.265625,
      -0.9609375,
      0.2197265625,
      3.53125,
      0.76171875,
      -2.046875,
      2.953125,
      1.53125,
      0.12255859375,
      -1.4140625,
      -2.34375,
      0.400390625,
      -1.6015625,
      3.015625,
      -2.5625,
      -0.25390625,
      -0.51171875,
      4.90625,
      1.0078125,
      2.796875,
      -2.984375,
      -1.3203125,
      3.171875,
      3.625,
      -1.9453125,
      -1.5078125,
      0.53515625,
      1.6328125,
      -6.78125,
      -2.015625,
      1.6875,
      0.234375,
      3,
      -7.1875,
      -4.25,
      0.185546875,
      -0.51953125,
      -2.84375,
      -7.3125,
      2.171875,
      -0.8515625,
      -2.546875,
      -6.0625,
      0.50390625,
      3.4375,
      4.375,
      2.5625,
      4,
      0.447265625,
      -1.8671875,
      2.234375,
      12.1875,
      -1.09375,
      -1.7265625,
      -0.220703125,
      -0.7734375,
      6.1875,
      3.8125,
      2.671875,
      -0.69140625,
      -0.376953125,
      1.1875,
      0.400390625,
      3.140625,
      2.78125,
      -1.484375,
      -2.59375,
      -0.00994873046875,
      3.71875,
      -1.7890625,
      -5.21875,
      0.5625,
      3.640625,
      0.9296875,
      2.828125,
      -2.515625,
      1.03125,
      -0.7578125,
      -2.640625,
      -0.11865234375,
      -4.59375,
      -3.875,
      -1.71875,
      1.90625,
      -0.87890625,
      0.314453125,
      -5.25,
      -0.380859375,
      0.302734375,
      -3.9375,
      0.59765625,
      -3.8125,
      -2.640625,
      -1.46875,
      -1.0703125,
      3.703125,
      0.859375,
      0.59375,
      1.1875,
      0.345703125,
      2.859375,
      -3.453125,
      -3.125,
      -5.5625,
      1.34375,
      2.546875,
      -0.5078125,
      -2.359375,
      -4.09375,
      -4.65625,
      -2.234375,
      -3.90625,
      0.41796875,
      2.59375,
      -2.046875,
      -2.484375,
      -5.21875,
      -2.046875,
      0.42578125,
      2.8125,
      -2.5,
      -6.875,
      -0.376953125,
      0.87109375,
      1.3046875,
      -1.21875,
      -3.296875,
      5.21875,
      -0.09619140625,
      2.453125,
      -0.63671875,
      1.0859375,
      0.56640625,
      -3.109375,
      -0.287109375,
      3.171875,
      0.10107421875,
      -5.5,
      -1.7890625,
      2.34375,
      -1.3359375,
      3.921875,
      -4.34375,
      3.953125,
      0.625,
      -1.59375,
      -0.66796875,
      0.447265625,
      4,
      -4.875,
      0.019775390625,
      3.03125,
      3.609375,
      3.4375,
      -1.0859375,
      0.455078125,
      1.03125,
      1.7578125,
      -4.84375,
      1.2890625,
      1.4140625,
      1.4140625,
      -1.1015625,
      -0.546875,
      0.9296875,
      -1.3359375,
      -0.8984375,
      -4.5,
      -5.3125,
      -2.09375,
      -1.5625,
      3.546875,
      1.640625,
      -0.06689453125,
      0.275390625,
      -6.15625,
      -2.609375,
      -2.9375,
      -2.828125,
      5.25,
      0.126953125,
      -0.03515625,
      1.9296875,
      -2.3125,
      0.6953125,
      2.65625,
      -5.65625,
      2.859375,
      7.625,
      2.75,
      -0.5234375,
      -1.71875,
      -1.8828125,
      6.5,
      -2.78125,
      1.1875,
      3.875,
      -2.03125,
      4.46875,
      2.21875,
      2.328125,
      -5.78125,
      0.66796875,
      -0.26953125,
      0.228515625,
      -1.78125,
      5.3125,
      0.2021484375,
      1.9140625,
      -3.53125,
      1.046875,
      -3.765625,
      0.62109375,
      -2.90625,
      -1.578125,
      -2.78125,
      0.349609375,
      2.703125,
      0.376953125,
      -7.59375,
      2.796875,
      0.8515625,
      -3.015625,
      -6,
      -0.72265625,
      3.328125,
      0.490234375,
      1.859375,
      2.078125,
      -0.78125,
      2.40625,
      3.53125,
      0.74609375,
      -1.9609375,
      -0.019775390625,
      1.4765625,
      2.921875,
      -0.60546875,
      2.234375,
      1.109375,
      1.3671875,
      -0.43359375,
      -1.7421875,
      -1.2421875,
      3.65625,
      2.078125,
      -4.3125,
      0.177734375,
      -1.1015625,
      0.212890625,
      -2.3125,
      -3.203125,
      1.4375,
      -1.125,
      -0.1796875,
      1.796875,
      -2.21875,
      1.0625,
      -1.5625,
      -0.65625,
      -0.53125,
      -3.25,
      2.15625,
      3.234375,
      1.828125,
      -0.404296875,
      2.53125,
      2.875,
      -0.6328125,
      0.90234375,
      3.375,
      0.408203125,
      -0.69921875,
      -2.859375,
      2.640625,
      1.40625,
      4.5,
      -6.25,
      1.203125,
      -0.87109375,
      -0.2421875,
      1.5234375,
      1.5859375,
      0.953125,
      2.140625,
      -6.125,
      -3.625,
      -4.46875,
      1.875,
      -1.125,
      1.234375,
      2.328125,
      -1.6171875,
      0.64453125,
      0.94921875,
      -3.625,
      2.71875,
      -0.318359375,
      1.3671875,
      1.125,
      1.796875,
      -0.8828125,
      -2.390625,
      1.9140625,
      -0.94921875,
      -0.1318359375,
      -1.921875,
      -6.375,
      1.71875,
      -2.25,
      2.671875,
      -1.5625,
      -4.375,
      1.8671875,
      -0.515625,
      1.140625,
      0.55078125,
      -0.201171875,
      -5.125,
      6.1875,
      1.25,
      -0.96875,
      3.921875,
      -0.62109375,
      -2.59375,
      -0.443359375,
      -0.353515625,
      2.328125,
      -3.203125,
      -0.6640625,
      2.109375,
      -2.15625,
      -0.53125,
      2.3125,
      0.0250244140625,
      3.4375,
      -2.09375,
      0.0869140625,
      -0.75,
      2.796875,
      2.515625,
      5.3125,
      4.5625,
      -1.8125,
      1.5546875,
      -4.75,
      3.671875,
      -0.7265625,
      0.1669921875,
      2.59375,
      -2.109375,
      0.4765625,
      1.4921875,
      3.0625,
      -4.40625,
      -2.28125,
      0.53125,
      1.453125,
      4.1875,
      -0.435546875,
      1.2734375,
      -0.71484375,
      -2.109375,
      -1.984375,
      -2.390625,
      1.2734375,
      -2.859375,
      -1.984375,
      2.046875,
      4.09375,
      -2.640625,
      2.078125,
      1.515625,
      -1.0078125,
      -0.8671875,
      2.234375,
      -7.9375,
      -2.078125,
      3.828125,
      -5.53125,
      4.0625,
      -1.828125,
      1.375,
      7.625,
      -1.390625,
      -3.46875,
      5.875,
      0.1767578125,
      -7.0625,
      -1.1015625,
      -1.859375,
      2.78125,
      1.3515625,
      -0.1474609375,
      1.7734375,
      1.625,
      5.375,
      -5.46875,
      3.140625,
      -1.9765625,
      -5.90625,
      3.6875,
      -2.375,
      1.0859375,
      -2.9375,
      -5.90625,
      -5.3125,
      3.53125,
      1.1171875,
      3.390625,
      3.984375,
      2.03125,
      -1.453125,
      2.46875,
      -2.703125,
      -4.21875,
      3.71875,
      0.302734375,
      -4.53125,
      -2.140625,
      1.046875,
      -0.5859375,
      -0.2001953125,
      -0.73828125,
      -0.546875,
      -1.8671875,
      2.03125,
      1.515625,
      5.78125,
      -2,
      -2.171875,
      -4.0625,
      -0.251953125,
      0.423828125,
      0.63671875,
      -1.796875,
      -1.8515625,
      -2.140625,
      -3.109375,
      1.1796875,
      -1.46875,
      -5.03125,
      -2.40625,
      -4.875,
      -2.96875,
      2.953125,
      2.828125,
      2.828125,
      -2.234375,
      -1.8984375,
      4.0625,
      2.328125,
      0.203125,
      -3.484375,
      2.09375,
      1.8203125,
      -3.53125,
      -0.302734375,
      1.6640625,
      -1.2890625,
      -0.8125,
      1.3984375,
      1.859375,
      0.228515625,
      -1.890625,
      0.86328125,
      3.625,
      -1.1015625,
      0.462890625,
      -0.419921875,
      -1.3125,
      0.890625,
      6.4375,
      0.69140625,
      -5.15625,
      -3.171875,
      -3.296875,
      -2.390625,
      -4.375,
      1.34375,
      -1.859375,
      1.9296875,
      3.65625,
      -0.2578125,
      2.203125,
      2.390625,
      -4.71875,
      -1.921875,
      5.625,
      0.74609375,
      -0.92578125,
      -0.4609375,
      2.59375,
      -3.75,
      5.125,
      3.546875,
      -1.421875,
      -2.984375,
      -0.8984375,
      0.1689453125,
      -3.265625,
      -1.515625,
      0.326171875,
      -2.265625,
      -3.71875,
      2.546875,
      -1.3984375,
      2.21875,
      -0.39453125,
      -0.796875,
      4.6875,
      -5.40625,
      0.173828125,
      0.671875,
      4.5,
      4.34375,
      -7.0625,
      -2.21875,
      -3.5625,
      1.1171875,
      -3.0625,
      0.95703125,
      -1.3828125,
      0.55859375,
      5.34375,
      -2.34375,
      -3.53125,
      -2.453125,
      -6,
      2.75,
      0.11669921875,
      -0.76953125,
      0.19921875,
      -2.75,
      2.890625,
      -1.3359375,
      2.703125,
      -5.5625,
      0.70703125,
      -3.4375,
      -0.58203125,
      -0.279296875,
      2.28125,
      0.033447265625,
      -1.828125,
      0.62890625,
      5.46875,
      -0.8828125,
      -1.359375,
      5.59375,
      1.78125,
      0.72265625,
      1.0546875,
      1.203125,
      2.828125,
      -0.498046875,
      -5,
      3,
      2.890625,
      -0.115234375,
      -0.9375,
      0.1884765625,
      -1.359375,
      0.275390625,
      -0.83984375,
      0.490234375,
      0.52734375,
      0.5234375,
      0.02490234375,
      -5.5,
      -2.296875,
      -3.125,
      -2.03125,
      0.2470703125,
      0.169921875,
      3.0625,
      2.96875,
      -0.08154296875,
      -1.6953125,
      -0.6875,
      -1.3125,
      -0.2021484375,
      4.65625,
      -0.140625,
      -0.98828125,
      -1.078125,
      1.109375,
      -2.609375,
      -3.09375,
      -1.640625,
      -0.275390625,
      -0.3671875,
      0.361328125,
      3.015625,
      -2.046875,
      1.5546875,
      0.8359375,
      2.5625,
      -0.45703125,
      3.34375,
      -1.0078125,
      3.53125,
      -2.125,
      -1.3984375,
      2.71875,
      -0.2177734375,
      1.390625,
      2.90625,
      -1.734375,
      0.73046875,
      1.484375,
      -3.375,
      4.5,
      -3.75,
      4.28125,
      -1.8359375,
      3.84375,
      2.203125,
      -2.671875,
      1.171875,
      3.609375,
      -3.296875,
      -0.6484375,
      -0.12255859375,
      1.46875,
      1.78125,
      0.984375,
      0.86328125,
      -1.4453125,
      0.97265625,
      -2.09375,
      -0.3203125,
      -0.7890625,
      -0.7734375,
      2.234375,
      -1.984375,
      1.421875,
      -0.62890625,
      1.0625,
      -1.2734375,
      1.796875,
      0.515625,
      1.0546875,
      0.82421875,
      -3.875,
      2.09375,
      -0.90234375,
      -0.80078125,
      3.3125,
      0.72265625,
      -3.125,
      -0.5390625,
      -1.59375,
      5.6875,
      0.3828125,
      -2.953125,
      2.65625,
      1.0546875,
      2.578125,
      -0.2255859375,
      1.0078125,
      -0.9140625,
      -0.5390625,
      -4.4375,
      -0.65234375,
      -2.921875,
      -1.7890625,
      -2.40625,
      -1.125,
      0.427734375,
      -0.337890625,
      -0.50390625,
      -1.0078125,
      -1.9296875,
      -4.125,
      -3.3125,
      2.5625,
      1.3828125,
      -4.5,
      1.5703125,
      -3.328125,
      3.3125,
      -0.984375,
      -3.203125,
      -1.78125,
      -3.9375,
      0.451171875,
      -0.90234375,
      -4.0625,
      -1.3828125,
      2.171875,
      -3.578125,
      0.28515625,
      -3.5,
      0.82421875,
      -0.58203125,
      2.765625,
      0.9765625,
      -1.125,
      0.298828125,
      -1.21875,
      -3,
      -3.8125,
      -2.734375,
      -0.33984375,
      1.265625,
      2.28125,
      -1.671875,
      -3.546875,
      -0.21875,
      0.9453125,
      -0.87109375,
      -0.322265625,
      0.6875,
      -5.46875,
      0.5859375,
      4.6875,
      0.458984375,
      0.61328125,
      -4.28125,
      0.5859375,
      -1.421875,
      1.859375,
      -0.75,
      2.46875,
      0.310546875,
      -1.40625,
      1.3984375,
      1.4140625,
      3.5,
      -1.6328125,
      0.7265625,
      2.421875,
      -0.38671875,
      4.03125,
      4.78125,
      0.6875,
      -3.359375,
      0.349609375,
      -2.21875,
      1.828125,
      -2.015625,
      -1.6953125,
      -1.25,
      1.8046875,
      1.71875,
      2.34375,
      2.578125,
      1.0234375,
      -2.4375,
      -0.408203125,
      -3.71875,
      1.796875,
      1.7421875,
      4.625,
      -0.130859375,
      0.1279296875,
      0.115234375,
      -1.4375,
      1.359375,
      -0.70703125,
      0.51953125,
      4.46875,
      -1.9921875,
      -0.10400390625,
      1.265625,
      2.109375,
      -2.03125,
      -2.234375,
      2.734375,
      -0.77734375,
      1.703125,
      -2.078125,
      0.09228515625,
      1.6484375,
      -2.796875,
      2.96875,
      1.625,
      -4.59375,
      -2.140625,
      -3.6875,
      0.040771484375,
      2.9375,
      -0.059814453125,
      1.703125,
      1.3671875,
      -0.67578125,
      1.5703125,
      -4.96875,
      1.671875,
      2.46875,
      -3.34375,
      -0.66015625,
      -1.7890625,
      0.76171875,
      2.03125,
      1.046875,
      -3.109375,
      -0.23828125,
      -3.171875,
      0.921875,
      -0.0947265625,
      1.1328125,
      -3.828125,
      1.375,
      -0.0245361328125,
      -1.5390625,
      1.1484375,
      4.46875,
      -3.4375,
      -2.65625,
      -2.03125,
      0.083984375,
      -0.09326171875,
      -0.478515625,
      -2.484375,
      2.078125,
      -0.322265625,
      -1.7109375,
      -2.0625,
      -0.275390625,
      0.65234375,
      0.251953125,
      0.8046875,
      -3.765625,
      -3.96875,
      3.015625,
      -1.453125,
      -1.6640625,
      -1.578125,
      -0.421875,
      -0.62890625,
      -2.546875,
      2.609375,
      -1.8125,
      -0.326171875,
      -2.5,
      3.96875,
      0.052490234375,
      0.016357421875,
      1.90625,
      -1.921875,
      1.6953125,
      -0.2060546875,
      -4.34375,
      -1.875,
      0.12158203125,
      -2.546875,
      -0.2734375,
      -2.265625,
      2.4375,
      3.78125,
      -0.13671875,
      -0.97265625,
      -1.125,
      1.125,
      -1.890625,
      1.28125,
      2.21875,
      0.4921875,
      0.72265625,
      0.671875,
      -0.69921875,
      -1.7265625,
      1.671875,
      1.3671875,
      0.4765625,
      2.359375,
      0.94140625,
      4.6875,
      1.2265625,
      2,
      -1.28125,
      1.4921875,
      -0.9609375,
      -0.04931640625,
      4.90625,
      0.474609375,
      2.28125,
      -0.65234375,
      0.13671875,
      -1.0078125,
      0.94140625,
      -2.3125,
      0.8359375,
      0.84765625,
      -3,
      2.65625,
      0.6796875,
      -1.359375,
      -1.2578125,
      1.953125,
      -0.30859375,
      0.95703125,
      1.578125,
      -0.89453125,
      -0.53515625,
      0.765625,
      0.66015625,
      1.84375,
      0.859375,
      -1.3515625,
      -0.16796875,
      -0.8515625,
      0.43359375,
      2.015625,
      4.78125,
      -0.6484375,
      3.484375,
      5.4375,
      0.44921875,
      -1.2265625,
      -2.71875,
      -4.34375,
      1.6015625,
      1.125,
      -0.73828125,
      3.9375,
      0.890625,
      -0.94921875,
      -1.484375,
      -1.5703125,
      -1.015625,
      1.1796875,
      1.7578125,
      0.4921875,
      -2.078125,
      -1.8671875,
      -0.59765625,
      0.408203125,
      1.328125,
      -0.41796875,
      0.49609375,
      -1.34375,
      0.13671875,
      1.8671875,
      1.234375,
      1.2421875,
      -0.68359375,
      -1.65625,
      2.15625,
      2.140625,
      -0.9296875,
      -0.453125,
      3.640625,
      -5.09375,
      -0.42578125,
      3.171875,
      -1.8203125,
      -2.640625,
      -2.203125,
      2.953125,
      0.01092529296875,
      0.7578125,
      -2.65625,
      0.90234375,
      -0.349609375,
      2.9375,
      0.10107421875,
      0.99609375,
      -3.78125,
      1.015625,
      -0.51171875,
      2.59375,
      -2,
      -2.015625,
      1.6640625,
      0.69140625,
      2.734375,
      1.46875,
      -0.08056640625,
      -1.78125,
      -1.5234375,
      -0.82421875,
      -1.9375,
      -0.2890625,
      1.75,
      2.859375,
      -2.828125,
      -1.234375,
      -1.15625,
      -0.7421875,
      0.6171875,
      -3,
      -1,
      0.6953125,
      0.65625,
      0.78515625,
      -0.1669921875,
      -1.5,
      1.2265625,
      1.59375,
      3.671875,
      -1.3671875,
      3.09375,
      -2.28125,
      2.140625,
      -1.8046875,
      -1.015625,
      3.640625,
      -1.8203125,
      0.037109375,
      2.8125,
      -0.353515625,
      -1.703125,
      3.640625,
      1.6953125,
      1.703125,
      1.3671875,
      -3.078125,
      1.859375,
      -1.9140625,
      -1.2109375,
      -0.00714111328125,
      -1.703125,
      -0.5625,
      -4.15625,
      0.21484375,
      -0.314453125,
      1.8046875,
      2.1875,
      0.90625,
      1.59375,
      0.96875,
      -2.640625,
      3.296875,
      2.53125,
      -0.95703125,
      -0.1357421875,
      -1.1640625,
      1.6328125,
      -1.9296875,
      -0.1630859375,
      -0.462890625,
      0.55078125,
      -0.13671875,
      1.2265625,
      -2.6875,
      0.1767578125,
      -0.3203125,
      -2.65625,
      1.578125,
      -1.3515625,
      0.1279296875,
      1.3125,
      -0.828125,
      4.8125,
      -1.015625,
      0.9296875,
      1.25,
      1.4921875,
      -4.0625,
      -2.28125,
      -2.578125,
      -5.71875,
      0.98828125,
      1.3203125,
      -0.7265625,
      -0.01226806640625,
      -2.3125,
      -0.23046875,
      0.94140625,
      -1.6875
    ],
    "summary": "# 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 非财务信息（服务绩效）的审计成本缺乏实证证据，现有研究未关注审计工作量影响 [cite I. INTRODUCTION] |\n| **核心方案** | 利用新西兰大型慈善机构强制审计服务绩效信息（SSP）的政策变化，量化审计费用增长 |\n| **关键机制** | 自然实验设计：比较Tier 1机构在2022年强制SSP审计前后的审计费用变化 [cite I. INTRODUCTION] |\n| **核心数据** | 新西兰最高层级慈善机构（Tier 1，年支出>3000万纽币）的审计数据，聚焦政策实施前后对比 |\n| **核心变量** | 因变量：审计费用；关键自变量：SSP审计强制实施（0/1）；控制变量：审计准则类型、事务所规模等 [cite I. INTRODUCTION] |\n| **主要结论** | SSP审计导致审计费用显著增长14.5%，增幅超过IFRS采纳的11%，但未延长审计时间 [cite ABSTRACT] |\n\n# 💡 深度解读 (The Feynman Explanation)\n\n想象一下，慈善机构原本只需要向公众展示\"我们收到了多少捐款\"（财务信息），就像你向父母汇报\"我这月零花钱花了500元\"。现在监管要求必须同时证明\"我用这些钱做了哪些实事\"（服务绩效），比如\"辅导了20个贫困学生，成绩平均提升15分\"。\n\n**原来的审计**就像只检查你的记账本是否准确，而**新的SSP审计**相当于还要核实你是否真的做了那些辅导工作、成绩数据是否真实。这需要审计师：\n1. 设计全新的核查程序（比如抽样联系学生家长）\n2. 验证非财务数据的收集流程（成绩记录系统是否可靠）\n3. 评估绩效指标的定义是否合理\n\n**为什么成本更高？** 核心在于**验证链条的延长**。财务数据有原始凭证（发票、银行流水）作为\"硬证据\"，而服务绩效数据往往依赖机构内部的记录系统。审计师需要从数据源头开始验证，就像不仅要检查你最后的成绩单，还要去学校核实每门课的成绩记录过程是否规范。这种\"从头到尾\"的验证逻辑天然比单纯核对财务报表更耗时耗力。\n\n论文发现的14.5%费用增长，本质上反映了这种**证据层级的下沉**——审计师必须深入业务操作层面，而不仅是会计系统层面。\n\n# ⚔️ 评审视角 (The Adversarial Review)\n\n1. **样本代表性局限**：研究仅聚焦顶级慈善机构（年支出>3000万纽币），这些机构本就具备成熟的内控体系。对于中小型机构，SSP审计成本增幅可能呈非线性上升（因缺乏基础数据系统），但论文未提供梯度分析 [cite I. INTRODUCTION末段]\n\n2. **成本归因模糊性**：2022年恰逢疫情后期，审计费用增长可能混杂了远程审计效率下降、供应链风险审查加强等干扰因素。论文未设置对照组（如同时期无需SSP审计的Tier 2机构）进行差分消除 [cite I. INTRODUCTION]\n\n3. **长期效应缺失**：仅分析政策实施首年数据，无法区分\"初始学习成本\"与\"持续审计成本\"。类比IFRS采纳研究显示，审计费用随会计师熟练度提升而回落，但本文结论隐含假设成本增幅具有永久性 [cite 与Higgins等2016对比处]\n\n# 📝 一句话总结 (The Takeaway)\n\n如果我只记这篇论文的一个贡献，那应该是：**首次量化证明了非财务信息强制审计会产生显著经济成本（14.5%费用增长），且这一成本超过传统会计准则变更（IFRS）的影响**。",
    "structure": {
      "sections": [
        {
          "title": "The cost of auditing service performance information",
          "level": 1,
          "start_line": 3
        },
        {
          "title": "The cost of auditing service performance information",
          "level": 1,
          "start_line": 27
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 29
        },
        {
          "title": "I. INTRODUCTION",
          "level": 1,
          "start_line": 43
        },
        {
          "title": "2. INSTITUTIONAL SETTING, LITERATURE REVIEW AND RESEARCH QUESTIONS",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "Institutional Setting",
          "level": 1,
          "start_line": 65
        },
        {
          "title": "Literature Review and Hypothesis Development",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "3. RESEARCH METHOD",
          "level": 1,
          "start_line": 89
        },
        {
          "title": "Sample",
          "level": 1,
          "start_line": 91
        },
        {
          "title": "Regression Models",
          "level": 1,
          "start_line": 95
        },
        {
          "title": "4. RESULTS",
          "level": 1,
          "start_line": 119
        },
        {
          "title": "Audit Fees and SSPs",
          "level": 1,
          "start_line": 142
        },
        {
          "title": "Audit Lag and SSPs",
          "level": 1,
          "start_line": 156
        },
        {
          "title": "5. CONCLUSION",
          "level": 1,
          "start_line": 177
        },
        {
          "title": "REFERENCES",
          "level": 1,
          "start_line": 185
        },
        {
          "title": "Appendix A",
          "level": 1,
          "start_line": 235
        },
        {
          "title": "Opinion",
          "level": 1,
          "start_line": 243
        },
        {
          "title": "Basis for opinion",
          "level": 1,
          "start_line": 256
        }
      ]
    },
    "tags": [
      "审计费用",
      "非财务信息鉴证",
      "公共部门会计"
    ],
    "suggested_tags": [
      "审计费用",
      "非财务信息鉴证",
      "公共部门会计",
      "会计准则影响",
      "非营利组织"
    ],
    "tag_suggestions": [
      {
        "name": "审计费用",
        "confidence": 0.95,
        "reason": "论文核心研究内容是服务绩效信息审计对审计费用的影响，发现审计费用增加14.5%"
      },
      {
        "name": "非财务信息鉴证",
        "confidence": 0.9,
        "reason": "研究聚焦于非财务信息（服务绩效信息）的鉴证成本，属于非财务保证领域"
      },
      {
        "name": "公共部门会计",
        "confidence": 0.85,
        "reason": "研究对象为新西兰非营利组织，遵循公共部门会计准则（PBE IPSAS）"
      },
      {
        "name": "会计准则影响",
        "confidence": 0.8,
        "reason": "分析会计准则变化（服务绩效报告要求）对审计实践的影响"
      },
      {
        "name": "非营利组织",
        "confidence": 0.75,
        "reason": "实证研究基于新西兰大型慈善机构的样本数据"
      }
    ],
    "tags_confirmed": true,
    "category": "审计费用",
    "analysis": {
      "status": "completed",
      "started_at": "2025-12-21T14:38:27.516444",
      "completed_at": "2025-12-21T14:39:29.812881",
      "summary": "# 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 非财务信息（服务绩效）的审计成本缺乏实证证据，现有研究未关注审计工作量影响 [cite I. INTRODUCTION] |\n| **核心方案** | 利用新西兰大型慈善机构强制审计服务绩效信息（SSP）的政策变化，量化审计费用增长 |\n| **关键机制** | 自然实验设计：比较Tier 1机构在2022年强制SSP审计前后的审计费用变化 [cite I. INTRODUCTION] |\n| **核心数据** | 新西兰最高层级慈善机构（Tier 1，年支出>3000万纽币）的审计数据，聚焦政策实施前后对比 |\n| **核心变量** | 因变量：审计费用；关键自变量：SSP审计强制实施（0/1）；控制变量：审计准则类型、事务所规模等 [cite I. INTRODUCTION] |\n| **主要结论** | SSP审计导致审计费用显著增长14.5%，增幅超过IFRS采纳的11%，但未延长审计时间 [cite ABSTRACT] |\n\n# 💡 深度解读 (The Feynman Explanation)\n\n想象一下，慈善机构原本只需要向公众展示\"我们收到了多少捐款\"（财务信息），就像你向父母汇报\"我这月零花钱花了500元\"。现在监管要求必须同时证明\"我用这些钱做了哪些实事\"（服务绩效），比如\"辅导了20个贫困学生，成绩平均提升15分\"。\n\n**原来的审计**就像只检查你的记账本是否准确，而**新的SSP审计**相当于还要核实你是否真的做了那些辅导工作、成绩数据是否真实。这需要审计师：\n1. 设计全新的核查程序（比如抽样联系学生家长）\n2. 验证非财务数据的收集流程（成绩记录系统是否可靠）\n3. 评估绩效指标的定义是否合理\n\n**为什么成本更高？** 核心在于**验证链条的延长**。财务数据有原始凭证（发票、银行流水）作为\"硬证据\"，而服务绩效数据往往依赖机构内部的记录系统。审计师需要从数据源头开始验证，就像不仅要检查你最后的成绩单，还要去学校核实每门课的成绩记录过程是否规范。这种\"从头到尾\"的验证逻辑天然比单纯核对财务报表更耗时耗力。\n\n论文发现的14.5%费用增长，本质上反映了这种**证据层级的下沉**——审计师必须深入业务操作层面，而不仅是会计系统层面。\n\n# ⚔️ 评审视角 (The Adversarial Review)\n\n1. **样本代表性局限**：研究仅聚焦顶级慈善机构（年支出>3000万纽币），这些机构本就具备成熟的内控体系。对于中小型机构，SSP审计成本增幅可能呈非线性上升（因缺乏基础数据系统），但论文未提供梯度分析 [cite I. INTRODUCTION末段]\n\n2. **成本归因模糊性**：2022年恰逢疫情后期，审计费用增长可能混杂了远程审计效率下降、供应链风险审查加强等干扰因素。论文未设置对照组（如同时期无需SSP审计的Tier 2机构）进行差分消除 [cite I. INTRODUCTION]\n\n3. **长期效应缺失**：仅分析政策实施首年数据，无法区分\"初始学习成本\"与\"持续审计成本\"。类比IFRS采纳研究显示，审计费用随会计师熟练度提升而回落，但本文结论隐含假设成本增幅具有永久性 [cite 与Higgins等2016对比处]\n\n# 📝 一句话总结 (The Takeaway)\n\n如果我只记这篇论文的一个贡献，那应该是：**首次量化证明了非财务信息强制审计会产生显著经济成本（14.5%费用增长），且这一成本超过传统会计准则变更（IFRS）的影响**。"
    }
  },
  "f475412b-8a8f-4871-a7dc-fa8df5df42cb": {
    "id": "f475412b-8a8f-4871-a7dc-fa8df5df42cb",
    "filename": "ssrn-5095149.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/f475412b-8a8f-4871-a7dc-fa8df5df42cb_ssrn-5095149.pdf",
    "status": "completed",
    "created_at": "2025-12-21 21:37:35.639519",
    "updated_at": "2025-12-21 13:39:26.790810",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
    "markdown_content": "# Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools\n\nAuthors:\n\nPia Kreijkes<sup>1</sup>, Viktor Kewenig<sup>2*</sup>, Martina Kuvalja<sup>1*</sup>, Mina Lee<sup>2</sup>, Sylvia Vitello<sup>1</sup>, Jake M. Hofman<sup>2</sup>, Abigail Sellen<sup>2</sup>, Sean Rintel<sup>2</sup>, Daniel G. Goldstein<sup>2</sup>, David Rothschild<sup>2</sup>, Lev Tankelevitch<sup>2</sup>, Tim Oates<sup>1</sup>\n\n*Joint second authors\n\n# Affiliations:\n\n$^{1}$ Cambridge University Press and Assessment  \n2Microsoft Research\n\n# Abstract\n\nThe rapid uptake of Generative AI, particularly large language models (LLMs), by students raises urgent questions about their effects on learning. We compared the impact of LLM use to that of traditional note-taking, or a combination of both, on secondary school students' reading comprehension and retention. We conducted a pre-registered, randomised controlled experiment with within- and between-participant design elements in schools. 405 students aged 14-15 studied two text passages and completed comprehension and retention tests three days later. Quantitative results demonstrated that both note-taking alone and combined with the LLM had significant positive effects on retention and comprehension compared to the LLM alone. Yet, most students preferred using the LLM over note-taking, and perceived it as more helpful. Qualitative results revealed that many students valued LLMs for making complex material more accessible and reducing cognitive load, while they appreciated note-taking for promoting deeper engagement and aiding memory. Additionally, we identified \"archetypes\" of prompting behaviour, offering insights into the different ways students interacted with the LLM. Overall, our findings suggest that, while note-taking promotes cognitive engagement and long-term comprehension and retention, LLMs may facilitate initial understanding and student interest. The study reveals the continued importance of traditional learning approaches, the benefits of combining AI use with traditional learning over using AI alone, and the AI skills that students need to maximise those benefits.\n\n# Main\n\nLearners' rapid and widespread adoption of Generative Artificial Intelligence (GenAI) tools, particularly Large Language Models (LLMs), has unsettled the global educational landscape by offering\n\nnew ways for students to engage with learning materials $^{1;2;3;4;5;6}$  while also creating new challenges $^{7;8;9;10;11;12}$ . Large national surveys in the UK and US have found that a sizeable proportion of school students use GenAI tools such as OpenAI's ChatGPT $^{13;14}$ . This development raises fundamental questions about teaching and learning models. And yet, the vast majority of existing research on learning with LLMs has focused on the higher education context, leaving substantial knowledge gaps regarding effects on younger learners $^{15}$ . In addition, previous research has concentrated on second language education, mostly writing performance, as well as computing, health, and physics $^{15}$ . While such studies overall reveal positive effects of LLM use on academic performance, researchers call for caution as these might reflect the quality of LLM-produced work rather than genuine improvements in students' learning $^{15}$ . The effect of LLM use on two foundational aspects of learning – understanding and retaining information – remains critically underexplored. Knowledge stored in long-term memory is a fundamental element of cognition, forming the basis of nearly all human activity $^{16}$ . Thus, understanding the effects of LLMs on these foundations is urgently required to guide how such tools are integrated into schools, as policymakers and educators on the front-line are grappling with many unknowns. This study presents one of the first large-scale quantitative investigation into how reading comprehension and retention are affected by the use of LLMs.\n\nReading comprehension is the process of making sense of written materials resulting in a mental representation of the material $^{17}$ . Models of reading comprehension, such as the Construction-Integration (CI) model $^{18}$ , highlight that readers need to understand a text at several levels: the surface structure (words and their syntactic relations), the textbase (propositions, which generally represent one full idea), and the situation model (inferences about the text) $^{17}$ . This multi-level structure is supported by neuroimaging studies $^{19;20;21;22;16}$ . The ability to make inferences is a key aspect of comprehension. Usually, two types of inferences are distinguished: text-based bridging inferences involve connecting information from different text locations (e.g., the current sentence with a previous sentence) and knowledge-based inferences involve connecting information in the text with prior knowledge $^{17}$ . A reader's ultimate comprehension of a text depends on complex interactions between various elements, including factors related to the reader's characteristics (e.g., decoding skills, vocabulary and linguistic knowledge, prior domain knowledge, working memory capacity, inference-making ability, knowledge of reading strategies, motivation, and goals) $^{23;24;25;26;27}$ , the text itself (e.g., genre, length, word and sentence complexity, cohesion) $^{28;29}$ , and the reading context (e.g., reading for leisure or academic purposes) $^{30;31}$ .\n\nReading retention is the process of storing the comprehended content from a text in long-term memory. For learning it is necessary to not just comprehend the text at the time of reading, but also being able to remember what one has read and understood later. Retention is, in part, determined by the level and quality of information processing during encoding (i.e., the initial information acquisition while reading). According to the Levels of Processing framework  $^{32;33}$ , information that is processed deeply and elaborately —through semantic analysis involving meaning, inferences, and implications— can be recalled more readily. Deep processing facilitates the formation of rich, interconnected semantic networks, which provide multiple retrieval cues, and thus enhance the retrieval potential, as well as the construction of a robust schematic framework wherein specific details are meaningfully organised and related  $^{32;34}$ .\n\nThere are several reading strategies and learning activities that can enhance comprehension and retention as outlined by McNamara $^{35}$  and Chi $^{36}$ . Throughout the reading process, monitoring comprehension is particularly crucial, and includes strategies such as generating questions to gauge one's understanding $^{35}$ . Text-focused strategies involve interpreting the meaning of words, sentences and ideas (e.g., paraphrasing, breaking up long and complex sentence into manageable chunks, making bridging inferences to link different concepts) $^{35}$ . Strategies such as paraphrasing, selecting, and repeating are also considered active learning strategies, and these can activate prior knowledge and support the encoding, storing and assimilation of new knowledge $^{36}$ . There\n\nare also several effective reading strategies that go beyond the text (e.g., generating questions, using self-explanations, and using external information sources) $^{35}$ . Such strategies are considered to be constructive as learners generate new ideas and integrate information more deeply through explaining, elaborating, and connecting. This involves cognitive processes such as inferring new knowledge, integrating and organising new and existing knowledge, and repairing faulty knowledge $^{36}$ . Lastly, interactive learning activities involve meaningful dialogue with a partner, including with peers or systems like intelligent tutoring agents $^{36;28}$ . Such interactions can enhance learning by providing scaffoldings, corrective feedback, as well as additional information and new perspectives. Importantly, a dialogue is only considered to be interactive if both partners make substantive contributions $^{36}$ .\n\nThe integration of LLM tools into education raises the crucial question of whether their use could facilitate or undermine such learning strategies while reading. These models offer unprecedented flexibility in generating explanations, providing diverse perspectives, responding to complex questions in real-time, and adapting to individual learners' needs<sup>37;38</sup>. By serving as an external knowledge resource that extends beyond learners' personal knowledge and skills, LLMs can potentially enhance students' understanding and engagement with educational materials<sup>39;40;10;41</sup>. Furthermore, LLMs' ability to provide immediate clarifications and simplify complex concepts may help reduce cognitive load<sup>42;43</sup>. Thus, LLMs may be particularly useful in helping learners build understanding at multiple levels: from surface-level text comprehension and identification of key ideas, to deeper text-base representation of meanings, and ultimately to a comprehensive mental representation at the situation-model level of comprehension.\n\nHowever, over-use of LLMs could lead to shallow processing, where learners passively receive information without actively engaging in deep cognitive processing or critical thinking $^{44;36;45;46;47}$ . This superficial engagement could hinder the development of comprehensive mental models, negatively affecting comprehension and long-term retention $^{33;48}$ . When learners depend excessively on LLMs for answers and explanations, they may be less inclined to employ self-explanation and elaboration strategies that are essential for comprehension and meaningful learning $^{35;49;42}$ . While LLMs can make information readily accessible, this accessibility needs to be leveraged in ways that promote, rather than substitute for, the deep cognitive processing necessary for knowledge consolidation and learning $^{50;51}$ .\n\nIn order to assess the effectiveness of using LLMs as a learning tool for reading comprehension and retention, we compared it to a widely used learning activity that can facilitate many active and constructive strategies – note-taking. It is one of the most common and widely used learning activities and has been found to be an effective aid to learning while reading $^{52;53}$ . Note-taking can stimulate active processing of information and encourage the integration of new material with prior knowledge, thereby aiding comprehension as well as creating retrieval cues that aid later recall $^{52;54}$ . The impact of note-taking appears to vary depending on the depth of cognitive processing involved. It could focus readers on shallower processing, because readers might pay more attention to the surface structure and textbase but it could also enhance the situation-model by encouraging elaboration and better mental organisation $^{55;56;57}$ . Kobayashi's $^{52}$  meta-analysis supports the former as it found relatively small effects for higher-order performance tests, suggesting that the generative value of note-taking may be limited and highly dependent on the quality of the notes taken (whether they are verbatim or generative). We also compared the effectiveness of using an LLM on its own with using an LLM in conjunction with note-taking, given that it might be useful to combine the activities of querying LLMs and taking notes to facilitate learning. The two activities could potentially have complementary effects on reading comprehension and retention by drawing on their respective strengths. However, there might also be a risk of dividing attention in a way that renders both activities less effective.\n\nTo examine whether LLMs can be used as a tool to support the fundamental learning processes of reading comprehension and retention, we conducted a large-scale, pre-registered, randomised\n\ncontrolled experiment with within- and between-participant design elements. The study involved 405 secondary school students, aged 14-15 years, and took place in seven schools in England (UK). The experiment consisted of a learning session and a test session, which were three days apart. In the learning session, each student was tasked with understanding and learning two text passages on a different history topic (Apartheid in South Africa and the Cuban Missile Crisis), each by using a different learning activity (learning condition) drawing on evidence-based strategies. Students were not informed that they would be tested on the passages. They were randomly assigned to one of two groups. Group 1 was exposed to conditions referred to as \"LLM\" (i.e., using an LLM to understand and learn a text) and \"Notes\" (i.e., taking notes to understand and learn a text) and Group 2 was exposed to conditions referred to as \"LLM\" and \"LLM+Notes\" (i.e., using an LLM alongside note-taking to understand and learn a text). Both learning condition and text order were randomised. The LLM functionality in the learning session was provided by a private Azure-hosted instance of OpenAI's GPT-3.5 turbo model. After each learning task, students responded to a survey about their learning experience, with both quantitative and qualitative questions.\n\nIn the test session, students completed a range of questions assessing different levels of comprehension and retention. Specifically, we assessed their literal retention, comprehension, and free recall. For each passage, literal retention (i.e., lower-level retention) was measured through eight short response (cued recall) and ten multiple choice (recognition) questions assessing literal information which did not require any knowledge-based inferences, and no or only minimal text-based (bridging) inferences. Comprehension (i.e., higher-level retention) was measured through three open response questions requiring bridging inferences to connect information from several different text locations as well as knowledge-based inferences. Free recall was assessed through one open response question for each text, asking students to write down everything they remembered, and thus measuring how much students retained and understood without any cueing.\n\nOur primary aim was to quantify the impact of using an LLM on students' reading comprehension and retention. We made the choice not to have a \"reading-only\" control condition both because it would limit participant fatigue in responding to conditions, and on the basis that any engagement with the text beyond passive reading is likely going to lead to improved learning outcomes[35;36], setting the bar for LLM use comparatively low. Instead, we decided to compare it against the common, evidence-based learning activity of note-taking. We also explored students' learning experiences when engaging in the different learning activities, including which activity they preferred and why, as well as different \"archetypes\" of prompting behaviour that shed light on the learning outcomes. The results offer valuable insights for stakeholders and policy makers of the global education landscape.\n\n# Results\n\nOur study investigated the effects of using an LLM on student learning outcomes compared to traditional note-taking in a sample of 344 students (after applying pre-registered exclusion criteria, see Methods for more information). Group 1 (LLM vs Notes conditions) had a final sample of 184 students and Group 2 (LLM vs LLM+Notes conditions) of 160 students. Among the students there were slightly more males than females, most were English native speakers, a small number of students  $(5.2\\%)$  received free school meals indicating socioeconomic disadvantage, and about half were taking History GCSEs (see Supplementary Table 3 for all student characteristics). Both groups showed similar prior familiarity with the three learning conditions (LLM, Notes, LLM+Notes). About half of the students regularly took notes and most reported limited prior use of LLM for learning (see Supplementary Table 4 for detailed frequencies).\n\n# Learning outcomes\n\nWe compared the impact of LLM (reference condition, used by all students) to the impact of Notes (used by students in Group 1) and LLM+Notes (used by students in Group 2) on students' literal retention, comprehension, and free recall. Traditional note-taking led to the best performance across all measures, followed by LLM+Notes, while using LLM alone resulted in the lowest scores (see Supplementary Table 5 for descriptive statistics).\n\nLinear mixed-effects models confirmed significant differences across the conditions (see Figure 1, see Supplementary Table 6 for all model coefficients, confidence intervals and effect sizes).\n\nFor literal retention, we found significant main effects for both Notes ( $\\beta = 1.92$ ,  $p < 0.001$ , 95% CI [1.42, 2.42]) and LLM+Notes ( $\\beta = 0.57$ ,  $p = 0.040$ , 95% CI [0.03, 1.11]), indicating that students performed better with Notes compared to LLM and better with LLM+Notes compared to LLM.\n\nFor comprehension, we again found significant main effects for both Notes ( $\\beta = 0.95$ ,  $p < 0.001$ , 95% CI [0.62, 1.28]) and LLM+Notes ( $\\beta = 0.35$ ,  $p = 0.049$ , 95% CI [0.00, 0.70]), where students had better performance with Notes compared to LLM and with LLM+Notes compared to LLM.\n\nFor free recall, we found a significant main effect for Notes ( $\\beta = 1.02$ ,  $p = 0.018$ , 95% CI [0.18, 1.86]) but not for LLM+Notes ( $\\beta = -0.08$ ,  $p = 0.855$ , 95% CI [-0.98, 0.81]). Thus, students showed better performance with Notes compared to LLM but there was no significant difference between LLM+Notes compared to LLM. Given the non-normal distribution of free recall scores, we also conducted non-parametric versions of these tests as a robustness check, detailed in the Methods section, which corroborated these findings.\n\nThese results suggest that both note-taking conditions (either alone or with LLM) showed improved learning compared to using LLM on its own. However, the benefit of note-taking was seen across all different measures of learning, whereas the benefit of LLM+Notes was seen for literal retention and comprehension but not for free recall.\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/f9c6b97ec629fd3a5afd56314cf1273a7a23652bdf7aa8dcc448b1d899f826ce.jpg)  \nFigure 1: Distribution of test performance by condition and group for Comprehension (left, max 12 points; Notes:  $M = 4.89$ ,  $SD = 2.52$ ; LLM+Notes:  $M = 4.11$ ,  $SD = 2.65$ ; LLM Group 1:  $M = 4.00$ ,  $SD = 2.44$ ; LLM Group 2:  $M = 3.80$ ,  $SD = 2.47$ ), *Literal retention (middle, max 20 points; Notes:  $M = 10.8$ ,  $SD = 4.29$ ; LLM+Notes:  $M = 9.68$ ,  $SD = 4.83$ ; LLM Group 1:  $M = 8.83$ ,  $SD = 3.96$ ; LLM Group 2:  $M = 8.95$ ,  $SD = 4.29$ ) and *Free recall (right, max 50 points; Notes:  $M = 5.36$ ,  $SD = 5.49$ ; LLM Group 1:  $M = 4.32$ ,  $SD = 4.15$ ; LLM Group 2:  $M = 4.32$ ,  $SD = 4.63$ ; LLM+Notes:  $M = 4.20$ ,  $SD = 5.07$ ). Mean values are indicated by the two large circles within each facet, whereas the smaller points show individual students scores. Error bars indicate one standard error above and below the mean. Group 1 is shown on the left facet of each subfigure, comparing LLM (red) and Notes (blue). Group 2 is on the right facet of each plot, comparing LLM (red) and LLM+Notes (green).\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/41488ca1a6c3943e2825383542041eb80af29edf193795e1cd6d1ef164a3df0a.jpg)\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/cfcb380db33b073aea66229200e4a4b9ce36c4e9d8d6f6b463a22debcaf33262.jpg)\n\n# Behavioural engagement\n\nBehavioural engagement with the LLM and note-taking was quantified by the average number of queries made to the LLM, the average number of words written in students' notes as well as time spent on task. Access to notes alongside the LLM reduced students' query frequency compared to LLM-only conditions (from 9.21 to 6.02 queries in Group 2). While students wrote a similar number of words in their notepad in both Notes and LLM+Notes conditions (around 100 words), a concerning proportion  $(25.63\\%)$  heavily copied from LLM outputs into their notes, with some  $(16.25\\%)$  showing nearly complete copying (more than  $90\\%$  overlap of trigrams between LLM output and notes). Additionally, students spent significantly less time on task when using only the LLM compared to conditions involving note-taking (differences of 0.80 and 1.54 minutes for Groups 1 and 2, respectively), suggesting deeper engagement when note-taking was involved. See Supplementary Table 7 for a full description of behavioural measures.\n\n# Prompting behaviour\n\nIn order to understand how students engaged with the LLM, we performed a qualitative analysis of all prompts  $(n = 4,929)$  using a hierarchical coding scheme where specific prompts were nested within overarching prompt types. Each prompt could be assigned to multiple codes. We identified four behavioural archetypes of how students worked with the LLM in relation to the task as well as two additional overarching prompt types that were not directly related to the task (see Figure 2 for the distribution of prompt types across each LLM session). For exact frequency counts of overarching prompt-types, see Supplementary Table 21 and for specific prompt types see Supplementary Table 22.\n\nThe most frequent archetype was seeking additional information and deeper understanding (2,265 prompts, as shown in the purple bars in Figure 2). The vast majority of students  $(90\\%)$\n\nused such a prompt type at least once, about  $40\\%$  used this as their first prompt, and  $60\\%$  as their most common prompt type (see Figure 3). These prompts primarily comprised requests for elaboration (1,479 instances) and general background information (514 instances). Examples include \"how are people today affected by the apatheid\" and \"why did it take so long to free nelson mandela\".\n\nInformation condensation (749 prompts, as shown in the teal bars in Figure 2) emerged as the second most common archetype, with  $27\\%$  of students using it as their first prompt, typically requesting summaries or key ideas, such as \"What are five key points from the entire text?\" or \"create a timeline of all the events\". The third archetype, basic understanding of the text (615 prompts, green bars in Figure 2), was used by  $70\\%$  of students at least once, mainly for definitions and content simplifications such as \"What is a sanction?\" and \"explain communist\". A fourth archetype, requesting direct study and memory help, was used infrequently (39 instances, red bars in Figure 2) despite students receiving no explicit instructions for such use. These ranged from asking the LLM to generate a quiz (\"ask me 4 questions about the text and tell me if i get them right after my next reply\") to pneumonic devices (\"create me a mnemonic device on the cuban missile crisis\").\n\nBeyond these archetypes, 760 prompts focused on interacting with the LLM rather than (or in addition to) text content (blue bars in Figure 2), primarily requesting specific formats or response improvements. Examples include \"can you put this into bullet points?\" and \"shorten the aftermath into 1 sentence\". Notably, only six prompts questioned the LLM's reliability. Finally, about  $10\\%$  of all interactions (501 prompts, brown bars in Figure 2) were off-topic or irrelevant (e.g., \"what is the meaning to life\" and \"Tell me about Harry Potter\"), showing that a small but potentially relevant prompt proportion was not task-focused, potentially due to low task motivation or boredom.\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/d626ae4afddf164784c2957f218467f2fcf897ba4e897712255c0f3e6a5a4074.jpg)  \nFigure 2: Distribution of prompt types across LLM sessions for different conditions and students. Each panel represents a specific combination of condition (LLM-only or LLM+Notes) and text passage (Apartheid in South Africa or Cuban Missile Crisis). Each bar shows the number of prompts within each type for an individual LLM session, with sessions sorted in descending order by the total number of prompts and ties broken by the number of prompts within each type.\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/5ab5a2be2e8d605619eba532a2e999f95f7a25c621f8c764c14c66b0525a4575.jpg)  \nAnalysis of overarching prompt types  \nFigure 3: Distribution of student prompts across different types, showing the percentage of students who used the prompt type at least once (blue), as their most common prompt (magenta), and as their first prompt (green). Prompt types are arranged by overall frequency.\n\n# Learning experiences and perceptions\n\nIn addition to analysing students' behavioural engagement, we asked them about their learning experiences and perceptions of the different conditions. The quantitative results are summarised in Figure 4, with details of statistical tests in Supplementary Table 15. We used an adjusted p-value threshold of  $0.05 / 18 = 0.002$  to gauge statistical significance based on the Bonferroni correction to account for multiple comparisons  $(n = 18)$ .\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/c4c266d6421d905ef8a8bd42b99b86f7e33f41d2190d0d2c236b0c94e604e5c3.jpg)\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/5cfcc2dc3286d102a1270677d41c112b1276718771814b3e2c1beaffb364cf11.jpg)\n\nFigure 4: Differences in learning experiences and perceptions by group and condition. The top panel displays perceived test performance on a 0-100 scale, while the middle and bottom panels show ratings for measures with positive and negative valences, respectively, on a 1-5 scale. Each point represents the mean rating for a condition, with error bars indicating one standard error above and below the mean.  \n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/b3374b799c65b963b25990f2d017fef1f4c77476810044f2ce97269baef4992c.jpg)  \nCondition  $\\rightarrow$  LLM only  $\\rightarrow$  LLM+Notes  $\\rightarrow$  Notes only\n\nContrary to actual learning outcomes, Group 1 students found the LLM more helpful, easier to use, and more enjoyable than note-taking, while reporting less effort investment. Group 2 showed similar experiences between conditions, except perceiving the LLM-only condition as less difficult than LLM+Notes. Students perceived task performance similar across conditions during learning. Following the test, students in both groups accurately reported their perceived test performance to be lower in the LLM-only conditions than in the Notes and LLM+Notes conditions.\n\nThese findings suggest that while the LLM-only condition was less effective for learning, it provided motivational benefits - particularly evident in Group 1's preferences. Importantly, these motivational benefits were maintained when combining LLM use with note-taking in Group 2.\n\n# Activity preferences\n\nStudents were asked to indicate their preferred learning activities and explain their preferences through an open response (see Table 1). In Group 1, most students preferred the LLM activity over traditional note-taking. Those students cited enhanced understanding, the LLM's ability to answer questions, and ease of the activity as their main reasons. Students favouring traditional notetaking emphasised benefits for understanding, the importance of self-generated work, and improved\n\nmemory retention. In Group 2, a substantial majority preferred the combined activity over using the LLM alone. Students preferring the combined activity noted the complementary benefits of both approaches, enhanced memory retention, and improved organisation. Those favouring the LLM-only activity emphasised its efficiency, particularly appreciating that the LLM did the work for them. This reveals an underlying tension between efficiency and depth of processing - while the LLM-only activity was perceived as more efficient, conditions involving note-taking demonstrated superior learning outcomes through deeper engagement and better retention.\n\nTable 1: Learning activity preferences and reasons by group  \n\n<table><tr><td>Activity preference and reasons</td><td>Count</td><td>Percentage</td></tr><tr><td colspan=\"3\">Group 1: LLM vs Notes</td></tr><tr><td>LLM over Notes</td><td>89</td><td>42.0</td></tr><tr><td>Notes over LLM</td><td>57</td><td>26.9</td></tr><tr><td>No preference</td><td>48</td><td>22.6</td></tr><tr><td>Not sure</td><td>18</td><td>8.5</td></tr><tr><td colspan=\"3\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>LLM over LLM+Notes</td><td>32</td><td>16.2</td></tr><tr><td>LLM+Notes over LLM</td><td>100</td><td>50.5</td></tr><tr><td>No preference</td><td>48</td><td>24.2</td></tr><tr><td>Not sure</td><td>18</td><td>9.1</td></tr><tr><td colspan=\"3\">Reasons for LLM over Notes preference</td></tr><tr><td>Helps understanding</td><td>34</td><td>21.9</td></tr><tr><td>Answers questions</td><td>23</td><td>14.8</td></tr><tr><td>Easy to use</td><td>22</td><td>14.2</td></tr><tr><td>Quick to use</td><td>18</td><td>11.6</td></tr><tr><td>Provides background</td><td>18</td><td>11.6</td></tr><tr><td>Summarises and simplifies</td><td>17</td><td>11.0</td></tr><tr><td>Engaging</td><td>10</td><td>6.5</td></tr><tr><td>Interactive</td><td>8</td><td>5.2</td></tr><tr><td>Helps remember</td><td>4</td><td>2.6</td></tr><tr><td colspan=\"3\">Reasons for Notes over LLM preference</td></tr><tr><td>Helps understanding</td><td>22</td><td>21.4</td></tr><tr><td>Own work</td><td>21</td><td>20.4</td></tr><tr><td>Aids memory</td><td>18</td><td>17.5</td></tr><tr><td>Helps processing</td><td>8</td><td>7.8</td></tr><tr><td>Unclear usage of LLM</td><td>7</td><td>6.8</td></tr><tr><td>Active learning</td><td>6</td><td>5.8</td></tr><tr><td>LLM distracts</td><td>6</td><td>5.8</td></tr><tr><td>Revisitable</td><td>5</td><td>4.9</td></tr><tr><td>Easier</td><td>4</td><td>3.9</td></tr><tr><td>Helps organisation</td><td>4</td><td>3.9</td></tr><tr><td colspan=\"3\">Reasons for LLM over LLM+Notes preference</td></tr><tr><td>Does the work for you</td><td>15</td><td>50.0</td></tr><tr><td>Notes not necessary</td><td>5</td><td>16.7</td></tr><tr><td>Quicker</td><td>4</td><td>13.3</td></tr><tr><td>More time for questions</td><td>4</td><td>13.3</td></tr><tr><td colspan=\"3\">Reasons for LLM+Notes over LLM preference</td></tr><tr><td>Best of both worlds</td><td>35</td><td>23.2</td></tr><tr><td>Helps remember</td><td>27</td><td>17.9</td></tr><tr><td>Helps organisation</td><td>24</td><td>15.9</td></tr><tr><td>Own work</td><td>21</td><td>13.9</td></tr><tr><td>Helps understanding</td><td>16</td><td>10.6</td></tr><tr><td>More helpful and easier</td><td>12</td><td>7.9</td></tr><tr><td>Helps process LLM output</td><td>6</td><td>4.0</td></tr><tr><td>More fun</td><td>4</td><td>2.6</td></tr><tr><td>LLM errors</td><td>3</td><td>2.0</td></tr></table>\n\nNote: This table only includes reasons that have been mentioned by at least three students.\n\n# Future use\n\nAt the end of the learning session, students reported their intentions for future use of each activity. In Group 1, the majority of students  $(64.4\\%)$  indicated they would use LLMs in the future, with only  $7.3\\%$  negating and  $28.2\\%$  being unsure. A smaller majority of students  $(55.3\\%)$  planned to take notes in the future, and  $10.6\\%$  did not think they would do so, while  $34.1\\%$  were uncertain. In Group 2, the majority of students  $(59.5\\%)$  intended to use LLMs in the future,  $10.4\\%$  did not and  $30.1\\%$  were unsure. A similar majority  $(58.5\\%)$  planned to use the combined LLM+Notes activity in the future, while  $14.6\\%$  did not and  $26.8\\%$  were unsure.\n\n# Discussion\n\nThis study provides new insights into how the use of LLMs compares to and interacts with traditional evidence-based practices (specifically note-taking) to support students' reading comprehension, retention, and engagement. It offers important perspectives on the cognitive and motivational dynamics underlying human-AI interactions in learning, and how these interactions influence educational outcomes and perceptions. In particular, it suggests that LLM use and more traditional note-taking have complementary roles in the learning process.\n\nIn this study, we found that note-taking—whether done alone or alongside LLM usage—produced higher comprehension and retention scores compared to using an LLM alone, underscoring the importance and effectiveness of traditional active learning strategies. At the same time, students generally used LLMs constructively and perceived them as more \"helpful\" and preferable to notetaking. How can we reconcile these seemingly conflicting results?\n\nOne part of the answer may be that students simply have a limited metacognitive understanding of what is in fact helpful for their own learning $^{58;59;60}$ , specifically in the context of GenAI $^{61}$ . In particular, they may underweight the importance of the \"desirable difficulties\" induced by activities such as note-taking $^{48}$ . Note-taking requires active processing of information, such as identifying important information, paraphrasing and summarising $^{52}$ . While these tasks demand cognitive effort and may not be inherently enjoyable, past research shows that the learning potential increases with the level of required cognitive engagement $^{62}$ . Having an LLM do some of the work of summarising a passage or explaining a concept may feel more enjoyable and efficient, but can reduce the cognitive engagement necessary for deep comprehension and long-term retention. Similar effects on LLM use on learners' affective-motivational state and mental effort were found in Deng et al.'s meta-analysis $^{15}$ . Additionally, LLMs may sometimes provide learners with distractions that are interesting, but that compete with the primary task at hand.\n\nAt the same time, our exploratory analysis of student prompts suggests that another part of the answer lies in the unique benefits LLMs provide, which may have been genuinely helpful beyond what our primary analyses captured. The vast majority of LLM use was constructive rather than distracting or reductive, with students seeking additional information and deeper understanding. Students demonstrated remarkable curiosity, asking sophisticated questions that extended beyond the immediate text. For example, in a passage about apartheid in South Africa that briefly mentions Nelson Mandela's journey from prisoner to president, one student asked, \"What was Mandela's life story?\" Similarly, in a passage on the Cuban Missile Crisis that assumes some background knowledge of the Cold War, another student asked, \"Why was America afraid of communism?\" These explorations represent a different kind of active learning opportunity that may not result from note-taking alone, underscoring the LLM's potential to expand intellectual horizons. That said, these deeper inquiries may have involved tradeoffs: they could have competed with processing the core information in the passage, reducing performance on tested items, but they likely also enhanced learning in ways not captured by our tests, which focused only on the explicit and implied content within the texts.\n\nTaken together, our findings demonstrate the value of combining LLM use and note-taking, which was not only more effective than LLM use alone but also students' preferred activity. This raises the opportunity and challenge of how to combine traditional evidence-based strategies like note-taking with the unique benefits offered by LLMs. Rather than viewing these as competing alternatives, we should think of them as complements that when thoughtfully integrated can enhance learning outcomes in ways that neither can achieve alone. A key to doing so is leveraging input from educators and researchers in the design and use of new LLM-based tools for learning, as has been key for past hybridisation of traditional and digital approaches $^{63;64}$ .\n\nOur work suggests several such directions. First and most easily would be to separate LLM use from note-taking. Under this model, students would first independently read a text, and then interact with an LLM to further clarify and explore its content. Following this they would take notes independently, without the ability to simply copy and paste output from the LLM. This would prevent students from taking shortcuts we have observed in this study, instead encouraging them to synthesise and internalise information themselves. This is a small but likely meaningful design choice that was not obvious to us a priori, but that emerged through our work and could be tested in future research.\n\nSecond, educators could actively train and guide students to use LLMs in ways that align with active learning strategies, such as asking targeted questions to clarify specific misunderstandings, engage in critical thinking, and integrate information, without overloading them with excessive information or reducing cognitive processing $^{36;35}$ . Likewise, educators could discourage the passive consumption of automatic summaries and explanations. This aligns with the conceptualisation of AI tools as \"thought partners\" that support existing human cognitive processes rather than disrupting them $^{9}$ . Going beyond learning activities, by guiding students to use LLMs more effectively, educators will help students develop their metacognitive skills more generally, which will make them better prepared to use these technologies in the long-term. Furthermore, software could be configured to support these goals by limiting distracting behaviour and encouraging productive use (plausibly by capturing data and using the LLM to provide feedback or nudges to the student based on their LLM interactions).\n\nAnd third, educators could leverage insights from students' interactions with the LLM to better understand what concepts they are struggling with or what they are curious about. This could be done at an individual level but could also be conducted collectively for an entire class, possibly through the use of automated tools that collect and analyse student interactions and then provide data back to the educational instructors in a privacy-protecting way to surface insights. The results could be used to tailor future lessons, activities and group discussions. For example, through analysing the prompts in our experiments, it becomes clear that students were curious about the tenets of communism and why they provoked such fear and opposition in the U.S.\n\nThis research makes several contributions to the growing field of research examining the impact of LLMs in education. While much prior work has focused on the impact of LLMs on task performance and efficiency, the present study investigated aspects that are more fundamental to learning and cognition. In addition, it examined the effects of LLMs within a large sample of secondary school students coming from different school types, rather than amongst students in higher education, who have received much more research attention thus far<sup>15</sup> Such populations can be difficult to reach, especially when several study sessions are involved. In designing the study, we aimed to be authentic to students' experiences in school, ensuring the findings hold practical significance. In particular, we used texts that reflect the topics and difficulty that such students might come across in the classroom, and we compared the effects of LLM use with a learning activity that is, at least until now, commonly used.\n\nOne limitation of the present study is that students received no in-depth training for the different learning activities. While we provided instructions and a demonstration video for how to interact with the LLM and take notes, students did not have an opportunity to practice. This might have\n\nbeen a particular disadvantage for the LLM conditions because students were less familiar with using LLMs than note-taking and might thus not have leveraged the activity as effectively. In addition, the study might have benefited from a baseline or passive reading condition to ascertain whether using the LLM to understand and learn a text provides benefits above passive reading (that is, to gauge its effectiveness per se). Another limitation is that we were practically constrained to a small set of retention and comprehension questions relative to the vast number of potential questions that could have been asked, although we sampled a wide range of content. Thus, we could have underestimated students' learning overall, with the exception of the free recall questions. Furthermore, the study was limited to a single, isolated activity outside of the context of normal use throughout an entire course of study. It is possible that repeated use or use in other settings (e.g., in everyday classrooms or independently for homework, unsupervised) could yield different results. Lastly, while we consider it a strength that we used texts that were appropriate to the student sample, it is possible that LLM usage might be more beneficial for texts that students struggle with, as indicated by a few students who stated they did not know what to ask the LLM. Hence, exploring the effects of LLM use for texts that go beyond students' current capabilities could further expand our understanding of potential applications.\n\nIt is crucial for future research to explore which ways of interacting with LLMs most effectively enhance learning outcomes. Future research must also explore the long-term consequences of LLM integration in learning contexts, particularly its impact on reading skills, independent problem-solving, and metacognition. Additionally, it will become vital to understand how these tools influence societal perceptions of effort, expertise, and achievement. The evolving role of LLMs and generative AI technology may shift the definition of essential expertise and change the landscape of necessary competencies across various fields<sup>8</sup>. Moving forward, it is vital for educators and society to identify which core skills remain indispensable in this new environment and to develop pedagogical strategies that ensure their preservation and growth<sup>9</sup>. This research marks only the beginning of understanding how to effectively use LLMs to complement existing activities and tools while maintaining students' cognitive engagement.\n\nIn summary, this study provides one of the first large-scale quantitative evidence on the effects of LLMs on reading comprehension and retention. Our findings reaffirm the importance of traditional strategies like note-taking, which foster deep cognitive engagement and strong learning outcomes. At the same time, LLMs introduce new possibilities for learning—offering opportunities to clarify, explore, and contextualise material—but these tools must be used with proper guidance aimed at enhancing, rather than bypassing, active learning. Rather than viewing these tools as a disruption to be resisted, educators and researchers have an opportunity to proactively shape their use to maximise learning potential. By doing so, we can prepare students to thrive in an AI-integrated world while preserving the focus, depth, and curiosity that define meaningful education.\n\n# Materials and Methods\n\nThis study comprised two stages: a piloting stage and a main study. The purpose of the piloting stage was to test the tasks and proposed procedures in the school context and amend them as appropriate. The methods and findings reported here are a part of the main study, which took place between March and July 2024.\n\n# Participants\n\nParticipants were 405 Year 10 students (aged 14-15 years) from seven secondary schools in England. Based on our exclusion criteria (see Supplementary Section 1.1), we retained 344 students for analysis. We made efforts to recruit 600 students but were unable to do so as we could not find enough schools before the start of the summer holidays. Recruitment methods included emailing\n\nschool headteachers in several counties and asking participating schools to contact other schools. The final school sample included three non-selective state schools, two grammar schools (one all girls, one all boys) and two independent schools, located in three different counties.\n\nOnce a school agreed to participate, all Year 10 students were invited to take part through the school's project lead. Information sheets were shared with students and their parents/guardians, after which both were asked to provide their informed written consent using an online Microsoft form. This study was conducted in line with the British Educational Research Association's  $^{65}$  ethical guidelines. Ethical approval was provided by the research ethics committees of the researchers' institutions.\n\n# Experimental design and procedure\n\nThe study was a pre-registered randomised controlled experiment with within- and between-participant design elements, as illustrated in Figure 5. Conducted over two sessions spaced three days apart, the experiment consisted of a learning session followed by a test session.\n\nLearning Session: In the learning session, students were tasked with understanding and learning two text passages on different history topics (Passage A and Passage B). Each passage was studied using a specific active learning activity (condition). The three conditions were:\n\n- LLM: Students were asked to use an LLM chatbot we created to help them understand and learn the passage.  \n- Notes: Students were asked to take notes to help them understand and learn the passage.  \n- LLM+Notes: Students were asked to use our LLM chatbot as well as take notes to help them understand and learn the passage.\n\nStudents were randomly assigned to one of two groups:\n\n- Group 1: Exposed to the LLM and Notes conditions.  \n- Group 2: Exposed to the  $LLM$  and  $LLM+Notes$  conditions.\n\nRandomisation assigned 184 students to Group 1 (53.5%) and 160 to Group 2 (46.5%). The order of conditions and passages was randomised. During this session, students also completed survey questions about their learning experiences.\n\nTest Session: In the test session, students answered comprehension and retention questions about the two passages (with passage order randomised) and completed survey questions regarding their general characteristics.\n\nTiming: Students spent a mean of approximately 35 minutes on the learning session and 30 minutes on the test session.\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/b21bdd2e3d49ceb66072818fc8bb684298786b88b09834ba3fb45c8e408c61ce.jpg)  \nRandomised order of group, condition and passage\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/b9b81a2d9ef90ec106dc670f00146ef1702cc9c8dc0607a32f8ae05c0131d727.jpg)  \nRandomised order of passage  \nFigure 5: Study design illustrating the activities and their order during Session 1 and 2.\n\n# Setup and system\n\nBoth sessions took place in schools during regular school hours. Groups of students participated simultaneously in classrooms, with each student completing the sessions on an individual laptop or computer. At the start of each session, the experimenter or teacher read out a script with introductory instructions. They also monitored students during the entire session and answered their questions.\n\nThe experiment was a web app hosted on github.com that students accessed via the browser. For the LLM functionality in Session 1, the app made backend calls to private Azure Functions that accessed an Azure-hosted instance of OpenAI's GPT-3.5 turbo model. The LLM interactions were limited to Azure and did not go back to OpenAI. Participants could issue a maximum of 20 prompts. The LLM was customised with a meta-prompt that was not visible to students (\"You are an AI chat bot that helps students read and comprehend the following passage: <text> Students can use this tool to define unfamiliar words, explain concepts, or summarise key points of the passage.\"). Figure 6 illustrates the task screen for the LLM+Notes condition. For the Notes and\n\n# Apartheid in South Africa\n\nIn 1910, four British colonies joined to create the \"Union of South Africa.\" The Union was part of the British Empire, and later became the Republic of South Africa that we know today. After World War II, many countries that were controlled by Western nations, including South Africa, wanted independence. The South African government wanted to break free from the British Empire. However, for Black South Africans, the main struggle was against the discrimination by White South Africans who were of British and Dutch descent.\n\nIn 1948, the National Party came to power. This new government formalised the discrimination and racial separation in a system called 'apartheid'. It lasted for over 40 years, during which many unfair laws were passed. For example, every citizen had to be classified by their skin colour, people of different skin colours were not allowed to marry each other, and people were forced to live in specific areas based on their skin colour. More than 3.5 million people of colour were forced to leave their homes, and many were pushed into poverty.\n\nAnti-apartheid groups like the African National Congress (ANC) at first only used peaceful protest. This changed after the Sharpeville Massacre in 1960 when police killed black people that were peacefully protesting outside the police station. Activists now also turned to violence, such as sabotage and attacks on police and military. In response, the government banned anti-apartheid groups. In the decades that followed, anti-apartheid activists faced arrests, prison, and even execution. For example, Nelson Mandela, the leader of the ANC, was in prison for 27 years.\n\nMore and more countries criticised apartheid and used sanctions and boycotts against South Africa. Horrific events at the Soweeto Youth Uprising in 1976 also gained global attention. Black students peacefully protested a new law that forced them to study in Afrikaans, the language of the Dutch colonisers. The police killed more than 100 teenagers. Growing pushback from outside and within South Africa put pressure on the government. Finally, Nelson Mandela was freed from prison, which started negotiations to end apartheid. The elections in 1994 granted all South African citizens, including Black citizens, voting rights. As a result, Mandela became the first democratically elected president. This marked the end of apartheid. However, even today, many Black South Africans still feel the negative effects of apartheid.\n\n# AI Chatbot ②\n\nYou can ask 20 more questions.\n\n# Notepad\n\n![](/uploads/images/f475412b-8a8f-4871-a7dc-fa8df5df42cb/34bb33463af6cbdc665c50ca9aa10ad1e76195cb893c9f0d2effdf2c955d4149.jpg)  \nFigure 6: Example task screen for the LLM+Notes condition.\n\nWhen you are finished with the task,\n\nclick continue.\n\nCONTINUE (12:29)\n\n#\n\nthe LLM conditions, only the notepad or chatbot was displayed, respectively.\n\n# Learning task and materials (Session 1)\n\nIn the learning session, students read two passages on a history topic, each with a different learning activity. They were asked to understand and learn the content of the texts as best as they could. Notably, students had not been told that they would be tested on the materials. For each task, they first received instructions (see Supplementary Section 2.6 about the value of active reading, what it involves, and how the given reading activity might support active reading). They then received more detailed task instructions describing specific strategies, which were followed by a video demonstration of the task and interface. The suggested strategies were based on the active reading and comprehension literature[29;35;36;66]. The content and wording of the instructions for the three conditions were kept as similar as possible. Once the task started, students needed to remain on the task page for 10 (minimum) to 15 (maximum) minutes.\n\nEach student read two expository text passages. Each passage covered a single topic which was included in at least one of the UK exam boards' GCSE History specifications: Apartheid in South Africa (Passage A) and The Cuban Missile Crisis (Passage B). The passages were adapted from two OpenStax textbooks (World History, Volume 2: from 1400; U.S. History). Substantial adaptations were made to ensure that the content and language difficulty as well as text features were comparable and appropriate for Year 10 students. Passages A and B had four paragraphs each and were nearly equal length (386 and 385 words), average word length (5.3 and 4.8 characters), word complexity (i.e., the average position of the words in the 10,000 most frequent English words list, 1986 and 1927), number of sentences (both 26) and CEFR level (both C1 – upper intermediate).\n\nTable 2: Question types and scoring for literal retention, comprehension, and free recall  \n\n<table><tr><td>Outcome</td><td>Question Type (N Questions per Text)</td><td>Scoring</td><td>Maximum score</td></tr><tr><td rowspan=\"2\">Literal retention</td><td>Short response - Cued recall (8)</td><td>For each literal piece of information:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>10</td></tr><tr><td>Multiple choice with four response options - Recognition (10)</td><td>0 - missing or incorrect1 - correct</td><td>10</td></tr><tr><td>Comprehension</td><td>Short response - Cued recall (3)</td><td>For each idea:0 - missing, incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>12</td></tr><tr><td>Free recall</td><td>Open response (1)</td><td>For each literal piece of information/idea:0 - incorrect or irrelevant0.5 - incomplete or partially correct1 - correct</td><td>50</td></tr></table>\n\nNote: Two of the eight \"Short response - Cued recall\" questions for literal retention are worth two points each.\n\nWe divided each passage into 50 main ideas to ensure comparability and to aid scoring.\n\n# Test task and materials (Session 2)\n\nIn the test session, students were told that they would answer some questions about the passages they read in Session 1 as well as some general questions about the task and themselves. For each passage, there were 22 test questions assessing literal retention, comprehension and free recall. Table2 provides an overview of how the different constructs were assessed. As pre-registered, we used a single literal retention score, which was the sum of the short response and multiple-choice scores. The question order for both passages was free response, comprehension, literal retention (cued recall) and, finally, literal retention (recognition). Students had to spend at least three minutes and a maximum of five minutes on the free-recall questions. Questions were carefully sequenced and separated by screens where needed to avoid that previous questions would provide cues for later questions. Example questions can be found in Supplementary Table 11.\n\nLiteral retention questions required literal recall or recognition of information from the passage to provide a correct response. In order to succeed, students did not need background knowledge beyond understanding the vocabulary used in the passage. They did not need to make any knowledge-based inferences (elaborations), and no or only minimal text-based (bridging) inferences, such as connecting two consecutive sentences. Accordingly, literal retention questions targeted the surface and textbase level of representation.\n\nIn contrast, comprehension questions probed for deeper comprehension as they required students to make bridging inferences to connect information from several different locations in the text. Participants needed to make knowledge-based inferences to earn more points, inferring information that was implied but not explicitly stated. Accordingly, comprehension questions targeted the situation-model level of representation.\n\nThe short response and open response questions were scored by three independent raters who were PhD students in Education and/or Psychology who were blind to condition. They were trained to use a scoring scheme that provided general instructions, rules, and detailed explanations and examples for each question. As part of the training, and to demonstrate consistent and accurate use of the scheme, raters scored responses from 25 students and received feedback. Each rater then independently scored the full set of responses, including the questions for both passages, from approximately 140 students.\n\nTo assess inter-rater reliability, the full set of responses from 35 students (approximately  $10\\%$  of the sample) was scored by all three raters. Reliability was evaluated using the intraclass-correlation coefficient (ICC) with a two-way model<sup>67</sup>. We measured absolute agreement and applied the single\n\nmeasure approach as we ultimately used scores from a single rater for all but the 35 students in the reliability sample. For those students, we used the median of the three ratings in subsequent analyses. The inter-rater reliabilities for the combined cued-recall retention scores (one for Passage A and one for Passage B), the combined comprehension scores, and the free recall scores ranged between .97 and .99, indicating excellent reliability $^{67}$ . The lower bounds of the  $95\\%$  confidence intervals were all above the .90 threshold for excellent reliability (see Supplementary Table 12).\n\n# Survey questions\n\nAll questions and response scales can be found in Supplementary Section 2.9. After each task in Session 1, students were asked to self-report on: the difficulty of the text and their familiarity with, and interest in, the topic; enjoyment, difficulty, and helpfulness of the learning activity, and likelihood of its future use; and the overall interest in the task, effort expenditure, and perceived task performance. Students were also asked to indicate whether they preferred any of the learning activities and why, whether they had ever used AI chatbots and if so, with what frequency, and, lastly, how often they had used these learning activities when reading a text for school.\n\nAfter each test in Session 2, students were asked to rate their perceived test performance. At the end of the session, they were asked to indicate whether they had engaged in any learning related to the two texts in between sessions. Students were also asked to report their gender, their English language status, and whether they were taking GCSE History.\n\nIn addition, Free School Meals (FSM) eligibility data was obtained from schools as a measure of student socioeconomic disadvantage $^{68}$ . This is because eligibility for FSM is typically based on family income and other socioeconomic factors.\n\n# Analytic strategies\n\nWe did not deviate from our pre-registered analyses other than described here. First, we extended analyses to conduct qualitative analyses exploring why students preferred one learning activity over another. Second, while we initially planned to explore interaction effects between learning conditions and Gender, EAL, FSM, History GCSE, and School type, we did not do so given our smaller than planned sample size.\n\nQuantitative analyses were run with Python 3.11 and R 4.4.2. We used a significance level of 0.05 (two-tailed) for all analyses. Effect sizes were estimated using Cohen's d, calculated as the mean difference divided by the standard deviation of paired differences for each variable.\n\n# Estimation of condition effects on text comprehension and retention\n\nMissing data handling There were no missing data on the dependent variables because participants were excluded if they did not complete both tests (see exclusion criteria) and because any missing responses on individual questions were scored as 0 points. Missingness in covariates was minimal and only occurred for the variables Gender, EAL and History GCSE  $(5.23\\%, 1.16\\%$  and  $1.16\\%$ , respectively). Missing data were handled using multiple imputation by chained equations (MICE) using the 'mice' package. Models were fitted on five imputed datasets and the results were pooled for combined estimates.\n\nMixed-effects regression We ran three linear mixed-effects regression models using the 'lme4' package, one for each outcome (i.e., literal retention, comprehension, free recall), where students were modelled as a random effect. Note that we pre-registered the regression for free recall as a secondary analysis but we are reporting it alongside the other outcomes for simplicity. The regression specification was as follows:\n\n$$\n\\begin{array}{l} Y _ {i j} = \\beta_ {0} + \\beta_ {1} \\text {C o n d i t i o n} _ {i j} + \\beta_ {2} \\text {G r o u p} _ {i j} + \\beta_ {3} \\text {S c h o o l} _ {i j} + \\beta_ {4} \\text {T e x t} _ {i j} + \\beta_ {5} \\text {T a k} _ {-} \\text {O r d e r} _ {i j} \\\\ + \\beta_ {6} \\text {T e s t} _ {-} \\operatorname {O r d e r} _ {i j} + \\beta_ {7} \\operatorname {G e n d e r} _ {i j} + \\beta_ {8} \\operatorname {F S M} _ {i j} + \\beta_ {9} \\operatorname {E A L} _ {i j} + \\beta_ {1 0} \\operatorname {H i s t o r y} _ {i j} + u _ {i j} + \\epsilon_ {i j} \\\\ \\end{array}\n$$\n\nWhere:\n\n-  $Y_{ij}$  represents the outcome for student  $i$  in condition  $j$ .  \n-  $\\beta_0$  represents the intercept of the model.  \n-  $\\beta_{1}$  to  $\\beta_{10}$  represent the coefficients for the fixed effects:\n\n- Condition: A categorical variable with three levels (0 = LLM, 1 = Notes, 2 = LLM+Notes).  \n- Group: A binary variable indicating group membership.  \n- School: A categorical variable with seven levels indicating school membership.  \n- Text: A binary variable indicating which text student  $i$  studied in condition  $j$ .  \n- Task order: A binary variable indicating whether student  $i$  did condition  $j$  first or second.  \n- Test order: A binary variable indicating whether the text was tested first or second.  \n- Gender: A categorical variable with four levels (0 = female, 1 = male, 2 = other, 3 = prefer not to say).  \n- FSM: A binary variable indicating whether the student received free school meals or not.  \n- EAL: A categorical variable indicating students' English language status (0 = first language, 1 = bilingual, 2 = other)  \n- History: A binary variable indicating whether or not students take History GCSEs.\n\n-  $u_{ij}$  represents the random intercept for each student.  \n-  $\\epsilon_{ij}$  represents the error term for student  $i$  in condition  $j$ .\n\nAs depicted in Figure 1, free recall scores were non-normally distributed, so we ran additional non-parametric permutation tests. Specifically, we used the 'infer' package in R to conduct paired permutation tests at the student level. These tests compared free recall scores between the LLM and Notes conditions in Group 1, and between the LLM and LLM+Notes conditions in Group 2. For each student, we calculated the difference between their two scores and averaged these differences across students. This test statistic was compared to a null distribution, generated by repeatedly randomising the signs of within-student differences and computing means. The process was repeated across all instances of imputed data, and the results were summarised by taking the median p-value across instances to yield a pooled p-value. Doing so gives similar findings to the mixed effects model: in Group 1 we find a significant difference for free recall between the Notes and LLM conditions  $(p = 0.02)$ , but do not find evidence for a significant difference in free recall for Group 2 between the LLM+Notes vs. LLM conditions  $(p = 0.80)$ .\n\n# Qualitative exploration of student prompts\n\nTo provide potential explanations for the effects of the LLM condition on reading comprehension and retention, we sought to understand what kind of prompts students made when using the LLM in planned exploratory analyses. The LLM prompts were analysed using a hierarchical coding scheme through GPT-4 in an automated Python script accessing the Azure OpenAI's API (deployment dated 2024-06-01). Temperature was set to 0 for deterministic outputs with a narrow sampling range (top-p=0.1) to ensure consistent classifications. The model was provided with detailed instructions and examples for each category, along with both texts that students were studying. Each prompt could receive multiple sub-codes.\n\nThe hierarchical coding scheme was developed through several iterations. The initial version was deductively and inductively developed by a researcher using active reading literature, students' task instructions, and piloting work. This scheme was expanded based on the API's suggestions and the API was then asked to code the data using the coding scheme. The researchers then iteratively refined the coding scheme based on checking portions of the API output. They merged, deleted, and added codes as needed and adapted code descriptions and examples to improve the quality of the API output. Finally, one of the researchers manually checked the API output for 500 prompts (approximately  $10\\%$  of the data) and found an error rate of  $5.6\\%$ . This was deemed to be an acceptable level. The assigned codes for these 500 prompts were adjusted where necessary, and the rest of the API output was left as it was. The final coding schemes for student prompts can be found in Supplementary Table 20.\n\n# Quantitative exploration of students' learning experience\n\nAs planned we explored a range of variables capturing students' learning experiences. More specifically, we compared students' learning experiences when using LLM vs. Notes and LLM vs. LLM+Notes using paired  $t$ -tests. We applied Bonferroni corrections to adjust for multiple comparisons. The  $t$ -tests were conducted using the 'tidyverse' package.\n\n# Qualitative exploration of students' activity preferences\n\nWe explored students' open response explanations for preferring one learning activity over another. The explanations were analysed by two of the authors with help from the API described above. Four preference groups were separately analysed:\n\n1. LLM over Notes,  \n2. Notes over LLM,  \n3. LLM over  $\\mathrm{LLM} + \\mathrm{Notes}$ , and  \n4. LLM+Notes over LLM.\n\nEach preference group had its own coding scheme which only included explanations for preferring the favoured activity over the non-favoured activity (i.e., benefits of note-taking were not coded if the student preferred the LLM over Notes). The initial schemes were developed by manually and deductively coding approximately  $30\\%$  of responses of each preference group. Several codes could be applied to each response. The initial coding schemes, including the category label, description and examples were provided to the API alongside the data and general coding instructions. The API did not suggest any further helpful codes. The researchers then iteratively refined the coding schemes by manually checking portions of the API output. They merged, deleted, and added codes as well as refined code descriptions and examples before the API analysis was rerun. This process was repeated until both researchers were satisfied with the coding schemes. Due to the\n\nsmall number of responses that had to be coded ( $n = 278$ ), one researcher checked the entire API output and made adjustments where necessary. The final coding schemes for activity preferences can be found in Supplementary Section 2.11.\n\n# Data availability\n\nAll quantitative data will be made available upon publication. We will not provide the following qualitative data as that would risk sharing identifiable information: Students' LLM interactions (only the applied codes will be shared), students' notes, students' activity preferences (only applied codes will be shared).\n\n# Code availability\n\nThe corresponding code will be shared upon publication.\n\n# Ethics declarations\n\n# Competing interests\n\nSome of the authors conduct research at a company that invests in generative AI and develops technology using generative AI models as a core component. The other authors are part of a publishing, assessment and learning organisation which increasingly uses AI in developing and operating assessment and learning products and services. However, this work is not connected to any specific product or monetisation efforts for either organisation.\n\n# Acknowledgements\n\nWe thank Dr Tom Benton and Dr Matthew Carroll for their valuable advice on the analyses conducted in this study.\n\n# Supplementary Material\n\n# Table of Contents\n\n# Supplementary Information\n\n- Participant Exclusion Criteria\n\n# Supplementary Tables\n\n- Student Characteristics  \nFamiliarity with Learning Activities  \n- Descriptive Statistics  \n- Mixed Effects Regression Results  \nBehavioural Engagement  \n- Introduction to Active Reading  \n- Introduction to Learning Activity\n\n- Specific instructions by Condition  \nTest Questions  \n- Inter-rater Reliability Results  \nSurvey Questions and Response Scales  \nSurvey Questions and Response Scales (session 2)  \n- Learning Experiences and Perceptions  \nCoding Scheme Activity Preferences  \nCoding scheme: LLM over Notes preferences  \nCoding scheme: Notes over LLM preferences  \nCoding scheme: LLM+Notes over LLM preferences  \nCoding Scheme Prompt Interactions  \n- Frequencies of Prompt Types\n\n# References\n\n[1] Cecilia Ka Yuk Chan. A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1):38, July 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00408-3. URL https://doi.org/10.1186/s41239-023-00408-3.  \n[2] Abdulhadi Shoufan. Exploring Students' Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey. IEEE Access, 11:38805-38818, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2023.3268224. URL https://ieeexplore.ieee.org/document/10105236/?arnumber=10105236. Conference Name: IEEE Access.  \n[3] K. Aleksić-Maslac, F. Borović, and Z. Biočina. PERCEPTION AND USAGE OF CHAT GPT IN THE EDUCATION SYSTEM. INTED2024 Proceedings, pages 1842-1848, 2024. ISSN 2340-1079. doi: 10.21125/inted.2024.0511. URL https://library.iated.org/view/ ALEKSICMASLAC2024PER. Conference Name: 18th International Technology, Education and Development Conference ISBN: 9788409592159 Meeting Name: 18th International Technology, Education and Development Conference Place: Valencia, Spain Publisher: IATED.  \n[4] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. Where to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal Machine Intelligence. ACM Transactions on Computer-Human Interaction, February 2022. ISSN 1073-0516. doi: 10.1145/3511599. URL https://dl.acm.org/doi/10.1145/3511599. Just Accepted.  \n[5] Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. Student perspectives on the use of generative artificial intelligence technologies in higher education. International Journal for Educational Integrity, 20(1):2, February 2024. ISSN 1833-2595. doi: 10.1007/s40979-024-00149-4. URL https://doi.org/10.1007/s40979-024-00149-4.\n\n[6] Duong Hoai Lan and Tran Minh Tung. Analyzing the Impact of Chat-GPT Usage by University Students in Vietnam. Migration Letters, 20(S10):259-268, November 2023. ISSN 1741-8992. doi: 10.59670/ml.v20iS10.5134. URL https://migrationletters.com/index.php/ml/article/view/5134. Number: S10.  \n[7] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnmann, Eyke Hüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel, Jürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 2023.  \n[8] Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, and Manuel Ninaus. Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning. Educational Psychology Review, 36(1):25, February 2024. ISSN 1573-336X. doi: 10.1007/s10648-024-09868-z. URL https://doi.org/10.1007/s10648-024-09868-z.  \n[9] Yogesh K. Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M. Baabdullah, Alex Koohang, Vishnupriya Raghavan, Manju Ahuja, Hanaa Albanna, Mousa Ahmad Albashrawi, Adil S. Al-Busaidi, Janarthanan Balakrishnan, Yves Barlette, Sriparna Basu, Indranil Bose, Laurence Brooks, Dimitrios Buhalis, Lemuria Carter, Soumyadeb Chowdhury, Tom Crick, Scott W. Cunningham, Gareth H. Davies, Robert M. Davison, Rahul De, Denis Dennehy, Yanqing Duan, Rameshwar Dubey, Rohita Dwivedi, John S. Edwards, Carlos Flavian, Robin Gauld, Varun Grover, Mei-Chih Hu, Marijn Janssen, Paul Jones, Iris Junglas, Sangeeta Khorana, Sascha Kraus, Kai R. Larsen, Paul Latreille, Sven Laumer, F. Tegwen Malik, Abbas Mardani, Marcello Mariani, Sunil Mithas, Emmanuel Mogaji, Jeretta Horn Nord, Siobhan O'Connor, Fevzi Okumus, Margherita Pagani, Neeraj Pandey, Savvas Papagiannidis, Ilias O. Pappas, Nishith Pathak, Jan Pries-Heje, Ramakrishnan Raman, Nripendra P. Rana, Sven-Volker Rehm, Samuel Ribeiro-Navarrete, Alexander Richter, Frantz Rowe, Suprateek Sarker, Bernd Carsten Stahl, Manoj Kumar Tiwari, Wil van der Aalst, Viswanath Venkatesh, Giampaoloiglia, Michael Wade, Paul Walton, Jochen Wirtz, and Ryan Wright. Opinion Paper: \"So what if ChatGPT wrote it?\" Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71:102642, August 2023. ISSN 0268-4012. doi: 10. 1016/j.ijinfomgt.2023.102642. URL https://www.sciencedirect.com/science/article/ pii/S0268401223000233.  \n[10] Jun-Jie Zhu, Jinyue Jiang, Meiqi Yang, and Zhiyong Jason Ren. ChatGPT and Environmental Research. *Environmental Science & Technology*, 57(46):17667-17670, November 2023. ISSN 0013-936X. doi: 10.1021/acs.est.3c01818. URL https://doi.org/10.1021/acs.est.3c01818. Publisher: American Chemical Society.  \n[11] Alex Barrett and Austin Pack. Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1):59, November 2023. ISSN 2365-9440. doi: 10.1186/s41239-023-00427-0. URL https://doi.org/10.1186/s41239-023-00427-0.  \n[12] Aiste Steponenaite and Basel Barakat. Plagiarism in AI Empowered World. In Margherita Antona and Constantine Stephanidis, editors, Universal Access in Human-Computer Interaction, pages 434–442, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-35897-5. doi: 10.1007/978-3-031-35897-5_31.\n\n[13] Ofcom. Online nation 2024 report. Technical report, Ofcom, November 2024. URL https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/.  \n[14] Walton Family Foundation. Teachers and Students Embrace ChatGPT for Education. Technical report, Walton Family Foundation, March 2023. URL https://www.waltonfamilyfoundation.org/learning/teachers-and-students-embrace-chatgpt-for-education. Section: Learning.  \n[15] Ruiqi Deng, Maoli Jiang, Xinlu Yu, Yuyan Lu, and Shasha Liu. Does chatgpt enhance student learning? a systematic review and meta-analysis of experimental studies. Computers Education, 227:105224, 2025. ISSN 0360-1315. doi: https://doi.org/10.1016/j.compedu.2024.105224. URL https://www.sciencedirect.com/science/article/pii/S0360131524002380.  \n[16] Jeffrey R. Binder and Rutvik H. Desai. The neurobiology of semantic memory. Trends in Cognitive Sciences, 15(11):527-536, November 2011. ISSN 1879-307X. doi: 10.1016/j.tics.2011.10.001.  \n[17] Danielle S. McNamara and Joe Magliano. Toward a comprehensive model of comprehension. In The psychology of learning and motivation, Vol. 51, The psychology of learning and motivation, pages 297-384. Elsevier Academic Press, San Diego, CA, US, 2009. ISBN 978-0-12-374489-0. doi: 10.1016/S0079-7421(09)51009-2.  \n[18] Walter Kintsch. The role of knowledge in discourse comprehension: A construction-integration model. *Psychological Review*, 95(2):163–182, 1988. ISSN 1939-1471. doi: 10.1037/0033-295X.95.2.163. Place: US Publisher: American Psychological Association.  \n[19] Gregory Hickok and David Poeppel. The cortical organization of speech processing. Nature Reviews Neuroscience, 8(5):393-402, May 2007. ISSN 1471-0048. doi: 10.1038/nrn2113. URL https://www.nature.com/articles/nrn2113. Publisher: Nature Publishing Group.  \n[20] Evelina Fedorenko, Anna A. Ivanova, and Tamar I. Regev. The language network as a natural kind within the broader landscape of the human brain. Nature Reviews Neuroscience, 25 (5):289-312, May 2024. ISSN 1471-0048. doi: 10.1038/s41583-024-00802-4. URL https://www.nature.com/articles/s41583-024-00802-4. Publisher: Nature Publishing Group.  \n[21] Rolf A. Zwaan and Gabriel A. Radvansky. Situation models in language comprehension and memory. *Psychological Bulletin*, 123(2):162–185, 1998. ISSN 1939-1455. doi: 10.1037/0033-2909.123.2.162. Place: US Publisher: American Psychological Association.  \n[22] Junhua Ding, Keliang Chen, Haoming Liu, Lin Huang, Yan Chen, Yingru Lv, Qing Yang, Qihao Guo, Zaizhu Han, and Matthew A. Lambon Ralph. A unified neurocognitive model of semantics language social behaviour and face recognition in semantic dementia. Nature Communications, 11(1):2595, May 2020. ISSN 2041-1723. doi: 10.1038/s41467-020-16089-9. URL https://www.nature.com/articles/s41467-020-16089-9. Publisher: Nature Publishing Group.  \n[23] Kate Cain and Jane Oakhill. Reading Comprehension Difficulties: Correlates, Causes, and Consequences. In *Children's comprehension problems in oral and written language: A cognitive perspective*, Challenges in language and literacy, pages 41-75. The Guilford Press, New York, NY, US, 2007. ISBN 978-1-59385-443-0.  \n[24] Meredithyth Daneman and Patricia A. Carpenter. Individual differences in working memory and reading. Journal of Verbal Learning & Verbal Behavior, 19(4):450-466, 1980. ISSN 0022-5371. doi: 10.1016/S0022-5371(80)90312-6. Place: Netherlands Publisher: Elsevier Science.\n\n[25] Charles A. Perfetti, Nicole Landi, and Jane Oakhill. The Acquisition of Reading Comprehension Skill. In *The science of reading: A handbook*, Blackwell handbooks of developmental psychology, pages 227-247. Blackwell Publishing, Malden, 2005. ISBN 978-1-4051-1488-2. doi: 10.1002/9780470757642.ch13.  \n[26] Jane V. Oakhill, Molly S. Berenhaus, and Kate Cain. Children's reading comprehension and comprehension difficulties. In *The Oxford handbook of reading*, Oxford library of psychology, pages 344–360. Oxford University Press, New York, NY, US, 2015. ISBN 978-0-19-932457-6. doi: 10.1093/oxfordhb/9780199324576.001.0001.  \n[27] Keith E. Stanovich. Matthew effects in reading: Some consequences of individual differences in the acquisition of literacy. Reading Research Quarterly, 21(4):360-407, 1986. ISSN 1936-2722. doi: 10.1598/RRQ.21.4.1. Place: US Publisher: International Reading Association.  \n[28] A. C. Graesser, M. Singer, and T. Trabasso. Constructing inferences during narrative text comprehension. *Psychological Review*, 101(3):371–395, July 1994. ISSN 0033-295X. doi: 10.1037/0033-295x.101.3.371.  \n[29] Danielle S. McNamara, Irwin B. Levinstein, and Chutima Boonthum. iSTART: Interactive strategy training for active reading and thinking. Behavior Research Methods, Instruments, 3 Computers, 36(2):222-233, May 2004. ISSN 1532-5970. doi: 10.3758/BF03195567. URL https://doi.org/10.3758/BF03195567.  \n[30] John T. Guthrie and Allan Wigfield. Engagement and motivation in reading. In Handbook of reading research, Vol. III, pages 403-422. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, US, 2000. ISBN 978-0-8058-2398-1 978-0-8058-2399-8.  \n[31] Tracy Linderholm, Sandra Virtue, Yuhtsuen Tzeng, and Paul van den Broek. Fluctuations in the Availability of Information During Reading: Capturing Cognitive Processes Using the Landscape Model. pages 165-186. December 2018. ISBN 978-1-315-04610-5. doi: 10.4324/9781315046105-5.  \n[32] Fergus I. M. Craik. Levels of processing: Past, present . . . and future? Memory, 10(5-6): 305-318, 2002. ISSN 1464-0686. doi: 10.1080/09658210244000135. Place: United Kingdom Publisher: Taylor & Francis.  \n[33] Fergus I. M. Craik and Endel Tulving. Depth of processing and the retention of words in episodic memory. Journal of Experimental Psychology: General, 104(3):268-294, 1975. ISSN 1939-2222. doi: 10.1037/0096-3445.104.3.268. Place: US Publisher: American Psychological Association.  \n[34] John R. Anderson. A spreading activation theory of memory. Journal of Verbal Learning and Verbal Behavior, 22(3):261-295, June 1983. ISSN 0022-5371. doi: 10.1016/S0022-5371(83)90201-3. URL https://www.sciencedirect.com/science/article/pii/S0022537183902013.  \n[35] Danielle S. McNamara, editor. Reading comprehension strategies: Theories, interventions, and technologies. Lawrence Erlbaum Associates Publishers, Mahwah, NJ, 2007.  \n[36] Michelene T. H. Chi. Active-Constructive-Interactive: A Conceptual Framework for Differentiating Learning Activities. Topics in Cognitive Science, 1(1):73-105, 2009. ISSN 1756-8765. doi: 10.1111/j.1756-8765.2008.01005.x. URL https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01005.x. _eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01005.x.\n\n[37] Rose Luckin, Wayne Holmes, and Laurie B Forcier. Intelligence Unleashed: An argument for AI in Education. Technical report, Open Ideas at Pearson / UCL, 2016. URL https://www.pearson.com/content/dam/corporate/global/pearson-dot-com/files/innovation/Intelligence-Unleashed-Publication.pdf.  \n[38] Wayne Holmes, Maya Bialik, and Charles Fadel. Artificial Intelligence in Education. Promise and Implications for Teaching and Learning. March 2019. ISBN 978-1-79429-370-0.  \n[39] Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, and Francesco Costantino. Students' use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances. Computers and Education: Artificial Intelligence, 5:100172, October 2023. doi: 10.1016/j.caeai.2023.100172.  \n[40] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models. In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, pages 27-43, Lugano and Virtual Event Switzerland, August 2022. ACM. ISBN 978-1-4503-9194-8. doi: 10.1145/3501385.3543957. URL https://dl.acm.org/doi/10.1145/3501385.3543957.  \n[41] Harsh Kumar, David M Rothschild, Daniel G Goldstein, and Jake M Hofman. Math Education With Large Language Models: Peril or Promise? 2023.  \n[42] John Sweller, Jeroen J. G. van Merrienboer, and Fred Paas. Cognitive architecture and instructional design: 20 years later. Educational Psychology Review, 31(2):261-292, 2019. ISSN 1573-336X. doi: 10.1007/s10648-019-09465-5. Place: Germany Publisher: Springer.  \n[43] Richard E. Mayer. Should There Be a Three-Strikes Rule Against Pure Discovery Learning? American Psychologist, 59(1):14-19, 2004. ISSN 1935-990X. doi: 10.1037/0003-066X.59.1.14. Place: US Publisher: American Psychological Association.  \n[44] Fergus I. M. Craik and Robert S. Lockhart. Levels of processing: A framework for memory research. Journal of Verbal Learning and Verbal Behavior, 11(6):671-684, December 1972. ISSN 0022-5371. doi: 10.1016/S0022-5371(72)80001-X. URL https://www.sciencedirect.com/science/article/pii/S002253717280001X.  \n[45] Xiaoming Zhai, Matthew Nyaaba, and Wenchao Ma. Can generative AI and ChatGPT outperform humans on cognitive-demanding problem-solving tasks in science?, January 2024. URL http://arxiv.org/abs/2401.15081. arXiv:2401.15081.  \n[46] Faycal Farhi, Riadh Jeljeli, Ibtehal Aburezeq, Fawzi Fayez Dweikat, Samer Ali Al-shami, and Radouane Slamene. Analyzing the students' views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artificial Intelligence, 5:100180, January 2023. ISSN 2666-920X. doi: 10.1016/j.caeai.2023.100180. URL https://www.sciencedirect.com/science/article/pii/S2666920X23000590.  \n[47] Hao Yu and Yunyun Guo. Generative artificial intelligence empowers educational reform: current status, issues, and prospects. Frontiers in Education, 8:1183162, June 2023. ISSN 2504-284X. doi: 10.3389/feduc.2023.1183162. URL https://www.frontiersin.org/articles/10.3389/feduc.2023.1183162/full.  \n[48] Elizabeth Ligon Bjork and Robert A. Bjork. Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. In *Psychology and the real world: Essays illustrating fundamental contributions to society*, pages 56-64. Worth Publishers, New York, NY, US, 2011. ISBN 978-1-4292-3043-8.\n\n[49] Michelene Chi, Stephanie Siler, Heisawn Jeong, Takashi Yamauchi, and Robert Hausmann. Learning from human tutoring. Cognitive Science, 25:471-533, July 2001. doi: 10.1016/S0364-0213(01)00044-1.  \n[50] Alvaro Pascual-Leone, Amir Amedi, Felipe Fregni, and Lotfi B. Merabet. The plastic human brain cortex. Annual Review of Neuroscience, 28:377-401, 2005. ISSN 0147-006X. doi: 10.1146/annurev.neuro.27.070203.144216.  \n[51] S. Dehaene and L. Naccache. Towards a cognitive neuroscience of consciousness: basic evidence and a workspace framework. Cognition, 79(1-2):1-37, April 2001. ISSN 0010-0277. doi: 10.1016/s0010-0277(00)00123-2.  \n[52] Keiichi Kobayashi. What limits the encoding eVect of note-taking? A meta-analytic examination. Contemporary Educational Psychology, 2005.  \n[53] Kenneth A. Kiewra. A review of note-taking: The encoding storage paradigm and beyond. Educational Psychology Review, 1(2):147-172, 1989. ISSN 1573-336X. doi: 10.1007/BF01326640. Place: Germany Publisher: Springer.  \n[54] Kenneth A. Kiewra. Investigating notetaking and review: A depth of processing alternative. Educational Psychologist, 20(1):23-32, 1985. ISSN 1532-6985. doi: 10.1207/s15326985ep2001_4. Place: US Publisher: Lawrence Erlbaum.  \n[55] Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky. Note taking, review, memory, and comprehension. The American Journal of Psychology, 124(1):63-73, 2011. ISSN 0002-9556. doi: 10.5406/amerjpsyc.124.1.0063.  \n[56] Dung C. Bui and Joel Myerson. The role of working memory abilities in lecture note-taking. Learning and Individual Differences, 33:12-22, 2014. ISSN 1873-3425. doi: 10.1016/j.lindif.2014.05.002. Place: Netherlands Publisher: Elsevier Science.  \n[57] Ralf Rummer, Judith Schweppe, Kathleen Gerst, and Simon Wagner. Is testing a more effective learning strategy than note-taking? Journal of Experimental Psychology. Applied, 23(3):293-300, September 2017. ISSN 1939-2192. doi: 10.1037/xap0000134.  \n[58] Lisa Geraci, Nikhil Kurpad, Rachel Tirso, Kathryn N. Gray, and Yuxiang Wang. Metacognitive errors in the classroom: The role of variability of past performance on exam prediction accuracy. *Metacognition and Learning*, 2022. doi: 10.1007/s11409-022-09326-7. URL https://doi.org/10.1007/s11409-022-09326-7. Advance online publication.  \n[59] Robert A. Bjork, John Dunlosky, and Nate Kornell. Self-Regulated Learning: Beliefs, Techniques, and Illusions. Annual Review of Psychology, 64(1):417-444, January 2013. ISSN 0066-4308, 1545-2085. doi: 10.1146/annurev-psych-113011-143823. URL https://www.annualreviews.org/doi/10.1146/annurev-psych-113011-143823.  \n[60] Justin Kruger and David Dunning. Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77(6):1121-1134, Dec 1999. doi: 10.1037//0022-3514.77.6.1121.  \n[61] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. The metacognitive demands and opportunities of generative ai. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, CHI '24, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703300. doi: 10.1145/3613904.3642902. URL https://doi.org/10.1145/3613904.3642902.\n\n[62] Axel Grund, Stefan Fries, Matthias Nückles, Alexander Renkl, and Julian Roelle. When is Learning \"Effortful\"? Scrutinizing the Concept of Mental Effort in Cognitively Oriented Research from a Motivational Perspective. Educational Psychology Review, 36(1):11, March 2024. ISSN 1040-726X, 1573-336X. doi: 10.1007/s10648-024-09852-7. URL https://link.springer.com/10.1007/s10648-024-09852-7.  \n[63] Louise Starkey. A review of research exploring teacher preparation for the digital age. Cambridge Journal of Education, 50(1):37-56, 2020. doi: 10.1080/0305764X.2019.1625867.  \n[64] Honghong Wang and Weiping Shi. Practical approaches to integrated values education for foreign language majors. Foreign Language World, (6):38-45, 2021.  \n[65] British Educational Research Association. Ethical Guidelines for Educational Research, fourth edition, 2018. URL https://www.bera.ac.uk/publication/ethical-guidelines-for-educational-research-2018.  \n[66] P. David Pearson, Laura R. Roehler, Janice A. Dole, and Gerald G. Duffy. Developing expertise in reading comprehension: What should be taught? How should it be taught? Technical Report 512, University of Illinois Urbana-Champaign Center for the Study of Reading, 1990. URL https://hdl.handle.net/2142/17648. Publisher: Champaign, Ill.: University of Illinois at Urbana-Champaign, Center for the Study of Reading.  \n[67] Terry K Koo and Mae Y Li. A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research. 2016.  \n[68] Chris Taylor. The reliability of free school meal eligibility as a measure of socio-economic disadvantage: Evidence from the millennium cohort study in wales. *British Journal of Educational Studies*, 66(1):29-51, 2018. doi: 10.1080/00071005.2017.1330464.\n\n# 1 Supplementary Information\n\n# 1.1 Participant Exclusion Criteria\n\nParticipants  $(n = 61)$  were excluded for the following reasons:\n\n1. Did not take part in Session 2 (n=36)  \n2. Did not complete both tasks in Session 1 (and/or withdrew intentionally)  $(n = 2)$  \n3. Stopped Session 2 before attempting all comprehension and retention questions  $(n = 8)$  \n4. Completed Session 2 in 10 minutes or less  $(n = 1)$  \n5. Reported substantially different prior knowledge of the two topics (3-point difference on a 5-point Likert-scale item)  $(n = 13)$  \n6. Cheated during a session (as observed by researcher, including opening a different browser to look up answers, copying answers from others, continuing conversation with neighbours). Responses of suspicious students were scanned and compared with that of other students in the same group. If suspicion confirmed based on responses (e.g., high overlap with a student), these were excluded  $(n = 1)$\n\n# 2 Supplementary Tables\n\n# 2.1 Student Characteristics\n\nTable 3: Student characteristics by group and overall totals (after exclusion,  $\\mathrm{N} = {344}$  )  \n\n<table><tr><td>Characteristic</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td><td>Total\nN students (%)</td></tr><tr><td>Male</td><td>102 (29.7%)</td><td>78 (22.7%)</td><td>180 (52.3%)</td></tr><tr><td>Female</td><td>57 (16.6%)</td><td>63 (18.3%)</td><td>120 (34.9%)</td></tr><tr><td>Other</td><td>1 (0.3%)</td><td>1 (0.3%)</td><td>2 (0.6%)</td></tr><tr><td>Prefer not to say</td><td>2 (0.6%)</td><td>0 (0.0%)</td><td>2 (0.6%)</td></tr><tr><td>FSM_Yes</td><td>9 (2.6%)</td><td>10 (2.9%)</td><td>19 (5.5%)</td></tr><tr><td>FSM_No</td><td>160 (46.5%)</td><td>163 (47.4%)</td><td>323 (93.9%)</td></tr><tr><td>EAL_Yes</td><td>130 (37.8%)</td><td>117 (34.0%)</td><td>247 (71.8%)</td></tr><tr><td>EAL_Other Language</td><td>2 (0.6%)</td><td>3 (0.9%)</td><td>5 (1.5%)</td></tr><tr><td>EAL_Bilingual</td><td>35 (10.2%)</td><td>29 (8.4%)</td><td>64 (18.6%)</td></tr><tr><td>History_Yes</td><td>99 (28.8%)</td><td>80 (23.3%)</td><td>179 (52.0%)</td></tr><tr><td>History_No</td><td>81 (23.5%)</td><td>58 (16.9%)</td><td>139 (40.4%)</td></tr></table>\n\n# 2.2 Familiarity with Learning Activities\n\nTable 4: Frequencies of prior learning activity use  \n\n<table><tr><td>Activity and frequency</td><td>Group 1\nN students (%)</td><td>Group 2\nN students (%)</td></tr><tr><td colspan=\"3\">Note-taking for learning</td></tr><tr><td>Never</td><td>7 (3.8%)</td><td>6 (3.8%)</td></tr><tr><td>Rarely</td><td>34 (18.5%)</td><td>25 (15.6%)</td></tr><tr><td>Sometimes</td><td>47 (25.5%)</td><td>44 (27.5%)</td></tr><tr><td>Often</td><td>69 (37.5%)</td><td>70 (43.8%)</td></tr><tr><td>Always</td><td>22 (12.0%)</td><td>17 (10.6%)</td></tr><tr><td colspan=\"3\">LLM use for learning</td></tr><tr><td>Never</td><td>32 (25.6%)</td><td>19 (18.1%)</td></tr><tr><td>Rarely</td><td>45 (36.0%)</td><td>44 (41.9%)</td></tr><tr><td>Sometimes</td><td>29 (23.2%)</td><td>26 (24.8%)</td></tr><tr><td>Often</td><td>15 (12.0%)</td><td>15 (14.3%)</td></tr><tr><td>Always</td><td>4 (3.2%)</td><td>1 (1.0%)</td></tr><tr><td colspan=\"3\">LLM + Notes for learning</td></tr><tr><td>Never</td><td>-</td><td>1 (1.6%)</td></tr><tr><td>Rarely</td><td>-</td><td>31 (48.4%)</td></tr><tr><td>Sometimes</td><td>-</td><td>23 (35.9%)</td></tr><tr><td>Often</td><td>-</td><td>8 (12.5%)</td></tr><tr><td>Always</td><td>-</td><td>1 (1.6%)</td></tr><tr><td colspan=\"3\">Prior LLM use</td></tr><tr><td>Yes</td><td>125 (70.2%)</td><td>105 (64.0%)</td></tr><tr><td>No</td><td>53 (29.8%)</td><td>59 (36.0%)</td></tr><tr><td colspan=\"3\">Frequency of LLM use amongst users</td></tr><tr><td>Less than once a week</td><td>74 (59.2%)</td><td>68 (64.8%)</td></tr><tr><td>One or two days a week</td><td>28 (22.4%)</td><td>33 (31.4%)</td></tr><tr><td>Three to five days a week</td><td>11 (8.8%)</td><td>5 (4.8%)</td></tr><tr><td>Most days of the week</td><td>12 (9.6%)</td><td>1 (1.0%)</td></tr></table>\n\n# 2.3 Descriptive Statistics\n\nTable 5: Descriptive statistics for comprehension, literal retention, and free recall across conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"4\">Comprehension (max 12 points)</td><td>Notes</td><td>4.89</td><td>2.52</td></tr><tr><td>LLM + Notes</td><td>4.11</td><td>2.65</td></tr><tr><td>LLM only (Group 1)</td><td>4.00</td><td>2.44</td></tr><tr><td>LLM only (Group 2)</td><td>3.80</td><td>2.47</td></tr><tr><td rowspan=\"4\">Literal retention (max 20 points)</td><td>Notes</td><td>10.8</td><td>4.29</td></tr><tr><td>LLM + Notes</td><td>9.68</td><td>4.83</td></tr><tr><td>LLM only (Group 1)</td><td>8.83</td><td>3.96</td></tr><tr><td>LLM only (Group 2)</td><td>8.95</td><td>4.29</td></tr><tr><td rowspan=\"4\">Free recall (max 50 points)</td><td>Notes</td><td>5.36</td><td>5.49</td></tr><tr><td>LLM Group 1</td><td>4.32</td><td>4.15</td></tr><tr><td>LLM Group 2</td><td>4.32</td><td>4.63</td></tr><tr><td>LLM + Notes</td><td>4.20</td><td>5.07</td></tr></table>\n\n# 2.4 Mixed Effects Regression Results\n\nTable 6: Model coefficients for literal retention, comprehension, and free recall  \n\n<table><tr><td>Term</td><td>Estimate</td><td>Std. Error</td><td>95% CI</td><td>Statistic</td><td>df</td><td>p-value</td><td>d</td></tr><tr><td colspan=\"8\">Literal retention</td></tr><tr><td>Intercept</td><td>8.2429</td><td>0.7966</td><td>[6.68, 9.81]</td><td>10.3476</td><td>489.3004</td><td>7.95 × 10-23</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.5668</td><td>0.2752</td><td>[0.03, 1.11]</td><td>2.0597</td><td>660.4521</td><td>0.0398</td><td>0.132</td></tr><tr><td>Condition notes</td><td>1.9188</td><td>0.2559</td><td>[1.42, 2.42]</td><td>7.4974</td><td>663.2789</td><td>2.09 × 10-13</td><td>0.443</td></tr><tr><td>Group 1</td><td>-0.6147</td><td>0.4155</td><td>[-1.43, 0.20]</td><td>-1.4793</td><td>661.9230</td><td>0.1395</td><td>-0.143</td></tr><tr><td>school_id S03</td><td>-0.8645</td><td>0.5993</td><td>[-2.04, 0.31]</td><td>-1.4424</td><td>638.7162</td><td>0.1497</td><td>-0.198</td></tr><tr><td>school_id S01</td><td>-1.9789</td><td>0.8005</td><td>[-3.55, -0.41]</td><td>-2.4720</td><td>657.4886</td><td>0.0137</td><td>-0.465</td></tr><tr><td>school_id S05</td><td>-0.3908</td><td>0.8562</td><td>[-2.07, 1.29]</td><td>-0.4564</td><td>612.9203</td><td>0.6483</td><td>-0.094</td></tr><tr><td>school_id S02</td><td>1.2932</td><td>0.5514</td><td>[0.21, 2.37]</td><td>2.3452</td><td>643.8234</td><td>0.0193</td><td>0.299</td></tr><tr><td>school_id S07</td><td>2.7561</td><td>1.1408</td><td>[0.52, 4.99]</td><td>2.4160</td><td>663.8251</td><td>0.0160</td><td>0.623</td></tr><tr><td>school_id S04</td><td>-4.7045</td><td>0.8102</td><td>[-6.29, -3.12]</td><td>-5.8067</td><td>641.0030</td><td>1.00 × 10-8</td><td>-1.075</td></tr><tr><td>Text Cuba</td><td>1.5218</td><td>0.1880</td><td>[1.15, 1.89]</td><td>8.0952</td><td>663.5151</td><td>2.74 × 10-15</td><td>0.351</td></tr><tr><td>Task_order 0</td><td>0.2310</td><td>0.1880</td><td>[-0.14, 0.60]</td><td>1.2283</td><td>659.9704</td><td>0.2198</td><td>0.052</td></tr><tr><td>Test_order 0</td><td>0.5186</td><td>0.1875</td><td>[0.15, 0.89]</td><td>2.7656</td><td>663.7540</td><td>0.0058</td><td>0.119</td></tr><tr><td>Gender (Male)</td><td>0.8396</td><td>0.4609</td><td>[-0.06, 1.74]</td><td>1.8217</td><td>335.9448</td><td>0.0694</td><td>0.193</td></tr><tr><td>Gender (Other)</td><td>1.1737</td><td>1.5839</td><td>[-1.93, 4.28]</td><td>0.7410</td><td>187.9029</td><td>0.4596</td><td>0.228</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.7770</td><td>1.4362</td><td>[-1.04, 4.59]</td><td>1.2373</td><td>474.9248</td><td>0.2166</td><td>0.226</td></tr><tr><td>FSM (Yes)</td><td>-0.9135</td><td>0.8574</td><td>[-2.59, 0.77]</td><td>-1.0654</td><td>653.1653</td><td>0.2871</td><td>-0.207</td></tr><tr><td>EAL (Bilingual)</td><td>0.4650</td><td>0.4780</td><td>[-0.47, 1.40]</td><td>0.9728</td><td>645.1354</td><td>0.3310</td><td>0.116</td></tr><tr><td>EAL (Other)</td><td>-0.3369</td><td>1.6161</td><td>[-3.50, 2.83]</td><td>-0.2085</td><td>660.9281</td><td>0.8349</td><td>-0.027</td></tr><tr><td>History (No)</td><td>-1.5365</td><td>0.3832</td><td>[-2.29, -0.79]</td><td>-4.0095</td><td>641.2946</td><td>6.80 × 10-5</td><td>-0.351</td></tr><tr><td colspan=\"8\">Comprehension</td></tr><tr><td>Intercept</td><td>4.0264</td><td>0.4409</td><td>[3.16, 4.89]</td><td>9.1318</td><td>638.9518</td><td>8.77 × 10-19</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>0.3533</td><td>0.1785</td><td>[0.00, 0.70]</td><td>1.9792</td><td>655.5471</td><td>0.0482</td><td>0.142</td></tr><tr><td>Condition notes</td><td>0.9500</td><td>0.1658</td><td>[0.62, 1.28]</td><td>5.7306</td><td>662.6375</td><td>1.52 × 10-8</td><td>0.382</td></tr><tr><td>Group 1</td><td>-0.0735</td><td>0.2395</td><td>[-0.54, 0.40]</td><td>-0.3068</td><td>657.2449</td><td>0.7591</td><td>-0.033</td></tr><tr><td>school_id S03</td><td>-0.9749</td><td>0.3320</td><td>[-1.63, -0.32]</td><td>-2.9365</td><td>655.1779</td><td>0.0034</td><td>-0.399</td></tr><tr><td>school_id S01</td><td>-1.9371</td><td>0.4438</td><td>[-2.81, -1.07]</td><td>-4.3645</td><td>662.1221</td><td>1.48 × 10-5</td><td>-0.783</td></tr><tr><td>school_id S05</td><td>-0.3167</td><td>0.4735</td><td>[-1.24, 0.61]</td><td>-0.6688</td><td>648.4704</td><td>0.5039</td><td>-0.142</td></tr><tr><td>school_id S02</td><td>0.5254</td><td>0.3052</td><td>[-0.07, 1.12]</td><td>1.7215</td><td>659.5381</td><td>0.0856</td><td>0.201</td></tr><tr><td>school_id S07</td><td>0.9683</td><td>0.6335</td><td>[-0.27, 2.21]</td><td>1.5284</td><td>663.5186</td><td>0.1269</td><td>0.377</td></tr><tr><td>school_id S04</td><td>-2.9725</td><td>0.4493</td><td>[-3.85, -2.09]</td><td>-6.6154</td><td>651.4740</td><td>7.74 × 10-11</td><td>-1.192</td></tr><tr><td>Text Cuba</td><td>-0.6057</td><td>0.1218</td><td>[-0.84, -0.37]</td><td>-4.9727</td><td>662.4076</td><td>8.42 × 10-7</td><td>-0.245</td></tr><tr><td>Task_order 0</td><td>0.0428</td><td>0.1219</td><td>[-0.20, 0.28]</td><td>0.3508</td><td>657.5431</td><td>0.7258</td><td>0.015</td></tr><tr><td>Test_order 0</td><td>0.6679</td><td>0.1215</td><td>[0.43, 0.91]</td><td>5.4958</td><td>662.7896</td><td>5.55 × 10-8</td><td>0.266</td></tr><tr><td>Gender (Male)</td><td>0.2287</td><td>0.2517</td><td>[-0.26, 0.72]</td><td>0.9086</td><td>542.3928</td><td>0.3640</td><td>0.078</td></tr><tr><td>Gender (Other)</td><td>0.0375</td><td>0.9339</td><td>[-1.79, 1.87]</td><td>0.0401</td><td>102.4863</td><td>0.9681</td><td>0.574</td></tr><tr><td>Gender (Prefer not to say)</td><td>1.5360</td><td>0.9257</td><td>[-0.28, 3.35]</td><td>1.6593</td><td>68.4482</td><td>0.1016</td><td>0.006</td></tr><tr><td>FSM (Yes)</td><td>-0.6056</td><td>0.4786</td><td>[-1.54, 0.33]</td><td>-1.2655</td><td>626.0565</td><td>0.2062</td><td>-0.236</td></tr><tr><td>EAL (Bilingual)</td><td>0.5813</td><td>0.2649</td><td>[0.06, 1.10]</td><td>2.1943</td><td>655.2427</td><td>0.0286</td><td>0.228</td></tr><tr><td>EAL (Other)</td><td>-0.2195</td><td>0.9140</td><td>[-2.01, 1.57]</td><td>-0.2402</td><td>556.3704</td><td>0.8103</td><td>-0.103</td></tr><tr><td>History (No)</td><td>-0.6719</td><td>0.2138</td><td>[-1.09, -0.25]</td><td>-3.1423</td><td>613.1612</td><td>0.0018</td><td>-0.262</td></tr><tr><td colspan=\"8\">Free recall</td></tr><tr><td>Intercept</td><td>4.4052</td><td>0.8507</td><td>[2.74, 6.08]</td><td>5.1786</td><td>662.4966</td><td>2.97 × 10-7</td><td>-</td></tr><tr><td>Condition LLM_notes</td><td>-0.0847</td><td>0.4590</td><td>[-0.98, 0.81]</td><td>-0.1846</td><td>661.9195</td><td>0.8536</td><td>-0.015</td></tr><tr><td>Condition notes</td><td>1.0185</td><td>0.4269</td><td>[0.18, 1.86]</td><td>2.3856</td><td>663.2739</td><td>0.0173</td><td>0.211</td></tr><tr><td>Group 1</td><td>-0.2703</td><td>0.4958</td><td>[-1.24, 0.70]</td><td>-0.5452</td><td>662.0547</td><td>0.5858</td><td>-0.058</td></tr><tr><td>school_id S03</td><td>-0.4702</td><td>0.6185</td><td>[-1.68, 0.74]</td><td>-0.7603</td><td>663.5556</td><td>0.4474</td><td>-0.086</td></tr><tr><td>school_id S01</td><td>-0.9612</td><td>0.8290</td><td>[-2.59, 0.66]</td><td>-1.1595</td><td>660.3122</td><td>0.2467</td><td>-0.189</td></tr><tr><td>school_id S05</td><td>2.1564</td><td>0.8819</td><td>[0.43, 3.89]</td><td>2.4452</td><td>662.7977</td><td>0.0147</td><td>0.459</td></tr><tr><td>school_id S02</td><td>2.7874</td><td>0.5687</td><td>[1.67, 3.90]</td><td>4.9012</td><td>663.9081</td><td>1.20 × 10-6</td><td>0.578</td></tr><tr><td>school_id S07</td><td>2.2260</td><td>1.1824</td><td>[-0.09, 4.54]</td><td>1.8827</td><td>663.2415</td><td>0.0602</td><td>0.459</td></tr><tr><td>school_id S04</td><td>-2.3075</td><td>0.8366</td><td>[-3.95, -0.67]</td><td>-2.7583</td><td>663.2134</td><td>0.0060</td><td>-0.468</td></tr><tr><td>Text Cuba</td><td>-0.1187</td><td>0.3137</td><td>[-0.73, 0.50]</td><td>-0.3783</td><td>662.8799</td><td>0.7053</td><td>-0.027</td></tr><tr><td>Task_order 0</td><td>-0.1370</td><td>0.3134</td><td>[-0.75, 0.48]</td><td>-0.4372</td><td>662.9483</td><td>0.6621</td><td>-0.029</td></tr><tr><td>Test_order 0</td><td>-0.3089</td><td>0.3130</td><td>[-0.92, 0.31]</td><td>-0.9870</td><td>663.8172</td><td>0.3240</td><td>-0.062</td></tr><tr><td>Gender (Male)</td><td>0.7972</td><td>0.4653</td><td>[-0.11, 1.71]</td><td>1.7133</td><td>662.1998</td><td>0.0871</td><td>0.178</td></tr><tr><td>Gender (Other)</td><td>1.5025</td><td>1.6550</td><td>[-1.74, 4.75]</td><td>0.9079</td><td>586.1239</td><td>0.3643</td><td>0.336</td></tr><tr><td>Gender (Prefer not to say)</td><td>-0.7067</td><td>1.7223</td><td>[-4.08, 2.67]</td><td>-0.4103</td><td>284.0426</td><td>0.6819</td><td>-0.249</td></tr><tr><td>FSM (Yes)</td><td>-0.0013</td><td>0.8884</td><td>[-1.74, 1.74]</td><td>-0.0014</td><td>660.6054</td><td>0.9886</td><td>0.016</td></tr><tr><td>EAL (Bilingual)</td><td>-0.4993</td><td>0.4958</td><td>[-1.47, 0.47]</td><td>-1.0070</td><td>644.7815</td><td>0.3143</td><td>-0.104</td></tr><tr><td>EAL (Other)</td><td>-0.7021</td><td>1.6974</td><td>[-4.03, 2.62]</td><td>-0.4137</td><td>647.6784</td><td>0.6793</td><td>-0.157</td></tr><tr><td>History (No)</td><td>-1.0261</td><td>0.3967</td><td>[-1.80, -0.25]</td><td>-2.5868</td><td>658.8462</td><td>0.0099</td><td>-0.210</td></tr></table>\n\n# 2.5 Behavioural Engagement\n\nTable 7: Behavioural engagement with the LLM and note-taking, including queries made, words in notes, and time on task. Significant differences in time spent on tasks are highlighted for comparison between conditions.  \n\n<table><tr><td>Measure</td><td>Condition</td><td>Mean (M)</td><td>Standard Deviation (SD)</td></tr><tr><td rowspan=\"3\">Number of queries</td><td>Group 1 (LLM + Notes)</td><td>10.98</td><td>6.46</td></tr><tr><td>Group 2 (LLM only)</td><td>9.21</td><td>5.72</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>6.02</td><td>4.64</td></tr><tr><td rowspan=\"2\">Words in notes</td><td>Group 1 (Notes)</td><td>100.74</td><td>115.63</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>103.83</td><td>158.24</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">Substantial overlap (≥ 70%)</td><td>25.63%</td></tr><tr><td>Trigram overlap (%)</td><td colspan=\"2\">High overlap (≥ 90%)</td><td>16.25%</td></tr><tr><td rowspan=\"4\">Time on task (minutes)</td><td>Group 1 (LLM)</td><td>-0.80</td><td>95% CI [-1.15, -0.46], d = -0.34</td></tr><tr><td>Group 1 (Notes)</td><td>10-15 range</td><td>-</td></tr><tr><td>Group 2 (LLM only)</td><td>-1.54</td><td>95% CI [-1.91, -1.17], d = -0.66</td></tr><tr><td>Group 2 (LLM + Notes)</td><td>10-15 range</td><td>-</td></tr></table>\n\n# 2.6 Student Task Instructions\n\nTable 8: Introduction to active reading (common across all conditions)  \n\n<table><tr><td>When you are trying to learn and understand a text, active reading can be a useful strategy.\nIt can help you to process the information more deeply and thus to learn better. Active reading\ninvolves:\n· figuring out what the main ideas and concepts in the text are,\n· what they mean,\n· how they relate to each other, and\n· asking questions about the information and then trying to answer them.</td></tr></table>\n\nTable 9: Learning activity introduction by condition  \n\n<table><tr><td>Condition</td><td>Activity introduction</td></tr><tr><td>Notes</td><td>Your task is to try to understand and learn a history text. To do so, please ac- \ntively read the text and take notes to help you. Taking notes is an important \npart of active reading. It is not about copying a lot of information from the text. \nInstead, find the key information in a section, think about what it means, and \nnote it down in your own words.</td></tr><tr><td>LLM</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text and use an AI chatbot to help you. Having a con-\nversation with the AI chatbot might help you to read more actively. You can \nask different questions about the text to help you understand what happened. \nIt may also help you to identify and understand key information.</td></tr><tr><td>LLM+Notes</td><td>Your task is to try to understand and learn a history text. To do so, please \nactively read the text, use an AI chatbot, and take notes to help you. \nHaving a conversation with the AI chatbot might help you to read more actively. \nYou can ask different questions about the text to help you understand what \nhappened. It may also help you to identify and understand key information. \nTaking notes is also important for active reading. It is not about copying a lot \nof information from the text. Instead, find the key information in a section, \nthink about what it means, and note it down in your own words.</td></tr></table>\n\nTable 10: Specific instructions by condition  \n\n<table><tr><td>Condition</td><td>Specific instructions</td></tr><tr><td>Notes</td><td>Actively read the text and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and note them down to help you:\n· The meaning of important words and concepts\n· The meaning of complex sentences\n· The key points or ideas, such as the dates, places, people and events\n· The connections between places, people and events\n· What happened, and why and how it happened\n· Similarities and differences between ideas and concepts\n· Your understanding of the text</td></tr><tr><td>LLM</td><td>Actively read the text and use the AI chatbot as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things and use the AI chatbot to help you. For example, you can use it to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\nYou can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr><tr><td>LLM+Notes</td><td>Actively read the text, use the AI chatbot and take notes as you go along. Even if you think you understand everything, try doing so as best as you can. Think about the following things, and use the AI chatbot and take notes to help you. For example, you can use the AI chatbot to:\n· Explain the meaning of important words and concepts\n· Rephrase or simplify complex sentences and explain them\n· Summarise the text and identify the key points or ideas, such as the dates, places, people and events\n· Clarify information you don’t understand\n· Explain the connections between places, people and events\n· Explain what happened, and why and how it happened\n· Identify similarities and differences between ideas and concepts\n· Check your understanding of the text\n You can also:\n· Ask the AI chatbot for more explanation if you do not understand its response or think that something might not be quite right\n· Ask follow-up questions\n· Ask it to use bullet points, make its answer shorter, or use simpler language</td></tr></table>\n\n# 2.7 Test Questions\n\nTable 11: Example questions for literal retention, comprehension, and free recall  \n\n<table><tr><td>Construct\nItem type</td><td>Example question</td></tr><tr><td colspan=\"2\">Literal retention</td></tr><tr><td>Short response</td><td>What horrific event happened at the Soweto Youth Uprising in 1976? (Passage A)\nWhy did US President Kennedy avoid the term &quot;blockade&quot; when announcing the naval action around Cuba? (Passage B)</td></tr><tr><td>Multiple choice</td><td>What led to violent anti-apartheid protests? (Passage A)\n1) Police forcefully segregating people.\n2) Police arresting Nelson Mandela.\n3) Police killing Black civilians.\n4) Police implementing strict curfews.\nHow did the US government discover the presence of Soviet missiles in Cuba? (Passage B)\n1) A Cuban informant told them about the missiles.\n2) The Cuban government made threats to employ the missiles.\n3) The US Navy intercepted a Soviet ship carrying the missiles.\n4) A US plane captured photos of the missiles.</td></tr><tr><td colspan=\"2\">Comprehension</td></tr><tr><td>Short response</td><td>Explain the role that Nelson Mandela played during apartheid and its eventual end.\nYou only need to write a short paragraph. (Passage A)\nExplain the role of the Soviet Union in the Cuban Missile Crisis.\nYou only need to write a short paragraph. (Passage B)</td></tr><tr><td colspan=\"2\">Free recall</td></tr><tr><td>Open response</td><td>Write down everything you remember from the text &quot;[title]&quot;. Try to include as many details as possible.\nFor example, think about what happened, why and how, when, where, and who was involved.\nYou can write in full sentences or bullet points.</td></tr></table>\n\n# 2.8 Inter-rater Reliability Results\n\nTable 12: Inter-coder reliability  \n\n<table><tr><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td><td>Item</td><td>ICC (A,1)</td><td>p-value</td><td>95% CI</td></tr><tr><td>1</td><td>0.867</td><td>3.08 × 10-24</td><td>[0.781, 0.925]</td><td>15</td><td>0.923</td><td>2.17 × 10-32</td><td>[0.871, 0.958]</td></tr><tr><td>2</td><td>0.918</td><td>5.77 × 10-32</td><td>[0.863, 0.955]</td><td>16</td><td>0.989</td><td>1.29 × 10-61</td><td>[0.980, 0.994]</td></tr><tr><td>3</td><td>0.967</td><td>1.30 × 10-45</td><td>[0.943, 0.982]</td><td>17</td><td>0.962</td><td>8.52 × 10-43</td><td>[0.935, 0.979]</td></tr><tr><td>4</td><td>0.911</td><td>1.38 × 10-30</td><td>[0.851, 0.951]</td><td>18</td><td>0.961</td><td>4.95 × 10-42</td><td>[0.933, 0.979]</td></tr><tr><td>5</td><td>0.891</td><td>1.92 × 10-27</td><td>[0.819, 0.939]</td><td>19</td><td>0.938</td><td>7.34 × 10-36</td><td>[0.895, 0.966]</td></tr><tr><td>6</td><td>1.000</td><td>NaN</td><td>[NaN, NaN]</td><td>20</td><td>0.963</td><td>8.25 × 10-44</td><td>[0.936, 0.980]</td></tr><tr><td>7</td><td>0.951</td><td>2.65 × 10-39</td><td>[0.916, 0.973]</td><td>21</td><td>0.859</td><td>3.92 × 10-24</td><td>[0.770, 0.921]</td></tr><tr><td>8</td><td>0.936</td><td>2.38 × 10-33</td><td>[0.891, 0.965]</td><td>22</td><td>0.893</td><td>3.34 × 10-27</td><td>[0.822, 0.940]</td></tr><tr><td>9</td><td>0.930</td><td>9.00 × 10-31</td><td>[0.880, 0.962]</td><td>23</td><td>0.953</td><td>2.93 × 10-25</td><td>[0.912, 0.976]</td></tr><tr><td>10</td><td>0.954</td><td>1.88 × 10-39</td><td>[0.921, 0.975]</td><td>24</td><td>0.971</td><td>9.27 × 10-33</td><td>[0.947, 0.985]</td></tr><tr><td>11</td><td>0.920</td><td>1.89 × 10-30</td><td>[0.864, 0.956]</td><td>25</td><td>0.959</td><td>3.71 × 10-39</td><td>[0.928, 0.978]</td></tr><tr><td>12</td><td>0.969</td><td>5.35 × 10-40</td><td>[0.946, 0.984]</td><td>26</td><td>0.988</td><td>1.02 × 10-60</td><td>[0.980, 0.994]</td></tr><tr><td>13</td><td>0.959</td><td>6.30 × 10-42</td><td>[0.930, 0.978]</td><td>27</td><td>0.968</td><td>4.23 × 10-38</td><td>[0.943, 0.983]</td></tr><tr><td>14</td><td>0.927</td><td>2.80 × 10-33</td><td>[0.877, 0.960]</td><td>28</td><td>0.983</td><td>7.93 × 10-56</td><td>[0.971, 0.991]</td></tr></table>\n\n# 2.9 Survey Questions and Response Scales\n\nTable 13: Survey questions and response scales - Session 1  \n\n<table><tr><td>Variable</td><td>Question and response scale</td></tr><tr><td>Text difficulty</td><td>How difficult to understand did you find the text on [Passage title]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Topic familiarity</td><td>How much did you already know about [Passage title] before starting the task? \n(Nothing at all, Not very much, A moderate amount, Quite a bit, Very much)</td></tr><tr><td>Topic interest</td><td>How interesting was the text on [Passage title]? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Activity enjoyment</td><td>How enjoyable was learning the text with the help of [activity]? \n(Not at all enjoyable, Not very enjoyable, Somewhat enjoyable, Quite enjoyable, Very enjoyable)</td></tr><tr><td>Activity difficulty</td><td>Overall, how difficult did you find the [activity]? \n(Not at all difficult, Not very difficult, Somewhat difficult, Quite difficult, Very difficult)</td></tr><tr><td>Activity helpfulness</td><td>How helpful was [activity] for understanding and learning the text? \n(Not at all helpful, Not very helpful, Somewhat helpful, Quite helpful, Very helpful)</td></tr><tr><td>Activity future use</td><td>Would you use a similar approach ([activity]) to understand and learn a text in the future? \n(Yes, No, I am not sure)</td></tr><tr><td>Task interest</td><td>How interesting was this task overall? \n(Not at all interesting, Not very interesting, Somewhat interesting, Quite interesting, Very interesting)</td></tr><tr><td>Task effort</td><td>How much effort did you put into understanding and learning the text on [Passage title]? \n(No effort at all, Only a little bit of effort, Some effort, Quite a bit of effort, A lot of effort)</td></tr><tr><td>Perceived task performance</td><td>How well do you think you did on the task? \n(Not at all well, Not very well, Somewhat well, Quite well, Very well)</td></tr><tr><td>Activity preference</td><td>Group 1: Which of the two learning approaches of this study did you prefer (note-taking or AI chatbot)? \n(I preferred learning by note-taking, I preferred learning with the help of the AI chatbot, I had no preference, I am not sure) \nGroup 2: Which of the two learning approaches of this study did you prefer (AI chatbot only or AI chatbot with note-taking)? \n(I preferred learning only with the help of the AI chatbot, I preferred learning with the help of the AI chatbot and by taking notes simultaneously, I had no preference, I am not sure)</td></tr><tr><td>Reason for preference</td><td>Can you tell us why you preferred this approach? [Open response]</td></tr><tr><td>Prior LLM use</td><td>Have you ever used an AI chatbot (such as ChatGPT, Microsoft Bing, and Google Bard AI) before this study? \n(Yes, No)</td></tr><tr><td>LLM use frequency</td><td>How often do you use an AI chatbot (approximately)? \n(Less than once a week, One or two days a week, Three to five days a week, Most days of the week)</td></tr><tr><td>Notes for learning frequency</td><td>How often do you take notes when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM for learning frequency</td><td>How often do you use an AI chatbot when reading a text for schoolwork, such as to prepare for a lesson or a test? \n(Never, Rarely, Sometimes, Often, Always)</td></tr><tr><td>LLM+Notes for learning frequency</td><td>Group 2 only: How often do you use the two approaches (using an AI chatbot and taking notes) at the same time when reading a text for schoolwork? \n(Never, Rarely, Sometimes, Often, Always)</td></tr></table>\n\nTable 14: Survey questions and response scales - Session 2  \n\n<table><tr><td>Variable</td><td>Item and response categories</td></tr><tr><td>Perceived test performance</td><td>If all the questions on [Passage title] combined were worth a maximum of 100 points, how many points do you think you would have (approximately) scored? [Open response]</td></tr><tr><td>Learning in between sessions</td><td>Have you done anything between the first session and today&#x27;s session to further explore or understand the topics of the two texts? That could include looking up information online, taking notes after the session or discussing the topic with others. If so, please provide as much detail as you can about what you have done. [Open response]</td></tr><tr><td>Gender</td><td>What is your gender? [Open response]</td></tr><tr><td>EAL</td><td>Which language do you feel most comfortable speaking and communicating in?\n(English, A language other than English, Equally English and another language)</td></tr><tr><td>History</td><td>Are you taking GCSE History? (Yes, No)</td></tr></table>\n\n# 2.10 Learning Experiences and Perceptions\n\nTable 15: Differences in learning experiences and perceptions between conditions (for Group 1 and Group 2)  \n\n<table><tr><td rowspan=\"2\">Variable</td><td colspan=\"5\">Group 1: LLM vs Notes</td><td colspan=\"5\">Group 2: LLM vs LLM+Notes</td></tr><tr><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td><td>Diff.</td><td>t(df)</td><td>p</td><td>95% CI</td><td>d</td></tr><tr><td>Activity helpfulness</td><td>0.41</td><td>4.38(181)</td><td>&lt;0.001</td><td>[0.22, 0.59]</td><td>0.33</td><td>-0.03</td><td>-0.35(157)</td><td>0.724</td><td>[-0.21, 0.15]</td><td>-0.03</td></tr><tr><td>Activity difficulty</td><td>-0.51</td><td>-7.00(181)</td><td>&lt;0.001</td><td>[-0.66, -0.37]</td><td>-0.52</td><td>-0.41</td><td>-4.99(159)</td><td>&lt;0.001</td><td>[-0.57, -0.25]</td><td>-0.40</td></tr><tr><td>Task effort</td><td>-0.25</td><td>-3.53(182)</td><td>0.001</td><td>[-0.38, -0.11]</td><td>-0.26</td><td>-0.08</td><td>-1.03(159)</td><td>0.305</td><td>[-0.22, 0.07]</td><td>-0.08</td></tr><tr><td>Activity enjoyment</td><td>0.68</td><td>6.50(181)</td><td>&lt;0.001</td><td>[0.47, 0.89]</td><td>0.48</td><td>0.00</td><td>0.00(158)</td><td>1.000</td><td>[-0.16, 0.16]</td><td>0.00</td></tr><tr><td>Text interest</td><td>-0.11</td><td>-1.38(183)</td><td>0.170</td><td>[-0.26, 0.05]</td><td>-0.10</td><td>0.06</td><td>0.79(159)</td><td>0.428</td><td>[-0.09, 0.22]</td><td>0.06</td></tr><tr><td>Text difficulty</td><td>0.03</td><td>0.50(183)</td><td>0.621</td><td>[-0.10, 0.16]</td><td>0.04</td><td>0.03</td><td>0.41(159)</td><td>0.684</td><td>[-0.10, 0.15]</td><td>0.03</td></tr><tr><td>Task interest</td><td>0.09</td><td>1.01(183)</td><td>0.315</td><td>[-0.09, 0.27]</td><td>0.07</td><td>-0.06</td><td>-0.79(159)</td><td>0.430</td><td>[-0.20, 0.08]</td><td>-0.06</td></tr><tr><td>Perceived task performance</td><td>0.00</td><td>0.00(182)</td><td>1.000</td><td>[-0.14, 0.14]</td><td>0.00</td><td>-0.11</td><td>-1.45(158)</td><td>0.150</td><td>[-0.25, 0.04]</td><td>-0.12</td></tr><tr><td>Perceived test performance</td><td>-9.66</td><td>-5.53(177)</td><td>&lt;0.001</td><td>[-13.11, -6.22]</td><td>-0.42</td><td>-6.80</td><td>-3.55(143)</td><td>0.001</td><td>[-10.59, -3.02]</td><td>-0.30</td></tr></table>\n\n# 2.11 Coding Scheme Activity Preferences\n\nTable 16: Coding scheme: LLM over LLM+Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM alone is quicker</td><td>Using the LLM alone is quicker than also taking notes, which takes time.</td><td>“It took less time to use the LLM”, “Notes take too much time.”</td></tr><tr><td>Both together not necessary</td><td>Notes are not necessary when the LLM already explains the text.</td><td>“The note-taking seemedunnec-\nsessary as the bot already helped explain”, “Using one sort of meant I didn’t need the other.”</td></tr><tr><td>LLM does the work for you</td><td>If you use the LLM alone, you don’t have to do the work your-\nself. The task becomes easier if you don’t have to take notes.</td><td>“Didn’t have to do any work”, “Clarify any information I didn’t know immediately without hav-\ning to scour the text”, “It was difficult to take notes at the same time as using the chatbot.”</td></tr><tr><td>Note-taking reduces question time</td><td>Note-taking takes away time from asking the LLM questions or understanding the text.</td><td>“I didn’t have enough time to ask as many questions when taking notes”, “I had more time to un-\nderstand the text.”</td></tr><tr><td>LLM does not support note-taking</td><td>LLM does not make note-taking easier.</td><td>&quot;Not as useful for making note-\ntaking easier.”</td></tr></table>\n\nTable 17: Coding scheme: LLM over Notes preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>LLM is quick</td><td>LLM is quick and saves time.</td><td>“Less time-consuming”, “Much quicker.”</td></tr><tr><td>LLM is easy</td><td>LLM is easy and requires little effort compared to note-taking, which takes more effort and is more difficult.</td><td>“More simple”, “It was easier.”</td></tr><tr><td>LLM is (inter)active</td><td>LLM is an interactive or active learning activity.</td><td>“Actively engaging with the bot”, “Felt more interactive.”</td></tr><tr><td>LLM is emotionally engaging</td><td>LLM is more fun, enjoyable, and interesting.</td><td>“Enjoyed reading its responses”, “More fun to use.”</td></tr><tr><td>LLM helps you focus</td><td>LLM helps you focus on the text.</td><td>“Allowed me to focus more on the text.”</td></tr><tr><td>LLM helps you understand</td><td>LLM helps understanding and helps you check your understanding.</td><td>“It gives you a better understanding”, “I could confirm anything I was unsure of to ensure I understood it.”</td></tr><tr><td>LLM helps you learn</td><td>LLM supports learning.</td><td>“The AI helped me to learn more efficiently”, “I was able to understand and learn the text a lot easier and quicker at a higher level.”</td></tr><tr><td>LLM answers questions</td><td>LLM is helpful for understanding because it can answer questions and explain what you don’t understand.</td><td>“Ask any relevant questions”, “If I had a question, it could answer it.”</td></tr><tr><td>LLM can provide background and additional information</td><td>LLM is helpful for understanding because it provides background information and can elaborate on what happens.</td><td>“I was given more background”, “It gives me the full context.”</td></tr><tr><td>LLM can summarise and simplify information</td><td>LLM is helpful for understanding because it can simplify and rephrase information as well as summarise.</td><td>“It puts it in a simpler way and form”, “I can ask the AI chatbot to rephrase key points”, “It can summarise key points.”</td></tr><tr><td>LLM helps you remember</td><td>LLM helps you to remember the information in the text.</td><td>“It has stuck in my head more”, “Giving me prompt questions, mnemonics, etc., which helped me remember”, “Took less time to memorise than note-taking.”</td></tr></table>\n\nTable 18: Coding scheme: Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Notes help you remember better</td><td>Note-taking helps you to remember information because you are physically writing it down. LLM does not help you remember as well.</td><td>“I can remember things better when I write them down”, “More helpful for developing recall”, “I learned more with note-taking”, “Just gave more background, rather than consolidating the knowledge.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and check your understanding.</td><td>“It was easier for me to understand what I was reading”, “I was understanding it more”, “Test what you have learned by paraphrasing.”</td></tr><tr><td>Note-taking is active</td><td>Note-taking is more active.</td><td>“Better active reading”, “Allows me to actively engage.”</td></tr><tr><td>Notes are your own work</td><td>Note-taking means that you do the work yourself. You do the thinking and can use your own words and capture your own views.</td><td>“You have to personally analyse it”, “I could condense the information into my own words”, “Made me think for myself”, “It is your view on the matter you are looking at”, “Alows me to feel proud of my work in the future.”</td></tr><tr><td>Notes help you process information</td><td>Note-taking helps you process the information.</td><td>“I was able to break down and process the text”, “Summarising the second text myself helped me to process the information.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“I am able to write down my own knowledge of what I had learned”, “I could actually learn the information rather than being told it.”</td></tr><tr><td>Notes can be revisited</td><td>Notes can be more easily revisited than the LLM output. You can easily access what you have learned or thought so far.</td><td>“I can come back to these notes at a later date if I am doing revision”, “Note-taking gives you something better to look back on in future.”</td></tr><tr><td>Notes are easier</td><td>Note-taking is easier than using the LLM.</td><td>“Easier to summarise”, “IDK, easier.”</td></tr><tr><td>Notes help with organisation</td><td>Notes help you to organise the information and thoughts and break it down into smaller parts to aid clarity.</td><td>“It is easy to organise my notes”, “It is easier to keep track of your train of thoughts”, “Helped me to break down the text into smaller chunks.”</td></tr><tr><td>LLM is distracting and provides too much information</td><td>LLM is distracting as you may ask questions that are not relevant or focus on things that are not important. LLM provides too much information, which can be overwhelming or confusing.</td><td>“I found myself easily distracted by the AI and was more tempted to ask random questions”, “It’s not clear as it gives too much information.”</td></tr><tr><td>LLM is repetitive and boring</td><td>LLM is boring and repetitive as it restates the information many times.</td><td>“It felt that it was just repeating it-self.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it and what kind of questions to ask.</td><td>“I struggled to think of questions to ask the AI”, “The text was very easy therefore didn’t feel the need to ask many questions.”</td></tr></table>\n\nTable 19: Coding scheme: LLM+Notes over LLM preferences  \n\n<table><tr><td>Code</td><td>Description</td><td>Examples</td></tr><tr><td>Both together are more enjoyable</td><td>Using LLM and notes together is more fun and enjoyable, whereas LLM alone can be boring.</td><td>“I enjoy using both at the same time”, “If I had to use the chatbot and ask it 20 questions, I would be very bored.”</td></tr><tr><td>Both together combine the best of both worlds</td><td>LLM and notes can be used in complementary ways to get the best of both, such as doing the work yourself and then using the LLM when you are unsure or stuck.</td><td>“It was easier to have my key notes summarised as well as text with more detail”, “It allowed me to note down the crucial parts of the event in a way that I can understand it and also get help from the AI chatbot on anything that isn’t clear.”</td></tr><tr><td>Both together are more helpful and easier</td><td>General statements about the strategy being more helpful, better, or easier for understanding and learning.</td><td>“Most helpful and easy to learn”, “Because I find it easier to remember and learn this way.”</td></tr><tr><td>Notes help you process and understand the information from the LLM</td><td>Notes help you process and understand the information given by the LLM.</td><td>“In order for me to process this, I find note-taking at the same time very helpful.”</td></tr><tr><td>Notes help with organisation</td><td>LLM provides information, but notes are needed to organise and structure ideas. The notes are also more focused and accessible.</td><td>“If I am only using the chatbot, then I have to scroll up to find what I am looking for”, “It was easier to keep track of things and go back over them.”</td></tr><tr><td>Notes are your own work</td><td>Taking notes means you do actual work and can capture your own thoughts rather than just reading output.</td><td>“It meant I was doing actual work.”</td></tr><tr><td>Notes help you remember</td><td>Notes help to remember the information.</td><td>“I like to write out information as I think it helps me remember it better.”</td></tr><tr><td>Notes help you understand</td><td>Note-taking helps you to understand better and to check your understanding.</td><td>“Simplifying it on paper made it easier to understand and remember.”</td></tr><tr><td>Notes help you learn</td><td>Notes help you to learn, capture what you have learned, or test what you have learned.</td><td>“You learn more”, “You can simplify what you have learnt in the notes.”</td></tr><tr><td>LLM can provide bad answers</td><td>LLM does not always answer questions well and sometimes not at all. LLM can be harmful.</td><td>“Some of the questions I had for the bot were not answered explicitly.”</td></tr><tr><td>LLM not always available</td><td>One needs to know how to take notes as LLMs might not always be available.</td><td>“You will not get an AI chatbot at all times.”</td></tr><tr><td>Not sure what to ask the bot</td><td>The LLM is not needed because everything is understood, or one does not know how to use it or what kind of questions to ask.</td><td>“I wasn’t sure what I was supposed to say to the bot. It was just kinda irritating.”</td></tr></table>\n\n# 2.12 Coding Scheme Prompt Interactions\n\nFor the full prompt coding scheme, please refer to tabular file 'PromptCoding.xslx'\n\nTable 20: Prompt Coding Scheme  \n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>The student asks the bot to summarise the entire text or a specific text selection.\nExamples: “Help me to summarise this paragraph”, “Summarise the text”, “Give me a summary of the first paragraph”, “Tell me what this text is about.”</td></tr><tr><td></td><td>Take notes</td><td>The student asks the bot to take notes about the text as a whole or a specific paragraph.\nExamples: “Make notes for the first paragraph.”</td></tr><tr><td></td><td>Identify key ideas</td><td>The student asks the bot to identify the key ideas or takeaway messages from the text, including key dates, places, people, and events.\nExamples: “What are the main points?”, “Give me all the important dates”, “What’s the takeaway message?”</td></tr><tr><td></td><td>Create timeline</td><td>The student asks the bot to create a timeline of events described in the text.\nExamples: “Put the important dates into chronological order”, “Give me a timeline of the events.”</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>The student asks the bot to define or explain a specific word or concept from the text. They request help to understand terminology but do not ask for factual information beyond that.\nExamples: “What does apartheid mean?”, “What is a colony?”, “What is a missile?”, “I don’t know what a blockade is.”</td></tr><tr><td></td><td>Simplify or explain difficult sentences</td><td>The student asks the bot to simplify or explain the provided passage or a specific selection of the passage.\nExamples: “Explain this in simple words”, “Make the text simpler”, “What does this sentence mean?”, “Simplify this text.”</td></tr><tr><td></td><td>Checking understanding</td><td>The student explains their understanding and seeks confirmation from the bot.\nExamples: “The US did not like Cuba because they thought that Castro was a communist, right?”, “So it was one officer that prevented the whole war?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>The student asks for background information on a place, time, or person mentioned in the text to provide context—information that is not too central for understanding the text but could be relevant.\nExamples: “Who was Kennedy?”, “What was Mandela famous for?”, “Tell me more about Cuba”, “How many British colonies were there in Africa?”, “Where were the Turkish missiles located?”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Elaboration and deeper understanding</td><td>The student asks for more details about an event, such as why it happened, who was involved, and the outcome.\nExamples: “Why did the US not like Castro?”, “Why did the exiles invade Cuba?”, “How did black people feel during apartheid?”</td></tr><tr><td></td><td>Ask for examples or analogies</td><td>The student requests examples or analogies to better understand a concept or event.\nExamples: “What are examples of how apartheid affected daily life?”, “Is there an analogy that explains the Cold War tensions?”, “What unfair laws were passed?”, “What were some of the boycotts?”</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>The student asks the bot to compare or contrast concepts, events, or figures.\nExamples: “How is apartheid different from segregation in the US?”, “Compare Kennedy and Khrushchev&#x27;s leadership styles.”</td></tr><tr><td></td><td>Critical analysis or evaluation</td><td>The student requests the bot to critically analyze or evaluate an action, situation, decision, or statement.\nExamples: “What are the strengths and weaknesses of Kennedy&#x27;s decision?”, “Evaluate the effectiveness of the blockade.”</td></tr><tr><td></td><td>Implications and significance</td><td>The student inquires about the broader implications, relevance, or consequences of information in the text.\nExamples: “What were the long-term effects of the crisis?”, “What is the situation like now?”, “Why should I care or learn about this?”</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>The student asks for assistance to learn and remember the text, including requests to be quizzed on the content.\nExamples: “Make a mnemonic”, “Write four questions about the text”, “How can I remember this better?”</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>The student requests that the bot provides its response in a specific format or length.\nExamples: “Summarize the main points in bullet points”, “Can you create a chart of the different policies?”, “Use only a few words”, “Make it short.”</td></tr><tr><td></td><td>Request improvement</td><td>The student asks the bot to improve its response or restate it in a simpler or shorter way rather than asking for simplifications of the provided passage.\nExamples: “I don’t understand what you said”, “Explain that again but shorter”, “What do you mean?”,\n“Simpler please”, “Can you write that in simpler terms?”, “Make the summary shorter.”</td></tr><tr><td></td><td>Relational language</td><td>The student engages in casual, polite conversation that is unrelated to the text.\nExamples: “How are you?”, “Thank you”, “Hello.”</td></tr></table>\n\nContinued on next page\n\n<table><tr><td>Overarching Code</td><td>Sub-code</td><td>Description and Examples</td></tr><tr><td></td><td>Checking source and trustworthiness</td><td>The student inquires about the sources or questions the accuracy of information.\nExamples: “What are your sources?”, “Why should I believe you?”, “I think your answer is wrong.”</td></tr><tr><td></td><td>Pasting text without specific request</td><td>The student pastes text directly from the provided passages without framing it as a specific question or request.\nExamples: “Nelson Mandela”, “In 1910, four British colonies joined to create the Union of South Africa”, “Missile.”</td></tr><tr><td>Irrelevant, Off-topic, miscellaneous</td><td>Irrelevant to text</td><td>The student asks a question unrelated to the text or its background.\nExamples: “Who is Che Guevara?”, “What is the song Abraxas?”</td></tr><tr><td></td><td>Miscellaneous</td><td>Use this code for segments that don’t fit any other codes. Use this as a last resort.</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Nonsensical input</td><td>The student types nonsensical characters, symbols, or text that does not form coherent words or sentences.\nExamples: “asdfgh”, “.”, “123”, “???”</td></tr></table>\n\n# 2.13 Frequency of Prompt Types\n\nTable 21: Frequencies of overarching prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Frequency</td></tr><tr><td>Archetype</td><td></td></tr><tr><td>Seeking additional information and deeper understanding</td><td>2265</td></tr><tr><td>Information condensation</td><td>749</td></tr><tr><td>Understanding the text</td><td>615</td></tr><tr><td>Study and memory help</td><td>39</td></tr><tr><td>Other</td><td></td></tr><tr><td>Interacting with the bot</td><td>760</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>501</td></tr></table>\n\nTable 22: Frequencies of specific prompt types  \n\n<table><tr><td>Overarching prompt type</td><td>Specific prompt type</td><td>Frequency</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Elaboration and deeper understanding</td><td>1479</td></tr><tr><td>Information condensation</td><td>Summarise</td><td>588</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>General background</td><td>514</td></tr><tr><td>Understanding the text</td><td>Define a word or concept</td><td>463</td></tr><tr><td>Interacting with the Bot</td><td>Request specific format or length</td><td>430</td></tr><tr><td>Irrelevant, Off-topic, Miscellaneous</td><td>Irrelevant to text</td><td>296</td></tr><tr><td>Understanding the text</td><td>Simplify or explain difficult sentences</td><td>126</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Implications and significance</td><td>119</td></tr><tr><td>Information condensation</td><td>Identify key ideas</td><td>114</td></tr><tr><td>Interacting with the bot</td><td>Request improvement</td><td>113</td></tr><tr><td>Interacting with the bot</td><td>Pasting text without specific request</td><td>106</td></tr><tr><td>Interacting with the bot</td><td>Relational language</td><td>105</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Nonsensical input</td><td>109</td></tr><tr><td>Irrelevant, off-topic, miscellaneous</td><td>Miscellaneous</td><td>96</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for examples or analogies</td><td>66</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Critical analysis or evaluation</td><td>54</td></tr><tr><td>Study and memory help</td><td>Study and memory help</td><td>39</td></tr><tr><td>Seeking additional information and deeper understanding</td><td>Ask for contrasts or comparisons</td><td>31</td></tr><tr><td>Understanding the text</td><td>Checking understanding</td><td>26</td></tr><tr><td>Information condensation</td><td>Take notes</td><td>26</td></tr><tr><td>Information condensation</td><td>Create timeline</td><td>21</td></tr><tr><td>Interacting with the bot</td><td>Checking source and trustworthiness</td><td>6</td></tr></table>\n\nNote: This table only includes prompt types that have been used at least three times by students.",
    "arxiv_id": "2401.15081",
    "error_message": null,
    "embedding": [
      -1.7890625,
      -1.7890625,
      0.2119140625,
      -4.4375,
      -1.6484375,
      0.3515625,
      -0.66796875,
      -1.8203125,
      0.5078125,
      2.4375,
      1.9140625,
      1.15625,
      2.15625,
      2.890625,
      -0.76171875,
      4.25,
      -0.064453125,
      -0.423828125,
      0.48046875,
      -7.125,
      0.5390625,
      1.46875,
      0.98046875,
      -5.5,
      3.796875,
      -4.375,
      -1.1484375,
      0.91796875,
      0.5,
      0.08251953125,
      7.1875,
      -7.1875,
      0.52734375,
      2.46875,
      0.70703125,
      1.2265625,
      -2.34375,
      -1.890625,
      7.25,
      3.25,
      -4.875,
      0.1552734375,
      1.703125,
      1.4921875,
      0.0859375,
      2.921875,
      1.5703125,
      -1.90625,
      -4.625,
      -0.81640625,
      -3.1875,
      -4.90625,
      8,
      -3.265625,
      3.046875,
      -3.171875,
      -5.0625,
      5.28125,
      -3.3125,
      -0.478515625,
      0.3046875,
      -0.87890625,
      1.328125,
      0.287109375,
      2.921875,
      1.34375,
      1.5390625,
      0.87109375,
      -3.453125,
      1.5625,
      2.15625,
      1.4765625,
      6.0625,
      -4.40625,
      9.0625,
      7.75,
      3.34375,
      2.21875,
      -0.1572265625,
      2.515625,
      -6,
      4.9375,
      4.3125,
      -2.078125,
      6.46875,
      3.046875,
      -1.1796875,
      -2.203125,
      -2.84375,
      2.46875,
      -1.1484375,
      -0.1318359375,
      -6.25,
      -3.15625,
      0.1337890625,
      3.03125,
      -1.0390625,
      -5.25,
      -4.84375,
      -0.423828125,
      -1.890625,
      -3.171875,
      1.078125,
      -6.6875,
      -4.75,
      -4.59375,
      -2.828125,
      -7.1875,
      -0.71484375,
      -1.5703125,
      -0.59375,
      2.546875,
      0.55859375,
      -1.1328125,
      0.85546875,
      -0.68359375,
      3.234375,
      -5.5,
      -3.265625,
      -0.431640625,
      0.6171875,
      2.703125,
      -1.109375,
      0.55078125,
      1.2421875,
      2.78125,
      -5.21875,
      2.9375,
      5.625,
      -0.984375,
      3.21875,
      -1.1875,
      5.40625,
      -0.6953125,
      -6.375,
      -3.546875,
      -4.40625,
      2.078125,
      4.78125,
      7.1875,
      -4.3125,
      -0.25390625,
      -1.65625,
      -8.75,
      2.953125,
      1.078125,
      -6.75,
      0.5859375,
      3.859375,
      -4.5625,
      -1.140625,
      0.79296875,
      4.03125,
      4.875,
      -1.90625,
      -5.09375,
      3.15625,
      2.296875,
      0.220703125,
      -2.140625,
      2.125,
      1.0234375,
      -1.15625,
      1.25,
      -0.5234375,
      -3.171875,
      -7.0625,
      1.6171875,
      -2.96875,
      -1.0546875,
      2.921875,
      13.5625,
      2.34375,
      -1.4765625,
      0.03662109375,
      0.4921875,
      -2.5,
      6.34375,
      1.96875,
      -0.703125,
      2.640625,
      1.5546875,
      -3.734375,
      1.6484375,
      -0.2197265625,
      0.46484375,
      3.25,
      -3.34375,
      2.03125,
      -1.375,
      2.765625,
      4.875,
      1.765625,
      -0.0458984375,
      -4.625,
      0.23046875,
      3.71875,
      1.3515625,
      -0.83984375,
      2.125,
      1.15625,
      -8.1875,
      1.3359375,
      -1.4296875,
      -3.84375,
      -2.25,
      4,
      -1.1328125,
      2.8125,
      -1.5390625,
      1.65625,
      -1.578125,
      0.71484375,
      1.828125,
      7.375,
      1.7265625,
      1.3359375,
      -0.279296875,
      3.96875,
      3.265625,
      4,
      3.125,
      2.5625,
      1.171875,
      -0.890625,
      3.109375,
      2.453125,
      3.625,
      -0.058837890625,
      5.34375,
      -0.1796875,
      4.125,
      5.5,
      -1.9765625,
      -1.703125,
      0.2392578125,
      -3.625,
      -0.64453125,
      -1.2734375,
      0.23046875,
      -3.859375,
      -2.4375,
      0.5234375,
      2.8125,
      1.6328125,
      -1.6015625,
      -0.52734375,
      -0.94140625,
      -0.8515625,
      -6.875,
      0.8984375,
      1.9765625,
      -9.8125,
      -3.6875,
      5.75,
      8.6875,
      -0.33984375,
      -0.287109375,
      -2.9375,
      -0.7421875,
      3.40625,
      -1.6171875,
      -3.671875,
      -0.205078125,
      1.9609375,
      -4.28125,
      5.875,
      -1.46875,
      3.78125,
      1.34375,
      0.2578125,
      -2.03125,
      -2.046875,
      0.058837890625,
      0.09375,
      5.53125,
      3.671875,
      -3.3125,
      0.578125,
      -2.125,
      -6.3125,
      -9.25,
      5.65625,
      -3.125,
      5.4375,
      -1.015625,
      0.5703125,
      4.78125,
      -1.6015625,
      12.875,
      2.15625,
      1.7421875,
      0.58984375,
      -1.2734375,
      -4.375,
      1.3671875,
      -4.21875,
      2.671875,
      -4.875,
      -0.486328125,
      4.8125,
      3.96875,
      -1.4765625,
      -4.1875,
      1.125,
      4.40625,
      1.5546875,
      -3.625,
      0.6796875,
      2.75,
      -3.90625,
      2.09375,
      6.9375,
      -3.609375,
      3.765625,
      -7.0625,
      -2.328125,
      6.3125,
      1.2421875,
      -1.0234375,
      -5.09375,
      -3.1875,
      -1.0546875,
      -2.734375,
      -2.75,
      -2.46875,
      0.4375,
      -0.259765625,
      2.46875,
      -0.53515625,
      1.359375,
      0.78125,
      -5.25,
      -9.6875,
      7.5,
      -3.453125,
      5.3125,
      0.76953125,
      -1.4296875,
      3.859375,
      -2.25,
      -3.578125,
      3.34375,
      -1.765625,
      -0.166015625,
      -1.78125,
      4.625,
      -2.46875,
      1.453125,
      -8.125,
      2.9375,
      0.80078125,
      1.234375,
      5,
      6.84375,
      -3.828125,
      1.09375,
      -2.34375,
      -2.53125,
      -0.53125,
      1.0859375,
      -1.28125,
      6.4375,
      -0.7578125,
      -3.734375,
      -2.71875,
      -0.5625,
      3.84375,
      -0.7109375,
      -0.68359375,
      0.314453125,
      -4.09375,
      0.53125,
      0.76171875,
      1.1796875,
      3.625,
      2.671875,
      -2.359375,
      -1.6484375,
      3.703125,
      -3.640625,
      0.80078125,
      -0.0830078125,
      -1.0625,
      2.9375,
      1.640625,
      1.1015625,
      2.984375,
      2.96875,
      0.036865234375,
      -2.375,
      1.1875,
      -2.703125,
      3.140625,
      1.703125,
      3.421875,
      -1.078125,
      1.953125,
      -0.9921875,
      -2.578125,
      5.5625,
      0.1337890625,
      -0.38671875,
      -2.90625,
      -3.53125,
      1.09375,
      1.8828125,
      -6.9375,
      0.279296875,
      2.09375,
      -1.4296875,
      2.875,
      -1.96875,
      0.20703125,
      -0.3125,
      3.234375,
      -1.0859375,
      2.96875,
      -5.875,
      -3.125,
      -3.390625,
      0.134765625,
      1.546875,
      -0.88671875,
      -0.30859375,
      0.51171875,
      4.4375,
      5.96875,
      0.89453125,
      -1.8125,
      1.4140625,
      0.051025390625,
      -3,
      0.45703125,
      0.0230712890625,
      -0.004425048828125,
      1.2734375,
      -4.5625,
      -4.53125,
      -0.357421875,
      2.671875,
      0.29296875,
      5.125,
      5.25,
      -2.65625,
      -2.265625,
      2.03125,
      3.234375,
      -4.09375,
      -5,
      -1.0703125,
      0.51953125,
      -1.1875,
      1.609375,
      1.890625,
      0.60546875,
      -0.060791015625,
      4.46875,
      2.046875,
      1.5,
      2.5,
      -0.41015625,
      -1.484375,
      -0.27734375,
      -0.05615234375,
      0.1708984375,
      -3.5,
      4.09375,
      6.34375,
      -11.375,
      -10.625,
      3.125,
      0.9375,
      -0.578125,
      -0.306640625,
      4.78125,
      2.03125,
      1.859375,
      -6.1875,
      -4.4375,
      -0.1875,
      -0.68359375,
      3.46875,
      2.21875,
      -1.0703125,
      -3.03125,
      -3.984375,
      4.46875,
      -0.62890625,
      4.53125,
      -0.0576171875,
      0.095703125,
      1.90625,
      -5.3125,
      2.328125,
      1.6328125,
      6.84375,
      -6.09375,
      0.2138671875,
      0.9765625,
      -8.3125,
      -1.3125,
      -3.65625,
      -0.21484375,
      0.07373046875,
      -0.98046875,
      5.28125,
      -3.453125,
      -0.4765625,
      -1.265625,
      2.546875,
      -4.1875,
      -3.171875,
      3.296875,
      -3.34375,
      -3.015625,
      0.25,
      0.8203125,
      1.0625,
      -1.4453125,
      -1.375,
      -0.400390625,
      3.953125,
      2.15625,
      0.0771484375,
      -1.4375,
      -0.890625,
      -2.5625,
      0.314453125,
      3.96875,
      3.375,
      3.046875,
      1.34375,
      -5.25,
      -2.109375,
      -0.57421875,
      0.42578125,
      1.5078125,
      -0.1474609375,
      0.10302734375,
      0.484375,
      3.515625,
      -4.15625,
      1.5546875,
      0.62109375,
      0.5625,
      -3.5,
      0.09228515625,
      4.125,
      3.46875,
      2.9375,
      3.140625,
      -0.6875,
      1.171875,
      0.9453125,
      -4.21875,
      -3.484375,
      -1.6484375,
      2.203125,
      0.99609375,
      -3.453125,
      -0.2578125,
      -1.5859375,
      -0.86328125,
      0.59375,
      -0.9375,
      3.203125,
      6.875,
      -2.15625,
      1.28125,
      -0.267578125,
      2.265625,
      -2.171875,
      1.8515625,
      1.953125,
      2.890625,
      -5.90625,
      -6.0625,
      -3.0625,
      -0.169921875,
      6.75,
      0.052490234375,
      4.4375,
      -2.734375,
      5.4375,
      1.3515625,
      -0.09521484375,
      -15.3125,
      2.515625,
      -1.0625,
      -3.5625,
      0.1181640625,
      -4.21875,
      2.6875,
      -1.859375,
      4.09375,
      0.341796875,
      -1.65625,
      -2.890625,
      5.3125,
      0.98828125,
      -0.484375,
      4.6875,
      2.328125,
      -6.09375,
      1.1953125,
      -0.51953125,
      -1.234375,
      0.97265625,
      -1.1484375,
      1.4609375,
      4.5,
      4.46875,
      -1.84375,
      -0.734375,
      1.6015625,
      -4.375,
      -0.19140625,
      1.6953125,
      2.65625,
      1.2578125,
      2.5625,
      -0.78515625,
      2.9375,
      -3.46875,
      1.953125,
      -0.15234375,
      -1.671875,
      -0.609375,
      6.28125,
      0.61328125,
      -2.953125,
      -4,
      -2.375,
      4.59375,
      3.296875,
      -5.84375,
      0.71484375,
      0.85546875,
      -2.21875,
      3.671875,
      -0.64453125,
      -0.2890625,
      -2.671875,
      0.306640625,
      1.390625,
      -3.359375,
      6.46875,
      2.984375,
      -5.875,
      0.52734375,
      0.34765625,
      1.1640625,
      0.2041015625,
      1.1484375,
      0.1279296875,
      -2.734375,
      -1.203125,
      3.875,
      -0.7109375,
      -3.71875,
      -0.890625,
      1.390625,
      -4.625,
      4.75,
      -3.625,
      -0.470703125,
      -2.625,
      -1.2578125,
      3.46875,
      2.1875,
      2.296875,
      -0.044921875,
      2.765625,
      3.0625,
      -3.15625,
      5.71875,
      -5.09375,
      -1.75,
      0.609375,
      -4.875,
      -3.546875,
      0.7109375,
      -0.56640625,
      2.234375,
      -0.0537109375,
      -1.7109375,
      -1.5703125,
      -6.4375,
      -1.6875,
      1.2265625,
      0.115234375,
      2.03125,
      -0.396484375,
      7.625,
      -2.15625,
      -1.2265625,
      1.921875,
      -1.2890625,
      -2.59375,
      -1.6640625,
      -1.4921875,
      -6.75,
      0.267578125,
      5.5625,
      4.46875,
      -1.4296875,
      7.03125,
      -0.1630859375,
      -1.7890625,
      -0.91796875,
      6.21875,
      -1.109375,
      -0.48828125,
      1.2421875,
      -0.61328125,
      -1.359375,
      -4.84375,
      -0.83984375,
      -2,
      3.5,
      -1.484375,
      -0.11328125,
      1.25,
      -4.4375,
      2.3125,
      -0.9375,
      -2.90625,
      -1.0859375,
      3.890625,
      -0.55859375,
      -1.8125,
      4.5625,
      1.3203125,
      2.375,
      2.390625,
      -1.7890625,
      4.90625,
      0.32421875,
      2.5,
      -3.75,
      -4.5625,
      -0.984375,
      -0.279296875,
      -1.125,
      2.21875,
      -2.203125,
      0.76953125,
      5.375,
      1.3046875,
      -4.9375,
      -1.6171875,
      4.3125,
      -0.8203125,
      0.130859375,
      -0.419921875,
      4.0625,
      1.3203125,
      1.734375,
      -0.953125,
      -4.78125,
      -1.9296875,
      4.65625,
      3.1875,
      -1.5703125,
      1.109375,
      4.21875,
      0.59375,
      3.421875,
      -4.78125,
      -5.1875,
      1.28125,
      -0.016845703125,
      -0.84765625,
      -1.6640625,
      8.25,
      -4.75,
      0.0595703125,
      -0.29296875,
      0.6328125,
      0.010986328125,
      1.609375,
      -0.96875,
      0.44921875,
      2.1875,
      -1.1953125,
      1.3828125,
      3.921875,
      -0.75390625,
      -0.390625,
      0.4921875,
      -0.29296875,
      -1.609375,
      2.15625,
      1.375,
      -1.1484375,
      -1.40625,
      -0.703125,
      -1.546875,
      4.6875,
      5.875,
      0.79296875,
      -0.73046875,
      2.65625,
      5.75,
      -0.10595703125,
      6.6875,
      1.5703125,
      9.1875,
      -2.546875,
      -2.34375,
      4.75,
      -4.28125,
      0.1953125,
      2.265625,
      -6.5,
      -0.494140625,
      -0.578125,
      -1.203125,
      -3.578125,
      1.046875,
      -3.625,
      -2.15625,
      6.28125,
      2.59375,
      0.30859375,
      3.734375,
      5.5625,
      0.85546875,
      -0.96875,
      -4.625,
      -2.6875,
      1.0390625,
      0.80078125,
      2.390625,
      -1.8828125,
      0.9296875,
      1.8125,
      2.34375,
      1.078125,
      -0.0546875,
      -2.390625,
      5.78125,
      0.22265625,
      0.384765625,
      5.21875,
      -2.234375,
      2.734375,
      0.255859375,
      3.578125,
      -3.859375,
      -1.28125,
      8.25,
      2.484375,
      -1.9921875,
      0.796875,
      0.328125,
      0.19140625,
      -2.328125,
      -1.8046875,
      -0.60546875,
      0.37109375,
      -3.828125,
      -1.6796875,
      -0.33984375,
      1.8828125,
      -3,
      1.7265625,
      2.15625,
      -4.375,
      1.265625,
      -0.330078125,
      -0.66015625,
      3.4375,
      0.75390625,
      4.5625,
      0.9609375,
      -3.109375,
      -5.25,
      -4.40625,
      -2.078125,
      0.365234375,
      2.0625,
      1.8671875,
      0.6484375,
      -3.53125,
      0.92578125,
      -5.71875,
      -0.44921875,
      -6.25,
      4.6875,
      0.00421142578125,
      -6.21875,
      -0.9453125,
      -2.6875,
      -7.40625,
      -2.640625,
      -1.390625,
      -2.53125,
      -1.21875,
      -4.53125,
      -0.0198974609375,
      -1.28125,
      -4.09375,
      -0.06689453125,
      -2.3125,
      -1.0625,
      3.25,
      -0.5703125,
      2.296875,
      -5.125,
      1.0625,
      0.90625,
      -0.68359375,
      2.28125,
      1.53125,
      4.71875,
      4.78125,
      -0.953125,
      2.34375,
      -2.203125,
      3.890625,
      -2.90625,
      8.75,
      4.375,
      0.30859375,
      -6.21875,
      2.203125,
      -0.78515625,
      0.67578125,
      -4.84375,
      -1.7734375,
      -0.953125,
      -2.6875,
      -0.8515625,
      0.26171875,
      2.5,
      -4.6875,
      -3.015625,
      0.58203125,
      -4.5625,
      1.9140625,
      2.390625,
      -0.609375,
      4.8125,
      -0.19921875,
      2.953125,
      1.125,
      2.140625,
      2.453125,
      -1.8515625,
      4.0625,
      -6.84375,
      2.453125,
      0.2353515625,
      -1.0546875,
      -0.56640625,
      -2.6875,
      1.34375,
      -1.0859375,
      0.74609375,
      2.390625,
      2.46875,
      1.171875,
      -0.625,
      5.15625,
      -1.2421875,
      -0.765625,
      -0.359375,
      -1.59375,
      3.859375,
      1.65625,
      1.7421875,
      -3.15625,
      1.375,
      -2.859375,
      0.009521484375,
      2.078125,
      -3.203125,
      -1.3984375,
      -1.4765625,
      -4.46875,
      5.78125,
      -1.8828125,
      -0.2421875,
      2.3125,
      3.078125,
      3.15625,
      3.453125,
      1.7421875,
      1.71875,
      1.2421875,
      -5.34375,
      5.0625,
      -1.25,
      -3.34375,
      4.9375,
      3.1875,
      6.625,
      -2.140625,
      -2.265625,
      -2.03125,
      -3.625,
      7.1875,
      -2.921875,
      -0.6015625,
      7.46875,
      -1.0390625,
      0.09521484375,
      -1.8515625,
      0.1650390625,
      1.15625,
      -0.9453125,
      -1.7890625,
      8.8125,
      5.71875,
      -2.28125,
      -1.03125,
      -3.9375,
      -2.859375,
      -1.75,
      -1.6953125,
      0.392578125,
      -0.77734375,
      1.9921875,
      1,
      -0.61328125,
      -1.515625,
      0.84765625,
      -1.71875,
      2.546875,
      3.21875,
      0.24609375,
      1.375,
      -1.4765625,
      1.7734375,
      -2.21875,
      1.859375,
      3.921875,
      -5.03125,
      1.4296875,
      3.0625,
      -0.82421875,
      3.28125,
      2.34375,
      -0.7578125,
      -1.3984375,
      -0.55078125,
      0.83203125,
      1.0390625,
      -0.86328125,
      0.875,
      -4.5,
      1.328125,
      4.84375,
      2.6875,
      -3.5625,
      5.875,
      0.48828125,
      -2.859375,
      1.8515625,
      -1.890625,
      -4.09375,
      1.640625,
      -3.34375,
      0.98828125,
      -0.1591796875,
      -1.0546875,
      0.423828125,
      1.359375,
      -6.78125,
      4.9375,
      -3.375,
      6.15625,
      1.53125,
      -0.5859375,
      0.50390625,
      -0.46875,
      -0.6328125,
      -1.0546875,
      2.125,
      2.078125,
      -2.28125,
      0.99609375,
      -3.546875,
      -0.1279296875,
      -3.171875,
      -2.34375,
      4.53125,
      -2.140625,
      2.515625,
      -1.9921875,
      2.21875,
      -7,
      -2.609375,
      -0.73828125,
      -0.287109375,
      0.0262451171875,
      2.796875,
      1.8046875,
      -1.3671875,
      1.59375,
      -2.96875,
      0.9453125,
      -3.921875,
      -1.078125,
      0.2373046875,
      -1.34375,
      1.546875,
      0.71484375,
      -2.03125,
      1.84375,
      -0.91015625,
      -3.609375,
      -1.28125,
      -1.875,
      2.125,
      -1.078125,
      -1.9375,
      0.75390625,
      1.5078125,
      1.265625,
      -0.85546875,
      1.1171875,
      0.64453125,
      3.109375,
      -0.80078125,
      2.21875,
      -0.92578125,
      -2.453125,
      -3.1875,
      -3.671875,
      -5.21875,
      1.765625,
      3.375,
      -3.890625,
      1.7421875,
      0.0240478515625,
      2.421875,
      1.796875,
      0.91796875,
      -0.63671875,
      1.9609375,
      1.7265625,
      0.71484375,
      -0.1240234375,
      2.25,
      -0.76171875,
      3.59375,
      -1.1640625,
      -3.09375,
      -2.265625,
      -1.6171875,
      -0.55859375,
      1.46875,
      -0.57421875,
      -2.296875,
      -1.9921875,
      -2.65625,
      -0.70703125,
      -3.640625,
      5.9375,
      2.15625,
      5.65625,
      2.984375,
      -0.7421875,
      0.373046875,
      -0.2314453125,
      0.138671875,
      3.140625,
      0.435546875,
      0.734375,
      0.0859375,
      -0.474609375,
      2.78125,
      -3.953125,
      -1.96875,
      -4.15625,
      0.38671875,
      4.65625,
      -0.1181640625,
      0.01025390625,
      1.2890625,
      -1.0234375,
      1.03125,
      0.255859375,
      3.734375,
      -1.3984375,
      -0.8828125,
      -0.96875,
      2.375,
      1.4765625,
      -3.53125,
      1.1640625,
      0.75,
      -0.9921875,
      0.412109375,
      2.4375,
      6.21875,
      -0.6953125,
      3.890625,
      -1.8359375,
      -4,
      -4.25,
      2.953125,
      -0.625,
      0.267578125,
      -1.4140625,
      -6.34375,
      -0.419921875,
      -2.46875,
      -1.6953125,
      6.21875,
      0.65625,
      3.671875,
      -0.50390625,
      3.921875,
      -0.022216796875,
      -5.625,
      -3.328125,
      3.40625,
      1.140625,
      -5.3125,
      0.0091552734375,
      -4.46875,
      -0.5859375,
      -1.21875,
      -8.25,
      0.671875,
      1.390625,
      3.828125,
      2.296875,
      0.2265625,
      2.25,
      -0.7890625,
      -4.25,
      -2.921875,
      -1.265625,
      3.125,
      2.21875,
      1.0078125,
      -2.953125,
      1.265625,
      -3.703125,
      1.0703125,
      -3.625,
      4.6875,
      -0.5390625,
      5.34375,
      1.4140625,
      4.84375,
      -8.375,
      -2.46875,
      -2.96875,
      -2.6875,
      -3.421875,
      -0.24609375,
      0.8359375,
      1.53125,
      1.65625,
      0.2177734375,
      -2.890625,
      -1.03125,
      -2.375,
      3.640625,
      1.2734375,
      0.5078125,
      -1.0078125,
      -0.08740234375,
      -5.3125,
      -1.671875,
      2.40625,
      -2.21875,
      -3.40625,
      3.71875,
      -0.93359375,
      4.84375,
      2.328125,
      0.208984375,
      -2.078125,
      4.40625,
      -0.578125,
      -4.375,
      -5.71875,
      -0.74609375,
      -0.220703125,
      -5.75,
      1.234375,
      -3.359375,
      1.390625,
      -4.53125,
      0.12451171875,
      -0.388671875,
      -1.4375,
      0.82421875,
      5.625,
      2.421875,
      -2.453125,
      3.015625,
      -3.703125,
      6.5625,
      3.921875,
      0.5859375,
      2.25,
      0.52734375,
      1.0703125,
      -4.46875,
      4.625,
      -0.703125,
      -3.109375,
      3.578125,
      5.25,
      -3.84375,
      -0.111328125,
      0.8046875,
      1,
      -1.296875,
      0.0225830078125,
      -3,
      4.8125,
      -1.5,
      -0.89453125,
      -5.40625,
      1.0546875,
      2.171875,
      -1.328125,
      2.453125,
      -1.625,
      2.8125,
      -4.125,
      -4.625,
      3.0625,
      2.21875,
      4.25,
      -3.421875,
      1.3984375,
      2.859375,
      1.1015625,
      2.875,
      -1.046875,
      -4.09375,
      -1.28125,
      0.57421875,
      -5,
      0.2412109375,
      -4.84375,
      -0.337890625,
      -4.1875,
      0.5078125,
      -4.3125,
      0.875,
      0.3046875,
      -1.2890625,
      -2.6875,
      -3.6875,
      -5.75,
      -3.171875,
      -1.1875,
      -1.4296875,
      -6.40625,
      -2.359375,
      1.734375,
      3.640625,
      4.34375,
      6.28125,
      3.640625,
      -1.6171875,
      0.81640625,
      -1.078125,
      0.310546875,
      0.25,
      0.232421875,
      -1.6484375,
      -2.1875,
      1.0234375,
      -0.38671875,
      5.28125,
      -3.390625,
      -2.546875,
      -3.484375,
      0.2578125,
      -1.5,
      1.0546875,
      0.58203125,
      -0.80078125,
      4.6875,
      -2.953125,
      2.859375,
      3.09375,
      -1.5859375,
      -5.125,
      4.1875,
      -1,
      2.09375,
      2.890625,
      0.43359375,
      -4.96875,
      3.171875,
      3.9375,
      -4.09375,
      3.625,
      1.0546875,
      -1.4140625,
      -3.359375,
      0.060302734375,
      1.1171875,
      5.5625,
      -1.8515625,
      3.515625,
      4.125,
      -1.046875,
      3.65625,
      5.5,
      -0.447265625,
      -2.1875,
      2.296875,
      0.51953125,
      -2.015625,
      -2.390625,
      1.8046875,
      -2.640625,
      -4.75,
      3.78125,
      2.53125,
      -0.96875,
      -0.546875,
      -1.546875,
      4.28125,
      3.375,
      -3.90625,
      0.50390625,
      -4.25,
      1.6875,
      -2.921875,
      -1,
      -4.71875,
      -0.5859375,
      -0.6796875,
      6.125,
      -2.515625,
      -4.09375,
      5,
      5.21875,
      -1.0078125,
      -1.1484375,
      5.125,
      1.3203125,
      -1,
      -4.3125,
      -2.578125,
      5.59375,
      1.3828125,
      4.9375,
      -0.7890625,
      1.234375,
      0.87890625,
      -2.421875,
      -5.65625,
      1.1875,
      -2.3125,
      -5.125,
      -3.21875,
      -2.359375,
      2.703125,
      -2.765625,
      4.09375,
      3.859375,
      0.46875,
      2.15625,
      0.36328125,
      2.828125,
      3.109375,
      -3.640625,
      1.390625,
      1.4609375,
      -2.984375,
      0.44140625,
      0.91796875,
      -2.21875,
      0.31640625,
      -2.5625,
      1.8515625,
      3.390625,
      -0.8203125,
      -1.8984375,
      -6.96875,
      2.46875,
      3.75,
      5.09375,
      -0.2431640625,
      -4.46875,
      1.6171875,
      1.375,
      -2.65625,
      -1.328125,
      2.3125,
      0.859375,
      1.578125,
      -1.515625,
      -1.0234375,
      4.78125,
      0.98828125,
      1.734375,
      -1.453125,
      -4,
      -2.5625,
      -0.875,
      -3.34375,
      -0.134765625,
      -2.09375,
      5.96875,
      -1.8984375,
      -0.953125,
      0.25,
      6.125,
      1.578125,
      2.3125,
      0.02880859375,
      0.3125,
      -0.169921875,
      3.078125,
      2.6875,
      -3.703125,
      1.765625,
      -0.2158203125,
      -1.078125,
      -2.546875,
      -1.75,
      -1.4453125,
      1.3203125,
      -4.15625,
      -0.396484375,
      -0.1357421875,
      2.125,
      -1.7890625,
      -9.6875,
      0.578125,
      1.15625,
      -3.28125,
      -2.203125,
      -2.34375,
      1.28125,
      6.53125,
      1.21875,
      5.0625,
      0.123046875,
      -2.953125,
      3.4375,
      13.9375,
      -3.078125,
      -3.75,
      0.439453125,
      -1.171875,
      6.1875,
      6.3125,
      0.58203125,
      2.75,
      1.0859375,
      -0.337890625,
      3.65625,
      0.76953125,
      4.40625,
      0.9765625,
      1.5078125,
      3.109375,
      0.92578125,
      -3.0625,
      -5.65625,
      -1.171875,
      -1.1171875,
      -1.4140625,
      2.078125,
      -1.5703125,
      0.4296875,
      0.8515625,
      -2.984375,
      -1.8828125,
      -2.421875,
      -3.65625,
      -0.9140625,
      -0.478515625,
      -1.796875,
      -0.65625,
      -3.796875,
      -0.94921875,
      0.455078125,
      -0.212890625,
      -3.6875,
      -5.5,
      -6.3125,
      2.203125,
      -1.125,
      -5.15625,
      2.1875,
      -3.171875,
      -3.421875,
      0.1572265625,
      -0.765625,
      -1.09375,
      0.1630859375,
      -6.65625,
      0.61328125,
      0.353515625,
      -0.92578125,
      -1.1953125,
      -3.5625,
      -4.40625,
      -4.28125,
      -1.3203125,
      -0.765625,
      -0.55078125,
      -3.46875,
      -3.796875,
      -3.234375,
      -0.86328125,
      1.875,
      1.265625,
      1.2890625,
      -3.015625,
      -1.4609375,
      2.9375,
      2.96875,
      -0.87890625,
      -3.640625,
      2.125,
      1.046875,
      1.015625,
      2.703125,
      -3.390625,
      2.703125,
      -2.03125,
      -0.9765625,
      -0.390625,
      1.7265625,
      -4.75,
      0.279296875,
      2.1875,
      -2.484375,
      6.3125,
      -5.625,
      3.09375,
      -0.2412109375,
      -6.46875,
      -0.376953125,
      0.8984375,
      1.515625,
      -2.28125,
      -0.79296875,
      2.109375,
      -1.3203125,
      1.75,
      0.498046875,
      -0.01055908203125,
      1.3984375,
      0.94140625,
      -5.1875,
      -0.049072265625,
      1.3203125,
      0.8671875,
      4.40625,
      2.53125,
      -0.50390625,
      -0.734375,
      4.375,
      -1.203125,
      -1.4296875,
      -3.21875,
      -2.1875,
      5.875,
      1.1328125,
      -0.859375,
      0.458984375,
      -7,
      -3.8125,
      -1.484375,
      -5.25,
      3.953125,
      -1.1484375,
      0.380859375,
      -3.359375,
      -4.15625,
      0.1064453125,
      3.09375,
      -4.21875,
      3.78125,
      2.453125,
      4.03125,
      0.13671875,
      -3.25,
      1.53125,
      0.94140625,
      -1.9609375,
      -3.515625,
      3.5625,
      -2.84375,
      2.4375,
      5,
      2.375,
      -4.75,
      4.3125,
      -1.453125,
      -4.71875,
      -0.341796875,
      2.921875,
      -1.7890625,
      -1.2109375,
      -4.6875,
      0.0654296875,
      -0.5,
      -2.0625,
      -1.1328125,
      -5.40625,
      -2.546875,
      -0.82421875,
      3.09375,
      1.3046875,
      -4.875,
      2.59375,
      2.703125,
      -5.875,
      -0.07470703125,
      -4.75,
      4.5625,
      -1.59375,
      2.859375,
      4.375,
      -0.69921875,
      -0.828125,
      1.1640625,
      1.9140625,
      -1.625,
      -4.1875,
      3.578125,
      2.09375,
      -3.859375,
      3.171875,
      3.109375,
      -2.0625,
      -0.296875,
      -4.46875,
      -1.40625,
      5.21875,
      3.421875,
      -3.390625,
      -2.015625,
      -0.76953125,
      1.296875,
      -4.53125,
      -5.25,
      4.0625,
      1.515625,
      1.9609375,
      1.8359375,
      1.265625,
      -3.09375,
      -1.8671875,
      -0.5078125,
      -2.1875,
      -3.390625,
      2.625,
      -2.15625,
      3.609375,
      -3.4375,
      6.09375,
      2.828125,
      1.2109375,
      -1.484375,
      0.1943359375,
      2.484375,
      1.0234375,
      -4,
      0.27734375,
      0.48046875,
      3.984375,
      -6.375,
      4.28125,
      -2.71875,
      2.984375,
      -4.71875,
      4.03125,
      -0.6796875,
      -0.490234375,
      -5.21875,
      -4.15625,
      -3.265625,
      3.515625,
      1.15625,
      0.87109375,
      3.296875,
      -0.55859375,
      0.359375,
      -0.265625,
      -3.421875,
      1.609375,
      -2.46875,
      -0.036865234375,
      1.1875,
      -0.7421875,
      0.875,
      0.275390625,
      7.1875,
      -2.65625,
      -1,
      -2.28125,
      -2.265625,
      -0.59765625,
      -4.71875,
      2.515625,
      -1.8203125,
      -3.546875,
      3.421875,
      2.03125,
      -2.15625,
      2.984375,
      1.1953125,
      -2.65625,
      4.625,
      3.46875,
      -5.4375,
      4.8125,
      -0.9765625,
      -3.8125,
      0.50390625,
      -0.72265625,
      -0.77734375,
      -5.96875,
      -0.435546875,
      4.09375,
      -3.390625,
      0.04345703125,
      2.140625,
      0.80859375,
      0.2255859375,
      -2.78125,
      5.21875,
      1.7890625,
      1.6015625,
      2.71875,
      4.09375,
      2.984375,
      -4.9375,
      0.6015625,
      -1.90625,
      -0.52734375,
      -2.625,
      -4.5625,
      2.40625,
      -1.25,
      3.078125,
      4.5,
      -1.53125,
      -9.75,
      -3.75,
      2.25,
      -2.125,
      2.9375,
      1.90625,
      1.0625,
      -2.09375,
      0.57421875,
      0.9375,
      4.1875,
      -1.1015625,
      -0.90234375,
      -5.625,
      0.33984375,
      -0.8046875,
      -5.75,
      0.7890625,
      0.92578125,
      -0.376953125,
      -2.296875,
      0.609375,
      -1.0390625,
      0.83203125,
      3.46875,
      -4.53125,
      2.40625,
      -0.92578125,
      -0.55859375,
      5.96875,
      0.44921875,
      5.15625,
      3.0625,
      -2.75,
      -5.21875,
      0.099609375,
      -0.1494140625,
      1.1484375,
      1.7265625,
      1.171875,
      5.03125,
      0.2333984375,
      2.4375,
      -6.96875,
      5.03125,
      0.232421875,
      -11.125,
      2.34375,
      -3,
      0.71875,
      -0.6953125,
      -8.625,
      -3,
      4.1875,
      -0.89453125,
      -0.828125,
      5.84375,
      0.56640625,
      0.353515625,
      1.4609375,
      -0.498046875,
      -4.875,
      2.15625,
      3.921875,
      -2.328125,
      0.275390625,
      3.828125,
      -2.078125,
      0.8125,
      -0.1376953125,
      2.796875,
      0.12158203125,
      -3.375,
      3.140625,
      2.40625,
      -2.453125,
      -3.28125,
      -4.1875,
      -0.05029296875,
      0.98828125,
      -3.703125,
      1.4609375,
      -2.21875,
      2.28125,
      -1.828125,
      -0.06103515625,
      -0.294921875,
      -4.03125,
      -1.640625,
      -2.875,
      -2.109375,
      0.94921875,
      3.0625,
      2.96875,
      -2.15625,
      -2.0625,
      4.1875,
      0.30859375,
      -0.7109375,
      -2.734375,
      3.984375,
      -3.265625,
      -3.046875,
      -2.609375,
      4.125,
      -2.640625,
      -3,
      1.953125,
      -0.62109375,
      -2.3125,
      -3.59375,
      -3,
      2.421875,
      -1.890625,
      -1.5703125,
      -2.1875,
      -0.88671875,
      3.703125,
      4.5625,
      -4.78125,
      -3.40625,
      -2.859375,
      -0.82421875,
      -5.375,
      -3.421875,
      -0.64453125,
      -2.96875,
      0.87890625,
      5.125,
      0.0167236328125,
      1.1015625,
      0.2734375,
      -6.875,
      -2.484375,
      3.90625,
      1.4140625,
      -3.65625,
      1.4140625,
      -0.96484375,
      -4.25,
      4.84375,
      9.625,
      2.5625,
      -3.5,
      1,
      -1.265625,
      -2.453125,
      -1.8203125,
      2.46875,
      -0.5234375,
      -5,
      5.90625,
      -2.859375,
      4.28125,
      1.953125,
      -1.1875,
      5.84375,
      -4.96875,
      3.0625,
      -1.296875,
      0.65234375,
      3.453125,
      -4.5,
      -1.9375,
      -3.640625,
      -2.625,
      1.1484375,
      -0.6171875,
      1.046875,
      -1.1953125,
      2.703125,
      2.265625,
      0.69140625,
      -0.7265625,
      -0.1513671875,
      5.34375,
      -4.4375,
      -0.421875,
      -2.359375,
      -1.6171875,
      -0.251953125,
      -2.6875,
      1.5703125,
      -5.0625,
      2.34375,
      0.58984375,
      1.6796875,
      1.2109375,
      1.78125,
      -3.359375,
      -2.375,
      -5.84375,
      1.09375,
      1.21875,
      4.96875,
      1.515625,
      1.9921875,
      3.171875,
      0.296875,
      3.5625,
      4.1875,
      6.28125,
      -3.71875,
      0.5859375,
      -0.89453125,
      0.396484375,
      -0.06201171875,
      -1.2421875,
      -0.5859375,
      1.1640625,
      4.75,
      0.30078125,
      -2.015625,
      -3.578125,
      -1.6953125,
      -2.546875,
      -1.15625,
      1.7734375,
      2.6875,
      0.73046875,
      0.765625,
      -1.15625,
      0.890625,
      0.83203125,
      5.1875,
      0.7890625,
      0.59375,
      -2.765625,
      1.8125,
      -2.828125,
      -2.078125,
      2.859375,
      -2.0625,
      2.453125,
      -1.09375,
      -1.3203125,
      -0.57421875,
      1.96875,
      -3.859375,
      3.09375,
      -1.625,
      2.4375,
      1.234375,
      1.5859375,
      -2.671875,
      1.53125,
      0.05029296875,
      2.609375,
      -3.75,
      -0.9609375,
      2.859375,
      2.5625,
      0.10205078125,
      0.318359375,
      -0.10400390625,
      0.94921875,
      0.6953125,
      -1.4453125,
      -1.0390625,
      -1.078125,
      3.328125,
      -0.58203125,
      0.58984375,
      2.109375,
      0.447265625,
      -3.65625,
      2.171875,
      -0.875,
      -0.6328125,
      -3.5,
      -0.255859375,
      2.8125,
      1.015625,
      -0.0234375,
      -0.94921875,
      -3.421875,
      -2.3125,
      -2.78125,
      -3.875,
      -0.140625,
      -2.53125,
      -4.59375,
      1.6484375,
      2.703125,
      0.40234375,
      0.44921875,
      0.255859375,
      1.3671875,
      0.10205078125,
      -2.3125,
      -0.1767578125,
      1.296875,
      0.470703125,
      -2.328125,
      2.21875,
      1.4140625,
      2.3125,
      2.40625,
      -0.85546875,
      0.498046875,
      -0.77734375,
      0.625,
      0.392578125,
      -2.203125,
      0.47265625,
      0.46875,
      -1.59375,
      -0.8203125,
      -0.68359375,
      -1.3046875,
      0.1357421875,
      -1.3515625,
      -1.015625,
      1.609375,
      0.0869140625,
      -2.171875,
      2.3125,
      4.40625,
      -3.265625,
      -1.671875,
      -3.078125,
      -0.625,
      -0.322265625,
      1.3359375,
      -4.46875,
      0.58203125,
      -3.296875,
      -1.296875,
      -0.578125,
      1.2734375,
      1.546875,
      -3.90625,
      -0.6640625,
      -1.7421875,
      0.41015625,
      0.1142578125,
      2.609375,
      1.0234375,
      -4.9375,
      -3.328125,
      0.6015625,
      -0.5390625,
      -0.240234375,
      1.1796875,
      -2.0625,
      -1.3828125,
      2.75,
      3.1875,
      -0.7734375,
      -2.03125,
      1.265625,
      0.61328125,
      0.498046875,
      1.8359375,
      -0.1396484375,
      2.109375,
      0.11572265625,
      -1.7265625,
      0.275390625,
      -1.2421875,
      -0.39453125,
      -0.421875,
      -0.59375,
      0.275390625,
      -1.921875,
      -1.6328125,
      -2.078125,
      0.126953125,
      -2.734375,
      1.7421875,
      1.1484375,
      -1.421875,
      1.3359375,
      1.2578125,
      -0.25,
      2.46875,
      1.1953125,
      2.609375,
      -0.640625,
      0.384765625,
      0.64453125,
      2.15625,
      1.875,
      1.3203125,
      -2.03125,
      -1.4453125,
      0.345703125,
      1.1875,
      0.84375,
      -3.4375,
      3.390625,
      1.1875,
      0.87109375,
      1.8671875,
      0.87890625,
      0.7890625,
      1.28125,
      -4.03125,
      2.359375,
      2.6875,
      -0.63671875,
      -0.357421875,
      0.77734375,
      0.267578125,
      -0.8671875,
      -1.1953125,
      -0.2578125,
      -1.1015625,
      3.546875,
      -0.0299072265625,
      1.1015625,
      1.8203125,
      -2.21875,
      -0.1640625,
      -1.453125,
      1.3046875,
      -2.28125,
      5,
      -2.53125,
      1.4375,
      2.859375,
      0.150390625,
      -1.9296875,
      -0.46875,
      -8,
      -1.8984375,
      -0.7578125,
      0.57421875,
      -0.50390625,
      -1.2109375,
      -1.5390625,
      -2.25,
      -0.259765625,
      0.6328125,
      -2.328125,
      2.296875,
      2.03125,
      1.859375,
      2.203125,
      0.4921875,
      -3.578125,
      -0.80078125,
      3.3125,
      -1.3515625,
      3.171875,
      0.028564453125,
      -2.078125,
      -1.2265625,
      -1.8828125,
      -5.4375,
      -0.72265625,
      -1.546875,
      1.0234375,
      1.203125,
      5.96875,
      1.28125,
      -2.53125,
      -0.58203125,
      0.578125,
      2.6875,
      -1.234375,
      -2.53125,
      3.203125,
      -0.68359375,
      0.94921875,
      -2.171875,
      -0.59375,
      -2.296875,
      0.400390625,
      1.65625,
      -0.4765625,
      3.578125,
      -0.58203125,
      -1.328125,
      0.0198974609375,
      -0.251953125,
      0.41796875,
      1.34375,
      0.0169677734375,
      4.75,
      0.4921875,
      0.70703125,
      2.015625,
      3.703125,
      0.3515625,
      -0.83203125,
      3.03125,
      0.03662109375,
      3.328125,
      4.125,
      -2.84375,
      -3.140625,
      2.09375,
      0.8515625,
      0.333984375,
      0.51171875,
      0.283203125,
      3.59375,
      -0.83203125,
      0.65625,
      1.328125,
      -0.349609375,
      -2.640625,
      -1.421875,
      2.984375,
      -4.78125,
      -0.419921875,
      0.6796875,
      -2.046875,
      -0.1513671875,
      0.87890625,
      4.15625,
      1.2890625,
      0.26953125,
      1.4296875,
      1.109375,
      -0.474609375,
      0.41015625,
      -1.34375,
      1.859375,
      3.609375,
      -0.08349609375,
      -2.34375,
      1.75,
      2.9375,
      4.03125,
      0.1328125,
      -2.375,
      3.140625,
      0.69921875,
      1.1015625,
      0.74609375,
      -1.3984375,
      2.34375,
      1.9921875,
      -0.353515625,
      -0.51171875,
      -1.5859375,
      0.64453125,
      2.765625,
      0.515625,
      -2.546875,
      3.515625,
      1.1015625,
      -1.8984375,
      -1.1640625,
      -0.65234375,
      -1.5078125,
      -1.546875,
      -2.5625,
      -0.76953125,
      -2.078125,
      5,
      -3.1875,
      0.25,
      2.140625,
      2.328125,
      2.890625,
      2.953125,
      1.125,
      2.34375,
      -4.90625,
      -0.7890625,
      1.6953125,
      -1.5234375,
      -4.4375,
      1.7109375,
      -2.140625,
      -4.875,
      0.7109375,
      -1.0546875,
      -1.5390625,
      -1.59375,
      -0.4453125,
      -1.984375,
      -2.5,
      0.6875,
      -1.46875,
      1.328125,
      -4.21875,
      -1.109375,
      -0.5,
      3.578125,
      0.8828125,
      -1.734375,
      2.0625,
      -0.1953125,
      0.79296875,
      0.458984375,
      -0.55859375,
      -0.6953125,
      -1.9296875,
      1.3046875,
      1.890625,
      -1.296875,
      -1.0390625,
      -1.390625,
      3.5625,
      -1.7890625,
      -0.8515625,
      -1.4921875,
      -1.1953125,
      0.0177001953125,
      7.0625,
      2.75,
      0.85546875,
      -2.296875,
      -2.03125,
      -0.58203125,
      3.828125,
      -0.71484375,
      -1.65625,
      -2.046875,
      3.21875,
      -1.8125,
      -1.2890625,
      -1.09375,
      0.7421875,
      -1.296875,
      -3.3125,
      0.37890625,
      -3.890625,
      0.2578125,
      4.59375,
      1.03125,
      -0.12890625,
      -1.6328125,
      2.671875,
      -3.40625,
      3.515625,
      -1.125,
      0.00726318359375,
      5.125,
      0.61328125,
      0.34375,
      1.0703125,
      0.8671875,
      0.177734375,
      2.515625,
      1.1171875,
      2.40625,
      2.5,
      -0.5078125,
      -1.03125,
      0.23828125,
      2.4375,
      -0.5546875,
      -3.171875,
      -1.0078125,
      -1.4765625,
      -4.1875,
      0.25390625,
      3.859375,
      1.28125,
      0.234375,
      1.171875,
      2.203125,
      -0.06982421875,
      2.734375,
      2.875,
      -0.1416015625,
      0.181640625,
      -1.0859375,
      -2.828125,
      -2.6875,
      1.328125,
      -0.671875,
      1.125,
      1.3828125,
      -1.453125,
      1.46875,
      -1.6640625,
      4.875,
      -2.171875,
      0.6484375,
      -0.173828125,
      -1.2265625,
      -3.015625,
      -2.421875,
      -2.625,
      2.6875,
      -1.359375,
      -0.2275390625,
      2.15625,
      -0.0068359375,
      -1.5078125,
      -1.4140625,
      -0.259765625,
      2.890625,
      -0.5078125,
      -3.65625,
      -0.1943359375,
      3.71875,
      -1.640625,
      0.96875,
      4.4375,
      2.140625,
      0.095703125,
      0.2275390625,
      1.78125,
      -3.875,
      -0.05908203125,
      0.06298828125,
      1.2734375,
      3,
      -2.453125,
      -4.03125,
      2.640625,
      1.9296875
    ],
    "summary": "# 🎯 结构化速读\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 学生快速采用LLM工具，但缺乏对其真实学习效果的系统研究，特别是对阅读理解与记忆保留的影响[cite] |\n| **核心方案** | 通过随机对照实验，比较LLM使用、传统笔记、以及两者结合对中学生学习效果的影响[cite] |\n| **关键概念** | \"学习原型\" - 识别学生使用LLM的不同行为模式，揭示个性化学习策略[cite] |\n| **核心数据** | 405名14-15岁学生，学习两篇文章，3天后测试理解和记忆[cite] |\n| **核心假设** | 传统笔记比单纯使用LLM更能促进深度认知加工和长期记忆[cite] |\n| **主要结论** | 笔记单独使用或与LLM结合效果显著优于单纯LLM使用，但学生主观偏好LLM[cite] |\n\n# 💡 费曼解读\n\n想象一下，学习就像在健身房锻炼肌肉。传统笔记就像是**自己做深蹲和卧推** - 过程很累，但每个动作都在真正强化你的肌肉（大脑）。而LLM就像是**请了个私人教练帮你举重** - 轻松省力，教练（AI）展示标准动作，但你自己的肌肉并没有得到充分锻炼。\n\n这篇论文发现了一个有趣的现象：学生们普遍喜欢请\"私人教练\"，因为**感觉**更轻松高效。但实际测试发现，那些坚持自己\"举重\"（做笔记）的学生，三天后肌肉记忆（知识保留）明显更好。\n\n为什么会出现这种\"感觉vs现实\"的差距？关键在于**认知加工的深度**。做笔记就像是你必须亲自消化食物 - 要咀嚼、要理解、要重新组织语言。这个过程强迫大脑建立更多的神经连接。而LLM直接给你\"预消化好的营养液\"，虽然容易吸收，但大脑的\"消化系统\"没有得到锻炼。\n\n更聪明的方法是**先自己尝试举重，再请教练纠正姿势** - 这就是笔记+LLM组合的效果最好[cite]。\n\n# ⚔️ 对抗性评审\n\n## 1. 实验生态效度问题\n**硬伤：** 实验设置过于理想化。现实中学生使用LLM是**开放式、多轮交互**的，而实验可能限制了使用方式。这就像研究\"社交媒体对社交能力的影响\"，但只允许被试发一条预设消息 - 严重低估了真实世界的复杂性。\n\n## 2. 长期效应缺失\n**硬伤：** 仅测试3天后的记忆效果[cite]。学习是一个**累积过程**，短期优势未必转化为长期能力。好比研究\"咖啡对工作效率的影响\"只观察喝完第一小时 - 完全忽略了后续的咖啡因崩溃。\n\n## 3. 主观偏好测量的表面性\n**硬伤：** 学生\"偏好\"LLM可能只是**新奇效应**或**认知懒惰**的体现。论文没有深入探究这种偏好背后的心理机制 - 是因为LLM真正提升了学习体验，还是仅仅因为它减少了即时认知负荷？\n\n# 📝 一句话总结\n\n如果我只记这篇论文的一个贡献，那应该是：**传统笔记的认知价值在AI时代依然不可替代，智能工具的最佳使用方式是辅助而非替代深度思考过程**。",
    "structure": {
      "sections": [
        {
          "title": "Effects of LLM use and note-taking on reading comprehension and memory: A randomised experiment in secondary schools",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Affiliations:",
          "level": 1,
          "start_line": 9
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 14
        },
        {
          "title": "Main",
          "level": 1,
          "start_line": 18
        },
        {
          "title": "Results",
          "level": 1,
          "start_line": 46
        },
        {
          "title": "Learning outcomes",
          "level": 1,
          "start_line": 50
        },
        {
          "title": "Behavioural engagement",
          "level": 1,
          "start_line": 71
        },
        {
          "title": "Prompting behaviour",
          "level": 1,
          "start_line": 75
        },
        {
          "title": "Learning experiences and perceptions",
          "level": 1,
          "start_line": 94
        },
        {
          "title": "Activity preferences",
          "level": 1,
          "start_line": 110
        },
        {
          "title": "Future use",
          "level": 1,
          "start_line": 122
        },
        {
          "title": "Discussion",
          "level": 1,
          "start_line": 126
        },
        {
          "title": "Materials and Methods",
          "level": 1,
          "start_line": 154
        },
        {
          "title": "Participants",
          "level": 1,
          "start_line": 158
        },
        {
          "title": "Experimental design and procedure",
          "level": 1,
          "start_line": 166
        },
        {
          "title": "Setup and system",
          "level": 1,
          "start_line": 194
        },
        {
          "title": "Apartheid in South Africa",
          "level": 1,
          "start_line": 200
        },
        {
          "title": "AI Chatbot ②",
          "level": 1,
          "start_line": 210
        },
        {
          "title": "Notepad",
          "level": 1,
          "start_line": 214
        },
        {
          "title": "Learning task and materials (Session 1)",
          "level": 1,
          "start_line": 229
        },
        {
          "title": "Test task and materials (Session 2)",
          "level": 1,
          "start_line": 243
        },
        {
          "title": "Survey questions",
          "level": 1,
          "start_line": 257
        },
        {
          "title": "Analytic strategies",
          "level": 1,
          "start_line": 265
        },
        {
          "title": "Estimation of condition effects on text comprehension and retention",
          "level": 1,
          "start_line": 271
        },
        {
          "title": "Qualitative exploration of student prompts",
          "level": 1,
          "start_line": 303
        },
        {
          "title": "Quantitative exploration of students' learning experience",
          "level": 1,
          "start_line": 309
        },
        {
          "title": "Qualitative exploration of students' activity preferences",
          "level": 1,
          "start_line": 313
        },
        {
          "title": "Data availability",
          "level": 1,
          "start_line": 326
        },
        {
          "title": "Code availability",
          "level": 1,
          "start_line": 330
        },
        {
          "title": "Ethics declarations",
          "level": 1,
          "start_line": 334
        },
        {
          "title": "Competing interests",
          "level": 1,
          "start_line": 336
        },
        {
          "title": "Acknowledgements",
          "level": 1,
          "start_line": 340
        },
        {
          "title": "Supplementary Material",
          "level": 1,
          "start_line": 344
        },
        {
          "title": "Table of Contents",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "Supplementary Information",
          "level": 1,
          "start_line": 348
        },
        {
          "title": "Supplementary Tables",
          "level": 1,
          "start_line": 352
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 375
        },
        {
          "title": "1 Supplementary Information",
          "level": 1,
          "start_line": 452
        },
        {
          "title": "1.1 Participant Exclusion Criteria",
          "level": 1,
          "start_line": 454
        },
        {
          "title": "2 Supplementary Tables",
          "level": 1,
          "start_line": 465
        },
        {
          "title": "2.1 Student Characteristics",
          "level": 1,
          "start_line": 467
        },
        {
          "title": "2.2 Familiarity with Learning Activities",
          "level": 1,
          "start_line": 476
        },
        {
          "title": "2.3 Descriptive Statistics",
          "level": 1,
          "start_line": 484
        },
        {
          "title": "2.4 Mixed Effects Regression Results",
          "level": 1,
          "start_line": 490
        },
        {
          "title": "2.5 Behavioural Engagement",
          "level": 1,
          "start_line": 496
        },
        {
          "title": "2.6 Student Task Instructions",
          "level": 1,
          "start_line": 502
        },
        {
          "title": "2.7 Test Questions",
          "level": 1,
          "start_line": 568
        },
        {
          "title": "2.8 Inter-rater Reliability Results",
          "level": 1,
          "start_line": 590
        },
        {
          "title": "2.9 Survey Questions and Response Scales",
          "level": 1,
          "start_line": 596
        },
        {
          "title": "2.10 Learning Experiences and Perceptions",
          "level": 1,
          "start_line": 625
        },
        {
          "title": "2.11 Coding Scheme Activity Preferences",
          "level": 1,
          "start_line": 631
        },
        {
          "title": "2.12 Coding Scheme Prompt Interactions",
          "level": 1,
          "start_line": 654
        },
        {
          "title": "2.13 Frequency of Prompt Types",
          "level": 1,
          "start_line": 692
        }
      ]
    },
    "tags": [
      "教育技术",
      "学习科学",
      "LLM评估"
    ],
    "suggested_tags": [
      "教育技术",
      "学习科学",
      "LLM评估",
      "人机交互"
    ],
    "tag_suggestions": [
      {
        "name": "教育技术",
        "confidence": 0.95,
        "reason": "论文研究LLM在中学教育场景中的应用效果，属于教育技术领域"
      },
      {
        "name": "学习科学",
        "confidence": 0.9,
        "reason": "研究阅读理解和记忆保留的认知过程，涉及学习科学的理论基础"
      },
      {
        "name": "LLM评估",
        "confidence": 0.85,
        "reason": "采用随机对照实验方法评估LLM对学习效果的影响"
      },
      {
        "name": "人机交互",
        "confidence": 0.8,
        "reason": "分析学生与LLM的交互行为模式，包括提示策略和用户体验"
      }
    ],
    "tags_confirmed": true,
    "category": "教育技术",
    "analysis": {
      "status": "completed",
      "started_at": "2025-12-21T14:00:02.487775",
      "completed_at": "2025-12-21T14:01:15.433383",
      "summary": "# 🎯 结构化速读\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 学生快速采用LLM工具，但缺乏对其真实学习效果的系统研究，特别是对阅读理解与记忆保留的影响[cite] |\n| **核心方案** | 通过随机对照实验，比较LLM使用、传统笔记、以及两者结合对中学生学习效果的影响[cite] |\n| **关键概念** | \"学习原型\" - 识别学生使用LLM的不同行为模式，揭示个性化学习策略[cite] |\n| **核心数据** | 405名14-15岁学生，学习两篇文章，3天后测试理解和记忆[cite] |\n| **核心假设** | 传统笔记比单纯使用LLM更能促进深度认知加工和长期记忆[cite] |\n| **主要结论** | 笔记单独使用或与LLM结合效果显著优于单纯LLM使用，但学生主观偏好LLM[cite] |\n\n# 💡 费曼解读\n\n想象一下，学习就像在健身房锻炼肌肉。传统笔记就像是**自己做深蹲和卧推** - 过程很累，但每个动作都在真正强化你的肌肉（大脑）。而LLM就像是**请了个私人教练帮你举重** - 轻松省力，教练（AI）展示标准动作，但你自己的肌肉并没有得到充分锻炼。\n\n这篇论文发现了一个有趣的现象：学生们普遍喜欢请\"私人教练\"，因为**感觉**更轻松高效。但实际测试发现，那些坚持自己\"举重\"（做笔记）的学生，三天后肌肉记忆（知识保留）明显更好。\n\n为什么会出现这种\"感觉vs现实\"的差距？关键在于**认知加工的深度**。做笔记就像是你必须亲自消化食物 - 要咀嚼、要理解、要重新组织语言。这个过程强迫大脑建立更多的神经连接。而LLM直接给你\"预消化好的营养液\"，虽然容易吸收，但大脑的\"消化系统\"没有得到锻炼。\n\n更聪明的方法是**先自己尝试举重，再请教练纠正姿势** - 这就是笔记+LLM组合的效果最好[cite]。\n\n# ⚔️ 对抗性评审\n\n## 1. 实验生态效度问题\n**硬伤：** 实验设置过于理想化。现实中学生使用LLM是**开放式、多轮交互**的，而实验可能限制了使用方式。这就像研究\"社交媒体对社交能力的影响\"，但只允许被试发一条预设消息 - 严重低估了真实世界的复杂性。\n\n## 2. 长期效应缺失\n**硬伤：** 仅测试3天后的记忆效果[cite]。学习是一个**累积过程**，短期优势未必转化为长期能力。好比研究\"咖啡对工作效率的影响\"只观察喝完第一小时 - 完全忽略了后续的咖啡因崩溃。\n\n## 3. 主观偏好测量的表面性\n**硬伤：** 学生\"偏好\"LLM可能只是**新奇效应**或**认知懒惰**的体现。论文没有深入探究这种偏好背后的心理机制 - 是因为LLM真正提升了学习体验，还是仅仅因为它减少了即时认知负荷？\n\n# 📝 一句话总结\n\n如果我只记这篇论文的一个贡献，那应该是：**传统笔记的认知价值在AI时代依然不可替代，智能工具的最佳使用方式是辅助而非替代深度思考过程**。"
    }
  },
  "a4cbb3b8-0995-4520-8921-6a698a043c04": {
    "id": "a4cbb3b8-0995-4520-8921-6a698a043c04",
    "filename": "ssrn-5390896.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/a4cbb3b8-0995-4520-8921-6a698a043c04_ssrn-5390896.pdf",
    "status": "completed",
    "created_at": "2025-12-21 21:46:03.961294",
    "updated_at": "2025-12-21 13:47:08.880161",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "Emergent gravity-like behaviors on complex latent space of variational encoder with nonlinear, data-adaptive regularization scheme.",
    "markdown_content": "# Emergent gravity-like behaviors on complex latent space of variational encoder with nonlinear, data-adaptive regularization scheme.\n\nBranislav Majerník\n\nFaculty of Mathematics, Physics and Informatics\n\nComenius University, 842 48 Bratislava, Slovakia\n\nbranislav.majernik@gmail.com\n\nORCID:0000-0003-0903-3653\n\nAugust 13,2025\n\n# Abstract\n\nAutoencoders are powerful neural network architectures designed for unsupervised learning by compressing high-dimensional data into a compact latent representation and subsequently reconstructing the original input. While traditional autoencoders use fully connected layers and fixed latent vectors, this work presents a convolutional autoencoder framework with a spatially structured latent space interpreted as a discrete complex-valued field, analogous to a quantum wavefunction. This approach retains spatial correlations and significantly reduces parameter count and overfitting. We propose a novel formulation where the latent representation is modeled as a complex-valued matrix  $\\Psi(t,x,y)$  enabling a probabilistic interpretation via  $|\\Psi|^2$  and evolution governed by discrete convolutional approximations of differential operators. Convolutions are shown to approximate Laplacians, allowing us to simulate wave-like propagation in the latent space. Time evolution of the latent field follows a discrete Schrödinger-like equation incorporating complex dynamics. Furthermore, we introduce a nonlinear, data-adaptive regularization scheme based on local gradients of  $\\Psi$ , which acts as an intelligent denoising filter. This adaptive mechanism emphasizes structurally significant regions—such as edges and transitions—by modulating learning dynamics based on latent curvature. The resulting architecture supports not only efficient reconstruction but also interpretable latent dynamics, offering a bridge between deep learning and physical field theory. Our formulation demonstrates how principles from quantum mechanics and differential geometry can inspire emergent behaviors such as metric curvature and gravity-like feedback within the latent space of deep networks, suggesting new directions for physically informed machine learning.\n\n# 1 Introduction\n\nAn autoencoder is a type of neural network architecture designed for unsupervised learning, with the primary objective of efficiently compressing, encoding, and embedding input data into a representation that captures its most salient features. The autoencoder then reconstructs the original input from this compressed representation. During training, the network learns to identify the underlying latent variables, hidden or implicit factors that, while not directly observable, significantly influence the structure and distribution of the data. The set of these latent variables forms what is referred to as the latent space. This latent space encapsulates only the most essential information required for accurate data reconstruction, effectively serving as a compact and informative representation of the original input.\n\nStandard autoencoders map inputs to fixed latent representations, variational autoencoderintroduce a probabilistic approach where the encoder outputs a distribution over the latent space\n\ndistribution  $q(z|x)$ , mean  $\\mu$  and variance  $\\sigma^2$ , see [1]. When using an encoder on an image, matrix, tensor field, on any high-dimensional field, the entire image, field must be flattened into a vector, which significantly increases the dimensionality of the vectors and thus the computational complexity. Let the image  $x \\in \\mathbb{R}^{H \\times W}$  have  $D = H \\cdot W$  pixels. After flattening, we get:\n\n$$\nz \\in \\mathbb {R} ^ {D}\n$$\n\nThan the encoder defines a mapping:\n\n$$\nf _ {\\mathrm {e n c}}: \\mathbb {R} ^ {H \\times W} \\to \\mathbb {R} ^ {D}, \\quad x \\mapsto z\n$$\n\nTherefore, it is advantageous to use a convolutional layer in both the encoder and decoder. Each filter represents a linear operator adapted to detect edges, textures, or other patterns.\n\nIf convolutional layers were replaced only by fully connected layers, we would lose locality, weight sharing, and spatial structure, leading to a larger number of parameters, increased overfitting, and weaker performance in image-based tasks. Therefore, it is advantageous to use convolutional layers both in the encoder and decoder. Here is summary how autoencoder works basically\n\n# 1.1 Encoder as a Projector to complex latent space\n\nAn autoencoder encodes the input\n\n$$\nx \\in \\mathbb {R} ^ {C \\times H \\times W}\n$$\n\ninto a latent space as:\n\n$$\nz = f _ {\\mathrm {e n c}} (x; \\theta)\n$$\n\nHere,  $f_{\\mathrm{enc}}$  is a composition of convolutional layers, nonlinear activations, and linear mappings. The output\n\n$$\nz \\in \\mathbb {R} ^ {d _ {1} \\times d _ {2} \\times d _ {3}}\n$$\n\nfor example,  $1 \\times 4 \\times 4$  can be interpreted as a discretized space (2D) with possible depth (time, frequency, channels)\n\n# 1.2 Matrix Representation of Space\n\nThe latent space is considered a tensor\n\n$$\nZ \\in \\mathbb {R} ^ {1 \\times 4 \\times 4}\n$$\n\nThis can be interpreted as a field of values (e.g., \"amplitudes\" in complex field) defined on a discrete grid. We can rewrite this structure as a discrete scalar field in space and time:\n\n$$\nZ _ {i, j} = \\psi \\left(t _ {i}, x _ {j}\\right)\n$$\n\nwhere  $t_i$  is the indexed time,  $x_j$  is the indexed space, and  $\\psi(t_i, x_j)$  are the values of the latent function.\n\n# 1.3 Mapping via Convolution as Operator Approximation\n\nConvolutional layers act as local linear operators that approximate derivatives — the foundation for the Laplacian operator, useful for regularization:\n\n$$\n\\operatorname {C o n v 2 D} (x) \\approx \\frac {\\partial^ {2}}{\\partial x ^ {2}} + \\frac {\\partial^ {2}}{\\partial y ^ {2}}\n$$\n\n# 1.4 Decoder: Inverse Mapping\n\nThe decoder is composed of linear and convolutional layers:\n\n$$\n\\hat {x} = f _ {\\mathrm {d e c}} (z; \\phi)\n$$\n\nThis maps the latent field back to the image. In physical analogy, the decoder interprets the latent field as a wavefunction or potential, from which it generates the \"observed reality.\"\n\n# Summary Symbolically\n\n$$\nx \\xrightarrow {\\mathrm {e n c o d e r} f _ {\\mathrm {e n c}}} z = \\psi (t, x) \\xrightarrow {\\mathrm {d e c o d e r} f _ {\\mathrm {d e c}}} \\hat {x}\n$$\n\nHere,  $z$  is a matrix representation of space (or space-time). It is a discrete field where hidden structures necessary for reconstruction are learned. Training maximizes the similarity between  $x$  and  $\\hat{x}$  using the MSE loss:\n\n$$\nL _ {\\mathrm {r e c o n}} = \\| x - \\hat {x} \\| ^ {2}\n$$\n\n# 2 Emergent gravity on complex latent space.\n\n# 2.1 Basic object: Complex wavefunction in matrix representation\n\nLet\n\n$$\n\\Psi (t, x, y) \\in \\mathbb {C}\n$$\n\nbe the wavefunction of a two-particle system in a two-dimensional discrete space, or continuously:\n\n$$\n\\Psi : \\mathbb {R} ^ {1 + 2} \\to \\mathbb {C}\n$$\n\nThe probability density is:\n\n$$\nP (t, x, y) = | \\Psi (t, x, y) | ^ {2}\n$$\n\nwith the normalization condition:\n\n$$\n\\int | \\Psi (t, x, y) | ^ {2} d x d y = 1\n$$\n\nIn discrete formulation:\n\n$$\n\\Psi (t) \\in \\mathbb {C} ^ {m \\times n}\n$$\n\nbe a time-dependent wavefunction defined on a discrete grid (e.g.,  $8 \\times 8$ ), where each element  $\\Psi_{ij}(t)$  represents the complex probability amplitude of a particle being at position  $(i,j)$  at time  $t$ . The associated probability density is:\n\n$$\nP _ {i j} (t) = \\left| \\Psi_ {i j} (t) \\right| ^ {2}\n$$\n\nWith normalization:\n\n$$\n\\sum_ {i = 1} ^ {m} \\sum_ {j = 1} ^ {n} | \\Psi_ {i j} (t) | ^ {2} = 1\n$$\n\n# 2.2 Latent space evolution\n\nUsing mentioned convolution mechanism in neural network formulate also discrete time evolution Application of the convolutional kernel kernel  $K$  to the wave function  $\\Psi_t$ , convolution:\n\n$$\n\\left(K * \\Psi_ {t}\\right) _ {i, j} = \\sum_ {a = - 1} ^ {1} \\sum_ {b = - 1} ^ {1} K _ {a, b} \\cdot \\psi_ {t, i - a, j - b}\n$$\n\nTo understand how does convolution describe wave propagation, we need understand what is convolution in this context. Convolution is an operation where each point of a new matrix is computed as a weighted sum of the neighboring values from the original matrix, according to a specific kernel. The applied convolution is a simplified model of propagation, used to local wave spreading from one point to its neighbors, similar to a discrete approximation of diffusion or wave propagation. A typical kernel for simple propagation, diffusion or wave spreading, may look like this:\n\n$$\nK = \\left[ \\begin{array}{c c c} 0 & \\alpha & 0 \\\\ \\alpha & 1 - 4 \\alpha & \\alpha \\\\ 0 & \\alpha & 0 \\end{array} \\right]\n$$\n\nwhere  $\\alpha$  is a small positive constant that determines the degree of propagation between neighbors. At each time step, we apply the convolution:\n\n$$\n\\psi^ {t + 1} = \\delta t \\psi^ {t} * K\n$$\n\nThe value at point  $(x, y)$  is obtained as a combination of the value at that point and its neighbors, according to the kernel. If we work with an image that has some symmetry, we can extract a lot of information from that symmetry, which allows us to significantly reduce its description, i.e., compress it. Rotational symmetry is typically used, for example in 2D images when rotated by 90 degrees. That mean for example augmentation of data by rotation during evolution. ktorá pomáha predíst overfittingu - siet sa nespolieha na špecifikné Rozloženie pixelov.\n\n$$\ni   \\delta t = \\left[ \\begin{array}{c c} 0 & - \\delta t \\\\ \\delta t & 0 \\end{array} \\right]\n$$\n\nIf we have two feature maps:\n\n$$\n\\Psi = \\operatorname {R e} (\\Psi) + i \\cdot \\operatorname {I m} (\\Psi)\n$$\n\nThen the operation:\n\n$$\n\\Psi^ {\\prime} = i \\cdot \\delta t \\cdot \\Psi \\quad \\Rightarrow \\quad \\left\\{ \\begin{array}{l} \\operatorname {R e} (\\Psi^ {\\prime}) = - \\delta t \\cdot \\operatorname {I m} (\\Psi) \\\\ \\operatorname {I m} (\\Psi^ {\\prime}) = \\delta t \\cdot \\operatorname {R e} (\\Psi) \\end{array} \\right.\n$$\n\nThis can be implemented as a fixed matrix operation over the channels and give a evolution in discrete Schrödinger-like equation :\n\n$$\n\\Psi^ {t + 1} = \\Psi^ {t} + i \\delta t (K * \\Psi^ {t})\n$$\n\nwhere  $i = \\sqrt{-1}$  and  $\\delta t > 0$  is the time step. The discrete Laplace operator on a 2D grid is defined as:\n\n$$\n\\left(\\Delta \\Psi\\right) _ {i, j} = \\Psi_ {i + 1, j} + \\Psi_ {i - 1, j} + \\Psi_ {i, j + 1} + \\Psi_ {i, j - 1} - 4 \\Psi_ {i, j}\n$$\n\nTime evolution with time step  $\\delta t$  and Laplacian filter:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot \\Delta \\Psi (t)\n$$\n\n# 2.3 Emergent Gravity: metric curvature as evolution feedback and autoencoder features intelligent denoiser\n\nA filter defined as\n\n$$\n\\kappa (x, y) = \\alpha \\left(| \\nabla_ {x} \\Psi (x, y) | ^ {2} + | \\nabla_ {y} \\Psi (x, y) | ^ {2}\\right)\n$$\n\nis an adaptive nonlinear filter that depends on the local amplitude variation (gradient) of the wavefunction (or neural layer output). Let's analyze its meaning and potential use in an autoencoder for image or time series processing.\n\n-  $\\nabla_x\\Psi$ ,  $\\nabla_y\\Psi$ : approximate derivative or difference between neighboring output values in the  $x$  and  $y$  directions.  \n-  $|\\nabla \\Psi |^2$ : measure of local variation (edges, transitions, brightness changes).  \n-  $\\kappa(x, y)$ : weight that increases where the image or texture is more complex.\n\nEffect on the Autoencoder\n\n1. Adaptive Attention to Edges and Details\n\nIn regions with high gradients (e.g., edges or jumps in signal),  $\\kappa(x, y)$  becomes large, assigning higher learning weight to these areas.\n\n2. Latent Space Regularization\n\nUsing  $\\kappa (x,y)$  in regularization (e.g., Laplacian energy term) encourages smoothness while preserving important transitions—acting as an intelligent denoiser.\n\n3. Structural Enhancement in Image or Signal\n\n- For images: enhances texture, contours, and key features (e.g., MNIST digit edges).  \n- For time series: enhances dynamics, sudden changes, or transitions.\n\nFor image data (e.g., MNIST, CIFAR)\n\n- Encoder can use  $\\kappa(x, y)$  as a local weight, e.g., adaptive spatial convolution.  \n- Decoder can reapply  $\\kappa(x, y)$  as a saliency map to guide fine reconstruction.\n\nFor 1D signals\n\n-  $\\kappa(t) = \\alpha |\\nabla \\Psi(t)|^2$  highlights temporal discontinuities (faults, pulses).  \n- Encourages attention to anomalies or fast transitions.\n\nWhen incorporated into a wave-like evolution equation:\n\n$$\n\\Psi^ {t + \\delta t} = \\Psi^ {t} + i \\delta t \\cdot (1 + \\kappa (x, y)) \\cdot \\Delta \\Psi\n$$\n\n$\\kappa$  acts as a dynamic spatial curvature that enhances wave behavior in regions with strong variation. The filter  $\\kappa(x, y)$  is then useful for: adaptive resolution control (enhance edges, suppress smooth), improving reconstruction of important image features, increasing autoencoder attention to structurally significant regions.\n\nWe introduce a curvature field  $\\kappa_{ij}$  (emergent \"graviton\") as a function of the local wave gradient magnitude and define in discrete form:\n\n$$\n\\kappa_ {i, j} = \\alpha \\left(\\left| \\frac {\\Psi_ {i + 1 , j} - \\Psi_ {i - 1 , j}}{2} \\right| ^ {2} + \\left| \\frac {\\Psi_ {i , j + 1} - \\Psi_ {i , j - 1}}{2} \\right| ^ {2}\\right)\n$$\n\nEach point evolves based on the amount of \"matter\" (i.e., gradient of  $\\Psi$ ) in its neighborhood. After each evolution normalization step:\n\n$$\n\\Psi (t) \\gets \\frac {\\Psi (t)}{\\sqrt {\\sum_ {i , j} | \\Psi_ {i j} (t) | ^ {2}}}\n$$\n\nInterpretation: Emergent Gravitational Interaction. A wavefunction with two maxima (particles A and B) creates local curvature via  $\\kappa$ , which in turn influences the wave evolution. Thus, particles attract each other through curvature feedback without any explicit potential term.\n\n# 2.4 Summary of Equations\n\nDiscrete Laplacian:\n\n$$\n\\left(\\Delta \\Psi\\right) _ {i, j} = \\Psi_ {i + 1, j} + \\Psi_ {i - 1, j} + \\Psi_ {i, j + 1} + \\Psi_ {i, j - 1} - 4 \\Psi_ {i, j}\n$$\n\nEmergent curvature:\n\n$$\n\\kappa_ {i, j} = \\alpha \\left(\\left| \\frac {\\Psi_ {i + 1 , j} - \\Psi_ {i - 1 , j}}{2} \\right| ^ {2} + \\left| \\frac {\\Psi_ {i , j + 1} - \\Psi_ {i , j - 1}}{2} \\right| ^ {2}\\right)\n$$\n\nEvolution with curvature:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot (1 + \\kappa_ {i, j}) \\cdot \\Delta \\Psi (t)\n$$\n\nNormalization:\n\n$$\n\\Psi \\gets \\frac {\\Psi}{\\sqrt {\\sum_ {i , j} | \\Psi_ {i , j} | ^ {2}}}\n$$\n\nwith discrete wave function, we consider a quantum system defined on a 2D grid of size  $N \\times N$ , where:\n\n$$\n\\Psi (x, y, t) \\in \\mathbb {C}\n$$\n\nis the complex probability amplitude of finding a particle at position  $(x,y)$  and time  $t$ . We get discrete-time version of the Schrödinger equation in a curved metric in form:\n\n$$\n\\Psi (t + 1) = \\frac {1}{\\| \\cdot \\|} [ \\Psi (t) + i \\delta t \\cdot (1 + \\kappa (t)) \\cdot \\Delta \\Psi (t) ]\n$$\n\nwhere:\n\n-  $\\Delta \\Psi$  is the discrete Laplacian operator applied to  $\\Psi$ ,  \n-  $\\kappa(t)$  is the metric curvature expressed as a function of the gradient of  $\\Psi$ ,  \n-  $\\|\\cdot\\|$  denotes the  $L^2$ -norm to ensure normalization.\n\ncomplex convolution kernel:\n\n$$\nK = \\left[ \\begin{array}{c c c} 0 & 1 + i & 0 \\\\ 1 - i & - 4 & 1 + i \\\\ 0 & 1 - i & 0 \\end{array} \\right]\n$$\n\nwhich we apply as a 2D convolution:\n\n$$\n\\Delta \\Psi = \\Psi * K\n$$\n\nwhere  $*$  denotes 2D convolution with periodic (wrapped) boundary conditions.\n\n# 2.5 Visualization\n\nAt each time step  $t = 0,1,\\dots ,T$  we visualize:\n\n$$\n| \\Psi (x, y) | ^ {2}\n$$\n\nthe probability density over the 2D grid.\n\n![](/uploads/images/a4cbb3b8-0995-4520-8921-6a698a043c04/8fc79172f86bbb7a52bdc2c023dc1e39d808b0f2ffbcec1ea41ecf057604b4b5.jpg)\n\nIn the first image, at time  $t = 0$ , we see two particles located at positions [2,2] and [5,5] within an 8x8 matrix. The image shows the squared magnitude of the complex amplitude, which corresponds to the probability of detecting a particle in a given region. The brightest colors (white, yellow) on the heatmap represent the normalized highest probability, indicating a kind of localization of the particle within the uncertainty, which is represented by the darker areas on the heatmap.\n\nIn the subsequent images, which describe the time evolution in a discrete form, we observe both the dispersion of amplitudes around the most probable locations, as well as an attraction between the areas of highest probability. For example, at  $t = 14$ , there is a clear shift of the most probable locations of both particles from their original positions toward each other, eventually leading to a kind of fusion or merging into the center, as one might expect from particles with equal mass.\n\n# 3 Conclusion and physics remarks\n\n# 3.1 Emergent Graviton Interaction as Metric Curvature\n\nWe consider emergent graviton interaction as curvature of the metric (i.e., not just a potential, but full tensorial curvature), which arises from the dynamics of the wavefunction of a two-particle system. Thus, the graviton is not introduced explicitly but should emerge from the interaction. Variational encoder with specifi convolution filters works as linearized approximation of Einstein's equations and introduce effective curvature via the metric perturbation tensor  $h_{\\mu \\nu}$ , where:\n\n$$\ng _ {\\mu \\nu} = \\eta_ {\\mu \\nu} + h _ {\\mu \\nu}, \\quad (\\text {l i n e a r a p p r o x i m a t i o n})\n$$\n\nand where  $h_{\\mu \\nu}$  emerges from the distribution  $\\Psi^2$ , similarly to quantum field theory, where the graviton is the quantum of metric perturbation. We define the effective curvature as a tensorial\n\nfunction of the density  $\\Psi^2$ :\n\n$$\nh _ {\\mu \\nu} (x, y) = \\kappa \\partial_ {\\mu} \\Psi^ {*} \\cdot \\partial_ {\\nu} \\Psi + \\mathrm {c . c .}\n$$\n\nIn discrete matrix form:\n\n$$\nh _ {0 0} \\sim \\Psi^ {2} \\quad (\\mathrm {e n e r g y}),\n$$\n\n$$\nh _ {i j} \\sim \\nabla_ {i} \\Psi^ {*} \\cdot \\nabla_ {j} \\Psi \\quad (\\text {m o m e n t u m f l u x e s}).\n$$\n\nIn a curved metric, the Schrödinger equation takes the form:\n\n$$\ni \\partial_ {t} \\Psi = - \\frac {1}{\\sqrt {g}} \\partial_ {k} \\left(\\sqrt {g} g ^ {k j} \\partial_ {j} \\Psi\\right)\n$$\n\nIn 2D, this can be reformulated as a convolution operation with a locally curved Laplacian operator.\n\n# 3.2 Why do the maxima approach each other? Interpretation via modified Schrödinger evolution\n\nBasic linear evolution without curvature: Without curvature (i.e.,  $\\kappa = 0$ ), we recover the classical (discrete) linear Schrödinger equation:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot \\Delta \\Psi\n$$\n\n- In this case, the Laplacian propagates phase information, but does not alter the position of the amplitude maxima.  \n- The system is linear and conservative; particle amplitudes may interfere slightly but do not attract or move toward each other.\n\nEvolution with curvature (emergent gravity): When we introduce curvature:\n\n$$\n\\Psi (t + \\delta t) = \\Psi (t) + i \\delta t \\cdot (1 + \\kappa) \\cdot \\Delta \\Psi\n$$\n\nand more precisely, if\n\n$$\n\\kappa = f \\left(\\left| \\nabla \\Psi \\right| ^ {2}\\right),\n$$\n\ni.e.,  $\\kappa$  depends on the local gradient magnitude of the wavefunction, we introduce a self-consistent curvature feedback:\n\n- In regions of high probability density (amplitude),  $|\\nabla \\Psi|^2$  is large  $\\Rightarrow \\kappa$  increases.  \n- The Laplacian has a stronger effect precisely where there is more \"mass\" (i.e., higher  $\\Psi$  amplitude).\n\nThis mimics the Einstein field equation in emergent form:\n\n$$\nR _ {\\mu \\nu} - \\frac {1}{2} R g _ {\\mu \\nu} \\sim T _ {\\mu \\nu}\n$$\n\nHere, the curvature of the metric (modeled by  $\\kappa$ ) is a function of the local energy density, proportional to  $|\\Psi|^2$  or  $|\\nabla \\Psi|^2$ .\n\nHow this causes gravitational attraction: Although the Laplacian typically causes wave spreading, if its strength is *amplified* in high-density regions due to curvature, an emergent effect appears. Each local amplitude maximum (interpreted as a particle) generates a localized curvature field. This field modifies the evolution of nearby parts of the wavefunction. As a result, the two amplitude maxima \"pull\" each other toward a central region, as the energetically favorable direction of propagation is toward stronger curvature (higher  $\\kappa$ ).\n\nFrom the point of view of trajectories, the amplitude peaks converge. In simulation, one observes:\n\n- The centers of mass of the two amplitude peaks shift from positions  $A$  and  $B$  toward each other.  \nTheir trajectories converge over time.  \n- The curvature modifies the Laplacian propagation such that the diffusion is no longer symmetric: this is not standard linear spreading.\n\nFor a grid point  $(i,j)$ :\n\n$$\n\\Psi_ {i, j} ^ {t + \\Delta t} = \\Psi_ {i, j} ^ {t} + i \\Delta t \\cdot (1 + \\kappa_ {i, j}) \\cdot \\left(\\Psi_ {i + 1, j} ^ {t} + \\Psi_ {i - 1, j} ^ {t} + \\Psi_ {i, j + 1} ^ {t} + \\Psi_ {i, j - 1} ^ {t} - 4 \\Psi_ {i, j} ^ {t}\\right)\n$$\n\nwith curvature defined locally by:\n\n$$\n\\kappa_ {i, j} = \\alpha \\cdot \\left(\\left| \\nabla_ {x} \\Psi_ {i, j} \\right| ^ {2} + \\left| \\nabla_ {y} \\Psi_ {i, j} \\right| ^ {2}\\right)\n$$\n\nThe wavefunction creates gravitational \"wells\" regions with enhanced amplitude. These wells deform the propagation of the wavefunction via a curvature-enhanced Laplacian. Effectively, the maxima of the wavefunction move toward one another. The emergent graviton is encoded in the curvature field  $\\kappa$  as a function of geometric self-deformation.\n\nThen can we ask: \"Is universe a variational autoencoder?\"\n\n# References\n\n[1] Diederik P. Kingma and Max Welling (2019), An Introduction to Variational Autoencoders, Foundations and Trends in Machine Learning: pp 1-18. DOI: 10.1561.",
    "arxiv_id": null,
    "error_message": null,
    "embedding": [
      -0.4140625,
      -2.921875,
      -1.4453125,
      -1.4765625,
      -1.4609375,
      1.484375,
      -2.25,
      -3.890625,
      0.828125,
      0.79296875,
      2.84375,
      1.140625,
      2.421875,
      1.921875,
      3.703125,
      -0.96484375,
      -0.58984375,
      -2.65625,
      2.25,
      -2.515625,
      -3.015625,
      6.5625,
      2.328125,
      -6.6875,
      -0.03271484375,
      1.546875,
      0.640625,
      -0.6171875,
      -0.67578125,
      -0.1728515625,
      3.90625,
      -5.09375,
      1.15625,
      1.640625,
      1.65625,
      -3.5625,
      -4.6875,
      -0.61328125,
      0.8046875,
      3.3125,
      -6.75,
      3.703125,
      0.1865234375,
      -0.859375,
      -2.328125,
      3.640625,
      1.3984375,
      -2.171875,
      -0.57421875,
      -2.140625,
      -3.0625,
      -6.5625,
      10.625,
      -3.203125,
      -0.01324462890625,
      -1.34375,
      -6.625,
      6.09375,
      -7.875,
      -2.296875,
      5.21875,
      0.439453125,
      4.53125,
      1.6015625,
      2.59375,
      4.5,
      0.890625,
      -0.6953125,
      -6.28125,
      4.6875,
      -2.09375,
      -1.484375,
      5.9375,
      -2.578125,
      5.53125,
      4.8125,
      1.1484375,
      0.7734375,
      -3.28125,
      3.109375,
      -3.84375,
      1.78125,
      5.1875,
      2.09375,
      4.21875,
      4.5,
      -4.5625,
      0.5390625,
      -1.46875,
      0.326171875,
      -2.515625,
      3.375,
      -3.65625,
      0.9140625,
      -0.11083984375,
      5.65625,
      1.84375,
      -5.6875,
      -7.875,
      1.0703125,
      -3.734375,
      0.0238037109375,
      -0.32421875,
      -3.53125,
      1.9453125,
      -5.5625,
      -3.03125,
      -5.8125,
      -4.59375,
      -4.75,
      -0.6171875,
      -0.7421875,
      2.515625,
      -2.078125,
      3.375,
      -0.0498046875,
      2.34375,
      -2.625,
      -3.125,
      0.435546875,
      -0.23046875,
      -1.984375,
      -0.59375,
      -1.7734375,
      1.375,
      0.455078125,
      -3.953125,
      2.234375,
      7.5,
      0.2294921875,
      2.8125,
      1.7265625,
      2.625,
      -0.6953125,
      -9.125,
      -2.953125,
      -2.078125,
      2.046875,
      2.4375,
      2.3125,
      -8.125,
      3.40625,
      2.390625,
      -6.4375,
      1.0625,
      -3.5625,
      -6,
      1.78125,
      3.265625,
      -1.6953125,
      4.53125,
      3.703125,
      -0.279296875,
      9.25,
      -1.4765625,
      -5.84375,
      2.53125,
      3.09375,
      2.25,
      -0.08642578125,
      -1.0234375,
      2.09375,
      -0.375,
      1.7578125,
      -0.73046875,
      -3.421875,
      -4.28125,
      4.78125,
      -2.515625,
      -0.033447265625,
      -0.55078125,
      15.5,
      6.34375,
      -2.40625,
      -2.15625,
      4.21875,
      -3.5,
      5.53125,
      0.80859375,
      4.0625,
      -1.0546875,
      0.953125,
      -1.2734375,
      3.640625,
      -0.19140625,
      -0.96484375,
      2.875,
      -3.078125,
      3.15625,
      -1.25,
      0.44921875,
      2.421875,
      -0.734375,
      0.8828125,
      -7.0625,
      -2.359375,
      2.234375,
      0.67578125,
      -2.546875,
      4.375,
      3.390625,
      -6.65625,
      0.09521484375,
      -2.265625,
      -3.796875,
      -0.96484375,
      3.09375,
      -0.796875,
      3.203125,
      -1.921875,
      -0.2080078125,
      1.5546875,
      6.34375,
      0.703125,
      7.3125,
      1.6484375,
      8.0625,
      -3.34375,
      2.53125,
      0.1494140625,
      2.984375,
      4.5625,
      1.1796875,
      -1.296875,
      -0.6875,
      3.125,
      1.984375,
      4.90625,
      5.03125,
      9.5,
      -0.37109375,
      -0.359375,
      3.4375,
      2.625,
      -1.7109375,
      -2.578125,
      -3.25,
      2.375,
      -0.8125,
      3.015625,
      -2.65625,
      -2.75,
      -0.53515625,
      4.4375,
      1.6640625,
      1.546875,
      -3.859375,
      -5.625,
      -4.21875,
      -7.71875,
      -1.046875,
      2.171875,
      -5.65625,
      -4.1875,
      5.4375,
      7.15625,
      -1.171875,
      1.078125,
      -0.37890625,
      -3.484375,
      4.1875,
      -3.03125,
      -7.84375,
      3.5625,
      1.390625,
      -6.09375,
      5.0625,
      -0.61328125,
      3.96875,
      2.546875,
      4.78125,
      -2.484375,
      0.53515625,
      -2.25,
      -0.455078125,
      5.4375,
      4.1875,
      -6.125,
      3.109375,
      -0.8203125,
      -4.0625,
      -5.03125,
      6.8125,
      -6.21875,
      5.28125,
      -3.484375,
      -1.3984375,
      5.625,
      -2.25,
      12.1875,
      7.625,
      -2.265625,
      -0.341796875,
      -2.125,
      -6.84375,
      2.453125,
      -4.15625,
      1,
      -4.59375,
      0.9921875,
      4.71875,
      1.7421875,
      -2.890625,
      2.640625,
      -2.515625,
      3.75,
      -2.109375,
      -1.2734375,
      -0.16015625,
      5.09375,
      2.71875,
      0.158203125,
      3.828125,
      -1.640625,
      -1.21875,
      -4.6875,
      -4.84375,
      -0.11279296875,
      1.71875,
      -4.65625,
      -3.578125,
      -4.65625,
      -1.5625,
      -0.796875,
      -4.625,
      -3.8125,
      2.296875,
      -2.15625,
      1.9609375,
      -2.953125,
      2.640625,
      3.296875,
      -5.25,
      -8.625,
      7.71875,
      -2.0625,
      1.8828125,
      7.46875,
      2.09375,
      2.953125,
      -5.03125,
      -3.296875,
      2.59375,
      -5.75,
      0.8984375,
      1.6171875,
      4.0625,
      -0.7109375,
      1.9453125,
      -3.78125,
      1.3203125,
      -0.7890625,
      2.28125,
      3.71875,
      5.90625,
      -0.87890625,
      0.1552734375,
      -0.83984375,
      0.44921875,
      -0.76171875,
      0.82421875,
      0.0208740234375,
      5.03125,
      1.75,
      -0.5,
      -4.625,
      -1.640625,
      2.5,
      0.28515625,
      -1.71875,
      3.15625,
      -1.828125,
      0.8515625,
      2.734375,
      2.546875,
      -0.67578125,
      -0.953125,
      -1.484375,
      -4.6875,
      0.89453125,
      -1.6484375,
      0.26953125,
      -0.58203125,
      3.078125,
      3.953125,
      3.125,
      -0.2138671875,
      5.78125,
      4.625,
      -2.953125,
      -1.1953125,
      1.4921875,
      -3.140625,
      -0.451171875,
      2.078125,
      1.171875,
      -2.9375,
      0.51953125,
      -1.8671875,
      3.296875,
      3.515625,
      -0.1640625,
      -0.73046875,
      1.9375,
      -5.125,
      -0.3984375,
      -1.34375,
      -1.046875,
      -0.7421875,
      -0.173828125,
      0.21875,
      1.53125,
      0.310546875,
      -2.125,
      -2.203125,
      0.7109375,
      -0.486328125,
      0.75,
      -4.8125,
      0.08642578125,
      -1.84375,
      2.578125,
      3.875,
      1.0703125,
      -1.2734375,
      2.84375,
      2.25,
      4.65625,
      2.625,
      0.412109375,
      -0.30859375,
      1.7109375,
      -4.5625,
      1.1875,
      -2.546875,
      -1.0546875,
      4.0625,
      -1.28125,
      -1.28125,
      -2.4375,
      -0.2216796875,
      -1.59375,
      3.78125,
      3.65625,
      0.2333984375,
      0.7578125,
      1.15625,
      4.625,
      -2.078125,
      -4.34375,
      -3.09375,
      -0.96484375,
      -1.6640625,
      1.4140625,
      -3.34375,
      0.201171875,
      -4.78125,
      1.5234375,
      3.5625,
      -1.09375,
      -0.53125,
      -2.84375,
      -0.90234375,
      2.203125,
      3.515625,
      1.3515625,
      1.125,
      2.53125,
      5.90625,
      -8.75,
      -10.8125,
      4.65625,
      0.41796875,
      -2.46875,
      -3.34375,
      1.8125,
      -2.421875,
      1.765625,
      -4.5,
      -3.3125,
      -2.515625,
      -3.234375,
      6.03125,
      0.66796875,
      1.8828125,
      -1.78125,
      -4.5625,
      6.1875,
      1.3984375,
      4.15625,
      -2.84375,
      2.765625,
      5.15625,
      -5.40625,
      4.9375,
      1.9921875,
      6.46875,
      -4.375,
      -0.60546875,
      4.78125,
      -8.375,
      0.66015625,
      -1.03125,
      1.046875,
      -3.15625,
      0.18359375,
      4.09375,
      -5.375,
      -2.890625,
      -1.625,
      7.28125,
      -3.125,
      -0.97265625,
      1.421875,
      -3.484375,
      -4.25,
      0.0269775390625,
      1.4140625,
      6.5625,
      -0.0322265625,
      -0.70703125,
      2.609375,
      -3.78125,
      0.8984375,
      1.359375,
      -4.6875,
      -1.7109375,
      -0.05322265625,
      2.546875,
      2.640625,
      1.6015625,
      1.1875,
      0.5546875,
      -2.90625,
      0.380859375,
      -0.59765625,
      -1.171875,
      -0.6015625,
      0.1396484375,
      5.15625,
      1.5390625,
      4.125,
      -6.90625,
      1,
      -0.4921875,
      0.50390625,
      -1.5,
      -2.015625,
      0.64453125,
      2.375,
      1.9765625,
      1.9765625,
      -3.53125,
      0.419921875,
      -0.94140625,
      -2.09375,
      -4.03125,
      1.03125,
      2.25,
      -4.09375,
      0.55078125,
      -5.65625,
      -0.0074462890625,
      5.21875,
      1.9375,
      -3.234375,
      2.40625,
      4.5,
      1.4375,
      2.171875,
      0.2734375,
      3.328125,
      -4.15625,
      -2.421875,
      -0.251953125,
      2,
      -5.5625,
      -5.78125,
      -3.171875,
      4.34375,
      7.8125,
      -3.609375,
      2.109375,
      -2.90625,
      6.1875,
      -0.1748046875,
      1.2578125,
      -17.125,
      0.34765625,
      -0.32421875,
      -5.125,
      -3.625,
      -3.875,
      3.484375,
      -4.9375,
      0.8671875,
      1.015625,
      -1.109375,
      1.328125,
      3.484375,
      -0.765625,
      -0.41015625,
      7.03125,
      1.7578125,
      0.474609375,
      0.73828125,
      -1.8671875,
      -4.8125,
      -1.890625,
      -2,
      -0.2578125,
      3.4375,
      1.78125,
      1.125,
      2.09375,
      2.96875,
      -4.96875,
      3.65625,
      3.890625,
      1.171875,
      -4.21875,
      -2.84375,
      -3.140625,
      1.3515625,
      -3.984375,
      3.40625,
      -0.349609375,
      -2.09375,
      2.3125,
      8.25,
      -3.421875,
      -5.34375,
      2.21875,
      -0.953125,
      2.734375,
      3.234375,
      -5.53125,
      3.546875,
      0.48828125,
      0.57421875,
      2.578125,
      -1.1796875,
      -1.8203125,
      -2.40625,
      3.828125,
      0.83984375,
      0.8515625,
      5.0625,
      -1.3125,
      -3.859375,
      -1.3359375,
      1.4765625,
      -2.65625,
      2.46875,
      2.59375,
      0.55078125,
      -0.353515625,
      1.5703125,
      2.578125,
      1.0234375,
      -3.34375,
      -4,
      -0.68359375,
      -8.3125,
      4.75,
      2.546875,
      1.9296875,
      -1.171875,
      -3.796875,
      3.90625,
      2.359375,
      -0.56640625,
      1.5078125,
      4.625,
      5.125,
      -3.78125,
      2.28125,
      -3.203125,
      -1.4140625,
      2.03125,
      -2.546875,
      -1.421875,
      2.296875,
      0.5390625,
      1.1875,
      -0.94140625,
      -1.9140625,
      -2.953125,
      -4.03125,
      -3.234375,
      2.125,
      0.498046875,
      3.875,
      -4.78125,
      5.65625,
      -1.5234375,
      -1.5,
      0.451171875,
      -1.046875,
      -0.353515625,
      -3.375,
      2.984375,
      -4.3125,
      -2.125,
      4.78125,
      -0.84375,
      -4.46875,
      5.90625,
      1.0625,
      -2.359375,
      -4.375,
      3.09375,
      -1.1015625,
      -1.0390625,
      2.984375,
      -3.59375,
      0.466796875,
      -6.09375,
      -2.03125,
      -4.6875,
      6.0625,
      -1.359375,
      1.0390625,
      -1.9609375,
      -3.359375,
      -3.671875,
      0.0654296875,
      -2.828125,
      -0.8515625,
      4.03125,
      -0.2236328125,
      -2.53125,
      1.390625,
      0.9453125,
      0.0281982421875,
      -0.87109375,
      -0.2236328125,
      4.375,
      2.203125,
      2.6875,
      -4.875,
      -1.8828125,
      -0.3359375,
      -1.4921875,
      -3.984375,
      3.671875,
      -1.375,
      -0.87109375,
      3.515625,
      1.9765625,
      -2.234375,
      -3.75,
      1.4609375,
      -5.96875,
      0.54296875,
      -0.546875,
      3.171875,
      1.7109375,
      0.8203125,
      -1.796875,
      -5.125,
      -4.28125,
      3.671875,
      1.3203125,
      -0.5859375,
      -3.359375,
      3.625,
      -5.1875,
      0.83984375,
      -8.25,
      -6.8125,
      0.04052734375,
      -2.203125,
      0.06787109375,
      0.431640625,
      8.125,
      -1.09375,
      1.578125,
      -4.65625,
      0.98828125,
      1.1640625,
      0.41796875,
      1.78125,
      1.375,
      2.796875,
      0.423828125,
      1.125,
      0.69921875,
      -1.0234375,
      0.6875,
      -3.90625,
      0.357421875,
      1.5703125,
      2.71875,
      2.515625,
      2.171875,
      -1.046875,
      -2.546875,
      -0.9453125,
      6.09375,
      3.375,
      -2.78125,
      0.279296875,
      -2.625,
      2.375,
      -5.3125,
      4.09375,
      -0.2158203125,
      11.875,
      -4.6875,
      -3.578125,
      3.625,
      0.138671875,
      -0.86328125,
      4.5,
      -4.78125,
      -3.59375,
      -0.447265625,
      2.53125,
      -3.78125,
      -0.375,
      -6.15625,
      -1.7109375,
      1.984375,
      1.84375,
      4.03125,
      3.140625,
      4.8125,
      1.4765625,
      -0.41796875,
      -5.03125,
      -4.125,
      -1.765625,
      -0.050537109375,
      -2.078125,
      -3.875,
      0.6015625,
      2.015625,
      4.75,
      -3.125,
      0.3671875,
      -2.859375,
      4.53125,
      -0.28125,
      -1.0078125,
      4.78125,
      -1.6484375,
      3.375,
      1.8125,
      0.62890625,
      -2.0625,
      -2.953125,
      7.09375,
      3.171875,
      -3.6875,
      1.75,
      -4,
      1.6015625,
      -2.84375,
      0.439453125,
      1.328125,
      -1.1640625,
      -1.109375,
      -2.3125,
      3.25,
      -1.453125,
      -3.5625,
      4.46875,
      -0.216796875,
      -4.71875,
      1.8671875,
      3.75,
      0.859375,
      1.6640625,
      -1.4296875,
      3.859375,
      -1.2421875,
      -5.125,
      -3.15625,
      -7.03125,
      -0.9375,
      0.71484375,
      -0.8828125,
      3.890625,
      3.78125,
      -3.75,
      1.875,
      -3.203125,
      1.4609375,
      -1.8125,
      4.96875,
      0.93359375,
      -6.40625,
      0.91796875,
      -5.9375,
      -4.5,
      -6.0625,
      -1.3046875,
      -2.96875,
      0.09423828125,
      -2.859375,
      -2.015625,
      0.203125,
      -3.640625,
      -0.05224609375,
      -3.21875,
      -0.4140625,
      1.828125,
      -2.15625,
      4.03125,
      -4.5,
      3.203125,
      0.828125,
      0.30859375,
      3.78125,
      -2.265625,
      -0.67578125,
      4.5,
      -2.3125,
      0.74609375,
      -0.625,
      6.75,
      -5.3125,
      6.625,
      2.1875,
      4.8125,
      -5.34375,
      5.03125,
      1.734375,
      3.328125,
      -4.15625,
      2.875,
      1.0703125,
      0.890625,
      2.265625,
      -1.484375,
      2.375,
      -3.859375,
      -3.78125,
      -0.81640625,
      -1.234375,
      0.41015625,
      4.09375,
      -0.43359375,
      1.1015625,
      -0.494140625,
      0.25390625,
      -0.45703125,
      0.51953125,
      -2.03125,
      -0.047607421875,
      2.125,
      -1.0546875,
      4.96875,
      -0.047119140625,
      2.40625,
      3.328125,
      -4.03125,
      1.859375,
      0.79296875,
      2.390625,
      4.90625,
      3.703125,
      -0.119140625,
      1.578125,
      3.8125,
      -0.373046875,
      -1.40625,
      -0.2578125,
      -4.84375,
      5.34375,
      -0.06982421875,
      -1.3359375,
      -2.40625,
      0.06787109375,
      -0.640625,
      2.390625,
      1.171875,
      -5.21875,
      -1.8828125,
      4.84375,
      -3.265625,
      2.203125,
      -1.046875,
      0.4453125,
      1.7421875,
      -0.80859375,
      4.96875,
      2.609375,
      -0.640625,
      3.484375,
      4.21875,
      -1.7890625,
      1.25,
      -2.140625,
      -0.11181640625,
      1.75,
      3.78125,
      3.09375,
      -1.1015625,
      1.0625,
      -3.640625,
      0.035888671875,
      3.890625,
      -1.1796875,
      3.15625,
      5.03125,
      -1.9140625,
      -0.337890625,
      -2.90625,
      -3.453125,
      1.609375,
      -2.625,
      1.8671875,
      7.0625,
      8.3125,
      -4.65625,
      -2.234375,
      -2.765625,
      -5.4375,
      0.5546875,
      0.36328125,
      0.82421875,
      -0.58203125,
      0.59375,
      0.65625,
      -1.4140625,
      -2.28125,
      0.328125,
      -4.28125,
      0.9453125,
      2.875,
      -2.734375,
      -1.4453125,
      0.0281982421875,
      -0.34375,
      -0.07177734375,
      0.1611328125,
      1.296875,
      -0.12890625,
      3.53125,
      -0.345703125,
      1.21875,
      2.515625,
      1.65625,
      2.21875,
      2.734375,
      -2.109375,
      -0.2080078125,
      0.431640625,
      -1.609375,
      -0.44921875,
      -0.416015625,
      -0.11572265625,
      4.03125,
      -0.33203125,
      0.34375,
      6,
      1.1796875,
      1.75,
      3.953125,
      -3.15625,
      -5.46875,
      -1.2734375,
      0.9609375,
      -1.25,
      0.90234375,
      -2.375,
      0.9140625,
      3.4375,
      -0.234375,
      4.40625,
      -3.75,
      9.125,
      2.734375,
      -1.15625,
      -0.8828125,
      -1.578125,
      3.0625,
      -1.4296875,
      0.60546875,
      -1.1015625,
      -6.0625,
      1.2109375,
      -1.9140625,
      4.65625,
      -0.244140625,
      -0.0179443359375,
      5.625,
      1.5078125,
      -0.8359375,
      -4.625,
      -0.60546875,
      -6.40625,
      -4.21875,
      -1.1953125,
      -0.953125,
      -0.5546875,
      -2.6875,
      -1.171875,
      2.171875,
      4.8125,
      -4.78125,
      0.52734375,
      -1.5546875,
      -1.375,
      -0.1494140625,
      -0.6171875,
      4.21875,
      4.4375,
      -2.796875,
      1.3828125,
      -6.125,
      -4.09375,
      -2.125,
      -0.8984375,
      3.953125,
      -0.75390625,
      -1.234375,
      -0.9140625,
      -1.1875,
      -3.109375,
      -0.609375,
      -4.40625,
      1.046875,
      3.90625,
      0.87109375,
      1.9453125,
      0.5703125,
      -1.3984375,
      -1.390625,
      -1.9375,
      -7.09375,
      2.671875,
      4.1875,
      -3.171875,
      3.796875,
      -0.53125,
      3.8125,
      0.1533203125,
      1.453125,
      0.859375,
      -0.54296875,
      3.359375,
      -2.140625,
      -2.828125,
      3.90625,
      2.421875,
      -1.1484375,
      -0.5078125,
      -1.21875,
      -4.4375,
      -0.3359375,
      -0.67578125,
      1.4765625,
      -1.75,
      1.328125,
      -0.41015625,
      -1.8203125,
      -2.34375,
      0.1728515625,
      8.25,
      1.890625,
      5.59375,
      6.59375,
      -1.9609375,
      -2,
      -0.1767578125,
      -3.65625,
      3.234375,
      0.296875,
      -3.984375,
      1.109375,
      0.0301513671875,
      4.75,
      -0.361328125,
      -3.03125,
      -3.03125,
      2.59375,
      4.5625,
      2.09375,
      -0.25,
      0.28515625,
      -1.546875,
      0.234375,
      -0.02978515625,
      -0.08251953125,
      -3.890625,
      -1.421875,
      -1.0859375,
      4.96875,
      2.125,
      -7.90625,
      0.154296875,
      3.96875,
      -1.59375,
      2.859375,
      0.322265625,
      6.59375,
      -1.1171875,
      3.609375,
      -3.109375,
      -1.9296875,
      -3.765625,
      5.1875,
      0.30859375,
      -2.453125,
      -3.28125,
      -5.21875,
      -3.765625,
      -1.0703125,
      1.8203125,
      3.109375,
      -0.166015625,
      1.65625,
      -2.9375,
      6.09375,
      1.3984375,
      -1.1875,
      1.796875,
      0.8828125,
      -0.49609375,
      -3.8125,
      -1.09375,
      -4.375,
      1.703125,
      -0.65234375,
      -9.8125,
      0.306640625,
      5.4375,
      2.875,
      0.75390625,
      1.625,
      0.2197265625,
      -1.421875,
      -2.90625,
      0.205078125,
      -0.8203125,
      -0.81640625,
      0.78515625,
      -0.4140625,
      -1.359375,
      6.6875,
      -1.234375,
      1.46875,
      -2.953125,
      4.78125,
      -0.734375,
      3.75,
      2.96875,
      3.109375,
      -7.96875,
      0.69921875,
      -2.015625,
      3.171875,
      -1.5859375,
      0.6640625,
      -2.09375,
      0.5625,
      4.5625,
      -0.6640625,
      -2.625,
      -1.78125,
      -1.8046875,
      3.578125,
      0.94140625,
      2.40625,
      -4.1875,
      3.71875,
      -3.9375,
      0.65234375,
      -1.03125,
      -2.484375,
      -0.9765625,
      0.3671875,
      1.0703125,
      2.125,
      2.375,
      -2.296875,
      -3.03125,
      2.203125,
      -1.2578125,
      -3.96875,
      -5.03125,
      1.765625,
      1.0703125,
      0.447265625,
      3.0625,
      -3.6875,
      5.21875,
      -3.703125,
      -0.875,
      2.4375,
      -3.40625,
      3.8125,
      6.125,
      5.5625,
      1.4296875,
      2.34375,
      -2.25,
      2.453125,
      1.1875,
      1.984375,
      2.46875,
      0.408203125,
      -0.69140625,
      -5.1875,
      2.921875,
      1.5234375,
      -1.09375,
      2.71875,
      2.84375,
      -6.96875,
      0.390625,
      3.125,
      3.953125,
      -3.640625,
      -5.5625,
      2.359375,
      5.75,
      -3.890625,
      1.3046875,
      -3.84375,
      2.4375,
      3.859375,
      -1.609375,
      4.625,
      2.078125,
      4.09375,
      -6.21875,
      -2.625,
      1,
      3.453125,
      0.2158203125,
      -4.21875,
      -2.421875,
      4.03125,
      0.640625,
      3.25,
      -2.28125,
      0.09765625,
      2.15625,
      4.59375,
      -4.0625,
      -2.921875,
      -5.125,
      0.2138671875,
      -2.0625,
      2.625,
      1.5859375,
      -0.1015625,
      1.6328125,
      4.15625,
      -2.46875,
      -1.6015625,
      -3.734375,
      -3.03125,
      -1.1875,
      -3.21875,
      -4.875,
      0.359375,
      -2.21875,
      1.578125,
      7.5625,
      7.84375,
      2.890625,
      -2.96875,
      -1.6484375,
      0.09326171875,
      -1.515625,
      -5.125,
      -0.77734375,
      -0.65625,
      -1.2421875,
      4.8125,
      -0.244140625,
      -0.90625,
      -4.5,
      0.3359375,
      -2.71875,
      0.064453125,
      1.203125,
      -0.294921875,
      -4.625,
      -2.40625,
      0.8671875,
      -0.57421875,
      4.625,
      3.46875,
      -3.578125,
      -1.890625,
      0.5625,
      -4.125,
      4.25,
      3.96875,
      -0.93359375,
      -0.61328125,
      7.4375,
      3.3125,
      -0.625,
      1.90625,
      -0.04638671875,
      1.59375,
      -3.625,
      4.9375,
      3.1875,
      1.5390625,
      0.796875,
      2.046875,
      1.796875,
      1.609375,
      5.03125,
      2.671875,
      3.921875,
      0.625,
      3.21875,
      -2.765625,
      -3.984375,
      0.859375,
      3.484375,
      1.1484375,
      -4.3125,
      1.1640625,
      1.5078125,
      2.25,
      1.5703125,
      1.4296875,
      1.9609375,
      3.078125,
      -4,
      2.21875,
      -7.34375,
      2.53125,
      -4.6875,
      1.140625,
      -6.625,
      0.314453125,
      3.71875,
      3.921875,
      0.96484375,
      -1.6875,
      -1.703125,
      1.09375,
      -0.55078125,
      -3.0625,
      3.765625,
      0.02978515625,
      0.2255859375,
      -1.734375,
      -2.59375,
      4.28125,
      1.1171875,
      -2.609375,
      -1.78125,
      -2.015625,
      -0.69140625,
      -3.125,
      -5.375,
      6.03125,
      1.71875,
      -5.9375,
      -6.96875,
      -3.609375,
      1.1875,
      -3.59375,
      0.78125,
      2.671875,
      -2.390625,
      3.96875,
      0.12158203125,
      2.890625,
      3.1875,
      0.72265625,
      0.4609375,
      0.7890625,
      0.61328125,
      -0.84375,
      1.7265625,
      -2.15625,
      -0.388671875,
      -3.21875,
      1.5234375,
      -0.9921875,
      -2.09375,
      -0.73828125,
      -6.09375,
      -4.5625,
      1.578125,
      0.115234375,
      5.25,
      0.296875,
      0.6484375,
      1.1171875,
      -3.4375,
      -2.8125,
      4.75,
      2.375,
      -1,
      0.47265625,
      -1.890625,
      3.65625,
      1.3203125,
      1.5625,
      -0.146484375,
      1.0078125,
      -3.140625,
      -4.125,
      -3.234375,
      2.171875,
      -3.203125,
      3.75,
      -0.625,
      -1.9453125,
      1.8984375,
      3.578125,
      0.326171875,
      1.65625,
      -0.7734375,
      0.85546875,
      0.82421875,
      0.921875,
      0.953125,
      -4.65625,
      2.0625,
      0.109375,
      -2.78125,
      0.271484375,
      -1.125,
      0.2734375,
      3.015625,
      -6.4375,
      0.6328125,
      -1.375,
      0.96484375,
      -2.765625,
      -11.5,
      -5.03125,
      -2.71875,
      -0.1826171875,
      -3.34375,
      1.6875,
      4.4375,
      2.859375,
      -0.7578125,
      4.25,
      -1.875,
      -2.921875,
      3.484375,
      13.3125,
      -1.546875,
      -1.859375,
      0.60546875,
      -0.1630859375,
      4.71875,
      5.8125,
      1.984375,
      -3.265625,
      1.59375,
      -1.234375,
      1.734375,
      -0.4765625,
      3.859375,
      -2.984375,
      -0.8828125,
      -0.82421875,
      -2.015625,
      -4.0625,
      -3.421875,
      -0.267578125,
      -2.6875,
      1.171875,
      3.9375,
      1.8671875,
      4.5625,
      4.46875,
      -0.486328125,
      -1.4765625,
      -1.078125,
      -4.46875,
      -2.8125,
      -0.32421875,
      -5.59375,
      3.78125,
      -4.28125,
      1.8671875,
      0.7578125,
      -1.296875,
      -2.53125,
      -2,
      -3.953125,
      2.890625,
      -3.65625,
      -0.1328125,
      -2.453125,
      -3.171875,
      -1.890625,
      2.296875,
      -2.015625,
      -0.99609375,
      -3.78125,
      -1.6796875,
      -1.125,
      -4.03125,
      -4.21875,
      -0.34765625,
      -7.8125,
      -5.0625,
      -2.9375,
      -0.734375,
      -0.341796875,
      -2.984375,
      0.7734375,
      -0.298828125,
      -4.28125,
      -0.75,
      0.1396484375,
      5.3125,
      -2.625,
      -2.71875,
      1.28125,
      4.125,
      1.296875,
      1.453125,
      -1.109375,
      4.40625,
      2.3125,
      -1.0078125,
      1.6875,
      -1.8046875,
      0.4921875,
      -5.59375,
      1.5234375,
      -0.08642578125,
      0.96875,
      -5.03125,
      1.0234375,
      -1.328125,
      0.2177734375,
      9.8125,
      -6.0625,
      3.96875,
      2.859375,
      -5.90625,
      -0.470703125,
      -1.2265625,
      0.6328125,
      -0.494140625,
      -4.25,
      2.53125,
      1.1953125,
      -2.625,
      0.498046875,
      3.6875,
      0.9453125,
      1.265625,
      0.039306640625,
      1.8984375,
      0.421875,
      0.0272216796875,
      5.84375,
      -0.8671875,
      0.71875,
      -1.1640625,
      -0.359375,
      -0.80078125,
      -1.03125,
      -0.11181640625,
      -1.7734375,
      4.71875,
      1.671875,
      0.470703125,
      -2.390625,
      -6.1875,
      -0.74609375,
      -0.69921875,
      -6.09375,
      4.125,
      -3.6875,
      -0.796875,
      -0.470703125,
      -2.546875,
      -2.390625,
      -2.390625,
      -9.125,
      2.265625,
      4.96875,
      1.828125,
      0.1689453125,
      -3.875,
      -1.203125,
      0.240234375,
      -1.0390625,
      2.09375,
      2.0625,
      -5.3125,
      -0.423828125,
      1.9453125,
      2.28125,
      -5.3125,
      4.40625,
      0.44921875,
      -3.765625,
      -1.34375,
      3.75,
      -3.03125,
      -1.6953125,
      -5.125,
      0.302734375,
      0.6171875,
      -4.34375,
      -6.59375,
      -4.5,
      -2.90625,
      1.4609375,
      5.28125,
      -1.8984375,
      -3.34375,
      4.53125,
      1.5546875,
      -5.96875,
      0.314453125,
      -1.71875,
      1.0625,
      -4.8125,
      0.640625,
      3.859375,
      3.3125,
      -1.5,
      3.90625,
      -0.6171875,
      -1.21875,
      -2.453125,
      -0.5078125,
      4.25,
      -1.328125,
      0.17578125,
      4.28125,
      -4.3125,
      0.357421875,
      -1.3125,
      -2.328125,
      5.40625,
      -0.030029296875,
      -2.46875,
      -1.109375,
      0.72265625,
      3.65625,
      -1.6875,
      -1.578125,
      3.671875,
      1.0859375,
      2.203125,
      3.171875,
      -1.8046875,
      -3.796875,
      0.62890625,
      -4.6875,
      -1.4375,
      -3.125,
      4.375,
      3.328125,
      -0.1572265625,
      -4.15625,
      7.75,
      1.8984375,
      1.328125,
      2.125,
      3.96875,
      5.78125,
      0.3671875,
      -4.3125,
      0.365234375,
      2.1875,
      4.40625,
      -7.625,
      2.625,
      -2.6875,
      0.83984375,
      -2.421875,
      1.9296875,
      -2.0625,
      -1.1796875,
      -3.6875,
      -4.5,
      -2.28125,
      -0.96484375,
      -0.84375,
      1.234375,
      1.5390625,
      0.984375,
      -0.166015625,
      0.65234375,
      -2.953125,
      3.28125,
      -2.6875,
      1.5390625,
      0.42578125,
      -2.015625,
      3.359375,
      1.6796875,
      2.796875,
      0.392578125,
      1.671875,
      -1.609375,
      -2.4375,
      0.31640625,
      -3.140625,
      2.9375,
      1.4296875,
      -7,
      0.984375,
      -2.109375,
      -1.0703125,
      -0.68359375,
      1.1953125,
      -2.9375,
      4.28125,
      0.50390625,
      -2.96875,
      2.46875,
      0.9921875,
      -3,
      -0.68359375,
      0.578125,
      -1.7421875,
      -2.265625,
      0.79296875,
      1.0625,
      -3,
      -1.5234375,
      2.328125,
      -1.640625,
      1.3515625,
      -1.9609375,
      1.171875,
      -1.796875,
      0.7734375,
      2.96875,
      1.375,
      1.0703125,
      -4.53125,
      0.52734375,
      -2.203125,
      1.0078125,
      -0.412109375,
      -1.5625,
      1.3046875,
      -1.0078125,
      2.859375,
      3.625,
      3.609375,
      -7.28125,
      -1.390625,
      0.5,
      1.75,
      1.890625,
      2.59375,
      1.6796875,
      -0.443359375,
      -1.015625,
      1.0625,
      0.25390625,
      0.67578125,
      -2.359375,
      -4.0625,
      1.984375,
      2.921875,
      -3.796875,
      -1.59375,
      0.2451171875,
      1.8828125,
      1.7734375,
      -1.078125,
      -0.5546875,
      -1.09375,
      4.6875,
      -5.21875,
      2.71875,
      2.34375,
      3.296875,
      1.328125,
      0.8515625,
      -2.640625,
      2.65625,
      -1.140625,
      -6.09375,
      -2.84375,
      1.0234375,
      2.390625,
      2.875,
      -0.78515625,
      4.96875,
      0.1650390625,
      3.28125,
      -3.390625,
      6.21875,
      1.5625,
      -6.34375,
      4.71875,
      -0.3671875,
      -0.5078125,
      -4.34375,
      -5.65625,
      -1.6171875,
      5,
      -1.2265625,
      -0.5078125,
      2.140625,
      2.375,
      -1.9609375,
      3.421875,
      -0.875,
      0.46875,
      1.0859375,
      -2.21875,
      -2.90625,
      -1.34375,
      3.75,
      -2.40625,
      -1.171875,
      -1.609375,
      2.09375,
      -1.078125,
      0.22265625,
      2.953125,
      5.375,
      4.3125,
      0.671875,
      -7.90625,
      1.59375,
      -3.4375,
      1.1640625,
      -1.75,
      -1.2734375,
      -0.435546875,
      -3.90625,
      -3.03125,
      3.21875,
      -6.5625,
      -0.265625,
      -3.953125,
      -3.453125,
      0.55859375,
      0.7578125,
      2.59375,
      -0.06298828125,
      1.5546875,
      0.98828125,
      1.765625,
      -1.75,
      -4.15625,
      -0.052490234375,
      -4.90625,
      -1.171875,
      -0.2373046875,
      2.84375,
      -4.53125,
      -3.53125,
      3.078125,
      0.73828125,
      2.234375,
      -3.828125,
      -1.015625,
      2.21875,
      3.40625,
      -0.27734375,
      -1.4609375,
      -0.255859375,
      -0.3359375,
      -0.5546875,
      -6.3125,
      0.6484375,
      0.796875,
      0.373046875,
      -0.50390625,
      -4.875,
      -1.3203125,
      -0.4140625,
      0.53125,
      0.91796875,
      0.158203125,
      -0.09619140625,
      0.392578125,
      -6.0625,
      1.3515625,
      1.6640625,
      0.71484375,
      2.625,
      -1.515625,
      0.28515625,
      -4.5,
      3.8125,
      5.1875,
      -1.3828125,
      -1.390625,
      -0.0272216796875,
      1.109375,
      -2.640625,
      -1.1328125,
      0.62109375,
      0.6953125,
      -8.4375,
      6.3125,
      0.7265625,
      3.46875,
      -0.4453125,
      -0.55078125,
      4.1875,
      -0.9375,
      4.21875,
      0.86328125,
      -2.46875,
      4.53125,
      -2.640625,
      1.578125,
      -1.515625,
      -1.8359375,
      -0.69921875,
      0.73828125,
      -1.328125,
      -2.09375,
      3.0625,
      -1.8984375,
      2.515625,
      -2.5,
      -3.140625,
      2.546875,
      -4.25,
      -3.28125,
      -0.68359375,
      -0.90625,
      1.6328125,
      -2.765625,
      1.9609375,
      -5.40625,
      -1.4140625,
      1.6640625,
      -1.0859375,
      -2.09375,
      4.15625,
      -2.375,
      -4.40625,
      -1.015625,
      1.8828125,
      0.6875,
      3.296875,
      -0.62109375,
      5,
      -0.5234375,
      -3.171875,
      1.015625,
      3.65625,
      2.59375,
      -0.050537109375,
      2.640625,
      0.9140625,
      0.86328125,
      -4.375,
      -2.09375,
      1.4609375,
      -0.08984375,
      2.796875,
      1.640625,
      0.126953125,
      0.56640625,
      -0.349609375,
      -2.0625,
      1.078125,
      2.5,
      -2.359375,
      0.81640625,
      -2.65625,
      2.6875,
      2.796875,
      -0.75390625,
      1.484375,
      -1.375,
      3.515625,
      4.09375,
      -3.015625,
      2.875,
      0.734375,
      -0.263671875,
      -0.1455078125,
      0.041015625,
      0.9296875,
      -3.296875,
      1.4375,
      -0.78515625,
      1.1953125,
      5.875,
      -0.302734375,
      -1.703125,
      3.40625,
      3.0625,
      -3,
      0.48828125,
      1.265625,
      1.34375,
      -1.375,
      0.50390625,
      1.109375,
      1.4921875,
      -1.9296875,
      1.1796875,
      -2.671875,
      2.0625,
      -1.4296875,
      1.5859375,
      1.6484375,
      -0.7265625,
      2.109375,
      1.8359375,
      -0.40234375,
      -3.234375,
      0.75,
      -0.29296875,
      5.90625,
      -1.7421875,
      -1.171875,
      -3.25,
      3.4375,
      -0.66015625,
      2.1875,
      4.9375,
      -1.9609375,
      2.359375,
      0.75390625,
      2.859375,
      -0.158203125,
      -1.953125,
      -3.265625,
      -0.90625,
      0.1396484375,
      0.1826171875,
      -0.5546875,
      -1.2890625,
      -3.34375,
      1.2734375,
      0.353515625,
      -1.1796875,
      -2.859375,
      2.171875,
      0.41015625,
      -1.4765625,
      0.9921875,
      1.9609375,
      -0.0869140625,
      1.7109375,
      0.953125,
      1.4609375,
      0.19921875,
      -3.375,
      1.78125,
      2.71875,
      0.78125,
      0.212890625,
      -1.375,
      3.328125,
      -0.10546875,
      -0.0036773681640625,
      -1.1484375,
      0.1240234375,
      -1.859375,
      -3.921875,
      0.66015625,
      1.4140625,
      -2.171875,
      1.46875,
      1.671875,
      0.7734375,
      0.58984375,
      -1.78125,
      2.828125,
      -1.421875,
      -4.375,
      1.1171875,
      -0.42578125,
      2.421875,
      -2.21875,
      0.1826171875,
      -3.578125,
      -2.40625,
      -1.703125,
      0.107421875,
      -1.859375,
      4.21875,
      0.5,
      1.375,
      -2.53125,
      -0.251953125,
      -1.578125,
      -1.7109375,
      1.453125,
      3.296875,
      -1.140625,
      -2.28125,
      1.3515625,
      0.384765625,
      -0.369140625,
      -4.46875,
      1.8046875,
      -1.0078125,
      2.0625,
      -3.390625,
      2,
      1.609375,
      -1.2109375,
      -0.5078125,
      0.828125,
      -1.7890625,
      4.53125,
      -2.625,
      2.671875,
      -1.734375,
      1.5703125,
      0.345703125,
      -1,
      -3.796875,
      -1.3828125,
      -2.15625,
      -0.330078125,
      -3.4375,
      2.203125,
      2.421875,
      -0.419921875,
      0.53125,
      1.9453125,
      1.875,
      0.44140625,
      -0.96875,
      -0.146484375,
      1.5703125,
      0.03759765625,
      3.1875,
      -2.125,
      0.466796875,
      -1.1640625,
      -0.50390625,
      -0.85546875,
      -3.171875,
      5.0625,
      1.015625,
      -1.078125,
      2.5,
      2.015625,
      -0.1708984375,
      0.18359375,
      1.3828125,
      3.625,
      -1.140625,
      1.7421875,
      -1.53125,
      3.28125,
      -1.3359375,
      0.453125,
      -0.33984375,
      1.09375,
      0.369140625,
      1.609375,
      1.2265625,
      -1.6328125,
      0.23046875,
      0.5703125,
      -1.71875,
      -0.8203125,
      1.921875,
      -3.546875,
      -2.9375,
      2.921875,
      -1.8671875,
      -1.546875,
      3.484375,
      -2.765625,
      -0.30859375,
      -1.1171875,
      -1.8359375,
      0.1083984375,
      2.171875,
      1.1484375,
      -1.578125,
      -0.63671875,
      -1.109375,
      2.3125,
      -0.2255859375,
      -3.75,
      0.87890625,
      -0.26171875,
      -1.4921875,
      2.171875,
      0.154296875,
      -0.294921875,
      -0.296875,
      -1.234375,
      -1.2265625,
      -0.087890625,
      4.125,
      1.53125,
      -0.1962890625,
      -1.859375,
      -4.875,
      -0.396484375,
      -0.7421875,
      -2.78125,
      -1.21875,
      3.28125,
      -0.46484375,
      -0.484375,
      -0.66796875,
      -0.423828125,
      1.75,
      1.5625,
      0.875,
      1.3515625,
      -0.875,
      -2.125,
      -2.4375,
      -3.5625,
      0.19140625,
      -0.443359375,
      0.7890625,
      0.51953125,
      -2.1875,
      0.734375,
      -1.8359375,
      -0.87890625,
      -2.078125,
      -1.6171875,
      -1.65625,
      1.046875,
      0.494140625,
      -2.984375,
      0.96484375,
      2.703125,
      4.84375,
      0.87109375,
      -3.21875,
      0.416015625,
      0.53125,
      2.46875,
      -0.1142578125,
      -2.375,
      0.8671875,
      -1.8125,
      -0.953125,
      -0.203125,
      1.4375,
      -0.1455078125,
      3.03125,
      3.796875,
      2.515625,
      2.828125,
      4.8125,
      1.1015625,
      -1.5546875,
      4.09375,
      -5,
      -0.96875,
      2.28125,
      -0.494140625,
      1.859375,
      2.53125,
      1.125,
      2.328125,
      0.1328125,
      -0.79296875,
      0.96484375,
      0.75,
      0.79296875,
      -4.4375,
      1.109375,
      -0.91015625,
      1.0859375,
      -0.0986328125,
      1.6171875,
      -1.3046875,
      -0.00994873046875,
      -1.203125,
      2.25,
      2.65625,
      0.60546875,
      3.109375,
      -5.46875,
      -2.46875,
      3.609375,
      0.90234375,
      -1.6875,
      -3.484375,
      1.8984375,
      -3.296875,
      0.034423828125,
      1.3671875,
      -0.55859375,
      -0.109375,
      -0.32421875,
      -3.953125,
      -0.380859375,
      -1.046875,
      -1.6015625,
      -0.67578125,
      -2.640625,
      0.494140625,
      -1.5546875,
      4.28125,
      -3.375,
      0.296875,
      -2.125,
      -0.6796875,
      4.40625,
      2.46875,
      1.4453125,
      2.21875,
      -0.6171875,
      -4.3125,
      1.609375,
      -3.71875,
      1.15625,
      -1.3671875,
      2.1875,
      1.203125,
      0.68359375,
      -2.90625,
      0.052001953125,
      -0.1630859375,
      -1,
      -0.578125,
      0.48828125,
      0.828125,
      -4.375,
      0.8828125,
      -0.251953125,
      0.90625,
      -0.36328125,
      -0.046875,
      -1.15625,
      -1.8828125,
      2.3125,
      -0.56640625,
      3.046875,
      2.15625,
      0.236328125,
      2.875,
      -0.73046875,
      -0.55859375,
      -2.421875,
      1.1015625,
      -0.828125,
      1.7265625,
      1.1484375,
      -1.125,
      3.34375,
      -2.34375,
      -0.302734375,
      1.0390625,
      1.3984375,
      -2.21875,
      2.390625,
      0.4765625,
      1.9375,
      -0.2578125,
      -2.890625,
      -1.109375,
      -0.5390625,
      -0.07666015625,
      1.8125,
      -4.84375,
      1.6875,
      -1.03125,
      -0.365234375,
      -2.40625,
      -3.8125,
      0.6328125,
      -1.640625,
      -3.28125,
      -0.1064453125,
      0.546875,
      -2.09375,
      -5.15625,
      1.0859375,
      -1.15625,
      -0.1474609375,
      -1.7578125,
      1.890625,
      3.203125,
      -1.21875,
      -3.984375,
      4.09375,
      -0.578125,
      -0.2470703125,
      4.0625,
      1.2734375,
      -0.064453125,
      3.359375,
      1.078125,
      4.375,
      -1.484375,
      0.90625,
      -2.5,
      -0.875,
      -1.328125,
      -1.1875,
      0.072265625,
      0.287109375,
      2.953125,
      -1.3671875,
      -0.1640625,
      1.015625,
      0.453125,
      1.0546875,
      2.609375,
      2.4375,
      0.79296875,
      -2.296875,
      -0.578125,
      2.875,
      2.40625,
      8.3125,
      0.08642578125,
      3.03125,
      1.3046875,
      -2.046875,
      -0.0869140625,
      0.169921875,
      -0.1708984375,
      -0.0286865234375,
      0.361328125,
      -3.171875,
      -0.4609375,
      -0.796875,
      2.8125,
      -1.0703125,
      4.65625,
      -1.0234375,
      1.71875,
      -3.78125,
      0.80859375,
      -0.578125,
      -0.40234375,
      1.1953125,
      -1.4296875,
      -2.125,
      -0.61328125,
      1.875,
      1.984375,
      -2.578125,
      0.5625,
      4.46875,
      0.87890625,
      0.44921875,
      -0.859375,
      -0.2373046875,
      0.9609375,
      1.15625,
      2.515625,
      -1.0703125,
      2.578125,
      -0.41015625,
      0.30078125,
      -0.240234375,
      1.7421875
    ],
    "summary": "# 论文审阅报告：Emergent gravity-like behaviors on complex latent space\n\n## 1. 🎯 结构化速读\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 传统自编码器将图像展平为向量，丢失空间结构，参数过多易过拟合 [cite: Sec 1] |\n| **核心方案** | 使用卷积自编码器构建复数潜在空间，将潜在表示建模为类波函数场 $\\Psi(t,x,y)$ [cite: Abstract] |\n| **关键概念** | 潜在空间作为离散复数场，卷积近似微分算子，非线性自适应正则化 [cite: Sec 1.3, Abstract] |\n| **核心数据** | 未明确说明具体数据集，但架构针对图像数据（如 $H\\times W$ 尺寸）[cite: Sec 1] |\n| **核心假设** | 卷积层可近似拉普拉斯算子，潜在场演化遵循类薛定谔方程，能涌现引力行为 [cite: Sec 2.2] |\n| **主要结论** | 架构支持高效重建和可解释潜在动力学，为物理启发的机器学习提供新方向 [cite: Abstract] |\n\n## 2. 💡 费曼式解读\n\n**给大一新生的解释：**\n\n想象你要记住一幅复杂的画作。传统方法就像把画剪成碎片塞进抽屉——虽然能还原，但失去了画面的整体结构和空间关系。\n\n这篇论文的做法更像是一位聪明的画家：他把画作\"翻译\"成一种特殊的\"能量场\"，这个场不仅记录颜色信息，还记录了画面各部分之间的\"力\"和\"势能\"。卷积操作就像是用一个魔法滤镜来观察这个场——它能捕捉到边缘、纹理等关键特征，就像我们的眼睛会自动聚焦在画面的重要过渡区域一样。\n\n最巧妙的是，他们让这个能量场按照类似量子力学的规则演化。就像水波纹会自然扩散和干涉一样，潜在场中的信息也会自动\"流动\"和\"自组织\"，最终涌现出类似引力的行为——重要的特征会像有质量物体一样\"吸引\"注意力，不重要的区域则被\"推开\"。\n\n## 3. ⚔️ 对抗性评审\n\n**作为苛刻审稿人的三点质疑：**\n\n1. **数学严谨性存疑**：论文声称卷积近似拉普拉斯算子，但未提供误差分析或收敛性证明。离散格点上的微分算子近似需要严格的数学基础，而文中仅以\"≈\"符号带过，缺乏量化评估 [cite: Sec 1.3]\n\n2. **\"引力行为\"定义模糊**：所谓\"引力式反馈\"缺乏明确定义和度量标准。是表现为某种势能场的平方反比律？还是时空度规的弯曲？这种类比需要更精确的物理对应关系 [cite: Sec 2]\n\n3. **实验验证严重不足**：论文完全是理论推导，缺乏实证支持。没有展示在具体数据集上的重建效果，也没有量化比较与传统方法的性能差异。所谓的\"涌现行为\"可能只是架构设计的副产品 [cite: 全文无实验部分]\n\n## 4. 📝 一句话总结\n\n如果只记一个贡献，那应该是：**将自编码器的潜在空间重新构想为遵循物理规律的动态场，为神经网络的可解释性提供了新的物理类比框架**。",
    "structure": {
      "sections": [
        {
          "title": "Emergent gravity-like behaviors on complex latent space of variational encoder with nonlinear, data-adaptive regularization scheme.",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 19
        },
        {
          "title": "1.1 Encoder as a Projector to complex latent space",
          "level": 1,
          "start_line": 41
        },
        {
          "title": "1.2 Matrix Representation of Space",
          "level": 1,
          "start_line": 63
        },
        {
          "title": "1.3 Mapping via Convolution as Operator Approximation",
          "level": 1,
          "start_line": 79
        },
        {
          "title": "1.4 Decoder: Inverse Mapping",
          "level": 1,
          "start_line": 87
        },
        {
          "title": "Summary Symbolically",
          "level": 1,
          "start_line": 97
        },
        {
          "title": "2 Emergent gravity on complex latent space.",
          "level": 1,
          "start_line": 109
        },
        {
          "title": "2.1 Basic object: Complex wavefunction in matrix representation",
          "level": 1,
          "start_line": 111
        },
        {
          "title": "2.2 Latent space evolution",
          "level": 1,
          "start_line": 155
        },
        {
          "title": "2.3 Emergent Gravity: metric curvature as evolution feedback and autoencoder features intelligent denoiser",
          "level": 1,
          "start_line": 211
        },
        {
          "title": "2.4 Summary of Equations",
          "level": 1,
          "start_line": 272
        },
        {
          "title": "2.5 Visualization",
          "level": 1,
          "start_line": 330
        },
        {
          "title": "3 Conclusion and physics remarks",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "3.1 Emergent Graviton Interaction as Metric Curvature",
          "level": 1,
          "start_line": 348
        },
        {
          "title": "3.2 Why do the maxima approach each other? Interpretation via modified Schrödinger evolution",
          "level": 1,
          "start_line": 382
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 442
        }
      ]
    },
    "tags": [
      "大语言模型"
    ],
    "suggested_tags": [
      "变分自编码器",
      "物理启发机器学习",
      "复杂潜在空间",
      "非线性正则化",
      "卷积算子近似"
    ],
    "tag_suggestions": [
      {
        "name": "变分自编码器",
        "confidence": 0.95,
        "reason": "论文核心研究基于变分自编码器架构，探讨其潜在空间的复杂结构和动态特性"
      },
      {
        "name": "物理启发机器学习",
        "confidence": 0.9,
        "reason": "论文将量子力学和微分几何原理应用于深度学习，展示了类重力行为在潜在空间中的涌现现象"
      },
      {
        "name": "复杂潜在空间",
        "confidence": 0.88,
        "reason": "研究重点在于将潜在空间建模为复数值矩阵场，类比量子波函数，具有空间结构和动态演化特性"
      },
      {
        "name": "非线性正则化",
        "confidence": 0.85,
        "reason": "提出基于局部梯度的数据自适应正则化方案，作为智能去噪滤波器，强调结构重要区域"
      },
      {
        "name": "卷积算子近似",
        "confidence": 0.82,
        "reason": "使用卷积层近似微分算子（如拉普拉斯算子），支持潜在空间中的波状传播和类薛定谔方程演化"
      }
    ],
    "tags_confirmed": true,
    "category": "大语言模型",
    "analysis": {
      "status": "completed",
      "started_at": "2025-12-21T13:58:30.260143",
      "completed_at": "2025-12-21T13:59:17.112559",
      "summary": "# 论文审阅报告：Emergent gravity-like behaviors on complex latent space\n\n## 1. 🎯 结构化速读\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 传统自编码器将图像展平为向量，丢失空间结构，参数过多易过拟合 [cite: Sec 1] |\n| **核心方案** | 使用卷积自编码器构建复数潜在空间，将潜在表示建模为类波函数场 $\\Psi(t,x,y)$ [cite: Abstract] |\n| **关键概念** | 潜在空间作为离散复数场，卷积近似微分算子，非线性自适应正则化 [cite: Sec 1.3, Abstract] |\n| **核心数据** | 未明确说明具体数据集，但架构针对图像数据（如 $H\\times W$ 尺寸）[cite: Sec 1] |\n| **核心假设** | 卷积层可近似拉普拉斯算子，潜在场演化遵循类薛定谔方程，能涌现引力行为 [cite: Sec 2.2] |\n| **主要结论** | 架构支持高效重建和可解释潜在动力学，为物理启发的机器学习提供新方向 [cite: Abstract] |\n\n## 2. 💡 费曼式解读\n\n**给大一新生的解释：**\n\n想象你要记住一幅复杂的画作。传统方法就像把画剪成碎片塞进抽屉——虽然能还原，但失去了画面的整体结构和空间关系。\n\n这篇论文的做法更像是一位聪明的画家：他把画作\"翻译\"成一种特殊的\"能量场\"，这个场不仅记录颜色信息，还记录了画面各部分之间的\"力\"和\"势能\"。卷积操作就像是用一个魔法滤镜来观察这个场——它能捕捉到边缘、纹理等关键特征，就像我们的眼睛会自动聚焦在画面的重要过渡区域一样。\n\n最巧妙的是，他们让这个能量场按照类似量子力学的规则演化。就像水波纹会自然扩散和干涉一样，潜在场中的信息也会自动\"流动\"和\"自组织\"，最终涌现出类似引力的行为——重要的特征会像有质量物体一样\"吸引\"注意力，不重要的区域则被\"推开\"。\n\n## 3. ⚔️ 对抗性评审\n\n**作为苛刻审稿人的三点质疑：**\n\n1. **数学严谨性存疑**：论文声称卷积近似拉普拉斯算子，但未提供误差分析或收敛性证明。离散格点上的微分算子近似需要严格的数学基础，而文中仅以\"≈\"符号带过，缺乏量化评估 [cite: Sec 1.3]\n\n2. **\"引力行为\"定义模糊**：所谓\"引力式反馈\"缺乏明确定义和度量标准。是表现为某种势能场的平方反比律？还是时空度规的弯曲？这种类比需要更精确的物理对应关系 [cite: Sec 2]\n\n3. **实验验证严重不足**：论文完全是理论推导，缺乏实证支持。没有展示在具体数据集上的重建效果，也没有量化比较与传统方法的性能差异。所谓的\"涌现行为\"可能只是架构设计的副产品 [cite: 全文无实验部分]\n\n## 4. 📝 一句话总结\n\n如果只记一个贡献，那应该是：**将自编码器的潜在空间重新构想为遵循物理规律的动态场，为神经网络的可解释性提供了新的物理类比框架**。"
    }
  },
  "900b8326-a7f7-47d7-8897-4b0e64d37488": {
    "id": "900b8326-a7f7-47d7-8897-4b0e64d37488",
    "filename": "2503.20701v2.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/900b8326-a7f7-47d7-8897-4b0e64d37488_2503.20701v2.pdf",
    "status": "completed",
    "created_at": "2025-12-21 22:08:19.613096",
    "updated_at": "2025-12-21 14:10:40.050825",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "UniEDU: Toward Unified and Efficient Large Multimodal Models for Educational Tasks",
    "markdown_content": "# UniEDU: Toward Unified and Efficient Large Multimodal Models for Educational Tasks\n\nZhendong Chu $^{\\text{♥}}$ , Jian Xie $^{\\text{♣}}$ , Shen Wang $^{\\text{♥}}$ , Zichao Wang $^{\\text{σ†}}$ , Qingsong Wen $^{\\text{♥}}$\n\nSquirrel Ai Learning\n\nFudan University  $\\sigma$  Adobe Research\n\n{zc9uy@virginia.edu, qingsongedu@gmail.com}\n\n# Abstract\n\nEducation materials for K-12 students often consist of multiple modalities, such as text and images, posing challenges for models to fully understand nuanced information in these materials. In this paper, we propose a unified and efficient large multimodal model UniEDU designed for various educational applications, including knowledge recommendation, knowledge tracing, time cost prediction, and user answer prediction, all within a single model. Unlike conventional task-specific models, UniEDU offers a unified solution that excels across multiple educational tasks while maintaining strong generalization capabilities. Its adaptability makes it well-suited for real-world deployment in diverse learning environments. Furthermore, UniEDU is optimized for industry-scale deployment by significantly reducing computational overhead—achieving approximately a  $3 \\times$  increase in efficiency—while maintaining competitive performance with minimal degradation compared to fully fine-tuned models. This work represents a significant step toward creating versatile AI systems tailored to the evolving demands of education.\n\n# 1 Introduction\n\nThe incorporation of artificial intelligence (AI) significantly enhances the quality of K-12 education by enabling more personalized learning experiences, improving student engagement (Chen and Leitch, 2024; Adetayo et al., 2024), and providing educators with valuable insights to tailor instruction to individual needs (Bhowmik et al., 2024; Zheng et al., 2025). For example, knowledge recommendation systems leverage AI to suggest relevant learning materials based on students' past performance and preferences (Wang et al., 2024b; Chu\n\net al., 2025), while knowledge tracing techniques track students' understanding over time, allowing for real-time adjustments to learning paths (Li et al., 2024; Shen et al., 2024; Yang et al., 2024b).\n\nDespite these advancements, previous research has primarily focused on plain text modality, while real-world K-12 scenarios often involve multimodal data, such as text and images in question stems. Furthermore, the significant differences between tasks pose a challenge in designing a unified model that can effectively handle diverse input types. However, since user profiles remain consistent across tasks, a unified approach could facilitate seamless knowledge transfer among them. For example, while knowledge recommendation is typically framed as a ranking problem and knowledge tracing as a binary classification task, both rely on a shared understanding of student learning behaviors and knowledge states. These disparities underscore the need for a unified model capable of handling the complexities of multimodal scenarios and supporting diverse task types within the context of educational AI assistance.\n\nLarge Multimodal Models (LMMs) (Liu et al., 2023b,a; Chen et al., 2024) emerge as a promising solution due to their proficiency in handling multimodal data. Furthermore, by leveraging the flexibility of natural language, LMMs can reframe tasks in a generative format and tailor input descriptions to effectively support a wide range of distinct tasks. However, the computational cost of processing long input contexts remains a significant challenge. Since user interaction histories often span extended periods—up to 300 interactions in our study, with a maximum length reaching 45,000 tokens—retaining all interactions would substantially increase token costs, thereby escalating both training and inference expenses. A detailed analysis of these computational costs is provided in Section 3.4. While directly truncating such data may risk losing important information, educational\n\nuser profiles are largely constructed from interaction histories, which makes them more amenable to compression. Unlike other domains that may require precise memory of all events, educational contexts often tolerate approximate representations, as not all historical details are equally critical for capturing learning behaviors and knowledge states (Rendle and Zhang, 2023; Purificato et al., 2024; Chu et al., 2024).\n\nTo address these challenges and accommodate the unique demands of educational settings, we propose UniEDU—a unified large multimodal model optimized for efficient deployment in educational assistant systems. UniEDU compresses student interaction histories into a compact set of tokens for efficient feature extraction and reformulates diverse real-world educational tasks within a generative framework. Comprehensive experiments demonstrate that UniEDU achieves strong performance across real-world tasks, outperforming task-specific models while delivering approximately a  $300\\%$  improvement in computational efficiency.\n\n# 2 Related Work\n\nTo provide students with support tailored to their abilities and preferences, it is essential to develop an effective AI assistant for K-12 learning. At the outset of AI integration in education, improving e-learning quality was a primary focus (Murtaza et al., 2022; Rahayu et al., 2022; Xu et al., 2025b), with techniques such as recommendation systems for personalized learning and adaptive learning platforms playing a central role in tailoring educational content to individual student needs (Zaiane, 2002; Ali et al., 2022). While these systems are effective, most are designed for specific tasks, such as knowledge tracing (Li et al., 2024; Shen et al., 2024), and lack generalization across diverse educational contexts.\n\nWith the development of LLMs (OpenAI, 2022, 2023; Dubey et al., 2024; Yang et al., 2024a), which leverage superior understanding and generation capabilities, e-learning assistants have made significant strides in expanding their generalization. These assistants can now serve both as teaching assistants (Xu et al., 2024; Guo et al., 2024; AbuRasheed et al., 2024; Xu et al., 2025a) and student support (Park et al., 2024; Liu et al., 2024; Scarlatos et al., 2025; Yan et al., 2024), reducing teachers' workloads while offering personalized responses tailored to each student's needs. However, since\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/6200ace1f1d9e45f7e954509ee089da2389e11460484f751fc0a814b4937c96e.jpg)  \nFigure 1: The architecture of UniEDU. The profile encoder processes history interactions with multimodal information, while the language model integrates compressed history interactions and task instructions to generate the output.\n\nLLMs are typically trained on general-domain data, they often struggle to adapt to the multimodal inputs and long-context scenarios common in modern e-learning environments. This highlights the need for a unified model capable of effectively handling these complexities.\n\n# 3 Methodology\n\n# 3.1 Model Architecture\n\nUniEDU comprises two main modules: the Profile Encoder and the Language Model. As illustrated in Figure 1, the Profile Encoder is for extracting features from the user's interaction history, while the Language Model is used to generate task-specific responses.\n\nThe Profile Encoder is designed for compressing the user's interaction history into a compact representation that the Language Model can efficiently process. Formally, let  $S = \\{X_1, X_2, \\ldots, X_n\\}$  represent a sequence of user interactions, where each interaction  $X_i$  is defined as  $X_i = \\{q_i, a_i, k_i, c_i, t_i\\}$ . These components are chosen for their relevance to downstream tasks and are representative of common inputs in real-world educational systems (See Section 4.1). Each component of  $X_i$  is characterized as follows:  $q_i$  denotes the question stem,  $a_i$  represents the user's response,  $k_i$  corresponds to the knowledge concept associated with the question,  $c_i$  indicates the correctness of the user's response, and  $t_i$  denotes the time taken by the user to complete the interaction.  $q_i$  could be multimodal, encompassing both visual information (e.g., figures associated with the question) and textual content. Please refer to Appendix A.2 for the demonstration of interaction history. Given the se\n\n<table><tr><td>Variable</td><td>Definition</td></tr><tr><td>a</td><td>number of attention heads</td></tr><tr><td>b</td><td>batch size</td></tr><tr><td>d</td><td>hidden dimension size</td></tr><tr><td>l</td><td>number of transformer layers</td></tr><tr><td>s</td><td>sequence length</td></tr><tr><td>t</td><td>tensor parallel size</td></tr><tr><td>v</td><td>vocabulary size</td></tr></table>\n\nTable 1: Definitions of the variables.\n\nquence  $S$ , the Profile Encoder compresses it into a feature matrix of shape  $|S| \\times m \\times h$ , where  $|S|$  is the sequence length,  $m$  is a hyperparameter that determines the number of tokens used to represent each interaction, and  $h$  is the hidden state dimension expected by the language model. To ensure compatibility, we apply a **Projector—a linear layer** that projects the encoder output to the hidden size of the Language Model.\n\nBy processing  $S$  through the Profile Encoder and Projector, we obtain  $|S|\\times m$  compressed profile embeddings, denoted as  $H_{p} = \\{h_{1},\\dots ,h_{m|S|}\\}$ . These embeddings, together with the uncompressed task instruction embeddings  $H_{i}$ , are then processed by the Language Model, which generates responses for different tasks.\n\n# 3.2 Training Objective\n\nTo enable multi-task learning, UniEDU is trained to generate task-specific outputs conditioned on the user's interaction history and task instructions. In particular, given a sequence of user interactions  $S$  and a task instruction  $\\mathbf{X}_{\\mathrm{inst}}$ , the model generates the corresponding target output  $\\mathbf{X}_{\\mathrm{t}}$ . The training process employs the standard auto-regressive training objective, formally defined as:\n\n$$\np \\left(\\mathbf {X} _ {\\mathrm {t}} \\mid S, \\mathbf {X} _ {\\text {i n s t}}\\right) = \\prod_ {i = 1} ^ {| \\mathbf {X} _ {\\mathrm {t}} |} p _ {\\theta} \\left(x _ {i} \\mid S, \\mathbf {X} _ {\\text {i n s t}}, \\mathbf {X} _ {\\mathrm {t}, <   i}\\right), \\tag {1}\n$$\n\nwhere  $\\theta$  represents the trainable parameters, and  $\\mathbf{X}_{\\mathrm{inst}}$  and  $\\mathbf{X}_{\\mathrm{t},<i}$  denote the instruction tokens and the generated target tokens preceding the current prediction token  $x_{i}$ , respectively. In Section 4, we discuss the education tasks we considered in detail.\n\n# 3.3 VRAM Computation\n\nIn this section, we provide a detailed analysis of why UniEDU is VRAM-efficient for both training and inference. We compare UniEDU's VRAM requirements with general fine-tuning demands, focusing on two key components: parameters-loaded\n\nVRAM (  $V R A M_{para}$ ) and activation memory (  $V R A M_{activation}$ ). In Table 1, we list all the definitions of the variables used in this section.\n\nAssuming both model parameters and activations are stored in a 16-bit floating point format, each element requires 2 bytes of storage. During the training stage, in addition to  $S_{\\mathrm{model}}$  for model loading, additional memory is required for storing optimizer states and gradients. Specifically, the Adam optimizer maintains two sets of moment estimates—first-order (mean of past gradients) and second-order (variance of past gradients)—for each model parameter, effectively doubling the memory required for optimization. As a result, the optimizer states require  $2S_{\\mathrm{model}}$ . Additionally, gradient storage requires  $S_{\\mathrm{model}}$ . Thus, the total VRAM for loading the parameters in the training stage is:\n\n$$\nV R A M _ {p a r a} ^ {t r a i n} = 4 \\times 2 S _ {m o d e l} = 8 S _ {m o d e l}. \\qquad (2)\n$$\n\nDuring inference, the only VRAM requirement is for loading the model itself, as no optimizer states or gradient storage are needed. Therefore, the VRAM required for inference is given by:\n\n$$\nV R A M _ {\\text {m o d e l}} ^ {\\text {i n f e r}} = 2 S _ {\\text {m o d e l}}. \\tag {3}\n$$\n\nFollowing the VRAM computation from NVIDIA, the activation memory required for Transformer is given by:\n\n$$\nV R A M _ {\\text {a c t i v a t i o n - b l o c k s}} = \\frac {s b d l}{t} \\left(3 4 + 5 \\frac {a s}{d}\\right). \\tag {4}\n$$\n\nIn addition to activations within Transformer blocks, there are activation memory requirements before and after these blocks. The token and position embeddings before the first block require:\n\n$$\nV R A M _ {\\text {a c t i v a t i o n - e m b e d d i n g}} = 4 b s d. \\tag {5}\n$$\n\nAfter passing through the Transformer blocks, the output tensors are typically stored in float32, even if the model was loaded at lower precision, as it often casts outputs to float32 by default (Smirnov, 2023). During training, probabilities that are the same size as the output tensor also need to be stored, contributing additional memory overhead. This results in the following VRAM usage:\n\n$$\nV R A M _ {\\text {a c t i v a t i o n - o u t p u t}} = \\left\\{ \\begin{array}{l l} 8 b s v, & \\text {t r a i n i n g} \\\\ 4 b s v, & \\text {i n f e r e n c e} \\end{array} \\right. \\tag {6}\n$$\n\nTo further optimize VRAM consumption, we employ Flash Attention (Dao et al., 2022), which reduces attention memory complexity from quadratic\n\n<table><tr><td rowspan=\"2\"></td><td rowspan=\"2\">Model Size</td><td rowspan=\"2\">VRAMpara</td><td colspan=\"3\">VRAMactivation</td><td rowspan=\"2\">VRAMtotal</td></tr><tr><td>Embedding</td><td>Blocks</td><td>Output</td></tr><tr><td colspan=\"7\">Training</td></tr><tr><td>Qwen2-VL-2B</td><td>2B</td><td>14.9GB</td><td>0.3GB</td><td>61.3GB</td><td>50.9GB</td><td>127.4GB</td></tr><tr><td>Qwen2-VL-7B</td><td>7B</td><td>52.2GB</td><td>0.3GB</td><td>143.0GB</td><td>50.9GB</td><td>246.4GB</td></tr><tr><td>UniEDU-5B</td><td>5B</td><td>37.3GB</td><td>1.8MB</td><td>1.1GB</td><td>0.4GB</td><td>38.8GB</td></tr><tr><td colspan=\"7\">Inference</td></tr><tr><td>Qwen2-VL-2B</td><td>2B</td><td>3.7GB</td><td>0.1GB</td><td>2.2GB</td><td>25.5GB</td><td>31.5GB</td></tr><tr><td>Qwen2-VL-7B</td><td>7B</td><td>13GB</td><td>0.3GB</td><td>5.1GB</td><td>25.5GB</td><td>43.9GB</td></tr><tr><td>UniEDU-5B</td><td>5B</td><td>9.3GB</td><td>1.8MB</td><td>25MB</td><td>0.2GB</td><td>9.5GB</td></tr></table>\n\nTable 2: VRAM Usage Comparison Across Different Models. The results assume  $b = 1$  and  $t = 1$ , with other parameters set according to their respective models. For UniEDU,  $s = 300$  due to compression, while for the other models,  $s = 45,000$ , representing the maximum number of history interaction tokens. For clarity, token counts for task instructions are omitted, resulting in slight discrepancies in real VRAM usage.\n\nto linear with respect to the sequence length. Given that the sequence length in our setting (up to  $45\\mathrm{K}$ ) is significantly larger than the number of attention heads  $a$ , the activation memory in the training stage can be approximated as:\n\n$$\nV R A M _ {a c t i v a t i o n} \\approx 3 4 \\frac {s b d l}{t} + (4 d + 8 v) b s. \\qquad (7)\n$$\n\nFor inference, the activation memory cost depends on the maximum single activation memory in blocks (i.e., the activation memory of each layer), as intermediate parameters for updates are not stored. Therefore, the inference cost is:\n\n$$\nV R A M _ {\\text {a c t i v a t i o n}} \\approx 3 4 \\frac {s b d}{t} + 4 b s v. \\tag {8}\n$$\n\n# 3.4 Efficiency Analysis\n\nIn Table 2, we present the VRAM requirements for Qwen2-VL-2B and 7B (Wang et al., 2024a), as well as our UniEDU. Due to the long context required for recommendation tasks (up to  $45\\mathrm{K}$  tokens in our dataset) and the large vocabulary size of modern LLMs, activation memory consumes a substantial amount of VRAM, leading to high computational costs during both training and inference. However, after compression, UniEDU significantly reduces VRAM usage compared to traditional models, achieving over a  $3\\times$  reduction even relative to the smaller Qwen2-VL-2B in both training and inference stages. This substantial decrease in memory consumption offers a significant advantage for real-world deployment, enabling the model to process larger batches and handle more data within the same timeframe.\n\n# 4 Experiments\n\n# 4.1 Education Tasks\n\nOur system primarily focuses on the subject of mathematics. During training, we use the same user interaction history across tasks while varying task instructions to avoid data leakage. Below, we detail the formulation of each task, with corresponding training examples provided in Appendix A.2.\n\nKnowledge Recommendation. This task aims to recommend relevant knowledge concept based on a user's interaction history. In the educational assistant context, the model identifies a student's weak areas and provides targeted recommendations, including both foundational knowledge to address weaknesses and advanced knowledge for further development. For example, if a student consistently struggles with questions involving quadratic equations, the model may recommend reviewing the fundamentals of factoring and completing the square. Conversely, if the student performs well on basic algebraic manipulation, the system might suggest more advanced topics such as functions or inequalities to support continued growth. Specifically, we define the data format as a triplet  $(S,Y,C)$ , where  $S$  represents the user's interaction history (as detailed in Section 3),  $Y$  denotes the ground truth knowledge concepts that reflect the student's weak areas, obtained from real-world exam history.  $C$  comprises candidate knowledge concepts, including both the ground truth concepts  $Y$  and distractors. To construct  $C$ , we sample  $K$  candidate concepts, where  $K \\in \\{5,10,25,50\\}$ , including one ground truth and  $K - 1$  distractors. The model needs to rank the candidate set  $C$  based on its modeling of the student's ability. Task performance is measured using Precision@1, where a prediction is\n\nconsidered correct only if the ground truth concept is ranked first among the  $K$  candidates.\n\nKnowledge Tracing. This task aims to predict whether a student can correctly answer a given question. The model must capture the user's profile, identifying both strengths and weaknesses, to make an accurate prediction. Specifically, given a sequence of the user's interaction history  $S$  and a question  $Q$ , the model is expected to predict a binary outcome: [True] or [False], where the ground truth is derived from the student's actual answer. The performance of this task is evaluated based on prediction accuracy.\n\nTime Cost Prediction. The goal of this task is to predict the time a student needs to solve a given question. The task requires the model to understand both the student's learning path and the inherent difficulty of the task. Specifically, similar to Knowledge Tracing, given a sequence of the user's interaction history  $S$  and a question  $Q$ , the model is expected to predict an integer value representing the time required, with the ground truth derived from the student's actual time spent. We evaluate the model's performance using Mean Absolute Error (MAE).\n\nUser Answer Prediction. The User Answer Prediction task aims to predict the user's possible answer to a given question based on their interaction history and learning profile. If the model thinks that the student can successfully answer the question, it needs to predict the correct answer (Liu et al., 2022). However, if the student is unlikely to succeed, the model needs to predict an answer that aligns with the student's profile, reflecting a potentially incorrect response. This task requires the model to capture the student's strengths, weaknesses, and learning paths to generate realistic answers. Specifically, given a sequence of the user's interaction history  $S$  and a question  $Q$ , the model predicts the most probable answer, with the ground truth being the student's actual response. We use exact match (EM) to evaluate the performance.\n\n# 4.2 Implementation Details\n\nDatasets. We collect our dataset from real student exercise data on a widely used e-learning platform and construct the training data for each task. The statistics of the dataset are shown in Table 3. Each student's history sequence exceeding 300 interactions is truncated into multiple segments. As a result, although we processed 13,239 students, the total number of sequences exceeds this count.\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/3336072f95b6948d4433baf45c9b3e62bcc854f4cc9462f2f894f82e17fb2d3b.jpg)\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/e433c042eac79c25ae445d01adb20250bb815c2ec1af452f3ac958e448cc6425.jpg)  \nFigure 2: Performance comparison of seven models on the Knowledge Recommendation task.\n\n<table><tr><td># of students</td><td>13,239</td></tr><tr><td># of knowledge</td><td>8,247</td></tr><tr><td># of questions</td><td>235,687</td></tr><tr><td># of interactions</td><td>3,892,084</td></tr></table>\n\nTable 3: Dataset statistics.\n\nBaselines. To assess UniEDU's effectiveness, we compare it against two representative baselines for each task. Specifically, for knowledge recommendation, we evaluate two widely adopted models: SASRec (Kang and McAuley, 2018) and Bert4Rec (Sun et al., 2019). For the knowledge tracing task, we consider extraKT (Li et al., 2024) and reKT (Shen et al., 2024). For time cost prediction, we utilize N-BEATS (Oreshkin et al., 2020) and Prophet (Meta, 2023). For user answer prediction, a generative task requiring the model to produce responses in natural language, we employ Qwen2-VL-2B and Qwen2-VL-7B (Wang et al., 2024a). Additionally, these two models, without fine-tuning, are included as baselines for the three aforementioned tasks.\n\nAll experiments are conducted using the same training and test sets. The maximum length of interaction history is 300, with a maximum token cost of 45,000, based on the Qwen tokenizer. For baseline models that require indexing specific users and items, we follow their official guidelines to complete this process.\n\nBackbone Models. We fine-tune UniEDU on the four tasks outlined in Section 4.1. For each task, we use 24,504 sequences for training, with  $5\\%$  of the data randomly selected as a validation set, and 2,784 sequences for testing. For UniEDU, we fix the encoder model as Qwen2-VL-2B and vary\n\n(a) Knowledge Tracing  \n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/98dfb1fec9a28fffe34844eb61a902d81c8997b363205a0679fc3970fe4bcb28.jpg)  \nextraKT reKT N-BEATS Prophet Qwen2-VL-2B Qwen2-VL-7B UniEDU-2.5B UniEDU-3.5B UniEDU-5B\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/a1247981029a0a121f33e0a132a5c54fce4e1990e083c84267722cc301ec5eed.jpg)  \n(b) Time Cost Prediction\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/e0f63d8522149bcd6c3fc68aa273fa09135f7125eec9c7210416b6df0e7c41e4.jpg)  \n(c) User Answer Prediction\n\nthe language model size by using Qwen2.5-0.5B, Qwen2.5-1.5B, and Qwen2.5-3B. These configurations form UniEDU-2.5B, UniEDU-3.5B, and UniEDU-5B, enabling us to assess the impact of model size on performance.\n\n# 4.3 Results\n\nWe compare the performance of baselines and UniEDU with various parameter sizes on four tasks. The results are reported in Figure 2 and Figure 3.\n\nFirst, UniEDU demonstrates strong performance across four tasks. Except for knowledge tracing, UniEDU outperforms task-specific models in Knowledge Recommendation, Time Cost Prediction, and User Answer Prediction. Notably, it achieves performance gains of approximately  $30\\%$  and  $20\\%$  over the best baselines in knowledge recommendation and time cost prediction, respectively. While UniEDU performs competitively in knowledge tracing, it slightly lags behind specialized models like extraKT and reKT, which are better suited for simpler discriminative tasks. However, these models struggle with unseen items, whereas UniEDU handles them effectively through natural language descriptions.\n\nSecond, model size significantly affects generative tasks but has limited impact on discriminative ones. For Knowledge Tracing and Time Cost Prediction, performance remains relatively stable across model sizes. In contrast, for Knowledge Recommendation and User Answer Prediction, larger models like UniEDU-5B show clear advantages over smaller variants. This suggests that tasks requiring longer or more complex generation benefit more from increased language model capacity.\n\n# 4.4 Analysis of Compression Tokens\n\nTo evaluate the impact of compression ratio on performance, we vary the number of compression tokens (i.e.,  $m$ , as defined in Section 3.1) to 1, 2, 3, meaning each history interaction  $X_{i}$  is compressed into 1, 2, 3 hidden states. We conduct this analysis\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/d690ab2187aa65771307e2a1ced7ff252bd2d072df272165c57a1e827e00a357.jpg)  \nFigure 3: Performance comparison of UniEDU and baseline models on Knowledge Tracing, Time Cost Prediction, and User Answer Prediction.\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/e50ad7aebcb84ddc2b54e7207974d19e5728e3067728d231e28a250eb0429ba4.jpg)  \nFigure 4: Performance of UniEDU-5B with different numbers of compression tokens. The red dashed line indicates Qwen2-VL-2B with full fine-tuning.\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/efff9b6878ebc2b931c862a3c12ef2f577256736b16f31e6ca25662d5c6a4bd3.jpg)\n\n![](/uploads/images/900b8326-a7f7-47d7-8897-4b0e64d37488/c958221214bf95e6405caa43b4f2554e3c1b769efca229d6830eaa73b2de5bd9.jpg)\n\non UniEDU-5B and use Qwen2-VL-2B as an upper bound, excluding the 7B variant due to its high computational cost.\n\nResults in Figure 4 show that increasing the number of compression tokens slightly degrades performance in Knowledge Recommendation and Knowledge Tracing, likely due to noise from excessive historical context. In contrast, User Answer Prediction benefits from additional context, as it requires modeling both historical interactions and candidate questions. Overall, our compression approach provides substantial efficiency gains with minimal performance loss, except in the more complex generative setting of User Answer Prediction. Furthermore, compared to the fully fine-tuned model, our compression technique achieves significant improvements in training and inference efficiency with minimal performance degradation, except for the User Answer Prediction task.\n\n# 5 Conclusion\n\nIn this paper, we propose UniEDU, a unified generative model for education that effectively handles various multimodal tasks while being computationally efficient. Unlike task-specific models, UniEDU not only achieves better performance but also generalizes well across different educational challenges, making it suitable for real-world de\n\nemployment. Extensive experiments validate its effectiveness, showing that compared to fully fine-tuned models, UniEDU reduces computation costs by approximately  $300\\%$  while incurring minor performance drops. Overall, UniEDU represents a promising step toward integrating LMMs into industrial education applications, offering a scalable and efficient approach to personalized learning.\n\n# Limitations\n\nWhile UniEDU shows strong performance and efficiency across multiple educational tasks, several limitations remain. First, its generalizability beyond mathematics to other subjects and task types (e.g., essay grading) has not been explored. Second, the compression strategy, though effective for reducing VRAM, introduces minor performance drops in complex generative tasks, with trade-offs between efficiency and fidelity requiring further study. Third, the interaction-history-based profile modeling may overlook latent learner traits like motivation or learning style; incorporating richer signals could improve personalization.\n\n# Broader Impact Statement\n\nUniEDU has the potential to significantly improve personalized learning by providing targeted knowledge recommendations based on students' interaction histories. This can enhance student engagement, support educators in curriculum design, and scale AI-driven education to a wider audience. Furthermore, our computationally efficient design in UniEDU makes it accessible to institutions and companies with limited computational resources, while maintaining competitive performance with minimal trade-offs.\n\nHowever, training large models on student data poses potential risks to student privacy. To mitigate these concerns, our dataset is constructed from real student interactions, but all personally identifiable information is strictly anonymized. Only interaction data relevant to learning behaviors is retained, while sensitive details such as names, user IDs, and other personal attributes are carefully masked to ensure privacy and compliance with ethical data usage standards.\n\n# References\n\nHasan Abu-Rasheed, Mohamad Hussam Abdulsalam, Christian Weber, and Madjid Fathi. 2024. Supporting student decisions on learning recommendations:\n\nAn llm-based chatbot with knowledge graph contextualization for conversational explainability and mentoring. arXiv preprint arXiv:2401.08517.  \nAdebowale Jeremy Adetayo, Mariam Oyinda Aborisade, and Basheer Abiodun Sanni. 2024. Microsoft copilot and anthropic claude ai in education and library service. Library Hi Tech News.  \nSadia Ali, Yaser Hafeez, Mamoona Humayun, Nor Shahida Mohd Jamail, Muhammad Aqib, and Asif Nawaz. 2022. Enabling recommendation system architecture in virtualized environment for e-learning. *Egyptian Informatics Journal*, 23(1):33-45.  \nSaptarshi Bhowmik, Luke West, Alex Barrett, Nuodi Zhang, Chih-Pu Dai, Zlatko Sokolikj, Sherry Southerland, Xin Yuan, and Fengfeng Ke. 2024. Evaluation of an llm-powered student agent for teacher training. In European Conference on Technology Enhanced Learning, pages 68-74. Springer.  \nCelia Chen and Alex Leitch. 2024. Llms as academic reading companions: Extending hci through synthetic personae. arXiv preprint arXiv:2403.19506.  \nZhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, et al. 2024. Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 24185-24198.  \nZhendong Chu, Shen Wang, Jian Xie, Tinghui Zhu, Yibo Yan, Jinheng Ye, Aoxiao Zhong, Xuming Hu, Jing Liang, Philip S Yu, et al. 2025. Llm agents for education: Advances and applications. arXiv preprint arXiv:2503.11733.  \nZhendong Chu, Zichao Wang, Ruiyi Zhang, Yangfeng Ji, Hongning Wang, and Tong Sun. 2024. Improve temporal awareness of llms for domain-general sequential recommendation. In ICML 2024 Workshop on In-Context Learning.  \nTri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022. Flashattention: Fast and memory-efficient exact attention with io-awareness. Advances in Neural Information Processing Systems, 35:16344-16359.  \nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783.  \nShuchen Guo, Ehsan Latif, Yifan Zhou, Xuan Huang, and Xiaoming Zhai. 2024. Using generative ai and multi-agents to provide automatic feedback. arXiv preprint arXiv:2411.07407.  \nWang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE international conference on data mining (ICDM), pages 197-206. IEEE.\n\nVijay Anand Korthikanti, Jared Casper, Sangkug Lym, Lawrence McAfee, Michael Andersch, Mohammad Shoeybi, and Bryan Catanzaro. 2023. Reducing activation recomputation in large transformer models. Proceedings of Machine Learning and Systems, 5:341-353.  \nXueyi Li, Youheng Bai, Teng Guo, Ying Zheng, Mingliang Hou, Bojun Zhan, Yaying Huang, Zitao Liu, Boyu Gao, and Weiqi Luo. 2024. Extending context window of attention based knowledge tracing models via length extrapolation. In ECAI 2024, pages 1479-1486. IOS Press.  \nHaotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee. 2023a. Improved baselines with visual instruction tuning.  \nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. 2023b. Visual instruction tuning. In NeurIPS.  \nNaiming Liu, Zichao Wang, Richard Baraniuk, and Andrew Lan. 2022. Open-ended knowledge tracing for computer science education. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.  \nZhengyuan Liu, Stella Xin Yin, Geyu Lin, and Nancy F. Chen. 2024. Personality-aware student simulation for conversational intelligent tutoring systems. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 626-642, Miami, Florida, USA. Association for Computational Linguistics.  \nMeta. 2023. Prophet.  \nMir Murtaza, Yamna Ahmed, Jawad Ahmed Shamsi, Fahad Sherwani, and Mariam Usman. 2022. Aibased personalized e-learning systems: Issues, challenges, and solutions. IEEE access, 10:81323-81342.  \nOpenAI. 2022. Chatgpt.  \nOpenAI. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.  \nBoris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. 2020. N-beats: Neural basis expansion analysis for interpretable time series forecasting. In International Conference on Learning Representations.  \nMinju Park, Sojung Kim, Seunghyun Lee, Soonwoo Kwon, and Kyuseok Kim. 2024. Empowering personalized learning through a conversation-based tutoring system with student modeling. In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pages 1-10.  \nErasmo Purificato, Ludovico Boratto, and Ernesto William De Luca. 2024. User modeling and user profiling: A comprehensive survey. arXiv preprint arXiv:2402.09660.\n\nNur W Rahayu, Ridi Ferdiana, and Sri S Kusumawardani. 2022. A systematic review of ontology use in e-learning recommender system. Computers and Education: Artificial Intelligence, 3:100047.  \nSteffen Rendle and Li Zhang. 2023. On reducing user interaction data for personalization. ACM Transactions on Recommender Systems, 1(3):1-28.  \nAlexander Scarlatos, Ryan S Baker, and Andrew Lan. 2025. Exploring knowledge tracing in tutor-student dialogues using llms. In Proceedings of the 15th International Learning Analytics and Knowledge Conference, pages 249-259.  \nXiaoxuan Shen, Fenghua Yu, Yaqi Liu, Ruxia Liang, Qian Wan, Kai Yang, and Jianwen Sun. 2024. Revisiting knowledge tracing: A simple and powerful model. In Proceedings of the 32nd ACM International Conference on Multimedia, pages 263-272.  \nAlex Smirnov. 2023. Breaking downgpu vram consumption.  \nFei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management, pages 1441-1450.  \nPeng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhi hao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, et al. 2024a. Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution. arXiv preprint arXiv:2409.12191.  \nShen Wang, Tianlong Xu, Hang Li, Chaoli Zhang, Joleen Liang, Jiliang Tang, Philip S Yu, and Qing-song Wen. 2024b. Large language models for education: A survey and outlook. arXiv preprint arXiv:2403.18105.  \nSonglin Xu, Xinyu Zhang, and Lianhui Qin. 2024. Eduagent: Generative student agents in learning. arXiv preprint arXiv:2404.07963.  \nTianlong Xu, Yi-Fan Zhang, Zhendong Chu, and Qing-song Wen. 2025a. Multimodal ai teacher: Integrating edge computing and reasoning models for enhanced student error analysis. AI Magazine, 46(3):e70030.  \nTianlong Xu, YiFan Zhang, Zhendong Chu, Shen Wang, and Qingsong Wen. 2025b. Ai-driven virtual teacher for enhanced educational efficiency: Leveraging large pretrain models for autonomous error analysis and correction. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 28801-28809.  \nYibo Yan, Shen Wang, Jiahao Huo, Hang Li, Boyan Li, Jiamin Su, Xiong Gao, Yi-Fan Zhang, Tianlong Xu, Zhendong Chu, et al. 2024. Errorradar: Benchmarking complex mathematical reasoning of multimodal large language models via error detection. arXiv preprint arXiv:2410.04509.\n\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al. 2024a. Qwen2 technical report. arXiv preprint arXiv:2407.10671.\n\nKaiqi Yang, Yucheng Chu, Taylor Darwin, Ahreum Han, Hang Li, Hongzhi Wen, Yasemin Copur-Gencturk, Jiliang Tang, and Hui Liu. 2024b. Content knowledge identification with multi-agent large language models (llms). In International Conference on Artificial Intelligence in Education, pages 284–292. Springer.\n\nOsmar R Zaiane. 2002. Building a recommender agent for e-learning systems. In International Conference on Computers in Education, 2002. Proceedings., pages 55-59. IEEE.\n\nLongwei Zheng, Fei Jiang, Xiaqing Gu, Yuanyuan Li, Gong Wang, and Haomin Zhang. 2025. Teaching via llm-enhanced simulations: Authenticity and barriers to suspension of disbelief. The Internet and Higher Education, 65:100990.\n\n# A Appendix\n\n# A.1 VRAM Calculation\n\nIn the NVIDIA paper (Korthikanti et al., 2023), the hidden size is increased to  $4h$  and then reduced back to  $h$  across layers. This varies in models like Qwen2-VL-7B, where the hidden size is 1,576, and the intermediate size is 8,960. For consistency, we adopt the evaluation strategy provided by NVIDIA, which may introduce a minor discrepancy in the real memory costs for models with different configurations.\n\n# A.2 Example Demonstration\n\nWe provide examples of the four tasks mentioned in Section 4.1. Let  $S = \\{X_1, X_2, \\ldots, X_n\\}$  denote a sequence of user interactions, where each interaction is defined as  $X_i = \\{q_i, a_i, k_i, c_i, t_i\\}$ , consisting of the question  $q_i$ , the user's response  $a_i$ , associated knowledge  $k_i$ , response correctness  $c_i$ , and response time  $t_i$ . The question  $q_i$  may be multimodal, incorporating both textual content and visual elements (e.g., figures).\n\nInteraction History:\n\nInteraction 1:  \nQuestion: The difference between 4.6 and 3.26 is ____ less than their sum.  \nUser's Response: [\"6.52\"]  \nCorrect: True  \nResponse Time: 61s  \nKnowledge Concept: Three-step word problems with decimal addition and subtraction\n\nInteraction 2:  \nQuestion: Shape A is translated ____ by ____ units to get Shape B.  \nImage: <image>  \nUser Answer: [\"down\", \"5\"]  \nCorrect: True  \nResponse Time: 22s  \nKnowledge Concept: Identifying the direction and distance of translation\n\nInteraction 3:  \nQuestion: Xiao Pang's electricity usage in the first quarter was: 105 kWh, 150 kWh, and 99 kWh. The average monthly electricity usage in the first quarter is ____ kWh.  \nUser Answer: [\"118\"]  \nCorrect: True  \nResponse Time: 71s  \nKnowledge Concept: Calculating average basic level\n\nInteraction n:  \nQuestion: Teacher Hu rode a bicycle to the library and crossed a 1500-meter bridge. On the way there, it took 300 seconds to cross the bridge, and on the way back, it took 200 seconds. Then the average speed over the round trip on the bridge is ____ meters/second.  \nUser Answer: [\"6\"]  \nCorrect: True  \nResponse Time: 69s  \nKnowledge Concept: Calculating average speed round trip\n\n# Knowledge Recommendation:\n\nBased on the user's past problem-solving history, select 1 knowledge concept from the following list that the user is likely to make mistakes on.\n\nCandidate Knowledge Concepts:  \nProperties of opposite numbers, absolute values, and reciprocals-evaluating algebraic expressions, Solving average problems using equations, Decomposition and composition of numbers within 10 (including 0), Midpoint of a line segment -identifying relationships involving sum, difference, and multiples,  \nApplications of ratio-given the total, Figures obtained by rotation followed by translation, Translation of figures in coordinate systems, Calculations of the form (\\alpha + \\beta)/2, Applications of linear equations-relationships between points on a number line, Calculating averages-pie chart interpretation, Finding the value represented by a point given the distance between two points, Simplified decimal addition and subtraction, Weighted averages-weights in percentage form, Identifying rotated figures-pattern problems, Weighted\n\naverages-weights in ratio form, Corresponding elements of congruent triangles-methods of geometric transformation, Translation drawing on a grid, Translating the rectangular coordinate system, Applications of common factors-finding the number in each group, Word problems with two-digit divisors-constant total amount\n\n# Knowledge Tracing:\n\nBased on the user's past problem-solving history, determine whether the following question can be answered correctly.  \nQuestion: Based on the picture, write two complete equations: ____ (separate with a comma)  \nKnowledge Concept: Addition and subtraction within 10  \nImage: <image>\n\n# Time Cost Prediction\n\nBased on the user's past problem-solving history, estimate how long the user will take to answer the following question (in seconds).  \nQuestion: The area of the figure below is --- square meters.  \nKnowledge Concept: Area units comparing sizes  \nImage: <image>\n\n# User Answer Prediction:\n\nBased on the user's past problem-solving history, predict the answer the user is likely to give for the following question.  \nQuestion: Look at the picture and write the equation. The complete equation is ---  \nKnowledge Concept: Advanced addition with carrying-adding to 7  \nImage:<image>\n\n<table><tr><td>Hyperparameter</td><td>Value</td></tr><tr><td>Encoder Layers</td><td>28</td></tr><tr><td>Encoder Heads</td><td>12</td></tr><tr><td>Encoder Hidden Size</td><td>1536</td></tr><tr><td>Projector Hidden Size</td><td>1536-&gt;2048</td></tr><tr><td>Language Model Layers</td><td>36</td></tr><tr><td>Language Model Heads</td><td>16</td></tr><tr><td>Language Model Hidden Size</td><td>2048</td></tr><tr><td>Max History Window</td><td>300</td></tr><tr><td># Compression Tokens</td><td>1/2/3</td></tr><tr><td>Optimizer</td><td>AdamW</td></tr><tr><td>Learning Rate</td><td>2.0e-6</td></tr><tr><td>Scheduler</td><td>Cosine</td></tr><tr><td>Batch Size per GPU</td><td>4</td></tr><tr><td>Training Steps</td><td>6000</td></tr></table>\n\nTable 4: Hyperparameter setting for UniEDU-5B.\n\n# A.3 Training Details\n\nIn Table 4, we introduce the hyperparameter configuration used to train UniEDU-5B.",
    "arxiv_id": "2503.20701",
    "error_message": null,
    "embedding": [
      -2.1875,
      0.294921875,
      -1.7421875,
      -0.0130615234375,
      -2.171875,
      1.9140625,
      0.057373046875,
      -2.953125,
      1.71875,
      4.53125,
      1.6796875,
      3.609375,
      1.0859375,
      3.890625,
      0.478515625,
      5.53125,
      -2.34375,
      2.34375,
      0.87109375,
      -6.875,
      -1.484375,
      4.375,
      1.7265625,
      -5.625,
      4.0625,
      -4.59375,
      -0.3125,
      4.1875,
      1.6328125,
      -0.087890625,
      6.71875,
      -4.40625,
      -1.3671875,
      1.2421875,
      0.388671875,
      0.08984375,
      -3.609375,
      -2.21875,
      4.25,
      5.03125,
      -8.75,
      2.890625,
      -0.011474609375,
      3.59375,
      -3.203125,
      7.5,
      -0.08056640625,
      -1.890625,
      -4.09375,
      -1.7421875,
      -5.4375,
      -2.65625,
      6.78125,
      0.306640625,
      3.234375,
      -3.765625,
      -6.8125,
      4.5,
      -6.53125,
      -3.09375,
      2.484375,
      -1.6796875,
      2.109375,
      0.8125,
      5.21875,
      3.5,
      0.45703125,
      -1.1015625,
      -5.15625,
      1.4921875,
      0.5078125,
      0.494140625,
      6.5,
      -2.140625,
      8,
      5.9375,
      3.421875,
      4.5625,
      -4.9375,
      3,
      -3.578125,
      4.71875,
      4.5,
      1.9765625,
      2.859375,
      2.796875,
      -0.73046875,
      1.03125,
      -2.140625,
      2.96875,
      -2.015625,
      1.984375,
      -6.53125,
      -2.28125,
      1.0625,
      3.703125,
      -3.703125,
      -4.25,
      -5.46875,
      0.59375,
      -1.046875,
      -0.859375,
      0.5546875,
      -6.34375,
      -2.578125,
      -4.40625,
      -2.21875,
      -7.40625,
      -2.5,
      -0.287109375,
      2.515625,
      -0.40625,
      3.65625,
      -1.265625,
      1.890625,
      -0.72265625,
      3.015625,
      -4.4375,
      -4.375,
      -0.703125,
      -2.390625,
      2.15625,
      -3.609375,
      0.07275390625,
      0.4140625,
      0.255859375,
      -4.59375,
      1.546875,
      7.09375,
      -1.4375,
      4.4375,
      1.2890625,
      2.0625,
      -1.2578125,
      -9,
      -3.984375,
      -5.125,
      3.53125,
      3.109375,
      5.46875,
      -6.21875,
      -1.4921875,
      -1.9296875,
      -3.40625,
      2.640625,
      -0.953125,
      -3.609375,
      -0.52734375,
      3.578125,
      -3.546875,
      1.203125,
      1.9375,
      2.6875,
      8.375,
      -3.34375,
      -2.046875,
      2.375,
      0.90234375,
      -0.6953125,
      -1.625,
      -0.462890625,
      1.9453125,
      -0.87109375,
      4.03125,
      -0.298828125,
      -2.5625,
      -6.28125,
      1.9140625,
      -1.109375,
      1.53125,
      0.671875,
      15.5625,
      0.37890625,
      -1.3515625,
      1.8046875,
      -0.474609375,
      -0.640625,
      6.875,
      -0.6640625,
      -0.150390625,
      2.09375,
      1.125,
      -4.59375,
      5.03125,
      -0.88671875,
      3.625,
      2.84375,
      -1.8828125,
      2.59375,
      0.0771484375,
      1.765625,
      1.6953125,
      4.90625,
      -0.00848388671875,
      -3.59375,
      1.0703125,
      3.1875,
      2.09375,
      -0.31640625,
      2.828125,
      -0.52734375,
      -9.3125,
      -0.56640625,
      -3.046875,
      -3.75,
      0.302734375,
      3.109375,
      -3.921875,
      4.125,
      -3.15625,
      1.6953125,
      2.609375,
      2.28125,
      1.4453125,
      6.1875,
      0.78125,
      1.390625,
      -3.28125,
      3.171875,
      -1.109375,
      4.28125,
      3.171875,
      1.515625,
      -0.859375,
      -0.92578125,
      2.421875,
      1.7578125,
      5.3125,
      3.515625,
      7.65625,
      -1.453125,
      2.71875,
      3.984375,
      -1.9453125,
      -3.265625,
      -1.59375,
      -4.09375,
      -0.62890625,
      -0.65625,
      0.5078125,
      -4.0625,
      -2.265625,
      -0.318359375,
      4.0625,
      2.484375,
      2.109375,
      -2.28125,
      -1.015625,
      -0.56640625,
      -8.625,
      2.84375,
      4.1875,
      -8.25,
      -2.28125,
      4.21875,
      8.0625,
      -0.0693359375,
      -0.71875,
      1.640625,
      -3.921875,
      4.96875,
      -3.59375,
      -6.28125,
      4.53125,
      -1.2421875,
      -3.5625,
      6.8125,
      -0.72265625,
      2.265625,
      3.96875,
      2.9375,
      -0.2109375,
      -1.1875,
      0.71484375,
      -4.0625,
      4.21875,
      1.046875,
      -5.0625,
      -0.10546875,
      -1.484375,
      -5.96875,
      -8.375,
      5.71875,
      -4.40625,
      5.125,
      -1.875,
      -0.73828125,
      5.28125,
      -0.859375,
      13.25,
      5.03125,
      -0.267578125,
      -0.51953125,
      -1.328125,
      -4.125,
      -0.7890625,
      -2.96875,
      0.10400390625,
      -5.125,
      1.7109375,
      3.96875,
      0.37890625,
      -1.8046875,
      -3.21875,
      -2.8125,
      5.4375,
      -0.84765625,
      -1.71875,
      -1.2890625,
      2.65625,
      -2.546875,
      -1.7109375,
      6.59375,
      -0.87109375,
      2.390625,
      -5.34375,
      -3.453125,
      1.1328125,
      1.1015625,
      -2.796875,
      -3.921875,
      -5.3125,
      -2.515625,
      -2.078125,
      -3.8125,
      -2.671875,
      -0.33984375,
      0.58203125,
      3.890625,
      1.7265625,
      1.4453125,
      0.64453125,
      -3.578125,
      -9.9375,
      6.46875,
      -0.8203125,
      0.5,
      3.25,
      -2.828125,
      1.9453125,
      -2.609375,
      -1.578125,
      4.9375,
      -2.234375,
      -0.2255859375,
      2.640625,
      5.0625,
      -1.8046875,
      2.09375,
      -7.03125,
      3.265625,
      3.859375,
      -0.203125,
      3.21875,
      10.625,
      -0.83203125,
      1.1328125,
      -1.3515625,
      1.9140625,
      -0.376953125,
      0.08203125,
      -3.578125,
      5.4375,
      -0.66796875,
      -2.5625,
      -2.734375,
      -3.328125,
      2.296875,
      -1.0703125,
      -1.5703125,
      -1.3046875,
      -2.4375,
      2.5625,
      0.11181640625,
      3.5625,
      -0.5078125,
      -0.65625,
      -3.046875,
      -3.21875,
      -0.36328125,
      -2.703125,
      0.2421875,
      -0.6640625,
      0.51953125,
      4.875,
      0.51171875,
      -2.125,
      4.8125,
      0.86328125,
      -1.375,
      -4.5,
      -2.671875,
      -3.734375,
      2.546875,
      4.25,
      3.546875,
      -1.3515625,
      2.09375,
      -0.8671875,
      -1.53125,
      4.03125,
      0.9453125,
      -2.640625,
      -2.5,
      -4.875,
      -1.2578125,
      1.203125,
      -6.25,
      1.6953125,
      3.203125,
      -1.390625,
      -0.0269775390625,
      -0.138671875,
      0.375,
      -0.9140625,
      1.6640625,
      -1.265625,
      0.56640625,
      -5.03125,
      -2.390625,
      -1.8359375,
      -0.5078125,
      0.59375,
      -1.390625,
      -1.1484375,
      -0.7734375,
      4.28125,
      3.109375,
      0.2392578125,
      1.4375,
      1.6640625,
      2.84375,
      -4.34375,
      1.9765625,
      -3.1875,
      -5.53125,
      4.46875,
      -4.5625,
      -2.5625,
      2.4375,
      2.78125,
      -1.0390625,
      7,
      2.421875,
      -4.09375,
      -0.69921875,
      2.703125,
      3.09375,
      -1.9609375,
      0.376953125,
      -0.1455078125,
      0.66796875,
      -1.7421875,
      1.15625,
      3.109375,
      1.2734375,
      -4.96875,
      1.828125,
      3.765625,
      0.96875,
      -0.82421875,
      1.4453125,
      -0.8046875,
      1.3203125,
      2.796875,
      -2.515625,
      -1.1796875,
      2.78125,
      3.90625,
      -5.78125,
      -7.90625,
      3.671875,
      1.078125,
      -3.34375,
      0.146484375,
      2.640625,
      2.890625,
      1.71875,
      -4.46875,
      -5.78125,
      -0.62109375,
      0.890625,
      4.15625,
      4.75,
      -2.859375,
      -5.15625,
      -2.46875,
      5.9375,
      3.21875,
      -0.07861328125,
      0.11181640625,
      0.310546875,
      1.65625,
      -4.8125,
      2.59375,
      2.1875,
      10.1875,
      -1.640625,
      -0.875,
      -1.421875,
      -9.25,
      -0.2421875,
      -2.546875,
      0.6640625,
      2.328125,
      1.59375,
      4.09375,
      -1.265625,
      -1.3515625,
      -1.5078125,
      5.34375,
      -0.81640625,
      -2.515625,
      1.671875,
      -4.09375,
      -2.109375,
      0.88671875,
      3,
      1.171875,
      -0.6640625,
      -2.921875,
      0.54296875,
      1.0625,
      -0.115234375,
      -1.671875,
      -1.203125,
      -3.171875,
      -0.68359375,
      3.59375,
      3.75,
      -0.0164794921875,
      -0.1103515625,
      -2.015625,
      -3.140625,
      -2.53125,
      -0.70703125,
      0.478515625,
      -1.5546875,
      1.6015625,
      0.80078125,
      0.703125,
      3.078125,
      -5.34375,
      -2.421875,
      -0.86328125,
      1.3828125,
      -4.75,
      1.1953125,
      -0.8046875,
      3.15625,
      4.21875,
      0.01434326171875,
      -5.4375,
      -1.5703125,
      0.36328125,
      -2.46875,
      -1.359375,
      -2.546875,
      1.203125,
      -2.703125,
      -0.56640625,
      -5.28125,
      -0.34765625,
      -0.09619140625,
      -0.52734375,
      -0.6328125,
      0.59375,
      5.34375,
      -0.056396484375,
      -0.82421875,
      2.890625,
      3.40625,
      -0.73828125,
      -2.09375,
      2.125,
      1.125,
      -5.75,
      -4.46875,
      -2.328125,
      3.765625,
      6.46875,
      0.494140625,
      4.21875,
      -3.8125,
      5.84375,
      -1.15625,
      2.171875,
      -16.5,
      3.515625,
      -1.2109375,
      -5.40625,
      0.71484375,
      -0.099609375,
      3.171875,
      -0.330078125,
      1.3671875,
      -0.1953125,
      0.73046875,
      2.828125,
      3.59375,
      -0.1689453125,
      -1.8828125,
      4.71875,
      2.03125,
      -2.90625,
      0.87890625,
      -1.5234375,
      -2.78125,
      1.625,
      -0.1728515625,
      2.40625,
      2.4375,
      3.328125,
      0.8984375,
      0.74609375,
      1.875,
      -5.78125,
      -1.875,
      2.578125,
      1.578125,
      -1.484375,
      -0.055419921875,
      -4.15625,
      3.265625,
      -4.375,
      4.9375,
      0.77734375,
      -3.96875,
      0.84765625,
      6.8125,
      -4.1875,
      -0.30859375,
      -3.25,
      3.859375,
      6.21875,
      5.09375,
      -5.625,
      0.75390625,
      0.0390625,
      1.015625,
      3.578125,
      -3.609375,
      -1.6640625,
      -3.53125,
      1.953125,
      -0.59375,
      -2.9375,
      5.59375,
      1.1171875,
      -4,
      2.125,
      0.921875,
      0.63671875,
      -1.4453125,
      1.375,
      1.875,
      1.0546875,
      1.5390625,
      2.109375,
      -1.234375,
      -4.96875,
      1.46875,
      1.203125,
      -4.96875,
      4.1875,
      -1.125,
      -1.796875,
      0.5078125,
      -2.71875,
      1.5234375,
      3.390625,
      2.53125,
      2.75,
      2.15625,
      0.470703125,
      -3.140625,
      3.75,
      -3.796875,
      -3.125,
      1.4921875,
      -2.53125,
      -0.875,
      1.59375,
      -1.9140625,
      0.92578125,
      -1.2421875,
      -2.40625,
      -5.9375,
      -4.53125,
      -1.03125,
      0.3828125,
      -0.9921875,
      3.609375,
      -2.890625,
      3.765625,
      -2.109375,
      -2.703125,
      0.2001953125,
      1.40625,
      -2.875,
      -0.5234375,
      -0.59375,
      -6.375,
      -0.7734375,
      7.53125,
      2.53125,
      -1.9921875,
      7.40625,
      -0.26953125,
      -0.6875,
      -0.8203125,
      3.734375,
      -4.625,
      -1.6875,
      1.125,
      -2.578125,
      -2.90625,
      -5.40625,
      0.2431640625,
      -1.7734375,
      4.65625,
      1.9140625,
      0.29296875,
      -0.625,
      -3.875,
      1.3828125,
      1.984375,
      -1.6015625,
      2.84375,
      4.28125,
      -2.828125,
      -2.1875,
      2.296875,
      3.453125,
      -1.4296875,
      -0.70703125,
      -1.5078125,
      3.34375,
      1.515625,
      2.828125,
      -1.7109375,
      -7.15625,
      -0.2412109375,
      -0.54296875,
      -1.234375,
      3.765625,
      1.1875,
      0.640625,
      5.28125,
      2.359375,
      -4.65625,
      -4.34375,
      4.5,
      -2.59375,
      2.046875,
      0.8046875,
      0.72265625,
      1.1328125,
      3.75,
      -2.984375,
      -5.5625,
      -1.4296875,
      2.4375,
      3.171875,
      -0.023193359375,
      -1.5390625,
      4.625,
      -2.03125,
      4.84375,
      -3.75,
      -4.75,
      1.90625,
      -0.65625,
      0.007354736328125,
      -1.2890625,
      9.9375,
      -2.4375,
      1.40625,
      -1.9375,
      2.234375,
      1.015625,
      0.84375,
      -1.5234375,
      -0.208984375,
      1.8515625,
      0.87109375,
      1.484375,
      -0.4296875,
      -4.75,
      -0.376953125,
      -2.390625,
      0.60546875,
      -3.375,
      2.828125,
      -0.484375,
      -1.265625,
      -1.8359375,
      0.50390625,
      -1.8125,
      4.1875,
      5.78125,
      1.3671875,
      -2.625,
      0.2470703125,
      2.875,
      -1.1796875,
      5.9375,
      1.3125,
      10.625,
      -3.984375,
      -2.3125,
      2.140625,
      0.275390625,
      0.302734375,
      1.6484375,
      -6.28125,
      -2.125,
      -2.75,
      0.65234375,
      -2.703125,
      0.96484375,
      -5.5625,
      -1.8046875,
      4.90625,
      2.296875,
      2.4375,
      3.640625,
      4.0625,
      0.1865234375,
      -0.34765625,
      -4.625,
      -2.84375,
      0.640625,
      -0.07275390625,
      -1.0078125,
      -5.21875,
      0.8984375,
      2.6875,
      5.375,
      -0.9296875,
      -2.484375,
      -3.203125,
      7.34375,
      -0.55078125,
      -1.5078125,
      0.74609375,
      -0.5078125,
      1.9453125,
      1.90625,
      3.171875,
      -4.3125,
      -1.171875,
      5.40625,
      5,
      -0.95703125,
      1.1640625,
      0.64453125,
      3.90625,
      -5.0625,
      -1.203125,
      1.0234375,
      0.57421875,
      -0.4375,
      0.3515625,
      -0.251953125,
      2.34375,
      -7.09375,
      2.734375,
      0.9765625,
      -4.65625,
      1.9765625,
      -0.34375,
      1.046875,
      0.55078125,
      2.34375,
      6.71875,
      -3.09375,
      -0.51953125,
      -3.234375,
      -9.0625,
      -3.046875,
      1.7421875,
      -0.6484375,
      1.4921875,
      4.4375,
      -4.53125,
      0.98828125,
      -5.90625,
      0.7578125,
      -4.0625,
      3.328125,
      0.703125,
      -2.203125,
      1.1875,
      -6.75,
      -7.625,
      -2.9375,
      -1.6484375,
      -1.234375,
      -3.515625,
      -4.96875,
      -3.421875,
      0.349609375,
      -6.625,
      -2.578125,
      -5.1875,
      0.11767578125,
      3.0625,
      1.9609375,
      3.21875,
      -4.0625,
      2.078125,
      2.484375,
      -1.953125,
      3.46875,
      2.109375,
      3.6875,
      6.3125,
      -0.453125,
      0.2158203125,
      -5.75,
      4.8125,
      -3.171875,
      6.34375,
      3.328125,
      1.0859375,
      -7.6875,
      2.328125,
      -1.875,
      2.171875,
      -5.84375,
      -0.91015625,
      0.2373046875,
      0.2578125,
      0.1240234375,
      -1.921875,
      4.21875,
      -4.21875,
      -1.703125,
      1.640625,
      -3.125,
      0.20703125,
      1.3203125,
      3.359375,
      5.53125,
      0.71484375,
      1.609375,
      0.73828125,
      0.83203125,
      2.359375,
      0.07861328125,
      4.28125,
      -5.125,
      0.515625,
      -0.66796875,
      -1.578125,
      0.2578125,
      -2.71875,
      1.3359375,
      -0.60546875,
      1.5,
      1.7578125,
      2,
      2.71875,
      1.3984375,
      3.921875,
      -0.150390625,
      0.09326171875,
      2.8125,
      -4.8125,
      4.40625,
      0.390625,
      0.74609375,
      -4.0625,
      -0.66796875,
      -3.21875,
      -0.5234375,
      0.8046875,
      -3.453125,
      -0.7890625,
      -0.73046875,
      -5.25,
      3.953125,
      -1.5703125,
      2.109375,
      3.203125,
      2.71875,
      4.84375,
      1.6875,
      1.984375,
      0.86328125,
      0.56640625,
      -1.703125,
      4.15625,
      -1.8046875,
      1.375,
      5.1875,
      3.625,
      3.4375,
      0.169921875,
      0.58984375,
      -0.85546875,
      -1.109375,
      1.328125,
      -2.390625,
      -1.0703125,
      5.40625,
      -1.3515625,
      0.408203125,
      0.337890625,
      0.333984375,
      -1.078125,
      0.1123046875,
      0.0830078125,
      4.59375,
      5.84375,
      -4.4375,
      0.1845703125,
      -3.78125,
      -1.2265625,
      1.046875,
      0.443359375,
      0.66015625,
      3.328125,
      -0.08544921875,
      1.140625,
      -2.78125,
      -2.375,
      -0.181640625,
      -2.90625,
      -0.55859375,
      2.53125,
      -0.451171875,
      -0.37890625,
      -0.83984375,
      0.07177734375,
      -3.765625,
      3.46875,
      4.59375,
      -4.5,
      2.03125,
      1.953125,
      -0.5078125,
      4.875,
      2.421875,
      -1.0859375,
      1.8984375,
      -0.22265625,
      -0.640625,
      2.6875,
      -2.015625,
      1.4453125,
      -0.07666015625,
      0.08203125,
      2.015625,
      3.0625,
      -1.828125,
      2.078125,
      0.84765625,
      -2.75,
      1.1171875,
      -1.8984375,
      -8.4375,
      -0.78125,
      -2.6875,
      -2.265625,
      -0.8671875,
      -4.21875,
      0.59375,
      2.453125,
      -7.15625,
      5.375,
      -2.578125,
      7.5625,
      0.423828125,
      -4.21875,
      -2.765625,
      -3.828125,
      3.875,
      -1.984375,
      2.015625,
      1.1015625,
      -0.44921875,
      4.40625,
      -1.0546875,
      -1.0625,
      -1.390625,
      0.08154296875,
      6.3125,
      -4.3125,
      0.345703125,
      -0.6640625,
      2.453125,
      -7.28125,
      -4,
      -0.58984375,
      0.921875,
      1.8828125,
      0.765625,
      -1.78125,
      0.59765625,
      2.234375,
      -2.859375,
      1.03125,
      -3.390625,
      -1.15625,
      2.234375,
      -1.3203125,
      5.4375,
      2.78125,
      -1.8125,
      -1.9453125,
      -2.421875,
      -3.625,
      -1.546875,
      0.07666015625,
      2.046875,
      -3.75,
      -1.4453125,
      -1.65625,
      0.796875,
      -0.078125,
      -0.69921875,
      1.53125,
      -0.050048828125,
      4.53125,
      0.052001953125,
      1.828125,
      1.1484375,
      1.7421875,
      -3.421875,
      -3.40625,
      -3.65625,
      3.546875,
      1.5859375,
      -0.97265625,
      0.74609375,
      -2.375,
      1.5703125,
      2.8125,
      -0.74609375,
      1.6015625,
      0.40625,
      3.921875,
      -0.6640625,
      -2.453125,
      3.6875,
      1.796875,
      3.421875,
      -3.5625,
      -4.78125,
      -4.4375,
      -0.1455078125,
      0.578125,
      -0.734375,
      -0.25390625,
      0.53515625,
      -2.59375,
      -0.76953125,
      -2.25,
      -0.055908203125,
      5.78125,
      2.21875,
      6.15625,
      1.1015625,
      1.1015625,
      -3.984375,
      -0.68359375,
      -1.109375,
      4.3125,
      0.35546875,
      -1.9375,
      3.640625,
      -0.37890625,
      3.578125,
      -4.40625,
      -3.53125,
      -5.375,
      -2.25,
      6.21875,
      -0.76953125,
      -0.68359375,
      1.4140625,
      2.375,
      0.48046875,
      1.296875,
      1.7109375,
      -1.828125,
      -3.296875,
      -4.21875,
      3.5,
      0.56640625,
      -3.578125,
      1.6171875,
      1.4296875,
      -2.328125,
      1.125,
      5.5,
      3.140625,
      -1.9140625,
      1.6875,
      -2.609375,
      -4.28125,
      -4.375,
      4.96875,
      2.859375,
      -0.9140625,
      -3.140625,
      -3.984375,
      -0.9375,
      -0.271484375,
      0.51171875,
      2.75,
      -2.109375,
      2.984375,
      -0.451171875,
      2.640625,
      3.484375,
      0.1162109375,
      -0.32421875,
      3.234375,
      2.796875,
      -3.21875,
      -0.466796875,
      -3.9375,
      -1.0859375,
      1.6328125,
      -7.40625,
      1.59375,
      -0.036376953125,
      0.326171875,
      4.75,
      1.28125,
      2.78125,
      1.546875,
      -3.25,
      -1.8046875,
      0.314453125,
      0.68359375,
      1.9296875,
      0.44140625,
      -2.078125,
      2.40625,
      -0.111328125,
      0.6484375,
      -5.03125,
      5.96875,
      -1.625,
      3.203125,
      1.6015625,
      3.265625,
      -6.625,
      -0.9296875,
      -2.0625,
      0.72265625,
      -1.484375,
      0.91015625,
      -0.6328125,
      1.09375,
      1.3515625,
      -1.6953125,
      -6.25,
      0.09716796875,
      -2.546875,
      1.1484375,
      -0.7578125,
      0.0081787109375,
      -5.625,
      2.546875,
      -6.21875,
      -0.74609375,
      3.703125,
      -0.4296875,
      -0.0908203125,
      0.83984375,
      -0.61328125,
      4.59375,
      3.578125,
      1.0703125,
      -2.515625,
      5.3125,
      -2.171875,
      -1.9765625,
      -5.40625,
      3.203125,
      -0.2216796875,
      -1.328125,
      1.9921875,
      -2.3125,
      5.34375,
      -2.578125,
      -2.625,
      -1.59375,
      -1.1640625,
      1.3984375,
      4.71875,
      2.1875,
      -0.921875,
      0.1611328125,
      -2.578125,
      3.84375,
      2.265625,
      -2.546875,
      -1.09375,
      -0.6875,
      -1.4921875,
      -4.625,
      4.875,
      2.515625,
      -1.375,
      3.640625,
      4.34375,
      -5.6875,
      0.6796875,
      3.9375,
      4.1875,
      -2.078125,
      -3.203125,
      -1.3359375,
      3.59375,
      -3.5,
      -0.455078125,
      -5.1875,
      1.7265625,
      2.15625,
      -3.125,
      1.2890625,
      -0.33203125,
      2.59375,
      -3.71875,
      0.15234375,
      0.859375,
      3.28125,
      3.84375,
      -2.84375,
      1.4140625,
      3.53125,
      1.7890625,
      5.125,
      -2.171875,
      -2.71875,
      -3.59375,
      1.234375,
      -3.40625,
      0.34765625,
      -5.53125,
      -1.3671875,
      -0.703125,
      -2.859375,
      0.171875,
      0.498046875,
      1.234375,
      1.296875,
      1.1171875,
      -2.640625,
      -4.25,
      -3.5,
      1.1484375,
      -0.01904296875,
      -4.25,
      1.796875,
      2.046875,
      4.1875,
      5.6875,
      5.15625,
      0.67578125,
      -2.3125,
      1.09375,
      -0.55859375,
      2.3125,
      -1.3984375,
      1.8203125,
      1.1328125,
      -2.515625,
      1.796875,
      0.640625,
      3.140625,
      -3.1875,
      0.07861328125,
      -3.21875,
      -2.734375,
      -0.65625,
      1.8046875,
      -0.91015625,
      0.404296875,
      3.03125,
      -2.484375,
      4.34375,
      2.4375,
      0.671875,
      -6.5,
      3.265625,
      -0.5546875,
      4.96875,
      3.890625,
      1.3984375,
      -2.28125,
      8,
      2.375,
      0.8671875,
      1.7734375,
      0.625,
      -0.2734375,
      -3.296875,
      3.28125,
      1.3984375,
      4.375,
      -0.376953125,
      2.9375,
      5.25,
      -1.734375,
      3.90625,
      4.875,
      0.15625,
      -0.298828125,
      4.625,
      0.018798828125,
      -5.0625,
      -0.123046875,
      3.1875,
      -2.53125,
      -2.515625,
      3.484375,
      0.421875,
      3.765625,
      -0.2890625,
      1.234375,
      0.75,
      4.875,
      -6.1875,
      1.625,
      -9.5,
      1.171875,
      -5.90625,
      3.25,
      -6.875,
      -0.26171875,
      0.58984375,
      4.28125,
      0.177734375,
      -5.21875,
      5.3125,
      5.03125,
      -1.7109375,
      -2.34375,
      5.59375,
      1.4375,
      -1.3125,
      -4.40625,
      -1.6328125,
      3.78125,
      -1.8671875,
      0.984375,
      -3.90625,
      1,
      2.796875,
      -2.96875,
      -3.453125,
      1.1015625,
      -1.4296875,
      -4.25,
      -4.84375,
      -3.78125,
      0.002166748046875,
      -4.25,
      4.15625,
      1.640625,
      -1.609375,
      2.9375,
      0.380859375,
      3.96875,
      2.421875,
      1,
      2.59375,
      0.373046875,
      2.109375,
      -0.71484375,
      3.453125,
      -4.40625,
      2.046875,
      -0.359375,
      0.93359375,
      -0.10693359375,
      -1.5859375,
      0.52734375,
      -6.28125,
      3.421875,
      3.03125,
      4,
      2.3125,
      -1.1484375,
      0.06494140625,
      3.265625,
      -1.640625,
      -0.83984375,
      2.78125,
      1.953125,
      -1.71875,
      3.171875,
      -2.5,
      5.4375,
      0.60546875,
      1.140625,
      2.40625,
      0.0751953125,
      -1.8125,
      0.12451171875,
      -3.28125,
      1.1875,
      -2.515625,
      1.0078125,
      -0.69140625,
      -3.03125,
      0.515625,
      3.53125,
      0.75390625,
      1.1640625,
      -2.78125,
      1.25,
      0.6328125,
      2.296875,
      -0.0771484375,
      -1.9296875,
      -0.71484375,
      -2.578125,
      -3.3125,
      -1.2734375,
      -2.046875,
      -0.21484375,
      2.984375,
      -1.7265625,
      -1.3125,
      -2.453125,
      1.46875,
      -1.484375,
      -11.6875,
      0.1025390625,
      -0.69140625,
      -0.70703125,
      -4.96875,
      0.6171875,
      2.28125,
      2.234375,
      2.25,
      6.03125,
      3.046875,
      -3.328125,
      5.46875,
      19.375,
      -3.5625,
      -3.078125,
      -1.25,
      -0.20703125,
      1.6875,
      7.78125,
      1.4609375,
      0.1650390625,
      0.7265625,
      3.5625,
      4.71875,
      0.69921875,
      2.0625,
      -0.671875,
      2.109375,
      2.46875,
      -0.546875,
      -3.609375,
      -4.6875,
      -2.734375,
      0.8203125,
      -1.125,
      3.4375,
      0.76171875,
      0.126953125,
      2.125,
      -1.84375,
      -1.65625,
      -2.8125,
      -0.035888671875,
      -2.21875,
      0.2890625,
      -3.796875,
      -0.1435546875,
      -3.921875,
      0.70703125,
      2.328125,
      -1.0859375,
      -1.5234375,
      -3.296875,
      -2.8125,
      1,
      -1.5859375,
      0.68359375,
      0.70703125,
      -1.9453125,
      -0.66015625,
      0.35546875,
      0.74609375,
      -2.109375,
      -2.546875,
      -2.90625,
      -0.06591796875,
      -1.078125,
      -2.25,
      0.79296875,
      -9,
      -1.59375,
      -5.625,
      0.326171875,
      -2.296875,
      -2.390625,
      -0.55078125,
      -1.6171875,
      -4.28125,
      -2.921875,
      -1.1328125,
      0.55859375,
      0.7578125,
      -3.546875,
      1.1328125,
      4.625,
      2.21875,
      1.1015625,
      -0.357421875,
      4.75,
      4.59375,
      -1.328125,
      1.234375,
      -3.234375,
      1.28125,
      -0.12060546875,
      -0.91796875,
      -2.609375,
      1.921875,
      -6.59375,
      2.65625,
      1.9140625,
      0.34765625,
      6.78125,
      -1.34375,
      2.453125,
      0.93359375,
      -3.328125,
      -4.71875,
      1.4375,
      0.31640625,
      -1.8984375,
      -1.328125,
      3.640625,
      1.3203125,
      -1.5234375,
      -2.1875,
      0.671875,
      -1.5078125,
      3.03125,
      -2.46875,
      2.8125,
      -2.609375,
      -0.201171875,
      1.578125,
      -0.203125,
      -0.34375,
      2.625,
      2.671875,
      -4.1875,
      -4.0625,
      -0.63671875,
      -1.1171875,
      4.34375,
      1.421875,
      -2.890625,
      0.734375,
      -7.625,
      -2.953125,
      -1.1953125,
      -3.109375,
      4.78125,
      -2.265625,
      3.84375,
      -2.5,
      -2.90625,
      0.66015625,
      1.34375,
      -3.453125,
      4.125,
      3.78125,
      2.109375,
      0.65234375,
      -3.34375,
      -0.671875,
      0.94921875,
      -2.5625,
      0.32421875,
      -2.3125,
      -3.921875,
      4.71875,
      3.28125,
      0.2412109375,
      -4.71875,
      5.59375,
      0.111328125,
      -3.78125,
      0.73828125,
      3.6875,
      -1.8515625,
      -2.4375,
      -4.21875,
      -2.25,
      -0.76171875,
      -0.88671875,
      -1.4609375,
      -4.4375,
      -1.375,
      1.125,
      2.46875,
      0.51171875,
      -5.34375,
      3.703125,
      5.125,
      -6,
      0.30859375,
      -3.765625,
      3.703125,
      -3.4375,
      -1.28125,
      4.875,
      -0.462890625,
      0.85546875,
      0.3203125,
      2.8125,
      -2.1875,
      -5.25,
      1.78125,
      3.703125,
      -3.421875,
      0.41015625,
      4.5625,
      -1.96875,
      1.1796875,
      -5.3125,
      -5.3125,
      5.875,
      8.25,
      -4.59375,
      -0.2314453125,
      -3.8125,
      -2.921875,
      -1.1015625,
      -2.625,
      1.71875,
      0.7265625,
      1.1015625,
      3.46875,
      1.1328125,
      -2.890625,
      -0.263671875,
      0.65234375,
      -0.88671875,
      -4.5,
      3.125,
      2.015625,
      1.6875,
      -7.5625,
      4.125,
      2.890625,
      0.92578125,
      -3.0625,
      3.28125,
      1.2421875,
      2.203125,
      -6.1875,
      -1.6015625,
      1.6171875,
      2.265625,
      -7.84375,
      3.484375,
      -2.125,
      2.3125,
      -1.6171875,
      3.90625,
      -2.453125,
      -0.224609375,
      -3.9375,
      -4.375,
      -6.03125,
      3.140625,
      -1.3828125,
      2.34375,
      3.078125,
      0.25,
      1.9375,
      4.21875,
      0.765625,
      2.015625,
      1.046875,
      -1.3515625,
      2.453125,
      -0.357421875,
      1.09375,
      -0.1953125,
      0.80859375,
      -1.3984375,
      -0.431640625,
      -0.81640625,
      -1.2734375,
      -3.578125,
      -5.40625,
      2.40625,
      1.5390625,
      -4.625,
      5.28125,
      -0.345703125,
      -1.828125,
      1.4609375,
      0.2314453125,
      -4.40625,
      4.96875,
      0.89453125,
      -6.09375,
      4.96875,
      0.18359375,
      -4.71875,
      0.5390625,
      -0.625,
      1.171875,
      -5.8125,
      0.494140625,
      4.3125,
      -5.4375,
      2.34375,
      1.234375,
      -0.90234375,
      -2.5625,
      -3.34375,
      0.259765625,
      -1.6953125,
      0.08984375,
      -0.455078125,
      3.078125,
      3.96875,
      -5.3125,
      0.408203125,
      -3.3125,
      2.921875,
      -2.53125,
      0.004150390625,
      1.0625,
      0.69140625,
      1.53125,
      3.453125,
      2.5625,
      -6.9375,
      -5.4375,
      -0.326171875,
      -3.328125,
      4.0625,
      0.494140625,
      0.66796875,
      -2.734375,
      -2,
      1.0390625,
      1.5625,
      0.12109375,
      -1.578125,
      -4.4375,
      2.84375,
      0.83203125,
      -9.125,
      1.015625,
      -0.1953125,
      0.27734375,
      -0.65625,
      0.26953125,
      -0.83203125,
      0.2177734375,
      2.46875,
      -2.375,
      3.1875,
      -1.7109375,
      0.353515625,
      2.21875,
      0.59765625,
      4.03125,
      2.3125,
      -3.921875,
      -7.375,
      0.91796875,
      1.84375,
      -0.99609375,
      3.609375,
      -0.5859375,
      4.53125,
      1.125,
      3.140625,
      -7.1875,
      4.78125,
      -0.056884765625,
      -6.40625,
      3.59375,
      -4.96875,
      0.30859375,
      -3.234375,
      -3.53125,
      -1.2734375,
      5.09375,
      -0.2314453125,
      2.203125,
      2.640625,
      -2.078125,
      -1.265625,
      3.46875,
      0.85546875,
      -3.40625,
      3.015625,
      2.234375,
      -3.984375,
      1.015625,
      2.703125,
      -1.3984375,
      -2.5,
      0.37109375,
      2.5625,
      -2.734375,
      -2.125,
      3.71875,
      3.09375,
      -0.1162109375,
      -2.71875,
      -5.0625,
      1.484375,
      -0.86328125,
      -4.53125,
      3.21875,
      -4.25,
      1.171875,
      -4.59375,
      2.390625,
      1.421875,
      -4.625,
      -1.40625,
      -4.4375,
      -0.57421875,
      1.5390625,
      3.625,
      2.375,
      -1.1015625,
      -1.9765625,
      3.578125,
      2.1875,
      -0.45703125,
      -4.5625,
      1.4453125,
      -3.265625,
      -2.796875,
      -2.734375,
      3.609375,
      -1.765625,
      -1.390625,
      1.3828125,
      4.4375,
      -1.234375,
      -4.5625,
      -0.71484375,
      3.21875,
      0.0084228515625,
      -0.0234375,
      -1.484375,
      -0.283203125,
      2.015625,
      1.9375,
      -3.46875,
      -3.828125,
      -1.046875,
      1.796875,
      -6.125,
      -4.625,
      2.28125,
      0.26171875,
      -1.8046875,
      2.359375,
      -0.31640625,
      -2.25,
      1.6171875,
      -6.15625,
      -2.03125,
      5.125,
      5.15625,
      1.6875,
      1.15625,
      -0.71484375,
      -3.46875,
      4.09375,
      7.84375,
      -0.90625,
      -1.59375,
      1.734375,
      -4.78125,
      -1.9296875,
      -0.88671875,
      1.0234375,
      -0.16796875,
      -6.40625,
      7.71875,
      -2.296875,
      2.3125,
      2.5,
      -2.75,
      0.82421875,
      -2.859375,
      5.71875,
      -1.6796875,
      2.328125,
      -0.40234375,
      -1.171875,
      -0.140625,
      -2.296875,
      -1.71875,
      -0.25390625,
      -2.0625,
      1.3046875,
      2.28125,
      2.671875,
      -2.34375,
      -0.5625,
      -1.1484375,
      -2.015625,
      3.75,
      -0.337890625,
      -3.875,
      -0.40234375,
      -3.8125,
      0.625,
      -0.84375,
      -0.890625,
      -4.71875,
      -3.09375,
      -2.859375,
      2.96875,
      -0.038330078125,
      2.765625,
      -1.46875,
      -3.15625,
      0.6015625,
      2.5625,
      3.203125,
      2.859375,
      4.5625,
      1.65625,
      -0.75390625,
      -1.671875,
      4.28125,
      3.65625,
      5.09375,
      -3,
      0.7421875,
      1.265625,
      0.6796875,
      -0.8359375,
      -1.3359375,
      1.1328125,
      -0.76171875,
      2.03125,
      -1.5625,
      0.10498046875,
      -0.72265625,
      1.2734375,
      -2.125,
      -1.796875,
      2.25,
      1.3046875,
      -3.1875,
      1.078125,
      2.734375,
      0.79296875,
      0.73828125,
      2.359375,
      0.1259765625,
      0.373046875,
      -2.140625,
      -0.56640625,
      1.5859375,
      -3.28125,
      0.79296875,
      -3.609375,
      -1.6796875,
      -0.75,
      -4.375,
      1.078125,
      -1.9140625,
      -1.6328125,
      1.9921875,
      -1.03125,
      1.5546875,
      3.53125,
      -1.4296875,
      0.65625,
      2.609375,
      1.5859375,
      1.0625,
      -1.671875,
      -0.8828125,
      2.09375,
      3.140625,
      -0.004669189453125,
      1.0703125,
      0.48828125,
      0.61328125,
      0.220703125,
      -2.0625,
      3.28125,
      -1.7890625,
      5.0625,
      -1.6875,
      0.2333984375,
      -0.609375,
      -0.859375,
      -2.1875,
      -1.3984375,
      -1.0703125,
      -1.890625,
      -2.671875,
      2.296875,
      1.234375,
      0.8125,
      2.40625,
      -0.69921875,
      0.796875,
      -0.5546875,
      -2.125,
      -0.345703125,
      -1.6796875,
      -5,
      0.7734375,
      0.84375,
      0.7265625,
      -2.28125,
      2.125,
      0.859375,
      0.6640625,
      -0.154296875,
      1.28125,
      1.0390625,
      1.765625,
      0.1220703125,
      -0.4296875,
      2.328125,
      1.1796875,
      -0.0181884765625,
      0.6015625,
      -1,
      -1.296875,
      0.5390625,
      0.65234375,
      1.0390625,
      -0.54296875,
      -1.8828125,
      2.125,
      0.279296875,
      3.015625,
      -2.359375,
      1.03125,
      0.8203125,
      -1.15625,
      1.171875,
      3.46875,
      -0.37890625,
      -5.28125,
      1.5625,
      3.8125,
      -5.625,
      -1.9375,
      -1.6171875,
      -2.375,
      -0.640625,
      -2.359375,
      -1.46875,
      -0.53125,
      -3.84375,
      2.203125,
      -0.400390625,
      2.296875,
      -0.953125,
      -2.390625,
      2.546875,
      -1.3203125,
      -0.2734375,
      -1.53125,
      -0.53515625,
      -0.38671875,
      -0.017333984375,
      -4.21875,
      1.375,
      1.4140625,
      -1.3125,
      -0.71484375,
      -0.1845703125,
      -0.76171875,
      -0.018798828125,
      0.921875,
      -2.59375,
      -2.453125,
      1.71875,
      0.322265625,
      0.255859375,
      0.5234375,
      -1.1953125,
      -2.03125,
      1.015625,
      -3.453125,
      2.3125,
      0.1943359375,
      -1.21875,
      0.06689453125,
      2.796875,
      -1.4609375,
      -0.27734375,
      -0.0625,
      -2.390625,
      -2.484375,
      -1.9140625,
      2.71875,
      -0.6328125,
      -1.734375,
      1.421875,
      2.34375,
      1.3203125,
      0.1435546875,
      -0.0888671875,
      0.98828125,
      -1.2265625,
      -0.53125,
      -0.48828125,
      0.9609375,
      2.8125,
      -2.484375,
      -1.3125,
      -2.5625,
      -1.1640625,
      -1.046875,
      -0.5,
      -3.34375,
      2.375,
      -0.76953125,
      0.365234375,
      3.625,
      2.25,
      2.671875,
      1.9609375,
      -3.828125,
      2.953125,
      4.75,
      0.275390625,
      -2.671875,
      0.57421875,
      -0.158203125,
      -0.6015625,
      -1.453125,
      -2.015625,
      -2.1875,
      0.5234375,
      2.1875,
      0.7109375,
      -2.390625,
      -1.109375,
      1.046875,
      2.140625,
      0.84375,
      -3.984375,
      0.67578125,
      -0.333984375,
      -3.09375,
      -1.9609375,
      -1.8125,
      0.9140625,
      2.078125,
      -4.65625,
      0.197265625,
      1.5,
      1.3828125,
      0.08447265625,
      -0.05224609375,
      0.3671875,
      -3.546875,
      -1.5078125,
      0.51953125,
      -1.8203125,
      -1.1171875,
      1.953125,
      0.392578125,
      -0.60546875,
      1.296875,
      -1.109375,
      -0.25,
      0.26171875,
      -2.265625,
      0.921875,
      0.4765625,
      -2.90625,
      -4.03125,
      -1.7109375,
      -5.90625,
      0.58984375,
      1.265625,
      -0.93359375,
      1.3828125,
      2.5625,
      0.408203125,
      -3.84375,
      -1.40625,
      1.25,
      3.53125,
      -1.1328125,
      0.3671875,
      1.1015625,
      -0.90625,
      0.55859375,
      -2.296875,
      1.125,
      -0.2578125,
      -0.388671875,
      -0.62109375,
      -3.171875,
      -0.34765625,
      1.484375,
      -5,
      -0.63671875,
      -1.6328125,
      -2.734375,
      0.16015625,
      -1.2109375,
      -0.3671875,
      3.625,
      0.5234375,
      2.5625,
      4.75,
      0.244140625,
      -0.984375,
      -0.68359375,
      1.921875,
      3.484375,
      0.828125,
      -0.1572265625,
      -1.21875,
      2.0625,
      0.47265625,
      -1.1953125,
      0.84765625,
      0.31640625,
      4.25,
      0.5234375,
      -0.298828125,
      0.7109375,
      1.578125,
      0.177734375,
      0.8515625,
      4.15625,
      -6.78125,
      0.59375,
      1.359375,
      -0.275390625,
      -0.341796875,
      2.1875,
      2.578125,
      0.83984375,
      5.59375,
      1.1953125,
      2.71875,
      2.046875,
      2.421875,
      -0.08349609375,
      0.400390625,
      1.2421875,
      0.162109375,
      2,
      0.361328125,
      -2.8125,
      2.921875,
      -0.97265625,
      -0.7265625,
      5.71875,
      -1.34375,
      0.38671875,
      1.2734375,
      1.3515625,
      3,
      0.51953125,
      -0.259765625,
      -1.78125,
      -0.478515625,
      1.3359375,
      1,
      0.41796875,
      -0.0927734375,
      1.515625,
      0.56640625,
      -1.234375,
      -1.8046875,
      -0.72265625,
      -2.6875,
      -2.34375,
      -2.59375,
      1,
      -0.27734375,
      2.390625,
      -2.25,
      1.9765625,
      -0.0869140625,
      1.78125,
      3.125,
      -0.0771484375,
      0.9453125,
      2.703125,
      -2.46875,
      -1.4140625,
      2.25,
      -0.625,
      -4.5,
      0.59375,
      0.92578125,
      -1.1796875,
      0.302734375,
      -0.98828125,
      -0.89453125,
      1.4765625,
      0.46875,
      -2.40625,
      -1.09375,
      2.25,
      -0.109375,
      2.03125,
      0.5703125,
      0.11083984375,
      2.046875,
      2.984375,
      1.6953125,
      -1.4609375,
      1.9921875,
      -0.890625,
      0.48828125,
      -1.2734375,
      -2.6875,
      -0.37109375,
      -2.359375,
      0.0296630859375,
      2.765625,
      -0.11181640625,
      -3.171875,
      -2.078125,
      2.296875,
      -0.96875,
      2.328125,
      1.46875,
      0.82421875,
      -0.236328125,
      1.6484375,
      1.2265625,
      1.515625,
      -2.640625,
      0.44140625,
      -2.265625,
      -0.23046875,
      -1.5078125,
      -1.71875,
      -2.125,
      0.640625,
      1.234375,
      1.890625,
      -1.53125,
      0.12353515625,
      -1.6015625,
      -3.0625,
      0.515625,
      -5.9375,
      0.3828125,
      2.296875,
      -0.83203125,
      0.2490234375,
      -0.61328125,
      2.75,
      -3.953125,
      0.61328125,
      -0.58203125,
      -0.25390625,
      -0.28125,
      1.328125,
      -2.25,
      4.15625,
      -1.109375,
      1.1796875,
      4.0625,
      0.267578125,
      2.28125,
      2.78125,
      -0.462890625,
      -0.703125,
      -0.365234375,
      0.71875,
      -1.6328125,
      -3.3125,
      0.0087890625,
      -1.6875,
      -1.25,
      -0.2421875,
      3.6875,
      1.7421875,
      -0.55078125,
      0.1923828125,
      3.0625,
      1.6875,
      1.3125,
      2.5,
      -2.875,
      -0.33203125,
      -4.9375,
      0.314453125,
      0.494140625,
      0.9765625,
      0.984375,
      1.8828125,
      -0.1884765625,
      0.41015625,
      -1.796875,
      -1.71875,
      1.1328125,
      -1.8671875,
      0.166015625,
      1.546875,
      -0.87890625,
      -1.609375,
      0.7734375,
      -4.125,
      3.5625,
      -3.140625,
      -0.033203125,
      0.314453125,
      -1.65625,
      -0.1943359375,
      -2.90625,
      -1.2109375,
      1.9921875,
      0.1650390625,
      0.7109375,
      -1.59375,
      2.625,
      -2.921875,
      -0.984375,
      2.828125,
      2.53125,
      0.318359375,
      0.10546875,
      -0.9921875,
      -0.51953125,
      1.6171875,
      -2.375,
      -1.203125,
      0.326171875,
      -2.03125,
      -0.5390625,
      3.4375,
      2.5625
    ],
    "summary": "# 论文评审报告：UniEDU\n\n## 1. 🎯 结构化速读\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 现有教育AI模型缺乏多模态理解能力，任务专用模型泛化性差，长交互历史导致计算成本过高 [cite Section 1] |\n| **核心方案** | 通过压缩学生交互历史为紧凑token表示，在单一生成式框架下统一处理多种教育任务 [cite Section 3.1] |\n| **关键概念** | 交互历史压缩：将长达300次的多模态交互压缩为固定长度表示，实现3倍效率提升 [cite Abstract] |\n| **核心数据** | 真实K-12教育场景数据，包含文本和图像的多模态问题，最长序列达45,000 tokens [cite Section 1] |\n| **核心假设** | 教育场景的交互历史可压缩而不损失关键信息，统一表示能促进任务间知识迁移 [cite Section 1] |\n| **主要结论** | UniEDU在保持性能接近全微调模型的同时，计算效率提升约300%，优于任务专用模型 [cite Abstract] |\n\n## 2. 💡 深度解读\n\n**给大一新生的解释：想象你是一位家教老师**\n\n传统的教育AI就像**各科专任老师**——数学老师只懂数学，英语老师只批改英语作业。每个老师都需要你完整复述过去一年的学习情况，这就像每次见面都要从头讲起，极其耗时[cite Section 1]。\n\nUniEDU的做法更像**一位全能家教**。它有个神奇的本领：当你描述学习经历时，它能自动提炼关键信息。比如你说了\"三角函数总是搞混正弦余弦\"，它会记下\"数学-三角函数-概念混淆\"这个核心点，而不是死记你的每一句话[cite Section 3.1]。\n\n**为什么压缩历史反而更有效？**\n就像好老师不会要求学生背诵所有错题，而是总结错误模式。教育场景中，重要的不是每个交互细节，而是**学习行为模式**和**知识掌握趋势**。压缩过程实际上是在去噪存精——保留\"该学生在几何证明题上反复出错\"这样的模式信息，舍弃\"某次考试的具体题目顺序\"这类无关细节[cite Section 1]。\n\n## 3. ⚔️ 评审视角\n\n### 硬伤1：压缩损失的风险评估不足\n论文声称教育场景\"容忍近似表示\"[cite Section 1]，但未提供压缩前后信息保真度的定量分析。**致命问题**：如果压缩过程丢失了关键转折点（如某次突破性进步），可能导致知识状态评估出现系统性偏差。\n\n### 硬伤2：任务统一性的强假设\n作者假设用户画像在不同任务间具有一致性[cite Section 1]，但推荐系统（关注兴趣偏好）与知识追踪（关注能力水平）的需求本质不同。**风险**：强行统一可能导致模型学习到折中的次优表示，无法在任一任务上达到极致性能。\n\n### 硬伤3：真实场景泛化性存疑\n实验仅在\"代表性\"交互数据上进行[cite Section 3.1]，但真实教育场景存在大量非典型模式（如间断学习、多科目交叉）。**隐患**：模型可能过拟合于理想化的连续学习轨迹，无法处理现实中的混乱数据。\n\n### 硬伤4：变量设计的创新与局限\n创新点在于将多模态交互历史$X_i = \\{q_i, a_i, k_i, c_i, t_i\\}$统一编码[cite Section 3.1]，但变量定义依赖预设的结构化字段。**漏洞**：实际教育系统中大量数据是非结构化的（如手写笔记、语音回答），当前设计无法直接扩展。\n\n## 4. 📝 一句话总结\n\n如果我只记这篇论文的一个贡献，那应该是：**通过可压缩的用户交互历史表示，首次实现了教育多模态任务的高效统一处理框架**。",
    "structure": {
      "sections": [
        {
          "title": "UniEDU: Toward Unified and Efficient Large Multimodal Models for Educational Tasks",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "Abstract",
          "level": 1,
          "start_line": 11
        },
        {
          "title": "1 Introduction",
          "level": 1,
          "start_line": 15
        },
        {
          "title": "2 Related Work",
          "level": 1,
          "start_line": 29
        },
        {
          "title": "3 Methodology",
          "level": 1,
          "start_line": 40
        },
        {
          "title": "3.1 Model Architecture",
          "level": 1,
          "start_line": 42
        },
        {
          "title": "3.2 Training Objective",
          "level": 1,
          "start_line": 56
        },
        {
          "title": "3.3 VRAM Computation",
          "level": 1,
          "start_line": 66
        },
        {
          "title": "3.4 Efficiency Analysis",
          "level": 1,
          "start_line": 120
        },
        {
          "title": "4 Experiments",
          "level": 1,
          "start_line": 124
        },
        {
          "title": "4.1 Education Tasks",
          "level": 1,
          "start_line": 126
        },
        {
          "title": "4.2 Implementation Details",
          "level": 1,
          "start_line": 140
        },
        {
          "title": "4.3 Results",
          "level": 1,
          "start_line": 171
        },
        {
          "title": "4.4 Analysis of Compression Tokens",
          "level": 1,
          "start_line": 179
        },
        {
          "title": "5 Conclusion",
          "level": 1,
          "start_line": 197
        },
        {
          "title": "Limitations",
          "level": 1,
          "start_line": 203
        },
        {
          "title": "Broader Impact Statement",
          "level": 1,
          "start_line": 207
        },
        {
          "title": "References",
          "level": 1,
          "start_line": 213
        },
        {
          "title": "A Appendix",
          "level": 1,
          "start_line": 265
        },
        {
          "title": "A.1 VRAM Calculation",
          "level": 1,
          "start_line": 267
        },
        {
          "title": "A.2 Example Demonstration",
          "level": 1,
          "start_line": 271
        },
        {
          "title": "Knowledge Recommendation:",
          "level": 1,
          "start_line": 306
        },
        {
          "title": "Knowledge Tracing:",
          "level": 1,
          "start_line": 316
        },
        {
          "title": "Time Cost Prediction",
          "level": 1,
          "start_line": 323
        },
        {
          "title": "User Answer Prediction:",
          "level": 1,
          "start_line": 330
        },
        {
          "title": "A.3 Training Details",
          "level": 1,
          "start_line": 341
        }
      ]
    },
    "tags": [
      "教育AI",
      "多模态学习",
      "统一模型"
    ],
    "suggested_tags": [
      "教育AI",
      "多模态学习",
      "统一模型",
      "模型压缩",
      "生成式AI"
    ],
    "tag_suggestions": [
      {
        "name": "教育AI",
        "confidence": 0.95,
        "reason": "论文专注于K-12教育场景，解决教育任务如知识推荐、知识追踪等"
      },
      {
        "name": "多模态学习",
        "confidence": 0.9,
        "reason": "模型处理文本和图像等多模态教育材料，属于多模态学习研究领域"
      },
      {
        "name": "统一模型",
        "confidence": 0.85,
        "reason": "提出UniEDU统一框架处理多种教育任务，避免任务特定模型设计"
      },
      {
        "name": "模型压缩",
        "confidence": 0.8,
        "reason": "通过压缩学生交互历史实现高效部署，提升300%计算效率"
      },
      {
        "name": "生成式AI",
        "confidence": 0.75,
        "reason": "采用生成式框架重新定义教育任务，利用自然语言灵活性"
      }
    ],
    "tags_confirmed": true,
    "category": "多模态学习",
    "analysis": {
      "status": "completed",
      "started_at": "2025-12-21T14:21:00.778666",
      "completed_at": "2025-12-21T14:22:25.580156",
      "summary": "# 论文评审报告：UniEDU\n\n## 1. 🎯 结构化速读\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 现有教育AI模型缺乏多模态理解能力，任务专用模型泛化性差，长交互历史导致计算成本过高 [cite Section 1] |\n| **核心方案** | 通过压缩学生交互历史为紧凑token表示，在单一生成式框架下统一处理多种教育任务 [cite Section 3.1] |\n| **关键概念** | 交互历史压缩：将长达300次的多模态交互压缩为固定长度表示，实现3倍效率提升 [cite Abstract] |\n| **核心数据** | 真实K-12教育场景数据，包含文本和图像的多模态问题，最长序列达45,000 tokens [cite Section 1] |\n| **核心假设** | 教育场景的交互历史可压缩而不损失关键信息，统一表示能促进任务间知识迁移 [cite Section 1] |\n| **主要结论** | UniEDU在保持性能接近全微调模型的同时，计算效率提升约300%，优于任务专用模型 [cite Abstract] |\n\n## 2. 💡 深度解读\n\n**给大一新生的解释：想象你是一位家教老师**\n\n传统的教育AI就像**各科专任老师**——数学老师只懂数学，英语老师只批改英语作业。每个老师都需要你完整复述过去一年的学习情况，这就像每次见面都要从头讲起，极其耗时[cite Section 1]。\n\nUniEDU的做法更像**一位全能家教**。它有个神奇的本领：当你描述学习经历时，它能自动提炼关键信息。比如你说了\"三角函数总是搞混正弦余弦\"，它会记下\"数学-三角函数-概念混淆\"这个核心点，而不是死记你的每一句话[cite Section 3.1]。\n\n**为什么压缩历史反而更有效？**\n就像好老师不会要求学生背诵所有错题，而是总结错误模式。教育场景中，重要的不是每个交互细节，而是**学习行为模式**和**知识掌握趋势**。压缩过程实际上是在去噪存精——保留\"该学生在几何证明题上反复出错\"这样的模式信息，舍弃\"某次考试的具体题目顺序\"这类无关细节[cite Section 1]。\n\n## 3. ⚔️ 评审视角\n\n### 硬伤1：压缩损失的风险评估不足\n论文声称教育场景\"容忍近似表示\"[cite Section 1]，但未提供压缩前后信息保真度的定量分析。**致命问题**：如果压缩过程丢失了关键转折点（如某次突破性进步），可能导致知识状态评估出现系统性偏差。\n\n### 硬伤2：任务统一性的强假设\n作者假设用户画像在不同任务间具有一致性[cite Section 1]，但推荐系统（关注兴趣偏好）与知识追踪（关注能力水平）的需求本质不同。**风险**：强行统一可能导致模型学习到折中的次优表示，无法在任一任务上达到极致性能。\n\n### 硬伤3：真实场景泛化性存疑\n实验仅在\"代表性\"交互数据上进行[cite Section 3.1]，但真实教育场景存在大量非典型模式（如间断学习、多科目交叉）。**隐患**：模型可能过拟合于理想化的连续学习轨迹，无法处理现实中的混乱数据。\n\n### 硬伤4：变量设计的创新与局限\n创新点在于将多模态交互历史$X_i = \\{q_i, a_i, k_i, c_i, t_i\\}$统一编码[cite Section 3.1]，但变量定义依赖预设的结构化字段。**漏洞**：实际教育系统中大量数据是非结构化的（如手写笔记、语音回答），当前设计无法直接扩展。\n\n## 4. 📝 一句话总结\n\n如果我只记这篇论文的一个贡献，那应该是：**通过可压缩的用户交互历史表示，首次实现了教育多模态任务的高效统一处理框架**。"
    }
  },
  "8c9e4c29-0445-4eae-a88e-5a1e4f14945e": {
    "id": "8c9e4c29-0445-4eae-a88e-5a1e4f14945e",
    "filename": "2512.02561v1.pdf",
    "file_path": "data/uploads/64d94413-f66a-4369-b6a0-66dcef7b83ee/8c9e4c29-0445-4eae-a88e-5a1e4f14945e_2512.02561v1.pdf",
    "status": "completed",
    "created_at": "2025-12-21 22:32:03.238641",
    "updated_at": "2025-12-21 14:33:36.672384",
    "user_id": "64d94413-f66a-4369-b6a0-66dcef7b83ee",
    "title": "EZYer: A simulacrum of high school with generative agent",
    "markdown_content": "# EZYer: A simulacrum of high school with generative agent\n\nJinming Yang†  \nUniversity of Electronic Science and Technology of China  \nChengdu, China  \n202522080607@std.uestc.edu.cn\n\nZimu Ji  \nShaanxi University of Science and Technology  \nXi'an, China  \n202215030214@sust.edu.cn\n\nWeiqi Luo  \nShaanxi University of Science and Technology  \nXi'an, China  \n202315030214@sust.edu.cn\n\nGaoxi Wang  \nShaanxi University of Science and Technology  \nXi'an, China  \n202315020203@sust.edu.cn\n\nBin Ma  \nShaanxi University of Science and Technology  \nXi'an, China  \n202315030113@sust.edu.cn\n\nYueling Deng  \nShaanxi University of Science and Technology  \nXi'an, China  \n202315030202@sust.edu.cn\n\n![](/uploads/images/8c9e4c29-0445-4eae-a88e-5a1e4f14945e/c481b841e6e52682e6499de1433a4a46c7c1175b6dc2cd5e22a8bb9f27bff36f.jpg)  \nFigure 1: Concept map of EZYer. The concept map visualizes the interactive interface, generative objects, and three functions of EZYer. First, to generate a Beamer that can be used in the high school math lesson based on the problems entered and materials and images uploaded by the user. Second, to design five generative agents based on the main roles in the high school math lesson. Each of these agents embodies a different personality and function, and interacts with each other according to elaborate prompts and their relationships, ultimately generating a well-formatted and well-organized Notes. Third, we set up an inspecting mechanism to ensure that all key features run smoothly through multiple dimensions of content inspection. With EZYer, we would like to explore the potential of LLM-empowered generative agents to simulating actual human behavior in instructional scenarios.\n\n# ABSTRACT\n\nWith the rapid development of the online education and large language model, the existing educational tools still suffer from incomplete service, insufficient performance and weak interactivity in terms of courseware generation, interactive notes and quality assurance of content. In particular, the proposed generative agent EZYer: 1) Teacher Module: Integrating the Text Corpus retrieval and in-depth generation technologies, it automatically generates structured teaching materials and LaTeX\n\nBeamer courseware in line with the high school mathematics syllabus and supports user-defined image insertion. 2) Student Module: Throughout the collaborative interaction of the four roles of Teacher, Assistant, Top Student and Struggling Student, Note Taker summarizes and generates academic notes to enhance the depth and interest of learning. 3) Controller: set up keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system. This ensure academic strictness and pedagogical propriety of EZYer inputs and outputs. In order to evaluate EZYer, this paper designs five-dimensional\n\nevaluation indexes of content accuracy, knowledge coverage, usability, formatting correctness and visual design and appeal, and scores 100 Beamer and Notes generated by EZYer by five large language models, separately, and the results show that the quality of EZYer-generated content is excellent and has a good application prospect.\n\n# KEYWORDS\n\nGenerative Educational Agent, LaTeX Beamer Courseware Generation, Content Inspecting Mechanism\n\n# 1 INTRODUCTION\n\nIn the current education model, teachers always need to integrate teaching materials before class and create clear courseware to assist their teaching [1], while students need to summarize the knowledge points of the day after class for review and learning [2]. Recently, AI Agent has made excellent breakthroughs in the field of education [3, 4, 5, 6, 7], and according to the feedback from teachers and students who have used educational tools [8, 9, 10] up until now, the currently released tools generally contract the shortages of incomplete service, insufficient performance, weak interactivity, and supplying of misleading information [11, 12] for instance, none of them have the ability to generate LaTeX Beamer functionality.\n\nTherefore, in consideration of fill the gap of Educational Agents in this area, we design EZYer: a generative agent of mathematical knowledge for high school teachers and students, where we choose the DeepSeek-V3 model. The EZYer was consisted from three core units: Teacher Module, Student Module, and Controller, which is established the generative agents [17, 18] of the large language model [13, 14, 15, 16]. After coming in Teacher Module, users only need to type the education content in the input box or upload a PDF/Word document. Firstly EZYer will detect whether the materials is consistently with Text Corpus automatically [19, 20] and if it matches, it will directly call the relevant content from Text Corpus and generate the teaching content and exercises. If it does not match, it will call DeepSeek API to generate the education materials and exercises, and generate LaTeX Beamer based on the teaching materials [21]. Not only that, teachers can also insert images into the Beamer according to their own ideas. We design different AI characters in Student Module to deeply replace the interactive learning scenarios [24, 25, 26, 27, 28, 29] of a real hall [22, 23], so that the students can experience the interactive learning style [30, 31] after entering Student Module. By simply typing their questions in the input box, the material is also automatically detected firstly whether it counterparts the content in Text Corpus. If it matches, the answer to the question is generated directly based on the set prompt and the related content in Text Corpus. If it does not match, DeepSeek API will be called to set up the content of the dialog. After passing the test, each role (Teacher, Assistant, Top Student, Struggling Student) will start outputting knowledge points, supplementary content, expanded content and error-prone points in proper sequence. At the end of the discussion, another\n\nrole (Note Taker) will summarize the conversation and generate Notes in PDF format. At the same time, in order to insure that EZYer can provide a good user experience all along operation, we have designed a inspecting mechanism (Controller) inside EZYer to review each time when users enter content, and to point out and block irrelevant content in a timely style, so as to provide the validity of the output content and to enhance the user experience of teachers and students.\n\nThe characteristic of EZYer lies in:\n\n(1) Teacher Module generates a professional Beamer that obeys the academic publishing standards based on an uploaded document or a simple description of the input.  \n(2) Student Module has interactive facial characteristics and could create Notes by summarizing the output of all roles.  \n(3) Controller makes sure the validity of the input and output content.\n\nIn order to systematically evaluate the reliability of our design of EZYer, we evaluated the generators (Beamer and Notes) of Teacher Module and Student Module using unique large language models. By setting different scoring mechanisms for Beamer and Notes respectively, and scoring them using five different large language models [32, 33], positive evaluation results were obtained, which proved that the generators of EZYer have good application prospects.\n\nTechnological contributions of EZYer:\n\n(1) As a professional and effective teaching tool, it raises the efficiency of teachers' lesson arrangement and the quality of instructional content through the innovative application of AI-generated content, and also guarantees that teachers in any technological background are able to make artistic education materials and devote more energy to teaching itself.  \n(2) Based on interactive learning and personalized summaries, it provides students with diverse learning perspectives to help them understand the knowledge points from various levels and depths, that greatly helps the personalization and efficiency of study.  \n(3) The design of Controller avoids the interference of invalid information, ensures that the input content is always in accordance with the teaching and learning aims, and effectively boosts the stability and dependability of the system.\n\nIn addition to the above technological innovations, EZYer has further made outstanding contributions in terms of educational equity and personalized learning support. (1) It reduces the pressure of teachers in education resource-poor regions on curriculum design and helps the utilization efficiency of educational resources, so promoting a more equitable distribution of instructional resources. (2) It can significantly enhance the efficiency and quality of education with the student public in underdeveloped areas. (3) EZYer breaks the geographic limitations and is able to be regionally adjusted according to the educational needs of different nations and regions, so that it can serve the worldwide users. This combination of globalization and localization will supply powerful support for educators all around the world.\n\n# 2 EZYER\n\n# 2.1 Teacher Module\n\nIn order to help our users own a better experience when generating their ideal Beamer, EZYer sets up a framework to exchange the data flow, and make sure there is a clear division of responsibilities. Upon different stages, different work there is.\n\nThe first work in Teacher Module is the enter content, to input and upload PDF/Word documents. Secondly, chapters can be split well enough in a clear way when procession, and EZYer will detect whether the content is already recorded in Text Corpus. If the counterparts can be matched, EZYer will use Text Corpus to generate content. On the other hand, EZYer will call DeepSeek API for the generation of teaching materials and exercises. Moreover, having pictures, clear type setting, and correct math formula as the essential parts of a presentation can be extremely important and indispensable. That is why the last step of output is matter. Users upload and insert the pictures follow their ideas, then EZYer will escape the providing materials, exercises and pictures into LaTeX, and compile it into Beamer document which is formatted by PDF.\n\nThis clear and complete architecture method defines the roles of each part, from input to processing and output. It ensures a smooth data flow, escaping the original text input and turning it into a final PDF.\n\nSince we have mentioned the three duties of Teacher Module, and simply list part of their functions, we are going to introduce how Teacher Module achieved them in detail and logical words.\n\nThe users first enter EZYer, type the knowledge points or keywords that need to be generated into LaTeX Beamer. Teacher Module uses the multi-modal input stream and paragraph semantic boundary detection to intelligently segment the unstructured raw text into a collection of knowledge point units, and searches for the existence of the knowledge point units in the collection in Text Corpus, and if it is contained in Text Corpus, it will directly called Text Corpus and generates teaching materials and exercises. If it does not exist in Text Corpus, the big model is called to perform a bidirectional transformation: the simplified knowledge point units are expanded into structured teaching materials.\n\nWe designed a set of structured prompt, templating to guide the large language model in generating teaching materials and exercises, and the prompt for the generated materials sections are provided here as examples:\n\n# Prompt\n\n1\n\nTransform the following raw content (which may be very brief) into a detailed, structured academic teaching material in English.\n\nThe generated content must strictly adhere to the high school mathematics curriculum and teaching standards.\n\nPlease provide a comprehensive explanation that includes:\n\n- A clear definition of the topic.  \n- An in-depth explanation covering fundamental concepts.  \n- Mathematical formulations (in LaTeX notation) where applicable.\n\n··\n\nFormat requirements:\n\n-Use Markdown with section headers (#for chapter titles).  \n-Present mathematical formulas in LaTeX notation.  \n-Organize the content using bullet points and paragraphs.  \n- The output must be strictly in English and written in a formal academic tone.\n\n··\n\n}\n\nThe prompt for generating exercises are similar to those for generating instructional materials. Please refer to Appendix A for the whole prompt.\n\nThe use of structured prompts significantly improves the quality of the instructional materials and exercises that generated by the large language model, and strictly ensure the generated mathematical formulas are in LaTeX format. So the users do not have to manually enter complex mathematical formulas, which greatly saves the time and improves the convenience. Finally, the user interface generates formatted Markdown teaching materials and exercises for reading.\n\nOnce this two operations are completed, Teacher Module can receives all the generated teaching materials. Then the user will be able to upload images for insertion into the selected page.\n\nWe designed another set of prompts (turn to Appendix A) to make sure the generated LaTeX code obey the formation of Beamer. So EZYer can handle the image path and insertion logic.\n\nWe transform the Markdown syntax and exercises into LaTeX code, and escape the special characters in the picture path into LaTeX. Then, we return the LaTeX code which can successfully compile on the website. Finally, compile these code into LaTeX Beamer formatted by PDF, so users can download it.\n\nInstead of simply presenting the generated instructional materials and exercises in Beamer directly, we re-partitioned the materials and designed a series of strict prompt for the large language model, so we could generate the content more streamlined and briefly presented in Beamer.\n\nIn order to systematically show the functions and algorithmic logic of Teacher Module, we select the method of formal mathematical model, through a series of mathematical formulas to define the content processing segmentation mechanism, teaching materials and image path escaping, compilation mechanism, LaTeX compilation mechanism, in order to reveal its inner principle and logic:\n\n$$\n\\mathcal {P} (I, \\theta , \\gamma) = \\mathcal {C} \\circ \\mathcal {B} \\left(\\left(\\mathcal {M} \\otimes \\mathcal {E}\\right) \\circ \\mathcal {S} (I), \\theta , \\gamma\\right) \\tag {1}\n$$\n\n![](/uploads/images/8c9e4c29-0445-4eae-a88e-5a1e4f14945e/3eec763f48b4006bb601756ab2b85492a724e9f0c319ead93efe76e6f897a0b0.jpg)  \nFigure 2: The overall framework of EZYer. EZYer consists of three core components: Teacher Module, Student Module, and Controller. Teacher Module generates materials based on the text and questions uploaded by the user, parses them, and then summarizes and generates a beamer that can be used for teaching and learning, according to the generated materials and the inserted images. Based on the generated materials and inserted images, it summarizes and generates a beamer that can be used for teaching, while Student Module matches the user's input with Text Corpus and calls the API of the large language model to realize the interaction of the five roles, and finally can export a high-quality notes with a clear structure and multi-faceted coverage. On the other hand, Controller verifies the user's input and the intellectual output to ensure the accuracy of incoming and transmitted material.\n\nWhere I is the user input,  $\\mathcal{S}$  is defined as the chapter segmentation function, and we set a parallel processing operator  $\\otimes$  to generate teaching materials and exercises in parallel for the content processed by  $\\mathcal{S}$  through the teaching material generation function  $\\mathcal{M}$  and the exercises generation function  $\\mathcal{E}$ . Here we also define  $\\theta$  as the user uploads the picture parameters of the picture, uploaded successfully set  $\\gamma$  used to indicate the picture location parameters, LaTeX Beamer generator function  $\\mathcal{B}$ , respectively,  $\\mathcal{M}$ ,  $\\mathcal{E}$ ,  $\\theta$ ,  $\\gamma$  in the content and parameters of the compilation, and finally through the compiler function  $\\mathcal{C}$ , compiled to PDF format.\n\nIn order to be able to better understand the equation (1), we will decompose the formula, each decomposition of the formula are explained.\n\n$$\n\\mathcal {S} (I) = \\left\\{\\mathcal {C} _ {1}, \\mathcal {C} _ {2}, \\dots , \\mathcal {C} _ {n} \\right\\} \\tag {2}\n$$\n\nEquation (2) uses the  $S$  function to partition the contents of user input I into n sections to facilitate subsequent operations.\n\n$$\n(\\mathcal {M} \\otimes \\mathcal {E}) \\circ \\mathcal {S} (I) =\n$$\n\n$$\n\\left(\\left(\\mathcal {M} _ {1}, \\{\\mathcal {E} _ {1 j} \\}\\right), \\left(\\mathcal {M} _ {2}, \\{\\mathcal {E} _ {2 j} \\}\\right), \\dots , \\left(\\mathcal {M} _ {n}, \\{\\mathcal {E} _ {n j} \\}\\right)\\right) \\tag {3}\n$$\n\nEquation (3) uses  $\\otimes$  to parallelize the content of the segmented chapters to generate instructional materials and practice problems via the  $\\mathcal{M}$  and  $\\mathcal{E}$  functions.\n\n$$\n\\mathcal {B} \\left(\\left\\{\\left(M _ {i}, \\left\\{\\varepsilon_ {i j} \\right\\}\\right) \\right\\}, \\theta , \\gamma\\right) = L \\tag {4}\n$$\n\nEquation (4) mainly integrates the content generated by M function and E-function as well as the  $\\theta, \\gamma$  of user uploaded images into LaTeX Beamer through  $\\mathcal{B}$  function.\n\n$$\n\\mathcal {C} (L) = P \\tag {5}\n$$\n\nFinally, Equation (5) compiles the integrated LaTeX Beamer to PDF using the  $\\mathcal{C}$  function.\n\nThe whole process fully considered the elements required for presentation, such as images, typography, mathematical formulas,\n\naccuracy and professionalism. To meet the needs of teaching scenarios in all aspects, especially at the end of the generation of Beamer in LaTeX format, EZYer allows users to get a more standardized and academic presentation, which is one of the main purposes of our design of EZYer.\n\n# 2.2 Student Module\n\nIn EZYer, we suppose an interaction framework based on the role division of labor. In order to realistically simulate the interaction behaviors in the classroom, we designed five roles and carefully designed the prompt for each of the role, including Teacher, Assistant, Top Student, Struggling Student, and Note Taker.\n\nSpecifically, we selected a recursive and cumulative functional relationship to describe the interaction between the following roles: Teacher first generates the content, Assistant adds to it, Top Student deepens the content, Struggling Student raises the error-prone points, and Note Taker summarizes all the content and generates Notes. This process can be expressed as the following recursive cumulative formula:\n\n$$\nT = f _ {0} \\left(I _ {0}\\right) \\tag {6}\n$$\n\n$$\nA = f _ {1} \\left(T, I _ {1}\\right) \\tag {7}\n$$\n\n$$\nT S = f _ {2} (T + A, I _ {2}) \\tag {8}\n$$\n\n$$\nS S = f _ {3} (T + A + T S, I _ {3}) \\tag {9}\n$$\n\n$$\nN T = f _ {4} (T + A + T S + S S, I _ {4}) \\tag {10}\n$$\n\nWhere, T is the output of Teacher, A is the output of Assistant, TS is the output of Student, SS is the output of Struggling Student, and NT is the Note Taker's notes summarizing the conversation of the previous four roles. The output of each role expands on the output of all previous roles to generate more comprehensive and richer learning content.\n\nThe design of the role is shown in Figure 3:\n\n![](/uploads/images/8c9e4c29-0445-4eae-a88e-5a1e4f14945e/99de05a8b5494748641f7a84afc018ed7d7ecb19f2d2817ec39b01a5baab1615.jpg)  \nFigure 3: The \"ID card\" for each role. Each \"ID card\" contains the Name, Function and Prompt of the character\n\nTeacher: Focuses on a systematic explanation of math concepts, presenting core knowledge points in a concise, clear and logical manner. Responds in a straightforward style and encourages students to explore further.\n\nAssistant: Builds on Teacher's explanations and provides additional details to help students strengthen their understanding. Responses are strictly centered on the core of Teacher explanation. Top Student: Extends Teacher and Assistant explanations by asking more deeper questions. Top Student not only asks more complex questions based on Teacher and Assistant feedback, but also guides other students to think deeply.\n\nStruggling Student: Struggling Student plays the role of a typical error-prone student in the class, providing feedback on common mistakes and difficulties in learning. The input of Struggling Student is based on the output of the previous roles, and reinforces the correct knowledge points through reverse thinking.\n\nNote Taker: Note Taker is responsible for summarizing the main points of classroom discussions and generating summary notes in an academic format. Note Taker summarizes the interactions of the other roles and generates concise and polished academic notes for the students.\n\nAn example of the role prompt is provided here:\n\n# Prompt\n\n```txt\nTeacher\n```\n\nRole(\"Teacher\", \"Teacher\", \"[Role Description] You are a teacher, a virtual AI instructor who specializes in teaching math to ordinary high schools.\\n[Behavior] When students ask questions, you provide concise and clear answers and encourage them to continue learning, and when users ask questions, you should explain the concept.\")\n\n}\n\nPlease refer to Appendix B respectively for the whole prompt.\n\nIn order to enhance the realism of EZYer, the behaviors and interactions of both the teacher role and the student role have been carefully designed. This approach is not limited to simulating a single teaching process, but explains and summarizes knowledge points from multiple dimensions.\n\nWhen the user enters the question, the keywords are first matched in Text Corpus, and if it is match successfully, Teacher takes the leading role in responding the question which is posed and based on users' own prompt and the information in Text Corpus. Teacher teaches the subject in the classroom to help the students set up a solid academic foundation. Therefore, Teacher output relies heavily on the definitions and standard content of Text Corpus, which usually includes basic conceptual explanations, definitions, examples and so on. So EZYer can make sure that students have an initial understanding of the problem and encourage them keep on learning. If the match fails, the current module will calls DeepSeek API interface to generate a response based on the context of the question itself and the default template set within the program.\n\nAssistant follows the answer of Teacher with additions and extensions content. To help students understand the content deeply. Assistant provides more specific details, examples, or additional explanations based on the answer of Teacher and related concepts in Text Corpus. It allows students to build on their initial understanding and gain more additional knowledge.\n\nThis is followed by Top Student response, a role set up to push students to think further. Top Student will not only rely on the responses of Teacher and Assistant, but will also generate deeper thinking based on the relevant content in Text Corpus, which will inspire the student set up a solid understanding of the concept.\n\nThen Struggling Student will bring up common student misconceptions or misinterpretations of knowledge points based on the content generated by Teacher, Assistant, and Top Student, thinking critically, asking counter-examples or questions to help other students correct their misunderstandings, and draw their attention to possible misconceptions.\n\nFinally, Note Taker, acts as a diligent student in the classroom, listening attentively and organizing notes and formulas. Note Taker does not make any statements, but only organizes the results of the interactions of the other four roles. Note Taker retains the useful information from the conversations of the other four roles, filters Markdown formatting, and generates a well-structured, well-organized Notes document which is following the rules of LaTeX compliant syntax specification.\n\nThis well-designed role interaction, by simulating the real classroom environment, makes the learning experience more dimensional to our real world. Not only to experience the multidimensional knowledge points explained, but also to generate a high-quality PDF format notes at the end.\n\n# 2.3 Controller\n\nIn EZYer, the Controller plays a special role in managing the requests from users, invoking the services, and handling the entire process, all along the process of input to the final output. Benefit from the efficient operation of Controller, EZYer can make sure that each link from the original text to the final generated teaching material, meets the predefined teaching goals and academic standards. Obviously, content review is the core to guarantee the operation of all the key functions mentioned above, so we set up an inspecting mechanism to ensure that the output of each link meets the academic standards and pedagogical appropriateness by reviewing the content in multiple dimensions, standards and pedagogical appropriateness. It consists of four systems: keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system.\n\nKeyword Filtering System. Controller first performs a preliminary check of the input content through the built-in keyword filtering mechanism. It detects whether the content contains valid keywords (e.g., “function”, “probability”, etc.) or disabled keywords (e.g., “differential equation”, “linear algebra”, etc.) in real time through regular expressions. The presence of valid keywords insure the content conforms to the high school mathematics syllabus. Meanwhile, disabled keywords do well in filter out those content which is not appropriate for high school education. This filtering mechanism is the basic content review step that guarantees the given topics and difficulty levels of the generated content are as expected.\n\nContent scoring system. After completing the basic keyword filtering, Controller will further calls DeepSeek API to assess the quality of the content through the content scoring system. The scoring system based on a scale of 1-5, and the evaluation of dimensions include logical coherence, pedagogical suitability and content relevance. The system focuses on checking whether the generated content meets the requirements of the high school mathematics curriculum standards. The scoring system supplies Controller with an automated way of controlling the quality of the content, ensuring that each generation is not only linguistically standardized, but also pedagogically appropriate.\n\nExamples of prompts for the scoring system are provided here: Prompt\n\n1\n\nYou are a virtual AI education assistant. Evaluate the following response based on the content provided:\n\n{reply_text}\n\nPlease rate the response from 1 to 5:\n\n1: Totally illogical or does not align with high school math curriculum.  \n2: Incoherent or acknowledging the response is part of a game.\n\n3: Not ideal but acceptable, contains irrelevant content.  \n4: Generally appropriate, contains minor awkwardness.  \n5: Perfectly appropriate, fits well with the context and educational goals of high school math.\n\nPlease provide a score with a brief reason.\n\n3\n\nRole Collaboration Validation System. Once the content passed the scoring system, Controller will enters the role validation phase. This is where Student Module defines four roles that can speak: Teacher, Teaching Assistant, Top Student, and Struggling Student, each of which is responsible for interacting with and validating the generated content from different perspectives. The output of each role is expanded based on the content of all previous roles: from the explanation of basic concepts, to the validation of in-depth thinking, to the reverse checking of error-prone points, each of them adds validation and depth to the final generated academic material. All people's responses are collected and reviewed as a whole by Controller. When the output score of any role falls below the score 3, Controller will automatically trigger the content correction process, requiring the re-generation of content that meets the criteria.\n\nDynamic Content Correction System. If content violations (such as low content score or keyword violation) are found during content scoring or role co-verification, Controller will automatically trigger dynamic content correction. For keyword violations, the system will return the specific offending terms and provide modification suggestions: if the content score is too low, API will be re-called to generate compliant content. For structural issues, Controller will analyze LaTeX compilation logs and make the necessary formatting corrections. This system ensures that content is automatically optimized and adjusted at every stage, ultimately ensuring that the generated teaching materials meet high academic standards.\n\n# 3 EVALUATION\n\nIn this section, we evaluate the generation from users (Beamer and Notes) in processing of using EZYer, and to explore the potential of EZYer. The empowered by the large language model, shows in terms of the generative agent simulating the behaviors of high school teachers and students in a real teaching environment. For this purpose, we set up a specific scoring mechanism for evaluating the quality of its generated Beamer and Notes. The evaluation process will be accomplished by evaluating multiple materials that generated by several large language models for EZYer, for which it was decided to use five dimensions for a comprehensive evaluation of the generated documents: content accuracy, knowledge coverage, usability, formatting correctness, and visual design and appeal.\n\n# 3.1 Scoring mechanism\n\nIn order to ensure that Beamer and Notes can be evaluated in a consistent way, we have developed a comprehensive scoring mechanism. The scoring mechanism designed a scale from 0 to 5, with 5 being the highest, and the model will give a score between\n\n0 and 5 according to the evaluation criteria, with two decimal places. Detailed scoring descriptions are shown in Table 1 and Table 2 (turn to Appendix C).\n\nFor the Beamer files generated by EZYer, content accuracy is primarily evaluated based on whether the generated text contains conceptual errors or reasoning flaws. Rigorous knowledge expression and clear logical structure are important factors in determining the evaluation. Knowledge coverage focuses on the key instructional elements, which is required for teaching, including definitions, formulas, examples and applications. If the content is comprehensive and well-structured, it will receive a higher score. Usability evaluates whether the teachers can quickly understand and directly apply the material in instructional exercises. If the language is standardized, the structure is coherent and the instructional orientation is clear, the score will be higher. Formatting correctness refers to the technical performance of the generated file in LaTeX environment. Syntactic accuracy, structural completeness and stable comparability are the main evaluation criteria. Visual design and appeal are also important indicators for assessing Beamer outputs. Coordinated color schemes, clearly segmented content and a professional overall style contribute to higher evaluation results.\n\nFor the Notes generated by EZYer, content accuracy focuses on whether the notes accurately reflect the effective information from the instructional dialogue. If the statements are rigorous and conceptually correct, the score will be higher. Knowledge coverage evaluates whether the notes fully include the key concepts and logical structure. If the components are complete and the content is well organized, the evaluation score will be higher. Usability emphasizes that the Notes are concise, clear and logically structured. If they enable students to understand and review efficiently, they will receive a higher score. Formatting correctness refers to whether the notes comply with LaTeX standards and exhibit clear structure and capably compiling. If the layout is standardized and there are no significant technical issues, the Notes will be rated favorably. Visual design and appeal consider whether the Notes are visually neat and aesthetically structured. If the sections are clearly defined, the layout is well balanced and the Notes are easy to read, this indicates strong learner-friendliness and professionalism, and will lead to a higher evaluation.\n\n# 3.2 Evaluation by Large Language Model\n\nThe large language model demonstrate varying strengths and limitations in specific tasks, with each model representing a distinct \"individual\" with unique backgrounds, capabilities, and expertise. In the preliminary phase of the large language model evaluation, 100 Beamer and Notes documents are generated based on various knowledge points from EZYer, and these documents are then incorporated into multiple large language models for the purposes of evaluation and testing. The evaluation process for large language models is to be conducted in strict accordance with the established scoring mechanism, with the objective of determining the evaluation value of the documents. The specific grand model assessment is demonstrated in (turn to Appendix D).\n\n![](/uploads/images/8c9e4c29-0445-4eae-a88e-5a1e4f14945e/a02087bc4c93cd3dae0aaaa9c196c7507dbf6932479cd4eefcb20004a666c26f.jpg)  \nFigure 4: Radar Chart for Evaluation Results of Large Language Models\n\nFigure 4 shows two radar charts evaluating the quality of Beamer and Notes documents generated using EZYer for five large language models (LLMs). Combined with the data on the radar charts, Beamer and Notes have a better perform on the dimensions of Content Accuracy and Knowledge Coverage (average score of 4.74 for Beamer and 4.70 for Notes), indicating that the generated products are content-rigorous and can be successfully used in high school classrooms. Formatting correctness also scored high in Beamer (mean score of 4.35), which highly recognizes the escape stability of LaTeX technical structure. There is still space for optimization in the dimensions \"Usability\" and \"Visual Design and Attractiveness\" (average score as low as 4.1). Based on the evaluation results of the large language model evaluation, we confirmed that the Beamer and Notes files generated by EZYer own a high quality, and the positive evaluation results validated the reliability of the generative intelligences applied to high school teachers and students.\n\n# 4 LIMITATIONS AND FUTURE WORK\n\nAlthough EZYer provides a very promising research direction in intelligently generating LaTeX Beamer and Notes, we still found potential limitations and challenges of EZYer, which need to be further studied and explored.\n\nRestricted Applicable Scenarios. EZYer currently only supports receiving and generating content related to high school mathematics. Because we set up a content review mechanism with features and corpus content related to high school mathematics. That makes it less adaptable to other countries and regions. Therefore, its expansion to other disciplines and educational stages requires extensive modifications. In the future, we will enhance the functionality of the content review mechanism and enrich the content in Text Corpus to compensate for the shortcomings in the applicable scenarios.\n\nGeneration speed/efficiency constraints. EZYer relies on the large language model API to generate teaching materials, exercises, compile LaTeX Beamer to conduct conversations and organize notes. However, calling the large language model API to generate and compile the content takes a certain amount of time. This is not fast enough. Most users always want to see results in a short period of time, otherwise they will easily lose interest and patience. In the future, we will look for effective ways to reduce the time when call the large language model API to generate content.\n\nLack of manual evaluation. When evaluating Beamer and Notes generated by EZYer, we only use the large language model as our evaluation method. But lack of manual evaluation. So part of the large language model might fail to recognize the escaped mathematical formulas correctly during the evaluation process due to their own shortcomings, resulting in a gap between the evaluation results and the manual evaluation results. Therefore, it is necessary to find some teachers and students who can actually use EZYer for assessment in the future.\n\n# REFERENCES\n\n[1] S. Aslam, Lim Mei Yen, and Shorouk Aboudahr, \"Influential Factors on Students' Academic Performance: The Impact of PowerPoint Presentations in Primary Public Schools, Sarawak, Malaysia,\" vol. 16, no. 38, pp. 3294-3302, Oct. 2023, doi: https://doi.org/10.17485/jjst/v16i38.1476.  \n[2] R. S. Jansen, D. Lakens, and W. A. IJsselsteijn, “An Integrative Review of the Cognitive Costs and Benefits of note-taking,” Educational Research Review, vol. 22, no. 22, pp. 223–233, Nov. 2017, doi: https://doi.org/10.1016/j.edurev.2017.10.001.  \n[3] E. Wang, B. Chen, M. Chowdhury, A. Kannan, and F. Liang, \"FLINT: A Platform for Federated Learning Integration,\" Proceedings of Machine Learning and Systems, vol. 5, Mar. 2023, Available: https://proceedings.mlsys.org/paper_files/paper/2023/bitical/0a1603 bfce9502551ad89906515b5941-Abstract-mlsys2023.html  \n[4] Shamini Shetye, \"An Evaluation of Khamigo, a Generative AI Tool, as a Computer-Assisted Language Learning App,\" Studies in Applied Linguistics and TESOL, vol. 24, no. 1, Jul. 2024, doi: https://doi.org/10.52214/salt.v24i1.12869.  \n[5] N. Viswanathan, S. Meacham, and F. F. Adedoyin, “Enhancement of online education system by using a multi-agent approach,” Computers and Education: Artificial Intelligence, vol. 3, p. 100057, 2022, doi: https://doi.org/10.1016/j.caeai.2022.100057.\n\n[6] A. Dieker et al., \"Using an Artificial Intelligence (AI) Agent to Support Teacher Instruction and Student Learning,\" Journal of Special Education Preparation, vol. 4, no. 2, pp. 78-88, 2024, Available: https://eric.ed.gov/?id=EJ1440761  \n[7] A. Bozkurt, \"Generative artificial intelligence (AI) powered conversational educational agents: The inevitable paradigm shift,\" Asian Journal of Distance Education, vol. 18, no. 1, Mar. 2023, Available: http://www.asianjde.com/ods/index.php/AsianJDE/article/view/718  \n[8] R. Hidayat, M. Z. bin Mohamed, N. N. binti Suhaizi, N. binti M. Sabri, M. K. H. bin Mahmud, and S. N. binti Baharuddin, \"Artificial intelligence in mathematics education: A systematic literature review,\" International Electronic Journal of Mathematics Education, vol. 17, no. 3, p. em0694, Jun. 2022, doi: https://doi.org/10.29333/iejme/12132.  \n[9] R. M. AlAli and A. A. Al-Barakat, \"Role of Teacher Understanding about Instructional Visual Aids in Developing National and International Student Learning Experiences,\" Journal of International Students, vol. 13, no. 4, pp. 331-354, 2023, Available: https://www.ojed.org/jis/article/view/6576  \n[10] Soegianto Soelistiono and Wahidin, \"Educational Technology Innovation: AIIntegrated Learning System Design in AILS-Based Education,\" Influence, vol. 5, no. 2, pp. 470-480, Aug. 2023, doi: https://doi.org/10.54783/influencejournal.v512.175.  \n[11] R. Hidayat, M. Z. bin Mohamed, N. N. binti Suhaizi, N. binti M. Sabri, M. K. H. bin Mahmud, and S. N. binti Baharuddin, \"Artificial intelligence in mathematics education: A systematic literature review,\" International Electronic Journal of Mathematics Education, vol. 17, no. 3, p. em0694, Jun. 2022, doi: https://doi.org/10.29333/eijme/12132.  \n[12] S. Gökçearslan, C. Tosun, and Z. G. Erdemir, “Benefits, Challenges, and Methods of Artificial Intelligence (AI) Chatbots in Education: A Systematic Literature Review,” International Journal of Technology in Education, vol. 7, no. 1, pp. 19–39, 2024, Available: https://eric.ed.gov/?id=EJ1415037  \n[13] J. Jeon and S. Lee, \"Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT,\" Education and Information Technologies, vol. 28, May 2023, doi: https://doi.org/10.1007/s10639-023-11834-1.  \n[14] S. Milano, J. A. McGrane, and S. Leonelli, \"Large language models challenge the future of higher education,\" Nature Machine Intelligence, vol. 5, pp. 1-2, Mar. 2023, doi: https://doi.org/10.1038/s42256-023-00644-2.  \n[15] Iris Cristina Pelaez-Sanchez, D. Velarde-Camaqui, and Leonardo David Glasserman-Morales, \"The impact of large language models on higher education: exploring the connection between AI and Education 4.0,\" Frontiers in Education, vol. 9, Jun. 2024, doi: https://doi.org/10.3389/feduc.2024.1392091.  \n[16] C.Xie, G. Xiong, H. Yang, O. Coleman, M. Kennedy, and A. Zhang, \"Leveraging Grounded Large Language Models to Automate Educational Presentation Generation,\" Proceedings of Machine Learning Research, vol. 1, pp. 1-14, 2024, Accessed: Apr. 21, 2025. [Online]. Available: https://neurips2024edu.github.io/paper_lists/submission25.pdf  \n[17] J. Park et al., \"Generative Agents: Interactive Simulacra of Human Behavior,\" vol. 23, 2023, doi: https://doi.org/10.1145/3586183.3606763.  \n[18] B. Y. Lin et al., \"SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks,\" Advances in Neural Information Processing Systems, vol. 36, pp. 23813-23825, Dec. 2023, Accessed: Apr. 21, 2025. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/2023/bash/4b0eea69deea512c9e2c469187643dc2-Abstract-Conference.html  \n[19] (语料库) L. Anthony, “What can corpus software do?,” Routledge eBooks, pp. 103-125, Jan. 2022, doi: https://doi.org/10.4324/9780367076399-9.  \n[20] T. Crossley, A. Heintz, J. S. Choi, J. Batchelor, M. Karimi, and A. Malatinszky, \"A large-scaled corpus for assessing text readability,\" Behavior Research Methods, Mar. 2022, doi: https://doi.org/10.3758/s13428-022-01802-x  \n[21] (LaTex Beamer) J.J. M. Sepulcre, “Sobre el uso de LaTeX en el ambito docente,” UNión - REVISTA IBEROAMERICANA DE EDUCACION MATEMATICA, vol. 20, no. 71, 2024, Accessed: Apr. 21, 2025. [Online]. Available: https://www.revistaunion.org.fespm.es/index.php/UNION/article/view/1594  \n[22] O.Wang, \"Effects of Different Educational Interaction Modes on Students' Independent Online Learning Ability,\" International Journal of Emerging Technologies in Learning (iJET), vol. 18, no. 18, pp. 76-87, Sep. 2023, doi: https://doi.org/10.3991/ijet.v18i18.42531.  \n[23] X. Xia, \"Interaction recognition and intervention based on context feature fusion of learning behaviors in interactive learning environments,\" Interactive Learning Environments, pp. 1-18, Jan. 2021, doi: https://doi.org/10.1080/10494820.2021.1871632.  \n[24] C.-P. Dai and F. Ke, \"Educational applications of artificial intelligence in simulation-based learning: A systematic mapping review,\" Computers and\n\nEducation: Artificial Intelligence, vol. 3, p. 100087, Jul. 2022, doi: https://doi.org/10.1016/j.caeai.2022.100087.  \n[25] J.P. Hertel and B. J. Millis, Using Simulations to Promote Learning in Higher Education. 2023. doi: https://doi.org/10.4324/9781003448594.  \n[26] A.Shi, Y. Wang, and N. Ding, \"The effect of game-based immersive virtual reality learning environment on learning outcomes: Designing an intrinsic integrated educational game for pre-class learning,\" Interactive Learning Environments, vol. 30, no. 4, pp. 1-14, Oct. 2019, doi: https://doi.org/10.1080/10494820.2019.1681467.  \n[27] N.Aoki, N. Mori, and M. OKada, \"Analysis of LLM-Based Narrative Generation Using the Agent-Based Simulation,\" Dec. 2023, doi: https://doi.org/10.1109/jiai-aai-winter61682.2023.00059.  \n[28] Y.-H. Bae and C. C. Bennett, \"Real-Time Multimodal Turn-taking Prediction to Enhance Cooperative Dialogue during Human-Agent Interaction,\" 2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), pp. 2037-2044, Aug. 2023, doi: https://doi.org/10.1109/ro-man57019.2023.10309569.  \n[29] J.Zhang et al., \"Virtual Triplets: A Mixed Modal Synchronous and Asynchronous Collaboration with Human-Agent Interaction in Virtual Reality,\" pp. 1-8, May 2024, doi: https://doi.org/10.1145/3613905.3650766.  \n[30] T.K. F. Chiu, B. L. Moorhouse, C. S. Chai, and M. Ismailov, “Teacher support and student motivation to learn with Artificial Intelligence (AI) based chatbot,” Interactive Learning Environments, vol. 32, no. 7, pp. 1-17, Feb. 2023, doi: https://doi.org/10.1080/10494820.2023.2172044.  \n[31] L. Yang, \"An 'Interactive Learning Model' to Enhance EFL Students' Lexical Knowledge and Reading Comprehension,\" Sustainability, vol. 15, no. 8, p. 6471, Apr. 2023, doi: https://doi.org/10.3390/su15086471.  \n[32] J. Zhang, K. Bao, Y. Zhang, W. Wang, F. Feng, and X. He, \"Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation,\" Sep. 2023, doi: https://doi.org/10.1145/3604915.3608860.  \n[33] M. Schäfer, S. Nadi, A. Eghbali, and F. Tip, \"An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation,\" IEEE Transactions on Software Engineering, pp. 1-21, 2023, doi: https://doi.org/10.1109/tse.2023.3334955.\n\n# APPENDIX\n\n# Appendix A\n\n# Prompt for the generate teaching materials:\n\nTransform the following raw content (which may be very brief or in Chinese) into a detailed, structured academic teaching material in English.\n\nThe generated content must strictly adhere to the Chinese high school mathematics curriculum and teaching standards.\n\nPlease provide a comprehensive explanation that includes:\n\n- A clear definition of the topic.  \n- An in-depth explanation covering fundamental concepts.\n\n- Multiple sections discussing properties, examples, applications, and advanced topics.\n\n- Mathematical formulations (in LaTeX notation) where applicable.\n\n- A minimum length of 500 words. Please ensure the output is no less than 500 words.\n\nRaw content:\n\n{chapter_content}\n\nFormat requirements:\n\n1. Use Markdown with section headers (#for chapter titles).  \n2. Highlight key terms using **bold**.  \n3. Present mathematical formulas in LaTeX notation.  \n4. Organize the content using bullet points and paragraphs.\n\n5. The output must be strictly in English and written in a formal academic tone.\n\nPrompt for the generate teaching exercises:\n\nBased on the following raw content (which may be very brief or in Chinese), create 3-5 detailed academic exercises in English. Please ensure that each exercise:\n\n- Requires the student to provide detailed explanations or mathematical derivations.\n\n- Includes clear instructions and context.  \n- Is written in a formal academic tone.  \n- If the input is very brief, generate general exercises with sufficient complexity.\n\nRaw content:\n\n{chapter_content}\n\nRequirements:\n\n1. Use numbered list format.  \n2. Ensure the exercises vary in difficulty.  \n3. Do not include the solutions.  \n4. The output must be strictly in English.\n\nPrompt for the generate LaTeX Beamer:\n\n\"Generate LaTeX Beamer code for an academic presentation with the following requirements:\n\nDocument Structure:\n\n{json.dumps(structured_input,indent  $= 2$  ）}\n\nTechnical Specifications:\n\n1. Use the beamer document class with XeLaTeX compilation.  \n2. Implement automatic special character escaping.  \n3. Ensure each chapter has a section header, and each section has multiple content frames, including bullet lists and enumerations.  \n4. Add one frame for each exercise.  \n5. Mathematical formulas should be formatted with LaTeX.  \n6. Make use of a professional title page.  \n7. Insert an image at the specified position if provided.  \n8. Output valid LaTeX code without comments or explanations.  \n9.Each chapter must contain at least one \\\\\\\\begin{frame}\\}...\\end{frame}\\}' framework.  \n10.Each framework must use '\\\\frametitle{\\{...\\}}' to define the title.\n\n# Appendix B\n\n# Prompt for roles:\n\n[\n\nTeacher\n\nRole(\"Teacher\", \"Teacher\", \"[Role Description] You are a teacher, a virtual AI instructor who specializes in teaching math to ordinary high schools.\\n[Behavior] When students ask questions, you provide concise and clear answers and encourage them to continue learning, and when users ask questions, you should explain the concept.\")\n\nAssistant\n\nRole(\"Assistant\", \"Assistant\", \"[Role Description]As a virtual classroom teaching assistant, your main role is to provide accurate\n\ninformation on the content of ordinary high school mathematics, based on the Teacher's speech, to help students deepen their understanding of the course content. You will choose when to speak very carefully, ensuring that your supplementary material and questions are helpful and appropriate, and do not repeat the teacher's lecture or unnecessarily interrupt the course flow. Your goal is to improve classroom interaction and learning efficiency through concise and accurate contributions while maintaining a friendly and encouraging tone.\"\n\nTop Student\n\nRole(\"Top Student\", \"Top Student\", \"[Role Description]You are a Student nicknamed Top Student who provides perspectives including some quality problems in regular high school math, helping to understand depth concepts. The content of the speech must be on the basis of Teacher and Assistant to carry on a deeper level of thinking and speech.\\n[Behavior] When it is your turn to speak, you are designed to express an opinion on the class material, providing an opinion that includes some quality questions and helps to understand in-depth concepts. Your goal is to enrich class conversation with a combination of accuracy and fun, avoid off-topic comments, and ensure that contributions are relevant to the course focus. You engage with class topics creatively and with rigorous logic while keeping the topic the same.\")\n\nStruggling Student\n\nRole(\"Struggling Student\", \"Struggling Student\", \"[Role Description]You are a Struggling Student who is struggling to understand the content in a short time and is asking typical wrong questions. I can give you some examples of mistakes as counterexamples.\\n[Behavior] Your goal is to analyze the teaching content and come up with relevant and constructive counter-examples or problems. If you need more background or explanation, please feel free to ask. Counterexamples or questions should be appropriate and ensure content security. Present counterexamples or problems in the context of critical thinking.\")\n\nNote Taker\n\nRole(\"Note Taker\", \"Note Taker\", \"[Role Description] Note Taker is a diligent student, you listen to conversations in class and extract key information to create concise notes and formulas. You need to summarize the dialogue content of all the characters above to generate a summary of this knowledge point.\\n[Behavior] The notes are brief, presented in a friendly, student-like tone, and appear to be shared with classmates. Notes emphasize quality and brevity, remove unnecessary information, focus only on key points, and exclude lessons and teacher introductions.\")\n\n]\n\nTable 1: Beamer File Quality Evaluation Table  \n\n<table><tr><td></td><td>0-1</td><td>1-2</td><td>2-3</td><td>3-4</td><td>4-5</td></tr><tr><td>Content Accuracy</td><td>Misleading</td><td>Partially Correct</td><td>Generally Correct</td><td>Mostly Accurate</td><td>Fully Accurate</td></tr><tr><td>Knowledge Coverage</td><td>Minimal Coverage</td><td>Incomplete Content</td><td>Basic Coverage</td><td>Comprehensive</td><td>Full Coverage</td></tr><tr><td>Usability</td><td>Fragmented</td><td>Hard to Follow</td><td>Clear Enough</td><td>Easy to Understand</td><td>Highly Professional</td></tr><tr><td>Formatting Correctness</td><td>Major Errors</td><td>Format Issues</td><td>Minor Issues</td><td>Well-Formatted</td><td>Perfect Format</td></tr><tr><td>Visual Design and Appeal</td><td>Poorly Designed</td><td>Unbalanced Layout</td><td>Acceptable Visuals</td><td>Neat and Consistent</td><td>Aesthetic &amp; Engaging</td></tr></table>\n\nTable 2: Notes File Quality Evaluation Table  \n\n<table><tr><td></td><td>0-1</td><td>1-2</td><td>2-3</td><td>3-4</td><td>4-5</td></tr><tr><td>Content Accuracy</td><td>Vague or Wrong</td><td>Some Errors</td><td>Mostly Correct</td><td>Minor Inaccuracy</td><td>Fully Accurate</td></tr><tr><td>Knowledge Coverage</td><td>Sparse Notes</td><td>Partial Concepts</td><td>Basic Key Points</td><td>Broadly Covered</td><td>Fully Covered</td></tr><tr><td>Usability</td><td>Disordered Notes</td><td>Hard to Review</td><td>Readable Structure</td><td>Clear and Concise</td><td>Logical and Helpful</td></tr><tr><td>Formatting Correctness</td><td>Major Issues</td><td>Inconsistent Style</td><td>Mostly Correct Format</td><td>Properly Structured</td><td>Fully Standardized</td></tr><tr><td>Visual Design and Appeal</td><td>Disorganized Style</td><td>Unclear Sections</td><td>Clean but Plain</td><td>Structured &amp; Balanced</td><td>Elegant &amp; Readable</td></tr></table>\n\n# Appendix D\n\nTable 3: Evaluation Results of Beamer Generated by Large Language Model  \n\n<table><tr><td></td><td>ChatGPT-o1</td><td>Claude 3.5 Sonnet</td><td>Gemini-2.0-Pro</td><td>Qwen2.5-Max</td><td>GLM-4-Plus</td></tr><tr><td>Content Accuracy</td><td>4.84</td><td>4.84</td><td>4.74</td><td>4.71</td><td>4.56</td></tr><tr><td>Knowledge Coverage</td><td>4.76</td><td>4.76</td><td>4.75</td><td>4.46</td><td>4.25</td></tr><tr><td>Usability</td><td>4.65</td><td>4.69</td><td>4.59</td><td>3.75</td><td>3.97</td></tr><tr><td>Formatting Correctness</td><td>4.83</td><td>4.74</td><td>4.47</td><td>3.29</td><td>4.41</td></tr><tr><td>Visual Design and Appeal</td><td>4.54</td><td>4.61</td><td>4.48</td><td>3.04</td><td>3.84</td></tr></table>\n\nTable 4: Evaluation Results of Notes Generated by Large Language Model  \n\n<table><tr><td></td><td>ChatGPT-o1</td><td>Claude 3.5 Sonnet</td><td>Gemini-2.0-Pro</td><td>Qwen2.5-Max</td><td>GLM-4-Plus</td></tr><tr><td>Content Accuracy</td><td>4.56</td><td>4.87</td><td>4.51</td><td>4.87</td><td>4.68</td></tr><tr><td>Knowledge Coverage</td><td>4.53</td><td>4.81</td><td>4.73</td><td>4.48</td><td>4.51</td></tr><tr><td>Usability</td><td>4.30</td><td>4.75</td><td>4.33</td><td>4.18</td><td>4.4</td></tr><tr><td>Formatting Correctness</td><td>4.02</td><td>4.65</td><td>4.17</td><td>3.70</td><td>4.53</td></tr><tr><td>Visual Design and Appeal</td><td>3.90</td><td>4.58</td><td>4.36</td><td>3.41</td><td>4.21</td></tr></table>",
    "arxiv_id": "2512.02561",
    "error_message": null,
    "embedding": [
      2.515625,
      0.75,
      0.2734375,
      -3.640625,
      -0.97265625,
      1.859375,
      -1.171875,
      -2.71875,
      1.96875,
      1.2265625,
      0.4375,
      3.875,
      3.109375,
      3.671875,
      0.09375,
      1.609375,
      -0.08837890625,
      1.4609375,
      0.11181640625,
      -5.125,
      -0.6328125,
      5.03125,
      1.3046875,
      -6.21875,
      3.921875,
      -2.734375,
      2.296875,
      2.8125,
      3.34375,
      -0.88671875,
      5.9375,
      -3.984375,
      -0.77734375,
      -0.99609375,
      -3.5625,
      3.59375,
      -2.765625,
      -0.609375,
      4.65625,
      5.40625,
      -4.09375,
      0.515625,
      0.2236328125,
      4,
      -2.75,
      3.578125,
      1.515625,
      -0.80078125,
      -3.21875,
      0.1513671875,
      -5.78125,
      -4.09375,
      6.78125,
      3.46875,
      4.5625,
      -2.546875,
      -6.40625,
      6.59375,
      -5.5625,
      -1.484375,
      1.4296875,
      0.197265625,
      3.609375,
      0.68359375,
      2.78125,
      3.953125,
      4.28125,
      1.6953125,
      -1.0546875,
      0.015869140625,
      1.4140625,
      1.0859375,
      6.40625,
      -3.46875,
      7.25,
      7.3125,
      4.90625,
      2,
      -1.453125,
      4.65625,
      -7.125,
      1.75,
      4.6875,
      -3.15625,
      2.78125,
      4.0625,
      0.09521484375,
      -3.265625,
      -4.3125,
      2.5625,
      -2.21875,
      1.2890625,
      -2.828125,
      -2.546875,
      1.078125,
      5.65625,
      -0.271484375,
      -2.65625,
      -10.25,
      4.40625,
      0.2001953125,
      -0.515625,
      -0.3515625,
      -6.5,
      -1.421875,
      -0.796875,
      -2.796875,
      -6.875,
      -3.265625,
      -3.78125,
      -0.51171875,
      1.2578125,
      0.9765625,
      -4.3125,
      -0.40625,
      -1.1796875,
      -0.8359375,
      -2.921875,
      -7.3125,
      -1.7421875,
      -0.30078125,
      -1.8515625,
      -1.9921875,
      0.80859375,
      5.3125,
      3.25,
      -4.75,
      4.03125,
      4.09375,
      -1.171875,
      6.21875,
      -0.349609375,
      3.734375,
      -1.6328125,
      -7.625,
      -0.291015625,
      -4.53125,
      2.0625,
      4.40625,
      6.25,
      -3.09375,
      -0.1728515625,
      -0.294921875,
      -4.59375,
      -0.796875,
      0.97265625,
      -9.6875,
      -0.1689453125,
      2.6875,
      -3.96875,
      1.5546875,
      0.0137939453125,
      3.234375,
      4.78125,
      -0.59765625,
      -2.6875,
      2.6875,
      0.81640625,
      -1.328125,
      -0.1904296875,
      -0.62890625,
      3.265625,
      -1.0078125,
      -0.236328125,
      -1.2421875,
      -4.25,
      -4.84375,
      2.71875,
      1.765625,
      -1.96875,
      -1.203125,
      14.6875,
      2.796875,
      -2.8125,
      2.40625,
      3.796875,
      -0.34375,
      6.53125,
      2.140625,
      2.75,
      0.921875,
      0.9140625,
      -1.6015625,
      4.34375,
      -2.578125,
      0.78125,
      3.65625,
      -1.90625,
      1.6171875,
      -2.328125,
      -0.66796875,
      2.3125,
      5.1875,
      1.8203125,
      -4.15625,
      -1.203125,
      2.515625,
      -0.265625,
      -1.7890625,
      3.03125,
      0.330078125,
      -7.375,
      0.22265625,
      -1.7734375,
      -2.296875,
      -1.3828125,
      4.78125,
      -1.4375,
      1.296875,
      -4.40625,
      -0.8359375,
      5.375,
      0.62109375,
      -0.2109375,
      7.53125,
      2.5,
      3.953125,
      -2.453125,
      4.5,
      -0.0771484375,
      3.953125,
      4.0625,
      2.34375,
      1.8203125,
      -1.6875,
      1.953125,
      2.875,
      5.125,
      0.76953125,
      4.96875,
      -0.0125732421875,
      1.7734375,
      2.875,
      0.007080078125,
      -4.0625,
      -4.5,
      -2.125,
      1.96875,
      -4.34375,
      0.283203125,
      -2.71875,
      -1.671875,
      1.5859375,
      -0.8359375,
      -0.251953125,
      -0.12158203125,
      -3.78125,
      -3.5625,
      -1.7578125,
      -4.96875,
      2.265625,
      2.234375,
      -5.09375,
      -2.53125,
      1.953125,
      3.828125,
      -0.353515625,
      -0.181640625,
      0.50390625,
      -3.6875,
      5.34375,
      -3.078125,
      -6.125,
      3.84375,
      2.984375,
      -5.15625,
      5.1875,
      1.1796875,
      4.1875,
      -0.177734375,
      -0.2421875,
      -0.5,
      -1.5859375,
      1.40625,
      -1.9453125,
      5,
      -0.63671875,
      -5.53125,
      2.78125,
      -1.8984375,
      -6.15625,
      -8.4375,
      6.25,
      -5.125,
      4.09375,
      -1.671875,
      0.640625,
      4.4375,
      -0.5625,
      11.125,
      7.3125,
      -0.07470703125,
      0.65234375,
      0.66796875,
      -4.21875,
      0.9375,
      -2.25,
      0.0791015625,
      -5.84375,
      -2.546875,
      2.453125,
      -0.80859375,
      -1.3828125,
      -0.01312255859375,
      -2.984375,
      3.21875,
      1.9921875,
      -4.6875,
      0.7109375,
      1.734375,
      1.234375,
      -0.244140625,
      5.46875,
      0.6171875,
      4.34375,
      -4.6875,
      -4.03125,
      1.515625,
      0.77734375,
      -5.59375,
      -4.6875,
      -2.0625,
      -1.7734375,
      -3.875,
      -3.15625,
      -4.78125,
      0.8671875,
      -0.10009765625,
      1.734375,
      -1.4765625,
      2.234375,
      -0.8125,
      -4.4375,
      -11.6875,
      6.28125,
      -4.28125,
      3.171875,
      2.8125,
      -1.09375,
      3.609375,
      -0.06884765625,
      -1.40625,
      4.78125,
      0.322265625,
      -1.3046875,
      1.4375,
      5.9375,
      -2.21875,
      0.48828125,
      -5.96875,
      5.625,
      3.671875,
      2.953125,
      2.40625,
      6.3125,
      -1.6328125,
      0.126953125,
      -0.8203125,
      2.875,
      0.8828125,
      1.4140625,
      -3.953125,
      6.34375,
      0.72265625,
      -1.890625,
      -3.578125,
      -0.08837890625,
      4.21875,
      -2.21875,
      -3.546875,
      -0.6484375,
      -3.140625,
      1.109375,
      -0.7890625,
      1.9765625,
      0.3125,
      1.21875,
      -3.96875,
      -4.28125,
      0.953125,
      -1.4296875,
      2.421875,
      -0.0269775390625,
      -0.25390625,
      2.359375,
      4.375,
      1.21875,
      2.484375,
      3.546875,
      -3.25,
      -2.953125,
      -0.05615234375,
      -2.453125,
      3.578125,
      2.984375,
      2.34375,
      0.2119140625,
      3.125,
      0.451171875,
      -1.203125,
      1.2109375,
      1.0234375,
      -2.46875,
      -0.9453125,
      -4.6875,
      2.0625,
      -0.39453125,
      -10,
      0.294921875,
      -1.125,
      0.58203125,
      0.9296875,
      2.453125,
      0.5546875,
      -0.1318359375,
      5.21875,
      -1.890625,
      1.9609375,
      -2.359375,
      -1.5234375,
      -4.84375,
      -0.51171875,
      0.041015625,
      -2.21875,
      -1.71875,
      0.58203125,
      1.921875,
      5.75,
      4.40625,
      1.3984375,
      1.9765625,
      2.984375,
      -3.171875,
      4.46875,
      -2.546875,
      -7.15625,
      1.0625,
      -4.5,
      1.015625,
      0.328125,
      2.75,
      0.37109375,
      3.984375,
      3.734375,
      -3.796875,
      -3.515625,
      3.640625,
      1.453125,
      -3.3125,
      -1.046875,
      1.53125,
      -0.66796875,
      1.015625,
      -0.9453125,
      3.09375,
      0.88671875,
      -4.40625,
      2.75,
      4.125,
      0.3828125,
      0.3671875,
      -4.5625,
      -1.296875,
      1.8671875,
      1.078125,
      -0.244140625,
      -0.8984375,
      3.859375,
      2.5625,
      -4.5625,
      -8.9375,
      5.8125,
      0.9609375,
      -2.21875,
      -1.140625,
      3.453125,
      1.078125,
      0.69921875,
      -7.3125,
      -4.15625,
      -1.25,
      -0.7890625,
      2.6875,
      0.84375,
      -0.95703125,
      -4.40625,
      -4.65625,
      4.5625,
      1.6640625,
      4.90625,
      -0.40625,
      -0.5625,
      3.140625,
      -2.53125,
      4.75,
      1.3515625,
      6.65625,
      -4.9375,
      1.1484375,
      -0.2333984375,
      -8.8125,
      0.8984375,
      -1.5546875,
      0.90625,
      2.703125,
      1.203125,
      0.8125,
      -3.328125,
      -2.421875,
      -0.10205078125,
      5.90625,
      1.1171875,
      -0.9453125,
      2.09375,
      -5,
      -1.9453125,
      3.359375,
      -0.049560546875,
      1.8359375,
      -0.85546875,
      -2.203125,
      4.125,
      -1.765625,
      0.78125,
      -2.15625,
      -3.40625,
      0.55859375,
      -4.96875,
      0.16796875,
      3.828125,
      -2.1875,
      2.609375,
      -1.0546875,
      -4.09375,
      -4.1875,
      -1.3046875,
      -1.3203125,
      -3.734375,
      -1.1875,
      1.3203125,
      3.53125,
      3.15625,
      -2.140625,
      -0.447265625,
      -1.859375,
      2.984375,
      -3.546875,
      1.1875,
      0.875,
      2.21875,
      0.392578125,
      2.296875,
      -5.71875,
      -1.8828125,
      -0.412109375,
      -2.3125,
      -3.203125,
      -2.234375,
      2.140625,
      -1.03125,
      -1.0703125,
      -2.765625,
      0.2412109375,
      1.265625,
      0.9140625,
      -0.396484375,
      3.265625,
      5.125,
      0.12890625,
      -1.8046875,
      0.8828125,
      4.46875,
      -2.671875,
      0.8828125,
      3.015625,
      1.1015625,
      -4.875,
      -5.46875,
      -2.25,
      1.703125,
      4.5625,
      -1.7890625,
      -0.146484375,
      -2.046875,
      3.578125,
      -0.57421875,
      3.15625,
      -14.25,
      2.484375,
      0.1162109375,
      -4.5,
      -0.6640625,
      -1.890625,
      2.125,
      -0.4296875,
      4.75,
      0.74609375,
      -1.0078125,
      1.234375,
      9.9375,
      -1.0625,
      -1.9296875,
      4.8125,
      1.0078125,
      -2.78125,
      2.078125,
      -0.734375,
      -3.625,
      0.7109375,
      1.4765625,
      -0.04248046875,
      -0.796875,
      3.140625,
      -2.484375,
      -0.27734375,
      4.1875,
      -4.75,
      -1.84375,
      3.546875,
      -0.671875,
      -1.375,
      0.435546875,
      -3.46875,
      1.453125,
      -3.71875,
      1.4375,
      1.4921875,
      -3.484375,
      0.25,
      3.296875,
      -2.546875,
      -2.96875,
      -0.283203125,
      -0.63671875,
      3.953125,
      2.859375,
      -4.09375,
      2.453125,
      0.7578125,
      1.828125,
      4.03125,
      -2.8125,
      -1.171875,
      -0.5859375,
      3.40625,
      -0.291015625,
      -0.578125,
      6.375,
      -2.90625,
      -4.9375,
      -0.625,
      0.8515625,
      -0.373046875,
      -0.76953125,
      2.125,
      1.7578125,
      -0.59765625,
      -0.0216064453125,
      2.5,
      0.4375,
      -3.421875,
      -0.609375,
      -2.203125,
      -6.15625,
      4.6875,
      -2.640625,
      -2.125,
      -0.9375,
      -3.546875,
      1.8828125,
      3.421875,
      0.039794921875,
      1.6640625,
      -0.365234375,
      4.34375,
      -5.1875,
      4.28125,
      -5.125,
      -6.1875,
      0.26953125,
      -0.5234375,
      -1.6328125,
      1.1640625,
      -1.859375,
      -1.0546875,
      0.123046875,
      -3.53125,
      -3.234375,
      -3.328125,
      -0.41796875,
      -0.26171875,
      0.2158203125,
      2.640625,
      -3.9375,
      0.6484375,
      -0.9296875,
      -2.53125,
      -2.421875,
      -1.2421875,
      -0.2578125,
      -1.6328125,
      1.6796875,
      -6.90625,
      -0.255859375,
      3.609375,
      3.828125,
      -2.234375,
      6.125,
      0.359375,
      -1.0390625,
      -0.54296875,
      3.4375,
      -3.484375,
      -0.5078125,
      0.01068115234375,
      -3.34375,
      -3.609375,
      -1.3203125,
      0.55078125,
      -2.890625,
      3.765625,
      -0.796875,
      -2.828125,
      -2.734375,
      -6.03125,
      -3.421875,
      -2.15625,
      -2.75,
      1.3046875,
      1.8359375,
      -0.6328125,
      -2.125,
      2.0625,
      0.302734375,
      2.015625,
      1.265625,
      -3.21875,
      2.734375,
      -0.58984375,
      2.953125,
      -2.46875,
      -6.40625,
      -0.251953125,
      0.236328125,
      -4.5,
      4.5625,
      -0.98046875,
      1.7734375,
      1.5625,
      3.65625,
      -4.8125,
      -1.5625,
      5.3125,
      -5.09375,
      0.26953125,
      0.031494140625,
      3.390625,
      -0.65234375,
      4.21875,
      2.265625,
      -3.296875,
      0.3515625,
      4.65625,
      0.6328125,
      -0.60546875,
      -3.875,
      2.765625,
      0.6484375,
      2.46875,
      -5.5,
      -4.0625,
      2.375,
      0.71484375,
      0.1650390625,
      -2.015625,
      6.1875,
      1.015625,
      0.87890625,
      -1.1953125,
      3.15625,
      4.1875,
      0.6640625,
      0.69921875,
      -2.53125,
      0.81640625,
      0.8515625,
      -1.7578125,
      -0.64453125,
      -1.0546875,
      -1.796875,
      -2.859375,
      -0.984375,
      -4.53125,
      6.21875,
      0.126953125,
      -1.4296875,
      -1.5078125,
      1.265625,
      1.578125,
      5.6875,
      4.84375,
      -3.234375,
      -0.53125,
      4.75,
      6.5625,
      -2.09375,
      6.46875,
      -0.439453125,
      8.0625,
      -3.3125,
      -1.1015625,
      4.1875,
      2.25,
      0.25,
      -0.435546875,
      -7.84375,
      -4.15625,
      -0.65234375,
      1.8203125,
      -2.453125,
      2.09375,
      -4.25,
      0.359375,
      4.21875,
      3.46875,
      3.21875,
      2.109375,
      4.3125,
      -0.2080078125,
      0.7734375,
      -1.703125,
      -1.515625,
      -2.109375,
      -2.5,
      -0.17578125,
      -2.265625,
      -0.62109375,
      2.984375,
      3.953125,
      1.1015625,
      -0.82421875,
      -2.296875,
      5.78125,
      1.171875,
      -0.498046875,
      2.25,
      1.515625,
      0.048095703125,
      0.75390625,
      3.515625,
      -3.265625,
      -0.36328125,
      7.59375,
      3.6875,
      -3.703125,
      1.7265625,
      -0.63671875,
      1.53125,
      -3.96875,
      -0.0286865234375,
      -0.29296875,
      -1.453125,
      -2.921875,
      -4.25,
      1.3125,
      0.50390625,
      -5.21875,
      2.25,
      -1.6484375,
      -7.15625,
      -0.09423828125,
      4.59375,
      0.7421875,
      1.625,
      0.4140625,
      4.375,
      -3.796875,
      -6.65625,
      -2.984375,
      -5.34375,
      -2.125,
      -1.078125,
      -0.6796875,
      1.3984375,
      2.34375,
      -4.625,
      3.875,
      -6.875,
      -1.3203125,
      -3.203125,
      2.890625,
      4.4375,
      -4.6875,
      1.0078125,
      -3.390625,
      -10.8125,
      -3.25,
      -4.625,
      -2.5625,
      -1.140625,
      -5.375,
      -2.609375,
      1.5703125,
      -6.15625,
      0.126953125,
      -2.890625,
      -0.042236328125,
      2.703125,
      1.125,
      -0.2431640625,
      -2.734375,
      2.09375,
      3.53125,
      -2.0625,
      3.03125,
      1.5,
      3.421875,
      1.65625,
      0.77734375,
      -0.08203125,
      -1.484375,
      5.0625,
      -3.53125,
      5.75,
      3.21875,
      0.8671875,
      -4.75,
      3.328125,
      0.41015625,
      4.15625,
      -4.25,
      0.30859375,
      -0.34375,
      -0.4453125,
      3.875,
      0.353515625,
      3,
      -4.28125,
      -3.546875,
      1.78125,
      -3.484375,
      1.7109375,
      3.5625,
      0.474609375,
      1.1953125,
      0.56640625,
      0.8203125,
      0.455078125,
      0.51953125,
      3.140625,
      -0.08056640625,
      -0.33984375,
      -3.453125,
      1.625,
      1.15625,
      -1.71875,
      1.0390625,
      -2.453125,
      -0.76953125,
      -0.54296875,
      1.5078125,
      3.046875,
      1.78125,
      3.515625,
      2.59375,
      0.5703125,
      0.26171875,
      -2.5625,
      -1.8125,
      -1.203125,
      6.03125,
      3.0625,
      2.78125,
      -0.447265625,
      -0.154296875,
      -1.28125,
      0.58203125,
      0.3671875,
      -8.3125,
      -3.703125,
      -2.0625,
      -3.53125,
      4.09375,
      -1.7890625,
      -0.0986328125,
      -0.14453125,
      2.296875,
      4.375,
      2.40625,
      -0.2734375,
      1.5625,
      -0.50390625,
      -1.8359375,
      3.5,
      -3.71875,
      -1.75,
      5.09375,
      0.29296875,
      4.15625,
      1.828125,
      -1.0234375,
      -0.392578125,
      2.5625,
      4.625,
      0.69921875,
      -2.171875,
      5.46875,
      -0.8515625,
      -2.265625,
      -0.0010223388671875,
      -2.984375,
      0.7265625,
      -0.1123046875,
      1.6953125,
      5.5625,
      5.0625,
      -1.671875,
      -1.2734375,
      -2.765625,
      0.25390625,
      1.796875,
      -2.09375,
      -0.6796875,
      1.234375,
      0.79296875,
      -0.4453125,
      -0.625,
      -0.5625,
      0.71484375,
      -3.171875,
      -2.296875,
      2.765625,
      -1.2421875,
      0.81640625,
      0.4765625,
      1.8046875,
      -3.71875,
      0.39453125,
      2.28125,
      -2.625,
      0.984375,
      2.015625,
      1.7734375,
      3.78125,
      2.109375,
      0.50390625,
      4.15625,
      -2.859375,
      -4.1875,
      1.640625,
      -0.984375,
      1.7265625,
      -3.6875,
      -0.404296875,
      2.5625,
      3.78125,
      -1.4453125,
      5.09375,
      -0.2060546875,
      -0.9765625,
      1.890625,
      -3.796875,
      -6.625,
      -4.125,
      -0.875,
      -0.71875,
      -1.6640625,
      -0.0027008056640625,
      0.828125,
      0.9140625,
      -3.515625,
      3.921875,
      -2.28125,
      6.75,
      1.6640625,
      -0.86328125,
      2.546875,
      0.11279296875,
      2.046875,
      -1.921875,
      4.15625,
      0.1806640625,
      -1.984375,
      5.03125,
      -4.625,
      0.359375,
      0.51171875,
      -0.55859375,
      1.8984375,
      -3.796875,
      -0.09033203125,
      0.027099609375,
      0.1083984375,
      -6.28125,
      -3.609375,
      -0.71484375,
      -0.68359375,
      1.1875,
      -2.140625,
      -2.171875,
      -0.1796875,
      2.890625,
      -2.71875,
      2.546875,
      -4.28125,
      -0.7734375,
      3.296875,
      -1.21875,
      2.3125,
      1.4609375,
      -2.921875,
      -1.625,
      -0.66015625,
      -4.84375,
      -5.21875,
      -1.609375,
      2.546875,
      -6.53125,
      -1.3515625,
      0.365234375,
      0.609375,
      0.486328125,
      1.2734375,
      2.40625,
      0.08447265625,
      2.453125,
      -1.15625,
      2.4375,
      -3.8125,
      3.25,
      -2.828125,
      -5.15625,
      -3.453125,
      3.015625,
      2.1875,
      -2.671875,
      3.015625,
      -0.9609375,
      2.859375,
      1.9921875,
      -0.875,
      -1.9140625,
      0.76171875,
      3.671875,
      0.07080078125,
      -0.3828125,
      1.6875,
      2.375,
      1.9921875,
      -3,
      -4.0625,
      -4.0625,
      1.3125,
      -2.546875,
      0.2578125,
      3.046875,
      -0.455078125,
      -0.34765625,
      -2.1875,
      -3.3125,
      0.279296875,
      4.75,
      2.90625,
      2.921875,
      1.8125,
      3.703125,
      -1.59375,
      -1.5390625,
      -1.3828125,
      4.6875,
      2.484375,
      -1.21875,
      2.421875,
      0.6875,
      3.703125,
      -0.435546875,
      -2.109375,
      -3.390625,
      1.6796875,
      6.5,
      2.71875,
      -1.8515625,
      1.3203125,
      -0.79296875,
      1.8671875,
      1.8046875,
      1.46875,
      -3.921875,
      -2.890625,
      -1.765625,
      1.7265625,
      1.9765625,
      -6.1875,
      2.5,
      -2.921875,
      2.046875,
      4.46875,
      1.0390625,
      3.828125,
      -0.421875,
      0.55859375,
      -1.9921875,
      -3.4375,
      -2.328125,
      4.40625,
      0.022216796875,
      2.125,
      -1.453125,
      -6.59375,
      -3.546875,
      -2.03125,
      -0.328125,
      4.96875,
      -0.328125,
      -1.0546875,
      -3.640625,
      3.828125,
      3.5,
      1.4453125,
      -3.984375,
      1.3359375,
      0.859375,
      -1.7421875,
      -0.65625,
      -4.96875,
      -1.3828125,
      -0.89453125,
      -8.1875,
      2.640625,
      1.4609375,
      -0.04443359375,
      1.8828125,
      -1.921875,
      3.15625,
      1.25,
      -2.46875,
      -1.140625,
      -1.3671875,
      2.171875,
      1.03125,
      -0.1259765625,
      -1.40625,
      3.046875,
      -0.62890625,
      0.1669921875,
      -3.046875,
      3.171875,
      -3.15625,
      1.703125,
      5.46875,
      3.03125,
      -5.375,
      0.72265625,
      -2.171875,
      -1.65625,
      -2.4375,
      -0.380859375,
      2.3125,
      1.53125,
      1.9375,
      -0.181640625,
      -2.796875,
      -0.9453125,
      -1.8046875,
      3.953125,
      1.671875,
      1.3203125,
      -5.65625,
      4,
      -5.65625,
      -1.40625,
      5.90625,
      -3.21875,
      -1.3984375,
      0.8203125,
      1.5,
      3.359375,
      2.421875,
      -0.8359375,
      -5.25,
      0.56640625,
      -2,
      -1.8046875,
      -5.5,
      5.1875,
      -1.9296875,
      -1.90625,
      3.421875,
      -1.890625,
      1.9453125,
      -0.78125,
      -3.046875,
      -1.9453125,
      -0.63671875,
      0.07666015625,
      2.125,
      1.9921875,
      -0.6953125,
      -3.09375,
      0.1513671875,
      4.21875,
      1.7578125,
      -1.921875,
      2.484375,
      -2.8125,
      2.40625,
      -7.4375,
      4.71875,
      1.1875,
      -0.2177734375,
      4.09375,
      3,
      -3.921875,
      2.640625,
      2.53125,
      3.515625,
      -1.5234375,
      -1.2265625,
      1.421875,
      2.734375,
      -5.03125,
      0.96484375,
      -3.515625,
      -0.3125,
      -0.0791015625,
      -1.8203125,
      1.1640625,
      1.2578125,
      1.9765625,
      -3.359375,
      1.328125,
      1.25,
      0.51953125,
      4.125,
      -3.5625,
      1.0546875,
      1.5,
      -1.7109375,
      4.21875,
      0.28125,
      -2.34375,
      -0.76171875,
      2.46875,
      -5.65625,
      -0.90625,
      -6.90625,
      1.0859375,
      -3.90625,
      -1.8671875,
      0.03857421875,
      1.4609375,
      0.95703125,
      1.6640625,
      0.1279296875,
      -2.234375,
      -2.171875,
      -4.5,
      -0.20703125,
      -4.625,
      -5.0625,
      -0.5234375,
      1.5859375,
      1.8984375,
      1.9296875,
      4.78125,
      3.5625,
      -2.875,
      0.486328125,
      -1,
      3.3125,
      -2.75,
      -0.2373046875,
      -1.53125,
      -0.4140625,
      3.3125,
      -1.1484375,
      3.53125,
      -7.03125,
      -3.171875,
      -3.0625,
      0.94921875,
      0.91796875,
      -1.5078125,
      -4.03125,
      1.0703125,
      5.0625,
      -0.30859375,
      4.875,
      0.310546875,
      -1.21875,
      -1.703125,
      -0.2138671875,
      -0.68359375,
      3.046875,
      2.328125,
      0.60546875,
      -3.65625,
      3.421875,
      2.9375,
      0.6484375,
      4.65625,
      -0.0208740234375,
      -0.427734375,
      -6.65625,
      2.78125,
      0.53515625,
      4.1875,
      -1.875,
      1.65625,
      3.984375,
      -0.55078125,
      5.0625,
      8.6875,
      -0.54296875,
      -2.9375,
      2.59375,
      0.63671875,
      -0.9453125,
      -0.83203125,
      2.6875,
      -2.515625,
      -1.71875,
      2.1875,
      -0.37109375,
      1.25,
      -0.421875,
      2.359375,
      3.6875,
      2.109375,
      -5.8125,
      2.53125,
      -7.40625,
      0.953125,
      -3.84375,
      3.171875,
      -6.3125,
      1.3671875,
      0.6875,
      2.640625,
      -0.7890625,
      -1.390625,
      2.25,
      1.84375,
      1.3125,
      -4.03125,
      3.734375,
      1.09375,
      0.37890625,
      -2.1875,
      -3.421875,
      2.8125,
      -1.59375,
      -0.96484375,
      -1.7734375,
      0.57421875,
      1.1484375,
      -4.4375,
      -4.53125,
      1.0703125,
      0.07421875,
      -8,
      -2.984375,
      0.0262451171875,
      -1.5859375,
      -6.0625,
      2.09375,
      3,
      0.71484375,
      2.171875,
      -2.328125,
      2.734375,
      0.416015625,
      2.25,
      4.96875,
      -0.69921875,
      -1.5546875,
      -0.298828125,
      2.71875,
      -2.75,
      1.78125,
      -0.85546875,
      2.28125,
      -1.203125,
      -1.5859375,
      -0.5546875,
      -5.15625,
      -0.2099609375,
      4.75,
      3.359375,
      0.51953125,
      -1.3984375,
      0.8828125,
      -0.0537109375,
      -0.2119140625,
      -0.79296875,
      1.9140625,
      -0.04931640625,
      -0.2021484375,
      -1.4375,
      -0.08251953125,
      2.90625,
      -0.271484375,
      2.671875,
      -0.89453125,
      0.74609375,
      -4.21875,
      -2.46875,
      -3.78125,
      -0.9140625,
      -2.265625,
      2.21875,
      -1.796875,
      -2.484375,
      0.54296875,
      2.59375,
      -1.515625,
      -0.140625,
      -0.451171875,
      -1.2890625,
      1.0546875,
      2.859375,
      -0.98046875,
      -3.359375,
      0.162109375,
      -0.69921875,
      0.62109375,
      -0.306640625,
      -1.5234375,
      -1.703125,
      3.546875,
      -0.310546875,
      0.515625,
      0.69921875,
      2.875,
      0.11767578125,
      -9.1875,
      -0.09521484375,
      1.109375,
      -1.0703125,
      -3.3125,
      0.0830078125,
      5.28125,
      1.7265625,
      2.390625,
      2.796875,
      -0.94140625,
      -2.15625,
      3.328125,
      14.9375,
      -1.640625,
      -5.375,
      0.1728515625,
      -4.34375,
      3.359375,
      6.125,
      0.1943359375,
      -2.875,
      -2.546875,
      0.25390625,
      1.265625,
      0.86328125,
      2.09375,
      -1.625,
      -2.359375,
      3.703125,
      -2.625,
      0.034423828125,
      -4.09375,
      -1.21875,
      -0.1591796875,
      -2.546875,
      2.96875,
      0.392578125,
      0.9609375,
      0.01226806640625,
      0.462890625,
      -0.337890625,
      -0.9921875,
      -1.546875,
      -1.8203125,
      -3.296875,
      -2.875,
      -0.396484375,
      -4.28125,
      2.125,
      2.328125,
      -0.98828125,
      0.71484375,
      -4.34375,
      -2.84375,
      1.25,
      -1.7109375,
      -2.171875,
      1.3515625,
      -0.65234375,
      0.028076171875,
      3.390625,
      -1.21875,
      -0.671875,
      -3.40625,
      -1.2578125,
      4.71875,
      0.4453125,
      -1.171875,
      -0.1171875,
      -4.625,
      -4.71875,
      -4.65625,
      1.2890625,
      -2.140625,
      -3.640625,
      -2.03125,
      0.6953125,
      -2.3125,
      -0.765625,
      0.765625,
      0.89453125,
      2.375,
      -3.640625,
      0.12158203125,
      3.15625,
      3.78125,
      0.9765625,
      -1.9296875,
      2.484375,
      3.421875,
      0.36328125,
      0.9140625,
      -0.1943359375,
      0.83203125,
      -4.625,
      0.185546875,
      -3.90625,
      0.404296875,
      -3.953125,
      2.265625,
      1.3984375,
      0.9453125,
      6.59375,
      -5.25,
      4.28125,
      1.796875,
      0.69140625,
      -3.578125,
      3.734375,
      1.546875,
      -0.2138671875,
      -1.890625,
      1.9296875,
      0.89453125,
      0.400390625,
      -1.5234375,
      1.1328125,
      -2.125,
      3.40625,
      -1.359375,
      4.1875,
      -0.61328125,
      -2.359375,
      1.3046875,
      -1.0234375,
      0.02490234375,
      0.1455078125,
      1.1796875,
      -3.09375,
      -3.03125,
      2.859375,
      -2.6875,
      2.90625,
      -1.3515625,
      -3.71875,
      -0.78125,
      -9,
      -5.875,
      -1.515625,
      -3.9375,
      1.9765625,
      -5.40625,
      -0.83203125,
      0.3046875,
      -2.65625,
      -4.15625,
      2.859375,
      -4.15625,
      2.203125,
      2.265625,
      1.5546875,
      0.93359375,
      -0.455078125,
      -1.03125,
      2.75,
      -5.03125,
      -1.234375,
      0.87109375,
      -4.09375,
      2.609375,
      4.96875,
      2.703125,
      0.5390625,
      2.953125,
      1.296875,
      -0.546875,
      0.8046875,
      2.734375,
      0.828125,
      -0.765625,
      -4.53125,
      -1.7109375,
      -1.4765625,
      -0.54296875,
      -2,
      -2.34375,
      -1.9140625,
      -1.59375,
      3.671875,
      1.015625,
      -4.6875,
      3.125,
      1.421875,
      -5.09375,
      -0.25390625,
      -1.3359375,
      6.3125,
      -2.140625,
      2.171875,
      6.65625,
      -2.0625,
      2.265625,
      3.15625,
      4.15625,
      -0.9140625,
      -2.6875,
      0.140625,
      3.640625,
      -5.25,
      3.546875,
      2.859375,
      0.57421875,
      -0.5703125,
      -2.359375,
      -4.375,
      4.96875,
      4.40625,
      -5.53125,
      1.0703125,
      0.5078125,
      2.828125,
      0.050537109375,
      -2.34375,
      2.4375,
      -0.5078125,
      1.25,
      0.953125,
      -0.546875,
      -2.53125,
      -0.12060546875,
      -3.84375,
      -0.29296875,
      -2.484375,
      1.09375,
      1.59375,
      1.453125,
      -5.40625,
      6.6875,
      1.4609375,
      0.68359375,
      -2.984375,
      2.3125,
      1.6875,
      -0.48828125,
      -4.4375,
      0.5625,
      -1.4921875,
      3.640625,
      -3.234375,
      2.375,
      -0.58984375,
      1.71875,
      1.328125,
      1.5859375,
      -1.4921875,
      1.859375,
      -2.921875,
      -2.203125,
      -3.671875,
      3.375,
      -2.5625,
      1.078125,
      1.65625,
      -1.2109375,
      1.8203125,
      1.1796875,
      -1.7109375,
      0.98828125,
      1.9921875,
      -1.8984375,
      2.609375,
      -0.0289306640625,
      1.7265625,
      0.52734375,
      3.65625,
      -1.140625,
      -2.5,
      -2.90625,
      -3.421875,
      0.85546875,
      -4.625,
      0.018798828125,
      1.1875,
      -4.5625,
      4.75,
      -1.2265625,
      0.26171875,
      1.09375,
      -0.046630859375,
      -5.21875,
      2.21875,
      2.84375,
      -5.34375,
      3.890625,
      1.171875,
      -2.5625,
      1.515625,
      -1.8828125,
      0.2431640625,
      -4.875,
      1.7421875,
      -0.0771484375,
      -3.671875,
      -0.609375,
      2.515625,
      0.435546875,
      2.109375,
      -2.734375,
      3.0625,
      1.8984375,
      5.40625,
      0.76953125,
      2.359375,
      5.46875,
      -3.125,
      0.470703125,
      -3.359375,
      4.1875,
      -1.2421875,
      0.1416015625,
      0.42578125,
      -1.71875,
      2.625,
      0.9609375,
      -0.1240234375,
      -5.46875,
      -3.25,
      0.62109375,
      -0.93359375,
      3.421875,
      0.220703125,
      0.4375,
      -1.8359375,
      -1.15625,
      1.421875,
      5.25,
      -1.34375,
      -2.28125,
      -3.671875,
      2.265625,
      -0.640625,
      -5.78125,
      -1.1640625,
      -1.4765625,
      -2.140625,
      -1.46875,
      -3.6875,
      -2.4375,
      0.88671875,
      3.296875,
      -6.875,
      2.015625,
      2.734375,
      0.05712890625,
      3.734375,
      -0.0966796875,
      2.53125,
      1.6875,
      -3.953125,
      -5.375,
      2.96875,
      -0.1005859375,
      0.28125,
      1.7421875,
      -4.625,
      3.125,
      1.1171875,
      6.84375,
      -6.1875,
      5.15625,
      0.97265625,
      -7.78125,
      3.15625,
      -3.3125,
      1.921875,
      -3.546875,
      -4.28125,
      -4.625,
      2.40625,
      3,
      2.140625,
      3.3125,
      -0.1572265625,
      -0.7265625,
      2.6875,
      -0.65234375,
      -0.1025390625,
      -0.5234375,
      2.140625,
      -1.546875,
      2.359375,
      3.5,
      -2,
      -1.5390625,
      -0.7890625,
      1.3125,
      -1.328125,
      -2.84375,
      5.96875,
      3.15625,
      1.3359375,
      -0.671875,
      -4.1875,
      -0.080078125,
      -1.21875,
      -3.140625,
      -0.059326171875,
      -2.984375,
      2.4375,
      -2.46875,
      1.5859375,
      0.703125,
      -5.4375,
      -2.171875,
      -1.796875,
      -1.6484375,
      0.75,
      -0.00689697265625,
      0.1201171875,
      -0.7734375,
      2.75,
      5.78125,
      1.671875,
      -1.671875,
      -2.375,
      1.0703125,
      -0.37109375,
      -2.71875,
      -3.078125,
      1.65625,
      -4.1875,
      -3.09375,
      3.484375,
      -1.1015625,
      0.84765625,
      -2.515625,
      -2.109375,
      0.73828125,
      4.6875,
      0.208984375,
      -0.71875,
      -2.1875,
      -1.0078125,
      1.0859375,
      -5.59375,
      -1.515625,
      1.7109375,
      1.0859375,
      -4.90625,
      0.9609375,
      0.5078125,
      -0.263671875,
      1.1328125,
      3.109375,
      0.59765625,
      -1.0390625,
      0.73046875,
      -7.84375,
      -0.41015625,
      5.59375,
      1.3828125,
      -0.04052734375,
      -0.44921875,
      -1.28125,
      -2.78125,
      3.609375,
      5.59375,
      -0.7734375,
      -1.828125,
      1.1484375,
      -0.61328125,
      -3.890625,
      -2.28125,
      1.296875,
      0.1376953125,
      -7,
      8.1875,
      -2.375,
      2.28125,
      1.6015625,
      0.7890625,
      6.1875,
      2.375,
      1.5390625,
      1.515625,
      -0.388671875,
      1.75,
      -4.4375,
      0.4140625,
      -1.078125,
      -3.21875,
      -1.484375,
      1.625,
      2.53125,
      0.86328125,
      5.5,
      -2.859375,
      0.01470947265625,
      1.3828125,
      -3.578125,
      3.671875,
      0.193359375,
      -4.03125,
      -0.3046875,
      -3.703125,
      0.2578125,
      -1.0703125,
      2.65625,
      -4.375,
      -2.734375,
      -2.65625,
      1.5,
      -1.0234375,
      0.005126953125,
      -1.8984375,
      -3.78125,
      0.337890625,
      1.46875,
      1.671875,
      4.15625,
      2.34375,
      3.453125,
      -1.2890625,
      -1.6484375,
      3.65625,
      4.59375,
      2.796875,
      -4.40625,
      0.1533203125,
      0.04248046875,
      0.3671875,
      -2.25,
      1.4609375,
      2.109375,
      -1.203125,
      3.828125,
      -0.62890625,
      1.1953125,
      -0.5703125,
      -1.75,
      -2.921875,
      0.431640625,
      0.8125,
      1.328125,
      1.1015625,
      -1.875,
      -0.263671875,
      2.234375,
      0.484375,
      0.166015625,
      0.015869140625,
      -0.71484375,
      -2.328125,
      -0.38671875,
      0.69921875,
      -0.8046875,
      0.1435546875,
      -3.765625,
      -0.8671875,
      -0.416015625,
      -0.953125,
      2.03125,
      2.09375,
      -0.89453125,
      4.40625,
      -0.443359375,
      -1.5078125,
      1.09375,
      -0.61328125,
      0.62109375,
      -0.025634765625,
      0.83203125,
      3,
      -1.484375,
      1.3203125,
      1.078125,
      4.59375,
      1.703125,
      0.87890625,
      1.75,
      1.1171875,
      -1.7578125,
      -0.984375,
      -1.734375,
      0.373046875,
      3.515625,
      0.96484375,
      0.87109375,
      0.2890625,
      -2.234375,
      -2.515625,
      0.98046875,
      -3.375,
      -1.296875,
      -0.22265625,
      0.75,
      -1.0234375,
      1.03125,
      3.78125,
      1.359375,
      0.19140625,
      -1.390625,
      -0.953125,
      -1.109375,
      0.7890625,
      -4.375,
      1.3203125,
      -2.125,
      1.640625,
      -0.0849609375,
      3.421875,
      3.765625,
      1.59375,
      -0.9609375,
      -0.63671875,
      -0.298828125,
      -0.62890625,
      0.048583984375,
      -1.671875,
      -1.1484375,
      4.46875,
      0.76171875,
      -1.265625,
      -0.498046875,
      -3.203125,
      -1.671875,
      1.109375,
      2.59375,
      2.265625,
      -1.2734375,
      -2.71875,
      1.6953125,
      -1.390625,
      3.28125,
      1.2421875,
      -1.3359375,
      3.1875,
      -1.5234375,
      0.37890625,
      0.53515625,
      -1.9765625,
      3.9375,
      1.1015625,
      -2.34375,
      -2.4375,
      1.5859375,
      -1.2890625,
      -1.8046875,
      -1.453125,
      -1.515625,
      -1.140625,
      -2.171875,
      -0.35546875,
      -0.1943359375,
      -1.0703125,
      -3.28125,
      -0.48046875,
      -1.453125,
      -2.984375,
      -2.328125,
      0.1953125,
      -1.6171875,
      -0.86328125,
      -2.59375,
      -1.3125,
      0.2197265625,
      1.2734375,
      -2.78125,
      -0.0289306640625,
      2.375,
      -1.7109375,
      1.625,
      -0.9296875,
      -0.10546875,
      1.7734375,
      1.1484375,
      -0.1611328125,
      0.60546875,
      0.97265625,
      1.375,
      0.796875,
      2.390625,
      -1.65625,
      -1.7890625,
      -0.002410888671875,
      1.0625,
      -2.078125,
      2.796875,
      -0.259765625,
      -2.359375,
      0.57421875,
      -3.53125,
      -1.0859375,
      -2.953125,
      3.265625,
      -0.875,
      -1.296875,
      -0.1904296875,
      -0.8671875,
      2.046875,
      0.97265625,
      -1.828125,
      -1.1171875,
      2.109375,
      -1.4765625,
      2.46875,
      1.6328125,
      1.703125,
      0.306640625,
      3.015625,
      -1.4296875,
      -1.1640625,
      -1.1015625,
      0.57421875,
      -2.625,
      -0.0810546875,
      -2.765625,
      2.5,
      1.390625,
      2.25,
      2.046875,
      -0.59765625,
      -2.5,
      7.65625,
      -0.96484375,
      -0.91015625,
      -0.92578125,
      -0.76171875,
      -0.0107421875,
      0.64453125,
      -1,
      -0.05810546875,
      -2.03125,
      1.9453125,
      0.703125,
      -2.890625,
      0.9453125,
      -1.7109375,
      -0.55859375,
      2.671875,
      0.40625,
      -3.765625,
      1.6015625,
      -0.48828125,
      0.3515625,
      -0.75,
      -0.8671875,
      -1.078125,
      1.09375,
      -0.1298828125,
      1.6171875,
      -1.1640625,
      0.498046875,
      0.232421875,
      0.65625,
      1.484375,
      -1.1484375,
      1.8828125,
      3.328125,
      1.953125,
      -1.078125,
      1.7265625,
      -0.294921875,
      -2.71875,
      -0.478515625,
      2.46875,
      0.56640625,
      2.890625,
      -0.8125,
      -0.8203125,
      2.671875,
      -0.83203125,
      0.859375,
      -1.3203125,
      -3.546875,
      -0.216796875,
      -1.59375,
      -2.328125,
      0.41015625,
      4.84375,
      1.578125,
      -0.57421875,
      0.67578125,
      -2.703125,
      3.65625,
      0.33203125,
      -1.09375,
      0.8828125,
      -0.76171875,
      0.5234375,
      -0.1328125,
      0.384765625,
      -1.328125,
      1.5625,
      -0.0693359375,
      -0.74609375,
      1.1328125,
      -2.21875,
      -0.5,
      1.328125,
      -1.125,
      -2.796875,
      -1.71875,
      -0.5625,
      1.96875,
      -2.546875,
      4.40625,
      0.10107421875,
      4.59375,
      0.9609375,
      -1.828125,
      -1.3984375,
      1.5234375,
      4.6875,
      2.046875,
      -1.125,
      -1.84375,
      -1.2734375,
      1.234375,
      2.59375,
      1.609375,
      -0.99609375,
      4.0625,
      0.41796875,
      -0.498046875,
      -1.5,
      -1.5234375,
      -0.06884765625,
      1.765625,
      5.5,
      -3.1875,
      -2.609375,
      0.050048828125,
      0.388671875,
      3.296875,
      3.0625,
      1.6484375,
      2.984375,
      2.125,
      -0.369140625,
      2.421875,
      -2.765625,
      0.1201171875,
      0.30078125,
      0.328125,
      2.078125,
      -0.6953125,
      -1.2109375,
      1.4296875,
      -4.34375,
      1.65625,
      -0.47265625,
      1.9140625,
      3.890625,
      -1.5625,
      -0.0126953125,
      -1.2421875,
      -0.5078125,
      2.421875,
      1.7734375,
      -0.609375,
      2.984375,
      -1.4375,
      5.21875,
      3.203125,
      0.703125,
      -3.328125,
      3.5,
      0.8671875,
      -2.890625,
      1.015625,
      -1.9453125,
      -2.65625,
      0.2236328125,
      -3.515625,
      -1.3359375,
      -2.4375,
      3.515625,
      -4.15625,
      2.625,
      4.0625,
      2.640625,
      3.09375,
      3.59375,
      -1.390625,
      1.6171875,
      -0.5390625,
      -4.375,
      3.265625,
      -1.46875,
      -4.375,
      2.078125,
      1.296875,
      -2.921875,
      -1.7890625,
      -2.9375,
      0.67578125,
      1.1015625,
      -1.1796875,
      -2.15625,
      0.95703125,
      1.6171875,
      -0.4140625,
      0.78515625,
      -1,
      -2.71875,
      -1.203125,
      3.28125,
      1.09375,
      0.126953125,
      -0.216796875,
      -0.703125,
      -0.271484375,
      0.29296875,
      -1.2890625,
      0.69140625,
      -1.21875,
      1.578125,
      1.125,
      1.2890625,
      -1.453125,
      -3.71875,
      1.8671875,
      0.37109375,
      1.265625,
      -0.23828125,
      1.1875,
      0.59765625,
      4.375,
      1.703125,
      1.3046875,
      -2.875,
      1.8828125,
      -3.125,
      1.75,
      -0.63671875,
      -1.5,
      -1.65625,
      3.0625,
      -1.1640625,
      -0.9140625,
      0.96875,
      1.3203125,
      1.96875,
      -2.671875,
      0.408203125,
      -2.359375,
      -3,
      3.265625,
      -0.051513671875,
      -0.52734375,
      -2,
      1.4296875,
      -3.1875,
      -0.055419921875,
      0.91796875,
      -2.4375,
      1.9921875,
      0.255859375,
      -1.484375,
      0.859375,
      0.73828125,
      -0.1708984375,
      2.15625,
      -1.625,
      1.9375,
      0.48046875,
      0.5390625,
      -0.8203125,
      -0.55078125,
      2.65625,
      -2.28125,
      -6.40625,
      -2.078125,
      0.10791015625,
      -0.7421875,
      -1.4921875,
      3.8125,
      0.130859375,
      2.484375,
      -1.6796875,
      -0.7734375,
      0.5546875,
      0.146484375,
      2.328125,
      -0.302734375,
      -1.6484375,
      -3.921875,
      -0.41796875,
      -0.609375,
      0.3515625,
      1.2109375,
      -1.453125,
      2.03125,
      0.400390625,
      -1.078125,
      -0.80859375,
      2.546875,
      -0.322265625,
      2.359375,
      -0.9375,
      -1.453125,
      -1.78125,
      2.0625,
      -2.15625,
      2.734375,
      1.4609375,
      2.546875,
      0.51953125,
      -0.423828125,
      -1.1875,
      -3.90625,
      1.4375,
      1.65625,
      -1.9375,
      1.8515625,
      -0.765625,
      1.2421875,
      0.08740234375,
      -0.984375,
      2.421875,
      2.25,
      1.1171875,
      -2.796875,
      0.75,
      -1.9453125,
      4.21875,
      0.66015625,
      0.07568359375,
      1.7109375,
      -0.96484375,
      -2.625,
      4.375,
      1.3046875
    ],
    "summary": "### 1. 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 现有教育工具“服务不全、性能不足、交互弱”，尤其缺 LaTeX Beamer 自动生成与多角色互动笔记 [cite: Abstract]。 |\n| **核心方案 (The Solution)** | EZYer =「教师模块（Beamer 生成）+ 学生模块（4 角色对话+笔记）+ 控制器（四重质检）」三合一的 LLM 驱动高中数学仿真课堂。 |\n| **关键概念 (Design Logic)** | 用“角色扮演”代替纯 prompt：把一堂课拆成教师、助教、学霸、学渣、记录员 5 个智能体，按固定顺序输出→汇总成笔记。 |\n| **核心数据** | 无公开训练集；仅自采 100 份高中数学素材→生成 100 份 Beamer + 100 份 Notes，再用 5 个 LLM 打分。 |\n| **核心假设和变量** | 假设：只要角色脚本足够细，LLM 就能稳定输出教学合规内容；变量：5 维评分（准确性、覆盖率、可用性、格式、视觉）。 |\n| **主要结论** | 自评 5 个 LLM 打分均 >4/5，作者宣称“质量优秀、前景良好” [cite: Abstract & Section 4]。 |\n\n---\n\n### 2. 💡 深度解读 (The Feynman Explanation)\n\n想象你在拍一部“高中数学小剧场”：\n\n- **老办法**（单 prompt）= 把剧本全塞给一位演员，让他一人分饰五角，结果常常背错台词、串戏、甚至胡说八道。  \n- **EZYer 办法**= 请 5 位真人演员，每人只背自己的台词：老师先讲知识点，助教补充，学霸举一反三，学渣专挑易错点，最后记录员把全场对话整理成一篇笔记。因为每个人物脚本短而固定，演员不容易忘词，也更少“自由发挥”出戏。\n\n为什么“分角色”就能让内容变严谨？  \n→ 把一次长生成拆成多轮短生成，每轮只聚焦一个小目标；错误被局限在单轮内，下一轮角色还能互相“纠错”，相当于用“流水线+交叉检查”把跑偏的台词当场剪掉。于是最终笔记既完整又相对可信——至少比一人独角戏更稳。\n\n---\n\n### 3. ⚔️ 评审视角 (The Adversarial Review)\n\n1. **数据源依赖 & 可复现性**  \n   100 份匿名高中讲义既未公开，也未说明抽样框架；别人拿不到同样 100 份原材料，就无法复现 Beamer/Notes 结果。没有语料清洗细节、去重策略，甚至是否涉及版权也零说明。\n\n2. **循环验证风险**  \n   用 LLM 给 LLM 打高分是“自己考自己”。5 个模型均来自同一文化圈（中文互联网语料），评分标准未盲测、未人工二次校验，极易出现“互相抬轿”型虚高。缺乏与人类教师/教研组的 ICC 系数，可信度≈0。\n\n3. **高难度≠高推理**  \n   角色脚本本质是让模型重复“模板化对话”：学霸→拓展，学渣→易错点。生成的“高难度”只是堆砌更多陈述句，并未产生需要多步逻辑链的崭新问题。学生真拿到笔记，仍可能只是背套路而非训练推理。\n\n4. **假设与变量漏洞**  \n   假设“角色脚本足够细就能稳定合规”，却未定义“足够细”的量化阈值；变量“可用性”由 LLM 打分，操作定义缺失，无法排除“格式花哨但教学错误”的假阳性。\n\n---\n\n### 4. 📝 一句话总结 (The Takeaway)\n\nEZYer 用“分角色流水线”把一次长生成拆成多轮短生成，自评虽高，却躲不开数据黑箱、循环验证与教学有效性三重硬伤。",
    "structure": {
      "sections": [
        {
          "title": "EZYer: A simulacrum of high school with generative agent",
          "level": 1,
          "start_line": 1
        },
        {
          "title": "ABSTRACT",
          "level": 1,
          "start_line": 36
        },
        {
          "title": "KEYWORDS",
          "level": 1,
          "start_line": 44
        },
        {
          "title": "1 INTRODUCTION",
          "level": 1,
          "start_line": 48
        },
        {
          "title": "2 EZYER",
          "level": 1,
          "start_line": 72
        },
        {
          "title": "2.1 Teacher Module",
          "level": 1,
          "start_line": 74
        },
        {
          "title": "Prompt",
          "level": 1,
          "start_line": 88
        },
        {
          "title": "2.2 Student Module",
          "level": 1,
          "start_line": 172
        },
        {
          "title": "Prompt",
          "level": 1,
          "start_line": 215
        },
        {
          "title": "2.3 Controller",
          "level": 1,
          "start_line": 241
        },
        {
          "title": "3 EVALUATION",
          "level": 1,
          "start_line": 274
        },
        {
          "title": "3.1 Scoring mechanism",
          "level": 1,
          "start_line": 278
        },
        {
          "title": "3.2 Evaluation by Large Language Model",
          "level": 1,
          "start_line": 288
        },
        {
          "title": "4 LIMITATIONS AND FUTURE WORK",
          "level": 1,
          "start_line": 297
        },
        {
          "title": "REFERENCES",
          "level": 1,
          "start_line": 307
        },
        {
          "title": "APPENDIX",
          "level": 1,
          "start_line": 346
        },
        {
          "title": "Appendix A",
          "level": 1,
          "start_line": 348
        },
        {
          "title": "Prompt for the generate teaching materials:",
          "level": 1,
          "start_line": 350
        },
        {
          "title": "Appendix B",
          "level": 1,
          "start_line": 422
        },
        {
          "title": "Prompt for roles:",
          "level": 1,
          "start_line": 424
        },
        {
          "title": "Appendix D",
          "level": 1,
          "start_line": 460
        }
      ]
    },
    "tags": [
      "生成式智能体",
      "教育AI",
      "LaTeX Beamer生成"
    ],
    "suggested_tags": [
      "生成式智能体",
      "教育AI",
      "LaTeX Beamer生成",
      "多角色协同",
      "内容质检机制"
    ],
    "tag_suggestions": [
      {
        "name": "生成式智能体",
        "confidence": 0.98,
        "reason": "论文核心贡献是构建EZYer——由教师、学生、笔记员等多角色LLM智能体协同的仿真系统，完全符合Generative Agent范式。"
      },
      {
        "name": "教育AI",
        "confidence": 0.96,
        "reason": "研究场景锁定高中数学教学，聚焦课件自动生成、互动笔记与内容质检，是典型的AI+教育应用。"
      },
      {
        "name": "LaTeX Beamer生成",
        "confidence": 0.92,
        "reason": "提出Teacher模块自动输出符合教学大纲的LaTeX Beamer课件，填补了现有教育工具对高质量排版课件支持的空白。"
      },
      {
        "name": "多角色协同",
        "confidence": 0.9,
        "reason": "通过Teacher、Assistant、Top Student、Struggling Student、Note Taker五类角色对话与协作，实现知识点多维度解析与笔记汇总，体现多智能体协同机制。"
      },
      {
        "name": "内容质检机制",
        "confidence": 0.88,
        "reason": "设计关键词过滤、内容评分、角色互验与动态纠错四级Controller，保证生成教学内容的学术严谨性与教学适切性。"
      }
    ],
    "tags_confirmed": true,
    "category": "生成式智能体",
    "analysis": {
      "status": "completed",
      "started_at": "2025-12-21T14:47:56.780870",
      "completed_at": "2025-12-21T14:48:53.843953",
      "summary": "### 1. 🎯 结构化速读 (The Skeleton)\n\n| 维度 | 关键内容提取 |\n| :--- | :--- |\n| **核心痛点** | 现有教育工具“服务不全、性能不足、交互弱”，尤其缺 LaTeX Beamer 自动生成与多角色互动笔记 [cite: Abstract]。 |\n| **核心方案 (The Solution)** | EZYer =「教师模块（Beamer 生成）+ 学生模块（4 角色对话+笔记）+ 控制器（四重质检）」三合一的 LLM 驱动高中数学仿真课堂。 |\n| **关键概念 (Design Logic)** | 用“角色扮演”代替纯 prompt：把一堂课拆成教师、助教、学霸、学渣、记录员 5 个智能体，按固定顺序输出→汇总成笔记。 |\n| **核心数据** | 无公开训练集；仅自采 100 份高中数学素材→生成 100 份 Beamer + 100 份 Notes，再用 5 个 LLM 打分。 |\n| **核心假设和变量** | 假设：只要角色脚本足够细，LLM 就能稳定输出教学合规内容；变量：5 维评分（准确性、覆盖率、可用性、格式、视觉）。 |\n| **主要结论** | 自评 5 个 LLM 打分均 >4/5，作者宣称“质量优秀、前景良好” [cite: Abstract & Section 4]。 |\n\n---\n\n### 2. 💡 深度解读 (The Feynman Explanation)\n\n想象你在拍一部“高中数学小剧场”：\n\n- **老办法**（单 prompt）= 把剧本全塞给一位演员，让他一人分饰五角，结果常常背错台词、串戏、甚至胡说八道。  \n- **EZYer 办法**= 请 5 位真人演员，每人只背自己的台词：老师先讲知识点，助教补充，学霸举一反三，学渣专挑易错点，最后记录员把全场对话整理成一篇笔记。因为每个人物脚本短而固定，演员不容易忘词，也更少“自由发挥”出戏。\n\n为什么“分角色”就能让内容变严谨？  \n→ 把一次长生成拆成多轮短生成，每轮只聚焦一个小目标；错误被局限在单轮内，下一轮角色还能互相“纠错”，相当于用“流水线+交叉检查”把跑偏的台词当场剪掉。于是最终笔记既完整又相对可信——至少比一人独角戏更稳。\n\n---\n\n### 3. ⚔️ 评审视角 (The Adversarial Review)\n\n1. **数据源依赖 & 可复现性**  \n   100 份匿名高中讲义既未公开，也未说明抽样框架；别人拿不到同样 100 份原材料，就无法复现 Beamer/Notes 结果。没有语料清洗细节、去重策略，甚至是否涉及版权也零说明。\n\n2. **循环验证风险**  \n   用 LLM 给 LLM 打高分是“自己考自己”。5 个模型均来自同一文化圈（中文互联网语料），评分标准未盲测、未人工二次校验，极易出现“互相抬轿”型虚高。缺乏与人类教师/教研组的 ICC 系数，可信度≈0。\n\n3. **高难度≠高推理**  \n   角色脚本本质是让模型重复“模板化对话”：学霸→拓展，学渣→易错点。生成的“高难度”只是堆砌更多陈述句，并未产生需要多步逻辑链的崭新问题。学生真拿到笔记，仍可能只是背套路而非训练推理。\n\n4. **假设与变量漏洞**  \n   假设“角色脚本足够细就能稳定合规”，却未定义“足够细”的量化阈值；变量“可用性”由 LLM 打分，操作定义缺失，无法排除“格式花哨但教学错误”的假阳性。\n\n---\n\n### 4. 📝 一句话总结 (The Takeaway)\n\nEZYer 用“分角色流水线”把一次长生成拆成多轮短生成，自评虽高，却躲不开数据黑箱、循环验证与教学有效性三重硬伤。"
    }
  }
}